id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2226136532,issue,closed,completed,Switching tabs reruns pivot table queries with no need,"### Describe the bug

Similar to already fixed #39863, but only affecting pivot tables. If I go back to a dashboard tab with a pivot table, it will rerun even though there's no reason for it (i.e. parameter values are the same, etc.)

> [!NOTE]
> For Metabase team: see this [internal thread](https://metaboat.slack.com/archives/C0645JP1W81/p1712249556925719) for more details

### To Reproduce

1. Create a pivot table (e.g. Count, Average of Total by Products.Category and People.Source)
2. Create a dashboard with two tabs, add the pivot table to ""Tab 1""
3. Open ""Tab 2""
4. Go back to ""Tab 1""
5. Notice that the FE sends a new dashcard query request

### Expected behavior

The FE should only rerun queries if something changed since the last run (e.g. parameters)

### Logs

_No response_

### Information about your Metabase installation

```JSON
49.3
```


### Severity

P2

### Additional context

_No response_",kulyk,2024-04-04 17:32:46+00:00,['kulyk'],2024-05-21 03:29:29+00:00,2024-05-21 03:29:29+00:00,https://github.com/metabase/metabase/issues/41043,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2226104726,issue,open,,Padding set to <Modal> doesn't work,"**Context**

The [default prop for the padding set on the ModalBody](https://github.com/metabase/metabase/blob/1f93ba5c6cb3eb89316ddc082d1bd4562e66b7e9/frontend/src/metabase/ui/components/overlays/Modal/Modal.styled.tsx#L35), is overriding the padding prop passed to the <Modal> component. The padding passed to <Modal> is ignored

Some examples are the modals used for the api keys which should have a padding of ""xl/32""
https://github.com/metabase/metabase/blob/1f93ba5c6cb3eb89316ddc082d1bd4562e66b7e9/frontend/src/metabase/admin/settings/components/ApiKeys/CreateApiKeyModal.tsx#L37-L43
but end up having a padding of 24
<img width=""230"" alt=""Screenshot 2024-04-04 at 19 12 01"" src=""https://github.com/metabase/metabase/assets/1914270/6330b52b-0526-443f-b8b1-dd1bd2dee8a7"">
(Note the two paddings in the css)

I tried to fix it in https://github.com/metabase/metabase/pull/40748 but it ended up [breaking](https://metaboat.slack.com/archives/C505ZNNH4/p1712240536876279) the [Save question modal](https://github.com/metabase/metabase/blob/1f93ba5c6cb3eb89316ddc082d1bd4562e66b7e9/frontend/src/metabase/containers/SaveQuestionModal/SaveQuestionModal.tsx#L215-L227) that uses the ""long version"" of the component using subcomponents and passing the padding directly to Modal.Content.

I believe the issue is that <Modal> uses <Modal.Content> internally and it ends up having the two paddings and it breaks.
",npretto,2024-04-04 17:17:35+00:00,[],2024-04-24 10:08:05+00:00,,https://github.com/metabase/metabase/issues/41042,"[('.CSS', ''), ('.Design Needed', '')]",[],
2225850988,issue,closed,completed,[Epic] Let users change the filter type after creation,"**Links**
- üìî [product doc](https://www.notion.so/metabase/Let-users-change-the-filter-type-after-creation-514c727bb17c48cc8bad24d91e9423df)
- feature branch: `change-filter-type`
- issue links: 
	- https://github.com/metabase/metabase/issues/14296
	- https://github.com/metabase/metabase/issues/20048
- üìî  [testing plan](https://www.notion.so/metabase/Testing-plan-84e93a971dc44974b177cbadc083612b)

**Implementation Plan**


***Milestone 1***
```[tasklist]
### Reworking to Mantine
- [ ] https://github.com/metabase/metabase/issues/41140
- [ ] https://github.com/metabase/metabase/issues/41174
``` 


***Milestone 2***
```[tasklist]
### Add changing type to the sidebar
- [ ] https://github.com/metabase/metabase/issues/41168
``` 

***Milestone 3***
```[tasklist]
### Removing mapping
- [ ] https://github.com/metabase/metabase/issues/41331
- [ ] https://github.com/metabase/metabase/issues/41371
```

***Milestone 4***
```[tasklist]
### Changing operator
- [ ] https://github.com/metabase/metabase/issues/41396
- [ ] https://github.com/metabase/metabase/issues/41313
- [ ] https://github.com/metabase/metabase/issues/41475
```

***Milestone 5***
```[tasklist]
### Handle Native questions
- [ ] https://github.com/metabase/metabase/issues/41397
- [ ] https://github.com/metabase/metabase/issues/41647
``` 

***Milestone 6***
```[tasklist]
### Preserving mappings
- [ ] https://github.com/metabase/metabase/issues/41658
``` 

***Milestone 7***
```[tasklist]
### Follow-ups
- [ ] https://github.com/metabase/metabase/issues/42198
- [ ] https://github.com/metabase/metabase/issues/42196
- [ ] https://github.com/metabase/metabase/issues/42197
- [ ] https://github.com/metabase/metabase/issues/42163
- [ ] https://github.com/metabase/metabase/issues/42105
- [ ] https://github.com/metabase/metabase/issues/41517
- [ ] https://github.com/metabase/metabase/issues/42104
```
",uladzimirdev,2024-04-04 15:36:52+00:00,['uladzimirdev'],2024-05-09 13:01:29+00:00,2024-05-09 13:01:28+00:00,https://github.com/metabase/metabase/issues/41037,"[('.Epic', 'Feature Implementation or Project')]",[],
2225797638,issue,open,,[Epic] Improve code-splitting,"Our existing code-splitting strategy does not provide optimal loading performance. Currently, all libraries go into the `vendor` bundle resulting in 5.66 MB (1.38 gzipped) and all of our code is included into `app-*` bundle which results in 4.25 MB (1.11 gzipped). These sizes impact the application startup time which delays data fetching requests:
<img width=""617"" alt=""Screenshot 2024-04-04 at 11 37 33‚ÄØAM"" src=""https://github.com/metabase/metabase/assets/14301985/93375c22-5088-4b67-8aa7-c40bf7ad9916"">

Current bundle analyzer snapshot
<img width=""1726"" alt=""Screenshot 2024-04-04 at 11 21 40‚ÄØAM"" src=""https://github.com/metabase/metabase/assets/14301985/369b4c7d-95f6-4ff1-85a0-a68befff8acf"">

A few things can be improvide. Firstly, we can start by splitting out rarely used heavy libraries like we already do with the sql-formatter. Then we need to split the app into chunks by areas. For example, dashboards may not need all the code of the QueryBuilder which includes almost the heaviest dependency `ace`.

**Implementation Plan**

- [x] Asynchronously load big chunks for rare one-time operations: pdf downloads, png downloads
- [ ] Detach query builder chunk
- [ ] Detach admin panel chunk
- [ ] Detach collections chunk
- [ ] Detach visualizations chunk
- [ ] Detach dashboards chunk
- [ ] Add CI check to ensure the chunks size keeps being reasonable

",alxnddr,2024-04-04 15:19:00+00:00,[],2025-02-04 20:29:50+00:00,,https://github.com/metabase/metabase/issues/41032,"[('Type:Tech Debt', 'or Refactoring'), ('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2106787693, 'issue_id': 2225797638, 'author': 'uladzimirdev', 'body': 'related https://github.com/metabase/metabase/issues/42550', 'created_at': datetime.datetime(2024, 5, 13, 6, 54, 40, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-05-13 06:54:40 UTC): related https://github.com/metabase/metabase/issues/42550

"
2225659514,issue,closed,completed,"Add controls for page up / down, home and end",,npfitz,2024-04-04 14:22:44+00:00,[],2024-04-15 14:04:52+00:00,2024-04-15 14:04:52+00:00,https://github.com/metabase/metabase/issues/41028,[],"[{'comment_id': 2056945278, 'issue_id': 2225659514, 'author': 'npfitz', 'body': 'Closed by #40631', 'created_at': datetime.datetime(2024, 4, 15, 14, 4, 52, tzinfo=datetime.timezone.utc)}]","npfitz (Issue Creator) on (2024-04-15 14:04:52 UTC): Closed by #40631

"
2225557608,issue,open,,Zapier connector,"**Is your feature request related to a problem? Please describe.**
There is a lack of connectivity between Metabase and other apps. Zapier is a commonly used automation app, and a connector can help in the process of various automations.

**Describe the solution you'd like**
To be inside Zapier's app so you can pull out data from Metabase or even put data into Metabase from any app that is supported in Zapier.

**Describe alternatives you've considered**
You can use Metabase public links, but you would need to develop the process yourself, and it's not automated. 

**How important is this feature to you?**
Requested by a customer, more words:
> links as a source to scrape data inside Zapier, but it's quite complex and repetitive. I was wondering if in the future Metabase could become anle app of Zapier, letting the user select directly the queries from the saved library instead of generating a public link every time and setting up a flow to scrape the data.

**Additional context**
N/A
",ignacio-mb,2024-04-04 13:41:44+00:00,[],2025-02-04 20:30:53+00:00,,https://github.com/metabase/metabase/issues/41026,"[('Type:New Feature', ''), ('Administration/Databases', ''), ('Organization/Apps', 'Data Apps')]","[{'comment_id': 2039616073, 'issue_id': 2225557608, 'author': 'paoliniluis', 'body': 'This is possible now that we have api keys, before we had to authenticate users and the tokens could expire', 'created_at': datetime.datetime(2024, 4, 5, 11, 57, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463221516, 'issue_id': 2225557608, 'author': 'micahdasMA', 'body': 'We would also love a Zapier app for Metabase! We are hoping to integrate some slack alerts based on query results', 'created_at': datetime.datetime(2024, 11, 7, 21, 10, 24, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-04-05 11:57:17 UTC): This is possible now that we have api keys, before we had to authenticate users and the tokens could expire

micahdasMA on (2024-11-07 21:10:24 UTC): We would also love a Zapier app for Metabase! We are hoping to integrate some slack alerts based on query results

"
2225534320,issue,closed,completed,Azure SQL Server caches the connection which leads to reusable old sessions,"### Describe the bug

A customer reported that they changed the password in their SQL server and that Metabase can still connect with the old password and not accepting the new one, so I had to see it with my own eyes

### To Reproduce

1) create a SQL server on Azure (logical, it's sort of the PaaS SQL server that Azure has)\
2) connect Metabase to it
3) change password of the database
4) see that Metabase keeps working with the old password...

SQL Server in the cloud seems to be using some sort of caching on the handshakes and not checking the password, so old sessions can be reused

### Expected behavior

We should be able to connect with the new password

### Logs

NA

### Information about your Metabase installation

```JSON
v49.x
```


### Severity

P3

### Additional context

This is mostly sure a Microsoft security bug, they can't sacrifice security for performance

NOTE: I tested with a different SQL client and it's the same thing",paoliniluis,2024-04-04 13:31:41+00:00,[],2024-12-23 11:52:26+00:00,2024-12-23 11:52:26+00:00,https://github.com/metabase/metabase/issues/41025,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/SQLServer', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Drivers', '')]","[{'comment_id': 2070140253, 'issue_id': 2225534320, 'author': 'paoliniluis', 'body': 'Microsoft is aware of the situation https://github.com/microsoft/mssql-jdbc/issues/2334', 'created_at': datetime.datetime(2024, 4, 22, 16, 31, 28, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-04-22 16:31:28 UTC): Microsoft is aware of the situation https://github.com/microsoft/mssql-jdbc/issues/2334

"
2225453377,issue,closed,completed,Make table schema non-nullable,"**Context**

- [Slack discussion](https://metaboat.slack.com/archives/C010L1Z4F9S/p1712221029962209)
- [Issue report](https://github.com/metabase/metabase/pull/40509#pullrequestreview-1978129507)

----

GET `/api/database/:id/schemas` returns `[""""]` for schema-less dbs.
GET `/api/table/:id` and `/api/table/:id/query_metadata` return `{ schema: null }` for tables from such dbs.
It makes it tricky for FE to match one with the other.
Let's make `Table[""schema""]` use an empty string instead of `null`.


We should also update `table_schema` attribute in results coming from search API and `/api/database/:id/metadata`",kamilmielnik,2024-04-04 13:04:33+00:00,['bshepherdson'],2024-04-08 13:31:06+00:00,2024-04-08 13:31:06+00:00,https://github.com/metabase/metabase/issues/41023,"[('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 2037167273, 'issue_id': 2225453377, 'author': 'kamilmielnik', 'body': 'Draft PR: #41003', 'created_at': datetime.datetime(2024, 4, 4, 13, 6, 48, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-04-04 13:06:48 UTC): Draft PR: #41003

"
2225330217,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/query_builder.module.css` + Icons + `frontend/src/metabase/css/components/list.module.css`,"```[tasklist]
### Tasks
- [x] `frontend/src/metabase/css/query_builder.module.css` Moved the only rule that needs migration to `list.module.css`
- [ ] https://github.com/metabase/metabase/pull/41030
```
",WiNloSt,2024-04-04 12:15:42+00:00,['WiNloSt'],2024-04-10 08:06:01+00:00,2024-04-10 08:06:01+00:00,https://github.com/metabase/metabase/issues/41019,[],[],
2225305217,issue,closed,completed,Update `canSave` to allow breakouts,,ranquild,2024-04-04 12:03:54+00:00,['snoe'],2024-04-08 17:12:02+00:00,2024-04-08 17:12:02+00:00,https://github.com/metabase/metabase/issues/41017,[],[],
2225305077,issue,closed,completed,Update `/api/card` to allow breakouts,,ranquild,2024-04-04 12:03:49+00:00,['snoe'],2024-04-08 17:12:14+00:00,2024-04-08 17:12:14+00:00,https://github.com/metabase/metabase/issues/41016,[],[],
2225304895,issue,closed,completed,"`queryFromTableOrCardMetadata` - make sure it uses existing metric clauses for the metric expression, copy breakout clauses from the metric",,ranquild,2024-04-04 12:03:44+00:00,['snoe'],2024-04-10 16:52:26+00:00,2024-04-10 16:52:26+00:00,https://github.com/metabase/metabase/issues/41015,[],[],
2225304690,issue,closed,completed,`displayInfo` changes - double check they‚Äôre in,`displayInfo` for card metadata which is a metric should have an additional field `isMetric`.,ranquild,2024-04-04 12:03:38+00:00,['metamben'],2024-04-10 23:40:09+00:00,2024-04-10 23:40:09+00:00,https://github.com/metabase/metabase/issues/41014,[],[],
2225304588,issue,closed,completed,`visibleColumns` - double check they‚Äôre in,`visibleColumns` and `...Columns` functions should return columns from the last stage of the metric query for the first stage of the query based on the metric.,ranquild,2024-04-04 12:03:35+00:00,['metamben'],2024-04-10 23:40:19+00:00,2024-04-10 23:40:19+00:00,https://github.com/metabase/metabase/issues/41013,[],[],
2225304413,issue,closed,completed,Ignore breakouts for source-table which is a metric,,ranquild,2024-04-04 12:03:30+00:00,['snoe'],2024-04-10 16:52:22+00:00,2024-04-10 16:52:22+00:00,https://github.com/metabase/metabase/issues/41012,[],[],
2225304271,issue,closed,completed,"Use existing metric clauses for new metrics, differentiate based on data source",,ranquild,2024-04-04 12:03:25+00:00,['snoe'],2024-04-10 16:52:18+00:00,2024-04-10 16:52:18+00:00,https://github.com/metabase/metabase/issues/41011,[],[],
2225302778,issue,closed,completed,`/api/collection/:id/items` and `root` - return new metrics for `metric`,,ranquild,2024-04-04 12:02:38+00:00,['snoe'],2024-04-16 14:58:20+00:00,2024-04-16 14:58:20+00:00,https://github.com/metabase/metabase/issues/41010,[],[],
2225302633,issue,closed,completed,`/api/search` - return new metrics for `metric`,,ranquild,2024-04-04 12:02:33+00:00,['snoe'],2024-04-16 14:58:16+00:00,2024-04-16 14:58:16+00:00,https://github.com/metabase/metabase/issues/41009,[],[],
2224928965,issue,closed,not_planned,SQL Server filtering null dateTime fields broke after update,"### Describe the bug

After the update some charts broke, when I investigate the root cause is on handling datetime fields. The question have filter checking if that datetime field is null. But in query it generates

SELECT
  SUM(
    ""Stok Kart Fiyat - StokKartId"".""usdFiyat"" * ""dbo"".""AMBALAJ"".""ambalajIciMiktar"" * 0.4
  ) AS ""USD Tutar""
FROM
  ""dbo"".""AMBALAJ""
  FULL JOIN ""dbo"".""STOK_KART_FIYAT"" AS ""Stok Kart Fiyat - StokKartId"" ON ""dbo"".""AMBALAJ"".""stokKartId"" = ""Stok Kart Fiyat - StokKartId"".""stokKartId""
WHERE
  (""dbo"".""AMBALAJ"".""kapatildi"" = 1)
 
   AND (""dbo"".""AMBALAJ"".""irsaliyeId"" IS NULL)
  AND (""Stok Kart Fiyat - StokKartId"".""fiyatListeId"" = 7)
  AND (
    **""dbo"".""AMBALAJ"".""deletedAt"" = CAST(NULL AS datetimeoffset)**
  )

Having this line like this returns null, It should be dbo.AMBALAJ IS NULL

### To Reproduce

1. Go to 'New Question'
2. Add a ""IS NULL"" filter to datetime field 
3. Results will be null

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 0.49.3
- SQL Server 2016
```


### Severity

Severe

### Additional context

_No response_",bilalsavas,2024-04-04 09:08:52+00:00,['lbrdnk'],2024-04-04 11:43:19+00:00,2024-04-04 11:43:19+00:00,https://github.com/metabase/metabase/issues/41005,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2036615977, 'issue_id': 2224928965, 'author': 'paoliniluis', 'body': 'I think we fixed it already, cc @lbrdnk', 'created_at': datetime.datetime(2024, 4, 4, 9, 10, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036914359, 'issue_id': 2224928965, 'author': 'paoliniluis', 'body': 'e.g. https://github.com/metabase/metabase/issues/40885', 'created_at': datetime.datetime(2024, 4, 4, 11, 28, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036935558, 'issue_id': 2224928965, 'author': 'lbrdnk', 'body': 'Fix for the issue is part of the PR https://github.com/metabase/metabase/pull/40957.', 'created_at': datetime.datetime(2024, 4, 4, 11, 39, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036942188, 'issue_id': 2224928965, 'author': 'paoliniluis', 'body': 'Closing due to duplicate then', 'created_at': datetime.datetime(2024, 4, 4, 11, 43, 19, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-04-04 09:10:26 UTC): I think we fixed it already, cc @lbrdnk

paoliniluis on (2024-04-04 11:28:22 UTC): e.g. https://github.com/metabase/metabase/issues/40885

lbrdnk (Assginee) on (2024-04-04 11:39:33 UTC): Fix for the issue is part of the PR https://github.com/metabase/metabase/pull/40957.

paoliniluis on (2024-04-04 11:43:19 UTC): Closing due to duplicate then

"
2224927728,issue,open,,Tabs inside cards,"**Is your feature request related to a problem? Please describe.**
It would be great to be able to place a number of visuals or the raw data for example, inside a tabbed container where users can interact with the data, different visuals without having to fill the page with more charts or more tabs.

**Describe the solution you'd like**
A set of tabs which will allow me to drop a different visual in each 

**Describe alternatives you've considered**
There are none, other than flooding a page with more visuals or creating more dashboard tabs.

**How important is this feature to you?**
Big, as it can save dashboard space and more pages/tabs being needed.

**Additional context**
Here is an [example](https://weqan.be/wp-content/uploads/2019/08/article2-1.gif2_-1.gif) of the behaviour in Qlik Sense.

",hss-iullah,2024-04-04 09:08:18+00:00,[],2024-04-04 11:46:36+00:00,,https://github.com/metabase/metabase/issues/41004,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2224229723,issue,open,,Use window function versions of cumulative aggregations for MongoDB,#13634 and #15118 are not fixed for MongoDB until we update it to implement cumulative aggregations natively like we did for most of the SQL drivers in #40752.,camsaul,2024-04-04 01:23:13+00:00,[],2025-02-04 20:27:55+00:00,,https://github.com/metabase/metabase/issues/41000,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2224151450,issue,open,,Map pins don't show tooltips when there are 1000+ data points,"### Describe the bug

When you create a pin map using the data in the Sample Database the pins don't have any tooltip showing the records data.

### To Reproduce

Go to Sample Database -> People -> Visualization
    Click on ""Map"" to change the visualization type
    Ensure that ""Pin Map"" is selected for map type, and that ""Latitude"" and ""Longitude"" are selected for the respective fields



### Expected behavior

Pins should appear with tooltips

### Logs

NA

### Information about your Metabase installation

```JSON
docker metabase:latest
```


### Severity

blocking adoption in an organization

### Additional context

Seems to be a regression based upon documentation",runxc1,2024-04-04 00:14:18+00:00,[],2025-02-04 20:31:57+00:00,,https://github.com/metabase/metabase/issues/40999,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Maps', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2037174845, 'issue_id': 2224151450, 'author': 'paoliniluis', 'body': '@runxc1 this worked before right?', 'created_at': datetime.datetime(2024, 4, 4, 13, 9, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2038123028, 'issue_id': 2224151450, 'author': 'runxc1', 'body': ""It's looking to perhaps be a setting based upon the number of pins on the map.   If I use the draw box to filter then I get the pins as expected.  I am just over 1,000"", 'created_at': datetime.datetime(2024, 4, 4, 20, 10, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2052148425, 'issue_id': 2224151450, 'author': 'ignacio-mb', 'body': 'Reproduced with the follwoing SQL\r\n\r\n```\r\nSELECT\r\n  (\r\n    FLOOR(((""PUBLIC"".""PEOPLE"".""LONGITUDE"" - -170.0) / 10.0)) * 10.0\r\n  ) + -170.0 AS ""LONGITUDE"",\r\n  (\r\n    FLOOR(((""PUBLIC"".""PEOPLE"".""LATITUDE"" - 20.0) / 10.0)) * 10.0\r\n  ) + 20.0 AS ""LATITUDE"",\r\n  ""PUBLIC"".""PEOPLE"".""EMAIL"" AS ""EMAIL"",\r\n  COUNT(*) AS ""count""\r\nFROM\r\n  ""PUBLIC"".""PEOPLE""\r\nGROUP BY\r\n  (\r\n    FLOOR(((""PUBLIC"".""PEOPLE"".""LONGITUDE"" - -170.0) / 10.0)) * 10.0\r\n  ) + -170.0,\r\n  (\r\n    FLOOR(((""PUBLIC"".""PEOPLE"".""LATITUDE"" - 20.0) / 10.0)) * 10.0\r\n  ) + 20.0,\r\n  ""PUBLIC"".""PEOPLE"".""EMAIL""\r\nORDER BY\r\n  (\r\n    FLOOR(((""PUBLIC"".""PEOPLE"".""LONGITUDE"" - -170.0) / 10.0)) * 10.0\r\n  ) + -170.0 ASC,\r\n  (\r\n    FLOOR(((""PUBLIC"".""PEOPLE"".""LATITUDE"" - 20.0) / 10.0)) * 10.0\r\n  ) + 20.0 ASC,\r\n  ""PUBLIC"".""PEOPLE"".""EMAIL"" ASC\r\n  \r\n  \r\n  LIMIT 1000\r\n```\r\nNo console errors\r\nNo explicit error in the backend (see a warning `Warning: cannot determine fields for an explicit source-query unless you also include source-metadata.\r\n `', 'created_at': datetime.datetime(2024, 4, 12, 17, 7, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2052152771, 'issue_id': 2224151450, 'author': 'ignacio-mb', 'body': 'Maybe related to https://github.com/metabase/metabase/issues/20090', 'created_at': datetime.datetime(2024, 4, 12, 17, 9, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187265855, 'issue_id': 2224151450, 'author': 'cdeweyx', 'body': 'Deciding to wait on this until we tackle maps more broadly ([thread](https://metaboat.slack.com/archives/C064QMXEV9N/p1719010377458719))', 'created_at': datetime.datetime(2024, 6, 24, 19, 32, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383445739, 'issue_id': 2224151450, 'author': 'ahmedsafadii', 'body': 'Same issue, it shows small box with no tootip', 'created_at': datetime.datetime(2024, 9, 30, 14, 55, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383642195, 'issue_id': 2224151450, 'author': 'runxc1', 'body': ""It'd be nice to have a setting for this.  I have 1300ish pins worldwide and don't care if the maps loads really slowly."", 'created_at': datetime.datetime(2024, 9, 30, 16, 19, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-04-04 13:09:40 UTC): @runxc1 this worked before right?

runxc1 (Issue Creator) on (2024-04-04 20:10:58 UTC): It's looking to perhaps be a setting based upon the number of pins on the map.   If I use the draw box to filter then I get the pins as expected.  I am just over 1,000

ignacio-mb on (2024-04-12 17:07:40 UTC): Reproduced with the follwoing SQL

```
SELECT
  (
    FLOOR(((""PUBLIC"".""PEOPLE"".""LONGITUDE"" - -170.0) / 10.0)) * 10.0
  ) + -170.0 AS ""LONGITUDE"",
  (
    FLOOR(((""PUBLIC"".""PEOPLE"".""LATITUDE"" - 20.0) / 10.0)) * 10.0
  ) + 20.0 AS ""LATITUDE"",
  ""PUBLIC"".""PEOPLE"".""EMAIL"" AS ""EMAIL"",
  COUNT(*) AS ""count""
FROM
  ""PUBLIC"".""PEOPLE""
GROUP BY
  (
    FLOOR(((""PUBLIC"".""PEOPLE"".""LONGITUDE"" - -170.0) / 10.0)) * 10.0
  ) + -170.0,
  (
    FLOOR(((""PUBLIC"".""PEOPLE"".""LATITUDE"" - 20.0) / 10.0)) * 10.0
  ) + 20.0,
  ""PUBLIC"".""PEOPLE"".""EMAIL""
ORDER BY
  (
    FLOOR(((""PUBLIC"".""PEOPLE"".""LONGITUDE"" - -170.0) / 10.0)) * 10.0
  ) + -170.0 ASC,
  (
    FLOOR(((""PUBLIC"".""PEOPLE"".""LATITUDE"" - 20.0) / 10.0)) * 10.0
  ) + 20.0 ASC,
  ""PUBLIC"".""PEOPLE"".""EMAIL"" ASC
  
  
  LIMIT 1000
```
No console errors
No explicit error in the backend (see a warning `Warning: cannot determine fields for an explicit source-query unless you also include source-metadata.
 `

ignacio-mb on (2024-04-12 17:09:54 UTC): Maybe related to https://github.com/metabase/metabase/issues/20090

cdeweyx on (2024-06-24 19:32:47 UTC): Deciding to wait on this until we tackle maps more broadly ([thread](https://metaboat.slack.com/archives/C064QMXEV9N/p1719010377458719))

ahmedsafadii on (2024-09-30 14:55:54 UTC): Same issue, it shows small box with no tootip

runxc1 (Issue Creator) on (2024-09-30 16:19:33 UTC): It'd be nice to have a setting for this.  I have 1300ish pins worldwide and don't care if the maps loads really slowly.

"
2224147938,issue,closed,not_planned,Add a setting to insert a session tracking Javascript code snippet,"**Is your feature request related to a problem? Please describe.**
Embedded Metabase does not allow admins to add a Javascript snipped for session tracking like Hotjar or similar.

**Describe the solution you'd like**
Add a setting to input a Javascript snippet for session tracking or specific plugins for Hotjar, etc. URLs (like select a supported session tracker, then enter the relevant parameters in a second input.)

**Describe alternatives you've considered**
- Custom build, does not work for Cloud customers

**How important is this feature to you?**
- a few requests per year from customers

**Additional context**
- https://help.hotjar.com/hc/en-us/articles/115011624347-Can-I-Track-iframes-Inside-Heatmaps-and-Recordings",likeshumidity,2024-04-04 00:10:44+00:00,[],2024-12-07 23:08:30+00:00,2024-12-07 23:08:30+00:00,https://github.com/metabase/metabase/issues/40998,"[('Type:New Feature', ''), ('.Needs Triage', ''), ('Embedding/Public', 'Simple public iframe embeds'), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding'), ('.Team/Embedding', '')]","[{'comment_id': 2122628914, 'issue_id': 2224147938, 'author': 'albertoperdomo', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/5462 @likeshumidity ?', 'created_at': datetime.datetime(2024, 5, 21, 13, 22, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525337947, 'issue_id': 2224147938, 'author': 'paoliniluis', 'body': 'dupe', 'created_at': datetime.datetime(2024, 12, 7, 23, 8, 27, tzinfo=datetime.timezone.utc)}]","albertoperdomo on (2024-05-21 13:22:41 UTC): Duplicate of https://github.com/metabase/metabase/issues/5462 @likeshumidity ?

paoliniluis on (2024-12-07 23:08:27 UTC): dupe

"
2224096093,issue,closed,completed,`mbql.u/add-order-by-clause` ignores clauses if an order by already exists for that field even if temporal unit is different,"There are some cases where we need to order on on the same field more than one, for example `:year` and `:month-of-year`. This is currently broken when using the legacy MBQL utils, it ignores any order bys against a column after the first.",camsaul,2024-04-03 23:07:03+00:00,['camsaul'],2024-08-28 02:10:40+00:00,2024-04-05 20:03:27+00:00,https://github.com/metabase/metabase/issues/40995,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2224090799,issue,closed,completed,"`unique-name-generator` generates incorrect names, which can cause broken queries","```clj
(let [unique-name (mbql.u/unique-name-generator)]
  [(unique-name :x ""A"")
   (unique-name :x ""B"")
   (unique-name :x ""A"")
   (unique-name :y ""A"")
   (unique-name :y ""A"")])
;; => [""A"" ""B"" ""A"" ""A_2"" ""A_3""]
```

but it should generate

```clj
(let [unique-name (mbql.u/unique-name-generator)]
  [(unique-name :x ""A"")
   (unique-name :x ""B"")
   (unique-name :x ""A"")
   (unique-name :y ""A"")
   (unique-name :y ""A"")])
;; => [""A"" ""B"" ""A"" ""A_2"" ""A_2""]
```",camsaul,2024-04-03 23:04:11+00:00,['camsaul'],2024-08-28 02:10:39+00:00,2024-04-05 20:03:27+00:00,https://github.com/metabase/metabase/issues/40994,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2224081572,issue,closed,completed,`add-alias-info` breakouts with multiple order bys on the same field,`add-alias-info` throws an Exception if we have multiple order bys on the same field with different temporal units.,camsaul,2024-04-03 22:57:19+00:00,['camsaul'],2024-08-28 02:10:39+00:00,2024-04-05 20:03:27+00:00,https://github.com/metabase/metabase/issues/40993,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2224074158,issue,closed,completed,Use window function versions of cumulative aggregations for BigQuery,#13634 and #15118 are not fixed for BigQuery until we update it to implement cumulative aggregations natively like we did for most of the other SQL drivers in #40752.,camsaul,2024-04-03 22:49:45+00:00,['camsaul'],2024-08-28 02:10:38+00:00,2024-04-08 21:41:54+00:00,https://github.com/metabase/metabase/issues/40992,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Team/Querying', '')]",[],
2224073833,issue,open,,Use window function versions of cumulative aggregations for Spark SQL,#13634 and #15118 are not fixed for Spark SQL until we update it to implement cumulative aggregations natively like we did for most of the other SQL drivers in #40752.,camsaul,2024-04-03 22:49:22+00:00,[],2025-02-04 20:27:56+00:00,,https://github.com/metabase/metabase/issues/40991,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('Database/Spark', ''), ('.Backend', ''), ('.Team/Drivers', '')]",[],
2224073782,issue,closed,completed,Fix window function cumulative aggregations for SQL Server,,camsaul,2024-04-03 22:49:18+00:00,['camsaul'],2024-08-28 02:10:38+00:00,2024-04-05 20:03:26+00:00,https://github.com/metabase/metabase/issues/40990,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]",[],
2224067515,issue,closed,completed,[dc.js migration] Multiple charts on staging appear empty or broken,"Some charts appear empty on staging home page
<img width=""1025"" alt=""Screenshot 2024-04-03 at 7 43 39‚ÄØPM"" src=""https://github.com/metabase/metabase/assets/14301985/6abfac7b-7237-4f26-8532-e28010e661a4"">
",alxnddr,2024-04-03 22:42:43+00:00,['alxnddr'],2024-04-04 22:17:10+00:00,2024-04-04 22:17:10+00:00,https://github.com/metabase/metabase/issues/40989,"[('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2223828226,issue,open,,Mathematical Formula Visualization,"**Is your feature request related to a problem? Please describe.**
A user might want to add to a chart a simple mathematical formula like y = 2x + 3 to an existing chart 

**Describe the solution you'd like**
A formula visualizer or graphical calculator engine that runs inside Metabase, like, for example, the following:
https://www.desmos.com/calculator
![Screenshot 2024-04-03 at 5 14 16‚ÄØPM](https://github.com/metabase/metabase/assets/132273646/cf57af80-ad1c-4c3c-aa82-455388f0d524)

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket: [26252](https://metabase.zendesk.com/agent/tickets/26252)

**Additional context**
Related to https://github.com/metabase/metabase/issues/32226

For example, you can be setting up a break-even point graph
![image](https://github.com/metabase/metabase/assets/132273646/6a430bd4-9911-4168-8410-ab7f8bb54e22)

In the customer's words: in our platform we are assessing different technologies and have cost formulas created for them, we want to visualize these cost formulas together in one chart to give more detail to what we claim to be the break-even point and how the costs develop depending on quantity
",ignacio-mb,2024-04-03 20:16:13+00:00,[],2024-04-15 13:31:08+00:00,,https://github.com/metabase/metabase/issues/40983,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.')]",[],
2223585947,issue,closed,completed,Cache UI: Follow-up work,"```[tasklist]
### Follow up work for cache UI
- [x] Measure minimum query duration in seconds (#40970)
- [x] Change default minimum query duration to 1 second (not 60 seconds) (#40970)
- [x] Add 'Invalidate now' button (#40972)
- [x] Move Invalidate now button to the top of the form along with the name of the database (#40972)
- [x] Create DelayedSpinner component (#41103)
- [ ] Add e2e tests. This will be complicated, since our test of the old cache invalidation UI was disabled due to a bug
- [ ] Ensure that form fields can be tabbed into even when behind form buttons div (I have this in a branch but I'm not sure it's worth pursuing)
- [x] Rename TTL to Multiplier
- [x] [not planned] Tweak: remove value from inputs (and just show placeholder) if it matches the default (and ensure form dirty status is correct)
- [ ] Polish: delay all spinners by 300 ms
- [ ] Try Ryan's suggestion to avoid the useVerticallyOverflows hook (https://app.graphite.dev/github/pr/metabase/metabase/39234/Basic-cache-admin-UI?utm_source=gt-slack-notif#comment-PRRC_kwDOAczgH85cTMwl)
- [ ] Explore Ryan's suggestion to use different forms for different strategies (https://app.graphite.dev/github/pr/metabase/metabase/39234/Basic-cache-admin-UI?utm_source=gt-slack-notif#comment-PRRC_kwDOAczgH85cTRiE)
- [ ] https://github.com/metabase/metabase/issues/41119
```
",rafpaf,2024-04-03 18:06:31+00:00,['rafpaf'],2024-04-18 18:27:00+00:00,2024-04-06 02:00:17+00:00,https://github.com/metabase/metabase/issues/40978,[],"[{'comment_id': 2040855622, 'issue_id': 2223585947, 'author': 'rafpaf', 'body': ""I've moved this list into the epic issue: https://github.com/metabase/metabase/issues/39153"", 'created_at': datetime.datetime(2024, 4, 6, 2, 0, 18, tzinfo=datetime.timezone.utc)}]","rafpaf (Issue Creator) on (2024-04-06 02:00:18 UTC): I've moved this list into the epic issue: https://github.com/metabase/metabase/issues/39153

"
2223288090,issue,open,,"sql query ""greater then"" filter in dashboard is not attaching to the report","### Describe the bug

In 0.49 version only dashboards ""Number"".""equal"" filter is working with ""SQL queries"".
You just cannot select corresponding variable if selecting other option then ""equal"".
![image](https://github.com/metabase/metabase/assets/159305166/3c6ac496-6bb9-432d-aff9-ef314c95f91c)


Using ""Greater then or equal to"" filter in a dashboard with ""question"" and ""sql query""

### To Reproduce

1. Create any sql query with int variable
2. create dashboard
3. add query to the dashboard
4. add ""number"" ""Greater then or equal to"" filter
5. try attaching this filter to the sql query variable


### Expected behavior

On step 5 it should be possible to attach filter to query variable.

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version: 0.49
```


### Severity

annoying

### Additional context

_No response_",alex-can-do-everything,2024-04-03 15:46:37+00:00,[],2025-02-04 20:29:46+00:00,,https://github.com/metabase/metabase/issues/40971,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 2064430918, 'issue_id': 2223288090, 'author': 'anarinya', 'body': 'Bumping this, running into the same issue. The dashboard filter will pick up the SQL query number filter only if you create a dashboard ""equals to"" filter, but won\'t acknowledge the SQL query filters exist if you try to create greater/less than ones.', 'created_at': datetime.datetime(2024, 4, 18, 16, 21, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2231682422, 'issue_id': 2223288090, 'author': 'nemanjaglumac', 'body': 'Hi @alex-can-do-everything and @anarinya \r\nI am trying to understand what are you trying to achieve here in order to reproduce this issue. Also, you said this as if it was working before version 49, but I checked past versions and this has never been possible.\r\n\r\nThis is version 47.6 where I tried ""Between"" filter\r\n![image](https://github.com/user-attachments/assets/7a0aff65-212d-4a3a-9bb6-3682a3d9f86f)\r\n\r\nThis is even older version 43.4 where I tried ""Greater than or equal to""\r\n![image](https://github.com/user-attachments/assets/a625164b-10ff-4ee5-8b69-4ba08037e892)\r\n\r\n---\r\n\r\nUnless I misunderstood something, this is not a bug at all. It is actually how things are supposed to work.\r\nLet\'s imagine two scenarios:\r\n1. `SELECT {{ num }}`, save it and add it to the dashboard. The only numeric filter that makes sense is ""equal to"" because you need to provide an explicit number\r\n2. `SELECT count(*) FROM orders WHERE orders.total > {{ num }}`, save it and add it to the dashboard. Again, the only thing you can do is to provide the explicit number because any conditions such as greater or less than, etc. are part of the query, and not part of the variable.\r\n\r\nThere is only one scenario where the full range of numeric dashboard parameters make sense. And that is when you map the sql variable to a field filter.\r\n`SELECT count(*) from ORDERS where {{ foo }}` and then you map foo to be a field filter that corresponds to the Orders.Total. Save it and add it to the dashboard. Now add a numeric dashboard filter and all options are valid.\r\n\r\nPlease share some more details and let me know if I misunderstood something.\r\nI\'ll change this to a feature request for now.', 'created_at': datetime.datetime(2024, 7, 16, 19, 28, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2234262211, 'issue_id': 2223288090, 'author': 'alex-can-do-everything', 'body': '0.You are right, it did not work, sorry for misleading\r\n\r\n2.yes,  for example you have the SQL query `SELECT count(*) FROM orders WHERE orders.total > {{ num }}` in your dashboard. But you also have ""question"" query in your dashboard. And you want to have "">"" filter.\r\nIn this case you have to use 2 filters: "">"" for the question and ""="" for the SQL, which is annoying.\r\n\r\nIn SQL query semantic meaning of the filter is reflected in the sql code, not the filter type. Current implementation does not allow you to use proper filter type to represent sql query semantics.', 'created_at': datetime.datetime(2024, 7, 17, 20, 53, tzinfo=datetime.timezone.utc)}]","anarinya on (2024-04-18 16:21:33 UTC): Bumping this, running into the same issue. The dashboard filter will pick up the SQL query number filter only if you create a dashboard ""equals to"" filter, but won't acknowledge the SQL query filters exist if you try to create greater/less than ones.

nemanjaglumac on (2024-07-16 19:28:25 UTC): Hi @alex-can-do-everything and @anarinya 
I am trying to understand what are you trying to achieve here in order to reproduce this issue. Also, you said this as if it was working before version 49, but I checked past versions and this has never been possible.

This is version 47.6 where I tried ""Between"" filter
![image](https://github.com/user-attachments/assets/7a0aff65-212d-4a3a-9bb6-3682a3d9f86f)

This is even older version 43.4 where I tried ""Greater than or equal to""
![image](https://github.com/user-attachments/assets/a625164b-10ff-4ee5-8b69-4ba08037e892)

---

Unless I misunderstood something, this is not a bug at all. It is actually how things are supposed to work.
Let's imagine two scenarios:
1. `SELECT {{ num }}`, save it and add it to the dashboard. The only numeric filter that makes sense is ""equal to"" because you need to provide an explicit number
2. `SELECT count(*) FROM orders WHERE orders.total > {{ num }}`, save it and add it to the dashboard. Again, the only thing you can do is to provide the explicit number because any conditions such as greater or less than, etc. are part of the query, and not part of the variable.

There is only one scenario where the full range of numeric dashboard parameters make sense. And that is when you map the sql variable to a field filter.
`SELECT count(*) from ORDERS where {{ foo }}` and then you map foo to be a field filter that corresponds to the Orders.Total. Save it and add it to the dashboard. Now add a numeric dashboard filter and all options are valid.

Please share some more details and let me know if I misunderstood something.
I'll change this to a feature request for now.

alex-can-do-everything (Issue Creator) on (2024-07-17 20:53:00 UTC): 0.You are right, it did not work, sorry for misleading

2.yes,  for example you have the SQL query `SELECT count(*) FROM orders WHERE orders.total > {{ num }}` in your dashboard. But you also have ""question"" query in your dashboard. And you want to have "">"" filter.
In this case you have to use 2 filters: "">"" for the question and ""="" for the SQL, which is annoying.

In SQL query semantic meaning of the filter is reflected in the sql code, not the filter type. Current implementation does not allow you to use proper filter type to represent sql query semantics.

"
2223219584,issue,open,,Add tabed parameter from a static embed,"**Is your feature request related to a problem? Please describe.**
currently all tabs are showable from a static embed

**Describe the solution you'd like**
Add tabed parameter from a static embed

**Describe alternatives you've considered**
Create multiple dashbord and not use tabs option

**How important is this feature to you?**
To allow tabs to be hidden if the questions in a tab are not part of a specific parameter value
",maximepvrt,2024-04-03 15:19:58+00:00,[],2024-07-05 10:18:15+00:00,,https://github.com/metabase/metabase/issues/40967,"[('Type:New Feature', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding')]","[{'comment_id': 2047153371, 'issue_id': 2223219584, 'author': 'maxdestors', 'body': 'Currently, `titled` display or hide the title and tabs together.\r\nit would be great to have :\r\n - `titled` to display or hide the title.\r\n - `tabed`:\r\n   - true: display all tabs.\r\n   - false: hide all tabs and display the content of the first tab.\r\n   - tab name (or tab id): hide all tabs and display the content of the selected tab.', 'created_at': datetime.datetime(2024, 4, 10, 10, 24, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2048602584, 'issue_id': 2223219584, 'author': 'maximepvrt', 'body': '@paoliniluis', 'created_at': datetime.datetime(2024, 4, 10, 23, 35, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2049670644, 'issue_id': 2223219584, 'author': 'maximepvrt', 'body': '@maxdestors Currently `titled` dispay or hide only the title (v0.48)\r\n\r\n![Capture d‚ÄôeÃÅcran 2024-04-11 aÃÄ 15 11 48](https://github.com/metabase/metabase/assets/1840026/b0dc64fd-d292-4e8b-9e48-e79caade4014)', 'created_at': datetime.datetime(2024, 4, 11, 13, 15, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2049847739, 'issue_id': 2223219584, 'author': 'maxdestors', 'body': 'I was running v0.49.3. But the behavior changed back in v0.49.4 see https://github.com/metabase/metabase/issues/41195', 'created_at': datetime.datetime(2024, 4, 11, 14, 38, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2070174051, 'issue_id': 2223219584, 'author': 'maximepvrt', 'body': '@flamber', 'created_at': datetime.datetime(2024, 4, 22, 16, 40, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2200615674, 'issue_id': 2223219584, 'author': 'albertoperdomo', 'body': 'Hello @maxdestors ,\r\nyes, that was a bug but it got fixed. Now the tabs show, but there is currently no way to hide certain tabs.', 'created_at': datetime.datetime(2024, 7, 1, 16, 48, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2200618631, 'issue_id': 2223219584, 'author': 'albertoperdomo', 'body': '@maximepvrt flamber no longer works at Metabase. No need to ping him.\r\n\r\n>To allow tabs to be hidden if the questions in a tab are not part of a specific parameter value\r\n\r\nI have trouble understanding this part. Can you please explain it for me?\r\n\r\nHow does the ideal solution look like for you? You pass an array of tab ids or names you want to hide?', 'created_at': datetime.datetime(2024, 7, 1, 16, 50, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206993384, 'issue_id': 2223219584, 'author': 'maximepvrt', 'body': '@albertoperdomo The @maxdestors proposal looks good to me with some adjustments:\r\n\r\n> `tabed`:\r\n> * true: display all tabs. (default)\r\n> * false: hide all tabs and display the content of the first tab or the tab selected with the `tab` parameter.\r\n\r\nAdditionally, please consider adding an option in the dashboard to hide a tab or a question based on a filter value.', 'created_at': datetime.datetime(2024, 7, 3, 18, 58, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208582954, 'issue_id': 2223219584, 'author': 'albertoperdomo', 'body': '@maximepvrt @maxdestors Can help me understand why you want to create a dashboard with multiple tabs but only embed a subset?', 'created_at': datetime.datetime(2024, 7, 4, 9, 56, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2208638658, 'issue_id': 2223219584, 'author': 'maximepvrt', 'body': ""@albertoperdomo To clarify why I want to hide tabs:\r\n\r\n**Custom Tab System**: I have two dashboard embeds in sequence on my page and want to create a tab system on my side. This way, I can load the iframe with the appropriate tab without displaying Metabase's tabs.\r\n\r\n**Conditional Tab Display**: I use Metabase to display statistics to my users, but not all users have access to all features of my tool. Therefore, displaying tabs that are not relevant to certain users is inconvenient. Hiding Metabase's tabs and using my custom tab system will solve this issue, at least until we can conditionally display tabs based on dashbaord parameters in metabase app."", 'created_at': datetime.datetime(2024, 7, 4, 10, 26, 35, tzinfo=datetime.timezone.utc)}]","maxdestors on (2024-04-10 10:24:59 UTC): Currently, `titled` display or hide the title and tabs together.
it would be great to have :
 - `titled` to display or hide the title.
 - `tabed`:
   - true: display all tabs.
   - false: hide all tabs and display the content of the first tab.
   - tab name (or tab id): hide all tabs and display the content of the selected tab.

maximepvrt (Issue Creator) on (2024-04-10 23:35:41 UTC): @paoliniluis

maximepvrt (Issue Creator) on (2024-04-11 13:15:07 UTC): @maxdestors Currently `titled` dispay or hide only the title (v0.48)

![Capture d‚ÄôeÃÅcran 2024-04-11 aÃÄ 15 11 48](https://github.com/metabase/metabase/assets/1840026/b0dc64fd-d292-4e8b-9e48-e79caade4014)

maxdestors on (2024-04-11 14:38:29 UTC): I was running v0.49.3. But the behavior changed back in v0.49.4 see https://github.com/metabase/metabase/issues/41195

maximepvrt (Issue Creator) on (2024-04-22 16:40:40 UTC): @flamber

albertoperdomo on (2024-07-01 16:48:52 UTC): Hello @maxdestors ,
yes, that was a bug but it got fixed. Now the tabs show, but there is currently no way to hide certain tabs.

albertoperdomo on (2024-07-01 16:50:40 UTC): @maximepvrt flamber no longer works at Metabase. No need to ping him.


I have trouble understanding this part. Can you please explain it for me?

How does the ideal solution look like for you? You pass an array of tab ids or names you want to hide?

maximepvrt (Issue Creator) on (2024-07-03 18:58:12 UTC): @albertoperdomo The @maxdestors proposal looks good to me with some adjustments:


Additionally, please consider adding an option in the dashboard to hide a tab or a question based on a filter value.

albertoperdomo on (2024-07-04 09:56:32 UTC): @maximepvrt @maxdestors Can help me understand why you want to create a dashboard with multiple tabs but only embed a subset?

maximepvrt (Issue Creator) on (2024-07-04 10:26:35 UTC): @albertoperdomo To clarify why I want to hide tabs:

**Custom Tab System**: I have two dashboard embeds in sequence on my page and want to create a tab system on my side. This way, I can load the iframe with the appropriate tab without displaying Metabase's tabs.

**Conditional Tab Display**: I use Metabase to display statistics to my users, but not all users have access to all features of my tool. Therefore, displaying tabs that are not relevant to certain users is inconvenient. Hiding Metabase's tabs and using my custom tab system will solve this issue, at least until we can conditionally display tabs based on dashbaord parameters in metabase app.

"
2223130943,issue,closed,completed,"[Epic] Modularize, rework, and improve search","```[tasklist]
### M1: minimal search
- [x] Minimal index management: delete/create/fill
- [x] Fill index with data: Questions (no Metrics/Models), Dashboards
- [x] Search query
- [x] Integrate with REST API (cookie + querystring to switch it)
- [x] Hide behind setting
- [x] https://github.com/metabase/metabase/pull/47752
- [x] Populate index on bootstrap
- [x] API to trigger synchronous re-indexing
- [ ] https://github.com/metabase/metabase/pull/47846
- [x] Search does completion
- [x] Faster model set
- [x] Skip ranking
- [ ] https://github.com/metabase/metabase/pull/48053
- [x] Filter models
- [x] Bug: model etc selectors not populated the same
```

```[tasklist]
### M2: replacing current search
- [x] More models
- [x] Batch insertion
- [x] Permissions
- [x] Replace index periodically via task
- [x] Update API to trigger the task, rather that reindexing directly
- [ ] https://github.com/metabase/metabase/pull/49335
- [ ] https://github.com/metabase/metabase/pull/49327
- [ ] https://github.com/metabase/metabase/pull/49422
- [x] Indexed Entity models
- [x] Handle archived filtering (hard off for some models)
- [ ] https://github.com/metabase/metabase/pull/49520
- [ ] https://github.com/metabase/metabase/pull/49484#pullrequestreview-2413389272
- [ ] https://github.com/metabase/metabase/pull/49660
- [ ] https://github.com/metabase/metabase/pull/49777
- [ ] https://github.com/metabase/metabase/pull/49824
- [ ] https://github.com/metabase/metabase/pull/49825
- [x] Clean up filter mapping
- [ ] https://github.com/metabase/metabase/pull/49842
- [ ] https://github.com/metabase/metabase/pull/49861
- [ ] https://github.com/metabase/metabase/pull/49666
- [ ] https://github.com/metabase/metabase/pull/49866
- [ ] https://github.com/metabase/metabase/pull/49899
- [ ] https://github.com/metabase/metabase/pull/49933
- [ ] https://github.com/metabase/metabase/pull/49951
- [ ] https://github.com/metabase/metabase/pull/50001
- [ ] https://github.com/metabase/metabase/pull/50019
- [ ] https://github.com/metabase/metabase/pull/50071
- [ ] https://github.com/metabase/metabase/pull/50046
- [ ] https://github.com/metabase/metabase/pull/50126
- [ ] https://github.com/metabase/metabase/issues/50204
- [ ] https://github.com/metabase/metabase/issues/50205
- [ ] https://github.com/metabase/metabase/issues/50206
- [ ] https://github.com/metabase/metabase/issues/50261
- [x] Smart bootstrapping - don't blow away the index if the schema is correct
```

```[tasklist]
### M3: making search better
- [ ] Only search completions in the command palette context
- [ ] Handle synonyms
- [ ] Better stemming
```

```[tasklist]
### M4: semantic search
- [ ] Option to enable (system setting, check for pg_vector)
- [ ] Model downloader
- [ ] Generate embeddings
```
",luizarakaki,2024-04-03 14:42:07+00:00,['crisptrutski'],2024-12-05 15:01:22+00:00,2024-12-05 13:03:44+00:00,https://github.com/metabase/metabase/issues/40964,"[('Organization/Search', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2483130433, 'issue_id': 2223130943, 'author': 'luizarakaki', 'body': 'TODOs on Nov 18\n\n- [x] Deploy to Stats\n- [x] Stemming (dictionary, English)\n- [x] cards (questions, models, metrics) recency: last_used_at\n- [x] pinned ranker weight = 0 by default\n- [x] set max recency drop-off at 30 days\n- [x] change percentile for populatiry\n- [x] check shape of popularity\n- [x] verified content and official collections\n- [x] personalized-recency\n- [x] context-dependent weights\n- [x] context-dependent entity type score\n- [x] context-dependent default filters\n- [x] exclude other people collection content by default (FE can override this)\n- [x] Profile performance\n- [ ] Create a last_used_at column on tables, to use for recency\n- [ ] facet (ts_stat)', 'created_at': datetime.datetime(2024, 11, 18, 13, 59, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520270683, 'issue_id': 2223130943, 'author': 'luizarakaki', 'body': 'Closing this one in favor of https://github.com/metabase/metabase/issues/50927 that contains the related work to ship the experimental version on 52 and make it GA on 53 (and remove old search)', 'created_at': datetime.datetime(2024, 12, 5, 13, 3, 44, tzinfo=datetime.timezone.utc)}]","luizarakaki (Issue Creator) on (2024-11-18 13:59:50 UTC): TODOs on Nov 18

- [x] Deploy to Stats
- [x] Stemming (dictionary, English)
- [x] cards (questions, models, metrics) recency: last_used_at
- [x] pinned ranker weight = 0 by default
- [x] set max recency drop-off at 30 days
- [x] change percentile for populatiry
- [x] check shape of popularity
- [x] verified content and official collections
- [x] personalized-recency
- [x] context-dependent weights
- [x] context-dependent entity type score
- [x] context-dependent default filters
- [x] exclude other people collection content by default (FE can override this)
- [x] Profile performance
- [ ] Create a last_used_at column on tables, to use for recency
- [ ] facet (ts_stat)

luizarakaki (Issue Creator) on (2024-12-05 13:03:44 UTC): Closing this one in favor of https://github.com/metabase/metabase/issues/50927 that contains the related work to ship the experimental version on 52 and make it GA on 53 (and remove old search)

"
2223052985,issue,closed,completed,"Downloading results of an embedded question (via iframe) fails because of ""Unknown parameter :format_rows""","**Describe the bug**
Since yesterday, when clicking the ""Download full results"" download button in the bottom right of an iframe-embedded question, it makes a network request to `https://my-metabase.com/api/embed/card/xxxxxxx/query/xlsx?format_rows=false`.
This then downloads a file which just contains the text `Unknown parameter :format_rows.` 

**Expected behavior**
If I copy the download link and remove the `?format_rows=false` query parameter, the file gets downloaded correctly, as expected. I have no idea though why this query parameter is now suddenly being added to the download URL.

**The downloaded file**
[query_result_2024-04-03T13_45_03.806Z.xlsx](https://github.com/metabase/metabase/files/14853439/query_result_2024-04-03T13_45_03.806Z.xlsx)

**Severity**
The issue is pretty annoying, as we have customers who download a daily Excel report from our dashboards and now they're blocked in doing so.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.210-201.855.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13 (Ubuntu 13.13-1.pgdg20.04+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-04-02"",
      ""tag"": ""v0.49.3"",
      ""hash"": ""dba0992""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",dbbert,2024-04-03 14:10:20+00:00,['adam-james-v'],2024-04-10 17:30:53+00:00,2024-04-10 17:30:12+00:00,https://github.com/metabase/metabase/issues/40959,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Customization/Formatting', ''), ('.Backend', ''), ('Embedding/Public', 'Simple public iframe embeds'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Visualization/Download', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2042716879, 'issue_id': 2223052985, 'author': 'dbbert', 'body': ""Is it possible we have something misconfigured on our end? I'm suprised this isn't a more popular issue impacting almost everyone."", 'created_at': datetime.datetime(2024, 4, 8, 13, 8, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2042725760, 'issue_id': 2223052985, 'author': 'jmm312', 'body': 'I have the same issue. I had to downgrade to v0.49.0 to get it to work.', 'created_at': datetime.datetime(2024, 4, 8, 13, 12, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2045149393, 'issue_id': 2223052985, 'author': 'kuesley', 'body': 'I have the same issue. I downgrade too', 'created_at': datetime.datetime(2024, 4, 9, 13, 11, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2046779533, 'issue_id': 2223052985, 'author': 'juheok', 'body': 'Same issue. We downgraded from 0.49.3 to 0.49.0 too.', 'created_at': datetime.datetime(2024, 4, 10, 7, 48, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2046975719, 'issue_id': 2223052985, 'author': 'dbbert', 'body': 'When downgrading, did you restore a previous database backup or is that not needed?', 'created_at': datetime.datetime(2024, 4, 10, 9, 9, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2047972480, 'issue_id': 2223052985, 'author': 'kuesley', 'body': '> When downgrading, did you restore a previous database backup or is that not needed?\r\n\r\nis not necessary', 'created_at': datetime.datetime(2024, 4, 10, 16, 15, 38, tzinfo=datetime.timezone.utc)}]","dbbert (Issue Creator) on (2024-04-08 13:08:12 UTC): Is it possible we have something misconfigured on our end? I'm suprised this isn't a more popular issue impacting almost everyone.

jmm312 on (2024-04-08 13:12:13 UTC): I have the same issue. I had to downgrade to v0.49.0 to get it to work.

kuesley on (2024-04-09 13:11:34 UTC): I have the same issue. I downgrade too

juheok on (2024-04-10 07:48:28 UTC): Same issue. We downgraded from 0.49.3 to 0.49.0 too.

dbbert (Issue Creator) on (2024-04-10 09:09:21 UTC): When downgrading, did you restore a previous database backup or is that not needed?

kuesley on (2024-04-10 16:15:38 UTC): is not necessary

"
2222845270,issue,closed,completed,Data Picker tests,"Update existing tests, and add test coverage for the new component.",kamilmielnik,2024-04-03 12:47:37+00:00,['kamilmielnik'],2024-05-17 09:33:33+00:00,2024-05-17 09:33:33+00:00,https://github.com/metabase/metabase/issues/40953,"[('.CI & Tests', ''), ('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2117144798, 'issue_id': 2222845270, 'author': 'kamilmielnik', 'body': 'Closed by #42565', 'created_at': datetime.datetime(2024, 5, 17, 9, 33, 33, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-17 09:33:33 UTC): Closed by #42565

"
2222836932,issue,closed,completed,Use `DataPicker` in `JoinTablePicker`,"- [x] `databaseId`
  - [x] `TablePicker`
  - [x] `QuestionPicker`
  - [x] `EntityPickerModal` - search
  - [x] add join, edit data source to use different db - join should disappear
- [x] current table does not appear selected in single-schema dbs",kamilmielnik,2024-04-03 12:43:47+00:00,['kamilmielnik'],2024-05-10 11:28:36+00:00,2024-05-10 11:28:35+00:00,https://github.com/metabase/metabase/issues/40952,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2104444685, 'issue_id': 2222836932, 'author': 'kamilmielnik', 'body': 'Closed by #42330', 'created_at': datetime.datetime(2024, 5, 10, 11, 28, 35, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-10 11:28:35 UTC): Closed by #42330

"
2222808024,issue,closed,completed,Style entity icons,"Icons in the Data Picker should have [specific colors](https://github.com/metabase/metabase/assets/6830683/6c80042f-0c08-4182-84ff-5db572c2110a).


Currently `ItemList` does not allow customizing icons in any way.
Moreover icons are currently tightly coupled with the entity framework (see `getIcon` in `EntityPicker/utils.ts`).

This task is to refactor `ItemList` to allow Icon customization AND to customize the icons in the Data Picker component.

----

Related [Slack thread](https://metaboat.slack.com/archives/C02H619CJ8K/p1715083195364169).",kamilmielnik,2024-04-03 12:31:09+00:00,[],2024-07-15 18:07:11+00:00,2024-07-15 18:06:01+00:00,https://github.com/metabase/metabase/issues/40950,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2042866852, 'issue_id': 2222808024, 'author': 'iethree', 'body': 'I would love to live in a world where icons were decoupled from entities, and there was just a `getIcon` function that you could pass a search item to, manually setting the `model` property if necessary', 'created_at': datetime.datetime(2024, 4, 8, 14, 12, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229092797, 'issue_id': 2222808024, 'author': 'iethree', 'body': 'see: [discussion](https://metaboat.slack.com/archives/C064EB1UE5P/p1721066749742059?thread_ts=1721059235.146929&cid=C064EB1UE5P)\r\n\r\n- https://github.com/metabase/metabase/pull/43161\r\n- https://github.com/metabase/metabase/pull/43095', 'created_at': datetime.datetime(2024, 7, 15, 18, 7, 10, tzinfo=datetime.timezone.utc)}]","iethree on (2024-04-08 14:12:37 UTC): I would love to live in a world where icons were decoupled from entities, and there was just a `getIcon` function that you could pass a search item to, manually setting the `model` property if necessary

iethree on (2024-07-15 18:07:10 UTC): see: [discussion](https://metaboat.slack.com/archives/C064EB1UE5P/p1721066749742059?thread_ts=1721059235.146929&cid=C064EB1UE5P)

- https://github.com/metabase/metabase/pull/43161
- https://github.com/metabase/metabase/pull/43095

"
2222761544,issue,open,,Inconsistancy between SQL and GUI query for date display of Trend chart,"### Describe the bug

When you convert a GUI query to SQL, the format of the date displayed on the trend chart changes. One of them is wrong?

### To Reproduce

1. Create a GUI question, Orders table, Count of rows by Created At
2. Select Trend Viz
3. Visualize the chart. See that the date has no time.
4. Now convert it to SQL
5. Run the query again
6. See that the chart has a different format, displaying the date format.

GUI:
![Screenshot 2024-04-03 at 9 09 17‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/0784277d-e5d0-44ae-b80a-d7fdddb4d7cc)

SQL:
![Screenshot 2024-04-03 at 9 08 18‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/ec2961ed-c30d-428c-b863-b31e1dbfb2fa)


### Expected behavior

One of them is wrong?

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 49.3
```


### Severity

P3

### Additional context

_No response_",ignacio-mb,2024-04-03 12:10:25+00:00,[],2025-02-04 20:31:51+00:00,,https://github.com/metabase/metabase/issues/40949,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2315603660, 'issue_id': 2222761544, 'author': 'Overbryd', 'body': 'I think this is related https://github.com/metabase/metabase/issues/39277, as the Trend-visualisation should receive formatting support for its date display.', 'created_at': datetime.datetime(2024, 8, 28, 14, 58, 4, tzinfo=datetime.timezone.utc)}]","Overbryd on (2024-08-28 14:58:04 UTC): I think this is related https://github.com/metabase/metabase/issues/39277, as the Trend-visualisation should receive formatting support for its date display.

"
2222654396,issue,closed,completed,Add analytics events for the native code preview in a notebook,"```[tasklist]
### Tasks
- [x] Add schema file
- [x] Add to frontend
- [x] Add tests
```
",nemanjaglumac,2024-04-03 11:20:10+00:00,['nemanjaglumac'],2024-04-03 15:59:56+00:00,2024-04-03 15:59:56+00:00,https://github.com/metabase/metabase/issues/40948,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2222313232,issue,open,,Cannot use column in join conditions more than once,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/b1217ef2-d8f9-4224-b4fa-fe995b292aa5



### To Reproduce

1. Create a question based on Orders table
2. Join People table
3. Add another join condition
4. Try to pick the same columns in the new join condition as in the default one

### Expected behavior

Column should get selected.


### Information about your Metabase installation

master, 12ea8d42b5


### Severity

P2
",kamilmielnik,2024-04-03 08:48:42+00:00,[],2025-02-04 20:27:16+00:00,,https://github.com/metabase/metabase/issues/40940,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Difficulty:Easy', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2042033890, 'issue_id': 2222313232, 'author': 'kamilmielnik', 'body': 'Found another case where condition disappears instead of being added:\r\n\r\nhttps://github.com/metabase/metabase/assets/6830683/dd70ee9a-d47f-4e21-b9a7-44e8536b3c66', 'created_at': datetime.datetime(2024, 4, 8, 7, 21, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2186871912, 'issue_id': 2222313232, 'author': 'ranquild', 'body': 'The bug that you cannot select the same column twice comes from MBQL lib. It incorrectly marks columns in `join-condition-lhs-columns` and `rhs` one as selectable. Removing this statement seems to fix the issue https://github.com/metabase/metabase/blob/1f74c4312a316128d094fd72b0dc435b2f809ff5/src/metabase/lib/join.cljc#L696. But when I did that my join condition starts to disappear after `toLegacyQuery -> fromLegacyQuery` conversion. Reassigning to QPD', 'created_at': datetime.datetime(2024, 6, 24, 15, 40, 49, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-04-08 07:21:21 UTC): Found another case where condition disappears instead of being added:

https://github.com/metabase/metabase/assets/6830683/dd70ee9a-d47f-4e21-b9a7-44e8536b3c66

ranquild on (2024-06-24 15:40:49 UTC): The bug that you cannot select the same column twice comes from MBQL lib. It incorrectly marks columns in `join-condition-lhs-columns` and `rhs` one as selectable. Removing this statement seems to fix the issue https://github.com/metabase/metabase/blob/1f74c4312a316128d094fd72b0dc435b2f809ff5/src/metabase/lib/join.cljc#L696. But when I did that my join condition starts to disappear after `toLegacyQuery -> fromLegacyQuery` conversion. Reassigning to QPD

"
2222124047,issue,closed,not_planned,multiple values error in parametes Parameters when destination is public  url,"### Describe the bug

i have a dashboard and applied clickable  behavior on a card . apllied some filters on dashboard but the values of filters are not passing correctly on the destination url . when i change the destination to question or dashboard it worked fine.
check this screen recording
https://drive.google.com/file/d/1JMokoXzeLExFeqG1vphN0sklMLL2VrO9/view

### To Reproduce

Create a card (card 1) 
write query 
add parameters in it


create another question (card 2)
make it available to public

create a clickable behavior link  card 1 to card 2

apply filters specially one that has multiple values 

now click on card 1 to trigger clickable behavior 

you will notice filters are not applied correctly



check this screen recording
https://drive.google.com/file/d/1JMokoXzeLExFeqG1vphN0sklMLL2VrO9/view

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
chrome Version 123.0.6312.86 (Official Build) (64-bit)
ubuntu 22.04
mysql 
metabase  0.48.7
jar file
mysql
```


### Severity

blocking the usage

### Additional context

_No response_",MeharG811,2024-04-03 07:28:13+00:00,[],2024-04-03 10:08:39+00:00,2024-04-03 10:08:38+00:00,https://github.com/metabase/metabase/issues/40939,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.'), ('Sharing/Public', '')]","[{'comment_id': 2033821027, 'issue_id': 2222124047, 'author': 'uladzimirdev', 'body': '@MeharG811 could you please provide more information about the click behaviour settings? \r\n\r\nI see it as a custom URL with the predefined URL params', 'created_at': datetime.datetime(2024, 4, 3, 7, 58, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2033851337, 'issue_id': 2222124047, 'author': 'uladzimirdev', 'body': 'I can confirm the broken behaviuor with a custom URL on click action:\r\n\r\n1. create a question from People\r\n2. add it to a dashboard, create a filter with a name ""param"" and map name column on it\r\n3. save dashboard and make it public, copy public URL\r\n4. add a custom click behaviour on e.g. email column and put url in destionation as `public url + ?param={{param}}`, e.g. `http://localhost:3000/public/dashboard/b56b0464-f609-439f-a74b-f8ee4912f8f8?param={{param}}`\r\n5. save dashboard, select 2 values in a filter, make sure question is filtered, then click on any email from the question -> you\'ll be redirected to a public URL with `param=value1,value2` which is wrong', 'created_at': datetime.datetime(2024, 4, 3, 8, 8, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2033981432, 'issue_id': 2222124047, 'author': 'paoliniluis', 'body': 'Isn¬¥t this a duplicate of https://github.com/metabase/metabase/issues/26412?', 'created_at': datetime.datetime(2024, 4, 3, 9, 2, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2034146800, 'issue_id': 2222124047, 'author': 'uladzimirdev', 'body': ""@paoliniluis you're right"", 'created_at': datetime.datetime(2024, 4, 3, 10, 8, 38, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-04-03 07:58:42 UTC): @MeharG811 could you please provide more information about the click behaviour settings? 

I see it as a custom URL with the predefined URL params

uladzimirdev on (2024-04-03 08:08:51 UTC): I can confirm the broken behaviuor with a custom URL on click action:

1. create a question from People
2. add it to a dashboard, create a filter with a name ""param"" and map name column on it
3. save dashboard and make it public, copy public URL
4. add a custom click behaviour on e.g. email column and put url in destionation as `public url + ?param={{param}}`, e.g. `http://localhost:3000/public/dashboard/b56b0464-f609-439f-a74b-f8ee4912f8f8?param={{param}}`
5. save dashboard, select 2 values in a filter, make sure question is filtered, then click on any email from the question -> you'll be redirected to a public URL with `param=value1,value2` which is wrong

paoliniluis on (2024-04-03 09:02:51 UTC): Isn¬¥t this a duplicate of https://github.com/metabase/metabase/issues/26412?

uladzimirdev on (2024-04-03 10:08:38 UTC): @paoliniluis you're right

"
2221521016,issue,closed,completed,"[dc.js migration] Grouping by day-of-week, day-of-month, etc. causes duplicated x-axis labels for some ranges","Both `Linear` and `Ordinal` scales are affected, but in different ways


https://github.com/metabase/metabase/assets/22608765/ce23b59c-4f16-42ae-82f7-0667b196dd1e

- [x] Ordinal Scales
   - Will be fixed by: https://github.com/metabase/metabase/pull/41055
- [x] Linear Scales 
  - Will be fixed by: https://github.com/metabase/metabase/pull/41001",JesseSDevaney,2024-04-02 21:52:15+00:00,['alxnddr'],2024-04-04 21:17:20+00:00,2024-04-04 21:17:20+00:00,https://github.com/metabase/metabase/issues/40935,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2035548303, 'issue_id': 2221521016, 'author': 'JesseSDevaney', 'body': 'I figured out the ordinal scale bug, but not the linear scale bug.\r\n\r\nI believe this is an ECharts specific bug, because I could not find anywhere in our code where we may be triggering more calls to the formatter for x-axis labels beyond what our actually existing data points are.\r\n\r\nMoving on for now. Hopefully someone else has better luck on this.', 'created_at': datetime.datetime(2024, 4, 3, 20, 43, 17, tzinfo=datetime.timezone.utc)}]","JesseSDevaney (Issue Creator) on (2024-04-03 20:43:17 UTC): I figured out the ordinal scale bug, but not the linear scale bug.

I believe this is an ECharts specific bug, because I could not find anywhere in our code where we may be triggering more calls to the formatter for x-axis labels beyond what our actually existing data points are.

Moving on for now. Hopefully someone else has better luck on this.

"
2221496873,issue,closed,completed,"Models stuck in ""refreshing"" state aren't refreshed","### Describe the bug

@john-metabase fixed this in https://github.com/metabase/metabase/pull/39664
but somehow it came back in https://github.com/metabase/metabase/pull/40578/files#diff-7d6505bf07340a1efd97f5e2372ecace87fcfef920a3a64723b9ee69f82c2cf6

<img width=""486"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/aa6616ff-9c8b-4c27-a1b0-96e96ef7325d"">
<img width=""964"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/546d16e7-d58e-43fd-889b-58d68290c327"">

Which means ""refreshing"" is no longer a refreshable-state (except it still is in OSS).

### To Reproduce

restart an instance while a model is refreshing. Or update a persisted_info state to be ""refreshing"" and it will never be refreshed again.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p2

### Additional context

_No response_",dpsutton,2024-04-02 21:34:17+00:00,['dpsutton'],2024-04-10 14:44:49+00:00,2024-04-10 14:44:49+00:00,https://github.com/metabase/metabase/issues/40934,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('Querying/Cache', '')]",[],
2221378275,issue,closed,completed,[dc.js migration] Fix E2E Specs,"- Epic: https://github.com/metabase/metabase/issues/36880

- [x] Track regression fixes and make sure that relevant tests are fixed in the process

---
- [x] `E2E Tests / e2e-tests-admin-ee`
  - https://github.com/metabase/metabase/pull/40937
- [x] `E2E Tests / e2e-tests-binning-ee`
  - https://github.com/metabase/metabase/pull/41146
- [x] `E2E Tests / e2e-tests-custom-column-ee`
  - https://github.com/metabase/metabase/pull/41210
- [x] `E2E Tests / e2e-tests-dashboard-ee`
  - https://github.com/metabase/metabase/pull/41211
- [x] `E2E Tests / e2e-tests-dashboard-cards-ee`
  - https://github.com/metabase/metabase/pull/41214
- [x] `E2E Tests / e2e-tests-embedding-ee`
  - https://github.com/metabase/metabase/pull/41336
- [x] `E2E Tests / e2e-tests-filters-ee`
  - https://github.com/metabase/metabase/pull/41337
- [x] `E2E Tests / e2e-tests-joins-ee`
- [x] `E2E Tests / e2e-tests-models-ee`
  - https://github.com/metabase/metabase/pull/41481
- [x] `E2E Tests / e2e-tests-native-ee`
- [x] `E2E Tests / e2e-tests-organization-ee`
  - https://github.com/metabase/metabase/pull/41485
- [x] `E2E Tests / e2e-tests-permissions-ee`
  - https://github.com/metabase/metabase/pull/41488
- [x] `E2E Tests / e2e-tests-question-ee`
  - https://github.com/metabase/metabase/pull/41542
- [x] `E2E Tests / e2e-tests-sharing-ee`
- [x] `E2E Tests / e2e-tests-visualizations-charts-ee`
  - https://github.com/metabase/metabase/pull/41618
- [x] `E2E Tests / e2e-tests-visualizations-tabular-ee`
  - https://github.com/metabase/metabase/pull/41663
- [x] `E2E Tests / e2e-tests-slow-ee`
  - https://github.com/metabase/metabase/pull/41699
- [x] `E2E Tests / e2e-tests-flaky-ee`
- [x] `E2E Tests / e2e-tests-mongo-ee`
  - https://github.com/metabase/metabase/pull/41700",JesseSDevaney,2024-04-02 20:21:39+00:00,['JesseSDevaney'],2024-04-25 17:00:59+00:00,2024-04-25 17:00:59+00:00,https://github.com/metabase/metabase/issues/40930,"[('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2221374009,issue,closed,completed,schema related permissions,,dpsutton,2024-04-02 20:18:23+00:00,['sloansparger'],2024-04-16 20:05:06+00:00,2024-04-16 20:05:06+00:00,https://github.com/metabase/metabase/issues/40929,[],[],
2221351594,issue,closed,completed,[dc.js migration] brushing is not working and sometimes uses the wrong column for filtering,https://github.com/metabase/metabase/assets/22608765/25bcdd2f-e584-40ed-be82-785022d6ab10,JesseSDevaney,2024-04-02 20:02:07+00:00,['JesseSDevaney'],2024-04-02 22:11:51+00:00,2024-04-02 22:11:51+00:00,https://github.com/metabase/metabase/issues/40927,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2221163181,issue,open,,Make other users' personal collections child-aware,"currently, we fetch the list of all other users personal collections (for admins) via `/api/collections?personal-only=true`

this endpoint doesn't tell us wheteher these collections have various kinds of subitems (with `here` and `below` properties), so for now we're pretending they all have children.

[discussion](https://metaboat.slack.com/archives/C064EB1UE5P/p1712082081810449)",iethree,2024-04-02 18:28:33+00:00,[],2024-05-16 06:57:43+00:00,,https://github.com/metabase/metabase/issues/40924,"[('.Backend', '')]","[{'comment_id': 2114205461, 'issue_id': 2221163181, 'author': 'kamilmielnik', 'body': 'This was duplicated by #42687 which I closed now.\r\nIt has some other details in it though, worth looking into.', 'created_at': datetime.datetime(2024, 5, 16, 6, 57, 41, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-05-16 06:57:41 UTC): This was duplicated by #42687 which I closed now.
It has some other details in it though, worth looking into.

"
2220755099,issue,closed,completed,[MBQL lib] Add join to suggestedJoinConditions,"Blocks https://github.com/metabase/metabase/pull/40891

Currently `suggestedJoinConditions` was made to work only for new join clauses. When we start to modify the rhs table for existing join clauses, it will return join conditions based on the columns from the same join clause that we want to replace, which results in a broken query. Suggested fix is to pass an optional `join` to `suggestedJoinConditions`. `suggestedJoinConditions` should ignore all join clauses in the referenced stage of the query with the same `join` or after it.",ranquild,2024-04-02 15:00:24+00:00,['bshepherdson'],2024-04-08 13:45:30+00:00,2024-04-08 13:45:30+00:00,https://github.com/metabase/metabase/issues/40916,[],"[{'comment_id': 2034894927, 'issue_id': 2220755099, 'author': 'bshepherdson', 'body': ""Making progress on this, but it's not ready for review yet.\r\n\r\nI think it's actually practical to look at the `joinable` parameter itself - if it's a join that already exists on the query, then we can figure out its position and make sure any suggestions are only using earlier joins."", 'created_at': datetime.datetime(2024, 4, 3, 15, 14, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2037144118, 'issue_id': 2220755099, 'author': 'ranquild', 'body': ""@bshepherdson `suggestedJoinConditions` is called like `suggestedJoinConditions(query, stageIndex, rhsTable)` where `rhsTable` is `joinable`; it won't be possible to compute the correct list only based on that. Instead of `joinPosition` I can pass the join clause itself. Wdyt?\r\n\r\nSo it will be `suggestedJoinConditions(query, stageIndex, joinable, join)` where `join` is optional"", 'created_at': datetime.datetime(2024, 4, 4, 12, 57, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2037292831, 'issue_id': 2220755099, 'author': 'bshepherdson', 'body': ""Ah, yeah, that's a good point. If you've got the position handy, that's easier to work with, so let's plan for\r\n`suggestedJoinConditions(query, stageIndex, newRhsTable, position)`, with position optional."", 'created_at': datetime.datetime(2024, 4, 4, 13, 57, 21, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-04-03 15:14:17 UTC): Making progress on this, but it's not ready for review yet.

I think it's actually practical to look at the `joinable` parameter itself - if it's a join that already exists on the query, then we can figure out its position and make sure any suggestions are only using earlier joins.

ranquild (Issue Creator) on (2024-04-04 12:57:04 UTC): @bshepherdson `suggestedJoinConditions` is called like `suggestedJoinConditions(query, stageIndex, rhsTable)` where `rhsTable` is `joinable`; it won't be possible to compute the correct list only based on that. Instead of `joinPosition` I can pass the join clause itself. Wdyt?

So it will be `suggestedJoinConditions(query, stageIndex, joinable, join)` where `join` is optional

bshepherdson (Assginee) on (2024-04-04 13:57:21 UTC): Ah, yeah, that's a good point. If you've got the position handy, that's easier to work with, so let's plan for
`suggestedJoinConditions(query, stageIndex, newRhsTable, position)`, with position optional.

"
2220729243,issue,closed,completed,Dashboard filters are sometimes too sensitive to drag on edit mode,"### Describe the bug

While editing a dashboard, when I want to link a filter to questions, it is hard to get it in selected state, as it's too 'draggable' and 'slides' arround

### To Reproduce

1. Go to a dashboard with filters
2. Click on pen icon (Edit the dashboard)
3. Click on a dashboard filter
4. Around 20% of the times the filter will 'jump' instead of get selected


### Expected behavior

The filter gets selected

### Logs

_No response_

### Information about your Metabase installation

```JSON
v0.49.1
```


### Severity

Minor inconvenience

### Additional context

_No response_",TLazarevic,2024-04-02 14:50:15+00:00,['npfitz'],2024-04-10 13:28:53+00:00,2024-04-10 13:28:53+00:00,https://github.com/metabase/metabase/issues/40914,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Frontend', '')]",[],
2220684959,issue,closed,completed,"Migrate global css in `frontend/src/metabase/css/dashboard.module.css`, `frontend/src/metabase/visualizations/components/LineAreaBarChart.module.css`","```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/40918
- [ ] https://github.com/metabase/metabase/pull/41018
```
",WiNloSt,2024-04-02 14:32:15+00:00,['WiNloSt'],2024-04-10 08:05:58+00:00,2024-04-10 08:05:58+00:00,https://github.com/metabase/metabase/issues/40910,[],[],
2220651090,issue,closed,completed,Upgrade metabase/connection-pool to 1.3.0,the pooler should have c3p0 in v.0.10.0 so we should bump the library when that's ready. It's our connection pooler so it's a pretty important change!,paoliniluis,2024-04-02 14:17:58+00:00,[],2025-01-16 21:04:40+00:00,2025-01-16 21:04:40+00:00,https://github.com/metabase/metabase/issues/40909,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('backend-deps', '')]",[],
2220583847,issue,open,,Public link always refers to main instance of metabase instead of custom domain,"### Describe the bug

self hosted metabase:

public dashboard can be linked as (subdomain.yourmetabase.com/public/dashboards/<string:uuid>)

public link can be linked as well as  (subdomain.yourmetabase.com/public/question/<string:uuid>)

however, if you visit the public link it will refer you to the main instance. If you visit the public dashboard it will stay on the subdomain.

This is a bug for us as have ip restrictions on the main instance


### To Reproduce

1. Go to a random question
2. Click sharing
3. Select for example: xlsx


```JSON
image:
  repository: metabase/metabase
  tag: v0.49.1
```


### Severity

annoying

### Additional context

_No response_",renew010101,2024-04-02 13:50:09+00:00,[],2025-02-04 20:31:10+00:00,,https://github.com/metabase/metabase/issues/40906,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('.Frontend', ''), ('.Team/Embedding', ''), ('Sharing/Public', '')]","[{'comment_id': 2032108125, 'issue_id': 2220583847, 'author': 'paoliniluis', 'body': ""sorry, I'm not able to understand the issue, can you please give us some reproducible steps?"", 'created_at': datetime.datetime(2024, 4, 2, 13, 54, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032128189, 'issue_id': 2220583847, 'author': 'renew010101', 'body': 'sorry.\r\n\r\nSure, \r\n\r\n1) Create a new question: https://metabase.services.yourmetabase.com/question/324-sales\r\n\r\n2) Go to sharing (icon right buttom)\r\n\r\n3) Select public link\r\n\r\n4) Use ""XLSX"" format\r\n\r\n5) Copy link. \r\n\r\n6) Change subdomain https://cllient-insights.services.yourmetabase.com/public/question/13104406-d9b0-4b88-8eb3-c9a14cdcc834.xlsx\r\n\r\n7) You will be referred towards: https://metabase.services.yourmetabase.com/public/question/13104406-d9b0-4b88-8eb3-c9a14cdcc834.xlsx\r\n\r\n8) With a public dashboard you stay on the sub domain. The issue only happens only with public links. Tested on various browsers (4/5G) in incognito mode\r\n\r\nReason:\r\n\r\nI believe the reason is the link tries to query:\r\n\r\nhttps://**metabase.services.yourmetabase.com**/api/public/card/13104406-d9b0-4b88-8eb3-c9a14cdcc834/query/csv?\r\n\r\nas it should query:\r\n\r\nhttps://**cllient-insights.services.yourmetabase.com**/api/public/card/13104406-d9b0-4b88-8eb3-c9a14cdcc834/query/csv?', 'created_at': datetime.datetime(2024, 4, 2, 14, 1, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2033949205, 'issue_id': 2220583847, 'author': 'paoliniluis', 'body': 'I don‚Äôt get it, if you configured Metabase to respond in https://metabase.services.yourmetabase.com, how would you expect to respond in another domain?', 'created_at': datetime.datetime(2024, 4, 3, 8, 49, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2424799402, 'issue_id': 2220583847, 'author': 'albertoperdomo', 'body': ""Hello @renew010101 , \n\n+1 to @paoliniluis 's comment. It seems you have configured MB to be on https://metabase.services.yourmetabase.com/. How do you expect it to point links to a different domain? Or is this an error in your repro instructions.\n\nPlease provide clear instructions for reproduction, otherwise we will have to close the issue. Thanks."", 'created_at': datetime.datetime(2024, 10, 20, 10, 4, 33, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-04-02 13:54:11 UTC): sorry, I'm not able to understand the issue, can you please give us some reproducible steps?

renew010101 (Issue Creator) on (2024-04-02 14:01:02 UTC): sorry.

Sure, 

1) Create a new question: https://metabase.services.yourmetabase.com/question/324-sales

2) Go to sharing (icon right buttom)

3) Select public link

4) Use ""XLSX"" format

5) Copy link. 

6) Change subdomain https://cllient-insights.services.yourmetabase.com/public/question/13104406-d9b0-4b88-8eb3-c9a14cdcc834.xlsx

7) You will be referred towards: https://metabase.services.yourmetabase.com/public/question/13104406-d9b0-4b88-8eb3-c9a14cdcc834.xlsx

8) With a public dashboard you stay on the sub domain. The issue only happens only with public links. Tested on various browsers (4/5G) in incognito mode

Reason:

I believe the reason is the link tries to query:

https://**metabase.services.yourmetabase.com**/api/public/card/13104406-d9b0-4b88-8eb3-c9a14cdcc834/query/csv?

as it should query:

https://**cllient-insights.services.yourmetabase.com**/api/public/card/13104406-d9b0-4b88-8eb3-c9a14cdcc834/query/csv?

paoliniluis on (2024-04-03 08:49:35 UTC): I don‚Äôt get it, if you configured Metabase to respond in https://metabase.services.yourmetabase.com, how would you expect to respond in another domain?

albertoperdomo on (2024-10-20 10:04:33 UTC): Hello @renew010101 , 

+1 to @paoliniluis 's comment. It seems you have configured MB to be on https://metabase.services.yourmetabase.com/. How do you expect it to point links to a different domain? Or is this an error in your repro instructions.

Please provide clear instructions for reproduction, otherwise we will have to close the issue. Thanks.

"
2220565863,issue,closed,completed,"Migrate global css in `frontend/src/metabase/components/sortable/sortable.module.css`, `frontend/src/metabase/nav/containers/MainNavbar/SidebarItems/sortable.module.css`","```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/40908
```
",WiNloSt,2024-04-02 13:41:59+00:00,['WiNloSt'],2024-04-03 09:06:41+00:00,2024-04-03 09:06:41+00:00,https://github.com/metabase/metabase/issues/40904,[],[],
2220414108,issue,closed,completed,[Epic] Fix FE metadata issues with duplicate columns,"Fixes the FE part of https://github.com/metabase/metabase/issues/36185
RTK query epic https://github.com/metabase/metabase/issues/40788

The underlying problem is that the FE normalizes all API data. For fields, the FE uses `field.id:field.table_id` for the key, which is not unique in case there is a model with metadata overrides where different query columns are mapped to the same field in the database. If this happens, the FE overwrites one field with another. From this point MBQL lib cannot function properly because metadata is incorrect.

Our solution to this issue is to construct metadata for MBQL lib using raw API data. New metadata object would have this shape:
```
{
  databases: Record<DatabaseId, Database>;
  tables: Record<TableId, Table>;
  fields: Record<FieldId, Field>;
  cards: Record<CardId, Card>;
}
```

We would group entities from responses by ID but won't do any normalization. E.g. if each `table` has `fields`, they would be passed unchanged and won't appear in the top-level `fields` property. MBQL lib should be updated to use this new format instead of the current one. It's very close to what we already have and shouldn't result in massive changes.

**Milestone 1 - replace api handlers in entities** - done

Part of milestone 1 in the [RTK query epic](https://github.com/metabase/metabase/issues/40788)

**Milestone 2 - use RTK query and entity framework caching for metadata requests**

```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/43628
- [ ] https://github.com/metabase/metabase/issues/43629
- [ ] https://github.com/metabase/metabase/pull/44721
```",ranquild,2024-04-02 12:36:12+00:00,['kamilmielnik'],2024-07-02 07:43:00+00:00,2024-07-02 07:42:59+00:00,https://github.com/metabase/metabase/issues/40898,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]","[{'comment_id': 2202195142, 'issue_id': 2220414108, 'author': 'kamilmielnik', 'body': 'I moved #44301, #44491, #44492 & #43630 to the RTK Query epic: #40788\r\n\r\n#44721 was the PR that allowed us to fix field-related FE metadata issues without a large RTK Query refactoring - I added it to this epic.\r\n\r\nEpic is complete. Closing.', 'created_at': datetime.datetime(2024, 7, 2, 7, 42, 59, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Assginee) on (2024-07-02 07:42:59 UTC): I moved #44301, #44491, #44492 & #43630 to the RTK Query epic: #40788

#44721 was the PR that allowed us to fix field-related FE metadata issues without a large RTK Query refactoring - I added it to this epic.

Epic is complete. Closing.

"
2220380670,issue,closed,completed,Search Results should also display collection they're in (similar to how search works today),,npfitz,2024-04-02 12:21:42+00:00,[],2024-04-11 17:14:36+00:00,2024-04-11 17:14:36+00:00,https://github.com/metabase/metabase/issues/40895,[],[],
2220347880,issue,closed,not_planned,Bad page title on question load,"### Describe the bug

While a dashboard is loading, the page browser tab title displays odd lambda values 

<img width=""84"" alt=""Screenshot 2024-04-02 at 14 02 21"" src=""https://github.com/metabase/metabase/assets/18078190/ba5e41d0-9bb5-479f-a2f9-9c039415fc3f"">


### To Reproduce

1. Go to a slow loading dashboard question
2. Inspect the title in the tab name
3. See error


### Expected behavior

Human readable title should be displayed

### Logs

_No response_

### Information about your Metabase installation

```JSON
- v0.49.1
```


### Severity

Not severe in any way

### Additional context

_No response_",TLazarevic,2024-04-02 12:06:24+00:00,[],2024-04-02 12:08:19+00:00,2024-04-02 12:07:51+00:00,https://github.com/metabase/metabase/issues/40894,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2031868838, 'issue_id': 2220347880, 'author': 'uladzimirdev', 'body': 'duplicate of https://github.com/metabase/metabase/issues/40051', 'created_at': datetime.datetime(2024, 4, 2, 12, 7, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2031869623, 'issue_id': 2220347880, 'author': 'uladzimirdev', 'body': ""@TLazarevic thanks for reporting, we're working on it"", 'created_at': datetime.datetime(2024, 4, 2, 12, 8, 18, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-04-02 12:07:51 UTC): duplicate of https://github.com/metabase/metabase/issues/40051

uladzimirdev on (2024-04-02 12:08:18 UTC): @TLazarevic thanks for reporting, we're working on it

"
2220297345,issue,closed,completed,[Epic] Allow changing data source in join,"Product doc https://www.notion.so/metabase/Allow-changing-data-source-in-join-10ce822731284486bec5de934789f376

```[tasklist]
- [ ] https://github.com/metabase/metabase/pull/40891
- [ ] https://github.com/metabase/metabase/issues/40916
```
",ranquild,2024-04-02 11:42:22+00:00,"['bshepherdson', 'ranquild']",2024-04-08 15:34:37+00:00,2024-04-08 15:34:30+00:00,https://github.com/metabase/metabase/issues/40890,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]","[{'comment_id': 2031969271, 'issue_id': 2220297345, 'author': 'bshepherdson', 'body': 'I assume there\'s a reason why this is tricky, but it\'s worth asking:\r\nWhen we\'re creating a new join, the FE holds a partial join with no condition set (if we can\'t guess a good FK -> PK condition). Why can\'t the same approach be used here?\r\n\r\nI guess it results in a confusing UX, since the join editing isn\'t a modal, there\'s not really any indication of it being a draft and not saved, nor that if cancelled the original join would still be there.\r\n\r\nCan you expand on what join conditions should be generated when ""forcefully"" generating a join condition? If we have a good suggestion, great, but if not, do we fall back on `t1.PK = t2.PK`? If the PKs are different types, is it acceptable to fall back to `0` = `1` or something else that would always be false?', 'created_at': datetime.datetime(2024, 4, 2, 12, 54, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032066540, 'issue_id': 2220297345, 'author': 'ranquild', 'body': '@bshepherdson agree. I found a way to make it FE-only. Hopefully the UX is not bad.', 'created_at': datetime.datetime(2024, 4, 2, 13, 36, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2033137129, 'issue_id': 2220297345, 'author': 'bshepherdson', 'body': '@ranquild is #40916 still necessary here?', 'created_at': datetime.datetime(2024, 4, 2, 21, 33, 18, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-04-02 12:54:53 UTC): I assume there's a reason why this is tricky, but it's worth asking:
When we're creating a new join, the FE holds a partial join with no condition set (if we can't guess a good FK -> PK condition). Why can't the same approach be used here?

I guess it results in a confusing UX, since the join editing isn't a modal, there's not really any indication of it being a draft and not saved, nor that if cancelled the original join would still be there.

Can you expand on what join conditions should be generated when ""forcefully"" generating a join condition? If we have a good suggestion, great, but if not, do we fall back on `t1.PK = t2.PK`? If the PKs are different types, is it acceptable to fall back to `0` = `1` or something else that would always be false?

ranquild (Issue Creator) on (2024-04-02 13:36:20 UTC): @bshepherdson agree. I found a way to make it FE-only. Hopefully the UX is not bad.

bshepherdson (Assginee) on (2024-04-02 21:33:18 UTC): @ranquild is #40916 still necessary here?

"
2220099215,issue,closed,not_planned,Highlighting specific pins in a pin map based on a categorical column.,"Problem of pin maps have limited additional functionality beyond marking strictly latitude and longitude coordinates.  Other information that would be useful to be able to highlight in a pin map is the different locations of pinned entities that fall under different categories. Highlighting could be done either by a transparency value for the pin or more useful for non-binary categories by different colors with an added legend.

Alternative I use now is creating custom SQL questions with parameter filters to only show pins of entities that match the selected category in the filter but this does not show the entire map as a full perspective.  Additionally does not work as well when selecting multiple values of the parameter to get an intuitive understanding of the visual without another method of differentiating pins.


",MickyKohoOC,2024-04-02 10:09:11+00:00,[],2024-06-05 14:55:26+00:00,2024-06-05 14:55:26+00:00,https://github.com/metabase/metabase/issues/40886,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2150283597, 'issue_id': 2220099215, 'author': 'paoliniluis', 'body': 'I think that this falls under https://github.com/metabase/metabase/issues/5973, is that correct?', 'created_at': datetime.datetime(2024, 6, 5, 14, 55, 26, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-06-05 14:55:26 UTC): I think that this falls under https://github.com/metabase/metabase/issues/5973, is that correct?

"
2220072750,issue,closed,completed,"""No method in multimethod 'coerce-temporal' for dispatch value: [nil java.time.LocalDateTime]"" when evaluating null datetimes","### Describe the bug

Seems that we don't like to evaluate null timestamps in sql server

### To Reproduce

1) spin up a sql server with the sample dataset, then set to null a few rows from the orders table
2) in metabase: new-> question-> orders table -> custom column: `case(isempty([Created At]), 1, 0)`
3) click on the sql button, you'll see the error in the title

### Expected behavior

We should be able to compile that

### Logs

NA

### Information about your Metabase installation

```JSON
a customer told is this is a regression in v49
```


### Severity

P1

### Additional context

wondering how much https://github.com/metabase/metabase/issues/40883 has to do on this",paoliniluis,2024-04-02 09:57:08+00:00,['lbrdnk'],2024-04-04 16:51:11+00:00,2024-04-04 16:51:11+00:00,https://github.com/metabase/metabase/issues/40885,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/SQLServer', None), ('Querying/Processor', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Notebook/Custom Column', ''), ('.Escalation', '')]",[],
2220033208,issue,closed,not_planned,Custom column to compare temporal to nulls is deleted from the notebook,"### Describe the bug

Interesting bug where we seem to fail when trying to build a column with a case statement trying to compare against null temporals

### To Reproduce

1) grab the postgres sample dataset and set to null a few dates in the orders table so you have data to play with
2) new->question-> do a custom column in the orders table that's: `case(isempty([Created At]), 1, 0)`
3) see that as soon as you click on accept the column is deleted, but it's still on the sql of the question
4) click on visualize
5) go back to the notebook, the column dissapeared

### Expected behavior

There's clearly some FE bug there, column should still be there

### Logs

no logs

### Information about your Metabase installation

```JSON
v49?
```


### Severity

P2, only because it won't crash everything like in SQL Server

### Additional context

NA",paoliniluis,2024-04-02 09:39:01+00:00,['lbrdnk'],2024-08-28 02:10:37+00:00,2024-04-05 14:39:20+00:00,https://github.com/metabase/metabase/issues/40883,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook/Custom Column', ''), ('.Team/Querying', '')]","[{'comment_id': 2039969067, 'issue_id': 2220033208, 'author': 'lbrdnk', 'body': 'Fixed by https://github.com/metabase/metabase/pull/40957', 'created_at': datetime.datetime(2024, 4, 5, 14, 39, 20, tzinfo=datetime.timezone.utc)}]","lbrdnk (Assginee) on (2024-04-05 14:39:20 UTC): Fixed by https://github.com/metabase/metabase/pull/40957

"
2220001947,issue,closed,not_planned,Add JWT auth flow code from PoC to Embedding SDK,,oisincoveney,2024-04-02 09:23:59+00:00,[],2024-04-02 09:24:38+00:00,2024-04-02 09:24:37+00:00,https://github.com/metabase/metabase/issues/40882,[],[],
2219892508,issue,closed,not_planned,Exporting the date as JSON now involves a new format instead of a timestamp,"### Describe the bug

Previously, when I downloaded my report in JSON format, I received a Unix timestamp in milliseconds. Now, the format I receive is like this: `1 April, 2024, 03:48`


### To Reproduce

1. Utilize the provided API endpoint: http://localhost:3000/api/card/123/query/json to fetch data, ensuring that there is at least one column containing date information.
2. The retrieved date is formatted.

### Expected behavior

The expected behavior is to extract the date with millisecond precision, as was the case previously.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.4.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.4.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.4.1+1"",
    ""os.name"": ""Windows Server 2016"",
    ""os.version"": ""10.0"",
    ""user.language"": ""fr"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.36""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-28"",
      ""tag"": ""v0.49.2"",
      ""hash"": ""4b83b88""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}
```


### Severity

The severity is very high, as there are post-processing scenarios that I have previously worked with based on the previous format.

### Additional context

{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.4.1+1"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.4.1"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.4.1+1"",
    ""os.name"": ""Windows Server 2016"",
    ""os.version"": ""10.0"",
    ""user.language"": ""fr"",
    ""user.timezone"": ""Europe/Paris""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.36""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-28"",
      ""tag"": ""v0.49.2"",
      ""hash"": ""4b83b88""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Paris""
    }
  }
}",vipera7,2024-04-02 08:30:24+00:00,[],2024-04-02 08:35:27+00:00,2024-04-02 08:35:27+00:00,https://github.com/metabase/metabase/issues/40881,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2031401602, 'issue_id': 2219892508, 'author': 'paoliniluis', 'body': ""We're fixing this in 49.3/49.4. We'll offer the options to export with and without formatting"", 'created_at': datetime.datetime(2024, 4, 2, 8, 35, 27, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-04-02 08:35:27 UTC): We're fixing this in 49.3/49.4. We'll offer the options to export with and without formatting

"
2219292469,issue,closed,completed,Drill-thru for usage analytics of a question is missing filters,"### Describe the bug

When viewing the usage analytics for a question, if you click on the title or data point of the _Question performance_ card, it won't have any filters, such as the question id. 

### To Reproduce

1. View usage analytics for a question
2. Click title or data point for Question performance card to do drill-thru to view the logs
3. There are no filters applied for the query logs

<img width=""753"" alt=""Screenshot 2024-04-01 at 4 36 52 PM"" src=""https://github.com/metabase/metabase/assets/9684260/375ca6f6-df1a-4e6a-bcfe-e22597870432"">


### Expected behavior

Same filters used in the dashboard should apply to the drill-thru question

### Logs

n/a

### Information about your Metabase installation

```JSON
Master @ Postgres
```


### Severity

Low

### Additional context

_No response_",maxzheng,2024-04-01 23:41:02+00:00,['luizarakaki'],2025-01-23 20:59:58+00:00,2025-01-23 20:59:58+00:00,https://github.com/metabase/metabase/issues/40878,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2190075409, 'issue_id': 2219292469, 'author': 'ranquild', 'body': 'The problem is that the dashboard uses a wrong field reference for this specific card which is recognized by QP but not MBQL lib and therefore filters are dropped when navigating to the question. The dashboard should use a correct, string-based field ref because the question is built on a model.\r\n\r\n![image](https://github.com/metabase/metabase/assets/8542534/339d1f93-b930-4daf-bdfe-45633c699b46)', 'created_at': datetime.datetime(2024, 6, 25, 22, 19, 12, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-06-25 22:19:12 UTC): The problem is that the dashboard uses a wrong field reference for this specific card which is recognized by QP but not MBQL lib and therefore filters are dropped when navigating to the question. The dashboard should use a correct, string-based field ref because the question is built on a model.

![image](https://github.com/metabase/metabase/assets/8542534/339d1f93-b930-4daf-bdfe-45633c699b46)

"
2219141893,issue,open,,Bug UI EmbedFrame,"### Describe the bug

If you place a dashboard in an iframe (sharing embed) on any other page, then when you scroll through the frame, problems with the background appear. I guess it's all about the position parameter: absolute; (EmbedFrame.styled.tsx)
![image](https://github.com/metabase/metabase/assets/153243688/1c4ddde1-4bc4-4c18-b2e5-ba350f829cfd)


### To Reproduce

1 create link (sharing embed) iframe
2 insert code to another page
3 scroll down content

### Expected behavior

![image](https://github.com/metabase/metabase/assets/153243688/03c6d562-9c0e-4bd0-9a1c-2e4cc14dcf77)


### Logs

the logs do not contain errors

### Information about your Metabase installation

```JSON
chrome 123.0.6312.86 version (last)
```


### Severity

not critical, but spoils the overall impression

### Additional context

_No response_",aim-dot-antares,2024-04-01 21:57:59+00:00,[],2024-05-21 13:25:24+00:00,,https://github.com/metabase/metabase/issues/40877,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/Embedding', '')]",[],
2219089852,issue,closed,not_planned,"Translation string interpolation on browser tab Title broken in master shows ""e=>e?E.t"" while loading","### Describe the bug

String interpolation issue with translations that shows briefly in title bar of browser tab after changing and rerunning a question.

### To Reproduce

1. Create an ad-hoc question
2. Add a filter
3. Watch the browser tab title, it briefly shows ""e=>e?E.t`Waiting ..."" while loading instead of the translation of ""Waiting ...""

![image](https://github.com/metabase/metabase/assets/8808703/ce9ab9ac-29a3-428e-b796-7fd194b8c2f2)


### Expected behavior

- expect to see translation

### Logs

n/a

### Information about your Metabase installation

```JSON
- `master` as of `80e6905`
```


### Severity

P2: standard bug

### Additional context

_No response_",likeshumidity,2024-04-01 21:24:09+00:00,[],2024-04-02 06:38:55+00:00,2024-04-02 06:38:55+00:00,https://github.com/metabase/metabase/issues/40875,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Needs Triage', ''), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature')]","[{'comment_id': 2030605837, 'issue_id': 2219089852, 'author': 'uladzimirdev', 'body': 'Probably duplicate of https://github.com/metabase/metabase/issues/40051', 'created_at': datetime.datetime(2024, 4, 1, 21, 38, 38, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-04-01 21:38:38 UTC): Probably duplicate of https://github.com/metabase/metabase/issues/40051

"
2218871349,issue,closed,completed,Migrate anonymous tracking to Snowplow,"There is a new [product doc](https://www.notion.so/metabase/Migrate-Anonymous-Stats-ping-to-Snowplow-18f155e235d34ba09f45518a866336e2?pvs=4)


```[tasklist]
### Tasks
- [ ] Milestone 1: initial migration and essential fields
- [ ] Milestone 2: extra features
- [ ] Milestone 3: extra metrics
```
",luizarakaki,2024-04-01 19:02:45+00:00,['noahmoss'],2024-10-03 20:26:19+00:00,2024-10-03 20:26:19+00:00,https://github.com/metabase/metabase/issues/40868,"[('.Epic', 'Feature Implementation or Project'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2218865284,issue,open,,Get correct commit info for cross version testing notification,"it seems that the github event payload for scheduled runs is different than for pull requests. we need to figure out how to get the correct information to make this slack message more intelligible

[Slack Message](https://metaboat.slack.com/archives/C5XHN8GLW/p1711876222100469?thread_ts=1711876222.100469&cid=C5XHN8GLW)",iethree,2024-04-01 18:58:47+00:00,[],2024-05-20 13:55:54+00:00,,https://github.com/metabase/metabase/issues/40867,"[('.CI & Tests', ''), ('.DX', 'Developer experience and QoL related.')]",[],
2218809820,issue,closed,completed,Make info hover icons less intrusive,"A couple of follow ups to the info icon feature to make them less intrusive.

[Product doc](https://www.notion.so/metabase/Surface-column-info-follow-ups-9ec2c0316c0d4a2b8c6b7e123a027a48)

- [x] Hide column info icons entirely if there is no description on the column
- [x] Try adding a delay before displaying the hover and evaluate how that feels, otherwise try out on-click instead of on-hover
- [x] Remove the icon bg, make the icon blue, and change the font weight from bold to normal
- [x] This is appearing for custom expressions, where it‚Äôs impossible to set a description for them",romeovs,2024-04-01 18:23:49+00:00,['romeovs'],2024-04-04 20:58:56+00:00,2024-04-04 20:10:26+00:00,https://github.com/metabase/metabase/issues/40863,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2218744230,issue,closed,completed,Hovering a column header when joining two models crashes the visualisation,"### Describe the bug

More info in [this thread](https://metaboat.slack.com/archives/C05MPF0TM3L/p1711991920221699).

[A video of the bug](https://www.loom.com/share/d68b727d27394154a60df7d5ff9d021a) and the [question that crashed](https://stats.metabase.com/question#eyJuYW1lIjoiQWNjb3VudCIsImRlc2NyaXB0aW9uIjoiVW5pZmllZCBsaXN0IG9mIHNlbGYtc2VydmljZSBhbmQgZW50ZXJwcmlzZSBhY2NvdW50cyBmb3Igb3VyIGN1c3RvbWVycywgaW5jbHVkaW5nIHRyaWFscy4iLCJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsiam9pbnMiOlt7ImZpZWxkcyI6ImFsbCIsImFsaWFzIjoiQWN0aXZpdHkiLCJjb25kaXRpb24iOlsiPSIsWyJmaWVsZCIsImluc3RhbmNlX2lkIix7ImJhc2UtdHlwZSI6InR5cGUvVVVJRCJ9XSxbImZpZWxkIiw1MzY5NDkseyJiYXNlLXR5cGUiOiJ0eXBlL1VVSUQiLCJqb2luLWFsaWFzIjoiQWN0aXZpdHkifV1dLCJzb3VyY2UtdGFibGUiOiJjYXJkX182MTIxIn1dLCJzb3VyY2UtdGFibGUiOiJjYXJkX180NTIzIiwiZmlsdGVyIjpbImFuZCIsWyI9IixbImZpZWxkIiwiaXNfY29udmVydGVkIix7ImJhc2UtdHlwZSI6InR5cGUvQm9vbGVhbiJ9XSx0cnVlXSxbInRpbWUtaW50ZXJ2YWwiLFsiZmllbGQiLCJjcmVhdGVkX2F0Iix7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWVXaXRoTG9jYWxUWiJ9XSwtMTIsIm1vbnRoIl0sWyJpcy1udWxsIixbImZpZWxkIiwiY2FuY2VsZWRfYXQiLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlVGltZVdpdGhMb2NhbFRaIn1dXV19fSwiZGlzcGxheSI6InRhYmxlIiwicGFyYW1ldGVycyI6W10sInZpc3VhbGl6YXRpb25fc2V0dGluZ3MiOnt9LCJvcmlnaW5hbF9jYXJkX2lkIjo0NTIzfQ==).


### To Reproduce

1. visit [this question](https://stats.metabase.com/question#eyJuYW1lIjoiQWNjb3VudCIsImRlc2NyaXB0aW9uIjoiVW5pZmllZCBsaXN0IG9mIHNlbGYtc2VydmljZSBhbmQgZW50ZXJwcmlzZSBhY2NvdW50cyBmb3Igb3VyIGN1c3RvbWVycywgaW5jbHVkaW5nIHRyaWFscy4iLCJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyNiwidHlwZSI6InF1ZXJ5IiwicXVlcnkiOnsiam9pbnMiOlt7ImZpZWxkcyI6ImFsbCIsImFsaWFzIjoiQWN0aXZpdHkiLCJjb25kaXRpb24iOlsiPSIsWyJmaWVsZCIsImluc3RhbmNlX2lkIix7ImJhc2UtdHlwZSI6InR5cGUvVVVJRCJ9XSxbImZpZWxkIiw1MzY5NDkseyJiYXNlLXR5cGUiOiJ0eXBlL1VVSUQiLCJqb2luLWFsaWFzIjoiQWN0aXZpdHkifV1dLCJzb3VyY2UtdGFibGUiOiJjYXJkX182MTIxIn1dLCJzb3VyY2UtdGFibGUiOiJjYXJkX180NTIzIiwiZmlsdGVyIjpbImFuZCIsWyI9IixbImZpZWxkIiwiaXNfY29udmVydGVkIix7ImJhc2UtdHlwZSI6InR5cGUvQm9vbGVhbiJ9XSx0cnVlXSxbInRpbWUtaW50ZXJ2YWwiLFsiZmllbGQiLCJjcmVhdGVkX2F0Iix7ImJhc2UtdHlwZSI6InR5cGUvRGF0ZVRpbWVXaXRoTG9jYWxUWiJ9XSwtMTIsIm1vbnRoIl0sWyJpcy1udWxsIixbImZpZWxkIiwiY2FuY2VsZWRfYXQiLHsiYmFzZS10eXBlIjoidHlwZS9EYXRlVGltZVdpdGhMb2NhbFRaIn1dXV19fSwiZGlzcGxheSI6InRhYmxlIiwicGFyYW1ldGVycyI6W10sInZpc3VhbGl6YXRpb25fc2V0dGluZ3MiOnt9LCJvcmlnaW5hbF9jYXJkX2lkIjo0NTIzfQ==)
2. hover a column title
3. the visualisation crashes

### Expected behavior

It should not crash.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase on `master` on cfca4987006971de010296413b9e664f85e39950
```


### Severity

P1

### Additional context

This was reproduced on stats.metabase.com",romeovs,2024-04-01 17:46:12+00:00,[],2024-04-02 15:17:44+00:00,2024-04-01 18:23:49+00:00,https://github.com/metabase/metabase/issues/40860,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]",[],
2218561462,issue,closed,completed,"[FE + BE] Update the permissions graph with the `view-data` and `create-queries` permissions, and allow it to be read & written via the admin panel","```[tasklist]
### Frontend Tasks
- [x] Update UI to all users to select all the new permission options
- [x] Enable granular permission for ""Create queries""
- [x] Sandboxing a table should downgrade all `create-queries` perms to `query-builder-only` for a table
- [x] Choosing ""Granular"" option for `create-queries` should downgrade all other tables for db to `query-builder-only` if db is set to `query-builder-and-native`
- [x] Do not disable ""Create queries"" options at table level when value is set at DB level
- [x] Refactor code to handle different perms have different default values if eluded in perms graph
- [x] Refactor FE perms code to use enums instead of magic strings
- [x] Add better typings to FE code to aid in bug discovery
- [x] Add new copy to the ""Permission help"" section
```

```[tasklist]
### Feeback/Bugs
- [x] Fix race condition that happens if you change a permission to granular and the database tables haven't loaded yet
- [x] Infer the db level create query permissions if the user have changed all granular permission to the same value
- [x] Fix databases with null schema name not displaying / updating values in graph correctly
- [x] Fix deleted groups getting sent to the server on save causing graph to not save correctly
- [x] Fix changing create query perms value in tables view chaning all view data perms to unrestricted
```

```[tasklist]
### E2E Test Coverage
- [x] Add test coverage for `view-data` = `blocked`
- [x] Add test coverage for `view-data` = `legacy-no-self-service`
- [x] Add test coverage for `view-data` = `granular`
- [x] Add test coverage for `view-data` = `sandboxed`
- [x] Add test coverage for `view-data` = `unrestricted`
- [x] Add test coverage for `view-data` = `impersonated`
- [x] Add test coverage for `create-queries` = `query-builder-and-native`
- [x] Add test coverage for `create-queries` = `query-builder`
- [x] Add test coverage for `create-queries` = `granular`
- [x] Add test coverage for `create-queries` = `no`
```
",sloansparger,2024-04-01 15:58:31+00:00,['sloansparger'],2024-04-17 13:40:35+00:00,2024-04-17 13:40:34+00:00,https://github.com/metabase/metabase/issues/40852,[],[],
2218498364,issue,open,,Make the logging asynchronous,"**Is your feature request related to a problem? Please describe.**
Our current logging seems to be synchronous, which can hurt the app performance on big bursts (either you have the logging on higher verbosity or the instance is getting hammered by lots of users). Log4j2 allows to configure async logging (https://logging.apache.org/log4j/2.x/manual/async.html) which seems to increase performance by making all logging asynchronous https://logging.apache.org/log4j/2.x/manual/async.html#asynchronous-logging-performance

**Describe the solution you'd like**
Switch from sync to async logging

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Just saw this while I was checking for some configs on Log4J2 docs, no one asked for this

**Additional context**
NA
",paoliniluis,2024-04-01 15:26:08+00:00,[],2025-02-04 20:30:59+00:00,,https://github.com/metabase/metabase/issues/40848,"[('.Performance', ''), ('Type:New Feature', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Operation/Logging', ""Related to what and how we log things to log files/SDOUT (don't confuse with Usage Analytics/Audit)"")]","[{'comment_id': 2130356465, 'issue_id': 2218498364, 'author': 'paoliniluis', 'body': ""A really interesting thing that I found debugging Metabase: let's say that the appender takes too much time (e.g. you're running out of disk iops for some reason, the http appender is taking too much time, etc). Well, this issue will make Metabase to start queuing requests as it needs to synchronously log stuff"", 'created_at': datetime.datetime(2024, 5, 24, 21, 5, 35, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-05-24 21:05:35 UTC): A really interesting thing that I found debugging Metabase: let's say that the appender takes too much time (e.g. you're running out of disk iops for some reason, the http appender is taking too much time, etc). Well, this issue will make Metabase to start queuing requests as it needs to synchronously log stuff

"
2218363040,issue,open,,Highlight values ABOVE GOALINE and BELOW GOALLINE for conditonal formatting,"**Is your feature request related to a problem? Please describe.**
For more clear data highlighting and indicating 

**Describe the solution you'd like**
Conditonal Formatting where values above the goalline you manually set are hightlighted and same thing for below 

**Describe alternatives you've considered**
there are none

**How important is this feature to you?**
8 / 10
very cool data visualization ; really can utilizie metabase to be a more revenue / financial tool platform 

**Additional context**
thank you",OdinTallBeard,2024-04-01 14:11:48+00:00,[],2024-05-29 12:49:17+00:00,,https://github.com/metabase/metabase/issues/40842,"[('Type:New Feature', ''), ('Visualization/Chart Settings', '')]",[],
2218037789,issue,open,,Granular permissions for content management/verification,"Currently all Admin user can mark a collection verified or Official , can we segregate based on user groups. It will give us permission for multi level authorization",hgupta1983,2024-04-01 10:57:17+00:00,[],2025-02-04 20:31:02+00:00,,https://github.com/metabase/metabase/issues/40837,"[('Type:New Feature', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('Organization/', ''), ('Organization/Verification & Official Items', '')]",[],
2217869138,issue,closed,completed,Migration doesn't like rows with null characters,"### Describe the bug

Hello,
I'm running metabase service on ubuntu and postgresql 14 as database.
`psql (14.9 (Ubuntu 14.9-0ubuntu0.22.04.1))`
Trying to update from 48.8 to 49.2 but metabase service doent work properly, 
when check journalctl there are some errors as 
 
```
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat:
Reason: clojure.lang.ExceptionInfo: ERROR: unsupported Unicode escape sequence
```
another error:
```
ERROR jdbcjobstore.JobStoreTX :: MisfireHandler: Error handling misfires: Couldn't store trigger 'DEFAULT.metabase.task.truncate-audit-log.trigger' for 'DEFAULT.metabase.task.truncate-audit-log.job' job:Cou>
 org.quartz.JobPersistenceException: Couldn't store trigger 'DEFAULT.metabase.task.truncate-audit-log.trigger' for 'DEFAULT.metabase.task.truncate-audit-log.job' job:Couldn't retrieve job because a required class was not found: met>
```
  

full log:
https://hackmd.io/@OdFNQ07XQeCmq8QL3wcWzw/BJluLgOJ0



### To Reproduce

follow update instructions.
Change newer merabase.jar and start metabase service


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Chrome Version 121.0.6167.140 (Official Build) (64-bit)
Ubuntu 22.04.1
Postgresql 14.9
Metabase 0.48.8
Jar File on Ubuntu
Postgresql 14.9
```


### Severity

FATAL

### Additional context

_No response_",bagafoot,2024-04-01 09:04:50+00:00,['calherries'],2024-04-19 09:53:35+00:00,2024-04-18 17:07:39+00:00,https://github.com/metabase/metabase/issues/40835,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Postgres', None), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2029482250, 'issue_id': 2217869138, 'author': 'qnkhuat', 'body': ""the query being executed is\r\n```sql\r\nUPDATE revision\r\n               SET object = jsonb_set(\r\n                  object::jsonb, '{type}',\r\n                  to_jsonb(CASE\r\n                              WHEN (object::jsonb->>'dataset')::boolean THEN 'model'\r\n                              ELSE 'question'\r\n                           END)::jsonb, true)\r\n               WHERE model = 'Card' AND (object::jsonb->>'dataset') IS NOT NULL;\r\n```\r\n\r\nit's probably something weird in your `revision.object` that makes this query fail."", 'created_at': datetime.datetime(2024, 4, 1, 9, 33, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029505637, 'issue_id': 2217869138, 'author': 'paoliniluis', 'body': '```\r\nApr 01 11:34:37 METABASE06S01 metabase[1162568]:   Detail: \\u0000 cannot be converted to text.\r\nApr 01 11:34:37 METABASE06S01 metabase[1162568]:   Where: JSON data, line 1: ....\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\windows\\\\win.ini\\u0000... {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\\n >\r\n```\r\nthis is interesting, what\'s that win.ini thing in the database?', 'created_at': datetime.datetime(2024, 4, 1, 9, 54, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029617801, 'issue_id': 2217869138, 'author': 'bagafoot', 'body': '@qnkhuat @paoliniluis \r\nthis is the problematic row \r\n\r\n```\r\n{\r\n  ""description"": ""Description"",\r\n  ""archived"": false,\r\n  ""collection_position"": null,\r\n  ""table_id"": 180,\r\n  ""database_id"": 2,\r\n  ""enable_embedding"": false,\r\n  ""collection_id"": null,\r\n  ""query_type"": ""query"",\r\n  ""name"": ""Beptr FactTumProjeler"",\r\n  ""embedding_params"": null,\r\n  ""cache_ttl"": null,\r\n  ""dataset_query"": {\r\n    ""database"": 2,\r\n    ""type"": ""query"",\r\n    ""query"": {\r\n      ""source-table"": 180\r\n    }\r\n  },\r\n  ""parameter_mappings"": [],\r\n  ""display"": ""table"",\r\n  ""collection_preview"": true,\r\n  ""visualization_settings"": {\r\n    ""table.pivot_column"": ""ProjectState_Id"",\r\n    ""table.cell_column"": ""..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\..\\\\windows\\\\win.ini\\u0000Project_Id""\r\n  },\r\n  ""parameters"": [],\r\n  ""dataset"": false\r\n}\r\n```', 'created_at': datetime.datetime(2024, 4, 1, 11, 29, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029659109, 'issue_id': 2217869138, 'author': 'paoliniluis', 'body': 'So the fix is simple, wipe that stuff from the database. I just changed the name of the issue to reflect the actual problem', 'created_at': datetime.datetime(2024, 4, 1, 12, 7, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2064592494, 'issue_id': 2217869138, 'author': 'calherries', 'body': ""resolved by https://github.com/metabase/metabase/pull/41584, the issue was that for postgres, converting text to JSONB doesn't work if the text contains any null characters."", 'created_at': datetime.datetime(2024, 4, 18, 17, 7, 39, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-04-01 09:33:57 UTC): the query being executed is
```sql
UPDATE revision
               SET object = jsonb_set(
                  object::jsonb, '{type}',
                  to_jsonb(CASE
                              WHEN (object::jsonb->>'dataset')::boolean THEN 'model'
                              ELSE 'question'
                           END)::jsonb, true)
               WHERE model = 'Card' AND (object::jsonb->>'dataset') IS NOT NULL;
```

it's probably something weird in your `revision.object` that makes this query fail.

paoliniluis on (2024-04-01 09:54:23 UTC): ```
Apr 01 11:34:37 METABASE06S01 metabase[1162568]:   Detail: \u0000 cannot be converted to text.
Apr 01 11:34:37 METABASE06S01 metabase[1162568]:   Where: JSON data, line 1: ....\\..\\..\\..\\..\\..\\..\\windows\\win.ini\u0000... {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n >
```
this is interesting, what's that win.ini thing in the database?

bagafoot (Issue Creator) on (2024-04-01 11:29:53 UTC): @qnkhuat @paoliniluis 
this is the problematic row 

```
{
  ""description"": ""Description"",
  ""archived"": false,
  ""collection_position"": null,
  ""table_id"": 180,
  ""database_id"": 2,
  ""enable_embedding"": false,
  ""collection_id"": null,
  ""query_type"": ""query"",
  ""name"": ""Beptr FactTumProjeler"",
  ""embedding_params"": null,
  ""cache_ttl"": null,
  ""dataset_query"": {
    ""database"": 2,
    ""type"": ""query"",
    ""query"": {
      ""source-table"": 180
    }
  },
  ""parameter_mappings"": [],
  ""display"": ""table"",
  ""collection_preview"": true,
  ""visualization_settings"": {
    ""table.pivot_column"": ""ProjectState_Id"",
    ""table.cell_column"": ""..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\windows\\win.ini\u0000Project_Id""
  },
  ""parameters"": [],
  ""dataset"": false
}
```

paoliniluis on (2024-04-01 12:07:40 UTC): So the fix is simple, wipe that stuff from the database. I just changed the name of the issue to reflect the actual problem

calherries (Assginee) on (2024-04-18 17:07:39 UTC): resolved by https://github.com/metabase/metabase/pull/41584, the issue was that for postgres, converting text to JSONB doesn't work if the text contains any null characters.

"
2217312281,issue,closed,not_planned,‰∏ä‰º†csvÊñá‰ª∂Êä•Èîô,Âú®ÊâßË°åÂÜôÂÖ•Êü•ËØ¢Êó∂Âá∫Èîô„ÄÇ(conn=4749) Identifier name '%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD_%EF%BF%BD%EF%BF%BD%C5%80' is too long,Memory5210,2024-04-01 01:24:09+00:00,[],2024-09-06 15:37:37+00:00,2024-09-06 15:37:37+00:00,https://github.com/metabase/metabase/issues/40831,"[('Priority:P2', 'Average run of the mill bug'), ('Visualization/Download', ''), ('.Team/Workflows', 'aka BEC'), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2029506683, 'issue_id': 2217312281, 'author': 'paoliniluis', 'body': 'Change the name of the CSV file to something shorter and try again. I think this is due to the encodings. Can you share the name of your CSV file?', 'created_at': datetime.datetime(2024, 4, 1, 9, 55, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030888062, 'issue_id': 2217312281, 'author': 'Memory5210', 'body': ""> Change the name of the CSV file to something shorter and try again. I think this is due to the encodings. Can you share the name of your CSV file?\r\n\r\nThe file names are ces.csv and ce.csv, just for testing functionality.I also think it's a encoding issue, but I don't know where to set it up."", 'created_at': datetime.datetime(2024, 4, 2, 0, 56, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030890054, 'issue_id': 2217312281, 'author': 'Memory5210', 'body': ""The downloaded CSV file in Chinese is also garbled due to the encoding format, but I don't know how to modify its default settings"", 'created_at': datetime.datetime(2024, 4, 2, 0, 59, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2334330558, 'issue_id': 2217312281, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/45689', 'created_at': datetime.datetime(2024, 9, 6, 15, 37, 37, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-04-01 09:55:23 UTC): Change the name of the CSV file to something shorter and try again. I think this is due to the encodings. Can you share the name of your CSV file?

Memory5210 (Issue Creator) on (2024-04-02 00:56:23 UTC): The file names are ces.csv and ce.csv, just for testing functionality.I also think it's a encoding issue, but I don't know where to set it up.

Memory5210 (Issue Creator) on (2024-04-02 00:59:11 UTC): The downloaded CSV file in Chinese is also garbled due to the encoding format, but I don't know how to modify its default settings

paoliniluis on (2024-09-06 15:37:37 UTC): duplicate of https://github.com/metabase/metabase/issues/45689

"
2216498336,issue,closed,not_planned,DB migration from H2 to MariaDB fails with UTF8mb3 error,"### Describe the bug

Despite Metabase's own documentation instructing us to configure the target DB as utf8mb4, migrating the DB from H2 to MariaDB fails, reporting apparent collation mismatch errors, which oddly relate to utf8mb3.

It appears that the migration script gets so far as to create tables in the target DB, but then falls over.

I have tried re-creating the MariaDB database with different collations (utf8mb3 for ex.) but this appears to make no difference and we get the same error.

### To Reproduce

Attempt to migrate H2 DB to MariaDB with:
 java -DMB_DB_TYPE=mysql -DMB_DB_CONNECTION_URI=""jdbc:mysql://it-db-server-2.my-domain.local:3306/metabase?user=metabase&password=1234567!"" -jar metabase.jar load-from-h2 metabase.db

### Expected behavior

DB should convert without issue.

### Logs
```
2024-03-20 19:29:25,892 INFO metabase.util :: Maximum memory available to JVM: 912.0 MB
2024-03-20 19:29:29,901 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. üîì
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-03-20 19:29:40,415 INFO driver.impl :: Registered abstract driver :sql  üöö
2024-03-20 19:29:40,445 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) üöö
2024-03-20 19:29:40,469 INFO metabase.util :: Load driver :sql-jdbc took 214.3 ms
2024-03-20 19:29:40,471 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) üöö
2024-03-20 19:29:40,802 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) üöö
2024-03-20 19:29:40,862 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) üöö
2024-03-20 19:29:43,544 INFO metabase.core ::
Metabase v0.49.0 (46c668b)

Copyright ¬© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-03-20 19:29:43,769 INFO driver.impl :: Registered abstract driver :metabase.driver.sql-jdbc.execute.legacy-impl/use-legacy-classes-for-read-and-set  üöö
2024-03-20 19:29:43,779 INFO driver.impl :: Registered abstract driver :metabase.driver.sql.query-processor.empty-string-is-null/empty-string-is-null  üöö
2024-03-20 19:29:44,424 INFO cmd.copy :: Set up h2 source database and run migrations...
2024-03-20 19:29:44,427 INFO db.setup :: Verifying h2 Database Connection ...
2024-03-20 19:29:45,234 INFO db.setup :: Successfully verified H2 2.1.214 (2022-06-13) application database connection. ‚úÖ
2024-03-20 19:29:45,236 INFO db.setup :: Checking if a database downgrade is required...
2024-03-20 19:29:46,674 INFO db.setup :: Running Database Migrations...
2024-03-20 19:29:46,675 INFO db.setup :: Setting up Liquibase...
2024-03-20 19:29:47,167 INFO db.setup :: Liquibase is ready.
2024-03-20 19:29:47,168 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-03-20 19:29:47,983 INFO db.liquibase :: No unrun migrations found.
2024-03-20 19:29:47,984 INFO db.setup :: Database Migrations Current ...  ‚úÖ
2024-03-20 19:29:47,985 INFO metabase.util :: Database setup took 3.6 s
2024-03-20 19:29:47,986 INFO cmd.copy :: [OK]
2024-03-20 19:29:47,987 INFO cmd.copy :: Set up mysql target database and run migrations...
2024-03-20 19:29:47,991 INFO db.setup :: Verifying mysql Database Connection ...
2024-03-20 19:29:48,166 INFO db.setup :: Successfully verified MariaDB 10.6.12-MariaDB-log application database connection. ‚úÖ
2024-03-20 19:29:48,167 INFO db.setup :: Checking if a database downgrade is required...
2024-03-20 19:29:48,585 INFO db.setup :: Running Database Migrations...
2024-03-20 19:29:48,586 INFO db.setup :: Setting up Liquibase...
2024-03-20 19:29:48,858 INFO db.setup :: Liquibase is ready.
2024-03-20 19:29:48,859 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-03-20 19:29:49,836 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...
2024-03-20 19:29:49,857 INFO db.liquibase :: No migration lock found.
2024-03-20 19:29:50,296 INFO db.liquibase :: Running 275 migrations ...
2024-03-20 19:29:54,320 INFO impl.StdSchedulerFactory :: Using default implementation for ThreadExecutor
2024-03-20 19:29:54,344 INFO core.SchedulerSignalerImpl :: Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
2024-03-20 19:29:54,344 INFO core.QuartzScheduler :: Quartz Scheduler v.2.3.2 created.
2024-03-20 19:29:54,347 INFO jdbcjobstore.JobStoreTX :: Using db table-based data access locking (synchronization).
2024-03-20 19:29:54,350 INFO jdbcjobstore.JobStoreTX :: JobStoreTX initialized.
2024-03-20 19:29:54,351 INFO core.QuartzScheduler :: Scheduler meta-data: Quartz Scheduler (v2.3.2) 'MetabaseScheduler' with instanceId 'g0001111710962994324'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.impl.jdbcjobstore.JobStoreTX' - which supports persistence. and is clustered.

2024-03-20 19:29:54,352 INFO impl.StdSchedulerFactory :: Quartz scheduler 'MetabaseScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
2024-03-20 19:29:54,352 INFO impl.StdSchedulerFactory :: Quartz scheduler version: 2.3.2
2024-03-20 19:29:54,400 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111710962994324 started.
2024-03-20 19:29:54,417 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111710962994324 shutting down.
2024-03-20 19:29:54,417 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111710962994324 paused.
2024-03-20 19:29:54,419 INFO core.QuartzScheduler :: Scheduler MetabaseScheduler_$_g0001111710962994324 shutdown complete.
2024-03-20 19:29:54,992 INFO db.custom-migrations :: No forward migration for DowngradeDashboardTab
2024-03-20 19:29:57,866 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat encountered an exception.

UPDATE SUMMARY
Run:                        275
Previously run:               0
Filtered out:                 5
-------------------------------
Total change sets:          280


FILTERED CHANGE SETS SUMMARY
DBMS mismatch:                5

2024-03-20 19:29:57,955 ERROR cmd.copy :: [FAIL]

clojure.lang.ExceptionInfo: ERROR Set up mysql target database and run migrations...: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '=' {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x75b34b86 ""clojure.core$map$fn__5931$fn__5932@75b34b86""]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with built query"" {:toucan2.pipeline/built-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with resolved query"" {:toucan2.pipeline/resolved-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.result-type/*, :toucan2.pipeline/parsed-args {:connectable nil, :queryable [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}}] [""with model"" {:toucan2.pipeline/model nil}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]} {}
        at metabase.cmd.copy$do_step$fn__102149.invoke(copy.clj:33)
        at metabase.cmd.copy$do_step.invokeStatic(copy.clj:29)
        at metabase.cmd.copy$do_step.invoke(copy.clj:27)
        at metabase.cmd.copy$fn__102339$copy_BANG___102344$fn__102345.invoke(copy.clj:387)
        at metabase.cmd.copy$fn__102339$copy_BANG___102344.invoke(copy.clj:372)
        at metabase.cmd.load_from_h2$load_from_h2_BANG_.invokeStatic(load_from_h2.clj:36)
        at metabase.cmd.load_from_h2$load_from_h2_BANG_.invoke(load_from_h2.clj:26)
        at clojure.lang.Var.invoke(Var.java:384)
        at metabase.cmd$load_from_h2.invokeStatic(cmd.clj:74)
        at metabase.cmd$load_from_h2.invoke(cmd.clj:68)
        at clojure.lang.AFn.applyToHelper(AFn.java:154)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.cmd$run_cmd$fn__103241.invoke(cmd.clj:301)
        at metabase.cmd$run_cmd.invokeStatic(cmd.clj:300)
        at metabase.cmd$run_cmd.invoke(cmd.clj:290)
        at clojure.lang.Var.invoke(Var.java:388)
        at metabase.core$run_cmd.invokeStatic(core.clj:178)
        at metabase.core$run_cmd.invoke(core.clj:176)
        at metabase.core$entrypoint.invokeStatic(core.clj:200)
        at metabase.core$entrypoint.doInvoke(core.clj:195)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at metabase.bootstrap.main(Unknown Source)
Caused by: liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '=' {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x75b34b86 ""clojure.core$map$fn__5931$fn__5932@75b34b86""]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with built query"" {:toucan2.pipeline/built-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with resolved query"" {:toucan2.pipeline/resolved-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.result-type/*, :toucan2.pipeline/parsed-args {:connectable nil, :queryable [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}}] [""with model"" {:toucan2.pipeline/model nil}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
        at liquibase.command.CommandScope.execute(CommandScope.java:253)
        at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.Liquibase.runInScope(Liquibase.java:1419)
        at liquibase.Liquibase.update(Liquibase.java:234)
        at liquibase.Liquibase.update(Liquibase.java:212)
        at liquibase.Liquibase.update(Liquibase.java:194)
        at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:240)
        at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:222)
        at metabase.db.setup$migrate_BANG_$fn__50987.invoke(setup.clj:80)
        at metabase.db.liquibase$do_with_liquibase$f_STAR___48693.invoke(liquibase.clj:135)
        at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:138)
        at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:126)
        at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)
        at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)
        at clojure.lang.RestFn.invoke(RestFn.java:445)
        at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)
        at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)
        at metabase.db.setup$setup_db_BANG_$fn__51015$fn__51016.invoke(setup.clj:165)
        at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)
        at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)
        at metabase.db.setup$setup_db_BANG_$fn__51015.invoke(setup.clj:160)
        at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)
        at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)
        at metabase.cmd.copy$fn__102339$copy_BANG___102344$fn__102345$fn__102352.invoke(copy.clj:388)
        at metabase.cmd.copy$do_step$fn__102149.invoke(copy.clj:30)
        ... 29 more
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '=' {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x75b34b86 ""clojure.core$map$fn__5931$fn__5932@75b34b86""]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with built query"" {:toucan2.pipeline/built-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with resolved query"" {:toucan2.pipeline/resolved-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.result-type/*, :toucan2.pipeline/parsed-args {:connectable nil, :queryable [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}}] [""with model"" {:toucan2.pipeline/model nil}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
        at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
        at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
        at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
        at liquibase.command.CommandScope.execute(CommandScope.java:217)
        ... 57 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '=' {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x75b34b86 ""clojure.core$map$fn__5931$fn__5932@75b34b86""]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with built query"" {:toucan2.pipeline/built-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with resolved query"" {:toucan2.pipeline/resolved-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.result-type/*, :toucan2.pipeline/parsed-args {:connectable nil, :queryable [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}}] [""with model"" {:toucan2.pipeline/model nil}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
        at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
        at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
        at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
        at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
        at liquibase.Scope.lambda$child$0(Scope.java:186)
        at liquibase.Scope.child(Scope.java:195)
        at liquibase.Scope.child(Scope.java:185)
        at liquibase.Scope.child(Scope.java:164)
        at liquibase.Scope.child(Scope.java:252)
        at liquibase.Scope.child(Scope.java:256)
        at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
        ... 65 more
Caused by: clojure.lang.ExceptionInfo: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '=' {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x75b34b86 ""clojure.core$map$fn__5931$fn__5932@75b34b86""]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with built query"" {:toucan2.pipeline/built-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with resolved query"" {:toucan2.pipeline/resolved-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.result-type/*, :toucan2.pipeline/parsed-args {:connectable nil, :queryable [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}}] [""with model"" {:toucan2.pipeline/model nil}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:79)
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
        at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
        at org.mariadb.jdbc.ClientSidePreparedStatement.executeInternal(ClientSidePreparedStatement.java:229)
        at org.mariadb.jdbc.ClientSidePreparedStatement.execute(ClientSidePreparedStatement.java:149)
        at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
        at toucan2.jdbc.query$reduce_jdbc_query.invokeStatic(query.clj:40)
        at toucan2.jdbc.query$reduce_jdbc_query.invoke(query.clj:22)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invokeStatic(pipeline.clj:19)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invoke(pipeline.clj:9)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18235.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.pipeline$transduce_execute$with_connection_STAR___21460.invoke(pipeline.clj:78)
        at toucan2.connection$bind_current_connectable_fn$fn__21137.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__21137.invoke(connection.clj:104)
        at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
        at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18229.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
        at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18229.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.pipeline$transduce_execute.invokeStatic(pipeline.clj:77)
        at toucan2.pipeline$transduce_execute.invoke(pipeline.clj:64)
        at clojure.lang.Var.invoke(Var.java:399)
        at toucan2.pipeline$transduce_compiled_query.invokeStatic(pipeline.clj:244)
        at toucan2.pipeline$transduce_compiled_query.invoke(pipeline.clj:240)
        at toucan2.pipeline$transduce_built_query.invokeStatic(pipeline.clj:252)
        at toucan2.pipeline$transduce_built_query.invoke(pipeline.clj:246)
        at toucan2.pipeline$transduce_query_primary_method_default.invokeStatic(pipeline.clj:272)
        at toucan2.pipeline$transduce_query_primary_method_default.invoke(pipeline.clj:269)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18235.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.pipeline$transduce_query_STAR_.invokeStatic(pipeline.clj:278)
        at toucan2.pipeline$transduce_query_STAR_.invoke(pipeline.clj:274)
        at toucan2.pipeline$transduce_with_model.invokeStatic(pipeline.clj:293)
        at toucan2.pipeline$transduce_with_model.invoke(pipeline.clj:280)
        at toucan2.pipeline$transduce_parsed.invokeStatic(pipeline.clj:309)
        at toucan2.pipeline$transduce_parsed.invoke(pipeline.clj:295)
        at toucan2.execute$fn__21576.invokeStatic(execute.clj:79)
        at toucan2.execute$fn__21576.invoke(execute.clj:77)
        at toucan2.execute$query_STAR_$query_STAR__STAR___21573.invoke(execute.clj:39)
        at toucan2.execute$query_STAR_$query_STAR__STAR___21573.invoke(execute.clj:33)
        at toucan2.execute$query_STAR_$query_STAR__STAR___21573.invoke(execute.clj:28)
        at toucan2.execute$query_STAR_$query_STAR__STAR___21573.invoke(execute.clj:25)
        at metabase.db.custom_migrations.CardRevisionAddType$with_connection_STAR___48509$with_transaction_STAR___48510.invoke(custom_migrations.clj:1050)
        at toucan2.connection$bind_current_connectable_fn$fn__21137.invoke(connection.clj:104)
        at metabase.db.connection$do_transaction$thunk__32312.invoke(connection.clj:150)
        at metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)
        at metabase.db.connection$do_transaction.invoke(connection.clj:146)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18231.invoke(threaded.clj:71)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2588)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.invoke(threaded.clj:44)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
        at metabase.db.custom_migrations.CardRevisionAddType$with_connection_STAR___48509.invoke(custom_migrations.clj:1037)
        at toucan2.connection$bind_current_connectable_fn$fn__21137.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__21137.invoke(connection.clj:104)
        at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
        at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18229.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
        at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__18227$fn__18228$fn__18229.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197$fn__18201.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6887)
        at clojure.core$reduce.invoke(core.clj:6869)
        at methodical.impl.combo.threaded$reducer_fn$fn__18197.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__18207.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at metabase.db.custom_migrations.CardRevisionAddType.execute(custom_migrations.clj:1037)
        at liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)
        at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)
        at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
        ... 80 more
Caused by: java.sql.SQLTransientConnectionException: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '='
        ... 426 more
Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '='
        at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:178)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:322)
        at org.mariadb.jdbc.ClientSidePreparedStatement.executeInternal(ClientSidePreparedStatement.java:220)
        ... 422 more
Caused by: java.sql.SQLException: Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '='
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:319)
        ... 423 more
Command failed with exception: ERROR Set up mysql target database and run migrations...: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.2024-01-22T11:52:00::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=79231) Illegal mix of collations (utf8mb3_general_ci,COERCIBLE) and (utf8mb3_unicode_ci,COERCIBLE) for operation '=' {:toucan2/context-trace [[""execute SQL with class com.mchange.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x75b34b86 ""clojure.core$map$fn__5931$fn__5932@75b34b86""]} [""with compiled query"" {:toucan2.pipeline/compiled-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with built query"" {:toucan2.pipeline/built-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with resolved query"" {:toucan2.pipeline/resolved-query [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.result-type/*, :toucan2.pipeline/parsed-args {:connectable nil, :queryable [""UPDATE revision\n               SET object = JSON_SET(\n                   object,\n                   '$.type',\n                   CASE\n                       WHEN JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) = 'true' THEN 'model'\n                       ELSE 'question'\n                   END)\n               WHERE model = 'Card' AND JSON_UNQUOTE(JSON_EXTRACT(object, '$.dataset')) IS NOT NULL;;""]}}] [""with model"" {:toucan2.pipeline/model nil}] [""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
```

### Information about your Metabase installation

```JSON
Linux: Rocky 9.3 (on GCP VM)
Metabase Version: Latest Community Edition (downloaded 2 days ago)
Metabase Type: JAR
Java version: 21
MariaDB Version: 10.6.7 (on separate server)
MariaDB DB Type: Charset: utf8mb4 / Collation: utf8mb4_unicode_ci
```


### Severity

Prevents me from trialling it in a production environment and considering it for corporate use or investment.

### Additional context

_No response_",hgpit,2024-03-30 14:40:38+00:00,[],2025-01-23 21:00:48+00:00,2025-01-23 21:00:48+00:00,https://github.com/metabase/metabase/issues/40830,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/MySQL', None), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2028647958, 'issue_id': 2216498336, 'author': 'hgpit', 'body': 'I reviewed patch changes for 0.49.1 and 0.49.2 but nothing covered in relation to this issue.', 'created_at': datetime.datetime(2024, 3, 31, 11, 9, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2037271748, 'issue_id': 2216498336, 'author': 'paoliniluis', 'body': '@qnkhuat have you been able to reproduce this?', 'created_at': datetime.datetime(2024, 4, 4, 13, 46, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2063490350, 'issue_id': 2216498336, 'author': 'qnkhuat', 'body': ""@paoliniluis No, I haven't. I only triaged it."", 'created_at': datetime.datetime(2024, 4, 18, 9, 59, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611007564, 'issue_id': 2216498336, 'author': 'luizarakaki', 'body': 'Closing this. If we have more info, happy to reopen', 'created_at': datetime.datetime(2025, 1, 23, 21, 0, 41, tzinfo=datetime.timezone.utc)}]","hgpit (Issue Creator) on (2024-03-31 11:09:52 UTC): I reviewed patch changes for 0.49.1 and 0.49.2 but nothing covered in relation to this issue.

paoliniluis on (2024-04-04 13:46:46 UTC): @qnkhuat have you been able to reproduce this?

qnkhuat on (2024-04-18 09:59:33 UTC): @paoliniluis No, I haven't. I only triaged it.

luizarakaki on (2025-01-23 21:00:41 UTC): Closing this. If we have more info, happy to reopen

"
2216047775,issue,open,,Filter selection when downloading a PDF will come aggregated,"### Describe the bug

a sad effect of us using html2pdf is that we save the filter selection aggregated. So if you have a filter and you choose 4 values, you'll get an export of ""4 selections"" rather than the actual 4 values you chose

### To Reproduce

1) create a dashboard and add a card
2) connect the filter to a card on a field that has categories, save it
3) select 4 values on the filter
4) export as PDF, see that the export has the filters aggregated

### Expected behavior

You should get the list of the filter values

### Logs

NA

### Information about your Metabase installation

```JSON
v49
```


### Severity

P2

### Additional context

_No response_",paoliniluis,2024-03-29 22:16:16+00:00,[],2025-02-04 20:31:05+00:00,,https://github.com/metabase/metabase/issues/40829,"[('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Reporting/Export', ''), ('Difficulty:Hard', ''), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]","[{'comment_id': 2031912255, 'issue_id': 2216047775, 'author': 'paoliniluis', 'body': 'Related to https://github.com/metabase/metabase/pull/38231 cc @perivamsi and @kulyk', 'created_at': datetime.datetime(2024, 4, 2, 12, 28, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2049313886, 'issue_id': 2216047775, 'author': 'perivamsi', 'body': ""This might be hard to do and the ROI isn't there in my opinion."", 'created_at': datetime.datetime(2024, 4, 11, 9, 41, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2051036356, 'issue_id': 2216047775, 'author': 'perivamsi', 'body': ""This might be nitpicking, but I don't think this is a bug. It is a limitation of the library we use and more of a feature request."", 'created_at': datetime.datetime(2024, 4, 12, 6, 0, 31, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-04-02 12:28:02 UTC): Related to https://github.com/metabase/metabase/pull/38231 cc @perivamsi and @kulyk

perivamsi on (2024-04-11 09:41:38 UTC): This might be hard to do and the ROI isn't there in my opinion.

perivamsi on (2024-04-12 06:00:31 UTC): This might be nitpicking, but I don't think this is a bug. It is a limitation of the library we use and more of a feature request.

"
2215928366,issue,closed,completed,[dc.js migration] histogram and ordinal scales do not respect column formatting,https://github.com/metabase/metabase/assets/22608765/64437933-ee1e-4cd4-b709-58e37068ae8b,JesseSDevaney,2024-03-29 19:52:01+00:00,['JesseSDevaney'],2024-04-04 20:01:46+00:00,2024-04-04 20:01:46+00:00,https://github.com/metabase/metabase/issues/40827,"[('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2215645353,issue,open,,Feature parity for row charts: suffixes and 'multiply value by',"**Is your feature request related to a problem? Please describe.**
Suffixs and 'Multiply Value by' dont show up for row charts 

**Describe the solution you'd like**
Fix ; Display Suffixs

**Describe alternatives you've considered**
This chart cant support this 

**How important is this feature to you?**
7 / 10 (good to have ; not critical ; however percentages are hard to display with this bc you have to multiply the value by 100 for it to show up correctly but if you hover over the data value it shows 900 % instead of 9 %)

**Additional context**
Add any other context or screenshots about the feature request here.

<img width=""1423"" alt=""Screenshot 2024-03-29 at 12 16 45 PM"" src=""https://github.com/metabase/metabase/assets/121153315/92ee92d3-bb4f-41f7-9812-d045d7922e8e"">

",OdinTallBeard,2024-03-29 16:19:21+00:00,[],2025-02-04 20:31:21+00:00,,https://github.com/metabase/metabase/issues/40819,"[('Type:New Feature', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2215594432,issue,open,,Aliases in GUI builder for multi-join fields to minimize confusion when selecting field for aggregation,"**Is your feature request related to a problem? Please describe.**
We have a customer that would like to be able to see aliases or some kind of identifier when joining to the same table multiple times in GUI builder. In the example they provided, they‚Äôre connecting on different fields.


**Describe the solution you'd like**
An identifier or alias of some sort within the GUI builder to mitigate confusion.
<img width=""995"" alt=""feature_request_1"" src=""https://github.com/metabase/metabase/assets/17398657/ec8b69d8-f4cb-4ba0-9c1c-840b55ae001b"">


**How important is this feature to you?**
They have end-users that would like to minimize confusion when queries are more complicated than the example I provided.

",FilmonK,2024-03-29 15:43:00+00:00,[],2024-04-26 19:21:00+00:00,,https://github.com/metabase/metabase/issues/40816,"[('Type:New Feature', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]",[],
2215593406,issue,closed,completed,Public dashboards no longer allow titled=false in url parameters (only allows true),"### Describe the bug

example:
https://metabase.company.com/public/dashboard/32c37b38-318a-4321-b142-99098kii89#theme=transparent&bordered=false&titled=false <- will load the page but the data will never populate, just spinning loader for every widget.

https://metabase.company.com/public/dashboard/32c37b38-318a-4321-b142-99098kii89#theme=transparent&bordered=false&titled=true <- everything loads just as it should except now has ugly title on the page.

this is happening directly after upgrading to v0.49.2 from v0.49.1

this seems to only apply to the title parameter, all the other params seem to still works as normal.

example:
#theme=transparent&bordered=false&titled=false <- FAILS
#theme=transparent&bordered=false&titled=true <- WORKS
#theme=transparent&bordered=false <-WORKS
#theme=transparent&bordered=true <- WORKS
#titled=false <-FAILS
#titled=true <- WORKS

### To Reproduce

happens when sharing any dashboard and attempting to hide the title of the dashboard by embedding via simple iframe or directly accessing the shared url with the parameters set as follows:
#theme=transparent&bordered=false&titled=false

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu222.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu222.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-92-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/Detroit""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.11.6-MariaDB-1:10.11.6+maria~ubu2204""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High / Breaking

### Additional context

_No response_",bharlettvista,2024-03-29 15:42:08+00:00,['ranquild'],2024-04-01 11:31:18+00:00,2024-04-01 11:31:18+00:00,https://github.com/metabase/metabase/issues/40815,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Frontend', '')]","[{'comment_id': 2027465024, 'issue_id': 2215593406, 'author': 'deniskaber', 'body': ""Hello @bharlettvista ! \r\n\r\nThank you for reporting the issue. \r\nI tried to reproduce this issue in different ways, but didn't manage to achieve results - dashboard loads without any errors even if I pass `titled=false`.\r\n\r\nCould you please double-check the full list of URL parameters you pass to a dashboard and send them to us. Also, could you please check if any console errors happen if you would pass `titled=false` ?\r\n\r\nThank you!"", 'created_at': datetime.datetime(2024, 3, 29, 16, 37, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027481948, 'issue_id': 2215593406, 'author': 'bharlettvista', 'body': ""Hi!,\r\n\r\nthe only parameters we are passing are: #theme=transparent&bordered=false&titled=false\r\nwhen titled=false is passed, the widgets are loaded but there is no data just the loading spinner forever\r\n\r\nits strange, when we pass the titled=false param there are no console errors, but also there are less 'files' pulled in via the (chrome dev console) Networking page....\r\n\r\nexample Networking tab when titled=false:\r\n![Screenshot 2024-03-29 at 12 52 24\u202fPM](https://github.com/metabase/metabase/assets/97744345/d9b16d0b-640d-4f17-a4f5-e0e4fbbc844d)\r\n\r\nexample Netwokring tab when titled is not passed in the URL, and all the data loads properly:\r\n![Screenshot 2024-03-29 at 12 53 39\u202fPM](https://github.com/metabase/metabase/assets/97744345/4858ad65-99e1-4e33-944b-e6ebb4899fdb)"", 'created_at': datetime.datetime(2024, 3, 29, 16, 54, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029619304, 'issue_id': 2215593406, 'author': 'ranquild', 'body': 'Fixed by https://github.com/metabase/metabase/pull/40836', 'created_at': datetime.datetime(2024, 4, 1, 11, 31, 18, tzinfo=datetime.timezone.utc)}]","deniskaber on (2024-03-29 16:37:10 UTC): Hello @bharlettvista ! 

Thank you for reporting the issue. 
I tried to reproduce this issue in different ways, but didn't manage to achieve results - dashboard loads without any errors even if I pass `titled=false`.

Could you please double-check the full list of URL parameters you pass to a dashboard and send them to us. Also, could you please check if any console errors happen if you would pass `titled=false` ?

Thank you!

bharlettvista (Issue Creator) on (2024-03-29 16:54:36 UTC): Hi!,

the only parameters we are passing are: #theme=transparent&bordered=false&titled=false
when titled=false is passed, the widgets are loaded but there is no data just the loading spinner forever

its strange, when we pass the titled=false param there are no console errors, but also there are less 'files' pulled in via the (chrome dev console) Networking page....

example Networking tab when titled=false:
![Screenshot 2024-03-29 at 12 52 24‚ÄØPM](https://github.com/metabase/metabase/assets/97744345/d9b16d0b-640d-4f17-a4f5-e0e4fbbc844d)

example Netwokring tab when titled is not passed in the URL, and all the data loads properly:
![Screenshot 2024-03-29 at 12 53 39‚ÄØPM](https://github.com/metabase/metabase/assets/97744345/4858ad65-99e1-4e33-944b-e6ebb4899fdb)

ranquild (Assginee) on (2024-04-01 11:31:18 UTC): Fixed by https://github.com/metabase/metabase/pull/40836

"
2215553016,issue,closed,completed,users,,ranquild,2024-03-29 15:12:04+00:00,['nemanjaglumac'],2024-04-16 15:48:06+00:00,2024-04-16 15:48:06+00:00,https://github.com/metabase/metabase/issues/40812,[],[],
2215552943,issue,closed,completed,timelines,,ranquild,2024-03-29 15:12:00+00:00,['ranquild'],2024-04-08 10:12:45+00:00,2024-04-08 10:12:45+00:00,https://github.com/metabase/metabase/issues/40811,[],[],
2215552853,issue,closed,completed,timeline-events,,ranquild,2024-03-29 15:11:55+00:00,['ranquild'],2024-04-08 10:12:45+00:00,2024-04-08 10:12:45+00:00,https://github.com/metabase/metabase/issues/40810,[],[],
2215552758,issue,closed,completed,tasks,,ranquild,2024-03-29 15:11:51+00:00,['nemanjaglumac'],2024-04-19 00:54:06+00:00,2024-04-19 00:54:05+00:00,https://github.com/metabase/metabase/issues/40809,[],[],
2215552611,issue,closed,completed,tables,,ranquild,2024-03-29 15:11:47+00:00,['ranquild'],2024-03-29 15:14:33+00:00,2024-03-29 15:14:33+00:00,https://github.com/metabase/metabase/issues/40808,[],"[{'comment_id': 2027369973, 'issue_id': 2215552611, 'author': 'ranquild', 'body': 'Closed by https://github.com/metabase/metabase/pull/40701', 'created_at': datetime.datetime(2024, 3, 29, 15, 14, 33, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-03-29 15:14:33 UTC): Closed by https://github.com/metabase/metabase/pull/40701

"
2215552503,issue,closed,completed,snippets,,ranquild,2024-03-29 15:11:42+00:00,['nemanjaglumac'],2024-04-22 13:30:52+00:00,2024-04-22 13:30:52+00:00,https://github.com/metabase/metabase/issues/40807,[],[],
2215552423,issue,closed,completed,snippet-collections,,ranquild,2024-03-29 15:11:38+00:00,['nemanjaglumac'],2024-04-29 19:29:44+00:00,2024-04-29 19:29:43+00:00,https://github.com/metabase/metabase/issues/40806,[],"[{'comment_id': 2083505822, 'issue_id': 2215552423, 'author': 'nemanjaglumac', 'body': 'Resolved by https://github.com/metabase/metabase/pull/41825', 'created_at': datetime.datetime(2024, 4, 29, 19, 29, 44, tzinfo=datetime.timezone.utc)}]","nemanjaglumac (Assginee) on (2024-04-29 19:29:44 UTC): Resolved by https://github.com/metabase/metabase/pull/41825

"
2215552318,issue,closed,completed,segments,,ranquild,2024-03-29 15:11:33+00:00,['ranquild'],2024-04-02 11:41:58+00:00,2024-04-02 11:41:58+00:00,https://github.com/metabase/metabase/issues/40805,[],[],
2215552246,issue,closed,completed,search,,ranquild,2024-03-29 15:11:29+00:00,['ranquild'],2024-04-08 10:11:59+00:00,2024-04-08 10:11:59+00:00,https://github.com/metabase/metabase/issues/40804,[],[],
2215552162,issue,closed,completed,schemas,,ranquild,2024-03-29 15:11:25+00:00,['ranquild'],2024-04-02 11:41:57+00:00,2024-04-02 11:41:57+00:00,https://github.com/metabase/metabase/issues/40803,[],[],
2215552074,issue,closed,completed,revisions,,ranquild,2024-03-29 15:11:21+00:00,['nemanjaglumac'],2024-04-22 07:11:03+00:00,2024-04-22 07:11:03+00:00,https://github.com/metabase/metabase/issues/40802,[],[],
2215551975,issue,closed,completed,recent-items,,ranquild,2024-03-29 15:11:16+00:00,['ranquild'],2024-04-09 13:10:53+00:00,2024-04-09 13:10:53+00:00,https://github.com/metabase/metabase/issues/40801,[],[],
2215551498,issue,closed,completed,questions,,ranquild,2024-03-29 15:10:53+00:00,['ranquild'],2024-04-04 13:15:52+00:00,2024-04-04 13:15:52+00:00,https://github.com/metabase/metabase/issues/40800,[],[],
2215551436,issue,closed,completed,pulses,,ranquild,2024-03-29 15:10:50+00:00,['nemanjaglumac'],2024-04-25 10:54:47+00:00,2024-04-25 10:54:47+00:00,https://github.com/metabase/metabase/issues/40799,[],[],
2215551346,issue,closed,completed,popular-items,,ranquild,2024-03-29 15:10:46+00:00,['ranquild'],2024-04-09 13:10:54+00:00,2024-04-09 13:10:54+00:00,https://github.com/metabase/metabase/issues/40798,[],[],
2215551261,issue,closed,completed,persisted-models,,ranquild,2024-03-29 15:10:42+00:00,['nemanjaglumac'],2024-04-24 12:43:10+00:00,2024-04-24 12:43:10+00:00,https://github.com/metabase/metabase/issues/40797,[],[],
2215551166,issue,closed,completed,metrics,,ranquild,2024-03-29 15:10:37+00:00,['ranquild'],2024-04-02 15:36:42+00:00,2024-04-02 15:36:42+00:00,https://github.com/metabase/metabase/issues/40796,[],[],
2215551044,issue,closed,completed,groups,,ranquild,2024-03-29 15:10:32+00:00,['nemanjaglumac'],2024-04-19 14:28:50+00:00,2024-04-19 14:28:50+00:00,https://github.com/metabase/metabase/issues/40795,[],[],
2215550936,issue,closed,completed,fields,,ranquild,2024-03-29 15:10:27+00:00,['ranquild'],2024-03-29 15:14:26+00:00,2024-03-29 15:14:25+00:00,https://github.com/metabase/metabase/issues/40794,[],"[{'comment_id': 2027369861, 'issue_id': 2215550936, 'author': 'ranquild', 'body': 'Closed by https://github.com/metabase/metabase/pull/40701', 'created_at': datetime.datetime(2024, 3, 29, 15, 14, 25, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-03-29 15:14:25 UTC): Closed by https://github.com/metabase/metabase/pull/40701

"
2215550824,issue,closed,completed,databases,,ranquild,2024-03-29 15:10:22+00:00,['ranquild'],2024-03-29 15:14:17+00:00,2024-03-29 15:14:16+00:00,https://github.com/metabase/metabase/issues/40793,[],"[{'comment_id': 2027369725, 'issue_id': 2215550824, 'author': 'ranquild', 'body': 'Closed by https://github.com/metabase/metabase/pull/40701', 'created_at': datetime.datetime(2024, 3, 29, 15, 14, 16, tzinfo=datetime.timezone.utc)}]","ranquild (Issue Creator) on (2024-03-29 15:14:16 UTC): Closed by https://github.com/metabase/metabase/pull/40701

"
2215550761,issue,closed,completed,database-candidates,,ranquild,2024-03-29 15:10:19+00:00,['iethree'],2024-04-02 16:49:48+00:00,2024-04-02 16:49:48+00:00,https://github.com/metabase/metabase/issues/40792,[],[],
2215550665,issue,closed,completed,dashboards,,ranquild,2024-03-29 15:10:15+00:00,['kamilmielnik'],2024-04-18 07:17:57+00:00,2024-04-17 22:40:25+00:00,https://github.com/metabase/metabase/issues/40791,[],[],
2215550575,issue,closed,completed,bookmarks,,ranquild,2024-03-29 15:10:11+00:00,['ranquild'],2024-04-09 13:10:54+00:00,2024-04-09 13:10:54+00:00,https://github.com/metabase/metabase/issues/40790,[],[],
2215550463,issue,closed,completed,alerts,,ranquild,2024-03-29 15:10:05+00:00,['ranquild'],2024-04-11 13:02:43+00:00,2024-04-11 12:49:19+00:00,https://github.com/metabase/metabase/issues/40789,[],[],
2215550010,issue,open,,[Epic] Migrate (entities) to RTK Query,"Make the entity framework use RTK query under the hood for all API requests.

# Entities

```[tasklist]
## Milestone 1 - replace api handlers in entities
- [ ] https://github.com/metabase/metabase/issues/40789
- [ ] https://github.com/metabase/metabase/issues/40790
- [ ] https://github.com/metabase/metabase/issues/41818
- [ ] https://github.com/metabase/metabase/issues/40791
- [ ] https://github.com/metabase/metabase/issues/40792
- [ ] https://github.com/metabase/metabase/issues/40793
- [ ] https://github.com/metabase/metabase/issues/40794
- [ ] https://github.com/metabase/metabase/issues/40795
- [ ] https://github.com/metabase/metabase/issues/40796
- [ ] https://github.com/metabase/metabase/issues/40797
- [ ] https://github.com/metabase/metabase/issues/40798
- [ ] https://github.com/metabase/metabase/issues/40799
- [ ] https://github.com/metabase/metabase/issues/40800
- [ ] https://github.com/metabase/metabase/issues/40801
- [ ] https://github.com/metabase/metabase/issues/40802
- [ ] https://github.com/metabase/metabase/issues/40803
- [ ] https://github.com/metabase/metabase/issues/40804
- [ ] https://github.com/metabase/metabase/issues/40805
- [ ] https://github.com/metabase/metabase/issues/40806
- [ ] https://github.com/metabase/metabase/issues/40807
- [ ] https://github.com/metabase/metabase/issues/40808
- [ ] https://github.com/metabase/metabase/issues/40809
- [ ] https://github.com/metabase/metabase/issues/40810
- [ ] https://github.com/metabase/metabase/issues/40811
- [ ] https://github.com/metabase/metabase/issues/40812
- [ ] https://github.com/metabase/metabase/pull/41622
- [ ] https://github.com/metabase/metabase/issues/41467
- [ ] https://github.com/metabase/metabase/issues/42503
```

```[tasklist]
## Milestone 2 - use RTK query instead of entity loaders
- [x] https://github.com/metabase/metabase/issues/44301
- [ ] https://github.com/metabase/metabase/issues/50317
- [ ] https://github.com/metabase/metabase/issues/43630
- [ ] alerts
- [ ] bookmarks
- [ ] dashboards
- [ ] database-candidates
- [ ] databases
- [ ] fields
- [ ] groups
- [ ] metrics
- [ ] persisted-models
- [ ] https://github.com/metabase/metabase/issues/41845
- [ ] pulses
- [ ] questions
- [ ] https://github.com/metabase/metabase/issues/41844
- [ ] revisions
- [ ] schemas
- [ ] search
- [ ] segments
- [ ] snippet-collections
- [ ] snippets
- [ ] tables
- [ ] https://github.com/metabase/metabase/issues/41580
- [ ] timeline-events
- [ ] timelines
- [ ] users
```
```[tasklist]
### Followups
- [ ] https://github.com/metabase/metabase/issues/41511
```

# Other endpoints
```[tasklist]
## Milestone 3
- [ ] services.js
```

",ranquild,2024-03-29 15:09:44+00:00,"['kamilmielnik', 'ranquild', 'iethree', 'nemanjaglumac']",2025-02-04 20:29:51+00:00,,https://github.com/metabase/metabase/issues/40788,"[('Type:Tech Debt', 'or Refactoring'), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2215541860,issue,closed,completed,[PIVOT TABLES] Front-end bug that scrolling bar end but has the row totals not showing,"### Describe the bug

When the pivot table has lots of rows, scrolling down to the end of table not shows the totals, one of the main use of pivot tables
![Screenshot from 2024-03-29 11-56-41](https://github.com/metabase/metabase/assets/6808348/32cd8669-b927-4125-85af-7e61d5baf9b6)


### To Reproduce

1. Create a pivot table lots of rows that need scrolling bar
2. Scroll to the end of the table



### Expected behavior

Show the entire table

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""pt-BR"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""19+36"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""19"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""19+36"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-26-cloud-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""clickhouse"",
      ""mysql"",
      ""postgres"",
      ""cubejs"",
      ""sqlserver"",
      ""googleanalytics"",
      ""athena"",
      ""bigquery-cloud-sdk"",
      ""mongo"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-22"",
      ""tag"": ""v0.48.7"",
      ""hash"": ""c192db1""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",dannyeuu,2024-03-29 15:03:17+00:00,[],2024-07-19 15:26:56+00:00,2024-07-18 22:20:28+00:00,https://github.com/metabase/metabase/issues/40787,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2170931660, 'issue_id': 2215541860, 'author': 'linucksrox', 'body': 'Every time I update I hope this has been fixed, but so far no dice. My workaround is toggling table view on and then back off (the button in the bottom center) and then it works as expected, just not on a fresh page load.', 'created_at': datetime.datetime(2024, 6, 15, 21, 52, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2237719333, 'issue_id': 2215541860, 'author': 'EmmadUsmani', 'body': ""@dannyeuu @linucksrox This was likely fixed by https://github.com/metabase/metabase/pull/44514, as I'm no longer able to reproduce it in master, see the comparison below. You should no longer experience this issue after upgrading to the latest v50 minor release.\r\n\r\n**48.2**\r\n\r\nhttps://github.com/user-attachments/assets/a2a3885d-fc96-49ae-9472-a87871be5322\r\n\r\n**master (commit df2d409)**\r\n\r\nhttps://github.com/user-attachments/assets/2afa9eb8-1667-4a77-81be-f037e78a51e8"", 'created_at': datetime.datetime(2024, 7, 18, 22, 20, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2237771176, 'issue_id': 2215541860, 'author': 'dannyeuu', 'body': 'Great! Thanks!', 'created_at': datetime.datetime(2024, 7, 18, 23, 26, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2237788029, 'issue_id': 2215541860, 'author': 'linucksrox', 'body': ""Thanks! Looks like it's fixed for me on the latest version."", 'created_at': datetime.datetime(2024, 7, 18, 23, 53, 54, tzinfo=datetime.timezone.utc)}]","linucksrox on (2024-06-15 21:52:28 UTC): Every time I update I hope this has been fixed, but so far no dice. My workaround is toggling table view on and then back off (the button in the bottom center) and then it works as expected, just not on a fresh page load.

EmmadUsmani on (2024-07-18 22:20:28 UTC): @dannyeuu @linucksrox This was likely fixed by https://github.com/metabase/metabase/pull/44514, as I'm no longer able to reproduce it in master, see the comparison below. You should no longer experience this issue after upgrading to the latest v50 minor release.

**48.2**

https://github.com/user-attachments/assets/a2a3885d-fc96-49ae-9472-a87871be5322

**master (commit df2d409)**

https://github.com/user-attachments/assets/2afa9eb8-1667-4a77-81be-f037e78a51e8

dannyeuu (Issue Creator) on (2024-07-18 23:26:43 UTC): Great! Thanks!

linucksrox on (2024-07-18 23:53:54 UTC): Thanks! Looks like it's fixed for me on the latest version.

"
2215344718,issue,closed,completed,EntityPicker incorrectly calculates paths for nested child collections of other users' personal collections,"Not a very common user path, but a very incorrect display is possible. ü•¥

![subcollection other user bug](https://github.com/metabase/metabase/assets/30528226/6eaebf80-c259-482c-b40f-fa6149ace4c8)
",iethree,2024-03-29 13:23:47+00:00,['iethree'],2024-04-01 14:04:38+00:00,2024-04-01 14:04:38+00:00,https://github.com/metabase/metabase/issues/40776,"[('Type:Bug', 'Product defects')]",[],
2215137610,issue,closed,completed,Date Filter is passing in +05:30 hr fomat instead normal date,"### Describe the bug

When user select date in the metabase filter it should pass as normal date like if they pass 29-03-2025 it should fetch records that satisfy that date But Metabase passing it as ""2024-03-27 18:30:00+05:30"" when date is compared it is showing 1 day before data
![date](https://github.com/metabase/metabase/assets/66297271/d514313b-f9ed-4b26-a469-23b49e0d810e)


### To Reproduce

1. Go to 'metabase SQL query'
2. Click on 'write query with some date make sure that date has some unwated prefix'
3. See error


### Expected behavior

It should pass date as what date we pass in filter 

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 0.49.2
- Chome Version 122.0.6261.111 (Official Build) (64-bit)
```


### Severity

User want report now itself 

### Additional context

_No response_",Ravi9535,2024-03-29 11:08:10+00:00,['camsaul'],2024-07-02 23:06:47+00:00,2024-07-02 22:19:46+00:00,https://github.com/metabase/metabase/issues/40775,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Processor', ''), ('.Backend', ''), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2027091230, 'issue_id': 2215137610, 'author': 'paoliniluis', 'body': ""What's your Metabase reporting timezone?"", 'created_at': datetime.datetime(2024, 3, 29, 11, 12, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027149836, 'issue_id': 2215137610, 'author': 'Ravi9535', 'body': 'Actually we use 2 database and the time zone in metabase is **Asia/Culcutta**\r\n1.Mysql \r\nhere in DB we are using +05:30 hr format\r\n2.Amazon redsshift\r\nHere we are storing the the date as it is not in +05:30 Hr format\r\n\r\nSo when I select 2024-03-29 it will check for 2024-03-28 18:30:00+05:30', 'created_at': datetime.datetime(2024, 3, 29, 11, 53, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027301367, 'issue_id': 2215137610, 'author': 'ranquild', 'body': 'The FE sends the correct parameter value (just the date). Should be a BE issue', 'created_at': datetime.datetime(2024, 3, 29, 14, 11, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2037300520, 'issue_id': 2215137610, 'author': 'paoliniluis', 'body': 'I ""think"" that the problem is that the error returned is wrong. The issue here is that Redshift does not seem to like a date + an integer\r\n![image](https://github.com/metabase/metabase/assets/1711649/e5ab2bb3-bdcc-4601-a2cd-ed6cc8deb955)', 'created_at': datetime.datetime(2024, 4, 4, 14, 0, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2204482076, 'issue_id': 2215137610, 'author': 'camsaul', 'body': ""So believe it or not,\r\n\r\n```sql\r\nSELECT date '2024-07-02' + 1\r\n```\r\n\r\nactually does work in Redshift (and Postgres), it seems to be sorta like\r\n\r\n```sql\r\nSELECT date '2024-07-02' + interval '1 day'\r\n```\r\n\r\naltho `date + int` returns a `date` while `date + interval` returns a `timestamp`.\r\n\r\nPrior to 0.49.8 for Redshift we generated parameterized SQL for dates, e.g. `? + 1`, leading to the syntax error, but now we generate inline `date '...'` literals.\r\n\r\nThis was fixed in 0.49.8 in #41864.\r\n\r\n![image](https://github.com/metabase/metabase/assets/1455846/50904ea7-8ebd-4b33-912a-44ab4a24bf06)"", 'created_at': datetime.datetime(2024, 7, 2, 21, 30, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2204641036, 'issue_id': 2215137610, 'author': 'github-actions[bot]', 'body': 'üöÄ This should also be released by [v0.50.10](https://github.com/metabase/metabase/milestone/249)', 'created_at': datetime.datetime(2024, 7, 2, 23, 6, 47, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-29 11:12:47 UTC): What's your Metabase reporting timezone?

Ravi9535 (Issue Creator) on (2024-03-29 11:53:33 UTC): Actually we use 2 database and the time zone in metabase is **Asia/Culcutta**
1.Mysql 
here in DB we are using +05:30 hr format
2.Amazon redsshift
Here we are storing the the date as it is not in +05:30 Hr format

So when I select 2024-03-29 it will check for 2024-03-28 18:30:00+05:30

ranquild on (2024-03-29 14:11:49 UTC): The FE sends the correct parameter value (just the date). Should be a BE issue

paoliniluis on (2024-04-04 14:00:53 UTC): I ""think"" that the problem is that the error returned is wrong. The issue here is that Redshift does not seem to like a date + an integer
![image](https://github.com/metabase/metabase/assets/1711649/e5ab2bb3-bdcc-4601-a2cd-ed6cc8deb955)

camsaul (Assginee) on (2024-07-02 21:30:21 UTC): So believe it or not,

```sql
SELECT date '2024-07-02' + 1
```

actually does work in Redshift (and Postgres), it seems to be sorta like

```sql
SELECT date '2024-07-02' + interval '1 day'
```

altho `date + int` returns a `date` while `date + interval` returns a `timestamp`.

Prior to 0.49.8 for Redshift we generated parameterized SQL for dates, e.g. `? + 1`, leading to the syntax error, but now we generate inline `date '...'` literals.

This was fixed in 0.49.8 in #41864.

![image](https://github.com/metabase/metabase/assets/1455846/50904ea7-8ebd-4b33-912a-44ab4a24bf06)

github-actions[bot] on (2024-07-02 23:06:47 UTC): üöÄ This should also be released by [v0.50.10](https://github.com/metabase/metabase/milestone/249)

"
2215083793,issue,closed,completed,[49.1] impossible to filter on IDs identified as Identity key (PK),"### Describe the bug

impossible to filter on IDs identified as Identity key (PK)
![image](https://github.com/metabase/metabase/assets/22106329/0be9f5c8-e6dc-485b-9063-b7e99105d288)


### To Reproduce

1. Go to a collection with a field set as Primary key by Metabase discovery
2. Click on filters
3. Scroll down to ID
4. See error


### Expected behavior

Filtering on IDs should be possible

### Logs

_No response_

### Information about your Metabase installation

```JSON
image: metabase/metabase:v0.49.1
MB_DB_TYPE: mysql
```


### Severity

Low

### Additional context

_No response_",kevbarns,2024-03-29 10:27:49+00:00,['uladzimirdev'],2024-05-08 19:54:41+00:00,2024-05-01 15:14:02+00:00,https://github.com/metabase/metabase/issues/40770,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.')]","[{'comment_id': 2027041734, 'issue_id': 2215083793, 'author': 'ranquild', 'body': '@kevbarns what is the database type for these columns?', 'created_at': datetime.datetime(2024, 3, 29, 10, 29, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027046809, 'issue_id': 2215083793, 'author': 'kevbarns', 'body': ""@ranquild it's a mongoDB database"", 'created_at': datetime.datetime(2024, 3, 29, 10, 34, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027129341, 'issue_id': 2215083793, 'author': 'paoliniluis', 'body': 'is the Id an UUID right?', 'created_at': datetime.datetime(2024, 3, 29, 11, 46, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027129499, 'issue_id': 2215083793, 'author': 'paoliniluis', 'body': 'probably the same as https://github.com/metabase/metabase/issues/40176?', 'created_at': datetime.datetime(2024, 3, 29, 11, 47, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027434207, 'issue_id': 2215083793, 'author': 'kevbarns', 'body': 'yes it is, thanks @paoliniluis', 'created_at': datetime.datetime(2024, 3, 29, 16, 11, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029400443, 'issue_id': 2215083793, 'author': 'uladzimirdev', 'body': ""Hey @kevbarns. FYI #40176 is fixed, but you'll need to wait for 0.49.3 to be released. Feel free to reopen this issue with more details if it's still an issue in 0.49.3"", 'created_at': datetime.datetime(2024, 4, 1, 8, 30, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2059274050, 'issue_id': 2215083793, 'author': 'kevbarns', 'body': ""hello @uladzimirdev , after updating to 0.49.5 I'm still having the issue."", 'created_at': datetime.datetime(2024, 4, 16, 14, 46, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2059338281, 'issue_id': 2215083793, 'author': 'uladzimirdev', 'body': '@kevbarns it would be helpful if you could record a small repro video as we have a test for initial problem and it passes, we might miss something specific in your case', 'created_at': datetime.datetime(2024, 4, 16, 15, 14, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2060957380, 'issue_id': 2215083793, 'author': 'kevbarns', 'body': 'hello @uladzimirdev, here is a loom video : https://www.loom.com/share/1e446df025a041e39420bc50d0ae77e5?sid=941cb337-4ab8-418b-a9d7-933d92c6a0c7\r\n- When visualizing a dataset, clicking on the field arrow set as Primary key by metabase discovery, filter button does not work\r\n- When visualizing a dataset, clicking on the filter button with the list of fields available, the field set as Primary key cannot be filtered (as shown in my screenshot above). \r\n- When changing the field type in the admin panel as entity name for example, filtering is available.', 'created_at': datetime.datetime(2024, 4, 17, 10, 39, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2076656066, 'issue_id': 2215083793, 'author': 'kevbarns', 'body': '@uladzimirdev is there a documentation/scripts available to rollback from `0.49.5` to `0.47.8` ? We also notice discrepancies with numbers when looked at from different filter settings.', 'created_at': datetime.datetime(2024, 4, 25, 8, 32, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2076776399, 'issue_id': 2215083793, 'author': 'paoliniluis', 'body': '@kevbarns you need to move to the latest version first and then do a ""migrate down"" https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase\r\n\r\nPlease move to 48 if possible, don\'t go that far in the past', 'created_at': datetime.datetime(2024, 4, 25, 9, 38, 41, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-03-29 10:29:34 UTC): @kevbarns what is the database type for these columns?

kevbarns (Issue Creator) on (2024-03-29 10:34:35 UTC): @ranquild it's a mongoDB database

paoliniluis on (2024-03-29 11:46:59 UTC): is the Id an UUID right?

paoliniluis on (2024-03-29 11:47:11 UTC): probably the same as https://github.com/metabase/metabase/issues/40176?

kevbarns (Issue Creator) on (2024-03-29 16:11:41 UTC): yes it is, thanks @paoliniluis

uladzimirdev (Assginee) on (2024-04-01 08:30:03 UTC): Hey @kevbarns. FYI #40176 is fixed, but you'll need to wait for 0.49.3 to be released. Feel free to reopen this issue with more details if it's still an issue in 0.49.3

kevbarns (Issue Creator) on (2024-04-16 14:46:02 UTC): hello @uladzimirdev , after updating to 0.49.5 I'm still having the issue.

uladzimirdev (Assginee) on (2024-04-16 15:14:47 UTC): @kevbarns it would be helpful if you could record a small repro video as we have a test for initial problem and it passes, we might miss something specific in your case

kevbarns (Issue Creator) on (2024-04-17 10:39:08 UTC): hello @uladzimirdev, here is a loom video : https://www.loom.com/share/1e446df025a041e39420bc50d0ae77e5?sid=941cb337-4ab8-418b-a9d7-933d92c6a0c7
- When visualizing a dataset, clicking on the field arrow set as Primary key by metabase discovery, filter button does not work
- When visualizing a dataset, clicking on the filter button with the list of fields available, the field set as Primary key cannot be filtered (as shown in my screenshot above). 
- When changing the field type in the admin panel as entity name for example, filtering is available.

kevbarns (Issue Creator) on (2024-04-25 08:32:46 UTC): @uladzimirdev is there a documentation/scripts available to rollback from `0.49.5` to `0.47.8` ? We also notice discrepancies with numbers when looked at from different filter settings.

paoliniluis on (2024-04-25 09:38:41 UTC): @kevbarns you need to move to the latest version first and then do a ""migrate down"" https://www.metabase.com/docs/latest/installation-and-operation/upgrading-metabase

Please move to 48 if possible, don't go that far in the past

"
2214769175,issue,closed,completed,Failed to save changes to the existing report/SQL query after latest version updation,"### Describe the bug

We have updated the Metabase to it's latest version currently 0.49.2 as on Mar-29-2024 now when we do some changes to the reports which are already saved in metabase we can't save changes to report once again.

### To Reproduce

1. Go to 'metabase'
2. Click on 'NEW - > SQL QUERY -> Select Database and write a query, run and save'
3. Now after save, do some changes to the same query and try to save the same query once again
4. It will show failed when you click on save (replace original question)

![about metabase](https://github.com/metabase/metabase/assets/66297271/15588594-3b2b-48f0-a740-725d697f1948)
![failed](https://github.com/metabase/metabase/assets/66297271/47dea86a-bb64-4409-9004-12723f1d9668)


### Expected behavior

It should allow us to edit and save as many times as earlier

### Logs

_No response_

### Information about your Metabase installation

```JSON
- METABASE 0.49.2
- CHROME Version 122.0.6261.111 (Official Build) (64-bit)
```


### Severity

Since this is last month of financial year we need some of the import information using reports

### Additional context

_No response_",Ravi9535,2024-03-29 06:42:29+00:00,[],2024-10-18 07:40:28+00:00,2024-06-06 19:46:47+00:00,https://github.com/metabase/metabase/issues/40769,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Needs Clarification', 'Issue is incomplete or missing actionable information.')]","[{'comment_id': 2026765437, 'issue_id': 2214769175, 'author': 'ranquild', 'body': '@Ravi9535 could you provide the logs? there should be an error when saving the question failed', 'created_at': datetime.datetime(2024, 3, 29, 6, 48, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026806986, 'issue_id': 2214769175, 'author': 'Ravi9535', 'body': 'Hi @ranquild , Since many users are using the saved reports the log is too much and it is running. So what exactly should I share regarding that log', 'created_at': datetime.datetime(2024, 3, 29, 7, 30, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026847941, 'issue_id': 2214769175, 'author': 'paoliniluis', 'body': '@Ravi9535 we need to see what happens in the server and in your browser when you click on save', 'created_at': datetime.datetime(2024, 3, 29, 8, 12, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026958431, 'issue_id': 2214769175, 'author': 'Ravi9535', 'body': 'When I click on save and it got failed.\r\nHere is the Log\r\n[log.log](https://github.com/metabase/metabase/files/14802373/log.log)', 'created_at': datetime.datetime(2024, 3, 29, 9, 44, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027101281, 'issue_id': 2214769175, 'author': 'paoliniluis', 'body': 'Are you using MySQL as the application database? Which version?', 'created_at': datetime.datetime(2024, 3, 29, 11, 22, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027135358, 'issue_id': 2214769175, 'author': 'Ravi9535', 'body': 'Yes,\r\nmysql  Ver 14.14 Distrib 5.7.42, for Linux (x86_64) using  EditLine wrapper', 'created_at': datetime.datetime(2024, 3, 29, 11, 48, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101938656, 'issue_id': 2214769175, 'author': 'ssshreyans26', 'body': '@ranquild @paoliniluis Is this issue resolved in the latest version of metabase community? If not is there a temporary patch/fix that we can apply or do we need to revert to previous version?', 'created_at': datetime.datetime(2024, 5, 9, 5, 1, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2101982652, 'issue_id': 2214769175, 'author': 'scykie', 'body': 'hi guys,\r\nhaving same issue while trying to replace the existing query, did anyone find any solution for this ?, when will this issue be fixed ????', 'created_at': datetime.datetime(2024, 5, 9, 5, 46, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2147495072, 'issue_id': 2214769175, 'author': 'nemanjaglumac', 'body': '@Ravi9535 @Ninx96 we\'re trying to reproduce the issue but it\'s hard with the very limited information that\'s available to us. For example:\r\n> Click on \'NEW - > SQL QUERY -> Select Database and write a query, run and save\'\r\n\r\nThis doesn\'t really tells me much, because the ""query"" can be `select 1` or it can be really complex with a lot of parameters. Looking at the logs, it seems that this query had at least one parameter marked as required.\r\n\r\nCan you confirm that?\r\nIf yes, can you try either:\r\n1. Marking it as not required or\r\n2. Giving the required filter/parameter the default value\r\n\r\nLet me know if that helps.', 'created_at': datetime.datetime(2024, 6, 4, 13, 8, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2148940587, 'issue_id': 2214769175, 'author': 'scykie', 'body': 'hi @nemanjaglumac \r\n\r\nyou can reproduce the issue by following the steps:\r\n\r\n1. try to run & save a native query to any connected sql database (can be as simple as ""select 1"")\r\n2. Once it is saved try to edit the same saved question (for example ""select 2"")\r\n3. when the save Question popup opens up select ""Replace original question"" and try to save it \r\n4. it will get failed \r\n\r\n\r\nlogs saying:\r\n\r\n[9344d828-2654-460a-9612-26e7477ea086] 2024-06-05T11:22:41+05:30 DEBUG metabase.server.middleware.log PUT /api/card/1005 400 2.7 ms (0 DB calls) \r\n{:errors {:collection_preview ""nullable boolean""},\r\n :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}', 'created_at': datetime.datetime(2024, 6, 5, 6, 4, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150259312, 'issue_id': 2214769175, 'author': 'nemanjaglumac', 'body': 'This error is completely different from the original one that @Ravi9535 attached.\r\n\r\n@Ninx96 are all these steps on the same version (if yes - which one?)? Or do you save an original question in one version (which one?) and then upgrade to some other version (which one?)?', 'created_at': datetime.datetime(2024, 6, 5, 14, 48, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150362544, 'issue_id': 2214769175, 'author': 'scykie', 'body': ""@nemanjaglumac all these steps are performed in the exact same version (0.49.8) currently.\n\n\nI have been facing this issue since i upgraded to this major version (0.49) \n\nI have even tried this same thing even after updating the patch versions till now in hopes that it might've solved in the upcoming version but no luck since"", 'created_at': datetime.datetime(2024, 6, 5, 15, 30, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150411847, 'issue_id': 2214769175, 'author': 'nemanjaglumac', 'body': 'Both @Ravi9535 and @Ninx96 - a really important missing piece of information - from which version you upgraded to v49?', 'created_at': datetime.datetime(2024, 6, 5, 15, 53, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150420267, 'issue_id': 2214769175, 'author': 'scykie', 'body': '@nemanjaglumac v43 in my case', 'created_at': datetime.datetime(2024, 6, 5, 15, 57, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2153114156, 'issue_id': 2214769175, 'author': 'Tony-metabase', 'body': 'Are you sure that the upgrade went well? Do you have the logs when you performed the update cause it could be something went wrong there and that would point us to the issue.\r\n\r\nAlso same question what application DB are you using? If MYSLQ the minimum recommended version is 8.0.17', 'created_at': datetime.datetime(2024, 6, 6, 18, 7, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2153118155, 'issue_id': 2214769175, 'author': 'nemanjaglumac', 'body': 'I spent A LOT of time trying to debug this. No matter what I do I cannot reproduce it.\r\n\r\nFor example:\r\nSpun up v43 (43.4) and created two SQL questions.\r\n\r\n```\r\nselect 1\r\n```\r\n\r\nand \r\n\r\n```\r\n\r\nSELECT\r\n  count(*)\r\nFROM\r\n  products\r\nWHERE\r\n  category = {{category}}\r\n```\r\n\r\nSaved both, and then upgraded to v49 (49.5)\r\n\r\nI was able to modify both questions and to save them (both to override them and to save as new).\r\nOn top of that, I was able to create a new SQL in the version 49 and to then update it and override it.\r\n\r\nThere needs to be something very specific about your questions or your environments that is causing this error.\r\n@Tony-metabase raised a good question about the MySQL version.\r\n\r\nThis is why we ask for the diagnostic info.', 'created_at': datetime.datetime(2024, 6, 6, 18, 9, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2153280429, 'issue_id': 2214769175, 'author': 'johnswanson', 'body': 'This looks to be a duplicate of this issue: https://github.com/metabase/metabase/issues/40600', 'created_at': datetime.datetime(2024, 6, 6, 19, 42, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2153285844, 'issue_id': 2214769175, 'author': 'nemanjaglumac', 'body': ""I'm closing this issue for the lack of the information, AND because it's most likely a duplicate.\r\nOnce #43296 gets merged to `master` and backported to `49` @Ravi9535 and @Ninx96 please check if that fixes an issue for you."", 'created_at': datetime.datetime(2024, 6, 6, 19, 46, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421669728, 'issue_id': 2214769175, 'author': 'GizzmoAsus', 'body': '@Ravi9535 I had this same issue against `v0.49.11` but upgrading to `v0.50.29` has resolved it.\n\n@paoliniluis for reference the issue I was seeing in the logs/api response was as follows:\n\n```\nPUT /api/card/58 400 1.9 ms (0 DB calls)\n{:errors {:collection_preview ""nullable boolean""},\n :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}\n```\n\nI thought it was because the query was a standalone one at the top level and not part of a collection but editing collection queries suffered the same issue but the latest version is working fine for me :)', 'created_at': datetime.datetime(2024, 10, 18, 7, 40, 26, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-03-29 06:48:33 UTC): @Ravi9535 could you provide the logs? there should be an error when saving the question failed

Ravi9535 (Issue Creator) on (2024-03-29 07:30:48 UTC): Hi @ranquild , Since many users are using the saved reports the log is too much and it is running. So what exactly should I share regarding that log

paoliniluis on (2024-03-29 08:12:16 UTC): @Ravi9535 we need to see what happens in the server and in your browser when you click on save

Ravi9535 (Issue Creator) on (2024-03-29 09:44:38 UTC): When I click on save and it got failed.
Here is the Log
[log.log](https://github.com/metabase/metabase/files/14802373/log.log)

paoliniluis on (2024-03-29 11:22:31 UTC): Are you using MySQL as the application database? Which version?

Ravi9535 (Issue Creator) on (2024-03-29 11:48:21 UTC): Yes,
mysql  Ver 14.14 Distrib 5.7.42, for Linux (x86_64) using  EditLine wrapper

ssshreyans26 on (2024-05-09 05:01:43 UTC): @ranquild @paoliniluis Is this issue resolved in the latest version of metabase community? If not is there a temporary patch/fix that we can apply or do we need to revert to previous version?

scykie on (2024-05-09 05:46:51 UTC): hi guys,
having same issue while trying to replace the existing query, did anyone find any solution for this ?, when will this issue be fixed ????

nemanjaglumac on (2024-06-04 13:08:19 UTC): @Ravi9535 @Ninx96 we're trying to reproduce the issue but it's hard with the very limited information that's available to us. For example:

This doesn't really tells me much, because the ""query"" can be `select 1` or it can be really complex with a lot of parameters. Looking at the logs, it seems that this query had at least one parameter marked as required.

Can you confirm that?
If yes, can you try either:
1. Marking it as not required or
2. Giving the required filter/parameter the default value

Let me know if that helps.

scykie on (2024-06-05 06:04:11 UTC): hi @nemanjaglumac 

you can reproduce the issue by following the steps:

1. try to run & save a native query to any connected sql database (can be as simple as ""select 1"")
2. Once it is saved try to edit the same saved question (for example ""select 2"")
3. when the save Question popup opens up select ""Replace original question"" and try to save it 
4. it will get failed 


logs saying:

[9344d828-2654-460a-9612-26e7477ea086] 2024-06-05T11:22:41+05:30 DEBUG metabase.server.middleware.log PUT /api/card/1005 400 2.7 ms (0 DB calls) 
{:errors {:collection_preview ""nullable boolean""},
 :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}

nemanjaglumac on (2024-06-05 14:48:53 UTC): This error is completely different from the original one that @Ravi9535 attached.

@Ninx96 are all these steps on the same version (if yes - which one?)? Or do you save an original question in one version (which one?) and then upgrade to some other version (which one?)?

scykie on (2024-06-05 15:30:11 UTC): @nemanjaglumac all these steps are performed in the exact same version (0.49.8) currently.


I have been facing this issue since i upgraded to this major version (0.49) 

I have even tried this same thing even after updating the patch versions till now in hopes that it might've solved in the upcoming version but no luck since

nemanjaglumac on (2024-06-05 15:53:24 UTC): Both @Ravi9535 and @Ninx96 - a really important missing piece of information - from which version you upgraded to v49?

scykie on (2024-06-05 15:57:15 UTC): @nemanjaglumac v43 in my case

Tony-metabase on (2024-06-06 18:07:08 UTC): Are you sure that the upgrade went well? Do you have the logs when you performed the update cause it could be something went wrong there and that would point us to the issue.

Also same question what application DB are you using? If MYSLQ the minimum recommended version is 8.0.17

nemanjaglumac on (2024-06-06 18:09:39 UTC): I spent A LOT of time trying to debug this. No matter what I do I cannot reproduce it.

For example:
Spun up v43 (43.4) and created two SQL questions.

```
select 1
```

and 

```

SELECT
  count(*)
FROM
  products
WHERE
  category = {{category}}
```

Saved both, and then upgraded to v49 (49.5)

I was able to modify both questions and to save them (both to override them and to save as new).
On top of that, I was able to create a new SQL in the version 49 and to then update it and override it.

There needs to be something very specific about your questions or your environments that is causing this error.
@Tony-metabase raised a good question about the MySQL version.

This is why we ask for the diagnostic info.

johnswanson on (2024-06-06 19:42:54 UTC): This looks to be a duplicate of this issue: https://github.com/metabase/metabase/issues/40600

nemanjaglumac on (2024-06-06 19:46:47 UTC): I'm closing this issue for the lack of the information, AND because it's most likely a duplicate.
Once #43296 gets merged to `master` and backported to `49` @Ravi9535 and @Ninx96 please check if that fixes an issue for you.

GizzmoAsus on (2024-10-18 07:40:26 UTC): @Ravi9535 I had this same issue against `v0.49.11` but upgrading to `v0.50.29` has resolved it.

@paoliniluis for reference the issue I was seeing in the logs/api response was as follows:

```
PUT /api/card/58 400 1.9 ms (0 DB calls)
{:errors {:collection_preview ""nullable boolean""},
 :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}
```

I thought it was because the query was a standalone one at the top level and not part of a collection but editing collection queries suffered the same issue but the latest version is working fine for me :)

"
2213831329,issue,open,,CSV upload support for MongoDB,"
**Describe the solution you'd like**
CSV upload support for MongoDB like you can with Postgres and MySQL

**How important is this feature to you?**
Requested by customers

**Additional context**
None
",dahyeik,2024-03-28 18:06:04+00:00,[],2024-04-24 09:04:10+00:00,,https://github.com/metabase/metabase/issues/40756,"[('Database/Mongo', None), ('Type:New Feature', ''), ('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2074457141, 'issue_id': 2213831329, 'author': 'happy0088', 'body': 'Looking forward to this feature .', 'created_at': datetime.datetime(2024, 4, 24, 9, 4, 9, tzinfo=datetime.timezone.utc)}]","happy0088 on (2024-04-24 09:04:09 UTC): Looking forward to this feature .

"
2213802941,issue,closed,not_planned,how to build drivers since bin/build-drivers was removed,"### Describe the bug

We upgraded from 0.48.8 to 0.49.2 and this broke https://github.com/ericcj/metabase-netsuite-driver because connection-details->spec is being called on its parent oracle driver instead of itself.  could you help me figure out what i need to implement/change to fix it?  I didn't see any updates to https://www.metabase.com/docs/latest/developers-guide/drivers/basics or https://github.com/metabase/sample-driver or https://github.com/metabase/metabase/releases/tag/v0.49.0

```
 :stacktrace
 [""--> driver.oracle$fn__117229.invokeStatic(oracle.clj:158)""
  ""driver.oracle$fn__117229.invoke(oracle.clj:154)""
  ""driver.sql_jdbc.connection$create_pool_BANG_.invokeStatic(connection.clj:168)""
  ""driver.sql_jdbc.connection$create_pool_BANG_.invoke(connection.clj:160)""
  ""driver.sql_jdbc.connection$db__GT_pooled_connection_spec.invokeStatic(connection.clj:288)""
  ""driver.sql_jdbc.connection$db__GT_pooled_connection_spec.invoke(connection.clj:228)""
  ""driver.sql_jdbc.execute$datasource.invokeStatic(execute.clj:197)""
  ""driver.sql_jdbc.execute$datasource.invoke(execute.clj:193)""
  ""driver.sql_jdbc.execute$datasource_with_diagnostic_info_BANG_.invokeStatic(execute.clj:204)""
  ""driver.sql_jdbc.execute$datasource_with_diagnostic_info_BANG_.invoke(execute.clj:199)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection_data_source.invokeStatic(execute.clj:296)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection_data_source.invoke(execute.clj:255)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:333)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
  ""driver.sql_jdbc.execute$fn__79060.invokeStatic(execute.clj:382)""
  ""driver.sql_jdbc.execute$fn__79060.invoke(execute.clj:380)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:692)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc$fn__106640.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__106640.invoke(sql_jdbc.clj:76)""
  ""driver.oracle$fn__117379.invokeStatic(oracle.clj:507)""
  ""driver.oracle$fn__117379.invoke(oracle.clj:505)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:202)""
  ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:186)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___72155.invoke(cache.clj:228)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66533.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71976.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71986.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71418.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__73323$combined_post_process__73328$combined_post_process_STAR___73329.invoke(query_processor.clj:262)""
  ""query_processor$fn__73323$combined_pre_process__73324$combined_pre_process_STAR___73325.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66630.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72066$fn__72070.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__72066.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67236$fn__67237.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67236.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__72063.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72368.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__72003$handle_audit_app_internal_queries__72004$fn__72006.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__72014.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__71129.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72299.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72900.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62764$thunk__62766.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62764$fn__62768.invoke(reducible.clj:131)""],
 :card_id 1351,
 :context :question,
 :error ""Assert failed: (or sid service-name)"",


### To Reproduce

Use netsuite driver with v0.49

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
v0.49
```


### Severity

blocking an upgrade

### Additional context

_No response_",ericcj,2024-03-28 17:50:10+00:00,[],2024-05-31 21:22:22+00:00,2024-05-31 21:21:41+00:00,https://github.com/metabase/metabase/issues/40754,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', '')]","[{'comment_id': 2025814721, 'issue_id': 2213802941, 'author': 'ericcj', 'body': 'oh i figured out it was because i had unused honeysql 1 imports:  FileNotFoundException: Could not locate honeysql/core__init.class, honeysql/core.clj or honeysql/core.cljc on classpath\r\n\r\nbut now i\'m stuck building any tips for how to fix this:\r\n\r\nthwomp:metabase-netsuite-driver ej$ clojure -X:build :project-dir ""\\""$(pwd)\\""""\r\nError building classpath. Local lib metabase/build-drivers not found: /Users/ej/metabase/bin/build-drivers', 'created_at': datetime.datetime(2024, 3, 28, 18, 4, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027409759, 'issue_id': 2213802941, 'author': 'bshepherdson', 'body': 'That looks like you need to run the script in your local Metabase dir to compile the core drivers: `./bin/build-drivers.sh`.\r\n\r\nSee [the docs](https://www.metabase.com/docs/latest/developers-guide/devenv#building-drivers) for more.\r\n\r\nI suppose dropping HoneySQL 1 from Metabase itself counts as a driver API change which should be documented. External drivers might rely on that dependency to be present, and they need to specify it themselves or use HoneySQL 2.', 'created_at': datetime.datetime(2024, 3, 29, 15, 49, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2028094578, 'issue_id': 2213802941, 'author': 'ericcj', 'body': 'build-drivers.sh works fine but that\'s just for the internal metabase drivers.  it looks like https://github.com/metabase/sample-driver?tab=readme-ov-file#usage hasn\'t been updated so i used the instructions from https://github.com/metabase/sudoku-driver/blob/master/README.md#build-it-updated-for-build-script-changes-in-metabase-0460 but i\'m not sure how to tell it to include modules/drivers/oracle/src in my path since netsuite depends on it as a parent:\r\n\r\n```\r\nthwomp:metabase ej$ bin/build-drivers.sh\r\n...\r\n  Successfully built all drivers.\r\nthwomp:metabase ej$ DRIVER_PATH=`readlink -f ~/metabase-netsuite-driver`\r\nthwomp:metabase ej$ clojure \\\r\n>   -Sdeps ""{:aliases {:sudoku {:extra-deps {com.metabase/sudoku-driver {:local/root \\""$DRIVER_PATH\\""}}}}}""  \\\r\n>   -X:build:sudoku \\\r\n>   build-drivers.build-driver/build-driver! \\\r\n>   ""{:driver :sudoku, :project-dir \\""$DRIVER_PATH\\"", :target-dir \\""$DRIVER_PATH/target\\""}""\r\nthwomp:metabase ej$\r\nthwomp:metabase ej$ clojure \\\r\n>   -Sdeps ""{:aliases {:metabase-netsuite-driver {:extra-deps {com.metabase/metabase-netsuite-driver-driver {:local/root \\""$DRIVER_PATH\\""}}}}}""  \\\r\n>   -X:build:metabase-netsuite-driver \\\r\n>   build-drivers.build-driver/build-driver! \\\r\n>   ""{:driver :metabase-netsuite-driver, :project-dir \\""$DRIVER_PATH\\"", :target-dir \\""$DRIVER_PATH/target\\""}""\r\nBuild driver :metabase-netsuite-driver (edition = :oss, options = {:project-dir ""/Users/ej/metabase-netsuite-driver"", :target-dir ""/Users/ej/metabase-netsuite-driver/target""})\r\n  Clean\r\n    Delete /Users/ej/metabase-netsuite-driver/target/jar if exists\r\n      Deleted /Users/ej/metabase-netsuite-driver/target/jar.\r\n    Delete /Users/ej/metabase-netsuite-driver/target/metabase-netsuite-driver.metabase-driver.jar if exists\r\n      Don\'t need to delete /Users/ej/metabase-netsuite-driver/target/metabase-netsuite-driver.metabase-driver.jar, file does not exist.\r\n  Copy :metabase-netsuite-driver source files\r\n    Copying files in [""/Users/ej/metabase-netsuite-driver/src"" ""/Users/ej/metabase-netsuite-driver/resources""]\r\n    Copied files in 2 directories in 103 ms.\r\n  Compile clojure source files\r\n    Compiling Clojure source files in [""/Users/ej/metabase-netsuite-driver/src"" ""/Users/ej/metabase-netsuite-driver/resources""] to /Users/ej/metabase-netsuite-driver/target/jar\r\n    Create directory /Users/ej/metabase-netsuite-driver/target/jar if it does not exist\r\n      /Users/ej/metabase-netsuite-driver/target/jar already exists.\r\n    Compiling namespaces [metabase.driver.netsuite]\r\n2024-03-30 09:42:25,913 INFO metabase.util :: Maximum memory available to JVM: 16.0 GB\r\noperator.clj:172 recur arg for primitive local: sum is not matching primitive, had: Object, needed: long\r\nAuto-boxing loop arg: sum\r\n2024-03-30 09:42:45,783 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. üîì\r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-03-30 09:42:50,131 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For production deployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database file regularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html\r\nReflection warning, clojurewerkz/quartzite/triggers.clj:85:6 - call to method forJob on org.quartz.TriggerBuilder can\'t be resolved (argument types: unknown).\r\nReflection warning, clojurewerkz/quartzite/scheduler.clj:254:3 - call to method checkExists on org.quartz.Scheduler can\'t be resolved (argument types: unknown).\r\n2024-03-30 09:42:59,854 INFO driver.impl :: Registered abstract driver :sql  üöö\r\n2024-03-30 09:43:10,278 ERROR driver.impl :: Error loading driver namespace\r\nclojure.lang.ExceptionInfo: Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath. {:classloader #object[clojure.lang.DynamicClassLoader 0x6eaded2a ""clojure.lang.DynamicClassLoader@6eaded2a""], :classpath-urls (), :system-classpath (... ""/Users/ej/NetSuiteJDBCDrivers/NQjc.jar"" ""/Users/ej/metabase-netsuite-driver/resources"" ""/Users/ej/metabase-netsuite-driver/src"" ""/opt/homebrew/Cellar/clojure/1.11.1.1189/libexec/exec.jar"" ""bin/build/resources"" ""bin/build/src"" ""resources"" ""src"")}\r\n\tat metabase.plugins.classloader$require_STAR_.invokeStatic(classloader.clj:132)\r\n\tat metabase.plugins.classloader$require_STAR_.doInvoke(classloader.clj:116)\r\n...\r\n\tat clojure.main.main(main.java:40)\r\nCaused by: java.io.FileNotFoundException: Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath.\r\n\tat clojure.lang.RT.load(RT.java:462)\r\n\t... 82 more\r\nStep failed: Syntax error macroexpanding at (metabase/driver/netsuite.clj:22:1).\r\n{:via\r\n [{:type clojure.lang.Compiler$CompilerException,\r\n   :message ""Syntax error macroexpanding at (metabase/driver/netsuite.clj:22:1)."",\r\n   :data #:clojure.error{:phase :execution, :line 22, :column 1, :source ""metabase/driver/netsuite.clj""},\r\n   :at [clojure.lang.Compiler load ""Compiler.java"" 7665]}\r\n  {:type java.lang.Exception,\r\n   :message ""Could not load :oracle driver."",\r\n   :at [metabase.driver.impl$require_driver_ns invokeStatic ""impl.clj"" 82]}\r\n  {:type clojure.lang.ExceptionInfo,\r\n   :message\r\n   ""Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath."",\r\n   :data\r\n   {:classloader #object[clojure.lang.DynamicClassLoader 0x6eaded2a ""clojure.lang.DynamicClassLoader@6eaded2a""],\r\n    :classpath-urls (),\r\n    :system-classpath\r\n    (...\r\n     ""/Users/ej/NetSuiteJDBCDrivers/NQjc.jar""\r\n     ""/Users/ej/metabase-netsuite-driver/resources""\r\n     ""/Users/ej/metabase-netsuite-driver/src""\r\n     ""/opt/homebrew/Cellar/clojure/1.11.1.1189/libexec/exec.jar""\r\n     ""bin/build/resources""\r\n     ""bin/build/src""\r\n     ""resources""\r\n     ""src"")},\r\n   :at [metabase.plugins.classloader$require_STAR_ invokeStatic ""classloader.clj"" 132]}\r\n  {:type java.io.FileNotFoundException,\r\n   :message\r\n   ""Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath."",\r\n   :at [clojure.lang.RT load ""RT.java"" 462]}],\r\n :trace\r\n [[clojure.lang.RT load ""RT.java"" 462]\r\n ...\r\n  [clojure.main main ""main.java"" 40]],\r\n :cause\r\n ""Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath."",\r\n :phase :execution}\r\n    Step ""Compile clojure source files"" failed with error ""Syntax error macroexpanding at (metabase/driver/netsuite.clj:22:1).""', 'created_at': datetime.datetime(2024, 3, 30, 14, 50, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2028304455, 'issue_id': 2213802941, 'author': 'ericcj', 'body': ""I think I got it working in https://github.com/ericcj/metabase-netsuite-driver/commit/9a1c1ca5910d5b62d5fb55ce5a76ef237945e27e but it's pretty hairy is there a simpler recommended way to build external drivers?"", 'created_at': datetime.datetime(2024, 3, 30, 17, 9, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2142993591, 'issue_id': 2213802941, 'author': 'camsaul', 'body': 'Adapting the example in https://github.com/metabase/sudoku-driver/tree/master?tab=readme-ov-file#build-it-updated-for-build-script-changes-in-metabase-0460 is still the recommended way to build third-party drivers, if you need to include other e.g. Oracle as a parent then you can include more `:extra-deps` when you run the build script, check out the [Clojure deps documentation](https://clojure.org/guides/deps_and_cli#local_jar) for more info about how this stuff works. I think something like this should do the trick:\r\n\r\n```sh\r\nORACLE_PATH=/path/to/metabase/modules/drivers/oracle\r\n\r\nclojure \\\r\n  -Sdeps ""{:aliases {:netsuite {:extra-deps {com.metabase/netsuite-driver {:local/root \\""$DRIVER_PATH\\""}}} :oracle {:extra-deps {com.metabase/oracle-driver {:local/root \\""$ORACLE_PATH\\""}}}}}""  \\\r\n  -X:build:netsuite:oracle \\\r\n  build-drivers.build-driver/build-driver! \\\r\n  ""{:driver :netsuite, :project-dir \\""$DRIVER_PATH\\"", :target-dir \\""$DRIVER_PATH/target\\""}""\r\n```\r\n\r\nI don\'t think you want to include oracle as a dep in your `deps.edn` or it\'s going to copy the compiled Oracle files and JDBC driver dep into your driver which is going to potentially cause problems if people try to use both drivers at the same time since we\'ll have two copies of the Oracle classes. You do need to add \r\n\r\n```yaml\r\ndriver:\r\n  parent: oracle\r\n```\r\n\r\nto your `resources/metabase-plugin.yaml` tho, then when Metabase loads your driver it will load the Oracle stuff first.\r\n\r\nYou can verify that your build driver doesn\'t contain the Oracle stuff by doing `jar -tf my-driver.jar` and making sure there aren\'t any  `metabase/driver/oracle` files in there.\r\n\r\nLet me know if you have any more questions.', 'created_at': datetime.datetime(2024, 5, 31, 21, 21, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2142994310, 'issue_id': 2213802941, 'author': 'camsaul', 'body': 'I should also mention `bin/build-drivers` was not removed, it was just renamed to `bin/build-drivers.sh`', 'created_at': datetime.datetime(2024, 5, 31, 21, 22, 20, tzinfo=datetime.timezone.utc)}]","ericcj (Issue Creator) on (2024-03-28 18:04:48 UTC): oh i figured out it was because i had unused honeysql 1 imports:  FileNotFoundException: Could not locate honeysql/core__init.class, honeysql/core.clj or honeysql/core.cljc on classpath

but now i'm stuck building any tips for how to fix this:

thwomp:metabase-netsuite-driver ej$ clojure -X:build :project-dir ""\""$(pwd)\""""
Error building classpath. Local lib metabase/build-drivers not found: /Users/ej/metabase/bin/build-drivers

bshepherdson on (2024-03-29 15:49:50 UTC): That looks like you need to run the script in your local Metabase dir to compile the core drivers: `./bin/build-drivers.sh`.

See [the docs](https://www.metabase.com/docs/latest/developers-guide/devenv#building-drivers) for more.

I suppose dropping HoneySQL 1 from Metabase itself counts as a driver API change which should be documented. External drivers might rely on that dependency to be present, and they need to specify it themselves or use HoneySQL 2.

ericcj (Issue Creator) on (2024-03-30 14:50:44 UTC): build-drivers.sh works fine but that's just for the internal metabase drivers.  it looks like https://github.com/metabase/sample-driver?tab=readme-ov-file#usage hasn't been updated so i used the instructions from https://github.com/metabase/sudoku-driver/blob/master/README.md#build-it-updated-for-build-script-changes-in-metabase-0460 but i'm not sure how to tell it to include modules/drivers/oracle/src in my path since netsuite depends on it as a parent:

```
thwomp:metabase ej$ bin/build-drivers.sh
...
  Successfully built all drivers.
thwomp:metabase ej$ DRIVER_PATH=`readlink -f ~/metabase-netsuite-driver`
thwomp:metabase ej$ clojure \
thwomp:metabase ej$
thwomp:metabase ej$ clojure \
Build driver :metabase-netsuite-driver (edition = :oss, options = {:project-dir ""/Users/ej/metabase-netsuite-driver"", :target-dir ""/Users/ej/metabase-netsuite-driver/target""})
  Clean
    Delete /Users/ej/metabase-netsuite-driver/target/jar if exists
      Deleted /Users/ej/metabase-netsuite-driver/target/jar.
    Delete /Users/ej/metabase-netsuite-driver/target/metabase-netsuite-driver.metabase-driver.jar if exists
      Don't need to delete /Users/ej/metabase-netsuite-driver/target/metabase-netsuite-driver.metabase-driver.jar, file does not exist.
  Copy :metabase-netsuite-driver source files
    Copying files in [""/Users/ej/metabase-netsuite-driver/src"" ""/Users/ej/metabase-netsuite-driver/resources""]
    Copied files in 2 directories in 103 ms.
  Compile clojure source files
    Compiling Clojure source files in [""/Users/ej/metabase-netsuite-driver/src"" ""/Users/ej/metabase-netsuite-driver/resources""] to /Users/ej/metabase-netsuite-driver/target/jar
    Create directory /Users/ej/metabase-netsuite-driver/target/jar if it does not exist
      /Users/ej/metabase-netsuite-driver/target/jar already exists.
    Compiling namespaces [metabase.driver.netsuite]
2024-03-30 09:42:25,913 INFO metabase.util :: Maximum memory available to JVM: 16.0 GB
operator.clj:172 recur arg for primitive local: sum is not matching primitive, had: Object, needed: long
Auto-boxing loop arg: sum
2024-03-30 09:42:45,783 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. üîì
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-03-30 09:42:50,131 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For production deployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database file regularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html
Reflection warning, clojurewerkz/quartzite/triggers.clj:85:6 - call to method forJob on org.quartz.TriggerBuilder can't be resolved (argument types: unknown).
Reflection warning, clojurewerkz/quartzite/scheduler.clj:254:3 - call to method checkExists on org.quartz.Scheduler can't be resolved (argument types: unknown).
2024-03-30 09:42:59,854 INFO driver.impl :: Registered abstract driver :sql  üöö
2024-03-30 09:43:10,278 ERROR driver.impl :: Error loading driver namespace
clojure.lang.ExceptionInfo: Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath. {:classloader #object[clojure.lang.DynamicClassLoader 0x6eaded2a ""clojure.lang.DynamicClassLoader@6eaded2a""], :classpath-urls (), :system-classpath (... ""/Users/ej/NetSuiteJDBCDrivers/NQjc.jar"" ""/Users/ej/metabase-netsuite-driver/resources"" ""/Users/ej/metabase-netsuite-driver/src"" ""/opt/homebrew/Cellar/clojure/1.11.1.1189/libexec/exec.jar"" ""bin/build/resources"" ""bin/build/src"" ""resources"" ""src"")}
	at metabase.plugins.classloader$require_STAR_.invokeStatic(classloader.clj:132)
	at metabase.plugins.classloader$require_STAR_.doInvoke(classloader.clj:116)
...
	at clojure.main.main(main.java:40)
Caused by: java.io.FileNotFoundException: Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath.
	at clojure.lang.RT.load(RT.java:462)
	... 82 more
Step failed: Syntax error macroexpanding at (metabase/driver/netsuite.clj:22:1).
{:via
 [{:type clojure.lang.Compiler$CompilerException,
   :message ""Syntax error macroexpanding at (metabase/driver/netsuite.clj:22:1)."",
   :data #:clojure.error{:phase :execution, :line 22, :column 1, :source ""metabase/driver/netsuite.clj""},
   :at [clojure.lang.Compiler load ""Compiler.java"" 7665]}
  {:type java.lang.Exception,
   :message ""Could not load :oracle driver."",
   :at [metabase.driver.impl$require_driver_ns invokeStatic ""impl.clj"" 82]}
  {:type clojure.lang.ExceptionInfo,
   :message
   ""Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath."",
   :data
   {:classloader #object[clojure.lang.DynamicClassLoader 0x6eaded2a ""clojure.lang.DynamicClassLoader@6eaded2a""],
    :classpath-urls (),
    :system-classpath
    (...
     ""/Users/ej/NetSuiteJDBCDrivers/NQjc.jar""
     ""/Users/ej/metabase-netsuite-driver/resources""
     ""/Users/ej/metabase-netsuite-driver/src""
     ""/opt/homebrew/Cellar/clojure/1.11.1.1189/libexec/exec.jar""
     ""bin/build/resources""
     ""bin/build/src""
     ""resources""
     ""src"")},
   :at [metabase.plugins.classloader$require_STAR_ invokeStatic ""classloader.clj"" 132]}
  {:type java.io.FileNotFoundException,
   :message
   ""Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath."",
   :at [clojure.lang.RT load ""RT.java"" 462]}],
 :trace
 [[clojure.lang.RT load ""RT.java"" 462]
 ...
  [clojure.main main ""main.java"" 40]],
 :cause
 ""Could not locate metabase/driver/oracle__init.class, metabase/driver/oracle.clj or metabase/driver/oracle.cljc on classpath."",
 :phase :execution}
    Step ""Compile clojure source files"" failed with error ""Syntax error macroexpanding at (metabase/driver/netsuite.clj:22:1).""

ericcj (Issue Creator) on (2024-03-30 17:09:26 UTC): I think I got it working in https://github.com/ericcj/metabase-netsuite-driver/commit/9a1c1ca5910d5b62d5fb55ce5a76ef237945e27e but it's pretty hairy is there a simpler recommended way to build external drivers?

camsaul on (2024-05-31 21:21:41 UTC): Adapting the example in https://github.com/metabase/sudoku-driver/tree/master?tab=readme-ov-file#build-it-updated-for-build-script-changes-in-metabase-0460 is still the recommended way to build third-party drivers, if you need to include other e.g. Oracle as a parent then you can include more `:extra-deps` when you run the build script, check out the [Clojure deps documentation](https://clojure.org/guides/deps_and_cli#local_jar) for more info about how this stuff works. I think something like this should do the trick:

```sh
ORACLE_PATH=/path/to/metabase/modules/drivers/oracle

clojure \
  -Sdeps ""{:aliases {:netsuite {:extra-deps {com.metabase/netsuite-driver {:local/root \""$DRIVER_PATH\""}}} :oracle {:extra-deps {com.metabase/oracle-driver {:local/root \""$ORACLE_PATH\""}}}}}""  \
  -X:build:netsuite:oracle \
  build-drivers.build-driver/build-driver! \
  ""{:driver :netsuite, :project-dir \""$DRIVER_PATH\"", :target-dir \""$DRIVER_PATH/target\""}""
```

I don't think you want to include oracle as a dep in your `deps.edn` or it's going to copy the compiled Oracle files and JDBC driver dep into your driver which is going to potentially cause problems if people try to use both drivers at the same time since we'll have two copies of the Oracle classes. You do need to add 

```yaml
driver:
  parent: oracle
```

to your `resources/metabase-plugin.yaml` tho, then when Metabase loads your driver it will load the Oracle stuff first.

You can verify that your build driver doesn't contain the Oracle stuff by doing `jar -tf my-driver.jar` and making sure there aren't any  `metabase/driver/oracle` files in there.

Let me know if you have any more questions.

camsaul on (2024-05-31 21:22:20 UTC): I should also mention `bin/build-drivers` was not removed, it was just renamed to `bin/build-drivers.sh`

"
2213714414,issue,closed,completed,"""Cannot read properties of undefined (reading 'id')"" when deleting custom user properties","### Describe the bug

If I want to delete user properties I get that error (users were created via sso without first or last name)

### To Reproduce

1) create a user via SSO without first name or last name
2) add user properties
3) save
4) then try to delete those

### Expected behavior

admins should be able to delete user properties

### Logs

middleware.log :: PUT /api/user/2 400 1.7 ms (0 DB calls) 
{:errors {:first_name ""nullable value must be a non-blank string.""},
 :specific-errors {:first_name [""should be at least 1 characters, received: \""\"""" ""non-blank string, received: \""\""""]}}

2024-03-28 17:01:12,834 DEBUG middleware.log :: GET /api/health 200 184.0 ¬µs (0 DB calls) App DB connections: 1/13 Jetty threads: 4/50 (2 idle, 0 queued) (39 total active threads) Queries in flight: 0 (0 queued)
2024-03-28 17:01:18,981 DEBUG middleware.log :: PUT /api/user/2 400 5.4 ms (1 DB calls) 
{:errors {:first_name ""Editing first name is not allowed for SSO users.""}}


### Information about your Metabase installation

```JSON
v49
```


### Severity

P3

### Additional context

workaround: users should have first or last name",paoliniluis,2024-03-28 17:02:22+00:00,['iethree'],2024-08-06 23:35:21+00:00,2024-08-06 23:01:21+00:00,https://github.com/metabase/metabase/issues/40750,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2220051982, 'issue_id': 2213714414, 'author': 'Tony-metabase', 'body': 'The problem is not just around user attributes and even if you create a user manually (not via SSO) without Last Name you end up with the same problem:\r\n\r\n<img width=""1217"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/7030447a-81f5-4629-a1cf-1d94327ceba1"">\r\n\r\nEven updating the email address won\'t work and will expect you to add the Last Name:\r\n\r\n<img width=""715"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/89bb6644-19a6-4e75-bf8e-690f9303f309"">\r\n\r\nI will increase this to P2 cause you have to add misleading information to a user to be able to use that user and the error message isn\'t clear which brings confusion to customers.', 'created_at': datetime.datetime(2024, 7, 10, 9, 50, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233756456, 'issue_id': 2213714414, 'author': 'sloansparger', 'body': ""Glanced at this a bit, it appears to be two things:\r\n1. The frontend isn't treating failed user update requests as errors, so it's expecting the response body to be an updated user when it's actually error details. (this subsequently causes the mistake of accessing the `id` property incorrectly in `frontend/src/metabase/redux/user.ts`).\r\n2. The specific failure in this case is that we're sending along first and last names as an empty string in the update request. The backend is allowing these fields to be null, but isn't treating empty strings as the null case. This is different from how we validate the creation of the user, so we should likely remove this validation / coerce the value to null on the backend."", 'created_at': datetime.datetime(2024, 7, 17, 16, 50, 18, tzinfo=datetime.timezone.utc)}]","Tony-metabase on (2024-07-10 09:50:26 UTC): The problem is not just around user attributes and even if you create a user manually (not via SSO) without Last Name you end up with the same problem:

<img width=""1217"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/7030447a-81f5-4629-a1cf-1d94327ceba1"">

Even updating the email address won't work and will expect you to add the Last Name:

<img width=""715"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/89bb6644-19a6-4e75-bf8e-690f9303f309"">

I will increase this to P2 cause you have to add misleading information to a user to be able to use that user and the error message isn't clear which brings confusion to customers.

sloansparger on (2024-07-17 16:50:18 UTC): Glanced at this a bit, it appears to be two things:
1. The frontend isn't treating failed user update requests as errors, so it's expecting the response body to be an updated user when it's actually error details. (this subsequently causes the mistake of accessing the `id` property incorrectly in `frontend/src/metabase/redux/user.ts`).
2. The specific failure in this case is that we're sending along first and last names as an empty string in the update request. The backend is allowing these fields to be null, but isn't treating empty strings as the null case. This is different from how we validate the creation of the user, so we should likely remove this validation / coerce the value to null on the backend.

"
2213594301,issue,open,,Improve setting names in subscriptions panel,"**Is your feature request related to a problem? Please describe.**
Currently there are 2 ways to hide data at dashboard level. One is at dashcard level, which will impacet the dsahboard at metabase level and at subscription level :

<img width=""1291"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/7f94adc5-dea3-49c7-b454-af1759bceb51"">

The second one is on the subscriptions panel:

<img width=""431"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/89de195f-a3c9-493c-bd43-5b8cc98cbac1"">

It's not clear to me `Don't send if there aren't results` what exactly is it referring to ...  It gives the impression that if there aren't results for a card it will not send but actually it will not send the subscription if all questions return nothing. So the wording isn't clear

**Describe the solution you'd like**
More clear description of what each setting does.

**Describe alternatives you've considered**
None

",Tony-metabase,2024-03-28 16:02:52+00:00,[],2024-03-28 16:02:52+00:00,,https://github.com/metabase/metabase/issues/40742,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('Type:New Feature', ''), ('.Frontend', '')]",[],
2213583070,issue,open,,Dashboard filter uses string input instead of a list with values for custom expressions,"### Describe the bug

An input instead of a list of values is shown when you click on filter

<img width=""657"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/30b37c44-fa52-4315-a7ab-32a0c7d475da"">


### To Reproduce

1. Create and save a Question called `People Question` from the Sample Database > People table with a custom column called `source state` as `concat([Source], "" "", [State])`
![image](https://github.com/metabase/metabase/assets/8808703/be3e955c-9fb6-4da2-aad4-d423e0703a92)

2. Add `People Question` to a dashboard called `Dashboard A`
3. Create a filter on the dashboard called `source state` and link to the `Person.source state` custom column
![image](https://github.com/metabase/metabase/assets/8808703/6b93f1c0-25f1-47aa-a90d-5d80c280b537)
4. Click on filter - popover contains an input and not a list of values

### Expected behavior

<img width=""692"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/33049661-6db6-4023-a4fc-cc319a91b6c0"">


### Logs

_No response_

### Information about your Metabase installation

```JSON
broken on master 06c664ae79c1ece003a15ad4ae7d1b18d669b4ca

since 08b8dfb1f415ef4bb2682845af326b8ae3a6c00a
```


### Severity

P2/P3

### Additional context

_No response_",uladzimirdev,2024-03-28 15:58:03+00:00,[],2024-06-20 16:07:34+00:00,,https://github.com/metabase/metabase/issues/40740,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.')]",[],
2213443733,issue,closed,completed,Misaligned search icon in Table Metadata,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/6830683/e3a8f736-5dce-4d9c-ba34-18d4b8b8561a)


### To Reproduce

1. Add a database with multiple schemas
2. Go to Admin > Table Metadata of that database


### Expected behavior

Search icon is inside the search input

### Information about your Metabase installation

master, 06c664ae79


### Severity

P3
",kamilmielnik,2024-03-28 14:53:50+00:00,[],2024-03-28 16:21:07+00:00,2024-03-28 16:21:07+00:00,https://github.com/metabase/metabase/issues/40737,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Metadata & Sync', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2213392125,issue,closed,completed,Add command palette trigger to Search Input in App Bar,,npfitz,2024-03-28 14:30:47+00:00,[],2024-04-02 17:48:27+00:00,2024-04-02 17:48:27+00:00,https://github.com/metabase/metabase/issues/40735,[],[],
2213338487,issue,open,,`enableCustomUserSelectHack` prop in `TableDraggable` does not work,"### Describe the bug

`Draggable` from `react-draggable` has `enableUserSelectHack` prop which prevents text selection on the entire page while something is being dragged.
We cannot use it because it causes [style element to be dynamically added](https://github.com/react-grid-layout/react-draggable/blob/e543a23/lib/DraggableCore.js#L316) which violates our CSP.

[Our attempt](https://github.com/metabase/metabase/pull/32526/files#diff-88d13a5246006e171ae65340a60b9ade73c16e5075516f62c3b6026d590a1fdcR26-R42) to re-do this hack on our side was incomplete/incorrect:
- `Draggable` does not accept `className` prop, so the inline styles are not used (and there's a [warning in JS console about that](https://github.com/metabase/metabase/assets/6830683/3340cc24-b24d-462f-a426-a6c72724a4b1))
- the `react-draggable-transparent-selection` class is expected to be added to the `body` element but this part has not been migrated to our code - it won't happen when we use `enableUserSelectHack={false}`

We also forgot to use `enableUserSelectHack={false}` in `PivotTableCell` ([it's currently enabled](https://github.com/metabase/metabase/blob/f2960b1/frontend/src/metabase/visualizations/visualizations/PivotTable/PivotTableCell.tsx#L95)).

### To Reproduce

1. Open table or pivot table visualization


### Expected behavior

- text cannot be selected while dragging table column headers
- there is no [warning in JS console](https://github.com/metabase/metabase/assets/6830683/3340cc24-b24d-462f-a426-a6c72724a4b1)


### Information about your Metabase installation

master, 06c664ae79


### Severity

P3
",kamilmielnik,2024-03-28 14:09:00+00:00,[],2024-03-28 14:10:27+00:00,,https://github.com/metabase/metabase/issues/40733,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2213290977,issue,open,,Cancel button on the dashboards,"**Is your feature request related to a problem? Please describe.**
We have a cross on the question that will cancel the query if a question is running. Why don't we have the same in the dashboard?

**Describe the solution you'd like**
A cancel button in the dashboard

**Describe alternatives you've considered**
closing the tab or the window

**How important is this feature to you?**
important for dashboards that take a long long time, like users that have massive datasets and they want to cancel the running dashboard before the query finishes (right now the only way of doing so is actually closing the tab or the window)

**Additional context**
NA
",paoliniluis,2024-03-28 13:48:13+00:00,[],2024-03-28 13:48:13+00:00,,https://github.com/metabase/metabase/issues/40731,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2213236411,issue,closed,not_planned,"Make ""don't bin"" default for numeric columns","[Binning for numeric columns doesn't work well, it's a backend problem and it's not easy to fix](https://github.com/metabase/metabase/issues/12004)
For now it's more useful to have it turned off. So let's make it as ""don't bin"" by default fro numeric columns.
For date columns the temporal bucketing defaults should not change (it's by month currently).
Latitude and longitude binning defaults should not change as well.",mngr,2024-03-28 13:22:58+00:00,[],2024-11-12 14:00:12+00:00,2024-11-12 14:00:12+00:00,https://github.com/metabase/metabase/issues/40729,"[('.Backend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]","[{'comment_id': 2464918160, 'issue_id': 2213236411, 'author': 'mngr', 'body': 'Canceled', 'created_at': datetime.datetime(2024, 11, 8, 14, 36, 5, tzinfo=datetime.timezone.utc)}]","mngr (Issue Creator) on (2024-11-08 14:36:05 UTC): Canceled

"
2213233147,issue,open,,Build linked filters structure from a model,"**Is your feature request related to a problem? Please describe.**
If you have a massive dataset then doing linked filters is really complicated, the queries will take a massive amount of time and probably they won't finish on time

**Describe the solution you'd like**
Let's build the linked filter structure from another dataset. E.g. Let's say that your database is a dimensional model with a trillion rows, instead of going to the actual DW on every filter click, let's allow the admin to pick a model where you have all the possible combination of filters, so Metabase queries that model instead of going to the fact / dimensions

**Describe alternatives you've considered**
None unfortunately, because if you want linked filters to work, you need to connect the filters with the cards so it inherits all the metadata

**How important is this feature to you?**
Important for customers with massive amounts of data

**Additional context**
NA
",paoliniluis,2024-03-28 13:21:25+00:00,[],2025-02-04 20:30:27+00:00,,https://github.com/metabase/metabase/issues/40728,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Models', 'aka Datasets'), ('.Product/HighEnd', ''), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only'), ('Semantic Model', '')]",[],
2213164780,issue,closed,completed,Setting `Hide this card if there are no results` at Dashboard level will remove it from the subscription even if there are results,"### Describe the bug

Setting `Hide this card if there are no results` at Dashboard level will remove it from the subscription even if there are results

### To Reproduce

1. Go to New -> Question ->  Sample Database -> Orders -> Save
2. Add it to dashboard and set the question to `Hide this card if there are no results`

<img width=""1473"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/44659e7b-7139-4ffc-891c-5ac952c91688"">

3. Send a Test subscription to email > I just get an empty email

<img width=""1146"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/f6f5f947-2acd-4207-a3a4-5b0dde676a4f"">

There are results in the question:

<img width=""1504"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/9548fb18-aee1-4c16-b2ce-5aabeb488fc4"">



### Expected behavior

Subscription needs to work as expected since there are results

### Logs

None that are relevant

### Information about your Metabase installation

1.49.1 and master



### Severity

This is blocking since subscription needs to work. This will break functionality for most customers I think and they won't know what is wrong

### Additional context

_No response_",Tony-metabase,2024-03-28 12:49:30+00:00,['adam-james-v'],2024-03-28 22:49:41+00:00,2024-03-28 21:19:27+00:00,https://github.com/metabase/metabase/issues/40726,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Escalation', '')]",[],
2213161305,issue,closed,completed,Model descriptions overflow when they contain a long URL,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/130925/a458dd2e-4cb3-41b9-86d0-7f4129b08300)

https://metaboat.slack.com/archives/C01LQQ2UW03/p1711614192773709

### To Reproduce

You can see the problem on https://stats.metabase.com/browse/models, in the 'Infrastructure' collection

### Expected behavior

Text should not overflow the card",rafpaf,2024-03-28 12:47:38+00:00,['rafpaf'],2024-03-29 18:29:12+00:00,2024-03-29 18:29:12+00:00,https://github.com/metabase/metabase/issues/40725,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Organization/Browse Data', '')]",[],
2213123159,issue,closed,completed,API error not handled in the query step preview,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/7429a962-197a-45ff-8972-b56e388efc15



### To Reproduce

1. Start a new GUI question
2. Select source table
3. Disable network
4. Click ""preview"" button

There's an API error and preview will stay in a loading state indefinitely.

### Expected behavior

API errors should be shown. Loading state should not be displayed

### Information about your Metabase installation

master, bee426d232

### Severity

P3",kamilmielnik,2024-03-28 12:30:35+00:00,[],2024-04-05 15:42:11+00:00,2024-04-05 15:42:11+00:00,https://github.com/metabase/metabase/issues/40724,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2033788413, 'issue_id': 2213123159, 'author': 'kamilmielnik', 'body': ""Partially duplicate of #40608.\r\n#40609 fixes #40608, so I'll rename this issue to be about error not being handled only."", 'created_at': datetime.datetime(2024, 4, 3, 7, 43, 6, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-04-03 07:43:06 UTC): Partially duplicate of #40608.
#40609 fixes #40608, so I'll rename this issue to be about error not being handled only.

"
2213050470,issue,closed,not_planned,"Inconsistent Behavior: ""Is not empty"" Filter Shows Empty Results for datetime fields","### Describe the bug

When applying the ""Is not empty"" filter on a datetime field, the results are inconsistent and shows rows with ""empty"" fields.

### To Reproduce

1. Open a question with a datetime containing both empty and non-empty values.
2. Click the filter dropdown for the desired field.
3. Select the ""Exclude"" option.
4. Select the ""Is not empty"" option.
5. Observe that it shows the ""empty"" rows.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-CA"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:123.0) Gecko/20100101 Firefox/123.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-163-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.2 (Debian 15.2-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Medium

### Additional context

![image](https://github.com/metabase/metabase/assets/15375579/979e4610-9986-415c-a278-0bbf6efab9f2)
",mrp97,2024-03-28 12:02:21+00:00,[],2024-07-19 15:18:03+00:00,2024-07-11 12:29:03+00:00,https://github.com/metabase/metabase/issues/40723,"[('.Product Input Needed', ''), ('.Team/Querying', '')]","[{'comment_id': 2222366874, 'issue_id': 2213050470, 'author': 'nemanjaglumac', 'body': '@mrp97 you chose to **exclude** (repro step 3) non-empty fields (repro step 4).\r\nThe result will show empty rows.\r\n\r\nDid you mean to exclude the empty fields instead?', 'created_at': datetime.datetime(2024, 7, 11, 8, 43, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222808752, 'issue_id': 2213050470, 'author': 'nemanjaglumac', 'body': ""I think it's safe to close this issue because:\r\n1. the OP described the expected behavior\r\n2. we have A LOT of E2E tests that cover this\r\n\r\nhttps://github.com/metabase/metabase/blob/e62d098b6d544fef2aa1d28e556767cc71be2e03/e2e/test/scenarios/filters/filter-types.cy.spec.js#L306-L375\r\n\r\n@mrp97 if I misunderstood you, please let me know or provide some additional details and we can reopen the issue."", 'created_at': datetime.datetime(2024, 7, 11, 12, 29, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2239440924, 'issue_id': 2213050470, 'author': 'mrp97', 'body': '> I think it\'s safe to close this issue because:\r\n> \r\n>     1. the OP described the expected behavior\r\n> \r\n>     2. we have A LOT of E2E tests that cover this\r\n> \r\n> \r\n> https://github.com/metabase/metabase/blob/e62d098b6d544fef2aa1d28e556767cc71be2e03/e2e/test/scenarios/filters/filter-types.cy.spec.js#L306-L375\r\n> \r\n> @mrp97 if I misunderstood you, please let me know or provide some additional details and we can reopen the issue.\r\n\r\n@nemanjaglumac Actually I was wrong! Everything worked properly. It was a mistake by me that I clicked on the ""Exclude"" options!\r\n\r\nMaybe it\'s a UX concern. For me finding rows where those specific field is ""Non Empty"" is important, so I should ""Exclude Empty"" rows. It confused me at first. By the way thanks for your follow up and I\'m sorry for the mistake!', 'created_at': datetime.datetime(2024, 7, 19, 15, 18, 2, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-11 08:43:45 UTC): @mrp97 you chose to **exclude** (repro step 3) non-empty fields (repro step 4).
The result will show empty rows.

Did you mean to exclude the empty fields instead?

nemanjaglumac on (2024-07-11 12:29:03 UTC): I think it's safe to close this issue because:
1. the OP described the expected behavior
2. we have A LOT of E2E tests that cover this

https://github.com/metabase/metabase/blob/e62d098b6d544fef2aa1d28e556767cc71be2e03/e2e/test/scenarios/filters/filter-types.cy.spec.js#L306-L375

@mrp97 if I misunderstood you, please let me know or provide some additional details and we can reopen the issue.

mrp97 (Issue Creator) on (2024-07-19 15:18:02 UTC): @nemanjaglumac Actually I was wrong! Everything worked properly. It was a mistake by me that I clicked on the ""Exclude"" options!

Maybe it's a UX concern. For me finding rows where those specific field is ""Non Empty"" is important, so I should ""Exclude Empty"" rows. It confused me at first. By the way thanks for your follow up and I'm sorry for the mistake!

"
2212962311,issue,closed,completed,"Migrate global css in `frontend/src/metabase/components/Popover/Popover.module.css`, `frontend/src/metabase/css/components/tippy.module.css`","```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/40730
- [x] `frontend/src/metabase/css/components/tippy.module.css` - 3rd party classes don't need migration
```
",WiNloSt,2024-03-28 11:17:14+00:00,['WiNloSt'],2024-04-02 13:41:38+00:00,2024-04-02 13:41:37+00:00,https://github.com/metabase/metabase/issues/40722,[],[],
2212844800,issue,closed,completed,Questions and Models (integrate `QuestionPicker` component),"Depends on #40207

- [x] do not show questions tab if there are no questions?
- [x] do not show models tab if there are no models?
- [x] handle `collectionId` prop
- [x] determine which tab to open initially (when editing, i.e. starting with initial value)
- [x] search for model + click",kamilmielnik,2024-03-28 10:16:50+00:00,['kamilmielnik'],2024-05-07 07:32:22+00:00,2024-05-07 07:32:22+00:00,https://github.com/metabase/metabase/issues/40719,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2097638510, 'issue_id': 2212844800, 'author': 'kamilmielnik', 'body': 'Closed by #42268', 'created_at': datetime.datetime(2024, 5, 7, 7, 32, 22, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-07 07:32:22 UTC): Closed by #42268

"
2212838657,issue,closed,completed,[Epic] Data picker,"**Links**
- parent epic: #35564
- [Product Doc](https://www.notion.so/metabase/Make-picking-an-item-a-nice-experience-with-an-EntityPicker-component-05e457c1b84f413f84ab9756e0c68b57)
- [Technical Design](https://www.notion.so/metabase/EntityPicker-Technical-Design-d4483523312e46c38ffd0bfe9c2371c7)
- feature branch: `data-picker`
  - Epic PR: #41175

**Implementation Plan**

The first milestone is about implementing the data picker and using it in `DataStep` component.

```[tasklist]
### Milestone 1
- [ ] https://github.com/metabase/metabase/issues/40298
- [ ] https://github.com/metabase/metabase/issues/41182
- [ ] https://github.com/metabase/metabase/issues/40719
- [ ] https://github.com/metabase/metabase/pull/42315
- [ ] https://github.com/metabase/metabase/issues/41172
- [ ] https://github.com/metabase/metabase/issues/42335
```

```[tasklist]
### Milestone 2 - Use Data picker in other places
- [ ] https://github.com/metabase/metabase/issues/40952
- [ ] https://github.com/metabase/metabase/issues/42559
- [ ] https://github.com/metabase/metabase/issues/40953
- [ ] https://github.com/metabase/metabase/issues/42675
- [ ] https://github.com/metabase/metabase/pull/42825
```",kamilmielnik,2024-03-28 10:14:08+00:00,['kamilmielnik'],2024-05-17 13:11:30+00:00,2024-05-17 12:53:31+00:00,https://github.com/metabase/metabase/issues/40717,"[('.Frontend', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2212716911,issue,closed,completed,Advanced option to turn off syncing field values doesn't work,"### Describe the bug

In the database setting you have an 3 advanced options to control field values syncing. When you select ‚ÄúOnly when adding a new filter widget‚Äù or ‚ÄúNever, I‚Äôll do this manually if I need to‚Äù, the existing field values sync job should be removed. Right now the jobs are still there and sync will continue to happens

### To Reproduce

1. Go to Admin -> Database setting
2. Go down to ""Scanning field values"" and select ""Never, I'll do this manually if I need to""
3. Make this query:  ```select * from qrtz_triggers where trigger_name = 'metabase.task.update-field-values.trigger.<YOUR-DB-ID>';```. This should return nothing

### Expected behavior

There is no scheduled triggers for syncing field values

### Logs

_No response_

### Information about your Metabase installation

```JSON
master, and probably has been like this since forever
```


### Severity

unexpected behavior

### Additional context

_No response_",qnkhuat,2024-03-28 09:13:38+00:00,['qnkhuat'],2024-04-16 06:40:15+00:00,2024-04-15 14:20:44+00:00,https://github.com/metabase/metabase/issues/40715,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Administration/Metadata & Sync', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2024734635, 'issue_id': 2212716911, 'author': 'qnkhuat', 'body': 'Once we fix this, we need to ensure the existing triggers for databases that have enabled these options are also removed.', 'created_at': datetime.datetime(2024, 3, 28, 9, 16, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2042418538, 'issue_id': 2212716911, 'author': 'qnkhuat', 'body': ""State matrix mapping to its corresponding option name on FE.\r\n\r\n| Use cases                     | let user control scheduling | is_full_sync | is_on_demand | cache_field_values | metadata_sync_schedule | cache_field_values_schedule | sync_strategy        |\r\n|-------------------------------|-----------------------------|--------------|--------------|--------------------|------------------------|-----------------------------|----------------------|\r\n| Default                       | false                       | true         | false        | nil                | randomized             | randomized                  | auto_full_sync       |\r\n| Regularly on a schedule       | true                        | true         | false        | non-nil map        | user input             | user input                  | manual_full_sync     |\r\n| Only when adding a new filter | true                        | false        | true         | nil                | user input             | nil                         | manual_on_demand     |\r\n| Never, I'll do it manually    | true                        | false        | false        | nil                | user input             | nil                         | manual_metadata_only |"", 'created_at': datetime.datetime(2024, 4, 8, 10, 40, 23, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-03-28 09:16:13 UTC): Once we fix this, we need to ensure the existing triggers for databases that have enabled these options are also removed.

qnkhuat (Issue Creator) on (2024-04-08 10:40:23 UTC): State matrix mapping to its corresponding option name on FE.

| Use cases                     | let user control scheduling | is_full_sync | is_on_demand | cache_field_values | metadata_sync_schedule | cache_field_values_schedule | sync_strategy        |
|-------------------------------|-----------------------------|--------------|--------------|--------------------|------------------------|-----------------------------|----------------------|
| Default                       | false                       | true         | false        | nil                | randomized             | randomized                  | auto_full_sync       |
| Regularly on a schedule       | true                        | true         | false        | non-nil map        | user input             | user input                  | manual_full_sync     |
| Only when adding a new filter | true                        | false        | true         | nil                | user input             | nil                         | manual_on_demand     |
| Never, I'll do it manually    | true                        | false        | false        | nil                | user input             | nil                         | manual_metadata_only |

"
2212682892,issue,closed,not_planned,point map not showing in static embedding on METABASE CLOUD,"**Describe the bug**
point map not showing in static embedding on metabase cloud

**Logs**
```
[c6798e9b-c5aa-4573-bbc8-52175b19bd82] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/205/132/45706/45719 401 119.0 ¬µs (0 DB calls) 
""Unauthenticated""

[987394a2-6c42-4a80-b727-7cfb22c93180] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/206/132/45706/45719 401 95.5 ¬µs (0 DB calls) 
""Unauthenticated""

[c6798e9b-c5aa-4573-bbc8-52175b19bd82] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/205/133/45706/45719 401 70.5 ¬µs (0 DB calls) 
""Unauthenticated""

[987394a2-6c42-4a80-b727-7cfb22c93180] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/206/133/45706/45719 401 80.6 ¬µs (0 DB calls) 
""Unauthenticated""

[c6798e9b-c5aa-4573-bbc8-52175b19bd82] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/204/132/45706/45719 401 75.2 ¬µs (0 DB calls) 
""Unauthenticated""

[987394a2-6c42-4a80-b727-7cfb22c93180] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/207/132/45706/45719 401 45.9 ¬µs (0 DB calls) 
""Unauthenticated""

[c6798e9b-c5aa-4573-bbc8-52175b19bd82] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/204/133/45706/45719 401 61.6 ¬µs (0 DB calls) 
""Unauthenticated""

[987394a2-6c42-4a80-b727-7cfb22c93180] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/207/133/45706/45719 401 39.6 ¬µs (0 DB calls) 
""Unauthenticated""

[c6798e9b-c5aa-4573-bbc8-52175b19bd82] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/203/132/45706/45719 401 115.2 ¬µs (0 DB calls) 
""Unauthenticated""

[987394a2-6c42-4a80-b727-7cfb22c93180] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/208/132/45706/45719 401 43.4 ¬µs (0 DB calls) 
""Unauthenticated""

[c6798e9b-c5aa-4573-bbc8-52175b19bd82] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/203/133/45706/45719 401 64.0 ¬µs (0 DB calls) 
""Unauthenticated""

[987394a2-6c42-4a80-b727-7cfb22c93180] 2024-03-28T15:47:13+07:00 DEBUG metabase.server.middleware.log GET /api/tiles/8/208/133/45706/45719 401 57.4 ¬µs (0 DB calls) 
""Unauthenticated""
```

**To Reproduce**
Steps to reproduce the behavior:
1. make dashboard with point map
2. publish static embedding
3. open dashboard with published link
4. map not showing

**Expected behavior**
<img width=""1472"" alt=""Screenshot 2024-03-28 at 15 51 33"" src=""https://github.com/metabase/metabase/assets/10842521/5b3d5db3-ea62-406c-9803-760d34e13455"">


**Screenshots**
https://klikpeta.metabaseapp.com/public/dashboard/b8126c9b-7522-484d-962d-03f889b78a97
<img width=""1494"" alt=""Screenshot 2024-03-28 at 15 53 41"" src=""https://github.com/metabase/metabase/assets/10842521/65bc2ad7-84ef-4336-bc22-cc71a927b860"">

**Severity**
super annoying


**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Safari/605.1.15"",
    ""vendor"": ""Apple Computer, Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.209-198.812.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-22"",
      ""tag"": ""v1.48.7"",
      ""hash"": ""c192db1""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Jakarta""
    }
  }
}
```",mfhanif,2024-03-28 08:55:27+00:00,[],2024-03-28 14:31:21+00:00,2024-03-28 11:44:20+00:00,https://github.com/metabase/metabase/issues/40714,[],"[{'comment_id': 2024986335, 'issue_id': 2212682892, 'author': 'paoliniluis', 'body': 'This is a duplicate of https://github.com/metabase/metabase/issues/9420, please contact support so we can tag this to your account and prioritize', 'created_at': datetime.datetime(2024, 3, 28, 11, 44, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2025352134, 'issue_id': 2212682892, 'author': 'mfhanif', 'body': 'I did contact [help@metabase.com](mailto:help@metabase.com) but no luck. Is there any other contact?', 'created_at': datetime.datetime(2024, 3, 28, 14, 31, 9, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-28 11:44:20 UTC): This is a duplicate of https://github.com/metabase/metabase/issues/9420, please contact support so we can tag this to your account and prioritize

mfhanif (Issue Creator) on (2024-03-28 14:31:09 UTC): I did contact [help@metabase.com](mailto:help@metabase.com) but no luck. Is there any other contact?

"
2212598465,issue,closed,completed,Visualization differs after converting question with aggregation and breakout to SQL,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/f7227e23-314e-4f23-9db8-03f7b066aa9f



### To Reproduce

1. Start a new question based on Orders table from Sample DB
2. Summarize ""Cumulative count of rows"" by ""Created At: Month""
3. Visualize it, remember the shape of the chart
4. Go back to notebook editor
5. Convert this question to SQL
6. Visualize it



### Expected behavior

Visualization should look the same as before converting the question to SQL


### Information about your Metabase installation

master, 7efd8d3627


### Severity

P2
",kamilmielnik,2024-03-28 08:03:40+00:00,['camsaul'],2024-08-28 02:10:37+00:00,2024-04-05 20:03:26+00:00,https://github.com/metabase/metabase/issues/40711,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Native', 'The SQL/native query editor'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2031850454, 'issue_id': 2212598465, 'author': 'darksciencebase', 'body': '(rerouting; [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1711613293992959))', 'created_at': datetime.datetime(2024, 4, 2, 11, 57, 32, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-04-02 11:57:32 UTC): (rerouting; [thread](https://metaboat.slack.com/archives/C0641E4PB9B/p1711613293992959))

"
2212162603,issue,closed,not_planned,why execute update sql every five minutes?,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/64348131/a301ec0e-c1c8-4563-9f63-1c7662034fb6)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

if will stop sometimes

### Logs

```
UPDATE `metabase_field` `f`
	INNER JOIN (
		SELECT MIN(`f`.`id`) AS `id`
		FROM `metabase_field` `f`
			INNER JOIN `metabase_table` `t` ON `f`.`table_id` = `t`.`id`
		WHERE (`t`.`db_id` = 67)
			AND (LOWER(`f`.`name`) = 'addedby_id')
			AND (LOWER(`t`.`name`) = 'dataintegritymodel')
			AND (LOWER(`t`.`schema`) IS NULL)
			AND (`f`.`active` = true)
			AND (`f`.`visibility_type` <> 'retired')
			AND (`t`.`active` = true)
			AND (`t`.`visibility_type` IS NULL)
	) `fk`
	ON `fk`.`id` = `f`.`id`
	INNER JOIN (
		SELECT MIN(`f`.`id`) AS `id`
		FROM `metabase_field` `f`
			INNER JOIN `metabase_table` `t` ON `f`.`table_id` = `t`.`id`
		WHERE (`t`.`db_id` = 67)
			AND (LOWER(`f`.`name`) = 'id')
			AND (LOWER(`t`.`name`) = 'user')
			AND (LOWER(`t`.`schema`) IS NULL)
			AND (`f`.`active` = true)
			AND (`f`.`visibility_type` <> 'retired')
			AND (`t`.`active` = true)
			AND (`t`.`visibility_type` IS NULL)
	) `pk`
	ON `f`.`fk_target_field_id` IS NULL
		OR `f`.`fk_target_field_id` <> `pk`.`id`
SET `fk_target_field_id` = `pk`.`id`, `semantic_type` = 'type/FK'
```

### Information about your Metabase installation

```JSON
v0.49.0
```


### Severity

info

### Additional context

_No response_",Danny5487401,2024-03-28 01:24:34+00:00,[],2024-06-20 16:25:25+00:00,2024-06-20 16:25:25+00:00,https://github.com/metabase/metabase/issues/40709,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('.Unable to Reproduce', ''), ('.Backend', '')]","[{'comment_id': 2024503091, 'issue_id': 2212162603, 'author': 'qnkhuat', 'body': ""@Danny5487401 this was triggered by our sync process. Not sure why it's being triggered every 5 minutes.\r\n\r\nCould you run this query to get the sync schedule info? \r\n```sql\r\nselect metadata_sync_schedule  from metabase_database where id = <YOUR DB ID>;\r\n```"", 'created_at': datetime.datetime(2024, 3, 28, 6, 38, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2069185988, 'issue_id': 2212162603, 'author': 'darksciencebase', 'body': '@Danny5487401 have you had a chance to try out the query that @qnkhuat posted above?', 'created_at': datetime.datetime(2024, 4, 22, 11, 44, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2181091967, 'issue_id': 2212162603, 'author': 'paoliniluis', 'body': 'Closing due to non response', 'created_at': datetime.datetime(2024, 6, 20, 16, 25, 25, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-03-28 06:38:34 UTC): @Danny5487401 this was triggered by our sync process. Not sure why it's being triggered every 5 minutes.

Could you run this query to get the sync schedule info? 
```sql
select metadata_sync_schedule  from metabase_database where id = <YOUR DB ID>;
```

darksciencebase on (2024-04-22 11:44:58 UTC): @Danny5487401 have you had a chance to try out the query that @qnkhuat posted above?

paoliniluis on (2024-06-20 16:25:25 UTC): Closing due to non response

"
2212134956,issue,closed,not_planned,Binning is broken,"### Describe the bug

Auto-binning is not helpful and setting the arbitrary bins count doesn't work

### To Reproduce

1. Go to New question
2. Choose Sample Database -> Accounts
3. Summarize Count by Seats
4. Visualize. You'll see 5 bins with 99% of values in the 1st bin:
<img width=""1477"" alt=""Captura de ecraÃÉ 2024-03-28, aÃÄs 00 31 29"" src=""https://github.com/metabase/metabase/assets/777800/fc7210a1-9f35-4812-843c-8265a9c26c71"">

5. Open the editor again
6. Choose 100 bins as binning for Seats
7. Visualize. You'll see 26 bins, which is a bit more useful, but it's not 100:
<img width=""1474"" alt=""Captura de ecraÃÉ 2024-03-28, aÃÄs 00 34 42"" src=""https://github.com/metabase/metabase/assets/777800/9ae06599-703b-40b9-942f-feed8604f729"">


### Expected behavior

When you set arbitrary amount of bins you should get the exact amount of bins you've set.
When you keep auto-binning it should choose the minimum amount of bins needed to have not more than 50% of the total in each of the bins (but not more than 100 bins).

### Logs

_No response_

### Information about your Metabase installation

```JSON
last version
```


### Severity

Very annoying, you have to set it to ""don't bin"" every time

### Additional context

_No response_",mngr,2024-03-28 00:47:14+00:00,[],2024-03-28 08:28:39+00:00,2024-03-28 08:28:38+00:00,https://github.com/metabase/metabase/issues/40708,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', '')]","[{'comment_id': 2024215177, 'issue_id': 2212134956, 'author': 'paoliniluis', 'body': 'Isn‚Äôt this a duplicate of https://github.com/metabase/metabase/issues/12004?', 'created_at': datetime.datetime(2024, 3, 28, 0, 54, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024319167, 'issue_id': 2212134956, 'author': 'ojjj13', 'body': 'You might get a more meaningful result if you choose x-axis to be linear and set up a filter, say < 200 in your case.', 'created_at': datetime.datetime(2024, 3, 28, 3, 11, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024659691, 'issue_id': 2212134956, 'author': 'ranquild', 'body': 'Duplicate https://github.com/metabase/metabase/issues/12004', 'created_at': datetime.datetime(2024, 3, 28, 8, 28, 39, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-28 00:54:09 UTC): Isn‚Äôt this a duplicate of https://github.com/metabase/metabase/issues/12004?

ojjj13 on (2024-03-28 03:11:46 UTC): You might get a more meaningful result if you choose x-axis to be linear and set up a filter, say < 200 in your case.

ranquild on (2024-03-28 08:28:39 UTC): Duplicate https://github.com/metabase/metabase/issues/12004

"
2211997462,issue,closed,completed,LDAP no longer works on OSS,"### Describe the bug

A new enterprise feature was added to disable automatic user provisioning. This new setting is present in the OSS admin UI so attempts to configure LDAP send a value over for the enterprise feature. The backend throws an error about an unknown setting.

### To Reproduce

![image](https://github.com/metabase/metabase/assets/6377293/64bf55e6-17d6-4f76-a35e-ff010eff6207)


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
0.49.1
```


### Severity

p1

### Additional context

_No response_",dpsutton,2024-03-27 22:18:00+00:00,['sloansparger'],2024-03-27 22:20:04+00:00,2024-03-27 22:18:12+00:00,https://github.com/metabase/metabase/issues/40704,"[('Type:Bug', 'Product defects'), ('Administration/Auth', 'Google Auth, LDAP, pw+email login'), ('Administration/', ''), ('Administration/Settings', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2024084562, 'issue_id': 2211997462, 'author': 'dpsutton', 'body': 'closed by https://github.com/metabase/metabase/pull/40685', 'created_at': datetime.datetime(2024, 3, 27, 22, 18, 12, tzinfo=datetime.timezone.utc)}]","dpsutton (Issue Creator) on (2024-03-27 22:18:12 UTC): closed by https://github.com/metabase/metabase/pull/40685

"
2211717513,issue,closed,completed,Keep native query preview sidebar in place while scrolling notebook steps,"AS @kamilmielnik noted in [this comment](https://github.com/metabase/metabase/pull/40595#discussion_r1538800534), a combination of certain screen sizes and very long multi-step queries might result in a native query preview sidebar content being unaccessible.

Here's a video from Kamil's comment that illustrates this behavior.
https://github.com/metabase/metabase/assets/6830683/b79d66dd-44d2-4a9f-bc92-67e9252a1d5a

The goal of this task is to prevent it.
",nemanjaglumac,2024-03-27 19:16:01+00:00,['nemanjaglumac'],2024-04-02 17:42:58+00:00,2024-04-02 17:42:58+00:00,https://github.com/metabase/metabase/issues/40697,"[('.CSS', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2211698238,issue,closed,completed,Dashcards from other tabs show up in the first one after entering and leaving editing mode,"### Describe the bug

If a dashboard has at least two tabs with cards on them, it's possible that cards from Tab B would show up in Tab A after entering and exiting editing mode

### To Reproduce

1. Create a dashboard with two tabs, one question per tab
2. Enter dashboard editing mode and leave it right away
3. Card from ""Tab 2"" can show up in ""Tab 1""


### Expected behavior

Tabs should only show their cards

### Logs

_No response_

### Information about your Metabase installation

```JSON
x.49.0
```


### Severity

P2/P3

### Additional context

_No response_",kulyk,2024-03-27 19:07:34+00:00,['kulyk'],2024-03-29 13:08:46+00:00,2024-03-28 00:07:50+00:00,https://github.com/metabase/metabase/issues/40695,"[('Priority:P2', 'Average run of the mill bug'), ('Reporting/Dashboards', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2211422438,issue,open,,Create indexes for Models in Mysql,"**Is your feature request related to a problem? Please describe.**
Models in Metabase could be way faster with indexes.


I use models with cache database to create ""sort of"" materialized views, the table created could be quite big and request against these models could be really slow (even slower than on the mysql main database) because there is no index on these tables. 

**Describe the solution you'd like**
You could create at least one index per column for all models, it will solve a lot of speed problems with models. 

**Describe alternatives you've considered**
Run a shell script that manually create these indexes after each model refresh using a cron.

**How important is this feature to you?**
I think Metabase is mostly used with SQL databases by small to medium companies. This kind of small improvement could be really usefull for all of us.

**Additional context**
An other quick win improvement with mysql :  [here](https://github.com/metabase/metabase/issues/39621) ",prigal,2024-03-27 17:49:25+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/40691,"[('Database/MySQL', None), ('Querying/Models', 'aka Datasets'), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2212610701, 'issue_id': 2211422438, 'author': 'OxanaMD', 'body': 'Upvoting, would help a ton!\r\n\r\n> I think Metabase is mostly used with SQL databases by small to medium companies. This kind of small improvement could be really usefull for all of us.\r\n\r\nHard plus! We are using postgres', 'created_at': datetime.datetime(2024, 7, 7, 23, 14, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2268549061, 'issue_id': 2211422438, 'author': 'usmk', 'body': ""That's really big issue. Please, solve it a.s.a.p, it's hard to work with big data!!!"", 'created_at': datetime.datetime(2024, 8, 5, 9, 5, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2268589157, 'issue_id': 2211422438, 'author': 'OxanaMD', 'body': ""> That's really big issue. Please, solve it a.s.a.p, it's hard to work with big data!!!\r\n\r\n@usmk upvote the issue (üëçüèº) and ask your team members to do so too."", 'created_at': datetime.datetime(2024, 8, 5, 9, 21, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269779536, 'issue_id': 2211422438, 'author': 'paoliniluis', 'body': 'workaround: use a data pipeline that will do the same thing as Metabase does but programmatically + creating the indexes', 'created_at': datetime.datetime(2024, 8, 5, 19, 39, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575695956, 'issue_id': 2211422438, 'author': 'thebiglabasky', 'body': ""Quick question to verify my assumption: is it because you can't create missing indexes straight in the source database? Or is it that you're persisting data through models and those are filtering the source data in a way which would require each model to have potentially different indices?\nAsking since the easiest solution is sometimes to create the index at the source."", 'created_at': datetime.datetime(2025, 1, 7, 16, 16, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576926701, 'issue_id': 2211422438, 'author': 'prigal', 'body': ""I use models, data is persisted by metabase in the cache db but no index is\r\ncreated on the model's table.\r\n\r\nLe mar. 7 janv. 2025, 17:16, Herv√© Labas ***@***.***> a\r\n√©crit :\r\n\r\n> Quick question to verify my assumption: is it because you can't create\r\n> missing indexes straight in the source database? Or is it that you're\r\n> persisting data through models and those are filtering the source data in a\r\n> way which would require each model to have potentially different indices?\r\n> Asking since the easiest solution is sometimes to create the index at the\r\n> source.\r\n>\r\n> ‚Äî\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/40691#issuecomment-2575695956>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAG2SIZOAKWU7WR5PZLEUHD2JP4VRAVCNFSM6AAAAABFLLD3PCVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDKNZVGY4TKOJVGY>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2025, 1, 8, 7, 28, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616156120, 'issue_id': 2211422438, 'author': 'ixipixi', 'body': '@thebiglabasky the tables that house the persisted data are dropped during the model refresh tasks. So if you persist model data and create indexes manually - they are lost each time Metabase refreshes the persisted data.', 'created_at': datetime.datetime(2025, 1, 27, 16, 0, 42, tzinfo=datetime.timezone.utc)}]","OxanaMD on (2024-07-07 23:14:50 UTC): Upvoting, would help a ton!


Hard plus! We are using postgres

usmk on (2024-08-05 09:05:05 UTC): That's really big issue. Please, solve it a.s.a.p, it's hard to work with big data!!!

OxanaMD on (2024-08-05 09:21:31 UTC): @usmk upvote the issue (üëçüèº) and ask your team members to do so too.

paoliniluis on (2024-08-05 19:39:07 UTC): workaround: use a data pipeline that will do the same thing as Metabase does but programmatically + creating the indexes

thebiglabasky on (2025-01-07 16:16:01 UTC): Quick question to verify my assumption: is it because you can't create missing indexes straight in the source database? Or is it that you're persisting data through models and those are filtering the source data in a way which would require each model to have potentially different indices?
Asking since the easiest solution is sometimes to create the index at the source.

prigal (Issue Creator) on (2025-01-08 07:28:25 UTC): I use models, data is persisted by metabase in the cache db but no index is
created on the model's table.

Le mar. 7 janv. 2025, 17:16, Herv√© Labas ***@***.***> a
√©crit :

ixipixi on (2025-01-27 16:00:42 UTC): @thebiglabasky the tables that house the persisted data are dropped during the model refresh tasks. So if you persist model data and create indexes manually - they are lost each time Metabase refreshes the persisted data.

"
2211264995,issue,closed,not_planned,Unable to Filter Array Column - Postgres,"### Describe the bug

Attempting to filter an array column on Postgres results in error:
![image](https://github.com/metabase/metabase/assets/90083658/923fda87-3489-4f37-b743-6e1dab42e75d)


### To Reproduce

Attempt to filter a column defined as `VARCHAR[]`.
Note that in my case, the column is created in a view with `ARRAY_AGG()`. Not sure if that matters.


### Expected behavior

The filter should not cause error

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:123.0) Gecko/20100101 Firefox/123.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.55-75.123.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Low

### Additional context

_No response_",MrChadMWood,2024-03-27 16:34:54+00:00,[],2024-03-27 16:36:44+00:00,2024-03-27 16:36:43+00:00,https://github.com/metabase/metabase/issues/40688,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2023242162, 'issue_id': 2211264995, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/18108', 'created_at': datetime.datetime(2024, 3, 27, 16, 36, 43, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-27 16:36:43 UTC): duplicate of https://github.com/metabase/metabase/issues/18108

"
2211185263,issue,open,,Select Multiple Values in Custom Dropdown Filters for SQL Questions,"**Is your feature request related to a problem? Please describe.**
I have a dashboard where I compute some metrics according to some filters, using BigQuery as a data source. These metrics are computed using different denormalized tables that contain a category column with the values I need to filter with. Since these are different tables, I haven't been able to use **field filters** since they wouldn't work across different tables without making a join for each filter. I am trying to use a **custom dropdown** populated with data from other questions. 

One issue I am facing is that with this method it seems impossible to select multiple values from the dropdown. Assume I have the following query:

```
SELECT
  *
FROM
  `dataset.table`
WHERE
  TRUE [[and `dataset.table`.`column` IN {{filter}}]] 
LIMIT 10
```

No matter the selection between Dropdown list, Search box and Input box, whenever I try to link the dashboard filter to this question, the Multiple Values/Single Values option in the filter disappear and I can only choose one value at the time, preventing me from filtering on multiple values.

**Describe the solution you'd like**
It would help greatly if the dropdown filters allowed the selection of multiple values when linked to SQL Questions. For example, the filter could output a list of strings or numbers, with or without parenthesis `('a', 'b', 'c', ...)` that could then be used to filter with an `IN` clause, which I believe is in most SQL dialects.

**Describe alternatives you've considered**
I think I might be able to use an input box, where a user could write manually the list of filter, for example `a,b,c,...` which I could then split into individual strings and put in an `IN` clause. The downside is that the user might not know the specific name of the filter beforehand, and is a rather manual task.

I am also not sure if this is just a limitation of SQL questions or also of GUI questions, but I take not. I am still not 100% familiar with GUI questions and a lot of these queries are complex and easier for me to write in SQL with BQ functions, so I'm not sure conversion to GUI questions would help.

I've considered making views in BQ to simplify the queries and use field filters or GUI questions, but it wouldn't help much since these metrics are computed on the fly on the slice of data that is put in the filters.

**How important is this feature to you?**
Quite important, currently we have a dashboard in Grafana that allow us to filter by multiple fields, and since these filters have a lot of values users usually select a couple of them and see the metrics only for those filters.

**Related issues**
https://github.com/metabase/metabase/issues/29997 - This I guess is the reason why Multiple Values dont work
",nhabbash,2024-03-27 16:00:15+00:00,[],2025-02-04 20:31:05+00:00,,https://github.com/metabase/metabase/issues/40684,"[('Type:New Feature', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor')]",[],
2211078327,issue,closed,not_planned,Â∑≤ÂΩíÊ°£ÁöÑÈõÜÂêà‰∏çËÉΩÂà†Èô§,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/49431955/6d5de072-14d6-4e7a-82c6-ff574beec107)
![image](https://github.com/metabase/metabase/assets/49431955/805f4df9-87bb-4517-88e9-fef90d812781)


### To Reproduce

Âú®Âà†Èô§Â∑≤ÂΩíÊ°£ÁöÑÈõÜÂêàÊó∂ÂÄôÔºåÁÇπÂáªÂà†Èô§Êä•Èîô‰∫Ü

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
docker metabase/metabase:v0.49.1
```


### Severity

ÂéÜÂè≤ÂΩíÊ°£Êó†Ê≥ïÂà†Èô§

### Additional context

_No response_",bold-rabbit,2024-03-27 15:15:40+00:00,[],2024-03-27 15:49:11+00:00,2024-03-27 15:49:11+00:00,https://github.com/metabase/metabase/issues/40680,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2023111551, 'issue_id': 2211078327, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/18372', 'created_at': datetime.datetime(2024, 3, 27, 15, 49, 11, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-27 15:49:11 UTC): duplicate of https://github.com/metabase/metabase/issues/18372

"
2210992075,issue,closed,completed,Hide Error Diagnostic modal + triggers in all embedding contexts,,iethree,2024-03-27 14:41:37+00:00,['iethree'],2024-05-14 15:36:18+00:00,2024-05-14 15:36:17+00:00,https://github.com/metabase/metabase/issues/40677,"[('Embedding/', 'Use this label when unsure which flavor of embedding is impacted')]",[],
2210952152,issue,open,,Table Metadata having 2 FKs from the same table pointing to another table will implicitly show the 1st FK in the UI,"### Describe the bug

Both the `FIRST_NAME ` and `LAST_NAME` in the `Accounts` table are set up as Foreign Keys to `NAME` in the `People` table.

When we select this join key, we get `FIRST_NAME ID` as default, which is fine, since it is also defined as a FK. However, even after changing it manually to `LAST_NAME ID`, the `Summarize` section will show `User - FIRST_NAME`.

Results wise the JOIN seems to still be applied on the LAST_NAME but visually is confusing 

### To Reproduce

1. Go to Admin -> Table Metadata -> Sample DB -> Accounts -> Set the FIRST_NAME and LAST_NAME as Foreign Key to Name in the People Table

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/a1b96f87-d955-4fe4-84a9-5f468ebc6acd"">

2. Go to New Question -> Accounts -> Joined with People on Last Name -> Count and Group by People Birth Date

<img width=""1497"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/c34f3823-a46c-4bad-9f08-f0d217805157"">

Notice how the FK you manually setup is being ignored and only the first FK is being shown in the aggreagte section. This is just a visual issue because also the SQL shows its picking the LAST_NAME and assigning it as First Name

<img width=""1503"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/2e713675-0ade-4880-b12b-b3d6fc76c115"">



### Expected behavior

The proper Foreign Key is shown in the aggregation based on what you are joining with

### Logs

None that are relevant

### Information about your Metabase installation

```JSON
1.49.1 and master
```


### Severity

Cosmetic issue but is very confusing when tables have multiple keys

### Additional context

_No response_",Tony-metabase,2024-03-27 14:26:06+00:00,[],2025-02-04 20:27:12+00:00,,https://github.com/metabase/metabase/issues/40676,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]",[],
2210950164,issue,closed,completed,Entity Picker Failed Request Error display,,iethree,2024-03-27 14:25:14+00:00,[],2024-04-01 14:00:45+00:00,2024-04-01 14:00:45+00:00,https://github.com/metabase/metabase/issues/40675,[],[],
2210879962,issue,closed,completed,Bigquery: Can't search field values for required partition tables,"### Describe the bug

When creating a question from a table that has a lot of rows (multiple 10.000s) and some filters of type ""Is""/""Is not"" on a same text column, the UI break and no data is being displayed. Instead a warning sign is showing with message ""Something's gone wrong"" when hovering. This happens both in the visualiser and editor modes (see screenshots below).

In my case I loaded 48 months of data partitions (with Dt = 48 last months) and had already set filters on column ""Type"" to not be ""BANK_DEPOSIT"" nor ""CARD"" and I was about to add another value to exclude. Please note that in the editor mode, even when the bug occur I can click the preview button next to the Filter section and see actual results, but the 3rd filter was not applied and the whole filter section is not showing anymore. It also sometimes happen when applying the first filter.

This bug appeared after updating from v0.48.3 to v0.49.1. I cannot give an exact threshold but it happens with tables that vae around 40.000 to 80.000 rows. Under 10.000 we don't seem to have this bug. In some cases we can use ""contains""/""does not contain"" and it will work, but for some other cases we want a specific filtering on the whole value and not just a substring.

In the visualiser mode the bug seems to not happen when creating filter by clicking on a cell and apply a ""Is"" or ""Is not"" on the cell's value. When creating the filter from the column header it almost always occurs on the first filter.

Visualiser mode:
<img width=""2558"" alt=""Screenshot 2024-03-27 at 14 26 42"" src=""https://github.com/metabase/metabase/assets/69579602/080dd671-5831-4b8f-9e2e-2090d804932e"">

Editor mode:
<img width=""1792"" alt=""Screenshot 2024-03-27 at 14 32 02"" src=""https://github.com/metabase/metabase/assets/69579602/dced9f9c-902c-406c-9ad4-830d6d5bcdfa"">


### To Reproduce

1. Create a question from a table that has a lot of rows (more than 10.000)

Either in editor mode or visualiser mode:
2. Apply 2 filters on a same column with parameter ""Is"" or ""Is not""
3. Apply a third filter with ""Is"" or ""Is not""
4. See the UI failing to display any data and not applying the later filter

### Expected behavior

I expect to be able to add as many filters I want to a same column.

### Logs

```
[a76dbbcd-e5eb-4647-9e35-862bcc736a63] 2024-03-27T14:42:27+01:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: 400 Bad Request
POST https://www.googleapis.com/bigquery/v2/projects/<project_name>/queries
{
  ""code"": 400,
  ""errors"": [
    {
      ""domain"": ""global"",
      ""location"": ""q"",
      ""locationType"": ""parameter"",
      ""message"": ""Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination"",
      ""reason"": ""invalidQuery""
    }
  ],
  ""message"": ""Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination"",
  ""status"": ""INVALID_ARGUMENT""
}
{:database_id 2,
 :started_at #t ""2024-03-27T13:42:27.200380860Z[Etc/UTC]"",
 :via
 [{:status :failed,
   :class com.google.cloud.bigquery.BigQueryException,
   :error
   ""Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination"",
   :stacktrace
   [""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:114)""
    ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:728)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
    ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
    ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
    ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__128578.invoke(bigquery_cloud_sdk.clj:343)""]}
  {:status :failed,
   :class java.util.concurrent.ExecutionException,
   :error
   ""com.google.cloud.bigquery.BigQueryException: Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination"",
   :stacktrace
   [""java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)""
    ""java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)""
    ""clojure.core$deref_future.invokeStatic(core.clj:2317)""
    ""clojure.core$future_call$reify__8544.deref(core.clj:7042)""
    ""clojure.core$deref.invokeStatic(core.clj:2337)""
    ""clojure.core$deref.invoke(core.clj:2323)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:331)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:327)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:371)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:369)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__128622.invoke(bigquery_cloud_sdk.clj:419)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:427)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:412)""
    ""driver.bigquery_cloud_sdk$fn__128629.invokeStatic(bigquery_cloud_sdk.clj:448)""
    ""driver.bigquery_cloud_sdk$fn__128629.invoke(bigquery_cloud_sdk.clj:440)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71992.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66378.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71813.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71823.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71255.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73137$combined_post_process__73142$combined_post_process_STAR___73143.invoke(query_processor.clj:262)""
    ""query_processor$fn__73137$combined_pre_process__73138$combined_pre_process_STAR___73139.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66475.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71903$fn__71907.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71903.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67081$fn__67082.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67081.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71900.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72205.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71840$handle_audit_app_internal_queries__71841$fn__71843.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71851.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70966.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72136.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72737.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62625$thunk__62627.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62625.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62637.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93630.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53145$fn__53147.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53145.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43756.invoke(streaming_response.clj:88)""]}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: com.google.cloud.bigquery.BigQueryException: Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination"",
   :stacktrace
   [""--> driver.bigquery_cloud_sdk$throw_invalid_query.invokeStatic(bigquery_cloud_sdk.clj:323)""
    ""driver.bigquery_cloud_sdk$throw_invalid_query.invoke(bigquery_cloud_sdk.clj:322)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:367)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:327)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:371)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:369)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__128622.invoke(bigquery_cloud_sdk.clj:419)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:427)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:412)""
    ""driver.bigquery_cloud_sdk$fn__128629.invokeStatic(bigquery_cloud_sdk.clj:448)""
    ""driver.bigquery_cloud_sdk$fn__128629.invoke(bigquery_cloud_sdk.clj:440)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71992.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66378.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71813.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71823.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71255.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73137$combined_post_process__73142$combined_post_process_STAR___73143.invoke(query_processor.clj:262)""
    ""query_processor$fn__73137$combined_pre_process__73138$combined_pre_process_STAR___73139.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66475.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71903$fn__71907.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71903.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67081$fn__67082.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67081.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71900.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72205.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71840$handle_audit_app_internal_queries__71841$fn__71843.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71851.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70966.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72136.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72737.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62625$thunk__62627.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62625.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62637.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93630.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53145$fn__53147.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53145.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43756.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:type :invalid-query,
    :sql
    ""-- Metabase:: userID: 5 queryType: MBQL queryHash: ace1a8506501d6f6f047d0b9fc33731f15926d7a0b7c98cf503090c3aeb863a6\nSELECT <`table_name`.`column` AS `column` for all columns> LIMIT 2000"",
    :parameters nil}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 2,
  :type ""query"",
  :query {:source-table 824},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT <table_name.column AS column> LIMIT 1048575"",
  :params nil,
  :table-name ""table_name"",
  :mbql? true},
 :status :failed,
 :class com.google.api.client.googleapis.json.GoogleJsonResponseException,
 :stacktrace
 [""com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest$3.interceptResponse(AbstractGoogleClientRequest.java:466)""
  ""com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:552)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:493)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:603)""
  ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:726)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
  ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
  ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
  ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
  ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__128578.invoke(bigquery_cloud_sdk.clj:343)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""400 Bad Request\nPOST https://www.googleapis.com/bigquery/v2/projects/<project_name>/queries\n{\n  \""code\"": 400,\n  \""errors\"": [\n    {\n      \""domain\"": \""global\"",\n      \""location\"": \""q\"",\n      \""locationType\"": \""parameter\"",\n      \""message\"": \""Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination\"",\n      \""reason\"": \""invalidQuery\""\n    }\n  ],\n  \""message\"": \""Cannot query over table 'datawarehouse.table_name' without a filter over column(s) 'dt' that can be used for partition elimination\"",\n  \""status\"": \""INVALID_ARGUMENT\""\n}"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 2,
  :type :query,
  :query
  {:source-table 824,
   :fields
   [[:field 15900 nil]
    [:field 15918 nil]
    [:field 15934 nil]
    [:field 15932 nil]
    [:field 15892 nil]
    [:field 15920 nil]
    [:field 15904 nil]
    [:field 15895 nil]
    [:field 21987 nil]
    [:field 15891 nil]
    [:field 21986 nil]
    [:field 15901 nil]
    [:field 15924 nil]
    [:field 15928 nil]
    [:field 15903 nil]
    [:field 15935 nil]
    [:field 15908 nil]
    [:field 33357 nil]
    [:field 15939 nil]
    [:field 15888 {:temporal-unit :default}]
    [:field 15905 {:temporal-unit :default}]
    [:field 15912 {:temporal-unit :default}]
    [:field 15926 nil]
    [:field 15938 nil]
    [:field 15890 nil]
    [:field 15907 nil]
    [:field 15936 nil]
    [:field 15931 nil]
    [:field 15927 nil]
    [:field 15937 nil]
    [:field 15898 nil]
    [:field 15933 nil]
    [:field 15915 nil]
    [:field 15911 nil]
    [:field 15917 nil]
    [:field 15930 nil]
    [:field 22888 nil]
    [:field 15916 nil]
    [:field 16817 nil]
    [:field 18897 nil]
    [:field 20900 nil]
    [:field 20901 nil]
    [:field 20902 nil]
    [:field 20741 nil]
    [:field 20742 {:temporal-unit :default}]
    [:field 27000 nil]
    [:field 30181 nil]
    [:field 27643 nil]
    [:field 27642 nil]
    [:field 27641 nil]
    [:field 27644 nil]
    [:field 27640 nil]
    [:field 31069 nil]
    [:field 30184 nil]
    [:field 30182 nil]
    [:field 31070 nil]
    [:field 15897 nil]
    [:field 15910 nil]
    [:field 15894 nil]
    [:field 15923 nil]
    [:field 15913 nil]
    [:field 15941 nil]
    [:field 15906 nil]
    [:field 15899 nil]
    [:field 15889 nil]
    [:field 15887 nil]
    [:field 15929 nil]
    [:field 15896 nil]
    [:field 15921 nil]
    [:field 15909 nil]
    [:field 15925 nil]
    [:field 15940 nil]
    [:field 15886 nil]
    [:field 15914 nil]
    [:field 15893 nil]
    [:field 15919 nil]
    [:field 15922 nil]
    [:field 21511 nil]
    [:field 30183 nil]
    [:field 30185 nil]
    [:field 15902 {:temporal-unit :default}]],
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 5, :context :ad-hoc}},
 :data {:rows [], :cols []}}
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""ANSI_X3.4-1968"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.10+7-Debian-1deb12u1"",
    ""java.vendor"": ""Debian"",
    ""java.vendor.url"": ""https://tracker.debian.org/openjdk-17"",
    ""java.version"": ""17.0.10"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.10+7-Debian-1deb12u1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.58+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking some users

### Additional context

Looking at the logs it seems that there's an issue with inferring the partitionning on our ""dt"" column even though there's an existing filter on dt = last 48 months given prior the bug occurs.",Timelessprod,2024-03-27 13:57:04+00:00,['qnkhuat'],2024-04-04 07:29:22+00:00,2024-04-03 15:27:26+00:00,https://github.com/metabase/metabase/issues/40673,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2024379665, 'issue_id': 2210879962, 'author': 'qnkhuat', 'body': '> Looking at the logs it seems that there\'s an issue with inferring the partitionning on our ""dt"" column even though there\'s an existing filter on dt = last 48 months given prior the bug occurs.\r\n\r\nnot sure how much you redacted, but looking at the query from the log:\r\n\r\n>   ""SELECT <table_name.column AS column> LIMIT 1048575"",\r\n\r\nI don\'t see the filter clause on the partitioned column anywhere. Did you have a filter on the partitioned column when you built the query? if yes, could you add the full native query that were executed, (with redacted info of course).\r\n\r\nAlso, I\'ve tried to reproduce with this table\r\n\r\n```sql\r\nCREATE TABLE big_table\r\n  (\r\n     id       INT64,\r\n     category STRING\r\n  )  \r\nPARTITION BY _PARTITIONDATE\r\nOPTIONS(require_partition_filter = TRUE);\r\n\r\nINSERT INTO big_table\r\n            (\r\n                        id,\r\n                        category\r\n            )\r\nSELECT id,\r\n       CASE\r\n              WHEN mod(id, 5) = 0 THEN \'A\'\r\n              WHEN mod(id, 5) = 1 THEN \'B\'\r\n              WHEN mod(id, 5) = 2 THEN \'C\'\r\n              WHEN mod(id, 5) = 3 THEN \'D\'\r\n              WHEN mod(id, 5) = 4 THEN \'E\'\r\n       END AS category\r\nFROM   (\r\n              SELECT row_number() OVER() AS id\r\n              FROM   unnest(generate_array(1, 50000)) ) \r\n```\r\ntried to add a few filters and it works fine\r\n![Screenshot 2024-03-28 at 11 32 25](https://github.com/metabase/metabase/assets/25661381/486acee5-266e-43bb-8c3b-37785f94d0ce)', 'created_at': datetime.datetime(2024, 3, 28, 4, 38, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024831467, 'issue_id': 2210879962, 'author': 'Timelessprod', 'body': 'Thanks for the feedback.\r\n\r\nOn my first screenshot the partition filter is visible, it\'s the ""Dt is in the previous 48 months"" (look on the top left corner) as this column represent the partition used on BigQuery. On the second screenshot, it is not visible because the bug makes the whole filter section of the editor disappearing.\r\n\r\nHere\'s the native query generated by Metabase in the bug case. I copied it from the editor mode just after the bug occured. For privacy reasons I give fake column names.\r\n\r\n```sql\r\nSELECT\r\n  `datawarehouse.tablename`.`column_1` AS `column_1`,\r\n  `datawarehouse.tablename`.`column_2` AS `column_2`,\r\n  `datawarehouse.tablename`.`column_3` AS `column_3`,\r\n  `datawarehouse.tablename`.`column_4` AS `column_4`,\r\n  -- [...]\r\n  `datawarehouse.tablename`.`column_78` AS `column_78`,\r\n  `datawarehouse.tablename`.`type` AS `type`,\r\n  `datawarehouse.tablename`.`dt` AS `dt`\r\nFROM\r\n  `datawarehouse.tablename`\r\nWHERE\r\n  (\r\n    `datawarehouse.tablename`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -48 month), month)\r\n  )\r\n   AND (\r\n    `datawarehouse.tablename`.`dt` < DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL 1 month), month)\r\n  )\r\nLIMIT\r\n  1048575\r\n  ```\r\n\r\nAnd we can see that the filter on column `type` that I wanted to add when the bug occured is not showing and that no filter at all is showing in the logs indeed.\r\n\r\nWe have it on multiple users and on different tables with filters on different columns but seems to be only text type column with ""Is"" or ""Is not"" filter categories.\r\n\r\nI hope these information help. Let me know if you need more context.', 'created_at': datetime.datetime(2024, 3, 28, 10, 7, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2025142354, 'issue_id': 2210879962, 'author': 'Timelessprod', 'body': ""I don't know the behavior of Metabase for this, but could it be that when we are typing the value for a text filter, Metabase tries to fetch the database for possible values in this fields (to proivide hints for the user in real time), but since it doesn't provide a Dt (partition) filter while doing this internal sub-query, it gets an error from the database server (BigQuery in my case) and don't handle it properly (by just not showing hints for possible values for example), causing the UI bug ?"", 'created_at': datetime.datetime(2024, 3, 28, 13, 6, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2025221154, 'issue_id': 2210879962, 'author': 'crisptrutski', 'body': 'This will need to be pushed out to 49.3 - we have a lot of important fixes pending and do not want to delay them further.', 'created_at': datetime.datetime(2024, 3, 28, 13, 42, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026557888, 'issue_id': 2210879962, 'author': 'qnkhuat', 'body': ""> I don't know the behavior of Metabase for this, but could it be that when we are typing the value for a text filter, Metabase tries to fetch the database for possible values in this fields (to proivide hints for the user in real time), but since it doesn't provide a Dt (partition) filter while doing this internal sub-query, it gets an error from the database server (BigQuery in my case) and don't handle it properly (by just not showing hints for possible values for example), causing the UI bug ?\r\n\r\n@Timelessprod you're absolutely correct ! the bug is in the query we make to search field values."", 'created_at': datetime.datetime(2024, 3, 29, 3, 21, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030926909, 'issue_id': 2210879962, 'author': 'qnkhuat', 'body': ""https://github.com/metabase/metabase/pull/40777 will fix the crashing issue. \r\n\r\nI'm working on https://github.com/metabase/metabase/pull/40767 to make the query return sensible field values.\r\n\r\nRemove from 49.3 milestone as this no longer is a regression."", 'created_at': datetime.datetime(2024, 4, 2, 1, 46, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036086042, 'issue_id': 2210879962, 'author': 'qnkhuat', 'body': 'The fix will be included in 49.4', 'created_at': datetime.datetime(2024, 4, 4, 2, 59, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036255417, 'issue_id': 2210879962, 'author': 'darksciencebase', 'body': '@qnkhuat do you mean 49.4? we released 49.3 already', 'created_at': datetime.datetime(2024, 4, 4, 6, 3, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036344129, 'issue_id': 2210879962, 'author': 'qnkhuat', 'body': 'yes. should be 49.4.', 'created_at': datetime.datetime(2024, 4, 4, 7, 0, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036396012, 'issue_id': 2210879962, 'author': 'Timelessprod', 'body': 'Perfect thank you very much for the fix!', 'created_at': datetime.datetime(2024, 4, 4, 7, 29, 21, tzinfo=datetime.timezone.utc)}]","qnkhuat (Assginee) on (2024-03-28 04:38:02 UTC): not sure how much you redacted, but looking at the query from the log:


I don't see the filter clause on the partitioned column anywhere. Did you have a filter on the partitioned column when you built the query? if yes, could you add the full native query that were executed, (with redacted info of course).

Also, I've tried to reproduce with this table

```sql
CREATE TABLE big_table
  (
     id       INT64,
     category STRING
  )  
PARTITION BY _PARTITIONDATE
OPTIONS(require_partition_filter = TRUE);

INSERT INTO big_table
            (
                        id,
                        category
            )
SELECT id,
       CASE
              WHEN mod(id, 5) = 0 THEN 'A'
              WHEN mod(id, 5) = 1 THEN 'B'
              WHEN mod(id, 5) = 2 THEN 'C'
              WHEN mod(id, 5) = 3 THEN 'D'
              WHEN mod(id, 5) = 4 THEN 'E'
       END AS category
FROM   (
              SELECT row_number() OVER() AS id
              FROM   unnest(generate_array(1, 50000)) ) 
```
tried to add a few filters and it works fine
![Screenshot 2024-03-28 at 11 32 25](https://github.com/metabase/metabase/assets/25661381/486acee5-266e-43bb-8c3b-37785f94d0ce)

Timelessprod (Issue Creator) on (2024-03-28 10:07:52 UTC): Thanks for the feedback.

On my first screenshot the partition filter is visible, it's the ""Dt is in the previous 48 months"" (look on the top left corner) as this column represent the partition used on BigQuery. On the second screenshot, it is not visible because the bug makes the whole filter section of the editor disappearing.

Here's the native query generated by Metabase in the bug case. I copied it from the editor mode just after the bug occured. For privacy reasons I give fake column names.

```sql
SELECT
  `datawarehouse.tablename`.`column_1` AS `column_1`,
  `datawarehouse.tablename`.`column_2` AS `column_2`,
  `datawarehouse.tablename`.`column_3` AS `column_3`,
  `datawarehouse.tablename`.`column_4` AS `column_4`,
  -- [...]
  `datawarehouse.tablename`.`column_78` AS `column_78`,
  `datawarehouse.tablename`.`type` AS `type`,
  `datawarehouse.tablename`.`dt` AS `dt`
FROM
  `datawarehouse.tablename`
WHERE
  (
    `datawarehouse.tablename`.`dt` >= DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL -48 month), month)
  )
   AND (
    `datawarehouse.tablename`.`dt` < DATE_TRUNC(DATE_ADD(CURRENT_DATE(), INTERVAL 1 month), month)
  )
LIMIT
  1048575
  ```

And we can see that the filter on column `type` that I wanted to add when the bug occured is not showing and that no filter at all is showing in the logs indeed.

We have it on multiple users and on different tables with filters on different columns but seems to be only text type column with ""Is"" or ""Is not"" filter categories.

I hope these information help. Let me know if you need more context.

Timelessprod (Issue Creator) on (2024-03-28 13:06:48 UTC): I don't know the behavior of Metabase for this, but could it be that when we are typing the value for a text filter, Metabase tries to fetch the database for possible values in this fields (to proivide hints for the user in real time), but since it doesn't provide a Dt (partition) filter while doing this internal sub-query, it gets an error from the database server (BigQuery in my case) and don't handle it properly (by just not showing hints for possible values for example), causing the UI bug ?

crisptrutski on (2024-03-28 13:42:56 UTC): This will need to be pushed out to 49.3 - we have a lot of important fixes pending and do not want to delay them further.

qnkhuat (Assginee) on (2024-03-29 03:21:46 UTC): @Timelessprod you're absolutely correct ! the bug is in the query we make to search field values.

qnkhuat (Assginee) on (2024-04-02 01:46:36 UTC): https://github.com/metabase/metabase/pull/40777 will fix the crashing issue. 

I'm working on https://github.com/metabase/metabase/pull/40767 to make the query return sensible field values.

Remove from 49.3 milestone as this no longer is a regression.

qnkhuat (Assginee) on (2024-04-04 02:59:18 UTC): The fix will be included in 49.4

darksciencebase on (2024-04-04 06:03:08 UTC): @qnkhuat do you mean 49.4? we released 49.3 already

qnkhuat (Assginee) on (2024-04-04 07:00:51 UTC): yes. should be 49.4.

Timelessprod (Issue Creator) on (2024-04-04 07:29:21 UTC): Perfect thank you very much for the fix!

"
2210813873,issue,closed,completed,Move Search Results to bottom of results (but above docs link) and increase number to 10,,npfitz,2024-03-27 13:30:00+00:00,['npfitz'],2024-04-15 14:08:04+00:00,2024-04-15 14:08:03+00:00,https://github.com/metabase/metabase/issues/40671,[],"[{'comment_id': 2056952592, 'issue_id': 2210813873, 'author': 'npfitz', 'body': 'Closed with https://github.com/metabase/metabase/pull/40650', 'created_at': datetime.datetime(2024, 4, 15, 14, 8, 3, tzinfo=datetime.timezone.utc)}]","npfitz (Issue Creator) on (2024-04-15 14:08:03 UTC): Closed with https://github.com/metabase/metabase/pull/40650

"
2210760813,issue,closed,completed,Negative fields with decimals don't get exported correctly,"### Describe the bug

If you download as a csv a table that has values that go from -0.01 to -0.0444... Metabase displays them correctly in the UI but when exporting, they get exported as 0 and that is incorrect. This in 48.x didn't happen.
See this:

![Screenshot 2024-03-27 at 10 00 14‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/404ce423-1029-494b-8727-92e345d00813)

The CSV export (wrong)
![Screenshot 2024-03-27 at 10 01 09‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/022a02ef-d7e6-4833-b216-756d0aa7441c)

The xlsx export (correct)
![Screenshot 2024-03-27 at 10 01 40‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/6aa5b90c-e0d0-4695-a490-1eada515474e)



### To Reproduce

1. Have a table that has a decimal field
2. Insert the values `INSERT INTO ""..."" (...) VALUES (-0.01), (-0.02), (-0.03), (-0.04), (-0.05);`
3. See them in the UI correctly
4. Export the table to CSV
5. See that values should be negative, and instead, they are 0

### Expected behavior

Should download the correct value. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 49.x
```


### Severity

P3 as there is a workaround, increasing the Minimum number of decimal places in the chart settings

### Additional context

_No response_",ignacio-mb,2024-03-27 13:06:36+00:00,[],2025-01-21 10:09:44+00:00,2025-01-21 10:09:43+00:00,https://github.com/metabase/metabase/issues/40670,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Export', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2569345792, 'issue_id': 2210760813, 'author': 'givemesomefaces', 'body': 'I tracked this issue, it existed in 49.x and 50.x, and it seems to be fixed above 51, so this issue can be closed.', 'created_at': datetime.datetime(2025, 1, 3, 14, 49, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604251293, 'issue_id': 2210760813, 'author': 'ignacio-mb', 'body': ""Thank you @givemesomefaces. It's true, it cannot be reproduced anymore. Closing!"", 'created_at': datetime.datetime(2025, 1, 21, 10, 9, 43, tzinfo=datetime.timezone.utc)}]","givemesomefaces on (2025-01-03 14:49:16 UTC): I tracked this issue, it existed in 49.x and 50.x, and it seems to be fixed above 51, so this issue can be closed.

ignacio-mb (Issue Creator) on (2025-01-21 10:09:43 UTC): Thank you @givemesomefaces. It's true, it cannot be reproduced anymore. Closing!

"
2210745359,issue,closed,completed,Visually adapt notebook steps for all sidebar states and for all screen sizes,"As @kamilmielnik noted in [this comment](https://github.com/metabase/metabase/pull/40595#discussion_r1538766901) there should not be so much white space between the notebook step and the native query preview sidebar.

The goal of this task is to find the right balance of widths for both the notebook editor and the query preview sidebar on multiple screen sizes.

Up until 960px, we're showing either the notebook editor or the sidebar (toggling their visibility).
Above 960px, we need to set the minimum width for the notebook editor to 640px, but we also need to find the correct max-width to prevent the content shifting upon the sidebar opening/closing.

This is how it currently looks: 

at 1024px
![Kapture 2024-03-27 at 13 57 52](https://github.com/metabase/metabase/assets/31325167/7bcb4e21-57b3-4c9f-a9d4-9d36e040e60c)

at 1280px
[Click to preview](https://github.com/metabase/metabase/assets/31325167/1afd1e77-7b3a-452c-bdc0-513a6929799d)

at 1600px
[Click to preview](https://github.com/metabase/metabase/assets/31325167/6c8bc7d1-d6d0-43a9-bb9b-be3c69509768)

at 1920px
[Click to preview](https://github.com/metabase/metabase/assets/31325167/56ba68e1-3d7a-48f5-ac82-e354a37533ca)

",nemanjaglumac,2024-03-27 12:59:35+00:00,['nemanjaglumac'],2024-04-02 17:42:58+00:00,2024-04-02 17:42:58+00:00,https://github.com/metabase/metabase/issues/40668,"[('.CSS', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2210628639,issue,closed,completed,Primary Key missing filter options,"### Describe the bug

Primary keys can only be filtered for `Is` and `Is Not`.

Most importantly - joining with a different table and trying to filter rows that gave or didn't give a match, this can be done only via `Is Empty` or `Is not Empty` filter options. 
<img width=""1282"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/607a92a0-af4f-4c0b-b6be-0266a9486608"">


### To Reproduce

1. Go to any table with primary key defined
2. Click on the column name to filter.

### Expected behavior

All text/numeric filter options as usual should be available for the primary keys as well. 
In many cases, primary key contains partial information about the that can be used to filter the data, hence `Contains` and `Does Not Contain` are also useful. 

This used to work as expected in earlier versions, but is missing in version `0.49`

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.3.39-MariaDB-0ubuntu0.20.04.2""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Calcutta""
    }
  }
}
```


### Severity

P1, breaking joins and adding complications in using tables

### Additional context

_No response_",abhishek-superk,2024-03-27 12:06:03+00:00,['bshepherdson'],2024-04-19 17:27:45+00:00,2024-04-18 12:46:03+00:00,https://github.com/metabase/metabase/issues/40665,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Backend', '')]","[{'comment_id': 2022913735, 'issue_id': 2210628639, 'author': 'bshepherdson', 'body': ""No repro.\r\n\r\nHere's what it looks like on master and 49.1, clicking on a numeric FK:\r\n![2024-03-27-101741_616x975_scrot](https://github.com/metabase/metabase/assets/157812/bf803fdf-fbf5-4409-b203-eb46cbaa11cb)\r\n\r\nWhere is that **Alias** field coming from? Perhaps from a model which does not define its type in the metadata, or from a SQL question? The column appears to be all blank, ie. `NULL` - if there's no values returned for a SQL column we don't know what type it is.\r\n\r\nI don't think this is a UI regression, but rather a metadata issue."", 'created_at': datetime.datetime(2024, 3, 27, 14, 29, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024234408, 'issue_id': 2210628639, 'author': 'abhishek-superk', 'body': 'That\'s weird, all our primary keys are giving only two options. \r\n<img width=""492"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/256e5b47-def2-4bc1-b4d2-1d601510f514"">\r\n<img width=""520"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/b2736ba8-9a82-4304-84a2-ae8b474ed8a5"">\r\n<img width=""520"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/a72b550b-59ec-4dd8-9888-34a0b86e8745"">\r\n\r\nThe table metadata doesn\'t seem to have any issue either, at least we didn\'t change anything after the update. \r\n<img width=""888"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/80f4f140-940f-4e27-af1a-81f892d48598"">\r\n\r\nIs there anything else we should check?', 'created_at': datetime.datetime(2024, 3, 28, 1, 22, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2025367205, 'issue_id': 2210628639, 'author': 'bshepherdson', 'body': ""There's been some other oddities around filters, so there may be some more subtle bug here. (For example, it might be a BigQuery-specific issue.)\r\n\r\nI'll investigate further and see if I can reproduce this."", 'created_at': datetime.datetime(2024, 3, 28, 14, 35, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026678902, 'issue_id': 2210628639, 'author': 'abhishek-superk', 'body': ""@bshepherdson Thank you, much appreciated! üôè \r\n\r\nOne other thing that changed in filters: \r\nIf you want to select 4 of the search results - previously you could just type once and select all 4, but now you gotta type again every time. Don't know where else to post this, couldn't think of what to write in a new issue."", 'created_at': datetime.datetime(2024, 3, 29, 5, 28, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2047590553, 'issue_id': 2210628639, 'author': 'bshepherdson', 'body': 'I\'m back to looking at this issue after dealing with some other escalations.\r\n\r\nI still can\'t reproduce this, even on BigQuery. @abhishek-superk can you still see this issue (on the latest 49.3 or 49.4 if it\'s practical to update)?\r\n\r\nIf you can, can you open the devtools Network tab, find the latest `/api/dataset` request (or `/api/card/$ID/query` for a saved question), and paste the `data.cols[0]` value showing one of these problem PKs? It should look something like this:\r\n```json\r\n{\r\n  ""description"": null,\r\n  ""semantic_type"": ""type/PK"",\r\n  ""table_id"": 653,\r\n  ""coercion_strategy"": null,\r\n  ""name"": ""id"",\r\n  ""settings"": null,\r\n  ""source"": ""fields"",\r\n  ""fk_target_field_id"": null,\r\n  ""field_ref"": [""field"", 1514, null],\r\n  ""effective_type"": ""type/Integer"",\r\n  ""nfc_path"": null,\r\n  ""parent_id"": null,\r\n  ""id"": 1514,\r\n  ""position"": 0,\r\n  ""visibility_type"": ""normal"",\r\n  ""display_name"": ""ID"",\r\n  ""fingerprint"": null,\r\n  ""base_type"": ""type/Integer""\r\n}\r\n```', 'created_at': datetime.datetime(2024, 4, 10, 13, 44, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2049156201, 'issue_id': 2210628639, 'author': 'perivamsi', 'body': ""@bshepherdson let's add the milestone after the fix is merged into master and is backported to 49. Otherwise we will keep pushing the milestones out."", 'created_at': datetime.datetime(2024, 4, 11, 8, 8, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2050400769, 'issue_id': 2210628639, 'author': 'abhishek-superk', 'body': 'Thanks @bshepherdson! Updated to 0.49.5 as it\'s the latest available now. Still getting only 2 options - `Is` and `Is Not` for PKs or FKs columns.\r\n\r\nHere\'s the `data.cols[0]` values for a table:\r\n\r\n```json\r\n{\r\n                ""description"": null,\r\n                ""semantic_type"": ""type/PK"",\r\n                ""table_id"": 2297,\r\n                ""coercion_strategy"": null,\r\n                ""name"": ""alias"",\r\n                ""settings"": null,\r\n                ""source"": ""fields"",\r\n                ""fk_target_field_id"": null,\r\n                ""field_ref"": [\r\n                    ""field"",\r\n                    49329,\r\n                    null\r\n                ],\r\n                ""effective_type"": ""type/Text"",\r\n                ""nfc_path"": null,\r\n                ""parent_id"": null,\r\n                ""id"": 49329,\r\n                ""position"": 0,\r\n                ""visibility_type"": ""normal"",\r\n                ""display_name"": ""Alias"",\r\n                ""fingerprint"": {\r\n                    ""global"": {\r\n                        ""distinct-count"": 9653,\r\n                        ""nil%"": 0.0\r\n                    },\r\n                    ""type"": {\r\n                        ""type/Text"": {\r\n                            ""percent-json"": 0.0,\r\n                            ""percent-url"": 0.0,\r\n                            ""percent-email"": 0.0,\r\n                            ""percent-state"": 0.0,\r\n                            ""average-length"": 14.251527389458424\r\n                        }\r\n                    }\r\n                },\r\n                ""base_type"": ""type/Text""\r\n            },\r\n\r\n\r\n```\r\n\r\n\r\nThe index of PK in the saved report was 1, so sharing that instead of 0:\r\n```json\r\n{\r\n                ""description"": ""SPA Product ID"",\r\n                ""semantic_type"": ""type/FK"",\r\n                ""table_id"": 2253,\r\n                ""coercion_strategy"": null,\r\n                ""name"": ""productId"",\r\n                ""settings"": null,\r\n                ""source"": ""fields"",\r\n                ""fk_target_field_id"": 91100,\r\n                ""field_ref"": [\r\n                    ""field"",\r\n                    119963,\r\n                    null\r\n                ],\r\n                ""effective_type"": ""type/Text"",\r\n                ""nfc_path"": null,\r\n                ""parent_id"": null,\r\n                ""id"": 119963,\r\n                ""position"": 2,\r\n                ""visibility_type"": ""normal"",\r\n                ""display_name"": ""ProductId"",\r\n                ""fingerprint"": {\r\n                    ""global"": {\r\n                        ""distinct-count"": 5569,\r\n                        ""nil%"": 0.0\r\n                    },\r\n                    ""type"": {\r\n                        ""type/Text"": {\r\n                            ""percent-json"": 0.0,\r\n                            ""percent-url"": 0.0,\r\n                            ""percent-email"": 0.0,\r\n                            ""percent-state"": 0.0,\r\n                            ""average-length"": 35.9948\r\n                        }\r\n                    }\r\n                },\r\n                ""base_type"": ""type/Text""\r\n            },\r\n```\r\n\r\nAlso, here\'s the same info for FK in this report:\r\n```json\r\n{\r\n                ""description"": ""Replenishment Alias"",\r\n                ""semantic_type"": ""type/FK"",\r\n                ""table_id"": 2253,\r\n                ""coercion_strategy"": null,\r\n                ""name"": ""alias"",\r\n                ""settings"": null,\r\n                ""source"": ""fields"",\r\n                ""fk_target_field_id"": 49329,\r\n                ""field_ref"": [\r\n                    ""field"",\r\n                    48348,\r\n                    null\r\n                ],\r\n                ""effective_type"": ""type/Text"",\r\n                ""nfc_path"": null,\r\n                ""parent_id"": null,\r\n                ""id"": 48348,\r\n                ""position"": 4,\r\n                ""visibility_type"": ""normal"",\r\n                ""display_name"": ""Alias"",\r\n                ""fingerprint"": {\r\n                    ""global"": {\r\n                        ""distinct-count"": 8009,\r\n                        ""nil%"": 0.0\r\n                    },\r\n                    ""type"": {\r\n                        ""type/Text"": {\r\n                            ""percent-json"": 0.0,\r\n                            ""percent-url"": 0.0,\r\n                            ""percent-email"": 0.0,\r\n                            ""percent-state"": 0.0,\r\n                            ""average-length"": 14.1712\r\n                        }\r\n                    }\r\n                },\r\n                ""base_type"": ""type/Text""\r\n            },\r\n```\r\n\r\n\r\nThe PK of the table shared is being referred as a FK in the report shared next, in case it helps.', 'created_at': datetime.datetime(2024, 4, 11, 19, 43, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2057751965, 'issue_id': 2210628639, 'author': 'bshepherdson', 'body': ""Okay, string keys are the issue here. I can reproduce this with a test table using string keys.\r\n![2024-04-15-162840_629x490_scrot](https://github.com/metabase/metabase/assets/157812/137df03f-9acd-41fa-b3a5-adba82d0c11f)\r\n\r\nI'll work on a fix, should be straightforward."", 'created_at': datetime.datetime(2024, 4, 15, 20, 31, 13, tzinfo=datetime.timezone.utc)}]","bshepherdson (Assginee) on (2024-03-27 14:29:16 UTC): No repro.

Here's what it looks like on master and 49.1, clicking on a numeric FK:
![2024-03-27-101741_616x975_scrot](https://github.com/metabase/metabase/assets/157812/bf803fdf-fbf5-4409-b203-eb46cbaa11cb)

Where is that **Alias** field coming from? Perhaps from a model which does not define its type in the metadata, or from a SQL question? The column appears to be all blank, ie. `NULL` - if there's no values returned for a SQL column we don't know what type it is.

I don't think this is a UI regression, but rather a metadata issue.

abhishek-superk (Issue Creator) on (2024-03-28 01:22:19 UTC): That's weird, all our primary keys are giving only two options. 
<img width=""492"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/256e5b47-def2-4bc1-b4d2-1d601510f514"">
<img width=""520"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/b2736ba8-9a82-4304-84a2-ae8b474ed8a5"">
<img width=""520"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/a72b550b-59ec-4dd8-9888-34a0b86e8745"">

The table metadata doesn't seem to have any issue either, at least we didn't change anything after the update. 
<img width=""888"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/80f4f140-940f-4e27-af1a-81f892d48598"">

Is there anything else we should check?

bshepherdson (Assginee) on (2024-03-28 14:35:09 UTC): There's been some other oddities around filters, so there may be some more subtle bug here. (For example, it might be a BigQuery-specific issue.)

I'll investigate further and see if I can reproduce this.

abhishek-superk (Issue Creator) on (2024-03-29 05:28:19 UTC): @bshepherdson Thank you, much appreciated! üôè 

One other thing that changed in filters: 
If you want to select 4 of the search results - previously you could just type once and select all 4, but now you gotta type again every time. Don't know where else to post this, couldn't think of what to write in a new issue.

bshepherdson (Assginee) on (2024-04-10 13:44:47 UTC): I'm back to looking at this issue after dealing with some other escalations.

I still can't reproduce this, even on BigQuery. @abhishek-superk can you still see this issue (on the latest 49.3 or 49.4 if it's practical to update)?

If you can, can you open the devtools Network tab, find the latest `/api/dataset` request (or `/api/card/$ID/query` for a saved question), and paste the `data.cols[0]` value showing one of these problem PKs? It should look something like this:
```json
{
  ""description"": null,
  ""semantic_type"": ""type/PK"",
  ""table_id"": 653,
  ""coercion_strategy"": null,
  ""name"": ""id"",
  ""settings"": null,
  ""source"": ""fields"",
  ""fk_target_field_id"": null,
  ""field_ref"": [""field"", 1514, null],
  ""effective_type"": ""type/Integer"",
  ""nfc_path"": null,
  ""parent_id"": null,
  ""id"": 1514,
  ""position"": 0,
  ""visibility_type"": ""normal"",
  ""display_name"": ""ID"",
  ""fingerprint"": null,
  ""base_type"": ""type/Integer""
}
```

perivamsi on (2024-04-11 08:08:11 UTC): @bshepherdson let's add the milestone after the fix is merged into master and is backported to 49. Otherwise we will keep pushing the milestones out.

abhishek-superk (Issue Creator) on (2024-04-11 19:43:28 UTC): Thanks @bshepherdson! Updated to 0.49.5 as it's the latest available now. Still getting only 2 options - `Is` and `Is Not` for PKs or FKs columns.

Here's the `data.cols[0]` values for a table:

```json
{
                ""description"": null,
                ""semantic_type"": ""type/PK"",
                ""table_id"": 2297,
                ""coercion_strategy"": null,
                ""name"": ""alias"",
                ""settings"": null,
                ""source"": ""fields"",
                ""fk_target_field_id"": null,
                ""field_ref"": [
                    ""field"",
                    49329,
                    null
                ],
                ""effective_type"": ""type/Text"",
                ""nfc_path"": null,
                ""parent_id"": null,
                ""id"": 49329,
                ""position"": 0,
                ""visibility_type"": ""normal"",
                ""display_name"": ""Alias"",
                ""fingerprint"": {
                    ""global"": {
                        ""distinct-count"": 9653,
                        ""nil%"": 0.0
                    },
                    ""type"": {
                        ""type/Text"": {
                            ""percent-json"": 0.0,
                            ""percent-url"": 0.0,
                            ""percent-email"": 0.0,
                            ""percent-state"": 0.0,
                            ""average-length"": 14.251527389458424
                        }
                    }
                },
                ""base_type"": ""type/Text""
            },


```


The index of PK in the saved report was 1, so sharing that instead of 0:
```json
{
                ""description"": ""SPA Product ID"",
                ""semantic_type"": ""type/FK"",
                ""table_id"": 2253,
                ""coercion_strategy"": null,
                ""name"": ""productId"",
                ""settings"": null,
                ""source"": ""fields"",
                ""fk_target_field_id"": 91100,
                ""field_ref"": [
                    ""field"",
                    119963,
                    null
                ],
                ""effective_type"": ""type/Text"",
                ""nfc_path"": null,
                ""parent_id"": null,
                ""id"": 119963,
                ""position"": 2,
                ""visibility_type"": ""normal"",
                ""display_name"": ""ProductId"",
                ""fingerprint"": {
                    ""global"": {
                        ""distinct-count"": 5569,
                        ""nil%"": 0.0
                    },
                    ""type"": {
                        ""type/Text"": {
                            ""percent-json"": 0.0,
                            ""percent-url"": 0.0,
                            ""percent-email"": 0.0,
                            ""percent-state"": 0.0,
                            ""average-length"": 35.9948
                        }
                    }
                },
                ""base_type"": ""type/Text""
            },
```

Also, here's the same info for FK in this report:
```json
{
                ""description"": ""Replenishment Alias"",
                ""semantic_type"": ""type/FK"",
                ""table_id"": 2253,
                ""coercion_strategy"": null,
                ""name"": ""alias"",
                ""settings"": null,
                ""source"": ""fields"",
                ""fk_target_field_id"": 49329,
                ""field_ref"": [
                    ""field"",
                    48348,
                    null
                ],
                ""effective_type"": ""type/Text"",
                ""nfc_path"": null,
                ""parent_id"": null,
                ""id"": 48348,
                ""position"": 4,
                ""visibility_type"": ""normal"",
                ""display_name"": ""Alias"",
                ""fingerprint"": {
                    ""global"": {
                        ""distinct-count"": 8009,
                        ""nil%"": 0.0
                    },
                    ""type"": {
                        ""type/Text"": {
                            ""percent-json"": 0.0,
                            ""percent-url"": 0.0,
                            ""percent-email"": 0.0,
                            ""percent-state"": 0.0,
                            ""average-length"": 14.1712
                        }
                    }
                },
                ""base_type"": ""type/Text""
            },
```


The PK of the table shared is being referred as a FK in the report shared next, in case it helps.

bshepherdson (Assginee) on (2024-04-15 20:31:13 UTC): Okay, string keys are the issue here. I can reproduce this with a test table using string keys.
![2024-04-15-162840_629x490_scrot](https://github.com/metabase/metabase/assets/157812/137df03f-9acd-41fa-b3a5-adba82d0c11f)

I'll work on a fix, should be straightforward.

"
2210406217,issue,closed,completed,Using Filters in SQL questions drives you crazy,"### Describe the bug

Playing around with filters is frustrating

### To Reproduce

1. Go to New -> SQL -> `Select * from orders where {{date}}` -> Set data as field filter

Notice how the UI already changes like something is off when a filter is added. Without filter:

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/9037d9d0-1dbd-40c2-9af3-487c29fb0d09"">

With Filter:

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/8d4c2b91-f8a6-4d16-8710-bd3b8215339f"">

2. Click on Filter and try to use  it. Notice the movements and hickups. Every click i perform the filter moves and my click is ignored:

https://github.com/metabase/metabase/assets/110378427/6bf83a52-f082-4935-8b46-86ac88c7cd74

I know we added the functionality to move filters around but something is just not right it feels off ... On master this doesn't happen i seem to experience this on 1.49.1

### Expected behavior

Smooth usage of filters

### Logs

None that are relevant

### Information about your Metabase installation

```JSON
1.49.1 and even though i can move filters on master I am not getting the same experience
```


### Severity

Very annoying 

### Additional context

_No response_",Tony-metabase,2024-03-27 10:21:35+00:00,[],2024-03-27 10:40:03+00:00,2024-03-27 10:40:03+00:00,https://github.com/metabase/metabase/issues/40663,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', ''), ('.Needs Triage', ''), ('.Escalation', '')]","[{'comment_id': 2022439845, 'issue_id': 2210406217, 'author': 'Tony-metabase', 'body': 'Closing as duplicate of https://github.com/metabase/metabase/issues/40232 ... Should make it in 49.2', 'created_at': datetime.datetime(2024, 3, 27, 10, 40, 3, tzinfo=datetime.timezone.utc)}]","Tony-metabase (Issue Creator) on (2024-03-27 10:40:03 UTC): Closing as duplicate of https://github.com/metabase/metabase/issues/40232 ... Should make it in 49.2

"
2210263855,issue,closed,completed,Populate example dashboard,[Reference dashboard](https://stats.metabase.com/dashboard/2190-e-commerce-insights?tab=598-overview&vendor=&date_range=&category=&location=),crisptrutski,2024-03-27 09:16:09+00:00,['calherries'],2024-04-24 12:24:28+00:00,2024-04-22 11:31:17+00:00,https://github.com/metabase/metabase/issues/40662,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2074825792, 'issue_id': 2210263855, 'author': 'calherries', 'body': ""This doesn't need a milestone because I added it to https://github.com/metabase/metabase/issues/40066"", 'created_at': datetime.datetime(2024, 4, 24, 12, 24, 27, tzinfo=datetime.timezone.utc)}]","calherries (Assginee) on (2024-04-24 12:24:27 UTC): This doesn't need a milestone because I added it to https://github.com/metabase/metabase/issues/40066

"
2209904648,issue,closed,completed,Iframe embedding overflow widgets issue,"### Describe the bug

![Screenshot 2024-03-27 at 10 50 14‚ÄØAM](https://github.com/metabase/metabase/assets/574802/dacf230a-ac15-4ce2-b8bd-64b1cd049085)

`EmbedFrame` is not resizing according to the widgets inside it. Widgets are overflowing out side of the main container. 
Setting `overflow: 'auto'` from dev tools fixes the issue however we can't inject the styles in iframe. 

### To Reproduce

1. Create a dashboard with lots of widgets
2. Render the iframe with Light theme inside the parent app with black background. 
3. You will see frame container is falling short of the combined widgets height. 


### Expected behavior

Background container should expand to the full widgets height. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.14.336-253.554.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""redshift"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.17""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-12"",
      ""tag"": ""v1.48.6"",
      ""hash"": ""b8818f9""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```


### Severity

blocking your usage of metabase entierly

### Additional context

_No response_",bitshadow,2024-03-27 05:35:34+00:00,['WiNloSt'],2024-04-04 06:21:10+00:00,2024-04-03 15:32:51+00:00,https://github.com/metabase/metabase/issues/40660,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Embedding/', 'Use this label when unsure which flavor of embedding is impacted'), ('.Frontend', '')]",[],
2209900839,issue,closed,not_planned,Zoom In / Out buttons in Region Map,"Requesting for a Zoom  In / Out buttons for Region Map as well.

Reference: https://github.com/metabase/metabase/issues/33928",talenodigital,2024-03-27 05:32:23+00:00,[],2024-03-27 12:13:18+00:00,2024-03-27 12:13:18+00:00,https://github.com/metabase/metabase/issues/40659,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2022621341, 'issue_id': 2209900839, 'author': 'ignacio-mb', 'body': 'Dupe of https://github.com/metabase/metabase/issues/33928', 'created_at': datetime.datetime(2024, 3, 27, 12, 13, 18, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-03-27 12:13:18 UTC): Dupe of https://github.com/metabase/metabase/issues/33928

"
2209734707,issue,closed,completed,"Progress visualisation not working, gives an error","### Describe the bug

I create a simple question returning a single count value, this previews in the notebook mode, and displays a number correctly when visualised. When I change it to a Progress visualisation I get the exclamation mark displayed instead. I then can't change back to a number or table, I need to refresh or start a new question.

### To Reproduce

1. Create a new question
2. Sample Database > Accounts
3. Count of rows
![image](https://github.com/metabase/metabase/assets/4504437/29adfe48-69ae-4e2b-9761-4453fcc8172e)
4. Visualise, Number is presented as expected
![image](https://github.com/metabase/metabase/assets/4504437/fa56011d-8cc2-4833-9d61-d7659d902cca)
5. Change the visualisation type to ""Progress"", error occurs
![image](https://github.com/metabase/metabase/assets/4504437/02c2a2d7-17cc-459f-a853-9174a7640e2e)
6. Can't change to any other type of visualisation, need to restart
7. Can't use the data/visualisation slider to view the raw data either


### Expected behavior

Progress chart to be displayed and I can continue to work on the question.

### Logs

JavaScript console:
```
TypeError: Cannot read properties of undefined (reading 'height')
    at oy.componentDidUpdate (Progress.jsx:100:39)
    at oy.componentDidMount (Progress.jsx:86:10)
    at react-dom.production.min.js:212:132
    at a$ (react-dom.production.min.js:213:322)
    at t.unstable_runWithPriority (scheduler.production.min.js:19:467)
    at on (react-dom.production.min.js:122:325)
    at aX (react-dom.production.min.js:248:370)
    at aW (react-dom.production.min.js:239:376)
    at react-dom.production.min.js:123:115
    at t.unstable_runWithPriority (scheduler.production.min.js:19:467)
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-NZ"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""Cp1252"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.2+8"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""17.0.2"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.2+8"",
    ""os.name"": ""Windows 10"",
    ""os.version"": ""10.0"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Pacific/Auckland""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlserver"",
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""12.1""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": ""Pacific/Auckland""
    }
  }
}
```


### Severity

Can't create progress bars at all. We don't use them much so not a big issue for me.

### Additional context

Also and issue in Firefox.

I don't get this on v0.48.6, progress bars are working as expected.",notrom,2024-03-27 03:19:03+00:00,['JesseSDevaney'],2024-04-16 13:55:50+00:00,2024-04-15 21:14:33+00:00,https://github.com/metabase/metabase/issues/40658,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2021857394, 'issue_id': 2209734707, 'author': 'notrom', 'body': 'Interestingly I can go ahead and save the question in that state, it still fails to render. I can then add it to a dashboard and it will render, but clicking the title to open it goes back to the error screen.\r\n![image](https://github.com/metabase/metabase/assets/4504437/90292349-f424-402e-8d35-815d2e46bc46)', 'created_at': datetime.datetime(2024, 3, 27, 3, 28, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2022529139, 'issue_id': 2209734707, 'author': 'paoliniluis', 'body': 'Lowering to p2', 'created_at': datetime.datetime(2024, 3, 27, 11, 23, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2048955831, 'issue_id': 2209734707, 'author': 'NicolasPA', 'body': 'I confirm this issue and the fact that it still renders in dashboard on v0.49.2.', 'created_at': datetime.datetime(2024, 4, 11, 5, 33, 1, tzinfo=datetime.timezone.utc)}]","notrom (Issue Creator) on (2024-03-27 03:28:58 UTC): Interestingly I can go ahead and save the question in that state, it still fails to render. I can then add it to a dashboard and it will render, but clicking the title to open it goes back to the error screen.
![image](https://github.com/metabase/metabase/assets/4504437/90292349-f424-402e-8d35-815d2e46bc46)

paoliniluis on (2024-03-27 11:23:03 UTC): Lowering to p2

NicolasPA on (2024-04-11 05:33:01 UTC): I confirm this issue and the fact that it still renders in dashboard on v0.49.2.

"
2209196468,issue,open,,Leverage Native Model Metadata in Notebook editor,"**Is your feature request related to a problem? Please describe.**
If you have a SQL model, and you configure the metadata to match the foreign keys to other tables, you still won't see the other tables in the summarization or while doing a join in the Notebook editor

To demonstrate:

1. Create a SQL question, `SELECT * FROM ORDERS`, save it
2. Convert into a model
3. Edit metadata, and set both User ID and Product ID fields Foreign keys and map them to the Product and People table <img width=""1500"" alt=""Screenshot 2024-03-26 at 7 30 33‚ÄØPM"" src=""https://github.com/metabase/metabase/assets/132273646/68349b41-da07-4c92-b181-4e35e68a7a2c"">
4. Save the changes
5. Use the query editor to summarize/aggregate. See that there is no Reference to other tables and that's a bummer
<img width=""859"" alt=""Screenshot 2024-03-26 at 7 31 39‚ÄØPM"" src=""https://github.com/metabase/metabase/assets/132273646/0cc02123-bf90-4c51-9645-3594b41f7000"">


**Describe the solution you'd like**
See the references to other tables as normal GUI model. 

**Describe alternatives you've considered**
Checked if this worked on a previous version (46, 47 or 48) but nothing. 

**How important is this feature to you?**
Requested by a customer, internal ticket: [25906](https://metabase.zendesk.com/agent/tickets/25906)

**Additional context**
Probably related to this https://github.com/metabase/metabase/issues/23044, this https://github.com/metabase/metabase/issues/35842 and maybe to this https://github.com/metabase/metabase/issues/40191
Can be tackled by SQL parser?
",ignacio-mb,2024-03-26 19:58:00+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/40645,"[('Type:New Feature', ''), ('Querying/Native', 'The SQL/native query editor'), ('Administration/Table Metadata', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Models', 'aka Datasets'), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2575716056, 'issue_id': 2209196468, 'author': 'thebiglabasky', 'body': 'It seems very related to #45146', 'created_at': datetime.datetime(2025, 1, 7, 16, 22, 3, tzinfo=datetime.timezone.utc)}]","thebiglabasky on (2025-01-07 16:22:03 UTC): It seems very related to #45146

"
2209144519,issue,closed,completed,Get rid of database connection help banner,":wave:  could we remove the ‚Äúdatabase connection help‚Äù banner at the top of instances today?

[Slack Message](https://metaboat.slack.com/archives/C064EB1UE5P/p1711474640599279?thread_ts=1711474640.599279&cid=C064EB1UE5P)",iethree,2024-03-26 19:29:27+00:00,['rafpaf'],2024-04-01 19:32:35+00:00,2024-03-27 17:51:48+00:00,https://github.com/metabase/metabase/issues/40644,"[('.Frontend', ''), ('Administration/Databases', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2208964038,issue,closed,completed,Raise model index limit,"We can index values in a model. When we first released the feature we set a limit of 5,000 values to limit. This is proving too low in practice. Let's raise this to a higher value.",dpsutton,2024-03-26 18:05:27+00:00,[],2024-03-26 20:22:14+00:00,2024-03-26 20:22:14+00:00,https://github.com/metabase/metabase/issues/40640,"[('Misc/API', ''), ('Type:New Feature', ''), ('Querying/Models', 'aka Datasets')]",[],
2208961908,issue,closed,completed,model indexes error when values are removed,"### Describe the bug

Model indexes should surface records from models in search. When new values are present they should be indexed, and when values are no longer present they should no longer be in the index.

There's an issue when removing values from the index where we use the wrong column name in the update:

```clojure
(when (seq deletions)
  (t2/delete! ModelIndexValue
              :model_index_id (:id model-index)
              :pk_ref [:in (->> deletions (map first))]))   ;; -> pk_ref is the column in model_index, not model_index_value
```

This yields values like:

```sql
select pk_ref, value_ref, state, error from model_index where state = 'error'

pk_ref,value_ref,state,error
""[""""field"""",563028,null]"",""[""""field"""",563018,null]"",error,""ERROR: column """"pk_ref"""" does not exist Position: 68""
""[""""field"""",534030,null]"",""[""""field"""",534037,null]"",error,""ERROR: column """"pk_ref"""" does not exist Position: 68""
""[""""field"""",545945,null]"",""[""""field"""",545948,null]"",error,""ERROR: column """"pk_ref"""" does not exist Position: 68""
```

### To Reproduce

Index a model, have it not have values any longer, and then it errors trying to remove them.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p2 (possibly higher but fixing now)

### Additional context

_No response_",dpsutton,2024-03-26 18:04:19+00:00,['dpsutton'],2024-03-28 10:05:40+00:00,2024-03-26 20:22:14+00:00,https://github.com/metabase/metabase/issues/40639,"[('Type:Bug', 'Product defects'), ('Misc/API', ''), ('Querying/Models', 'aka Datasets')]",[],
2208820342,issue,open,,Metabase model does not display information correctly,"### Describe the bug

When creating a query that combines the same table but pertains to different fields, Metabase generates a new alias and applies the transformation without any issues, as shown in the attached image.

![image](https://github.com/metabase/metabase/assets/106935910/bdf49e37-5604-401b-83c0-590a6bc1acd7)


However, when this query is transformed into a model, the two columns related to the same table end up merging, displaying only the information from one of them, thus not allowing the user to change the metadata or view the correct information.

![image](https://github.com/metabase/metabase/assets/106935910/e056df0d-8614-4b9b-b4af-98d09114dd28)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

The model should exhibit the same behavior as the previous query before being transformed into a model.

### Logs

_No response_

### Information about your Metabase installation

```JSON
""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
```


### Severity

High

### Additional context

_No response_",francisco-mooddie,2024-03-26 17:05:54+00:00,[],2025-02-04 20:31:07+00:00,,https://github.com/metabase/metabase/issues/40635,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2194456222, 'issue_id': 2208820342, 'author': 'kamilmielnik', 'body': 'Partially fixed by #44721', 'created_at': datetime.datetime(2024, 6, 27, 11, 40, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194887270, 'issue_id': 2208820342, 'author': 'kamilmielnik', 'body': ""FE side fixed by https://github.com/metabase/metabase/pull/44721.\r\n\r\nBut the issue is still there on the BE side.\r\nWe've added a repro: #44824\r\n\r\nThe problem is that POST `/api/dataset` returns incorrect columns in both `data.results_metadata.columns` and `data.cols`.\r\nAlso affects `results_metadata` in `/api/card`."", 'created_at': datetime.datetime(2024, 6, 27, 14, 30, 43, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-06-27 11:40:25 UTC): Partially fixed by #44721

kamilmielnik on (2024-06-27 14:30:43 UTC): FE side fixed by https://github.com/metabase/metabase/pull/44721.

But the issue is still there on the BE side.
We've added a repro: #44824

The problem is that POST `/api/dataset` returns incorrect columns in both `data.results_metadata.columns` and `data.cols`.
Also affects `results_metadata` in `/api/card`.

"
2208790973,issue,closed,not_planned,Shortcut to open code editor,"**Is your feature request related to a problem? Please describe.**
Its very annoying to have to click the tiny 'open editor' button everytime. 


**Describe the solution you'd like**
Please add the same quick button you have to open the side bar (Cmd + .) to open the code editor.

Allow you to open and close the code editor easily.

View graph, then instantly see code.

**Describe alternatives you've considered**
Please please 

**How important is this feature to you?**
10 / 10 convenience and seamlessness to product

**Additional context**
please ",OdinTallBeard,2024-03-26 16:53:06+00:00,[],2024-05-29 10:10:33+00:00,2024-03-26 23:09:03+00:00,https://github.com/metabase/metabase/issues/40634,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2020980258, 'issue_id': 2208790973, 'author': 'OdinTallBeard', 'body': 'I think [ Cmd + ; ] would be a good input', 'created_at': datetime.datetime(2024, 3, 26, 16, 54, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2021617583, 'issue_id': 2208790973, 'author': 'ignacio-mb', 'body': 'Dupe of https://github.com/metabase/metabase/issues/38687. Fyi, this is coming very soon', 'created_at': datetime.datetime(2024, 3, 26, 23, 9, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2137048064, 'issue_id': 2208790973, 'author': 'OdinTallBeard', 'body': 'Hi this has still not happened yet', 'created_at': datetime.datetime(2024, 5, 29, 10, 10, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2137048439, 'issue_id': 2208790973, 'author': 'OdinTallBeard', 'body': 'please put this in this would be great for seamlessness', 'created_at': datetime.datetime(2024, 5, 29, 10, 10, 32, tzinfo=datetime.timezone.utc)}]","OdinTallBeard (Issue Creator) on (2024-03-26 16:54:59 UTC): I think [ Cmd + ; ] would be a good input

ignacio-mb on (2024-03-26 23:09:03 UTC): Dupe of https://github.com/metabase/metabase/issues/38687. Fyi, this is coming very soon

OdinTallBeard (Issue Creator) on (2024-05-29 10:10:22 UTC): Hi this has still not happened yet

OdinTallBeard (Issue Creator) on (2024-05-29 10:10:32 UTC): please put this in this would be great for seamlessness

"
2208784248,issue,closed,not_planned,Charts are not appearing correct on email + slack automations ; double y axis are happening when I specifically specify not to,"**Is your feature request related to a problem? Please describe.**
My charts reflect INACCURATE DATA 

**Describe the solution you'd like**
Graphs to reflect correctly + how they do in Metabase in the automated emails and slacks

**Describe alternatives you've considered**
Ive played around with the settings and does not fix it 

**How important is this
EXTREMLY 10/10

It shows incorrect data to the viewer

**Additional context**
Add any other context or screenshots about the feature request here.
<img width=""462"" alt=""Screenshot 2024-03-26 at 12 48 06 PM"" src=""https://github.com/metabase/metabase/assets/121153315/78427cd3-b7cb-4e79-a76d-f7c39d43f6f6"">
<img width=""1459"" alt=""Screenshot 2024-03-26 at 12 48 34 PM"" src=""https://github.com/metabase/metabase/assets/121153315/e7af7a40-6800-4c4c-b326-7048e08fbb8d"">
",OdinTallBeard,2024-03-26 16:49:41+00:00,[],2024-03-27 11:20:54+00:00,2024-03-27 11:20:54+00:00,https://github.com/metabase/metabase/issues/40632,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2021183932, 'issue_id': 2208784248, 'author': 'cgg-pwdt', 'body': 'I believe this relates to this issue : https://github.com/metabase/metabase/issues/20559', 'created_at': datetime.datetime(2024, 3, 26, 18, 27, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2021734716, 'issue_id': 2208784248, 'author': 'ojjj13', 'body': 'Pulse inconsistency has been an issue for a very long time.', 'created_at': datetime.datetime(2024, 3, 27, 0, 59, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2022525400, 'issue_id': 2208784248, 'author': 'paoliniluis', 'body': 'Duplicate of pulse inconsistency bugs, we‚Äôre trying to fix it soon but it‚Äôs hard', 'created_at': datetime.datetime(2024, 3, 27, 11, 20, 54, tzinfo=datetime.timezone.utc)}]","cgg-pwdt on (2024-03-26 18:27:34 UTC): I believe this relates to this issue : https://github.com/metabase/metabase/issues/20559

ojjj13 on (2024-03-27 00:59:20 UTC): Pulse inconsistency has been an issue for a very long time.

paoliniluis on (2024-03-27 11:20:54 UTC): Duplicate of pulse inconsistency bugs, we‚Äôre trying to fix it soon but it‚Äôs hard

"
2208749691,issue,closed,completed,UI Adjustments,"Link to[ Figma](https://www.figma.com/file/itS8tiVp9ea8dQPqTvhpwF/Beautifying-the-command-palette?type=design&node-id=6-2&mode=design&t=8lGsEWIiEKMNyggN-0)

Summary:
match search bar and item size
heading styles, division
icon soft blue, change in active state
icon grey change
open next to return key, remove open from footer
change select icon, also color (called sort)
match overlay to other modals (color, remove blur)",npfitz,2024-03-26 16:33:56+00:00,['npfitz'],2024-04-03 13:21:29+00:00,2024-04-03 13:21:29+00:00,https://github.com/metabase/metabase/issues/40631,[],[],
2208503471,issue,open,,Move CSV uploads to RTK Query,- make sure that uploads invalidate table tags so that the upload-management payloads get invalidated,iethree,2024-03-26 14:59:05+00:00,[],2024-07-15 16:46:56+00:00,,https://github.com/metabase/metabase/issues/40625,"[('Organization/Uploads', 'Direct data upload (CSV)')]","[{'comment_id': 2107392481, 'issue_id': 2208503471, 'author': 'iethree', 'body': ""this doesn't need to block v50"", 'created_at': datetime.datetime(2024, 5, 13, 12, 2, 40, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-05-13 12:02:40 UTC): this doesn't need to block v50

"
2208381599,issue,closed,not_planned,Scalar view stays after more columns are added to a native query,"### Describe the bug

The query results show a nice ""scalar"" view if you select only a single column. Example `select 'foo'`

<img width=""1344"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/69350bd9-7c5f-4fbb-8b0d-49815a2bca3f"">

If you then extend this same query to `select 'foo', 'bar'` the viz display does not realize it's seeing more than a single column and continues to only show the first column:

<img width=""1451"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/2be68202-33ed-4db1-b18f-7c3a9f84fd5c"">

This is because the display ""scalar"" has been encoded in the query:

```clojure
;; ""#eyJkYXRhc2V0X3F1ZXJ5Ijp7ImRhdGFiYXNlIjoyLCJ0eXBlIjoibmF0aXZlIiwibmF0aXZlIjp7InF1ZXJ5Ijoic2VsZWN0ICdmb28nLCAnYmFyJyIsInRlbXBsYXRlLXRhZ3MiOnt9fX0sImRpc3BsYXkiOiJzY2FsYXIiLCJwYXJhbWV0ZXJzIjpbXSwidmlzdWFsaXphdGlvbl9zZXR0aW5ncyI6e319""


{:dataset_query {:database 2,
                 :type ""native"",
                 :native {:query ""select 'foo', 'bar'"",
                          :template-tags {}}},
 :display ""scalar"",  ;; <----------------
 :parameters [],
 :visualization_settings {}}
```

And reloading the page, sharing the link, etc still exemplifies this bug.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

A native query selecting a single column and a single row. Then extend to multiple columns and you will only see the first column.

`select email from PEOPLE where id = 1` on sample database. Then `select id, email from PEOPLE where id = 1`

<img width=""1451"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/0b8bbc48-8b1a-404a-b126-90cc1ab20316"">


### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p2

### Additional context

at first thought it was a p1. But since it requires selecting a single column first and then not dropping that it seems not a p1.",dpsutton,2024-03-26 14:13:56+00:00,[],2024-09-27 15:47:15+00:00,2024-09-27 15:47:15+00:00,https://github.com/metabase/metabase/issues/40623,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/', ''), ('Querying/Native', 'The SQL/native query editor'), ('Visualization/Scalars', 'Numbers, progress bars, gauges'), ('Visualization/Tables', 'raw, summarized and tabular visualizations'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2179266539, 'issue_id': 2208381599, 'author': 'JesseSDevaney', 'body': 'Dropping this for now in favor of higher priority issues. \r\n\r\nContext: https://metaboat.slack.com/archives/C064QMXEV9N/p1718761174731189?thread_ts=1718747924.798209&cid=C064QMXEV9N', 'created_at': datetime.datetime(2024, 6, 19, 18, 11, 39, tzinfo=datetime.timezone.utc)}]","JesseSDevaney on (2024-06-19 18:11:39 UTC): Dropping this for now in favor of higher priority issues. 

Context: https://metaboat.slack.com/archives/C064QMXEV9N/p1718761174731189?thread_ts=1718747924.798209&cid=C064QMXEV9N

"
2208279173,issue,closed,completed,Filter modal UI breaks when there are many tables in a question,"### Describe the bug

When there are several tables in a question, either via explicit or automatic joins, the table selector in the filter model may overflow, causing the elements that don't fit to spill into a second column, which breaks the UI.

### To Reproduce

1. Go to Table Metadata, Sample Database, rename Reviews to 'Reviews, but a very long name' 
2. Create a GUI question, Reviews inner join Orders
3. Click on Visualize
4. Click on Filter
5. Resize the browser so that there is less vertical space, and see the error:

<img width=""828"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/a4e914bc-57d1-48eb-9e66-821ca0af3acb"">



### Expected behavior

The table selector should be vertically scrollable?

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.75-0-virt"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v1.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Reported by a customer

### Additional context

_No response_",zbodi74,2024-03-26 13:36:35+00:00,['nemanjaglumac'],2024-07-11 13:34:05+00:00,2024-07-11 13:32:14+00:00,https://github.com/metabase/metabase/issues/40622,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/', ''), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2222953272, 'issue_id': 2208279173, 'author': 'kamilmielnik', 'body': 'Closed by #45352 + #45363', 'created_at': datetime.datetime(2024, 7, 11, 13, 32, 14, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-07-11 13:32:14 UTC): Closed by #45352 + #45363

"
2208238140,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/scroll.module.css`,,oisincoveney,2024-03-26 13:22:52+00:00,['oisincoveney'],2024-03-28 14:11:39+00:00,2024-03-28 14:11:39+00:00,https://github.com/metabase/metabase/issues/40620,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2208100576,issue,closed,completed,Unable to see all labels in pie diagram in Metabase,"### Describe the bug

Unable to see all labels in pie diagram in Metabase
![image](https://github.com/metabase/metabase/assets/165027906/09b962f3-e3ee-4e41-ac6c-60bc974a624a)

In the above image i'm not able to get the percentages for few areas in the pie chart

### To Reproduce

I have written a query to get the list of hours spent on a program, i am listing all the programs available in the database
![image](https://github.com/metabase/metabase/assets/165027906/2c211809-99b2-4637-b4b8-3d92d2b2f103)
The above is my data used to represent the pie diagram

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.12""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-22"",
      ""tag"": ""v0.48.7"",
      ""hash"": ""c192db1""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

high

### Additional context

_No response_",akhilasemsani,2024-03-26 12:22:23+00:00,[],2024-10-08 16:18:49+00:00,2024-08-05 05:53:12+00:00,https://github.com/metabase/metabase/issues/40617,"[('Type:New Feature', ''), ('.Completeness', ''), ('.Frontend', ''), ('Visualization/Charts/Pie', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2020405552, 'issue_id': 2208100576, 'author': 'paoliniluis', 'body': 'Hi, the problem here seems to be that those legends will not fit on the chart, how do you think this should be managed?', 'created_at': datetime.datetime(2024, 3, 26, 13, 16, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2021192848, 'issue_id': 2208100576, 'author': 'francisco-mooddie', 'body': '> Hi, the problem here seems to be that those legends will not fit on the chart, how do you think this should be managed?\r\n\r\nTo resolve this issue, an additional option should be added to the pie chart settings to enable the listing of percentages both on the chart and in the legend.', 'created_at': datetime.datetime(2024, 3, 26, 18, 32, 41, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-26 13:16:23 UTC): Hi, the problem here seems to be that those legends will not fit on the chart, how do you think this should be managed?

francisco-mooddie on (2024-03-26 18:32:41 UTC): To resolve this issue, an additional option should be added to the pie chart settings to enable the listing of percentages both on the chart and in the legend.

"
2207489824,issue,closed,completed,Notebook query preview exists even before the data source is selected,"### Describe the bug

We're showing the notebook query preview even before someone selects a data source. Clicking on it will result in a forever loading spinner and a failed `POST /api/dataset` request.

### To Reproduce

1. Click on ""New"" > Question
![new](https://github.com/metabase/metabase/assets/31325167/e18bd19a-f4df-483d-8a7b-7c9427eb61b0)
2. Click on the little preview button next to the blue ""Pick your starting data"" rectangle
3. The loader is spinning ad infinitum and there is a failed request in the network tab
![Kapture 2024-03-26 at 08 50 21](https://github.com/metabase/metabase/assets/31325167/f00c577e-2834-470d-a7c4-61f063e8031c)

### Expected behavior

The preview button should appear only when a query can run, i.e. when there is a data source.

### Logs
```json
{
  ""via"": [
    {
      ""type"": ""clojure.lang.ExceptionInfo"",
      ""message"": ""`database` is required for all queries whose type is not `internal`."",
      ""data"": {
        ""status-code"": 400,
        ""query"": {
          ""type"": ""query"",
          ""query"": {
            ""limit"": 10
          },
          ""parameters"": [],
          ""middleware"": {
            ""js-int-to-string?"": true,
            ""userland-query?"": true,
            ""add-default-userland-constraints?"": true
          },
          ""info"": null
        }
      },
      ""at"": [
        ""metabase.api.dataset$fn__114124$_AMPERSAND_f__114127"",
        ""doInvoke"",
        ""dataset.clj"",
        60
      ]
    }
  ],
  ""trace"": [
    [
      ""metabase.api.dataset$fn__114124$_AMPERSAND_f__114127"",
      ""doInvoke"",
      ""dataset.clj"",
      60
    ],
    [...],
    [
      ""java.lang.Thread"",
      ""run"",
      ""Thread.java"",
      829
    ]
  ],
  ""cause"": ""`database` is required for all queries whose type is not `internal`."",
  ""data"": {
    ""status-code"": 400,
    ""query"": {
      ""type"": ""query"",
      ""query"": {
        ""limit"": 10
      },
      ""parameters"": [],
      ""middleware"": {
        ""js-int-to-string?"": true,
        ""userland-query?"": true,
        ""add-default-userland-constraints?"": true
      },
      ""info"": null
    }
  },
  ""message"": ""`database` is required for all queries whose type is not `internal`."",
  ""query"": {
    ""type"": ""query"",
    ""query"": {
      ""limit"": 10
    },
    ""parameters"": [],
    ""middleware"": {
      ""js-int-to-string?"": true,
      ""userland-query?"": true,
      ""add-default-userland-constraints?"": true
    },
    ""info"": null
  }
}
```

### Information about your Metabase installation

local dev, `master`, dc279fd, H2, Sample Database



### Severity

P3
",nemanjaglumac,2024-03-26 07:49:39+00:00,['nemanjaglumac'],2024-04-11 08:55:35+00:00,2024-04-03 11:09:54+00:00,https://github.com/metabase/metabase/issues/40608,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]",[],
2206965983,issue,closed,completed,Send locale parameter via headers,"**Is your feature request related to a problem? Please describe.**
We have a customer that needs to send the locale via headers https://www.metabase.com/docs/latest/embedding/interactive-embedding#locale. We need to accept the parameter via url or via headers

**Describe the solution you'd like**
Accept the locale parameter via a header

**Describe alternatives you've considered**
None

**How important is this feature to you?**
Requested by a customer due to an internal requirement

**Additional context**
NA
",paoliniluis,2024-03-26 00:12:16+00:00,[],2024-04-01 09:45:51+00:00,2024-04-01 09:45:51+00:00,https://github.com/metabase/metabase/issues/40607,"[('Type:Documentation', ''), ('Type:New Feature', ''), ('Embedding/Interactive', 'Interactive Embedding, previously known as Full app embedding')]","[{'comment_id': 2029435419, 'issue_id': 2206965983, 'author': 'WiNloSt', 'body': 'We implemented `X-Metabase-Locale` in https://github.com/metabase/metabase/pull/12566. Would this work for them?', 'created_at': datetime.datetime(2024, 4, 1, 8, 56, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029495245, 'issue_id': 2206965983, 'author': 'paoliniluis', 'body': 'another day, another undocumented secret we find hidden in the depths of the code. Thanks @WiNloSt', 'created_at': datetime.datetime(2024, 4, 1, 9, 45, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029495807, 'issue_id': 2206965983, 'author': 'paoliniluis', 'body': '@jeff-bruemmer FYI, I guess that no one even knew this existed', 'created_at': datetime.datetime(2024, 4, 1, 9, 45, 51, tzinfo=datetime.timezone.utc)}]","WiNloSt on (2024-04-01 08:56:52 UTC): We implemented `X-Metabase-Locale` in https://github.com/metabase/metabase/pull/12566. Would this work for them?

paoliniluis (Issue Creator) on (2024-04-01 09:45:16 UTC): another day, another undocumented secret we find hidden in the depths of the code. Thanks @WiNloSt

paoliniluis (Issue Creator) on (2024-04-01 09:45:51 UTC): @jeff-bruemmer FYI, I guess that no one even knew this existed

"
2206942973,issue,closed,not_planned,ERROR: Interval end (763426800000000) must be after last timestamp (763429126166353),"### Describe the bug

Running a query against our database led to the following error:
ERROR: Interval end (763426800000000) must be after last timestamp (763429126166353)
This query had a datetime column with 1 value per day at midnight each day. Small, seemingly unrelated, modifications to the query would either fix the query or break it again with the same error. After realizing the query always worked outside of metabase, I was able to determine that the issue goes away after turning off a timezone option. US/Pacific would reproduce the issue, UTC would not.

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

Error should not occur.

### Logs

[8bdb4dc8-879f-4a08-8471-5c9f438e6640] 2024-03-25T16:02:05-07:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: ERROR: Interval end (763426800000000) must be after last timestamp (763430024941659)
{:database_id 2,
 :started_at #t ""2024-03-25T23:02:04.489120Z[GMT]"",
 :via
 [{:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error ""Error executing query: ERROR: Interval end (763426800000000) must be after last timestamp (763430024941659)"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__77872$fn__77873.invoke(execute.clj:698)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__77872.invoke(execute.clj:695)""
    ""driver.sql_jdbc.execute$fn__77665$fn__77666.invoke(execute.clj:388)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
    ""driver.sql_jdbc.execute$fn__77665.invokeStatic(execute.clj:382)""
    ""driver.sql_jdbc.execute$fn__77665.invoke(execute.clj:380)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:686)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc$fn__111188.invokeStatic(sql_jdbc.clj:82)""
    ""driver.sql_jdbc$fn__111188.invoke(sql_jdbc.clj:80)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70857.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__65066.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__70678.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__70688.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__69925.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__71991$combined_post_process__71996$combined_post_process_STAR___71997.invoke(query_processor.clj:262)""
    ""query_processor$fn__71991$combined_pre_process__71992$combined_pre_process_STAR___71993.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65163.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__70768$fn__70772.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:94)""
    ""driver$do_with_driver.invoke(driver.clj:89)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__70768.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__65555$fn__65556.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__65555.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__70765.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__71070.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__70705$handle_audit_app_internal_queries__70706$fn__70708.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__70716.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__69640.invoke(constraints.clj:102)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__71001.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__71591.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___60736$thunk__60738.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___60736.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___60748.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__94112.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51589$fn__51591.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__51589.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__42912.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :postgres,
    :sql
    [""-- Metabase:: userID: 3 queryType: native queryHash: 968fa4bf8d6b1b79306a85366153c1c8d5ca7fd79838020b6a736d3791f3bb67""
  [REDACTED],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :state ""XX000"",
 :error_type :invalid-query,
 :json_query
 {:type ""native"",
  :native
  {:query
   [REDACTED]
   :template-tags {}},
  :database 2,
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class org.postgresql.util.PSQLException,
 :stacktrace
 [""org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2713)""
  ""org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2401)""
  ""org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:368)""
  ""org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:498)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:415)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:335)""
  ""org.postgresql.jdbc.PgStatement.executeCachedSql(PgStatement.java:321)""
  ""org.postgresql.jdbc.PgStatement.executeWithFlags(PgStatement.java:297)""
  ""org.postgresql.jdbc.PgStatement.execute(PgStatement.java:292)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__77791.invokeStatic(execute.clj:560)""
  ""driver.sql_jdbc.execute$fn__77791.invoke(execute.clj:558)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:568)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:565)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__77872$fn__77873.invoke(execute.clj:696)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__77872.invoke(execute.clj:695)""
  ""driver.sql_jdbc.execute$fn__77665$fn__77666.invoke(execute.clj:388)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
  ""driver.sql_jdbc.execute$fn__77665.invokeStatic(execute.clj:382)""
  ""driver.sql_jdbc.execute$fn__77665.invoke(execute.clj:380)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:686)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc$fn__111188.invokeStatic(sql_jdbc.clj:82)""
  ""driver.sql_jdbc$fn__111188.invoke(sql_jdbc.clj:80)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___70857.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__65066.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__70678.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__70688.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__69925.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__71991$combined_post_process__71996$combined_post_process_STAR___71997.invoke(query_processor.clj:262)""
  ""query_processor$fn__71991$combined_pre_process__71992$combined_pre_process_STAR___71993.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__65163.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__70768$fn__70772.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:94)""
  ""driver$do_with_driver.invoke(driver.clj:89)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__70768.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__65555$fn__65556.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__65555.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__70765.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__71070.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__70705$handle_audit_app_internal_queries__70706$fn__70708.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__70716.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__69640.invoke(constraints.clj:102)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__71001.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__71591.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___60736$thunk__60738.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___60736.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___60748.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__94112.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__51589$fn__51591.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__51589.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__42912.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""ERROR: Interval end (763426800000000) must be after last timestamp (763430024941659)"",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}

### Information about your Metabase installation

```JSON
- Metabase Cloud
https://strella.metabaseapp.com
```


### Severity

Annoying

### Additional context

_No response_",mattweissstrella,2024-03-25 23:48:05+00:00,[],2024-03-26 17:26:30+00:00,2024-03-26 00:08:22+00:00,https://github.com/metabase/metabase/issues/40605,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', '')]","[{'comment_id': 2019136757, 'issue_id': 2206942973, 'author': 'paoliniluis', 'body': ""please send us a ticket if you're a cloud customer"", 'created_at': datetime.datetime(2024, 3, 26, 0, 8, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2021051663, 'issue_id': 2206942973, 'author': 'mattweissstrella', 'body': ""> please send us a ticket if you're a cloud customer\r\n\r\n@paoliniluis How do I do this? The only link I see in the cloud application takes me here."", 'created_at': datetime.datetime(2024, 3, 26, 17, 26, 29, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-26 00:08:22 UTC): please send us a ticket if you're a cloud customer

mattweissstrella (Issue Creator) on (2024-03-26 17:26:29 UTC): @paoliniluis How do I do this? The only link I see in the cloud application takes me here.

"
2206569194,issue,closed,completed,[dc.js migration] query builder performance slow for certain questions,"https://github.com/metabase/metabase/assets/37751258/65e98cb4-b105-4fba-808a-240f811dc996

http://localhost:3000/question/287-bar-stacked-pow-y-axis-poke-avg-of-base-stats-by-gen

In the recording you can see there is no lag on stats, but with echarts there is significant lag when switching to the table view, or opening the notebook editor.

Here is the csv if you need to repro on a different app db

[pokedex.csv](https://github.com/metabase/metabase/files/14748854/pokedex.csv)
",EmmadUsmani,2024-03-25 19:49:35+00:00,['JesseSDevaney'],2024-03-28 22:07:57+00:00,2024-03-28 22:07:57+00:00,https://github.com/metabase/metabase/issues/40602,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2026218265, 'issue_id': 2206569194, 'author': 'JesseSDevaney', 'body': 'Could not reproduce locally with the same dataset and visualization settings applied.', 'created_at': datetime.datetime(2024, 3, 28, 22, 7, 57, tzinfo=datetime.timezone.utc)}]","JesseSDevaney (Assginee) on (2024-03-28 22:07:57 UTC): Could not reproduce locally with the same dataset and visualization settings applied.

"
2206562298,issue,closed,completed,[dc.js migration] custom y-axis range broken on log & pow y-axis scales,"<img width=""1898"" alt=""Screenshot 2024-03-25 at 12 41 57 PM"" src=""https://github.com/metabase/metabase/assets/37751258/a09fa40b-1509-457d-a2b5-36ad430d80ef"">

ECharts on left, stats on right",EmmadUsmani,2024-03-25 19:45:54+00:00,['JesseSDevaney'],2024-03-29 19:12:04+00:00,2024-03-29 19:12:04+00:00,https://github.com/metabase/metabase/issues/40601,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2206562292,issue,closed,completed,Cannot duplicate or save questions when moving from 42 to 49,"**Describe the bug**
Cannot duplicate a question

**Logs**
Error 400 card API : should be a boolean, recebido: 0

PUT /api/card/310 400 1.9 ms (0 chamadas ao banco de dados) 
{:errors {:collection_preview ""nullable boolean""},
 :specific-errors {:collection_preview [""should be a boolean, recebido: 1""]}}

**To Reproduce**
Steps to reproduce the behavior:
1. Go to Question
2. Click on Duplicate
3. Click in Duplicate

**Expected behavior**
Duplicate

**Screenshots**
![image](https://github.com/metabase/metabase/assets/3492068/698b2410-8069-4102-8702-f6774ffacef1)

**Severity**
It's very Hard because I copy many 

**Additional context**
It happens if I change something and try to save as another question too.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-1111-azure"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.32""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",satodu,2024-03-25 19:45:54+00:00,['johnswanson'],2024-06-12 16:06:11+00:00,2024-06-06 19:55:34+00:00,https://github.com/metabase/metabase/issues/40600,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Organization/Collections', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2018881403, 'issue_id': 2206562292, 'author': 'satodu', 'body': 'I did changing in the payload from 0 to false, but I don\'t know where change in the code\r\n\r\n ""dataset"": false,', 'created_at': datetime.datetime(2024, 3, 25, 20, 44, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2019029691, 'issue_id': 2206562292, 'author': 'paoliniluis', 'body': ""I just tested this and can't reproduce, are you running Metabase behind a WAF and you're getting the assets of the frontend cached?"", 'created_at': datetime.datetime(2024, 3, 25, 22, 27, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2019103947, 'issue_id': 2206562292, 'author': 'satodu', 'body': 'https://github.com/metabase/metabase/assets/3492068/eff877e1-3865-4aee-82c8-ac446c868afb\r\n\r\nNo, I am running using kubernetes, with container.\r\n\r\nI solved using directly the entrypoint I will try to fix in the code, but I neves used the metabase on local for development, look how I did to solved and above you can see the error.\r\n\r\n\r\nhttps://github.com/metabase/metabase/assets/3492068/7b146646-87c1-495e-8f04-f8f209a362f9', 'created_at': datetime.datetime(2024, 3, 25, 23, 32, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2019104583, 'issue_id': 2206562292, 'author': 'satodu', 'body': '@paoliniluis please reopen my thread I will try to solve but maybe can help someone.', 'created_at': datetime.datetime(2024, 3, 25, 23, 33, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027545296, 'issue_id': 2206562292, 'author': 'alquerci', 'body': 'Hello there,\r\n\r\nThis issue was caught after migration from version between 0.40 and 0.48 to version 0.49.1.\r\nBut no issue from fresh installation of version 0.49.1.\r\n\r\nBrowser: Firefox 124.0\r\nBase URL: `https://custom.tld/metabase`\r\nNo CDN, No cache used by the browser.\r\n\r\nThe request payload\r\n![image](https://github.com/metabase/metabase/assets/2987860/a7c0a1ec-ad58-41a1-b289-81ae7a0c3478)', 'created_at': datetime.datetime(2024, 3, 29, 17, 51, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027962996, 'issue_id': 2206562292, 'author': 'paoliniluis', 'body': 'Hi, we need a way to reproduce this, otherwise we can‚Äôt fix', 'created_at': datetime.datetime(2024, 3, 30, 8, 8, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2028838049, 'issue_id': 2206562292, 'author': 'alquerci', 'body': '@paoliniluis indeed\r\n\r\n### In short\r\nGiven v0.42.6\r\nWhen migrate to v0.49.2 and edit and save an existing question.\r\nThen `collection_preview: 1` instead of `collection_preview: true`\r\n\r\n### More details steps\r\n1. Start `metabase/metabase:v0.42.6`\r\n2. Create SQL question ""What is the version of mysql server?"" with `select version()`\r\n3. Stop\r\n4. Start `metabase/metabase:v0.49.2`\r\n5. Open question, ""What is the version of mysql server?""\r\n6. Change the SQL content, adding a space is enough\r\n7. Save the question\r\n\r\nUsing this docker-compose configuration.\r\n\r\n```yaml\r\nversion: \'3.8\'\r\n\r\nvolumes:\r\n  source-database: ~\r\n  metabase-mariadb: ~\r\n\r\nservices:\r\n  metabase:\r\n    # image: metabase/metabase:v0.49.2\r\n    image: metabase/metabase:v0.42.6\r\n    environment:\r\n      MB_JETTY_HOST: 0.0.0.0\r\n      MB_JETTY_PORT: 3000\r\n      MB_DB_TYPE: mysql\r\n      MB_DB_DBNAME: name\r\n      MB_DB_USER: user\r\n      MB_DB_PASS: pass\r\n      MB_DB_HOST: metabase-mariadb\r\n    depends_on:\r\n      - metabase-mariadb\r\n      - database\r\n\r\n  metabase-mariadb:\r\n    image: mariadb:10.11.7\r\n    volumes:\r\n      - metabase-mariadb:/var/lib/mysql\r\n    environment:\r\n      MARIADB_ROOT_PASSWORD: root\r\n      MARIADB_DATABASE: name\r\n      MARIADB_USER: user\r\n      MARIADB_PASSWORD: pass\r\n\r\n  database:\r\n    image: mysql:5.7.42-debian\r\n    command: --default-authentication-plugin=mysql_native_password\r\n    volumes:\r\n      - source-database:/var/lib/mysql\r\n    environment:\r\n      MYSQL_ROOT_PASSWORD: root\r\n      MYSQL_DATABASE: name\r\n      MYSQL_USER: user\r\n      MYSQL_PASSWORD: pass\r\n```', 'created_at': datetime.datetime(2024, 3, 31, 17, 42, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2031362643, 'issue_id': 2206562292, 'author': 'paoliniluis', 'body': 'Interesting, I can\'t still recognize if this should be tackled by backend or frontend, but clearly we had stuff in 42 that don\'t work anymore in 49\r\n\r\neither way, the repro stack is easier:\r\n```\r\nservices:\r\n  metabase:\r\n    image: metabase/metabase:v0.49.2\r\n    # image: metabase/metabase:v0.42.6\r\n    ports:\r\n      - 3000:3000\r\n    environment:\r\n      MB_JETTY_HOST: 0.0.0.0\r\n      MB_JETTY_PORT: 3000\r\n      MB_DB_TYPE: mysql\r\n      MB_DB_DBNAME: name\r\n      MB_DB_USER: user\r\n      MB_DB_PASS: pass\r\n      MB_DB_HOST: metabase-mariadb\r\n    depends_on:\r\n      - metabase-mariadb\r\n\r\n  metabase-mariadb:\r\n    image: mariadb:11.2.2\r\n    environment:\r\n      MARIADB_ROOT_PASSWORD: root\r\n      MARIADB_DATABASE: name\r\n      MARIADB_USER: user\r\n      MARIADB_PASSWORD: pass\r\n```\r\n\r\n1) Start v42, initialize it, create a question on the sample db with ""select 1"", save it\r\n2) stop the stack (do not remove the containers, just stop those)\r\n3) change the line from 42 to 49\r\n4) start the stack again (metabase will perform the migrations\r\n5) open the saved question and add a space or a new line, try to save\r\nyou\'ll get\r\n```\r\nmetabase-1          | 2024-04-02 08:14:34,966 DEBUG middleware.log :: PUT /api/card/1 400 5.2 ms (0 DB calls) \r\nmetabase-1          | {:errors {:collection_preview ""nullable boolean""},\r\nmetabase-1          |  :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}\r\nmetabase-1          | \r\n\r\n```', 'created_at': datetime.datetime(2024, 4, 2, 8, 17, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2031364981, 'issue_id': 2206562292, 'author': 'paoliniluis', 'body': 'Interesting, I can\'t still recognize if this should be tackled by backend or frontend, but clearly we had stuff in 42 that don\'t work anymore in 49\r\n\r\neither way, the repro stack is easier:\r\n```\r\nservices:\r\n  metabase:\r\n    image: metabase/metabase:v0.49.2\r\n    # image: metabase/metabase:v0.42.6\r\n    ports:\r\n      - 3000:3000\r\n    environment:\r\n      MB_JETTY_HOST: 0.0.0.0\r\n      MB_JETTY_PORT: 3000\r\n      MB_DB_TYPE: mysql\r\n      MB_DB_DBNAME: name\r\n      MB_DB_USER: user\r\n      MB_DB_PASS: pass\r\n      MB_DB_HOST: metabase-mariadb\r\n    depends_on:\r\n      - metabase-mariadb\r\n\r\n  metabase-mariadb:\r\n    image: mariadb:11.2.2\r\n    environment:\r\n      MARIADB_ROOT_PASSWORD: root\r\n      MARIADB_DATABASE: name\r\n      MARIADB_USER: user\r\n      MARIADB_PASSWORD: pass\r\n```\r\n\r\n1) Start v42, initialize it, create a question on the sample db with ""select 1"", save it\r\n2) stop the stack (do not remove the containers, just stop those)\r\n3) change the line from 42 to 49\r\n4) start the stack again (metabase will perform the migrations\r\n5) open the saved question and add a space or a new line, try to save\r\nyou\'ll get\r\n```\r\nmetabase-1          | 2024-04-02 08:14:34,966 DEBUG middleware.log :: PUT /api/card/1 400 5.2 ms (0 DB calls) \r\nmetabase-1          | {:errors {:collection_preview ""nullable boolean""},\r\nmetabase-1          |  :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}\r\nmetabase-1          | \r\n\r\n```', 'created_at': datetime.datetime(2024, 4, 2, 8, 18, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120520736, 'issue_id': 2206562292, 'author': 'ranquild', 'body': ""It seems that `collection_preview` wasn't correctly migrated"", 'created_at': datetime.datetime(2024, 5, 20, 13, 58, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2129052728, 'issue_id': 2206562292, 'author': 'yreifschneider', 'body': '@johnswanson unfortunately, this issue is still present in version 0.49.12 but with different column `dataset` in table `report_card`.\r\n\r\n![Frage ¬∑ Metabase_2024-05-24_11-22-19](https://github.com/metabase/metabase/assets/1786271/295802d9-e8a9-4d6d-ba9b-94f42c96f299)', 'created_at': datetime.datetime(2024, 5, 24, 9, 22, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2138674037, 'issue_id': 2206562292, 'author': 'SakuragiYoshimasa', 'body': 'I opened PR for `report_card.dataset` mentioned by @yreifschneider, could @johnswanson review?', 'created_at': datetime.datetime(2024, 5, 30, 4, 49, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2163418000, 'issue_id': 2206562292, 'author': 'alquerci', 'body': 'Thank you very much to all who contributed to fix this issue. :heart:', 'created_at': datetime.datetime(2024, 6, 12, 16, 5, 46, tzinfo=datetime.timezone.utc)}]","satodu (Issue Creator) on (2024-03-25 20:44:13 UTC): I did changing in the payload from 0 to false, but I don't know where change in the code

 ""dataset"": false,

paoliniluis on (2024-03-25 22:27:30 UTC): I just tested this and can't reproduce, are you running Metabase behind a WAF and you're getting the assets of the frontend cached?

satodu (Issue Creator) on (2024-03-25 23:32:46 UTC): https://github.com/metabase/metabase/assets/3492068/eff877e1-3865-4aee-82c8-ac446c868afb

No, I am running using kubernetes, with container.

I solved using directly the entrypoint I will try to fix in the code, but I neves used the metabase on local for development, look how I did to solved and above you can see the error.


https://github.com/metabase/metabase/assets/3492068/7b146646-87c1-495e-8f04-f8f209a362f9

satodu (Issue Creator) on (2024-03-25 23:33:29 UTC): @paoliniluis please reopen my thread I will try to solve but maybe can help someone.

alquerci on (2024-03-29 17:51:32 UTC): Hello there,

This issue was caught after migration from version between 0.40 and 0.48 to version 0.49.1.
But no issue from fresh installation of version 0.49.1.

Browser: Firefox 124.0
Base URL: `https://custom.tld/metabase`
No CDN, No cache used by the browser.

The request payload
![image](https://github.com/metabase/metabase/assets/2987860/a7c0a1ec-ad58-41a1-b289-81ae7a0c3478)

paoliniluis on (2024-03-30 08:08:04 UTC): Hi, we need a way to reproduce this, otherwise we can‚Äôt fix

alquerci on (2024-03-31 17:42:40 UTC): @paoliniluis indeed

### In short
Given v0.42.6
When migrate to v0.49.2 and edit and save an existing question.
Then `collection_preview: 1` instead of `collection_preview: true`

### More details steps
1. Start `metabase/metabase:v0.42.6`
2. Create SQL question ""What is the version of mysql server?"" with `select version()`
3. Stop
4. Start `metabase/metabase:v0.49.2`
5. Open question, ""What is the version of mysql server?""
6. Change the SQL content, adding a space is enough
7. Save the question

Using this docker-compose configuration.

```yaml
version: '3.8'

volumes:
  source-database: ~
  metabase-mariadb: ~

services:
  metabase:
    # image: metabase/metabase:v0.49.2
    image: metabase/metabase:v0.42.6
    environment:
      MB_JETTY_HOST: 0.0.0.0
      MB_JETTY_PORT: 3000
      MB_DB_TYPE: mysql
      MB_DB_DBNAME: name
      MB_DB_USER: user
      MB_DB_PASS: pass
      MB_DB_HOST: metabase-mariadb
    depends_on:
      - metabase-mariadb
      - database

  metabase-mariadb:
    image: mariadb:10.11.7
    volumes:
      - metabase-mariadb:/var/lib/mysql
    environment:
      MARIADB_ROOT_PASSWORD: root
      MARIADB_DATABASE: name
      MARIADB_USER: user
      MARIADB_PASSWORD: pass

  database:
    image: mysql:5.7.42-debian
    command: --default-authentication-plugin=mysql_native_password
    volumes:
      - source-database:/var/lib/mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: name
      MYSQL_USER: user
      MYSQL_PASSWORD: pass
```

paoliniluis on (2024-04-02 08:17:36 UTC): Interesting, I can't still recognize if this should be tackled by backend or frontend, but clearly we had stuff in 42 that don't work anymore in 49

either way, the repro stack is easier:
```
services:
  metabase:
    image: metabase/metabase:v0.49.2
    # image: metabase/metabase:v0.42.6
    ports:
      - 3000:3000
    environment:
      MB_JETTY_HOST: 0.0.0.0
      MB_JETTY_PORT: 3000
      MB_DB_TYPE: mysql
      MB_DB_DBNAME: name
      MB_DB_USER: user
      MB_DB_PASS: pass
      MB_DB_HOST: metabase-mariadb
    depends_on:
      - metabase-mariadb

  metabase-mariadb:
    image: mariadb:11.2.2
    environment:
      MARIADB_ROOT_PASSWORD: root
      MARIADB_DATABASE: name
      MARIADB_USER: user
      MARIADB_PASSWORD: pass
```

1) Start v42, initialize it, create a question on the sample db with ""select 1"", save it
2) stop the stack (do not remove the containers, just stop those)
3) change the line from 42 to 49
4) start the stack again (metabase will perform the migrations
5) open the saved question and add a space or a new line, try to save
you'll get
```
metabase-1          | 2024-04-02 08:14:34,966 DEBUG middleware.log :: PUT /api/card/1 400 5.2 ms (0 DB calls) 
metabase-1          | {:errors {:collection_preview ""nullable boolean""},
metabase-1          |  :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}
metabase-1          | 

```

paoliniluis on (2024-04-02 08:18:40 UTC): Interesting, I can't still recognize if this should be tackled by backend or frontend, but clearly we had stuff in 42 that don't work anymore in 49

either way, the repro stack is easier:
```
services:
  metabase:
    image: metabase/metabase:v0.49.2
    # image: metabase/metabase:v0.42.6
    ports:
      - 3000:3000
    environment:
      MB_JETTY_HOST: 0.0.0.0
      MB_JETTY_PORT: 3000
      MB_DB_TYPE: mysql
      MB_DB_DBNAME: name
      MB_DB_USER: user
      MB_DB_PASS: pass
      MB_DB_HOST: metabase-mariadb
    depends_on:
      - metabase-mariadb

  metabase-mariadb:
    image: mariadb:11.2.2
    environment:
      MARIADB_ROOT_PASSWORD: root
      MARIADB_DATABASE: name
      MARIADB_USER: user
      MARIADB_PASSWORD: pass
```

1) Start v42, initialize it, create a question on the sample db with ""select 1"", save it
2) stop the stack (do not remove the containers, just stop those)
3) change the line from 42 to 49
4) start the stack again (metabase will perform the migrations
5) open the saved question and add a space or a new line, try to save
you'll get
```
metabase-1          | 2024-04-02 08:14:34,966 DEBUG middleware.log :: PUT /api/card/1 400 5.2 ms (0 DB calls) 
metabase-1          | {:errors {:collection_preview ""nullable boolean""},
metabase-1          |  :specific-errors {:collection_preview [""should be a boolean, received: 1""]}}
metabase-1          | 

```

ranquild on (2024-05-20 13:58:48 UTC): It seems that `collection_preview` wasn't correctly migrated

yreifschneider on (2024-05-24 09:22:46 UTC): @johnswanson unfortunately, this issue is still present in version 0.49.12 but with different column `dataset` in table `report_card`.

![Frage ¬∑ Metabase_2024-05-24_11-22-19](https://github.com/metabase/metabase/assets/1786271/295802d9-e8a9-4d6d-ba9b-94f42c96f299)

SakuragiYoshimasa on (2024-05-30 04:49:55 UTC): I opened PR for `report_card.dataset` mentioned by @yreifschneider, could @johnswanson review?

alquerci on (2024-06-12 16:05:46 UTC): Thank you very much to all who contributed to fix this issue. :heart:

"
2206261345,issue,open,,Ability to set default dashboard filters using user attributes ,"**Is your feature request related to a problem? Please describe.**
You may not want to set a default value to filters, as people from different groups want to have different results

**Describe the solution you'd like**
Pre-filter dashboards based on a user's attributes, e.g. for dashboards targeting Recruiters, default to filtering by the current user's name

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer that use the same dashboard for different groups

**Additional context**
N/A",ignacio-mb,2024-03-25 17:06:34+00:00,[],2025-02-04 20:29:47+00:00,,https://github.com/metabase/metabase/issues/40590,"[('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Administration/People', 'and Groups. Also user Account Settings'), ('Reporting/Dashboards/Filters & Parameters', 'Related to the setup and use of filters and parameters in dashboards only')]",[],
2206246418,issue,open,,Add Error state for incorrect CSV/TSV file upload type,"If you upload a csv file via a system dialog, it filters to valid files, and then if you upload something invalid, it warns you. However, if you upload via dragging into a collection, it just silently rejects. We should add an explicit error UI state",iethree,2024-03-25 17:01:27+00:00,[],2025-02-05 19:16:14+00:00,,https://github.com/metabase/metabase/issues/40589,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Uploads', 'Direct data upload (CSV)')]",[],
2206119075,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/hover.module.css`,,oisincoveney,2024-03-25 16:07:04+00:00,['oisincoveney'],2024-04-12 14:09:40+00:00,2024-03-27 15:08:42+00:00,https://github.com/metabase/metabase/issues/40585,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2206100802,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/link.module.css`,,oisincoveney,2024-03-25 15:58:04+00:00,['oisincoveney'],2024-03-26 12:20:59+00:00,2024-03-26 12:20:59+00:00,https://github.com/metabase/metabase/issues/40583,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2206045359,issue,open,,[Testing plan] Show generated SQL in a side bar automatically,"# Testing plan for #40254

## Dimensions
- Database querying language
    - SQL
    - JSON
- User native permissions
    - On
    - Off
- Screen size
    - Mobile
    - Desktop
- Type of the query
    - GUI only
    - GUI converted to native
    - Simple
    - Nested


## Milestone 1 (E2E)
### Actions
- Open a gui query, switch to notebook and show query preview in a sidebar
    - Navigate away and expect the sidebar to be still open next time we visit notebook
- Convert the query to its native form
    - Make sure question can be saved
    - Make sure ""Explore results"" works
- Make sure the sidebar still works on a small screen
    - It should cover the notebook editor fully
- Make sure users without native permissions cannot even open SQL preview from the notebook mode


```[tasklist]
### Tasks
```
",nemanjaglumac,2024-03-25 15:31:54+00:00,['nemanjaglumac'],2024-04-04 22:53:44+00:00,,https://github.com/metabase/metabase/issues/40579,"[('.TestingStrategy/FE', '')]",[],
2205970326,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/text.module.css`,,oisincoveney,2024-03-25 15:01:22+00:00,['oisincoveney'],2024-03-28 14:15:01+00:00,2024-03-28 14:15:01+00:00,https://github.com/metabase/metabase/issues/40576,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2205902855,issue,closed,completed,Users with 'Editors' role don't see Dashboard subscriptions created by Admin,"### Describe the bug

When 'Admin' creates a Dashboard subscription and there recipients with 'Editors' role.

Users with 'Editors' role don't see this subscription at all and can't manage it (correct timing, add/remove new recipients etc)

It looks like a bug as before it was working OK and Dashboard subscriptions were always visible for 'Editors', regardless who created   it

![image](https://github.com/metabase/metabase/assets/26248319/3786eb05-15e6-4b3e-8533-230c60dfbd38)


### To Reproduce

1. Go create a 'Dashboard' as an 'Admin' and create a Subscription
2. Add users with 'Editors' role as recipients of subscription
3. Save subscription
4. Ask user with 'Editors' role open this 'Dashboard'
4. He won't see a Subscription at all


### Expected behavior

All users with 'Editors' should see Dashboard subscriptions, regardless who created it

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.57-060157-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",ismayil22,2024-03-25 14:31:39+00:00,['johnswanson'],2024-03-27 21:41:26+00:00,2024-03-27 17:58:07+00:00,https://github.com/metabase/metabase/issues/40573,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions')]","[{'comment_id': 2023438104, 'issue_id': 2205902855, 'author': 'johnswanson', 'body': ""Hi @ismayil22, thank you for the bug report! Looking into this, this was actually an intentional change. You can read a bit about it [here](https://github.com/metabase/metabase/security/advisories/GHSA-ch8f-hhq9-7gv5), but essentially, the old behavior was a security concern. A user with fewer *data* privileges could add themselves to a dashboard subscription created by someone with *more* data privileges, and thus get access to more data than they should have.\r\n\r\nThere [is a proposal to allow non-admins to view and edit subscriptions](https://github.com/metabase/metabase/issues/33131) on questions they can access, with a new permission. I think that would solve the problem for you, so you might want to subscribe to that if you're interested.\r\n\r\nThanks again for submitting the issue! I'll close for now since it was an intentional change."", 'created_at': datetime.datetime(2024, 3, 27, 17, 58, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024040162, 'issue_id': 2205902855, 'author': 'ismayil22', 'body': 'Thanks @johnswanson for more details üëç, will subscribe to the mentioned discussion', 'created_at': datetime.datetime(2024, 3, 27, 21, 41, 25, tzinfo=datetime.timezone.utc)}]","johnswanson (Assginee) on (2024-03-27 17:58:08 UTC): Hi @ismayil22, thank you for the bug report! Looking into this, this was actually an intentional change. You can read a bit about it [here](https://github.com/metabase/metabase/security/advisories/GHSA-ch8f-hhq9-7gv5), but essentially, the old behavior was a security concern. A user with fewer *data* privileges could add themselves to a dashboard subscription created by someone with *more* data privileges, and thus get access to more data than they should have.

There [is a proposal to allow non-admins to view and edit subscriptions](https://github.com/metabase/metabase/issues/33131) on questions they can access, with a new permission. I think that would solve the problem for you, so you might want to subscribe to that if you're interested.

Thanks again for submitting the issue! I'll close for now since it was an intentional change.

ismayil22 (Issue Creator) on (2024-03-27 21:41:25 UTC): Thanks @johnswanson for more details üëç, will subscribe to the mentioned discussion

"
2205871553,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/hide.module.css`,,oisincoveney,2024-03-25 14:17:29+00:00,['oisincoveney'],2024-04-01 08:14:31+00:00,2024-04-01 08:14:31+00:00,https://github.com/metabase/metabase/issues/40571,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2205840323,issue,open,,hive partitioned tables bigquery do not get synced,"### Describe the bug

After upgrading to the newest version of Metabase 0.49.1 the sync with partitioned parquet files on BigQuery does not work as expected.

### To Reproduce

1. Go to and create a table:

CREATE EXTERNAL TABLE `project.dataset.table`
WITH PARTITION COLUMNS (

)
OPTIONS(
  description=""something"",
  enum_as_string=true,
  enable_list_inference=true,
  format=""PARQUET"",
  decimal_target_types=[""BIGNUMERIC""],
  hive_partition_uri_prefix=""gs://dataset/table/"",
  require_hive_partition_filter=true,
  uris=[""gs://dataset/table/dt=*""]
);

2. Open in Metabase
3. See sync/fingerprinting does not work. Error shows in logs as well. Metabase does not see this table as partitioned.


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""ANSI_X3.4-1968"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""17.0.10+7-Debian-1deb12u1"",
    ""java.vendor"": ""Debian"",
    ""java.vendor.url"": ""https://tracker.debian.org/openjdk-17"",
    ""java.version"": ""17.0.10"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""17.0.10+7-Debian-1deb12u1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.58+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High. Lots of Metabase Users impacted

### Additional context

_No response_",carstenkadmos,2024-03-25 14:02:36+00:00,[],2025-02-04 20:25:20+00:00,,https://github.com/metabase/metabase/issues/40569,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/Metadata & Sync', ''), ('Database/BigQuery', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2018208826, 'issue_id': 2205840323, 'author': 'paoliniluis', 'body': ""We didn't do any change to BigQuery at all. cc @calherries and @qnkhuat"", 'created_at': datetime.datetime(2024, 3, 25, 15, 1, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2018231642, 'issue_id': 2205840323, 'author': 'carstenkadmos', 'body': 'Quick clarification. Fingerprinting never worked due to partitioning. but with 0.49 we expected this to work. However, in our case we use external tables on BigQuery.', 'created_at': datetime.datetime(2024, 3, 25, 15, 10, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2018596828, 'issue_id': 2205840323, 'author': 'paoliniluis', 'body': 'Why did you expect this to work in v49? we never said we were going to support partitioned tables in the current version', 'created_at': datetime.datetime(2024, 3, 25, 18, 3, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2019324499, 'issue_id': 2205840323, 'author': 'qnkhuat', 'body': '@paoliniluis we shipped this in 49 https://github.com/metabase/metabase/issues/36668, this is an overlooked case where it uses hive_partition_filter', 'created_at': datetime.datetime(2024, 3, 26, 3, 38, 16, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-25 15:01:03 UTC): We didn't do any change to BigQuery at all. cc @calherries and @qnkhuat

carstenkadmos (Issue Creator) on (2024-03-25 15:10:29 UTC): Quick clarification. Fingerprinting never worked due to partitioning. but with 0.49 we expected this to work. However, in our case we use external tables on BigQuery.

paoliniluis on (2024-03-25 18:03:50 UTC): Why did you expect this to work in v49? we never said we were going to support partitioned tables in the current version

qnkhuat on (2024-03-26 03:38:16 UTC): @paoliniluis we shipped this in 49 https://github.com/metabase/metabase/issues/36668, this is an overlooked case where it uses hive_partition_filter

"
2205777280,issue,open,,Export to JSON (or CSV) Stopped working,"### Describe the bug

The export to JSON (or CSV) suddenly stopped working. I used to get the data through the endpoint api/card/<card number>/query/json

### To Reproduce

Authenticate and make a GET request to api/card/<card number>/query/json

I Can't reproduce it in the sample database

### Expected behavior

To get the results in Json Format

### Logs

Heres the resulting JSON
[export.json](https://github.com/metabase/metabase/files/14744227/export.json)
 (with sensitive data replaced)

### Information about your Metabase installation

```JSON
I am using the metabase docker with the v0.49 tag on a Azure environment.
The database is on Postgres V12.16
```


### Severity

Blocking some users

### Additional context

_No response_",feulo-cit,2024-03-25 13:31:52+00:00,['adam-james-v'],2025-02-04 20:29:35+00:00,,https://github.com/metabase/metabase/issues/40567,"[('Type:Bug', 'Product defects'), ('.Unable to Reproduce', ''), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team'), ('.Possibly Already Fixed', 'This might already be fixed, e.g. because we fixed something similar to it recently. TODO-list')]","[{'comment_id': 2033058467, 'issue_id': 2205777280, 'author': 'adam-james-v', 'body': ""@feulo-cit , I'm curious if you're able to test a few different variations of the card/query that fails, in order to provide some more details as well as answer a couple questions.\r\n\r\nDoes the query succeed for other cards in general?\r\nDoes the query succeed for other export types? (csv and xlsx)?\r\nIf you take out certain columns (for example, the timestamp and templateNames columns), does it work?\r\n\r\nAny other details about the query can be very helpful for me to be able to reproduce and solve this for you."", 'created_at': datetime.datetime(2024, 4, 2, 20, 44, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2033911851, 'issue_id': 2205777280, 'author': 'paoliniluis', 'body': 'First of all: we don‚Äôt have all the troubleshooting info, second, we don‚Äôt have the logs here. We can‚Äôt reproduce if we don‚Äôt have all the information', 'created_at': datetime.datetime(2024, 4, 3, 8, 33, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2037021146, 'issue_id': 2205777280, 'author': 'feulo-cit', 'body': 'Hello,\r\n\r\nI made the tests suggested by @adam-james-v and find out that the problem is for all export types (CSV, JSON, XLS) and in all cards. Then I started to remove some columns and it seems to be failing only when the timestamp column is present.\r\n \r\nI requested the logs to the admin (I do not have access to them) and I will post them here as soon as I get them', 'created_at': datetime.datetime(2024, 4, 4, 12, 15, 53, tzinfo=datetime.timezone.utc)}]","adam-james-v (Assginee) on (2024-04-02 20:44:45 UTC): @feulo-cit , I'm curious if you're able to test a few different variations of the card/query that fails, in order to provide some more details as well as answer a couple questions.

Does the query succeed for other cards in general?
Does the query succeed for other export types? (csv and xlsx)?
If you take out certain columns (for example, the timestamp and templateNames columns), does it work?

Any other details about the query can be very helpful for me to be able to reproduce and solve this for you.

paoliniluis on (2024-04-03 08:33:18 UTC): First of all: we don‚Äôt have all the troubleshooting info, second, we don‚Äôt have the logs here. We can‚Äôt reproduce if we don‚Äôt have all the information

feulo-cit (Issue Creator) on (2024-04-04 12:15:53 UTC): Hello,

I made the tests suggested by @adam-james-v and find out that the problem is for all export types (CSV, JSON, XLS) and in all cards. Then I started to remove some columns and it seems to be failing only when the timestamp column is present.
 
I requested the logs to the admin (I do not have access to them) and I will post them here as soon as I get them

"
2205673051,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/headings.module.css`,,oisincoveney,2024-03-25 12:47:08+00:00,['oisincoveney'],2024-03-27 10:59:35+00:00,2024-03-27 10:59:35+00:00,https://github.com/metabase/metabase/issues/40565,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2205652696,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/grid.module.css`,,oisincoveney,2024-03-25 12:36:45+00:00,['oisincoveney'],2024-04-12 14:09:56+00:00,2024-03-26 09:27:55+00:00,https://github.com/metabase/metabase/issues/40562,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2205510784,issue,closed,not_planned,Migrate H2 metabase docker compose,"Im trying to swap the H2 database to my postgresql database. Im trying to implement it trough docker compose but i have already switched the h2 database so i dont know if there is any option to do it by docker compose.

There is the code: (the line 'command' were just a new implementation i were trying to improve).
services:
  frontend:
    image: metabase/metabase
    ports:
      - ""3000:3000""
    environment:
      - MB_DB_TYPE=postgres
      - MB_DB_DBNAME=postgres
      - MB_DB_PORT=5432
      - MB_DB_USER=postgres
      - MB_DB_PASS=mypass
      - MB_DB_HOST=backend
    
    command: exec su metabase -s /bin/sh -c ""exec java $JAVA_OPTS -jar /app/metabase.jar $@""


  backend:
    image: postgres
    ports:
      - ""5432:5432""
    environment:
      POSTGRES_PASSWORD: mypass
    volumes:
      - pgdata:/var/lib/postgresql/data

  
volumes:
  pgdata:


- issue links: _related issues if any_

",XaviG99,2024-03-25 11:21:12+00:00,[],2024-03-25 12:32:41+00:00,2024-03-25 12:32:41+00:00,https://github.com/metabase/metabase/issues/40558,[],"[{'comment_id': 2017900677, 'issue_id': 2205510784, 'author': 'darksciencebase', 'body': ""@XaviG99 hi there! the `.Task` label is for internal use. if you don't have a bug to report, please use [our forum](https://discourse.metabase.com/) or contact support in case you're a customer."", 'created_at': datetime.datetime(2024, 3, 25, 12, 32, 41, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-03-25 12:32:41 UTC): @XaviG99 hi there! the `.Task` label is for internal use. if you don't have a bug to report, please use [our forum](https://discourse.metabase.com/) or contact support in case you're a customer.

"
2205474956,issue,closed,completed,Table is not preselected for a nested Mongo question coverted to native query,"### Describe the bug

This is a repeat of #15946, but this time for a nested Mongo question.

### To Reproduce

1. Open a mongo table ""Products"" from a Sample Database and save as the ""Source""
2. Click on ""New"" question > choose ""Saved questions"" and select ""Source""
3. Save as ""Nested""
4. Open a notebook editor
5. Convert the query to its native form
6. Notice that the table is not selected and there are no results
![image](https://github.com/metabase/metabase/assets/31325167/3f70244f-1870-4c27-8924-42e417f77655)

p.s. if you manually select a table, you should be able to run a query

### Expected behavior

A table should be preselected.

### Logs

_No response_

### Information about your Metabase installation

```JSON
local dev, `master` at https://github.com/metabase/metabase/commit/d52d4fe18a2d008eb6b201868a86fa13efc424f0
```


### Severity

P3

### Additional context

_No response_",nemanjaglumac,2024-03-25 11:01:39+00:00,['ranquild'],2025-01-27 16:15:07+00:00,2025-01-27 14:52:35+00:00,https://github.com/metabase/metabase/issues/40557,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Querying/MBQL', ''), ('.Frontend', ''), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/Querying', '')]",[],
2205421177,issue,closed,completed,"the admin dashboard doesnt list ""API key"" option under ""authentication"" menu","### Describe the bug

I tried to follow the isntructions here to set up an API key:
https://www.metabase.com/docs/master/people-and-groups/api-keys

but i cannot see the API key option in the Authentication menu (I see only Google and LDAP)

### To Reproduce

1. Go to admin potal
2. Click on authentication menu
3. See only ""Google"" and ""LDAP"" offered, no ""API key""


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-azure"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-02-12"",
      ""tag"": ""v0.48.6"",
      ""hash"": ""b8818f9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

high

### Additional context

_No response_",scd75,2024-03-25 10:37:45+00:00,[],2024-03-25 10:40:38+00:00,2024-03-25 10:40:38+00:00,https://github.com/metabase/metabase/issues/40554,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2017700218, 'issue_id': 2205421177, 'author': 'perivamsi', 'body': 'Please upgrade to version 49 to get this feature', 'created_at': datetime.datetime(2024, 3, 25, 10, 40, 25, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-03-25 10:40:25 UTC): Please upgrade to version 49 to get this feature

"
2205408063,issue,closed,completed,Common Metrics gone after Summarising by some other column,"### Describe the bug

NOTE: this issue is duplicated from [link](https://github.com/metabase/metabase/issues/40393). I'm afraid I used the wrong method to raise the issue and it didn't had bug type tag. Apologies for the spam.

When creating a Metabase question, selecting a **Common Metric** and creating a summary, we lose the Common Metrics group. Moreover, if we pick the initial Common Metric added, Metabase shows a error message. The console log displays a ""metric with id xx not found"" issue.

We've recorded the following Loom to show the issue: 
[loom](https://www.loom.com/share/a3775a517dc3402ba4e37bd1e4e7fdb0?sid=b196bff3-b455-40dc-8348-a94d9b3663b6)

If we pick all the Common Metrics we are summarizing and then the Dimensions, Metabase outputs the result properly. However, we lose the ability to edit the question.


### To Reproduce

1. Go to 'New > Question' 
2. Click on 'Pick the metric you want to summarize' add any *Common Metric* 
3. Summarize by some other column
4. Go back to metrics
5. Common Metrics are not there.
6. If you click on the initial metric selected, metabase outputs an error.


### Expected behavior

Common metrics should not disappear.

### Logs

Logs
metric with ID does not exist : 32 > react-dom.prodcution.min.js:209
Error app.ts:30

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.205-195.804.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking significant part of the metabase usage 

### Additional context

![image](https://github.com/metabase/metabase/assets/136714486/c3e0ca61-dd25-4951-b124-b6e7de906114)

https://www.loom.com/share/a3775a517dc3402ba4e37bd1e4e7fdb0?sid=b196bff3-b455-40dc-8348-a94d9b3663b6
",cgg-pwdt,2024-03-25 10:32:16+00:00,['uladzimirdev'],2024-03-27 07:16:52+00:00,2024-03-26 21:46:11+00:00,https://github.com/metabase/metabase/issues/40553,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('Administration/Metrics & Segments', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2021533797, 'issue_id': 2205408063, 'author': 'cgg-pwdt', 'body': ""thanks everyone! life savers üöÄ \r\n\r\nas I mentioned before this was duplicated because I used the wrong form initially. Here's the dupe: https://github.com/metabase/metabase/issues/40393"", 'created_at': datetime.datetime(2024, 3, 26, 21, 50, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2022103758, 'issue_id': 2205408063, 'author': 'uladzimirdev', 'body': 'thanks for the effort on providing clear steps to reproduce the issue @cgg-pwdt', 'created_at': datetime.datetime(2024, 3, 27, 7, 16, 39, tzinfo=datetime.timezone.utc)}]","cgg-pwdt (Issue Creator) on (2024-03-26 21:50:42 UTC): thanks everyone! life savers üöÄ 

as I mentioned before this was duplicated because I used the wrong form initially. Here's the dupe: https://github.com/metabase/metabase/issues/40393

uladzimirdev (Assginee) on (2024-03-27 07:16:39 UTC): thanks for the effort on providing clear steps to reproduce the issue @cgg-pwdt

"
2205312302,issue,closed,completed,Error when importing MongoDB database with collection having nested fields with more than 1 level of nesting,"### Describe the bug

Using the serialization feature, importing a MongoDB database containing a collection with nested objects is failing.
Example of such collection:
```JSON
{""_id"":{""$oid"":""65d636516d51677dd86e8d04""},""level_0"":{""level_1"":{""level_2"":""test""}}}
```
level_0 is a parent object having a level_1 child object containing a level_2 string

### To Reproduce

1. Create a MongoDB collection inside a database with the following document:
    ```JSON
    {""_id"":{""$oid"":""65d636516d51677dd86e8d04""},""level_0"":{""level_1"":{""level_2"":""test""}}}
    ```
2. Launch a new instance of Metabase (I'm using the docker image) and add the connection to the MongoDB database containing that collection.
3. Export the Metabase database with
    ```SHELL
    java -jar /app/metabase.jar export exportFolder --no-settings
    ```
4. Copy the export folder exportFolder to your local drive
5. Remove the container and start a new fresh Metabase instance/container.
6. Copy the export folder exportFolder from your local drive to the Metabase instance
7. Import the Metabase database with
   ```SHELL
    java -jar /app/metabase.jar import exportFolder
    ```

### Expected behavior

The import should succeed without errors, if any cards/questions are built upon this MongoDB collection, they should also be working fine.

### Logs

<details>
<summary>Click to expand the logs from the import command:</summary>

```
Warning: environ value jdk-11.0.22+7 for key :java-version has been overwritten with 11.0.22
2024-03-25 09:05:00,174 INFO metabase.util :: Maximum memory available to JVM: 3.9 GB
2024-03-25 09:05:01,729 WARN db.env :: WARNING: Using Metabase with an H2 application database is not recommended for production deployments. For production deployments, we highly recommend using Postgres, MySQL, or MariaDB instead. If you decide to continue to use H2, please be sure to back up the database file regularly. For more information, see https://metabase.com/docs/latest/operations-guide/migrating-from-h2.html
2024-03-25 09:05:01,870 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. üîì 
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-03-25 09:05:03,273 ERROR public-settings.premium-features :: Error validating token : Assert failed: Metabase DB is not yet set up
((requiring-resolve (quote metabase.db/db-is-set-up?)))
2024-03-25 09:05:06,684 INFO driver.impl :: Registered abstract driver :sql  üöö
2024-03-25 09:05:06,694 INFO driver.impl :: Registered abstract driver :sql-jdbc (parents: [:sql]) üöö
2024-03-25 09:05:06,698 INFO metabase.util :: Load driver :sql-jdbc took 73.6 ms
2024-03-25 09:05:06,699 INFO driver.impl :: Registered driver :h2 (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:06,831 INFO driver.impl :: Registered driver :mysql (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:06,858 INFO driver.impl :: Registered driver :postgres (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:09,587 INFO metabase.core :: 
Metabase v1.48.4 (62145b0)

Copyright ¬© 2024 Metabase, Inc.

Metabase Enterprise Edition extensions are PRESENT.

Usage of Metabase Enterprise Edition features are subject to the Metabase Commercial License. See https://www.metabase.com/license/commercial/ for details.
2024-03-25 09:05:09,731 INFO metabase.plugins :: Loading plugins in /home/metabase/plugins...
2024-03-25 09:05:10,098 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :bigquery-cloud-sdk...
2024-03-25 09:05:10,106 INFO driver.impl :: Registered driver :bigquery-cloud-sdk (parents: [:sql]) üöö
2024-03-25 09:05:10,111 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlite...
2024-03-25 09:05:10,112 INFO driver.impl :: Registered driver :sqlite (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,123 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :mongo...
2024-03-25 09:05:10,124 INFO driver.impl :: Registered driver :mongo  üöö
2024-03-25 09:05:10,130 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :googleanalytics...
2024-03-25 09:05:10,130 INFO driver.impl :: Registered driver :googleanalytics  üöö
2024-03-25 09:05:10,136 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :vertica...
2024-03-25 09:05:10,137 INFO driver.impl :: Registered driver :vertica (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,148 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :athena...
2024-03-25 09:05:10,149 INFO driver.impl :: Registered driver :athena (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,154 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sqlserver...
2024-03-25 09:05:10,155 INFO driver.impl :: Registered driver :sqlserver (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,179 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :snowflake...
2024-03-25 09:05:10,180 INFO driver.impl :: Registered driver :snowflake (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,188 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :oracle...
2024-03-25 09:05:10,189 INFO driver.impl :: Registered driver :oracle (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,193 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :redshift...
2024-03-25 09:05:10,194 INFO driver.impl :: Registered driver :redshift (parents: [:postgres]) üöö
2024-03-25 09:05:10,200 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :hive-like...
2024-03-25 09:05:10,201 INFO driver.impl :: Registered abstract driver :hive-like (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,202 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :sparksql...
2024-03-25 09:05:10,203 INFO driver.impl :: Registered driver :sparksql (parents: [:hive-like]) üöö
2024-03-25 09:05:10,214 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :presto-jdbc...
2024-03-25 09:05:10,215 INFO driver.impl :: Registered driver :presto-jdbc (parents: [:sql-jdbc]) üöö
2024-03-25 09:05:10,220 DEBUG plugins.lazy-loaded-driver :: Registering lazy loading driver :druid...
2024-03-25 09:05:10,220 INFO driver.impl :: Registered driver :druid  üöö
2024-03-25 09:05:10,223 INFO db.setup :: Verifying h2 Database Connection ...
2024-03-25 09:05:10,712 INFO db.setup :: Successfully verified H2 2.1.214 (2022-06-13) application database connection. ‚úÖ
2024-03-25 09:05:10,714 INFO db.setup :: Checking if a database downgrade is required...
2024-03-25 09:05:11,073 INFO db.setup :: Running Database Migrations...
2024-03-25 09:05:11,074 INFO db.setup :: Setting up Liquibase...
2024-03-25 09:05:11,119 INFO db.setup :: Liquibase is ready.
2024-03-25 09:05:11,120 INFO db.liquibase :: Checking if Database has unrun migrations...
2024-03-25 09:05:11,538 INFO db.liquibase :: No unrun migrations found.
2024-03-25 09:05:11,539 INFO db.setup :: Database Migrations Current ...  ‚úÖ
2024-03-25 09:05:11,541 INFO metabase.util :: Database setup took 1.3 s
2024-03-25 09:05:11,625 INFO public-settings.premium-features :: GETTING ACTIVE USER COUNT!
2024-03-25 09:05:11,666 INFO public-settings.premium-features :: => 1
2024-03-25 09:05:11,666 INFO public-settings.premium-features :: Checking with the MetaStore to see whether token '82a5...30d4' is valid...
2024-03-25 09:05:12,353 INFO serialization.cmd :: Loading serialized Metabase files from export
2024-03-25 09:05:12,453 INFO v2.load :: Loading Database sample-db
2024-03-25 09:05:12,557 INFO driver.impl :: Initializing driver :sql...
2024-03-25 09:05:12,558 INFO driver.impl :: Initializing driver :sql-jdbc...
2024-03-25 09:05:12,559 INFO driver.impl :: Initializing driver :h2...
2024-03-25 09:05:12,607 INFO driver.impl :: Initializing driver :mongo...
2024-03-25 09:05:12,609 INFO plugins.classloader :: Added URL file:/home/metabase/plugins/mongo.metabase-driver.jar to classpath
2024-03-25 09:05:12,611 DEBUG plugins.init-steps :: Loading plugin namespace metabase.driver.mongo...
WARNING: random-uuid already refers to: #'clojure.core/random-uuid in namespace: monger.util, being replaced by: #'monger.util/random-uuid
2024-03-25 09:05:13,290 INFO driver.impl :: Registered driver :mongo  üöö
2024-03-25 09:05:13,306 INFO metabase.util :: Load lazy loading driver :mongo took 695.7 ms
2024-03-25 09:05:13,436 INFO task.sync-databases :: Scheduling sync/analyze for database 2: trigger: metabase.task.sync-and-analyze.trigger.2
2024-03-25 09:05:13,438 INFO task.sync-databases :: Scheduling field-values for database 2: trigger: metabase.task.update-field-values.trigger.2
2024-03-25 09:05:13,440 INFO v2.load :: Loading Database sample-db > Table gs_7334
2024-03-25 09:05:13,443 INFO v2.load :: Loading Database sample-db
2024-03-25 09:05:13,504 INFO v2.load :: Loading Database sample-db > Table gs_7334 > Field level_2
2024-03-25 09:05:13,506 INFO v2.load :: Loading Database sample-db > Table gs_7334
clojure.lang.ExceptionInfo: Failed to load into database for [#ordered/map ([:id ""sample-db""] [:model ""Database""]) #ordered/map ([:id ""gs_7334""] [:model ""Table""]) #ordered/map ([:id ""level_2""] [:model ""Field""])] {:path [#ordered/map ([:id ""sample-db""] [:model ""Database""]) #ordered/map ([:id ""gs_7334""] [:model ""Table""]) #ordered/map ([:id ""level_2""] [:model ""Field""])], :deps-chain #{}}
        at metabase_enterprise.serialization.v2.load$load_one_BANG_.invokeStatic(load.clj:70)
        at metabase_enterprise.serialization.v2.load$load_one_BANG_.invoke(load.clj:33)
        at clojure.core.protocols$fn__8249.invokeStatic(protocols.clj:168)
        at clojure.core.protocols$fn__8249.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at metabase_enterprise.serialization.v2.load$load_metabase_BANG_.invokeStatic(load.clj:98)
        at metabase_enterprise.serialization.v2.load$load_metabase_BANG_.doInvoke(load.clj:83)
        at clojure.lang.RestFn.invoke(RestFn.java:423)
        at metabase_enterprise.serialization.cmd$fn__108901$_AMPERSAND_f__108903.doInvoke(cmd.clj:100)
        at clojure.lang.RestFn.applyTo(RestFn.java:142)
        at clojure.core$apply.invokeStatic(core.clj:671)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase_enterprise.serialization.cmd$fn__108901$fn__108908.doInvoke(cmd.clj:80)
        at clojure.lang.RestFn.invoke(RestFn.java:464)
        at metabase_enterprise.serialization.cmd$fn__108911$_AMPERSAND_f__108912.invoke(cmd.clj:110)
        at metabase_enterprise.serialization.cmd$fn__108911$fn__108914.invoke(cmd.clj:102)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.cmd$call_enterprise.invokeStatic(cmd.clj:54)
        at metabase.cmd$call_enterprise.doInvoke(cmd.clj:43)
        at clojure.lang.RestFn.invoke(RestFn.java:439)
        at metabase.cmd$import.invokeStatic(cmd.clj:192)
        at metabase.cmd$import.doInvoke(cmd.clj:188)
        at clojure.lang.RestFn.invoke(RestFn.java:410)
        at clojure.lang.AFn.applyToHelper(AFn.java:154)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.cmd$run_cmd$fn__107980.invoke(cmd.clj:301)
        at metabase.cmd$run_cmd.invokeStatic(cmd.clj:300)
        at metabase.cmd$run_cmd.invoke(cmd.clj:290)
        at clojure.lang.Var.invoke(Var.java:388)
        at metabase.core$run_cmd.invokeStatic(core.clj:178)
        at metabase.core$run_cmd.invoke(core.clj:176)
        at metabase.core$entrypoint.invokeStatic(core.clj:200)
        at metabase.core$entrypoint.doInvoke(core.clj:195)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.lang.Var.applyTo(Var.java:705)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)
        at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at metabase.bootstrap.main(Unknown Source)
Caused by: clojure.lang.ExceptionInfo: Referential integrity constraint violation: ""FK_FIELD_PARENT_REF_FIELD_ID: PUBLIC.METABASE_FIELD FOREIGN KEY(PARENT_ID) REFERENCES PUBLIC.METABASE_FIELD(ID) (249)""; SQL statement:
INSERT INTO ""METABASE_FIELD"" (""DESCRIPTION"", ""DATABASE_TYPE"", ""SEMANTIC_TYPE"", ""TABLE_ID"", ""COERCION_STRATEGY"", ""NAME"", ""HAS_FIELD_VALUES"", ""SETTINGS"", ""CAVEATS"", ""FK_TARGET_FIELD_ID"", ""UPDATED_AT"", ""CUSTOM_POSITION"", ""EFFECTIVE
_TYPE"", ""ACTIVE"", ""NFC_PATH"", ""PARENT_ID"", ""DATABASE_IS_AUTO_INCREMENT"", ""JSON_UNFOLDING"", ""POSITION"", ""VISIBILITY_TYPE"", ""PREVIEW_DISPLAY"", ""DISPLAY_NAME"", ""DATABASE_POSITION"", ""DATABASE_REQUIRED"", ""CREATED_AT"", ""BASE_TYPE"", ""P
OINTS_OF_INTEREST"") VALUES (NULL, ?, NULL, ?, NULL, ?, NULL, NULL, NULL, NULL, NOW(), ?, ?, TRUE, NULL, ?, FALSE, FALSE, ?, ?, TRUE, ?, ?, FALSE, ?, ?, NULL) [23506-214] {:toucan2/context-trace [[""execute SQL with class com.mcha
nge.v2.c3p0.impl.NewProxyConnection"" {:toucan2.jdbc.query/sql-args [""INSERT INTO \""METABASE_FIELD\"" (\""DESCRIPTION\"", \""DATABASE_TYPE\"", \""SEMANTIC_TYPE\"", \""TABLE_ID\"", \""COERCION_STRATEGY\"", \""NAME\"", \""HAS_FIELD_VALUES\"", \""S
ETTINGS\"", \""CAVEATS\"", \""FK_TARGET_FIELD_ID\"", \""UPDATED_AT\"", \""CUSTOM_POSITION\"", \""EFFECTIVE_TYPE\"", \""ACTIVE\"", \""NFC_PATH\"", \""PARENT_ID\"", \""DATABASE_IS_AUTO_INCREMENT\"", \""JSON_UNFOLDING\"", \""POSITION\"", \""VISIBILITY_TYP
E\"", \""PREVIEW_DISPLAY\"", \""DISPLAY_NAME\"", \""DATABASE_POSITION\"", \""DATABASE_REQUIRED\"", \""CREATED_AT\"", \""BASE_TYPE\"", \""POINTS_OF_INTEREST\"") VALUES (NULL, ?, NULL, ?, NULL, ?, NULL, NULL, NULL, NULL, NOW(), ?, ?, TRUE, NULL,
 ?, FALSE, FALSE, ?, ?, TRUE, ?, ?, FALSE, ?, ?, NULL)"" ""java.lang.String"" 22 ""level_2"" 0 ""type/Text"" 249 3 ""normal"" ""Level 2"" 3 #t ""2024-03-25T08:41:04.560274"" ""type/Text""]}] [""resolve connection"" {:toucan2.connection/connectab
le org.h2.jdbc.JdbcConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}] {:toucan2.pipeline/rf #object[clojure.core$map$fn__5931$fn__5932 0x370f893e ""clojure.core$map$fn__5931$fn__5932@370f893e""]} [""with comp
iled query"" {:toucan2.pipeline/compiled-query [""INSERT INTO \""METABASE_FIELD\"" (\""DESCRIPTION\"", \""DATABASE_TYPE\"", \""SEMANTIC_TYPE\"", \""TABLE_ID\"", \""COERCION_STRATEGY\"", \""NAME\"", \""HAS_FIELD_VALUES\"", \""SETTINGS\"", \""CAVEATS\
"", \""FK_TARGET_FIELD_ID\"", \""UPDATED_AT\"", \""CUSTOM_POSITION\"", \""EFFECTIVE_TYPE\"", \""ACTIVE\"", \""NFC_PATH\"", \""PARENT_ID\"", \""DATABASE_IS_AUTO_INCREMENT\"", \""JSON_UNFOLDING\"", \""POSITION\"", \""VISIBILITY_TYPE\"", \""PREVIEW_DISPLA
Y\"", \""DISPLAY_NAME\"", \""DATABASE_POSITION\"", \""DATABASE_REQUIRED\"", \""CREATED_AT\"", \""BASE_TYPE\"", \""POINTS_OF_INTEREST\"") VALUES (NULL, ?, NULL, ?, NULL, ?, NULL, NULL, NULL, NULL, NOW(), ?, ?, TRUE, NULL, ?, FALSE, FALSE, ?, 
?, TRUE, ?, ?, FALSE, ?, ?, NULL)"" ""java.lang.String"" 22 ""level_2"" 0 ""type/Text"" 249 3 ""normal"" ""Level 2"" 3 #t ""2024-03-25T08:41:04.560274"" ""type/Text""]}] [""with built query"" {:toucan2.pipeline/built-query {:insert-into [:metaba
se_field], :values ((toucan2.instance/instance :model/Field {:description nil, :database_type ""java.lang.String"", :semantic_type nil, :table_id 22, :coercion_strategy nil, :name ""level_2"", :has_field_values nil, :settings nil, :
caveats nil, :fk_target_field_id nil, :updated_at [:metabase.util.honey-sql-2/typed :%now {:metabase.util.honeysql-extensions/database-type ""timestamp""}], :custom_position 0, :effective_type ""type/Text"", :active true, :nfc_path 
nil, :parent_id 249, :database_is_auto_increment false, :json_unfolding false, :position 3, :visibility_type ""normal"", :preview_display true, :display_name ""Level 2"", :database_position 3, :database_required false, :created_at #
t ""2024-03-25T08:41:04.560274"", :base_type ""type/Text"", :points_of_interest nil}))}}] [""resolve connection"" {:toucan2.connection/connectable metabase.db.connection.ApplicationDB}] [""resolve connection"" {:toucan2.connection/conne
ctable :default}] [""resolve connection"" {:toucan2.connection/connectable nil}] [""with resolved query"" {:toucan2.pipeline/resolved-query {}}] [""with parsed args"" {:toucan2.pipeline/query-type :toucan.query-type/insert.instances, 
:toucan2.pipeline/parsed-args {:rows [{:description nil, :database_type ""java.lang.String"", :semantic_type nil, :table_id 22, :coercion_strategy nil, :name ""level_2"", :has_field_values nil, :settings nil, :caveats nil, :fk_targe
t_field_id nil, :custom_position 0, :effective_type ""type/Text"", :active true, :nfc_path nil, :parent_id 249, :database_is_auto_increment false, :json_unfolding false, :position 3, :visibility_type ""normal"", :preview_display tru
e, :display_name ""Level 2"", :database_position 3, :database_required false, :created_at #t ""2024-03-25T08:41:04.560274"", :base_type ""type/Text"", :points_of_interest nil}]}}] [""with model"" {:toucan2.pipeline/model :model/Field}] 
[""with unparsed args"" {:toucan2.pipeline/query-type :toucan.query-type/insert.instances, :toucan2.pipeline/unparsed-args (:model/Field {:description nil, :database_type ""java.lang.String"", :semantic_type nil, :table_id 22, :coer
cion_strategy nil, :name ""level_2"", :has_field_values nil, :settings nil, :caveats nil, :fk_target_field_id nil, :custom_position 0, :effective_type ""type/Text"", :active true, :nfc_path nil, :parent_id 249, :database_is_auto_inc
rement false, :json_unfolding false, :position 3, :visibility_type ""normal"", :preview_display true, :display_name ""Level 2"", :database_position 3, :database_required false, :created_at #t ""2024-03-25T08:41:04.560274"", :base_type ""type/Text"", :points_of_interest nil})}]]}
        at org.h2.message.DbException.getJdbcSQLException(DbException.java:508)
        at org.h2.message.DbException.getJdbcSQLException(DbException.java:477)
        at org.h2.message.DbException.get(DbException.java:223)
        at org.h2.message.DbException.get(DbException.java:199)
        at org.h2.constraint.ConstraintReferential.checkRowOwnTable(ConstraintReferential.java:311)
        at org.h2.constraint.ConstraintReferential.checkRow(ConstraintReferential.java:252)
        at org.h2.table.Table.fireConstraints(Table.java:1172)
        at org.h2.table.Table.fireAfterRow(Table.java:1190)
        at org.h2.command.dml.Insert.insertRows(Insert.java:188)
        at org.h2.command.dml.Insert.update(Insert.java:135)
        at org.h2.command.CommandContainer.executeUpdateWithGeneratedKeys(CommandContainer.java:242)
        at org.h2.command.CommandContainer.update(CommandContainer.java:163)
        at org.h2.command.Command.executeUpdate(Command.java:252)
        at org.h2.jdbc.JdbcPreparedStatement.execute(JdbcPreparedStatement.java:254)
        at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.execute(NewProxyPreparedStatement.java:67)
        at toucan2.jdbc.query$reduce_jdbc_query.invokeStatic(query.clj:40)
        at toucan2.jdbc.query$reduce_jdbc_query.invoke(query.clj:22)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invokeStatic(pipeline.clj:19)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_default_default.invoke(pipeline.clj:9)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:482)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_toucan_result_type_pks_default.invokeStatic(pipeline.clj:30)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_toucan_result_type_pks_default.invoke(pipeline.clj:22)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17911.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_toucan2_jdbc_pipeline_DML_queries_returning_instances_default.invokeStatic(pipeline.clj:62)
        at toucan2.jdbc.pipeline$transduce_execute_with_connection_primary_method_java_sql_Connection_toucan2_jdbc_pipeline_DML_queries_returning_instances_default.invoke(pipeline.clj:52)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17911.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.pipeline$transduce_execute$with_connection_STAR___21132$with_transaction_STAR___21133.invoke(pipeline.clj:75)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:190)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17907.invoke(threaded.clj:71)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2588)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:44)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
        at toucan2.pipeline$transduce_execute$with_connection_STAR___21132.invoke(pipeline.clj:74)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
        at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17905.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
        at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17905.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.pipeline$transduce_execute.invokeStatic(pipeline.clj:74)
        at toucan2.pipeline$transduce_execute.invoke(pipeline.clj:64)
        at clojure.lang.Var.invoke(Var.java:399)
        at toucan2.pipeline$transduce_compiled_query.invokeStatic(pipeline.clj:244)
        at toucan2.pipeline$transduce_compiled_query.invoke(pipeline.clj:240)
        at toucan2.pipeline$transduce_built_query.invokeStatic(pipeline.clj:252)
        at toucan2.pipeline$transduce_built_query.invoke(pipeline.clj:246)
        at toucan2.pipeline$transduce_query_primary_method_default.invokeStatic(pipeline.clj:272)
        at toucan2.pipeline$transduce_query_primary_method_default.invoke(pipeline.clj:269)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:667)
        at clojure.core$apply.invoke(core.clj:662)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17911.invoke(threaded.clj:79)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.doInvoke(core.clj:2589)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.doInvoke(threaded.clj:46)
        at clojure.lang.RestFn.applyTo(RestFn.java:151)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:482)
        at toucan2.tools.before_insert$transduce_query_around_method_toucan_query_type_insert__STAR__toucan2_tools_before_insert_before_insert_default$with_connection_STAR___25175$with_transaction_STAR___25176.invoke(before_insert.clj:37)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at metabase.db.connection$do_transaction$thunk__32276.invoke(connection.clj:150)
        at metabase.db.connection$do_transaction.invokeStatic(connection.clj:162)
        at metabase.db.connection$do_transaction.invoke(connection.clj:146)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
        at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17907.invoke(threaded.clj:71)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2588)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:44)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
        at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
        at clojure.lang.AFn.applyToHelper(AFn.java:165)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:457)
        at clojure.core$partial$fn__5908.invoke(core.clj:2643)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
        at toucan2.tools.before_insert$transduce_query_around_method_toucan_query_type_insert__STAR__toucan2_tools_before_insert_before_insert_default$with_connection_STAR___25175.invoke(before_insert.clj:36)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at toucan2.connection$bind_current_connectable_fn$fn__20813.invoke(connection.clj:104)
        at toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource.invokeStatic(connection.clj:18)
        at toucan2.jdbc.connection$do_with_connection_primary_method_javax_sql_DataSource.invoke(connection.clj:15)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17905.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at metabase.db.connection$do_with_connection_primary_method_default.invokeStatic(connection.clj:142)
        at metabase.db.connection$do_with_connection_primary_method_default.invoke(connection.clj:140)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17905.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
        at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.combo.threaded$fn__17903$fn__17904$fn__17905.invoke(threaded.clj:70)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873$fn__17877.invoke(threaded.clj:23)
        at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
        at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
        at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
        at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
        at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
        at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
        at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
        at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
        at clojure.core$reduce.invokeStatic(core.clj:6886)
        at clojure.core$reduce.invoke(core.clj:6868)
        at methodical.impl.combo.threaded$reducer_fn$fn__17873.invoke(threaded.clj:21)
        at clojure.core$comp$fn__5876.invoke(core.clj:2587)
        at methodical.impl.combo.threaded$combine_with_threader$fn__17883.invoke(threaded.clj:43)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
        at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
        at clojure.lang.AFn.applyToHelper(AFn.java:160)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:436)
        at clojure.core$partial$fn__5908.invoke(core.clj:2642)
        at clojure.lang.AFn.applyToHelper(AFn.java:156)
        at clojure.lang.RestFn.applyTo(RestFn.java:132)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
        at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
        at toucan2.tools.before_insert$transduce_query_around_method_toucan_query_type_insert__STAR__toucan2_tools_before_insert_before_insert_default.invokeStatic(before_insert.clj:36)
        at toucan2.tools.before_insert$transduce_query_around_method_toucan_query_type_insert__STAR__toucan2_tools_before_insert_before_insert_default.invoke(before_insert.clj:31)
        at clojure.lang.AFn.applyToHelper(AFn.java:178)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$partial$fn__5908.doInvoke(core.clj:2639)
        at clojure.lang.RestFn.applyTo(RestFn.java:146)
        at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
        at clojure.lang.RestFn.applyTo(RestFn.java:137)
        at clojure.core$apply.invokeStatic(core.clj:675)
        at clojure.core$apply.doInvoke(core.clj:662)
        at clojure.lang.RestFn.invoke(RestFn.java:533)
        at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:65)
        at methodical.impl.standard$invoke_multifn.doInvoke(standard.clj:47)
        at clojure.lang.RestFn.invoke(RestFn.java:594)
        at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:199)
        at toucan2.pipeline$transduce_query_STAR_.invokeStatic(pipeline.clj:278)
        at toucan2.pipeline$transduce_query_STAR_.invoke(pipeline.clj:274)
        at toucan2.pipeline$transduce_with_model.invokeStatic(pipeline.clj:293)
        at toucan2.pipeline$transduce_with_model.invoke(pipeline.clj:280)
        at toucan2.pipeline$transduce_parsed.invokeStatic(pipeline.clj:309)
        at toucan2.pipeline$transduce_parsed.invoke(pipeline.clj:295)
        at toucan2.pipeline$transduce_unparsed.invokeStatic(pipeline.clj:317)
        at toucan2.pipeline$transduce_unparsed.invoke(pipeline.clj:311)
        at toucan2.pipeline$transduce_unparsed_with_default_rf.invokeStatic(pipeline.clj:374)
        at toucan2.pipeline$transduce_unparsed_with_default_rf.invoke(pipeline.clj:368)
        at toucan2.insert$insert_returning_instances_BANG_.invokeStatic(insert.clj:163)
        at toucan2.insert$insert_returning_instances_BANG_.doInvoke(insert.clj:154)
        at clojure.lang.RestFn.invoke(RestFn.java:421)
        at metabase.models.serialization$fn__44643.invokeStatic(serialization.clj:612)
        at metabase.models.serialization$fn__44643.invoke(serialization.clj:610)
        at clojure.lang.MultiFn.invoke(MultiFn.java:234)
        at metabase.models.serialization$default_load_one_BANG_.invokeStatic(serialization.clj:639)
        at metabase.models.serialization$default_load_one_BANG_.invoke(serialization.clj:632)
        at metabase.models.serialization$fn__44654.invokeStatic(serialization.clj:643)
        at metabase.models.serialization$fn__44654.invoke(serialization.clj:642)
        at metabase.models.field$fn__53286.invokeStatic(field.clj:459)
        at metabase.models.field$fn__53286.invoke(field.clj:458)
        at clojure.lang.MultiFn.invoke(MultiFn.java:234)
        at metabase_enterprise.serialization.v2.load$load_one_BANG_.invokeStatic(load.clj:67)
        ... 52 more
Caused by: org.h2.jdbc.JdbcSQLIntegrityConstraintViolationException: Referential integrity constraint violation: ""FK_FIELD_PARENT_REF_FIELD_ID: PUBLIC.METABASE_FIELD FOREIGN KEY(PARENT_ID) REFERENCES PUBLIC.METABASE_FIELD(ID) (249)""; SQL statement:
INSERT INTO ""METABASE_FIELD"" (""DESCRIPTION"", ""DATABASE_TYPE"", ""SEMANTIC_TYPE"", ""TABLE_ID"", ""COERCION_STRATEGY"", ""NAME"", ""HAS_FIELD_VALUES"", ""SETTINGS"", ""CAVEATS"", ""FK_TARGET_FIELD_ID"", ""UPDATED_AT"", ""CUSTOM_POSITION"", ""EFFECTIVE
_TYPE"", ""ACTIVE"", ""NFC_PATH"", ""PARENT_ID"", ""DATABASE_IS_AUTO_INCREMENT"", ""JSON_UNFOLDING"", ""POSITION"", ""VISIBILITY_TYPE"", ""PREVIEW_DISPLAY"", ""DISPLAY_NAME"", ""DATABASE_POSITION"", ""DATABASE_REQUIRED"", ""CREATED_AT"", ""BASE_TYPE"", ""POINTS_OF_INTEREST"") VALUES (NULL, ?, NULL, ?, NULL, ?, NULL, NULL, NULL, NULL, NOW(), ?, ?, TRUE, NULL, ?, FALSE, FALSE, ?, ?, TRUE, ?, ?, FALSE, ?, ?, NULL) [23506-214]
        ... 570 more
Command failed with exception: Failed to load into database for [#ordered/map ([:id ""sample-db""] [:model ""Database""]) #ordered/map ([:id ""gs_7334""] [:model ""Table""]) #ordered/map ([:id ""level_2""] [:model ""Field""])]
```

</details>

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36 Edg/122.0.0.0"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-29"",
      ""tag"": ""v1.48.4"",
      ""hash"": ""62145b0""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

This is blocking our industrialization

### Additional context

_No response_",chrisgroffils,2024-03-25 09:42:09+00:00,['piranha'],2024-05-27 08:31:32+00:00,2024-05-27 08:19:07+00:00,https://github.com/metabase/metabase/issues/40551,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Operation/Serialization', 'Enterprise contents migration'), ('.Escalation', ''), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2020416430, 'issue_id': 2205312302, 'author': 'luizarakaki', 'body': ""Nested fields have the parent field as a reference.\r\n\r\nWe need to load them in the right order to avoid FK key constraints: all root fields, then 1st level, then 2nd level etc.\r\n\r\nI'm not sure if we have this data in the db. Maybe we would need to save this on sync or rebuild this tree from the references."", 'created_at': datetime.datetime(2024, 3, 26, 13, 21, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2036176453, 'issue_id': 2205312302, 'author': 'gRastogi1981', 'body': '@luizarakaki , do we have any solution on this issue and release plan for the fix. \r\n\r\nOur 90% collections use nested data structure and our decision to purchase Metabase license would rely on this problem fix.\r\n\r\nThanks!', 'created_at': datetime.datetime(2024, 4, 4, 4, 36, 33, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-26 13:21:21 UTC): Nested fields have the parent field as a reference.

We need to load them in the right order to avoid FK key constraints: all root fields, then 1st level, then 2nd level etc.

I'm not sure if we have this data in the db. Maybe we would need to save this on sync or rebuild this tree from the references.

gRastogi1981 on (2024-04-04 04:36:33 UTC): @luizarakaki , do we have any solution on this issue and release plan for the fix. 

Our 90% collections use nested data structure and our decision to purchase Metabase license would rely on this problem fix.

Thanks!

"
2205128402,issue,closed,completed,Implement webhook handlers to reset/refresh query cache,"From @luizarakaki 

- For programmatic cache invalidation, I think it makes sense for this endpoint to invalidate only the policy cache. If the policy was overwritten at the dashboard/question level, we shouldn‚Äôt invalidate the dashboard/question cache.
  - The basic use case would be: the database has 1 or 2 tables that are updated near real-time, all others follow the standard daily ETL. In this case, I‚Äôd set the database policy to duration (say 48h), but would use the endpoint to invalidate the cache after each ETL run.
  - For one or two dashboards that query the near real-time tables, I‚Äôd set it as duration (1h) or TTL.
  - When I hit the endpoint to invalidate the db cache, I would expect to invalidate only the policy, and keep the cache for overwritten policies.
- But when manually invalidating the cache, I can see people wanting a ‚Äútotal flush‚Äù to invalidate not only the db policy cache, but all downstream too.

----

`config=123` flushes the policy
`question=456` or `dashboard=234` or `db=1` flushes the entity (for dashboards and dbs - all nested questions regardless if they have different configs)",piranha,2024-03-25 08:00:39+00:00,['piranha'],2024-04-08 12:02:09+00:00,2024-04-08 12:00:24+00:00,https://github.com/metabase/metabase/issues/40548,"[('Querying/Cache', ''), ('.Team/Workflows', 'aka BEC')]",[],
2204864515,issue,closed,not_planned,v0.49.x version of metabase fails to initialize when using mysql 8.0 as database (ApsaraDB / Alibaba Cloud),"### Describe the bug

When I try to use the v0.49.x version of metabase, it fails to initialize

### To Reproduce

Whether upgrading from an older version, or using the new database directly with v0.49.x, the same problem occurs at startup


### Expected behavior

The service is up and running normally.


### Logs

```

2024-03-25 04:11:48,953 INFO plugins.dependencies :: Metabase Vertica Driver dependency {:class com.vertica.jdbc.Driver} satisfied? false


2024-03-25 04:11:48,958 INFO plugins.dependencies :: Plugins with unsatisfied deps: [""Metabase Oracle Driver"" ""Metabase Vertica Driver""]


2024-03-25 04:11:48,973 INFO metabase.core :: Setting up and migrating Metabase DB. Please sit tight, this may take a minute...


2024-03-25 04:11:48,981 INFO db.setup :: Verifying mysql Database Connection ...


2024-03-25 04:11:49,209 INFO db.setup :: Successfully verified MySQL 8.0.34 application database connection. ‚úÖ


2024-03-25 04:11:49,210 INFO db.setup :: Checking if a database downgrade is required...


2024-03-25 04:11:50,261 INFO db.setup :: Running Database Migrations...


2024-03-25 04:11:50,262 INFO db.setup :: Setting up Liquibase...


2024-03-25 04:11:50,578 INFO db.setup :: Liquibase is ready.


2024-03-25 04:11:50,579 INFO db.liquibase :: Checking if Database has unrun migrations...


2024-03-25 04:11:51,644 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken...


2024-03-25 04:11:51,652 INFO db.liquibase :: No migration lock found.


2024-03-25 04:11:52,133 INFO db.liquibase :: Running 17 migrations ...


2024-03-25 04:11:53,205 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.00-059::qnkhuat encountered an exception.



UPDATE SUMMARY


Run:                         17


Previously run:             258


Filtered out:                 5


-------------------------------


Total change sets:          280




FILTERED CHANGE SETS SUMMARY


DBMS mismatch:                5



2024-03-25 04:11:53,262 ERROR metabase.core :: Metabase Initialization FAILED


liquibase.exception.CommandExecutionException: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:


     Reason: clojure.lang.ExceptionInfo: (conn=420) SAVEPOINT 4c7fbe51-8c36-4d93-a6bd-742b2143c2c6 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}


	at liquibase.command.CommandScope.execute(CommandScope.java:253)


	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245)


	at liquibase.Scope.lambda$child$0(Scope.java:186)


	at liquibase.Scope.child(Scope.java:195)


	at liquibase.Scope.child(Scope.java:185)


	at liquibase.Scope.child(Scope.java:164)


	at liquibase.Liquibase.runInScope(Liquibase.java:1419)


	at liquibase.Liquibase.update(Liquibase.java:234)


	at liquibase.Liquibase.update(Liquibase.java:212)


	at liquibase.Liquibase.update(Liquibase.java:194)


	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invokeStatic(liquibase.clj:240)


	at metabase.db.liquibase$migrate_up_if_needed_BANG_.invoke(liquibase.clj:222)


	at metabase.db.setup$migrate_BANG_$fn__50987.invoke(setup.clj:80)


	at metabase.db.liquibase$do_with_liquibase$f_STAR___48693.invoke(liquibase.clj:135)


	at metabase.db.liquibase$do_with_liquibase.invokeStatic(liquibase.clj:138)


	at metabase.db.liquibase$do_with_liquibase.invoke(liquibase.clj:126)


	at metabase.db.setup$migrate_BANG_.invokeStatic(setup.clj:75)


	at metabase.db.setup$migrate_BANG_.doInvoke(setup.clj:56)


	at clojure.lang.RestFn.invoke(RestFn.java:445)


	at metabase.db.setup$run_schema_migrations_BANG_.invokeStatic(setup.clj:147)


	at metabase.db.setup$run_schema_migrations_BANG_.invoke(setup.clj:141)


	at metabase.db.setup$setup_db_BANG_$fn__51015$fn__51016.invoke(setup.clj:165)


	at metabase.util.jvm$do_with_us_locale.invokeStatic(jvm.clj:239)


	at metabase.util.jvm$do_with_us_locale.invoke(jvm.clj:225)


	at metabase.db.setup$setup_db_BANG_$fn__51015.invoke(setup.clj:160)


	at metabase.db.setup$setup_db_BANG_.invokeStatic(setup.clj:159)


	at metabase.db.setup$setup_db_BANG_.invoke(setup.clj:153)


	at metabase.db$setup_db_BANG_$fn__51029.invoke(db.clj:69)


	at metabase.db$setup_db_BANG_.invokeStatic(db.clj:64)


	at metabase.db$setup_db_BANG_.invoke(db.clj:55)


	at metabase.core$init_BANG__STAR_.invokeStatic(core.clj:113)


	at metabase.core$init_BANG__STAR_.invoke(core.clj:98)


	at metabase.core$init_BANG_.invokeStatic(core.clj:156)


	at metabase.core$init_BANG_.invoke(core.clj:151)


	at metabase.core$start_normally.invokeStatic(core.clj:168)


	at metabase.core$start_normally.invoke(core.clj:162)


	at metabase.core$entrypoint.invokeStatic(core.clj:201)


	at metabase.core$entrypoint.doInvoke(core.clj:195)


	at clojure.lang.RestFn.invoke(RestFn.java:397)


	at clojure.lang.AFn.applyToHelper(AFn.java:152)


	at clojure.lang.RestFn.applyTo(RestFn.java:132)


	at clojure.lang.Var.applyTo(Var.java:705)


	at clojure.core$apply.invokeStatic(core.clj:667)


	at clojure.core$apply.invoke(core.clj:662)


	at metabase.bootstrap$_main.invokeStatic(bootstrap.clj:31)


	at metabase.bootstrap$_main.doInvoke(bootstrap.clj:28)


	at clojure.lang.RestFn.invoke(RestFn.java:397)


	at clojure.lang.AFn.applyToHelper(AFn.java:152)


	at clojure.lang.RestFn.applyTo(RestFn.java:132)


	at metabase.bootstrap.main(Unknown Source)


Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:

....

	... 218 more


2024-03-25 04:11:53,292 INFO metabase.core :: Metabase Shutting Down ...


2024-03-25 04:11:53,299 INFO metabase.server :: Shutting Down Embedded Jetty Webserver


2024-03-25 04:11:53,310 INFO metabase.core :: Metabase Shutdown COMPLETE
```

### Information about your Metabase installation

```JSON
- database: MySQL  8.0.34
- Metabae version : 0.49.0 /0.49.1
- Metabase hosting env:  Docker 
- Metabase internal database:  MySQL  8.0.34
```


### Severity

P1

### Additional context

_No response_",UlyC,2024-03-25 04:32:50+00:00,[],2025-01-10 14:40:08+00:00,2024-12-24 16:45:49+00:00,https://github.com/metabase/metabase/issues/40546,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Database/MySQL', None), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2017204044, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""Please upgrade to 8.0.17 and try again, it's now our minimum supported version https://www.metabase.com/docs/latest/installation-and-operation/configuring-application-database#mysql-or-mariadb"", 'created_at': datetime.datetime(2024, 3, 25, 4, 48, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017206550, 'issue_id': 2204864515, 'author': 'UlyC', 'body': ""> Please upgrade to 8.0.17 and try again, it's now our minimum supported version https://www.metabase.com/docs/latest/installation-and-operation/configuring-application-database#mysql-or-mariadb\r\n\r\nAs you can see in the log, my MySQL version is 8.0.34"", 'created_at': datetime.datetime(2024, 3, 25, 4, 51, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017212928, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'We\'ll need more logs to diagnose this, could you change the log level for `liquibase` to `DEBUG` level using this log config\r\n\r\n```xml\r\n<?xml version=""1.0"" encoding=""UTF-8""?>\r\n<Configuration>\r\n  <Appenders>\r\n    <Console name=""STDOUT"" target=""SYSTEM_OUT"" follow=""true"">\r\n      <PatternLayout pattern=""%date %level %logger{2} :: %message%n%throwable"">\r\n        <replace regex="":basic-auth \\\\[.*\\\\]"" replacement="":basic-auth [redacted]""/>\r\n      </PatternLayout>\r\n    </Console>\r\n\r\n  </Appenders>\r\n\r\n  <Loggers>\r\n    <Logger name=""metabase"" level=""INFO""/>\r\n    <Logger name=""metabase-enterprise"" level=""INFO""/>\r\n    <Logger name=""metabase.metabot"" level=""DEBUG""/>\r\n    <Logger name=""metabase.plugins"" level=""DEBUG""/>\r\n    <Logger name=""metabase.server.middleware"" level=""DEBUG""/>\r\n    <Logger name=""metabase.query-processor.async"" level=""DEBUG""/>\r\n    <Logger name=""com.mchange"" level=""ERROR""/>\r\n    <Logger name=""org.quartz"" level=""INFO""/>\r\n    <Logger name=""liquibase"" level=""DEBUG""/>\r\n    <Logger name=""toucan2"" level=""TRACE""/>\r\n    <Logger name=""net.snowflake.client.jdbc.SnowflakeConnectString"" level=""ERROR""/>\r\n\r\n    <Root level=""WARN"">\r\n      <AppenderRef ref=""STDOUT""/>\r\n    </Root>\r\n  </Loggers>\r\n</Configuration>\r\n```\r\n\r\nThen start metabase again with this command\r\n\r\n```bash\r\njava -Dlog4j.configurationFile=file:/path/to/custom/log4j2.xml -jar metabase.jar\r\n```', 'created_at': datetime.datetime(2024, 3, 25, 4, 55, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017214701, 'issue_id': 2204864515, 'author': 'UlyC', 'body': ""I'm using metabase in a docker container on remote server, do I need to package the image myself?"", 'created_at': datetime.datetime(2024, 3, 25, 4, 58, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017215356, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'try this\r\n```bash\r\ndocker run -p 3000:3000 -v $PWD/my_log4j2.xml:/tmp/my_log4j2.xml -e JAVA_OPTS=-Dlog4j.configurationFile=file:///tmp/my_log4j2.xml metabase/metabase`\r\n```', 'created_at': datetime.datetime(2024, 3, 25, 4, 59, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017224719, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': '@UlyC added another entry for `toucan2`, please update!', 'created_at': datetime.datetime(2024, 3, 25, 5, 7, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017239302, 'issue_id': 2204864515, 'author': 'UlyC', 'body': '@qnkhuat  \r\n\r\nSince the log is too long, I put it in an attachment\r\n[r6lcafa8r3wd1qnkqdhpvhna1_logs.txt](https://github.com/metabase/metabase/files/14739132/r6lcafa8r3wd1qnkqdhpvhna1_logs.txt)', 'created_at': datetime.datetime(2024, 3, 25, 5, 22, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017274950, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""Thanks, unfortunately the log is not very helpful.\r\n\r\nCould you try running this query?\r\n\r\n```sql\r\nselect table_name, column_name, column_default, is_nullable  from information_schema.columns where data_type = 'datetime' and TABLE_SCHEMA = 'metabase';\r\n```"", 'created_at': datetime.datetime(2024, 3, 25, 5, 47, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017277552, 'issue_id': 2204864515, 'author': 'UlyC', 'body': '<img width=""850"" alt=""image"" src=""https://github.com/metabase/metabase/assets/36838240/3cded0a4-75cc-49b2-85f7-e334165b912d"">', 'created_at': datetime.datetime(2024, 3, 25, 5, 50, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017311160, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'interesting, did you make any changes to the DB schema manually?', 'created_at': datetime.datetime(2024, 3, 25, 6, 25, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017313860, 'issue_id': 2204864515, 'author': 'UlyC', 'body': ""Nope, I'm using a whole new database,and  I haven't changed any of the data.\r\n\r\nDo I need to create a new database to debug it?"", 'created_at': datetime.datetime(2024, 3, 25, 6, 27, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017374454, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""I have a fix here, it would be nice if you could verify if it's fixed by using the jars from this [build](https://github.com/metabase/metabase/actions/runs/8416379324?pr=40547).\r\n\r\nNote: this is not production-ready build, so DO NOT use it with your production database."", 'created_at': datetime.datetime(2024, 3, 25, 7, 23, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029002603, 'issue_id': 2204864515, 'author': 'Frederic-Zhou', 'body': 'v49.2 will still report the same error, Mysql 8.0.34\r\nlog blow :\r\n```\r\nWarning: environ value jdk-11.0.22+7 for key :java-version has been overwritten with 11.0.22\r\n2024-04-01 01:46:42,017 INFO metabase.util :: Maximum memory available to JVM: 6.8 GB\r\n2024-04-01 01:46:44,234 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. üîì \r\n For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html\r\n2024-04-01 01:46:50,565 INFO driver.impl :: \x1b[34mRegistered abstract driver :sql\x1b[0m  üöö\r\n2024-04-01 01:46:50,578 INFO driver.impl :: \x1b[34mRegistered abstract driver :sql-jdbc\x1b[0m (parents: [:sql]) üöö\r\n2024-04-01 01:46:50,585 INFO metabase.util :: \x1b[32mLoad driver :sql-jdbc took 86.8 ms\x1b[0m\r\n2024-04-01 01:46:50,585 INFO driver.impl :: \x1b[34mRegistered driver :h2\x1b[0m (parents: [:sql-jdbc]) üöö\r\n2024-04-01 01:46:50,764 INFO driver.impl :: \x1b[34mRegistered driver :mysql\x1b[0m (parents: [:sql-jdbc]) üöö\r\n2024-04-01 01:46:50,800 INFO driver.impl :: \x1b[34mRegistered driver :postgres\x1b[0m (parents: [:sql-jdbc]) üöö\r\n2024-04-01 01:46:52,722 INFO metabase.core :: \r\nMetabase v0.49.2 (4b83b88) \r\n\r\nCopyright ¬© 2024 Metabase, Inc. \r\n\r\nMetabase Enterprise Edition extensions are NOT PRESENT.\r\n2024-04-01 01:46:52,734 INFO metabase.core :: Starting Metabase in STANDALONE mode\r\n2024-04-01 01:46:52,786 INFO metabase.server :: Launching Embedded Jetty Webserver with config:\r\n {:port 3000, :host ""0.0.0.0""}\r\n\r\n```\r\nthen error occur\r\n```\r\nCaused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:\r\n     Reason: clojure.lang.ExceptionInfo: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)\r\n\tat liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)\r\n\tat liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:217)\r\n\t... 49 more\r\nCaused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:\r\n     Reason: clojure.lang.ExceptionInfo: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)\r\n\tat liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)\r\n\tat liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)\r\n\tat liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.Scope.child(Scope.java:252)\r\n\tat liquibase.Scope.child(Scope.java:256)\r\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)\r\n\t... 57 more\r\nCaused by: clojure.lang.ExceptionInfo: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)\r\n\tat org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)\r\n\tat org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)\r\n\tat org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)\r\n\tat org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)\r\n\tat org.mariadb.jdbc.MariaDbConnection.rollback(MariaDbConnection.java:784)\r\n\tat com.mchange.v2.c3p0.impl.NewProxyConnection.rollback(NewProxyConnection.java:1007)\r\n\tat metabase.db.connection$do_transaction$thunk__32318.invoke(connection.clj:156)\r\n\tat metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)\r\n\tat metabase.db.connection$do_transaction.invoke(connection.clj:146)\r\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)\r\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:457)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2643)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18232.invoke(threaded.clj:71)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)\r\n\tat clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)\r\n\tat clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)\r\n\tat clojure.core.protocols$fn__8244.invoke(protocols.clj:124)\r\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\r\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\r\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\r\n\tat clojure.core$reduce.invokeStatic(core.clj:6887)\r\n\tat clojure.core$reduce.invoke(core.clj:6869)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)\r\n\tat clojure.core$comp$fn__5876.invoke(core.clj:2588)\r\n\tat methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:44)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)\r\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:457)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2643)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)\r\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\r\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)\r\n\tat metabase.db.custom_migrations.UnifyTimeColumnsType$with_connection_STAR___48503.invoke(custom_migrations.clj:992)\r\n\tat toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)\r\n\tat toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)\r\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)\r\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)\r\n\tat clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)\r\n\tat clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)\r\n\tat clojure.core.protocols$fn__8244.invoke(protocols.clj:124)\r\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\r\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\r\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\r\n\tat clojure.core$reduce.invokeStatic(core.clj:6887)\r\n\tat clojure.core$reduce.invoke(core.clj:6869)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)\r\n\tat clojure.core$comp$fn__5876.invoke(core.clj:2587)\r\n\tat methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\r\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\r\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)\r\n\tat toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)\r\n\tat toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)\r\n\tat clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)\r\n\tat clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)\r\n\tat clojure.core.protocols$fn__8244.invoke(protocols.clj:124)\r\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\r\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\r\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\r\n\tat clojure.core$reduce.invokeStatic(core.clj:6887)\r\n\tat clojure.core$reduce.invoke(core.clj:6869)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)\r\n\tat clojure.core$comp$fn__5876.invoke(core.clj:2587)\r\n\tat methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\r\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\r\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)\r\n\tat metabase.db.custom_migrations.UnifyTimeColumnsType.execute(custom_migrations.clj:992)\r\n\tat liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)\r\n\tat liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)\r\n\tat liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)\r\n\t... 72 more\r\nCaused by: java.sql.SQLSyntaxErrorException: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist\r\n\t... 221 more\r\nCaused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist\r\n\tat org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)\r\n\tat org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)\r\n\t... 217 more\r\nCaused by: java.sql.SQLException: SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)\r\n\t... 218 more\r\n2024-04-01 00:47:15,502 INFO metabase.core :: Metabase Shutting Down ...\r\n2024-04-01 00:47:15,503 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\n2024-04-01 00:47:15,510 INFO metabase.core :: Metabase Shutdown COMPLETE\r\n```', 'created_at': datetime.datetime(2024, 4, 1, 1, 27, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029086840, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': '@Frederic-Zhou could you rerun with this [log](https://github.com/metabase/metabase/issues/40546#issuecomment-2017212928) config?', 'created_at': datetime.datetime(2024, 4, 1, 3, 15, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029101003, 'issue_id': 2204864515, 'author': 'Frederic-Zhou', 'body': 'Yes, but need to wait a moment. I changed the database connection of the previous container to Postgre SQL and it worked fine.\r\nI will restart a container to test MySQL', 'created_at': datetime.datetime(2024, 4, 1, 3, 34, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029118663, 'issue_id': 2204864515, 'author': 'Frederic-Zhou', 'body': '@qnkhuat \r\nI copied the log configuration file, put it on disk, mounted it to /tmp/my_log4j2.xml, and set the environment variable JAVA_OPTS = -Dlog4j.configurationFile=file://tmp/my_log4j2.xml After restarting, the log is as follows\r\n```\r\nCaused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:\r\n     Reason: clojure.lang.ExceptionInfo: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)\r\n\tat liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)\r\n\tat liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)\r\n\tat liquibase.command.CommandScope.execute(CommandScope.java:217)\r\n\t... 49 more\r\nCaused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:\r\n     Reason: clojure.lang.ExceptionInfo: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)\r\n\tat liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)\r\n\tat liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)\r\n\tat liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)\r\n\tat liquibase.Scope.lambda$child$0(Scope.java:186)\r\n\tat liquibase.Scope.child(Scope.java:195)\r\n\tat liquibase.Scope.child(Scope.java:185)\r\n\tat liquibase.Scope.child(Scope.java:164)\r\n\tat liquibase.Scope.child(Scope.java:252)\r\n\tat liquibase.Scope.child(Scope.java:256)\r\n\tat liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)\r\n\t... 57 more\r\nCaused by: clojure.lang.ExceptionInfo: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\r\n\tat org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)\r\n\tat org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)\r\n\tat org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)\r\n\tat org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)\r\n\tat org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)\r\n\tat org.mariadb.jdbc.MariaDbConnection.rollback(MariaDbConnection.java:784)\r\n\tat com.mchange.v2.c3p0.impl.NewProxyConnection.rollback(NewProxyConnection.java:1007)\r\n\tat metabase.db.connection$do_transaction$thunk__32318.invoke(connection.clj:156)\r\n\tat metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)\r\n\tat metabase.db.connection$do_transaction.invoke(connection.clj:146)\r\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)\r\n\tat metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:457)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2643)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18232.invoke(threaded.clj:71)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)\r\n\tat clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)\r\n\tat clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)\r\n\tat clojure.core.protocols$fn__8244.invoke(protocols.clj:124)\r\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\r\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\r\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\r\n\tat clojure.core$reduce.invokeStatic(core.clj:6887)\r\n\tat clojure.core$reduce.invoke(core.clj:6869)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)\r\n\tat clojure.core$comp$fn__5876.invoke(core.clj:2588)\r\n\tat methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:44)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)\r\n\tat toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:165)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:457)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2643)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)\r\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\r\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)\r\n\tat metabase.db.custom_migrations.UnifyTimeColumnsType$with_connection_STAR___48503.invoke(custom_migrations.clj:992)\r\n\tat toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)\r\n\tat toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)\r\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)\r\n\tat toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)\r\n\tat clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)\r\n\tat clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)\r\n\tat clojure.core.protocols$fn__8244.invoke(protocols.clj:124)\r\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\r\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\r\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\r\n\tat clojure.core$reduce.invokeStatic(core.clj:6887)\r\n\tat clojure.core$reduce.invoke(core.clj:6869)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)\r\n\tat clojure.core$comp$fn__5876.invoke(core.clj:2587)\r\n\tat methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\r\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\r\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)\r\n\tat toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)\r\n\tat toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)\r\n\tat clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)\r\n\tat clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)\r\n\tat clojure.core.protocols$fn__8244.invoke(protocols.clj:124)\r\n\tat clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)\r\n\tat clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)\r\n\tat clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8236.invoke(protocols.clj:75)\r\n\tat clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)\r\n\tat clojure.core$reduce.invokeStatic(core.clj:6887)\r\n\tat clojure.core$reduce.invoke(core.clj:6869)\r\n\tat methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)\r\n\tat clojure.core$comp$fn__5876.invoke(core.clj:2587)\r\n\tat methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)\r\n\tat toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat clojure.core$partial$fn__5908.invoke(core.clj:2642)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:156)\r\n\tat clojure.lang.RestFn.applyTo(RestFn.java:132)\r\n\tat clojure.lang.AFunction$1.doInvoke(AFunction.java:31)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:421)\r\n\tat methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)\r\n\tat methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)\r\n\tat methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)\r\n\tat metabase.db.custom_migrations.UnifyTimeColumnsType.execute(custom_migrations.clj:992)\r\n\tat liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)\r\n\tat liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)\r\n\tat liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)\r\n\t... 72 more\r\nCaused by: java.sql.SQLSyntaxErrorException: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist\r\n\t... 221 more\r\nCaused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist\r\n\tat org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)\r\n\tat org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)\r\n\t... 217 more\r\nCaused by: java.sql.SQLException: SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)\r\n\tat org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)\r\n\t... 218 more\r\n2024-04-01 03:56:56,019 INFO metabase.core :: Metabase Shutting Down ...\r\n2024-04-01 03:56:56,024 INFO metabase.server :: Shutting Down Embedded Jetty Webserver\r\n2024-04-01 03:56:56,032 INFO metabase.core :: Metabase Shutdown COMPLETE\r\n```', 'created_at': datetime.datetime(2024, 4, 1, 4, 1, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029142458, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'Could you please dump the log into a txt file? I need to look at the toucan2 logs before the error.', 'created_at': datetime.datetime(2024, 4, 1, 4, 33, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029142738, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'also, is this a fresh db?', 'created_at': datetime.datetime(2024, 4, 1, 4, 33, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029277759, 'issue_id': 2204864515, 'author': 'Frederic-Zhou', 'body': '> also, is this a fresh db?\r\n\r\nyes, this is a new db.\r\n\r\nI installed it on Alibaba Cloud ACK, and I need to look into how to download the full logs', 'created_at': datetime.datetime(2024, 4, 1, 7, 3, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2042194073, 'issue_id': 2204864515, 'author': 'wjh000123', 'body': ""I'm facing the same issue here, and I do nothing to the database, my db version is `8.0.28`. Just try to upgrade as usual, and it says `Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat: Reason: clojure.lang.ExceptionInfo: (conn=4816479) SAVEPOINT 547b5804-a609-4dd9-b3b8-618c4e0b5b81 does not exist {:toucan2/context-trace`"", 'created_at': datetime.datetime(2024, 4, 8, 8, 44, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2042210324, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""@wjh000123, please follow the above instructions to get a detailed lob.  It'll help us debug what's going on."", 'created_at': datetime.datetime(2024, 4, 8, 8, 52, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2043915183, 'issue_id': 2204864515, 'author': 'wjh000123', 'body': '@qnkhuat ,  how about this. [](url)\r\n[r6lcafa8r3wd1qnkqdhpvhna1_logs.txt](https://github.com/metabase/metabase/files/14912015/r6lcafa8r3wd1qnkqdhpvhna1_logs.txt)', 'created_at': datetime.datetime(2024, 4, 9, 0, 8, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2116932322, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""@wjh000123 sorry for the late response. We've published the fix, could you try to use the latest version and see if the fix works? the log say you used 49.0 which doesn't have our fix."", 'created_at': datetime.datetime(2024, 5, 17, 7, 33, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2116952706, 'issue_id': 2204864515, 'author': 'WangDanpeng', 'body': 'I just tried 0.49.11 and the problem is not solved', 'created_at': datetime.datetime(2024, 5, 17, 7, 47, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2116979057, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""@WangDanpeng thanks for checking, could you give us the result of running this query\r\n```sql\r\nSELECT table_name, column_name, is_nullable FROM information_schema.columns WHERE (data_type = 'datetime') AND (table_schema = DATABASE());\r\n```"", 'created_at': datetime.datetime(2024, 5, 17, 8, 3, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119563027, 'issue_id': 2204864515, 'author': 'WangDanpeng', 'body': '@qnkhuat \r\n![image](https://github.com/metabase/metabase/assets/20870505/4f4aadb2-0a4e-48bc-a276-7a5515fb17fc)', 'created_at': datetime.datetime(2024, 5, 20, 2, 40, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2119627893, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'The migration is trying to convert all of these columns to `timestamp(6)` type, I wonder what went wrong here.\r\n\r\nCould you try again and post the full log here?', 'created_at': datetime.datetime(2024, 5, 20, 4, 13, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2122486692, 'issue_id': 2204864515, 'author': 'sungaomeng', 'body': '@qnkhuat \r\nI had the same problem\r\nMy upgrade from v0.46.6.4 to v0.48.13 worked fine, but a SAVEPOINT error does not exist when upgrading from v0.48.13 to v0.49.0\r\nAttached is the log of log4j2.xml Debug and the results of Mysql Select\r\nIf you need any more information, please contact me\r\n\r\n```\r\ndocker run -d -p 6100:3000     -e ""MB_DB_TYPE=mysql""     -e ""MB_DB_CONNECTION_URI=jdbc:mysql://rm-***.mysql.rds.aliyuncs.com:3306/metabase_upgrade_test?user=***&password=***""   --name metabase-test   -v $PWD/my_log4j2.xml:/tmp/my_log4j2.xml -e JAVA_OPTS=-Dlog4j.configurationFile=file:///tmp/my_log4j2.xml  metabase/metabase:v0.49.0\r\n```\r\n![metabase-0.49.0.log](https://github.com/metabase/metabase/files/15389601/metabase-0.49.0.log)\r\n![mysql](https://github.com/metabase/metabase/assets/20450635/dac54895-fba5-4bd3-83ba-f6bfc9de9e9c)', 'created_at': datetime.datetime(2024, 5, 21, 12, 6, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2123923267, 'issue_id': 2204864515, 'author': 'WangDanpeng', 'body': '[metabase_20240522.log](https://github.com/metabase/metabase/files/15398565/metabase_20240522.log)\r\n@qnkhuat  This is the full log from when I deployed 0.49.11.', 'created_at': datetime.datetime(2024, 5, 22, 5, 57, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2124981015, 'issue_id': 2204864515, 'author': 'paoliniluis', 'body': '@sungaomeng please try going to 49.11', 'created_at': datetime.datetime(2024, 5, 22, 14, 42, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2126060033, 'issue_id': 2204864515, 'author': 'sungaomeng', 'body': '> @sungaomeng please try going to 49.11\r\nA direct upgrade from 48.13 to 49.11 has the same problem, which is verified by the minimum version upgrade and is caused by the change between 48.13 and 49.0', 'created_at': datetime.datetime(2024, 5, 23, 2, 6, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2126211480, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""The migration is trying to change the db type of these columns from datetime to timestamp(6).\r\n\r\nOne workaround is to alter these yourself.\r\n\r\nStep 1: Run this query to find all the columns that you need to change type: \r\n```sql\r\nSELECT table_name, column_name, is_nullable FROM information_schema.columns WHERE (data_type = 'datetime') AND (table_schema = DATABASE()) AND table_name not like 'v_%' AND LOWER(table_name) NOT IN ('databasechangelog', 'databasechangeloglock'); \r\n```\r\n\r\nStep 2: for each column, run this query\r\n\r\n```sql\r\nALTER TABLE `TABLE_NAME` MODIFY `COLUMN_NAME` TIMESTAMP(6) `NOT NULL OR NULL`\r\n```\r\n\r\nCould you try this and let us know how it goes?\r\n\r\nP/s: make sure you backup your DB first."", 'created_at': datetime.datetime(2024, 5, 23, 4, 33, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2146753003, 'issue_id': 2204864515, 'author': 'wjh000123', 'body': ""> The migration is trying to change the db type of these columns from datetime to timestamp(6).\r\n> \r\n> One workaround is to alter these yourself.\r\n> \r\n> Step 1: Run this query to find all the columns that you need to change type:\r\n> \r\n> ```sql\r\n> SELECT table_name, column_name, is_nullable FROM information_schema.columns WHERE (data_type = 'datetime') AND (table_schema = DATABASE()) where table_name not like 'v_%'; \r\n> ```\r\n> \r\n> Step 2: for each column, run this query\r\n> \r\n> ```sql\r\n> ALTER TABLE `TABLE_NAME` MODIFY `COLUMN_NAME` TIMESTAMP(6) `NOT NULL OR NULL`\r\n> ```\r\n> \r\n> Could you try this and let us know how it goes?\r\n> \r\n> P/s: make sure you backup your DB first.\r\n\r\nAfter manually update the column type from `datetime` to `timestamp`, the upgrade could go on, and it's OK now."", 'created_at': datetime.datetime(2024, 6, 4, 6, 58, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2159612060, 'issue_id': 2204864515, 'author': 'wjh000123', 'body': ""After I tried to upgrade to new version, the similar error occurred, which was:\r\n `Reason: liquibase.exception.DatabaseException: (conn=7301810) Invalid default value for 'updated_at' [Failed SQL: (1067) CREATE TABLE `metabase`.`cloud_migration` (`id` INT AUTO_INCREMENT NOT NULL COMMENT 'Unique ID', `external_id` LONGTEXT NOT NULL COMMENT 'Matching ID in Cloud for this migration', `upload_url` LONGTEXT NOT NULL COMMENT 'URL where the backup will be uploaded to', `state` VARCHAR(32) DEFAULT 'init' NOT NULL COMMENT 'Current state of the migration: init, setup, dump, upload, done, error, cancelled', `progress` INT DEFAULT 0 NOT NULL COMMENT 'Number between 0 to 100 representing progress as a percentage', `created_at` timestamp(6) NOT NULL COMMENT 'Timestamp when the config was inserted', `updated_at` timestamp(6) NOT NULL COMMENT 'Timestamp when the config was updated', CONSTRAINT `PK_CLOUD_MIGRATION` PRIMARY KEY (`id`)) COMMENT='Migrate to cloud directly from Metabase' ENGINE InnoDB CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;]`\r\n\r\nAfter some investigation, the root cause of mine issue is that the sql_mode in mysql 8 (you can check it by `show variables like 'sql_mode' ; `), it has `NO_ZERO_IN_DATE,NO_ZERO_DATE` by default, just delete these two items. Maybe the migration script shoud consider this situation. @qnkhuat"", 'created_at': datetime.datetime(2024, 6, 11, 1, 46, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2159652939, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': 'Thanks for the detailed info and the workaround. \r\n\r\nCould you create a new issue for this? Someone might benefit from your workaround, and it helps us prioritize the bug.', 'created_at': datetime.datetime(2024, 6, 11, 2, 27, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2185568141, 'issue_id': 2204864515, 'author': 'qnkhuat', 'body': ""This seems to relate to https://github.com/metabase/metabase/issues/43985#issuecomment-2167306996; we need to try to reproduce this on the Alibaba cloud database.\r\n\r\nI'm lowering the priority for this because it shouldn't be a new issue for new installers, and we have a workaround."", 'created_at': datetime.datetime(2024, 6, 24, 4, 12, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2248764420, 'issue_id': 2204864515, 'author': 'paoliniluis', 'body': '@UlyC did you use some specific transaction isolation mode here? or maybe the database forces a specific one?', 'created_at': datetime.datetime(2024, 7, 24, 19, 37, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418971165, 'issue_id': 2204864515, 'author': 'myesn', 'body': '@paoliniluis hi, I‚Äôm also using Alibaba Cloud RDS MySQL 8.0, I created a new database, the same error occurs after running metabase.jar, metabase.jar is the latest, please tell me what is the solution?\n\n```\n2024-10-17 16:49:50,698 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.00-059::qnkhuat encountered an exception.\nclojure.lang.ExceptionInfo: (conn=326345) SAVEPOINT b6f999cd-5f20-48f4-8aa8-72d9589c9b91 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}\n```', 'created_at': datetime.datetime(2024, 10, 17, 9, 2, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503396250, 'issue_id': 2204864515, 'author': 'Code-Farmer-Ming', 'body': '@wjh000123 you rock', 'created_at': datetime.datetime(2024, 11, 27, 9, 42, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504346519, 'issue_id': 2204864515, 'author': 'paoliniluis', 'body': '@myesn there‚Äôs no solution yet, as apsaradb seems to be different than mysql', 'created_at': datetime.datetime(2024, 11, 27, 16, 48, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516408921, 'issue_id': 2204864515, 'author': 'Hipocoro', 'body': 'Just for the record, this also fails in AWS RDS using MariaDB 10.6.16.\n\nI was trying to update from 0.47.x to 0.51.x\n\nTo get it working I got the change the RDS parameter group _sql_mode_ removing `NO_ZERO_IN_DATE,NO_ZERO_DATE`. After restarting the instance I got it working.', 'created_at': datetime.datetime(2024, 12, 4, 7, 31, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561283983, 'issue_id': 2204864515, 'author': 'paoliniluis', 'body': 'following the thread on https://github.com/metabase/metabase/issues/46111', 'created_at': datetime.datetime(2024, 12, 24, 16, 45, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577730054, 'issue_id': 2204864515, 'author': 'zhoujunhe', 'body': 'Ëøô‰∏™ÈóÆÈ¢òÂæàÁÆÄÂçïÔºåÂêØÂä®metabaseÁöÑÊó∂ÂÄôÊääÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ‰ª•‰∏ãÂÄºÔºåÊ≥®ÊÑèÊääIPÔºåÊï∞ÊçÆÂ∫ìÔºåÁî®Êà∑ÂêçÂíåÂØÜÁ†ÅÊç¢ÊàêËá™Â∑±ÁöÑÔºåÂè™Ë¶Åsql_modeÊ≤°ÊúâNO_ZERO_IN_DATE,NO_ZERO_DATEÂ∞±Ë°åÔºåÊàëÈáåÂè™‰ΩøÁî®‰∫ÜSTRICT_TRANS_TABLESÔºåÂ§ßÂÆ∂Áî®ÈòøÈáå‰∫ëÁöÑÂ∫îÈÉΩ‰ºö‰∏≠ÊñáÂêßÔºåËøô‰∏™Âú®metabaseÂÆòÊñπÊñáÊ°£ËøòÁâπÊÑèÊèê‰∫Ü‰∏çÊîØÊåÅÈòøÈáå‰∫ëÁöÑmysqlÔºåÂÖ∂ÂÆûÊñáÊ°£Ê†áËÆ∞‰∏Ä‰∏ãÔºåÁ¢∞Âà∞ËøôÈóÆÈ¢òËÆ©Â§ßÂÆ∂‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèMB_DB_CONNECTION_URIÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇ\n\n```\nMB_DB_CONNECTION_URI=""jdbc:mysql://{IP}:3306/metabase?sessionVariables=sql_mode=\'STRICT_TRANS_TABLES\'""\nMB_DB_USER=""username""\nMB_DB_PASS=""password""\n```', 'created_at': datetime.datetime(2025, 1, 8, 13, 54, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578003118, 'issue_id': 2204864515, 'author': 'paoliniluis', 'body': '@UlyC @zhoujunhe can you upgrade to 52.5?', 'created_at': datetime.datetime(2025, 1, 8, 15, 46, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581683251, 'issue_id': 2204864515, 'author': 'zhoujunhe', 'body': '> [@UlyC](https://github.com/UlyC) [@zhoujunhe](https://github.com/zhoujunhe) can you upgrade to 52.5?\n\nÂèØ‰ª•ÁöÑÔºåÊàëÂ∑≤ÁªèÊõ¥Êñ∞Âà∞52.5ÁâàÊú¨‰∫Ü', 'created_at': datetime.datetime(2025, 1, 10, 3, 45, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582859914, 'issue_id': 2204864515, 'author': 'paoliniluis', 'body': '@zhoujunhe does it still fail?', 'created_at': datetime.datetime(2025, 1, 10, 14, 40, 7, tzinfo=datetime.timezone.utc)}]","qnkhuat on (2024-03-25 04:48:28 UTC): Please upgrade to 8.0.17 and try again, it's now our minimum supported version https://www.metabase.com/docs/latest/installation-and-operation/configuring-application-database#mysql-or-mariadb

UlyC (Issue Creator) on (2024-03-25 04:51:30 UTC): As you can see in the log, my MySQL version is 8.0.34

qnkhuat on (2024-03-25 04:55:47 UTC): We'll need more logs to diagnose this, could you change the log level for `liquibase` to `DEBUG` level using this log config

```xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<Configuration>
  <Appenders>
    <Console name=""STDOUT"" target=""SYSTEM_OUT"" follow=""true"">
      <PatternLayout pattern=""%date %level %logger{2} :: %message%n%throwable"">
        <replace regex="":basic-auth \\[.*\\]"" replacement="":basic-auth [redacted]""/>
      </PatternLayout>
    </Console>

  </Appenders>

  <Loggers>
    <Logger name=""metabase"" level=""INFO""/>
    <Logger name=""metabase-enterprise"" level=""INFO""/>
    <Logger name=""metabase.metabot"" level=""DEBUG""/>
    <Logger name=""metabase.plugins"" level=""DEBUG""/>
    <Logger name=""metabase.server.middleware"" level=""DEBUG""/>
    <Logger name=""metabase.query-processor.async"" level=""DEBUG""/>
    <Logger name=""com.mchange"" level=""ERROR""/>
    <Logger name=""org.quartz"" level=""INFO""/>
    <Logger name=""liquibase"" level=""DEBUG""/>
    <Logger name=""toucan2"" level=""TRACE""/>
    <Logger name=""net.snowflake.client.jdbc.SnowflakeConnectString"" level=""ERROR""/>

    <Root level=""WARN"">
      <AppenderRef ref=""STDOUT""/>
    </Root>
  </Loggers>
</Configuration>
```

Then start metabase again with this command

```bash
java -Dlog4j.configurationFile=file:/path/to/custom/log4j2.xml -jar metabase.jar
```

UlyC (Issue Creator) on (2024-03-25 04:58:14 UTC): I'm using metabase in a docker container on remote server, do I need to package the image myself?

qnkhuat on (2024-03-25 04:59:08 UTC): try this
```bash
docker run -p 3000:3000 -v $PWD/my_log4j2.xml:/tmp/my_log4j2.xml -e JAVA_OPTS=-Dlog4j.configurationFile=file:///tmp/my_log4j2.xml metabase/metabase`
```

qnkhuat on (2024-03-25 05:07:16 UTC): @UlyC added another entry for `toucan2`, please update!

UlyC (Issue Creator) on (2024-03-25 05:22:13 UTC): @qnkhuat  

Since the log is too long, I put it in an attachment
[r6lcafa8r3wd1qnkqdhpvhna1_logs.txt](https://github.com/metabase/metabase/files/14739132/r6lcafa8r3wd1qnkqdhpvhna1_logs.txt)

qnkhuat on (2024-03-25 05:47:30 UTC): Thanks, unfortunately the log is not very helpful.

Could you try running this query?

```sql
select table_name, column_name, column_default, is_nullable  from information_schema.columns where data_type = 'datetime' and TABLE_SCHEMA = 'metabase';
```

UlyC (Issue Creator) on (2024-03-25 05:50:39 UTC): <img width=""850"" alt=""image"" src=""https://github.com/metabase/metabase/assets/36838240/3cded0a4-75cc-49b2-85f7-e334165b912d"">

qnkhuat on (2024-03-25 06:25:14 UTC): interesting, did you make any changes to the DB schema manually?

UlyC (Issue Creator) on (2024-03-25 06:27:58 UTC): Nope, I'm using a whole new database,and  I haven't changed any of the data.

Do I need to create a new database to debug it?

qnkhuat on (2024-03-25 07:23:56 UTC): I have a fix here, it would be nice if you could verify if it's fixed by using the jars from this [build](https://github.com/metabase/metabase/actions/runs/8416379324?pr=40547).

Note: this is not production-ready build, so DO NOT use it with your production database.

Frederic-Zhou on (2024-04-01 01:27:14 UTC): v49.2 will still report the same error, Mysql 8.0.34
log blow :
```
Warning: environ value jdk-11.0.22+7 for key :java-version has been overwritten with 11.0.22
2024-04-01 01:46:42,017 INFO metabase.util :: Maximum memory available to JVM: 6.8 GB
2024-04-01 01:46:44,234 INFO util.encryption :: Saved credentials encryption is DISABLED for this Metabase instance. üîì 
 For more information, see https://metabase.com/docs/latest/operations-guide/encrypting-database-details-at-rest.html
2024-04-01 01:46:50,565 INFO driver.impl :: [34mRegistered abstract driver :sql[0m  üöö
2024-04-01 01:46:50,578 INFO driver.impl :: [34mRegistered abstract driver :sql-jdbc[0m (parents: [:sql]) üöö
2024-04-01 01:46:50,585 INFO metabase.util :: [32mLoad driver :sql-jdbc took 86.8 ms[0m
2024-04-01 01:46:50,585 INFO driver.impl :: [34mRegistered driver :h2[0m (parents: [:sql-jdbc]) üöö
2024-04-01 01:46:50,764 INFO driver.impl :: [34mRegistered driver :mysql[0m (parents: [:sql-jdbc]) üöö
2024-04-01 01:46:50,800 INFO driver.impl :: [34mRegistered driver :postgres[0m (parents: [:sql-jdbc]) üöö
2024-04-01 01:46:52,722 INFO metabase.core :: 
Metabase v0.49.2 (4b83b88) 

Copyright ¬© 2024 Metabase, Inc. 

Metabase Enterprise Edition extensions are NOT PRESENT.
2024-04-01 01:46:52,734 INFO metabase.core :: Starting Metabase in STANDALONE mode
2024-04-01 01:46:52,786 INFO metabase.server :: Launching Embedded Jetty Webserver with config:
 {:port 3000, :host ""0.0.0.0""}

```
then error occur
```
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 49 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 57 more
Caused by: clojure.lang.ExceptionInfo: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
	at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)
	at org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)
	at org.mariadb.jdbc.MariaDbConnection.rollback(MariaDbConnection.java:784)
	at com.mchange.v2.c3p0.impl.NewProxyConnection.rollback(NewProxyConnection.java:1007)
	at metabase.db.connection$do_transaction$thunk__32318.invoke(connection.clj:156)
	at metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)
	at metabase.db.connection$do_transaction.invoke(connection.clj:146)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18232.invoke(threaded.clj:71)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2588)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:44)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
	at metabase.db.custom_migrations.UnifyTimeColumnsType$with_connection_STAR___48503.invoke(custom_migrations.clj:992)
	at toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)
	at toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
	at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at metabase.db.custom_migrations.UnifyTimeColumnsType.execute(custom_migrations.clj:992)
	at liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 72 more
Caused by: java.sql.SQLSyntaxErrorException: (conn=1071) SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist
	... 221 more
Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist
	at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)
	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)
	... 217 more
Caused by: java.sql.SQLException: SAVEPOINT f26e4754-eb68-4da7-98e2-3578856cb6e2 does not exist
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)
	... 218 more
2024-04-01 00:47:15,502 INFO metabase.core :: Metabase Shutting Down ...
2024-04-01 00:47:15,503 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-04-01 00:47:15,510 INFO metabase.core :: Metabase Shutdown COMPLETE
```

qnkhuat on (2024-04-01 03:15:47 UTC): @Frederic-Zhou could you rerun with this [log](https://github.com/metabase/metabase/issues/40546#issuecomment-2017212928) config?

Frederic-Zhou on (2024-04-01 03:34:47 UTC): Yes, but need to wait a moment. I changed the database connection of the previous container to Postgre SQL and it worked fine.
I will restart a container to test MySQL

Frederic-Zhou on (2024-04-01 04:01:36 UTC): @qnkhuat 
I copied the log configuration file, put it on disk, mounted it to /tmp/my_log4j2.xml, and set the environment variable JAVA_OPTS = -Dlog4j.configurationFile=file://tmp/my_log4j2.xml After restarting, the log is as follows
```
Caused by: liquibase.exception.LiquibaseException: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:151)
	at liquibase.command.core.AbstractUpdateCommandStep.lambda$run$0(AbstractUpdateCommandStep.java:110)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:108)
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105)
	at liquibase.command.CommandScope.execute(CommandScope.java:217)
	... 49 more
Caused by: liquibase.exception.MigrationFailedException: Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat:
     Reason: clojure.lang.ExceptionInfo: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:797)
	at liquibase.changelog.visitor.UpdateVisitor.executeAcceptedChange(UpdateVisitor.java:119)
	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:68)
	at liquibase.changelog.ChangeLogIterator$2.lambda$run$0(ChangeLogIterator.java:133)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.changelog.ChangeLogIterator$2.run(ChangeLogIterator.java:122)
	at liquibase.Scope.lambda$child$0(Scope.java:186)
	at liquibase.Scope.child(Scope.java:195)
	at liquibase.Scope.child(Scope.java:185)
	at liquibase.Scope.child(Scope.java:164)
	at liquibase.Scope.child(Scope.java:252)
	at liquibase.Scope.child(Scope.java:256)
	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:89)
	... 57 more
Caused by: clojure.lang.ExceptionInfo: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:62)
	at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
	at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:362)
	at org.mariadb.jdbc.MariaDbStatement.execute(MariaDbStatement.java:500)
	at org.mariadb.jdbc.MariaDbConnection.rollback(MariaDbConnection.java:784)
	at com.mchange.v2.c3p0.impl.NewProxyConnection.rollback(NewProxyConnection.java:1007)
	at metabase.db.connection$do_transaction$thunk__32318.invoke(connection.clj:156)
	at metabase.db.connection$do_transaction.invokeStatic(connection.clj:165)
	at metabase.db.connection$do_transaction.invoke(connection.clj:146)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invokeStatic(connection.clj:199)
	at metabase.db.connection$do_with_transaction_primary_method_java_sql_Connection.invoke(connection.clj:172)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18232.invoke(threaded.clj:71)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2588)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:44)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invokeStatic(connection.clj:249)
	at toucan2.connection$do_with_transaction_around_method_toucan2_connection_default.invoke(connection.clj:245)
	at clojure.lang.AFn.applyToHelper(AFn.java:165)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:457)
	at clojure.core$partial$fn__5908.invoke(core.clj:2643)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:58)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:195)
	at metabase.db.custom_migrations.UnifyTimeColumnsType$with_connection_STAR___48503.invoke(custom_migrations.clj:992)
	at toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)
	at toucan2.connection$bind_current_connectable_fn$fn__21138.invoke(connection.clj:104)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invokeStatic(connection.clj:13)
	at toucan2.jdbc.connection$do_with_connection_primary_method_java_sql_Connection.invoke(connection.clj:11)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at toucan2.connection$do_with_connection_primary_method_.invokeStatic(connection.clj:204)
	at toucan2.connection$do_with_connection_primary_method_.invoke(connection.clj:194)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.combo.threaded$fn__18228$fn__18229$fn__18230.invoke(threaded.clj:70)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198$fn__18202.invoke(threaded.clj:23)
	at clojure.lang.ArrayChunk.reduce(ArrayChunk.java:58)
	at clojure.core.protocols$fn__8244.invokeStatic(protocols.clj:136)
	at clojure.core.protocols$fn__8244.invoke(protocols.clj:124)
	at clojure.core.protocols$fn__8204$G__8199__8213.invoke(protocols.clj:19)
	at clojure.core.protocols$seq_reduce.invokeStatic(protocols.clj:31)
	at clojure.core.protocols$fn__8236.invokeStatic(protocols.clj:75)
	at clojure.core.protocols$fn__8236.invoke(protocols.clj:75)
	at clojure.core.protocols$fn__8178$G__8173__8191.invoke(protocols.clj:13)
	at clojure.core$reduce.invokeStatic(core.clj:6887)
	at clojure.core$reduce.invoke(core.clj:6869)
	at methodical.impl.combo.threaded$reducer_fn$fn__18198.invoke(threaded.clj:21)
	at clojure.core$comp$fn__5876.invoke(core.clj:2587)
	at methodical.impl.combo.threaded$combine_with_threader$fn__18208.invoke(threaded.clj:43)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invokeStatic(connection.clj:118)
	at toucan2.connection$do_with_connection_around_method_toucan2_connection_default.invoke(connection.clj:106)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at clojure.core$partial$fn__5908.invoke(core.clj:2642)
	at clojure.lang.AFn.applyToHelper(AFn.java:156)
	at clojure.lang.RestFn.applyTo(RestFn.java:132)
	at clojure.lang.AFunction$1.doInvoke(AFunction.java:31)
	at clojure.lang.RestFn.invoke(RestFn.java:421)
	at methodical.impl.standard$invoke_multifn.invokeStatic(standard.clj:55)
	at methodical.impl.standard$invoke_multifn.invoke(standard.clj:47)
	at methodical.impl.standard.StandardMultiFn.invoke(standard.clj:193)
	at metabase.db.custom_migrations.UnifyTimeColumnsType.execute(custom_migrations.clj:992)
	at liquibase.change.custom.CustomChangeWrapper.generateStatements(CustomChangeWrapper.java:169)
	at liquibase.database.AbstractJdbcDatabase.executeStatements(AbstractJdbcDatabase.java:1271)
	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:755)
	... 72 more
Caused by: java.sql.SQLSyntaxErrorException: (conn=2001) SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist
	... 221 more
Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist
	at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:263)
	at org.mariadb.jdbc.MariaDbStatement.executeInternal(MariaDbStatement.java:356)
	... 217 more
Caused by: java.sql.SQLException: SAVEPOINT 09b8fb05-358c-4a1b-a1e5-cc4c8fd2bced does not exist
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
	at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)
	... 218 more
2024-04-01 03:56:56,019 INFO metabase.core :: Metabase Shutting Down ...
2024-04-01 03:56:56,024 INFO metabase.server :: Shutting Down Embedded Jetty Webserver
2024-04-01 03:56:56,032 INFO metabase.core :: Metabase Shutdown COMPLETE
```

qnkhuat on (2024-04-01 04:33:36 UTC): Could you please dump the log into a txt file? I need to look at the toucan2 logs before the error.

qnkhuat on (2024-04-01 04:33:58 UTC): also, is this a fresh db?

Frederic-Zhou on (2024-04-01 07:03:45 UTC): yes, this is a new db.

I installed it on Alibaba Cloud ACK, and I need to look into how to download the full logs

wjh000123 on (2024-04-08 08:44:22 UTC): I'm facing the same issue here, and I do nothing to the database, my db version is `8.0.28`. Just try to upgrade as usual, and it says `Migration failed for changeset migrations/001_update_migrations.yaml::v49.00-059::qnkhuat: Reason: clojure.lang.ExceptionInfo: (conn=4816479) SAVEPOINT 547b5804-a609-4dd9-b3b8-618c4e0b5b81 does not exist {:toucan2/context-trace`

qnkhuat on (2024-04-08 08:52:31 UTC): @wjh000123, please follow the above instructions to get a detailed lob.  It'll help us debug what's going on.

wjh000123 on (2024-04-09 00:08:59 UTC): @qnkhuat ,  how about this. [](url)
[r6lcafa8r3wd1qnkqdhpvhna1_logs.txt](https://github.com/metabase/metabase/files/14912015/r6lcafa8r3wd1qnkqdhpvhna1_logs.txt)

qnkhuat on (2024-05-17 07:33:26 UTC): @wjh000123 sorry for the late response. We've published the fix, could you try to use the latest version and see if the fix works? the log say you used 49.0 which doesn't have our fix.

WangDanpeng on (2024-05-17 07:47:10 UTC): I just tried 0.49.11 and the problem is not solved

qnkhuat on (2024-05-17 08:03:46 UTC): @WangDanpeng thanks for checking, could you give us the result of running this query
```sql
SELECT table_name, column_name, is_nullable FROM information_schema.columns WHERE (data_type = 'datetime') AND (table_schema = DATABASE());
```

WangDanpeng on (2024-05-20 02:40:02 UTC): @qnkhuat 
![image](https://github.com/metabase/metabase/assets/20870505/4f4aadb2-0a4e-48bc-a276-7a5515fb17fc)

qnkhuat on (2024-05-20 04:13:50 UTC): The migration is trying to convert all of these columns to `timestamp(6)` type, I wonder what went wrong here.

Could you try again and post the full log here?

sungaomeng on (2024-05-21 12:06:45 UTC): @qnkhuat 
I had the same problem
My upgrade from v0.46.6.4 to v0.48.13 worked fine, but a SAVEPOINT error does not exist when upgrading from v0.48.13 to v0.49.0
Attached is the log of log4j2.xml Debug and the results of Mysql Select
If you need any more information, please contact me

```
docker run -d -p 6100:3000     -e ""MB_DB_TYPE=mysql""     -e ""MB_DB_CONNECTION_URI=jdbc:mysql://rm-***.mysql.rds.aliyuncs.com:3306/metabase_upgrade_test?user=***&password=***""   --name metabase-test   -v $PWD/my_log4j2.xml:/tmp/my_log4j2.xml -e JAVA_OPTS=-Dlog4j.configurationFile=file:///tmp/my_log4j2.xml  metabase/metabase:v0.49.0
```
![metabase-0.49.0.log](https://github.com/metabase/metabase/files/15389601/metabase-0.49.0.log)
![mysql](https://github.com/metabase/metabase/assets/20450635/dac54895-fba5-4bd3-83ba-f6bfc9de9e9c)

WangDanpeng on (2024-05-22 05:57:44 UTC): [metabase_20240522.log](https://github.com/metabase/metabase/files/15398565/metabase_20240522.log)
@qnkhuat  This is the full log from when I deployed 0.49.11.

paoliniluis on (2024-05-22 14:42:10 UTC): @sungaomeng please try going to 49.11

sungaomeng on (2024-05-23 02:06:30 UTC): A direct upgrade from 48.13 to 49.11 has the same problem, which is verified by the minimum version upgrade and is caused by the change between 48.13 and 49.0

qnkhuat on (2024-05-23 04:33:14 UTC): The migration is trying to change the db type of these columns from datetime to timestamp(6).

One workaround is to alter these yourself.

Step 1: Run this query to find all the columns that you need to change type: 
```sql
SELECT table_name, column_name, is_nullable FROM information_schema.columns WHERE (data_type = 'datetime') AND (table_schema = DATABASE()) AND table_name not like 'v_%' AND LOWER(table_name) NOT IN ('databasechangelog', 'databasechangeloglock'); 
```

Step 2: for each column, run this query

```sql
ALTER TABLE `TABLE_NAME` MODIFY `COLUMN_NAME` TIMESTAMP(6) `NOT NULL OR NULL`
```

Could you try this and let us know how it goes?

P/s: make sure you backup your DB first.

wjh000123 on (2024-06-04 06:58:17 UTC): After manually update the column type from `datetime` to `timestamp`, the upgrade could go on, and it's OK now.

wjh000123 on (2024-06-11 01:46:24 UTC): After I tried to upgrade to new version, the similar error occurred, which was:
 `Reason: liquibase.exception.DatabaseException: (conn=7301810) Invalid default value for 'updated_at' [Failed SQL: (1067) CREATE TABLE `metabase`.`cloud_migration` (`id` INT AUTO_INCREMENT NOT NULL COMMENT 'Unique ID', `external_id` LONGTEXT NOT NULL COMMENT 'Matching ID in Cloud for this migration', `upload_url` LONGTEXT NOT NULL COMMENT 'URL where the backup will be uploaded to', `state` VARCHAR(32) DEFAULT 'init' NOT NULL COMMENT 'Current state of the migration: init, setup, dump, upload, done, error, cancelled', `progress` INT DEFAULT 0 NOT NULL COMMENT 'Number between 0 to 100 representing progress as a percentage', `created_at` timestamp(6) NOT NULL COMMENT 'Timestamp when the config was inserted', `updated_at` timestamp(6) NOT NULL COMMENT 'Timestamp when the config was updated', CONSTRAINT `PK_CLOUD_MIGRATION` PRIMARY KEY (`id`)) COMMENT='Migrate to cloud directly from Metabase' ENGINE InnoDB CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;]`

After some investigation, the root cause of mine issue is that the sql_mode in mysql 8 (you can check it by `show variables like 'sql_mode' ; `), it has `NO_ZERO_IN_DATE,NO_ZERO_DATE` by default, just delete these two items. Maybe the migration script shoud consider this situation. @qnkhuat

qnkhuat on (2024-06-11 02:27:33 UTC): Thanks for the detailed info and the workaround. 

Could you create a new issue for this? Someone might benefit from your workaround, and it helps us prioritize the bug.

qnkhuat on (2024-06-24 04:12:40 UTC): This seems to relate to https://github.com/metabase/metabase/issues/43985#issuecomment-2167306996; we need to try to reproduce this on the Alibaba cloud database.

I'm lowering the priority for this because it shouldn't be a new issue for new installers, and we have a workaround.

paoliniluis on (2024-07-24 19:37:52 UTC): @UlyC did you use some specific transaction isolation mode here? or maybe the database forces a specific one?

myesn on (2024-10-17 09:02:48 UTC): @paoliniluis hi, I‚Äôm also using Alibaba Cloud RDS MySQL 8.0, I created a new database, the same error occurs after running metabase.jar, metabase.jar is the latest, please tell me what is the solution?

```
2024-10-17 16:49:50,698 ERROR liquibase.changelog :: ChangeSet migrations/001_update_migrations.yaml::v49.00-059::qnkhuat encountered an exception.
clojure.lang.ExceptionInfo: (conn=326345) SAVEPOINT b6f999cd-5f20-48f4-8aa8-72d9589c9b91 does not exist {:toucan2/context-trace [[""resolve connection"" {:toucan2.connection/connectable org.mariadb.jdbc.MariaDbConnection}] [""resolve connection"" {:toucan2.connection/connectable nil}]]}
```

Code-Farmer-Ming on (2024-11-27 09:42:12 UTC): @wjh000123 you rock

paoliniluis on (2024-11-27 16:48:59 UTC): @myesn there‚Äôs no solution yet, as apsaradb seems to be different than mysql

Hipocoro on (2024-12-04 07:31:56 UTC): Just for the record, this also fails in AWS RDS using MariaDB 10.6.16.

I was trying to update from 0.47.x to 0.51.x

To get it working I got the change the RDS parameter group _sql_mode_ removing `NO_ZERO_IN_DATE,NO_ZERO_DATE`. After restarting the instance I got it working.

paoliniluis on (2024-12-24 16:45:49 UTC): following the thread on https://github.com/metabase/metabase/issues/46111

zhoujunhe on (2025-01-08 13:54:58 UTC): Ëøô‰∏™ÈóÆÈ¢òÂæàÁÆÄÂçïÔºåÂêØÂä®metabaseÁöÑÊó∂ÂÄôÊääÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ‰ª•‰∏ãÂÄºÔºåÊ≥®ÊÑèÊääIPÔºåÊï∞ÊçÆÂ∫ìÔºåÁî®Êà∑ÂêçÂíåÂØÜÁ†ÅÊç¢ÊàêËá™Â∑±ÁöÑÔºåÂè™Ë¶Åsql_modeÊ≤°ÊúâNO_ZERO_IN_DATE,NO_ZERO_DATEÂ∞±Ë°åÔºåÊàëÈáåÂè™‰ΩøÁî®‰∫ÜSTRICT_TRANS_TABLESÔºåÂ§ßÂÆ∂Áî®ÈòøÈáå‰∫ëÁöÑÂ∫îÈÉΩ‰ºö‰∏≠ÊñáÂêßÔºåËøô‰∏™Âú®metabaseÂÆòÊñπÊñáÊ°£ËøòÁâπÊÑèÊèê‰∫Ü‰∏çÊîØÊåÅÈòøÈáå‰∫ëÁöÑmysqlÔºåÂÖ∂ÂÆûÊñáÊ°£Ê†áËÆ∞‰∏Ä‰∏ãÔºåÁ¢∞Âà∞ËøôÈóÆÈ¢òËÆ©Â§ßÂÆ∂‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèMB_DB_CONNECTION_URIÂ∞±ÂèØ‰ª•‰∫Ü„ÄÇ

```
MB_DB_CONNECTION_URI=""jdbc:mysql://{IP}:3306/metabase?sessionVariables=sql_mode='STRICT_TRANS_TABLES'""
MB_DB_USER=""username""
MB_DB_PASS=""password""
```

paoliniluis on (2025-01-08 15:46:26 UTC): @UlyC @zhoujunhe can you upgrade to 52.5?

zhoujunhe on (2025-01-10 03:45:39 UTC): ÂèØ‰ª•ÁöÑÔºåÊàëÂ∑≤ÁªèÊõ¥Êñ∞Âà∞52.5ÁâàÊú¨‰∫Ü

paoliniluis on (2025-01-10 14:40:07 UTC): @zhoujunhe does it still fail?

"
2204415551,issue,closed,not_planned,Changes in date and number format- when fetching results through API query/csv or xlsx or json endpoint,"### Describe the bug

In Metabase version 0.49.0, there is a discrepancy in the formatting of downloaded CSV, XLSX, or JSON files when compared to the previous version. Specifically, the issue arises with visualizations containing percentages or numbers with comma separators, as well as date formats are reflected as such is downloads without raw numbers and value.

Affected Functionality:
Downloading CSV, XLSX, or JSON files through the API endpoint (api/card/query/csv).
Date formats in downloaded files.
example result: February 19, 2024, 12:00 AM	60.58%

Expected Behavior:
In previous versions of Metabase, the downloaded files retained the raw values with many decimal places for numerical data and followed a consistent date format.
actual result: 2024-02-19T00:00:00Z	      0.605767631	

Impact:
The formatting differences in the downloaded files make it challenging to compare results between the current and previous versions of Metabase, especially when migrating reports or analyzing data.



### To Reproduce

Output from sample database:
![image](https://github.com/metabase/metabase/assets/139036730/3c7ee1e0-ed31-4aa9-9d90-32fa05f0e516)

Downloaded result through api/card/csv has same visualization results.
![image](https://github.com/metabase/metabase/assets/139036730/6f2d4a82-db5c-4e26-8be8-45561df49e98)

Expected result (as in previous metabase version before v0.49.0):
![image](https://github.com/metabase/metabase/assets/139036730/86a04ae4-3166-4621-891d-de6658282b29)



### Expected behavior

The downloaded files / fetched results through API  retained the raw values with many decimal places for numerical data and followed a consistent date format.
Date format to return to how it worked prior to 0.49.0

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.15+10"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.15"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.15+10"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""bigquery-cloud-sdk"",
      ""mongo"",
      ""postgres"",
      ""presto-jdbc"",
      ""snowflake""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""5.7.39-log""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.5""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2022-06-13"",
      ""tag"": ""v0.43.3"",
      ""branch"": ""release-x.43.x"",
      ""hash"": ""c9c7ef0""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Dhaka""
    }
  }
}
```


### Severity

2- Causing issue in migrating reports

### Additional context

This was working good before v0.49.0",Varshini-S-5007402,2024-03-24 15:38:58+00:00,[],2024-03-25 15:06:34+00:00,2024-03-25 15:06:33+00:00,https://github.com/metabase/metabase/issues/40544,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2018221329, 'issue_id': 2204415551, 'author': 'paoliniluis', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/40420', 'created_at': datetime.datetime(2024, 3, 25, 15, 6, 34, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-25 15:06:34 UTC): Duplicate of https://github.com/metabase/metabase/issues/40420

"
2204233921,issue,open,,MB_SAML_GROUP_SYNC doesn't take affect,"**Describe the bug**
I've configured SAML authentication through environment variables, but SAML group sync isn't working and when I navigate to `/admin/settings/authentication/saml` the setting is disabled. 

**Logs**
Please include javascript console and server logs around the time this bug occurred. For information about how to get these, consult our [bug troubleshooting guide](https://metabase.com/docs/latest/troubleshooting-guide/bugs.html)

**To Reproduce**
Steps to reproduce the behavior:
1. Configure SAML authentication completely through environment variables including MB_SAML_GROUP_SYNC
2. Go to /admin/settings/authentication/saml in metabase
3. Scroll down to group sync settings
4. See that group sync is disabled

**Expected behavior**
Group sync is enabled

**Screenshots**
In the `/api/session/properties` I see this in the response 

<img width=""293"" alt=""Screenshot 2024-03-24 at 7 55 42‚ÄØAM"" src=""https://github.com/metabase/metabase/assets/132286260/a38c5a62-ea79-43fd-9e14-1e9a38b78809"">

and in the ui on `/admin/settings/authentication/saml`

<img width=""742"" alt=""Screenshot 2024-03-24 at 7 57 36‚ÄØAM"" src=""https://github.com/metabase/metabase/assets/132286260/efa7a9ca-dc09-424e-918e-d1d40889657f"">

**Severity**
How severe an issue is this bug to you? Is this annoying, blocking some users, blocking an upgrade or blocking your usage of Metabase entirely?

Very annoying as we have to manually update this and all of the other saml properties configured via env vars in order to save the config.

**Additional context**
Add any other context about the problem here.

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.209-198.858.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""googleanalytics"",
      ""bigquery-cloud-sdk"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.4""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v1.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",brandonjfeldkamp,2024-03-24 08:01:50+00:00,[],2024-05-31 17:37:33+00:00,,https://github.com/metabase/metabase/issues/40543,"[('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2203689059,issue,closed,not_planned,url path for get started should be changed ,"### Describe the bug

right now the url path for get started/sign up is this  ""https://store.metabase.com/checkout"" which is confusing as it is not usually used. so if it is changed to /signup 

### To Reproduce

1. Go to https://store.metabase.com
2. Click on get started button
3. check url path
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
chrome version:123.0.6312.58
```


### Severity

low priority issue

### Additional context

_No response_",jeevikasirwani,2024-03-23 04:34:14+00:00,[],2024-03-26 13:16:59+00:00,2024-03-26 13:16:59+00:00,https://github.com/metabase/metabase/issues/40542,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]",[],
2203408998,issue,closed,completed,Creating a new native query inserts 3 newlines in sql editor,"### Describe the bug

Click on ""New > SQL query""

<img width=""262"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/1685149f-5c64-4bd9-824f-05f277184c1e"">

The cursor appears at the top of the text input. Start typing ""select"" and three new lines will be inserted
![image](https://github.com/metabase/metabase/assets/6377293/bb56886b-53e8-474a-b552-835663d557a8)


Seems to only manifest in Firefox and not chrome

### To Reproduce

stated above

### Expected behavior

no unintentional newlines

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

p3

### Additional context

_No response_",dpsutton,2024-03-22 22:20:48+00:00,['romeovs'],2024-10-08 17:04:58+00:00,2024-07-09 06:57:32+00:00,https://github.com/metabase/metabase/issues/40538,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/Native', 'The SQL/native query editor'), ('.Team/Querying', '')]","[{'comment_id': 2208809256, 'issue_id': 2203408998, 'author': 'romeovs', 'body': 'This was caused by the [upgrade to react 18](https://github.com/metabase/metabase/pull/41975), good thing the [fix was easy](https://github.com/metabase/metabase/pull/45129).', 'created_at': datetime.datetime(2024, 7, 4, 12, 10, 11, tzinfo=datetime.timezone.utc)}]","romeovs (Assginee) on (2024-07-04 12:10:11 UTC): This was caused by the [upgrade to react 18](https://github.com/metabase/metabase/pull/41975), good thing the [fix was easy](https://github.com/metabase/metabase/pull/45129).

"
2203195176,issue,closed,completed,[dc.js migration] tooltip double renders on hover,"
https://github.com/metabase/metabase/assets/22608765/bf848bd6-bb1c-4f1e-884f-486d7f7eb459

",JesseSDevaney,2024-03-22 19:42:24+00:00,['alxnddr'],2024-04-15 15:34:33+00:00,2024-04-15 15:34:33+00:00,https://github.com/metabase/metabase/issues/40532,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2015928616, 'issue_id': 2203195176, 'author': 'JesseSDevaney', 'body': 'Attempted this, but could not find a solution in a reasonable time.\r\n\r\n---\r\n**To summarize:**\r\n\r\nWhen hovering over the outer edge of a point, it sometimes makes the `target` of the event, the series line instead of the data point even though it is still passing the data of the point itself. \r\n\r\nThis causes the tooltip to be rendered on top of the box containing the series line instead of the data point itself. \r\n\r\nIf you then move closer to the data point, it will re-render on top of the data point because the new target is now the data point itself.', 'created_at': datetime.datetime(2024, 3, 22, 21, 9, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2018278617, 'issue_id': 2203195176, 'author': 'EmmadUsmani', 'body': '@alxnddr Fixed this once before https://github.com/metabase/metabase/issues/39408', 'created_at': datetime.datetime(2024, 3, 25, 15, 28, 24, tzinfo=datetime.timezone.utc)}]","JesseSDevaney (Issue Creator) on (2024-03-22 21:09:37 UTC): Attempted this, but could not find a solution in a reasonable time.

---
**To summarize:**

When hovering over the outer edge of a point, it sometimes makes the `target` of the event, the series line instead of the data point even though it is still passing the data of the point itself. 

This causes the tooltip to be rendered on top of the box containing the series line instead of the data point itself. 

If you then move closer to the data point, it will re-render on top of the data point because the new target is now the data point itself.

EmmadUsmani on (2024-03-25 15:28:24 UTC): @alxnddr Fixed this once before https://github.com/metabase/metabase/issues/39408

"
2203146681,issue,closed,completed,[dc.js migration] toggling show values on data points causes significant decrease in performance,"https://github.com/metabase/metabase/assets/22608765/b4acb43b-d8eb-44ab-b510-f28a133cdc12

The larger a dataset is the greater the performance impact",JesseSDevaney,2024-03-22 19:08:46+00:00,['JesseSDevaney'],2024-03-22 19:36:42+00:00,2024-03-22 19:36:42+00:00,https://github.com/metabase/metabase/issues/40529,"[('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2202898041,issue,closed,completed,Increase rate limit of actions from 1 to 10 per second ,"**Is your feature request related to a problem? Please describe.**
A customer mentioned that 1 second was too little time, as they have several users (more than 20) at the same time loading data instead of using other tools like Excel.

**Describe the solution you'd like**
Increase the rate limit of actions from 1 to 10 requests per second 

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
N/A

**Additional context**
[Thread](https://metaboat.slack.com/archives/C05MPF0TM3L/p1706042975259839)
",ignacio-mb,2024-03-22 16:42:12+00:00,[],2024-03-25 13:00:20+00:00,2024-03-25 12:03:16+00:00,https://github.com/metabase/metabase/issues/40527,"[('Type:New Feature', ''), ('Querying/Actions', ''), ('.Team/Workflows', 'aka BEC')]",[],
2202890328,issue,closed,not_planned,Wrong record opens while clicking on Detail View in a model's results,"### Describe the bug

I have a model built on SQL question to Clickhouse:
```
SELECT
    click_id,
    click.created AS created,
    publisher_id,
    ad_space_id,
    ad_space.tld    AS ad_space_url,
    affiliate_id    AS provider_id,
    network.name    AS provider_name,
    merchant_id,
    program_id,
    marketing_id,
    origin_referer,
    cutToFirstSignificantSubdomain(origin_referer)          AS origin_referer_domain,
    replacement_referer,
    cutToFirstSignificantSubdomain(replacement_referer)     AS replacement_referer_domain,
    is_js_redirect,
    if(is_js_redirect = 1, 302, 301)                        AS redirect_type,
    cutToFirstSignificantSubdomain(outgoing_get_param_ref)   AS outgoing_get_param_ref_domain,
    click.url   AS url,
    redirect_url,
    missing_affiliation,
    click.product_id AS product_id,
    device,
    user_referer,
    cutToFirstSignificantSubdomain(user_referer)                AS user_referer_domain,
    user_ip_region,
    country_code,
    coupon_id,
    domain_tracker,
    erid,
    is_ab_test,
    panel_hash,
    missing_target_url
FROM stg_click AS click
    LEFT JOIN avw_network_actual AS network ON click.affiliate_id = network.id
    LEFT JOIN avw_domain_actual AS ad_space ON click.ad_space_id = ad_space.id
SETTINGS final = 1
```
I open results of model and click on Detail View of one of the records. Please pay attention to its ID:
<img width=""715"" alt=""Screenshot at Mar 22 20-28-19"" src=""https://github.com/metabase/metabase/assets/74110979/2cb5ff5e-3250-4e08-881c-0af1aec876a5"">

Then I see the popup with details, but these details are from ANOTHER record. Look at the ID:
<img width=""717"" alt=""Screenshot at Mar 22 20-27-46"" src=""https://github.com/metabase/metabase/assets/74110979/e442206c-a0f1-4cb6-a977-30092ac586bd"">

We already have several cases when these wrong details confused us in our decisions.


### To Reproduce

1. Go to `+ New` -> `Model`.
2. Add SQL query.
3. Save the model.
4. Open its results.
5. Click on Detail View.


### Expected behavior

I expected to see details of selected record, not another one's.

### Logs

```
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:32+04:00 DEBUG metabase.server.middleware.log POST /api/dashboard/156/dashcard/1586/card/1776/query 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 4,5 s (15 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 3 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 1/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:32+04:00 DEBUG metabase.server.middleware.log POST /api/dashboard/156/dashcard/1578/card/1770/query 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 4,8 s (15 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 2 / 50 (5 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 2 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 3/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:33+04:00 DEBUG metabase.server.middleware.log POST /api/dashboard/156/dashcard/1577/card/1768/query 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 5,9 s (15 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 1 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 2/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:33+04:00 DEBUG metabase.server.middleware.log POST /api/dashboard/156/dashcard/1587/card/1777/query 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 6,0 s (15 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 2 / 50 (5 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 4/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:39+04:00 INFO metabase.api.dataset –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ - –∫–∞—Ä—Ç–æ—á–∫–∞ 1765
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:39+04:00 WARN metabase.query-processor.middleware.fix-bad-references –ü–ª–æ—Ö–æ–π :field clause [:field 61258 {:base-type :type/Date, :temporal-unit :day}] –¥–ª—è –ø–æ–ª—è ""avw_click_hist.created"" –≤ [:filter :and :=]: –∫–ª–∞—É–∑–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å :join-alias. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ. –ó–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ —Ç–∞–∫, –∫–∞–∫ –æ–∂–∏–¥–∞–ª–æ—Å—å.
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:08:40+04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 1,4 s (12 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 2 / 50 (5 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 0/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:00+04:00 DEBUG metabase.server.middleware.log GET /api/timeline 200 9,0 ms (4 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (5 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/database/14/schemas 200 34,7 ms (4 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (3 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/table/card__1765/query_metadata 200 41,1 ms (10 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/table/3560/query_metadata 200 75,1 ms (11 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 3 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 7 / 50 (1 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/table/3963/query_metadata 200 82,8 ms (11 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 3 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 7 / 50 (1 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/table/3570/query_metadata 200 80,5 ms (9 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 3 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 7 / 50 (1 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/table/3581/query_metadata 200 91,3 ms (9 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 7 / 50 (1 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (152 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/table/3564/query_metadata 200 102,7 ms (11 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (6 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (154 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/card/1765 200 42,8 ms (14 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (154 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 INFO metabase.api.dataset –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ - –∫–∞—Ä—Ç–æ—á–∫–∞ 1765
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 WARN metabase.query-processor.middleware.fix-bad-references –ü–ª–æ—Ö–æ–π :field clause [:field 61258 {:base-type :type/Date, :temporal-unit :day}] –¥–ª—è –ø–æ–ª—è ""avw_click_hist.created"" –≤ [:filter :and :=]: –∫–ª–∞—É–∑–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å :join-alias. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ. –ó–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ —Ç–∞–∫, –∫–∞–∫ –æ–∂–∏–¥–∞–ª–æ—Å—å.
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:01+04:00 DEBUG metabase.server.middleware.log GET /api/collection/321 200 12,2 ms (5 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (154 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 1 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:02+04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 1,1 s (12 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (154 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 0/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:03+04:00 DEBUG metabase.server.middleware.log GET /api/database/14 200 4,7 ms (3 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (154 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:09+04:00 DEBUG metabase.server.middleware.log GET /api/action 200 17,9 ms (4 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (154 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/alert/question/1765 200 1,5 ms (1 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/field/54347 200 16,4 ms (7 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 4 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 7 / 50 (3 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/field/54185 200 22,7 ms (7 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 6 / 50 (3 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/field/58870 200 37,5 ms (7 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 6 / 50 (3 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/field/54004 200 35,8 ms (7 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (5 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/field/53943 200 27,8 ms (7 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 6 / 50 (3 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 DEBUG metabase.server.middleware.log GET /api/collection/230 200 8,3 ms (4 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:44+04:00 INFO metabase.api.dataset –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ - –∫–∞—Ä—Ç–æ—á–∫–∞ 1765
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:47+04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 2,3 s (11 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 2 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 0/5 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T20:09:53+04:00 DEBUG metabase.server.middleware.log GET /api/action 200 8,9 ms (4 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (7 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (151 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""ru-RU"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-28-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""clickhouse"",
      ""h2"",
      ""bigquery-cloud-sdk"",
      ""googleanalytics""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.4 (Debian 11.4-1.pgdg90+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",tritatuy,2024-03-22 16:38:54+00:00,[],2024-04-03 21:40:23+00:00,2024-03-22 16:44:27+00:00,https://github.com/metabase/metabase/issues/40526,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2015488411, 'issue_id': 2202890328, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/39477', 'created_at': datetime.datetime(2024, 3, 22, 16, 44, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030021412, 'issue_id': 2202890328, 'author': 'uladzimirdev', 'body': ""~@paoliniluis did you link the correct issue? I don't see how they are related~\r\n\r\nupd, it's a dup indeed"", 'created_at': datetime.datetime(2024, 4, 1, 15, 43, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2035648518, 'issue_id': 2202890328, 'author': 'uladzimirdev', 'body': 'Actually we have another issue for models, so it‚Äôs still a duplicate, but of the different issue', 'created_at': datetime.datetime(2024, 4, 3, 21, 40, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-22 16:44:27 UTC): duplicate of https://github.com/metabase/metabase/issues/39477

uladzimirdev on (2024-04-01 15:43:15 UTC): ~@paoliniluis did you link the correct issue? I don't see how they are related~

upd, it's a dup indeed

uladzimirdev on (2024-04-03 21:40:23 UTC): Actually we have another issue for models, so it‚Äôs still a duplicate, but of the different issue

"
2202865244,issue,open,,Implement the icon wrapper component using Mantine,"We have way too many ways to style a component that should simply be an icon wrapper.

![image](https://github.com/metabase/metabase/assets/31325167/d0629875-54e6-411b-bb2a-fc8459774e43)

To name just a few:
- https://github.com/metabase/metabase/blob/b4fa0de/frontend/src/metabase/components/IconWrapper/IconWrapper.jsx
- https://github.com/metabase/metabase/blob/b4fa0de3c074e7b65f4b80f9d4698920afa7568d/frontend/src/metabase/components/IconButtonWrapper/IconButtonWrapper.tsx
- https://github.com/metabase/metabase/blob/b4fa0de3c074e7b65f4b80f9d4698920afa7568d/frontend/src/metabase/search/components/SearchResult/components/ItemIcon.styled.tsx#L22
- https://github.com/metabase/metabase/blob/b4fa0de3c074e7b65f4b80f9d4698920afa7568d/frontend/src/metabase/nav/components/StoreLink/StoreLink.styled.tsx#L12
- https://github.com/metabase/metabase/blob/b4fa0de3c074e7b65f4b80f9d4698920afa7568d/frontend/src/metabase/query_builder/components/view/ViewHeader/ViewHeader.styled.tsx#L193

## Task
Find a suitable Mantine component that would be a good candidate for this role, adjust it to our needs, export it and bring unified approach and harmony to our many icon states. The choice will most likely be between:
1. https://v6.mantine.dev/core/unstyled-button/
2. https://v6.mantine.dev/core/action-icon/",nemanjaglumac,2024-03-22 16:24:19+00:00,['nemanjaglumac'],2024-03-27 11:11:02+00:00,,https://github.com/metabase/metabase/issues/40523,"[('.Design Needed', ''), ('.Frontend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('good first issue', 'A starter issue that is good for someone new to the codebase or is a new contributor')]",[],
2202847637,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/cursor.module.css`,,oisincoveney,2024-03-22 16:14:16+00:00,['oisincoveney'],2024-04-17 06:33:20+00:00,2024-04-17 06:33:20+00:00,https://github.com/metabase/metabase/issues/40521,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2202817482,issue,open,,Can't open Detail View in question based on model with composite primary keys from Clickhouse,"### Describe the bug

I have a model built on SQL query to Clickhouse's system table `system.query_log`. The query is:
```
SELECT event_time,
       initial_user,
       type,
       read_bytes / 1000000 AS read_mbytes,
       result_bytes / 1000000 AS result_mbytes,
       query_duration_ms / 60000 AS query_duration_min,
       memory_usage / 1000000 AS memory_usage_mbytes,
       ProfileEvents.Values[indexOf(ProfileEvents.Names, 'UserTimeMicroseconds')] / 1000 / 1000 AS CPU_load,
       read_rows,
       result_rows,
       written_rows,
       written_bytes / 1000000 AS written_mbytes,
       toString(normalized_query_hash) AS normalized_query_hash,
       query_id,
       initial_query_id,
       query,
       query_start_time,
       hostName() AS host_name,
       current_database,
       query_kind,
       arrayStringConcat(databases, ', ') AS databases,
       arrayStringConcat(tables, ', ') AS tables,
       arrayStringConcat(views, ', ') AS views,
       exception_code,
       exception,
       is_initial_query,
       user,
       initial_query_start_time,
       interface,
       is_secure,
       client_hostname,
       client_name,
       quota_key,
       Settings,
       arrayStringConcat(used_aggregate_functions, ', ') AS used_aggregate_functions,
       arrayStringConcat(used_aggregate_function_combinators, ', ') AS used_aggregate_function_combinators,
       arrayStringConcat(used_database_engines, ', ') AS used_database_engines,
       arrayStringConcat(used_data_type_families, ', ') AS used_data_type_families,
       arrayStringConcat(used_dictionaries, ', ') AS used_dictionaries,
       arrayStringConcat(used_formats, ', ') AS used_formats,
       arrayStringConcat(used_functions, ', ') AS used_functions,
       arrayStringConcat(used_storages, ', ') AS used_storages,
       arrayStringConcat(used_table_functions, ', ') AS used_table_functions,
       arrayStringConcat(used_row_policies, ', ') AS used_row_policies,
       query_cache_usage,
       toUnixTimestamp(event_time) AS event_timestamp
FROM clusterAllReplicas('clickhouse_cluster', system.query_log)
WHERE event_date > today() - 7
ORDER BY event_time ASC
```
When I'm opening the results and trying to press Detail View I see nothing but exclamation mark:
<img width=""718"" alt=""Screenshot at Mar 22 19-44-23"" src=""https://github.com/metabase/metabase/assets/74110979/225120b4-2324-45bf-92f7-1f4dae764020"">

The same situation is happen when I'm trying to create a question to this model.
It works ok with other Clickhouse's models I've done. But this one doesn't work even after updating from 0.47 to 0.49.1.


### To Reproduce

1. Click on `+ New` -> `Model` 
2. Past my SQL query to the model builder
3. Save the model.
4. Open the model's results.
5. Press `Detail View`


### Expected behavior

I expect to see the popup with values of all fields.

### Logs

```
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:00+04:00 INFO metabase.task.sync-databases Starting sync task for Database 26.
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:00+04:00 DEBUG metabase.server.middleware.log GET /api/setup/admin_checklist 200 26,3 ms (9 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 3 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 5 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (142 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:00+04:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 24,4 ms (6 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 5 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (143 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:00+04:00 DEBUG metabase.server.middleware.log GET /api/setting 200 75,6 ms (13 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (145 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:07+04:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 13,4 ms (1 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (145 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:10+04:00 ERROR metabase.driver.util Failed to connect to Database,java.util.concurrent.TimeoutException: –¢–∞–π–º-–∞—É—Ç –ø–æ—Å–ª–µ 10,0 s,	at metabase.util.jvm$deref_with_timeout.invokeStatic(jvm.clj:287),	at metabase.util.jvm$deref_with_timeout.invoke(jvm.clj:279),	at metabase.util.jvm$do_with_timeout.invokeStatic(jvm.clj:294),	at metabase.util.jvm$do_with_timeout.invoke(jvm.clj:290),	at metabase.driver.util$can_connect_with_details_QMARK_.invokeStatic(util.clj:147),	at metabase.driver.util$can_connect_with_details_QMARK_.doInvoke(util.clj:136),	at clojure.lang.RestFn.invoke(RestFn.java:442),	at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_$fn__106132$fn__106133.invoke(sync_databases.clj:87),	at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_$fn__106132.invoke(sync_databases.clj:86),	at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invokeStatic(sync_databases.clj:83),	at metabase.task.sync_databases$sync_and_analyze_database_STAR__BANG_.invoke(sync_databases.clj:76),	at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invokeStatic(sync_databases.clj:112),	at metabase.task.sync_databases$sync_and_analyze_database_BANG_.invoke(sync_databases.clj:100),	at metabase.task.sync_databases.SyncAndAnalyzeDatabase.execute(sync_databases.clj:117),	at org.quartz.core.JobRunShell.run(JobRunShell.java:202),	at org.quartz.simpl.SimpleThreadPool$WorkerThread.run(SimpleThreadPool.java:573)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:33+04:00 DEBUG metabase.server.middleware.log GET /api/activity/recent_views 200 27,0 ms (7 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (145 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:34+04:00 DEBUG metabase.server.middleware.log GET /api/activity/popular_items 200 881,1 ms (10 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (3 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (145 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:35+04:00 DEBUG metabase.server.middleware.log GET /api/alert/question/1726 200 1,5 ms (1 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (145 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:35+04:00 INFO metabase.api.dataset –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ - –∫–∞—Ä—Ç–æ—á–∫–∞ 1726
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:40+04:00 DEBUG metabase.server.middleware.log POST /api/dataset 202 [–ê–°–ò–ù–•–†–û–ù–ù–´–ô: completed] 4,2 s (11 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 3 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 2 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (146 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 1 (0 –≤ –æ—á–µ—Ä–µ–¥–∏); clickhouse DB 14 connections: 0/1 (0 threads blocked)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:48+04:00 DEBUG metabase.server.middleware.log GET /api/setup/admin_checklist 200 23,4 ms (9 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 5 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (146 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:48+04:00 DEBUG metabase.server.middleware.log GET /api/session/properties 200 39,1 ms (6 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 2 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (146 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:48+04:00 DEBUG metabase.server.middleware.log GET /api/setting 200 39,5 ms (12 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 4 / 50 (2 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (146 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
[f0714a4d-4c0a-41b6-82e0-34d2eba378e0] 2024-03-22T19:54:50+04:00 DEBUG metabase.server.middleware.log GET /api/util/bug_report_details 200 8,2 ms (1 –≤—ã–∑–æ–≤—ã –ë–î) –°–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –ë–î –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: 1 / 10 –ü–æ—Ç–æ–∫–∏ Jetty: 3 / 50 (4 –±–µ–∑–¥–µ–π—Å—Ç–≤—É–µ—Ç, 0 –≤ –æ—á–µ—Ä–µ–¥–∏) (146 –≤—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ç–µ–º) –ó–∞–ø—Ä–æ—Å—ã –≤ –ø–æ–ª–µ—Ç–µ: 0 (0 –≤ –æ—á–µ—Ä–µ–¥–∏)
```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""ru-RU"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.0-28-amd64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""clickhouse"",
      ""h2"",
      ""bigquery-cloud-sdk"",
      ""googleanalytics""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.4 (Debian 11.4-1.pgdg90+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",tritatuy,2024-03-22 15:59:11+00:00,[],2025-02-04 20:31:34+00:00,,https://github.com/metabase/metabase/issues/40520,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Unable to Reproduce', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Visualization/Detail', 'ObjectDetail'), ('.Team/Querying', '')]","[{'comment_id': 2027128944, 'issue_id': 2202817482, 'author': 'paoliniluis', 'body': ""can you check the browser logs? I need to see the browser console to see what's the error"", 'created_at': datetime.datetime(2024, 3, 29, 11, 46, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2034494991, 'issue_id': 2202817482, 'author': 'tritatuy', 'body': '> can you check the browser logs? I need to see the browser console to see what\'s the error\r\n\r\nHi! Here are the logs from opening model and then clicking on Detail View:\r\n```\r\nanalytics.js:24 Refused to load the script \'https://www.googletagmanager.com/gtag/js?id=G-29NY6M1W10&cx=c&_slc=1\' because it violates the following Content Security Policy directive: ""script-src \'self\' \'unsafe-eval\' https://maps.google.com https://accounts.google.com https://www.google-analytics.com   \'sha256-K2AkR/jTLsGV8PyzWha7/ey1iaD9c5jWRYwa++ZlMZc=\' \'sha256-ib2/2v5zC6gGM6Ety7iYgBUvpy/caRX9xV/pzzV7hf0=\' \'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE=\'"". Note that \'script-src-elem\' was not explicitly set, so \'script-src\' is used as a fallback.\r\n\r\nId @ analytics.js:24\r\n(anonymous) @ analytics.js:75\r\noc @ analytics.js:37\r\nEa @ analytics.js:36\r\ng.onreadystatechange @ analytics.js:35\r\nXMLHttpRequest.send (async)\r\nwd @ analytics.js:36\r\npe @ analytics.js:35\r\nSa @ analytics.js:41\r\nHa.D @ analytics.js:38\r\npc.send @ analytics.js:77\r\nX.b.<computed> @ analytics.js:57\r\nZ.v @ analytics.js:93\r\nZ.D @ analytics.js:92\r\nN @ analytics.js:94\r\np @ analytics.js:66\r\nc @ analytics.js:25\r\n(anonymous) @ routes.jsx:123\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nhVt @ route-guards.jsx:76\r\na @ routes.jsx:121\r\nPromise.then (async)\r\nhVt @ route-guards.jsx:76\r\na @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\no @ TransitionUtils.js:43\r\n(anonymous) @ TransitionUtils.js:114\r\n(anonymous) @ TransitionUtils.js:84\r\nl @ AsyncUtils.js:34\r\ng @ AsyncUtils.js:51\r\nr @ TransitionUtils.js:83\r\nrunEnterHooks @ TransitionUtils.js:107\r\n(anonymous) @ createTransitionManager.js:70\r\nr @ TransitionUtils.js:74\r\nrunChangeHooks @ TransitionUtils.js:131\r\nl @ createTransitionManager.js:67\r\n(anonymous) @ createTransitionManager.js:45\r\nl @ AsyncUtils.js:41\r\ng @ AsyncUtils.js:51\r\nN @ matchRoutes.js:231\r\nc @ createTransitionManager.js:41\r\nr @ createTransitionManager.js:222\r\nlisten @ createTransitionManager.js:246\r\ncomponentWillMount @ Router.js:102\r\nSo @ react-dom.production.min.js:137\r\nUa @ react-dom.production.min.js:176\r\nxs @ react-dom.production.min.js:263\r\nSc @ react-dom.production.min.js:246\r\n_c @ react-dom.production.min.js:246\r\ngc @ react-dom.production.min.js:239\r\ndc @ react-dom.production.min.js:230\r\nel @ react-dom.production.min.js:281\r\n(anonymous) @ react-dom.production.min.js:284\r\nMc @ react-dom.production.min.js:240\r\nal @ react-dom.production.min.js:284\r\nt.render @ react-dom.production.min.js:290\r\nYI @ app.js:73\r\n(anonymous) @ app.js:106\r\nShow 34 more frames\r\nShow less\r\nThird-party cookie will be blocked. Learn more in the Issues tab.\r\nThird-party cookie will be blocked. Learn more in the Issues tab.\r\nThird-party cookie will be blocked. Learn more in the Issues tab.\r\nThird-party cookie will be blocked. Learn more in the Issues tab.\r\nThird-party cookie will be blocked. Learn more in the Issues tab.\r\nThird-party cookie will be blocked. Learn more in the Issues tab.\r\nStructuredQuery.ts:368 Warning: can\'t clean query without metadata!\r\nvalue @ StructuredQuery.ts:368\r\nvalue @ Question.ts:1143\r\nf @ urls.ts:42\r\nk @ questions.ts:106\r\n(anonymous) @ NewItemMenu.tsx:79\r\nya @ react-dom.production.min.js:162\r\nt.useMemo @ react.production.min.js:25\r\n$i @ NewItemMenu.tsx:72\r\nta @ react-dom.production.min.js:153\r\nja @ react-dom.production.min.js:175\r\nxs @ react-dom.production.min.js:263\r\nSc @ react-dom.production.min.js:246\r\n_c @ react-dom.production.min.js:246\r\ngc @ react-dom.production.min.js:239\r\n(anonymous) @ react-dom.production.min.js:123\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nJi @ react-dom.production.min.js:123\r\nZi @ react-dom.production.min.js:122\r\nmc @ react-dom.production.min.js:240\r\nnotify @ Subscription.js:16\r\nnotifyNestedSubs @ Subscription.js:88\r\ni @ Subscription.js:93\r\ng @ redux.js:296\r\n(anonymous) @ middleware.js:22\r\n(anonymous) @ index.js:28\r\n(anonymous) @ index.js:20\r\ndispatch @ redux.js:691\r\n(anonymous) @ utils.js:200\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nm @ promise.ts:61\r\na @ promise.ts:61\r\nPromise.then (async)\r\nm @ promise.ts:61\r\na @ promise.ts:61\r\n(anonymous) @ promise.ts:61\r\n(anonymous) @ promise.ts:61\r\n(anonymous) @ utils.js:196\r\n(anonymous) @ index.js:16\r\n(anonymous) @ redux.js:578\r\n(anonymous) @ EntityListLoader.jsx:111\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nC @ PaginationState.jsx:8\r\na @ EntityListLoader.jsx:107\r\n(anonymous) @ EntityListLoader.jsx:107\r\n(anonymous) @ EntityListLoader.jsx:107\r\n(anonymous) @ EntityListLoader.jsx:106\r\nvalue @ EntityListLoader.jsx:130\r\nhs @ react-dom.production.min.js:212\r\nkc @ react-dom.production.min.js:255\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nRc @ react-dom.production.min.js:248\r\ngc @ react-dom.production.min.js:239\r\n(anonymous) @ react-dom.production.min.js:123\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nJi @ react-dom.production.min.js:123\r\nZi @ react-dom.production.min.js:122\r\ndc @ react-dom.production.min.js:230\r\nenqueueSetState @ react-dom.production.min.js:132\r\ny.setState @ react.production.min.js:12\r\n(anonymous) @ Router.js:109\r\n(anonymous) @ createTransitionManager.js:228\r\n(anonymous) @ createTransitionManager.js:83\r\n(anonymous) @ AsyncUtils.js:74\r\n(anonymous) @ AsyncUtils.js:80\r\n(anonymous) @ getComponents.js:6\r\n(anonymous) @ getComponents.js:30\r\n(anonymous) @ AsyncUtils.js:79\r\nm @ AsyncUtils.js:78\r\nx @ getComponents.js:29\r\nu @ createTransitionManager.js:77\r\nl @ AsyncUtils.js:47\r\n(anonymous) @ TransitionUtils.js:88\r\n(anonymous) @ TransitionUtils.js:110\r\n(anonymous) @ routes.jsx:124\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nhVt @ route-guards.jsx:76\r\na @ routes.jsx:121\r\nPromise.then (async)\r\nhVt @ route-guards.jsx:76\r\na @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\no @ TransitionUtils.js:43\r\n(anonymous) @ TransitionUtils.js:114\r\n(anonymous) @ TransitionUtils.js:84\r\nl @ AsyncUtils.js:34\r\ng @ AsyncUtils.js:51\r\nr @ TransitionUtils.js:83\r\nrunEnterHooks @ TransitionUtils.js:107\r\n(anonymous) @ createTransitionManager.js:70\r\nr @ TransitionUtils.js:74\r\nrunChangeHooks @ TransitionUtils.js:131\r\nl @ createTransitionManager.js:67\r\n(anonymous) @ createTransitionManager.js:45\r\nl @ AsyncUtils.js:41\r\ng @ AsyncUtils.js:51\r\nN @ matchRoutes.js:231\r\nc @ createTransitionManager.js:41\r\nr @ createTransitionManager.js:222\r\nlisten @ createTransitionManager.js:246\r\ncomponentWillMount @ Router.js:102\r\nSo @ react-dom.production.min.js:137\r\nUa @ react-dom.production.min.js:176\r\nxs @ react-dom.production.min.js:263\r\nSc @ react-dom.production.min.js:246\r\n_c @ react-dom.production.min.js:246\r\ngc @ react-dom.production.min.js:239\r\ndc @ react-dom.production.min.js:230\r\nel @ react-dom.production.min.js:281\r\n(anonymous) @ react-dom.production.min.js:284\r\nMc @ react-dom.production.min.js:240\r\nal @ react-dom.production.min.js:284\r\nt.render @ react-dom.production.min.js:290\r\nYI @ app.js:73\r\n(anonymous) @ app.js:106\r\nShow 92 more frames\r\nShow less\r\nmetadata.js:333 loadMetadataForQueries: type question not implemented\r\n(anonymous) @ metadata.js:333\r\nQt @ map.js:13\r\nPn.ue.<computed> @ mixin.js:14\r\n(anonymous) @ metadata.js:321\r\n(anonymous) @ index.js:16\r\ndispatch @ redux.js:691\r\n(anonymous) @ actions.ts:22\r\n(anonymous) @ index.js:16\r\ndispatch @ redux.js:691\r\n(anonymous) @ initializeQB.ts:303\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\ncr @ parameterUtils.ts:104\r\na @ parameterUtils.ts:104\r\nPromise.then (async)\r\ncr @ parameterUtils.ts:104\r\na @ parameterUtils.ts:104\r\n(anonymous) @ parameterUtils.ts:104\r\n(anonymous) @ parameterUtils.ts:104\r\nkr @ initializeQB.ts:237\r\nSr @ initializeQB.ts:237\r\n(anonymous) @ initializeQB.ts:374\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\ncr @ parameterUtils.ts:104\r\na @ parameterUtils.ts:104\r\n(anonymous) @ parameterUtils.ts:104\r\n(anonymous) @ parameterUtils.ts:104\r\n(anonymous) @ initializeQB.ts:371\r\n(anonymous) @ index.js:16\r\nn.<computed> @ bindActionCreators.js:8\r\n(anonymous) @ QueryBuilder.jsx:293\r\n(anonymous) @ useMount.js:4\r\nds @ react-dom.production.min.js:211\r\nBc @ react-dom.production.min.js:257\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nCc @ react-dom.production.min.js:257\r\ngc @ react-dom.production.min.js:239\r\n(anonymous) @ react-dom.production.min.js:123\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nJi @ react-dom.production.min.js:123\r\nZi @ react-dom.production.min.js:122\r\nmc @ react-dom.production.min.js:240\r\nnotify @ Subscription.js:16\r\nnotifyNestedSubs @ Subscription.js:88\r\ni @ Subscription.js:93\r\ng @ redux.js:296\r\n(anonymous) @ middleware.js:22\r\n(anonymous) @ index.js:28\r\n(anonymous) @ index.js:20\r\ndispatch @ redux.js:691\r\n(anonymous) @ utils.js:238\r\nsetTimeout (async)\r\n(anonymous) @ utils.js:238\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nm @ promise.ts:61\r\na @ promise.ts:61\r\nPromise.then (async)\r\nm @ promise.ts:61\r\na @ promise.ts:61\r\n(anonymous) @ promise.ts:61\r\n(anonymous) @ promise.ts:61\r\n(anonymous) @ utils.js:225\r\n(anonymous) @ utils.js:310\r\n(anonymous) @ utils.js:198\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nm @ promise.ts:61\r\na @ promise.ts:61\r\n(anonymous) @ promise.ts:61\r\n(anonymous) @ promise.ts:61\r\n(anonymous) @ utils.js:196\r\n(anonymous) @ index.js:16\r\n(anonymous) @ redux.js:578\r\n(anonymous) @ EntityListLoader.jsx:111\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nC @ PaginationState.jsx:8\r\na @ EntityListLoader.jsx:107\r\n(anonymous) @ EntityListLoader.jsx:107\r\n(anonymous) @ EntityListLoader.jsx:107\r\n(anonymous) @ EntityListLoader.jsx:106\r\nvalue @ EntityListLoader.jsx:130\r\nhs @ react-dom.production.min.js:212\r\nkc @ react-dom.production.min.js:255\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nRc @ react-dom.production.min.js:248\r\ngc @ react-dom.production.min.js:239\r\n(anonymous) @ react-dom.production.min.js:123\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nJi @ react-dom.production.min.js:123\r\nZi @ react-dom.production.min.js:122\r\ndc @ react-dom.production.min.js:230\r\nenqueueSetState @ react-dom.production.min.js:132\r\ny.setState @ react.production.min.js:12\r\n(anonymous) @ Router.js:109\r\n(anonymous) @ createTransitionManager.js:228\r\n(anonymous) @ createTransitionManager.js:83\r\n(anonymous) @ AsyncUtils.js:74\r\n(anonymous) @ AsyncUtils.js:80\r\n(anonymous) @ getComponents.js:6\r\n(anonymous) @ getComponents.js:30\r\n(anonymous) @ AsyncUtils.js:79\r\nm @ AsyncUtils.js:78\r\nx @ getComponents.js:29\r\nu @ createTransitionManager.js:77\r\nl @ AsyncUtils.js:47\r\n(anonymous) @ TransitionUtils.js:88\r\n(anonymous) @ TransitionUtils.js:110\r\n(anonymous) @ routes.jsx:124\r\nu @ runtime.js:63\r\n(anonymous) @ runtime.js:293\r\n(anonymous) @ runtime.js:118\r\nhVt @ route-guards.jsx:76\r\na @ routes.jsx:121\r\nPromise.then (async)\r\nhVt @ route-guards.jsx:76\r\na @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\n(anonymous) @ routes.jsx:121\r\no @ TransitionUtils.js:43\r\n(anonymous) @ TransitionUtils.js:114\r\n(anonymous) @ TransitionUtils.js:84\r\nl @ AsyncUtils.js:34\r\ng @ AsyncUtils.js:51\r\nr @ TransitionUtils.js:83\r\nrunEnterHooks @ TransitionUtils.js:107\r\n(anonymous) @ createTransitionManager.js:70\r\nr @ TransitionUtils.js:74\r\nrunChangeHooks @ TransitionUtils.js:131\r\nl @ createTransitionManager.js:67\r\n(anonymous) @ createTransitionManager.js:45\r\nl @ AsyncUtils.js:41\r\ng @ AsyncUtils.js:51\r\nN @ matchRoutes.js:231\r\nc @ createTransitionManager.js:41\r\nr @ createTransitionManager.js:222\r\nlisten @ createTransitionManager.js:246\r\ncomponentWillMount @ Router.js:102\r\nSo @ react-dom.production.min.js:137\r\nUa @ react-dom.production.min.js:176\r\nxs @ react-dom.production.min.js:263\r\nSc @ react-dom.production.min.js:246\r\n_c @ react-dom.production.min.js:246\r\ngc @ react-dom.production.min.js:239\r\ndc @ react-dom.production.min.js:230\r\nel @ react-dom.production.min.js:281\r\n(anonymous) @ react-dom.production.min.js:284\r\nMc @ react-dom.production.min.js:240\r\nal @ react-dom.production.min.js:284\r\nt.render @ react-dom.production.min.js:290\r\nYI @ app.js:73\r\n(anonymous) @ app.js:106\r\nShow 108 more frames\r\nShow less\r\nobject-detail.js:27 Error: Minified React error #31; visit https://reactjs.org/docs/error-decoder.html?invariant=31&args[]=object%20with%20keys%20%7Bmax_threads%2C%20connect_timeout_with_failover_secure_ms%2C%20idle_connection_timeout%2C%20s3_min_upload_part_size%2C%20s3_max_single_part_upload_size%2C%20distributed_directory_monitor_batch_inserts%2C%20do_not_merge_across_partitions_select_final%2C%20os_thread_priority%2C%20log_queries%2C%20log_queries_cut_to_length%2C%20distributed_product_mode%2C%20max_concurrent_queries_for_user%2C%20any_join_distinct_right_table_keys%2C%20insert_distributed_sync%2C%20joined_subquery_requires_alias%2C%20max_bytes_before_external_group_by%2C%20max_bytes_before_external_sort%2C%20timeout_before_checking_execution_speed%2C%20join_algorithm%2C%20max_memory_usage%2C%20send_logs_level%2C%20max_partitions_per_insert_block%2C%20allow_drop_detached%2C%20database_atomic_wait_for_drop_and_detach_synchronously%2C%20cast_ipv4_ipv6_default_on_conversion_error%2C%20kafka_disable_num_consumers_limit%2C%20force_remove_data_recursively_on_drop%7D&args[]= for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\r\n    at Ro (react-dom.production.min.js:139:47)\r\n    at react-dom.production.min.js:149:278\r\n    at Na (react-dom.production.min.js:173:103)\r\n    at xs (react-dom.production.min.js:265:156)\r\n    at Sc (react-dom.production.min.js:246:265)\r\n    at _c (react-dom.production.min.js:246:194)\r\n    at gc (react-dom.production.min.js:239:172)\r\n    at react-dom.production.min.js:123:115\r\n    at t.unstable_runWithPriority (scheduler.production.min.js:19:467)\r\n    at Vi (react-dom.production.min.js:122:325)\r\ncs @ react-dom.production.min.js:209\r\nn.payload @ react-dom.production.min.js:227\r\nmo @ react-dom.production.min.js:129\r\nUa @ react-dom.production.min.js:177\r\nxs @ react-dom.production.min.js:263\r\nSc @ react-dom.production.min.js:246\r\n_c @ react-dom.production.min.js:246\r\ngc @ react-dom.production.min.js:239\r\n(anonymous) @ react-dom.production.min.js:123\r\nt.unstable_runWithPriority @ scheduler.production.min.js:19\r\nVi @ react-dom.production.min.js:122\r\nJi @ react-dom.production.min.js:123\r\nZi @ react-dom.production.min.js:122\r\nmc @ react-dom.production.min.js:240\r\nnotify @ Subscription.js:16\r\nnotifyNestedSubs @ Subscription.js:88\r\ni @ Subscription.js:93\r\ng @ redux.js:296\r\n(anonymous) @ middleware.js:22\r\n(anonymous) @ index.js:28\r\n(anonymous) @ index.js:20\r\ndispatch @ redux.js:691\r\n(anonymous) @ object-detail.js:27\r\n(anonymous) @ index.js:16\r\nonZoomRow @ TableInteractive.jsx:82\r\n(anonymous) @ TableInteractive.jsx:486\r\nShow 23 more frames\r\nShow less\r\n```', 'created_at': datetime.datetime(2024, 4, 3, 12, 37, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2034611245, 'issue_id': 2202817482, 'author': 'paoliniluis', 'body': ""Thanks, can you send a screenshot of some sort? I'm not able to see the error ordered"", 'created_at': datetime.datetime(2024, 4, 3, 13, 26, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2039728394, 'issue_id': 2202817482, 'author': 'tritatuy', 'body': 'that\'s how it looks after loading the model:\r\n<img width=""385"" alt=""Screenshot at Apr 05 16-49-56"" src=""https://github.com/metabase/metabase/assets/74110979/7bad094f-7625-48cb-952c-4ad451a22249"">\r\n\r\nand this one after clicking on Detailed View:\r\n<img width=""386"" alt=""Screenshot at Apr 05 16-50-20"" src=""https://github.com/metabase/metabase/assets/74110979/1f8bacca-beb4-4c9d-a4c6-e21295db855a"">', 'created_at': datetime.datetime(2024, 4, 5, 12, 51, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457394126, 'issue_id': 2202817482, 'author': 'kamilmielnik', 'body': ""The important part in logs is this: \n\n```\nobject-detail.js:27 Error: Minified React error #31; visit https://reactjs.org/docs/error-decoder.html?invariant=31&args[]=object%20with%20keys%20%7Bmax_threads%2C%20connect_timeout_with_failover_secure_ms%2C%20idle_connection_timeout%2C%20s3_min_upload_part_size%2C%20s3_max_single_part_upload_size%2C%20distributed_directory_monitor_batch_inserts%2C%20do_not_merge_across_partitions_select_final%2C%20os_thread_priority%2C%20log_queries%2C%20log_queries_cut_to_length%2C%20distributed_product_mode%2C%20max_concurrent_queries_for_user%2C%20any_join_distinct_right_table_keys%2C%20insert_distributed_sync%2C%20joined_subquery_requires_alias%2C%20max_bytes_before_external_group_by%2C%20max_bytes_before_external_sort%2C%20timeout_before_checking_execution_speed%2C%20join_algorithm%2C%20max_memory_usage%2C%20send_logs_level%2C%20max_partitions_per_insert_block%2C%20allow_drop_detached%2C%20database_atomic_wait_for_drop_and_detach_synchronously%2C%20cast_ipv4_ipv6_default_on_conversion_error%2C%20kafka_disable_num_consumers_limit%2C%20force_remove_data_recursively_on_drop%7D&args[]= for the full message or use the non-minified dev environment for full errors and additional helpful warnings.\n```\n\nStacktrace indicates that it happens [when `ZOOM_IN_ROW` action is dispatched](https://github.com/metabase/metabase/blob/92d615073a3ba31710e26be9f2e83141352d1d1c/frontend/src/metabase/query_builder/actions/object-detail.js#L27).\n\nFollowing the link gives us this error:\n```\nObjects are not valid as a React child (found: object with keys {max_threads, connect_timeout_with_failover_secure_ms, idle_connection_timeout, s3_min_upload_part_size, s3_max_single_part_upload_size, distributed_directory_monitor_batch_inserts, do_not_merge_across_partitions_select_final, os_thread_priority, log_queries, log_queries_cut_to_length, distributed_product_mode, max_concurrent_queries_for_user, any_join_distinct_right_table_keys, insert_distributed_sync, joined_subquery_requires_alias, max_bytes_before_external_group_by, max_bytes_before_external_sort, timeout_before_checking_execution_speed, join_algorithm, max_memory_usage, send_logs_level, max_partitions_per_insert_block, allow_drop_detached, database_atomic_wait_for_drop_and_detach_synchronously, cast_ipv4_ipv6_default_on_conversion_error, kafka_disable_num_consumers_limit, force_remove_data_recursively_on_drop}). If you meant to render a collection of children, use an array instead.\n```\n\nInstead of data (text/number) React is given an object to render.\nAttributes of this object indicate that this is some kind of clickhouse settings object (see e.g. [1](https://clickhouse.com/docs/en/operations/settings/query-complexity#settings-max_partitions_per_insert_block), [2](https://clickhouse.com/docs/en/engines/table-engines/integrations/s3#settings)).\nThis makes it look like a BE issue because such object should never reach FE.\n\n----\n\nI failed to reproduce this in `master`.\nI used ClickHouse 24.11.1.942.\nNote: I had to remove `ProfileEvents.Values[indexOf(ProfileEvents.Names, 'UserTimeMicroseconds')] / 1000 / 1000 AS CPU_load,` because it gave me this error: `Code: 44. DB::Exception: Invalid column type for ColumnUnique::insertRangeFrom. Expected String, got LowCardinality(String). (ILLEGAL_COLUMN)`.\nI'll try 0.49 tomorrow."", 'created_at': datetime.datetime(2024, 11, 5, 14, 56, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458950142, 'issue_id': 2202817482, 'author': 'kamilmielnik', 'body': ""> I'll try 0.49 tomorrow.\n\nI can't reproduce the issue in 0.49.1, I tried metabase-clickhouse-driver 1.4.0."", 'created_at': datetime.datetime(2024, 11, 6, 8, 7, 42, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-29 11:46:25 UTC): can you check the browser logs? I need to see the browser console to see what's the error

tritatuy (Issue Creator) on (2024-04-03 12:37:59 UTC): Hi! Here are the logs from opening model and then clicking on Detail View:
```
analytics.js:24 Refused to load the script 'https://www.googletagmanager.com/gtag/js?id=G-29NY6M1W10&cx=c&_slc=1' because it violates the following Content Security Policy directive: ""script-src 'self' 'unsafe-eval' https://maps.google.com https://accounts.google.com https://www.google-analytics.com   'sha256-K2AkR/jTLsGV8PyzWha7/ey1iaD9c5jWRYwa++ZlMZc=' 'sha256-ib2/2v5zC6gGM6Ety7iYgBUvpy/caRX9xV/pzzV7hf0=' 'sha256-isH538cVBUY8IMlGYGbWtBwr+cGqkc4mN6nLcA7lUjE='"". Note that 'script-src-elem' was not explicitly set, so 'script-src' is used as a fallback.

Id @ analytics.js:24
(anonymous) @ analytics.js:75
oc @ analytics.js:37
Ea @ analytics.js:36
g.onreadystatechange @ analytics.js:35
XMLHttpRequest.send (async)
wd @ analytics.js:36
pe @ analytics.js:35
Sa @ analytics.js:41
Ha.D @ analytics.js:38
pc.send @ analytics.js:77
X.b.<computed> @ analytics.js:57
Z.v @ analytics.js:93
Z.D @ analytics.js:92
N @ analytics.js:94
p @ analytics.js:66
c @ analytics.js:25
(anonymous) @ routes.jsx:123
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
hVt @ route-guards.jsx:76
a @ routes.jsx:121
Promise.then (async)
hVt @ route-guards.jsx:76
a @ routes.jsx:121
(anonymous) @ routes.jsx:121
(anonymous) @ routes.jsx:121
(anonymous) @ routes.jsx:121
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
l @ AsyncUtils.js:34
g @ AsyncUtils.js:51
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
l @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
l @ AsyncUtils.js:41
g @ AsyncUtils.js:51
N @ matchRoutes.js:231
c @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
So @ react-dom.production.min.js:137
Ua @ react-dom.production.min.js:176
xs @ react-dom.production.min.js:263
Sc @ react-dom.production.min.js:246
_c @ react-dom.production.min.js:246
gc @ react-dom.production.min.js:239
dc @ react-dom.production.min.js:230
el @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
Mc @ react-dom.production.min.js:240
al @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
YI @ app.js:73
(anonymous) @ app.js:106
Show 34 more frames
Show less
Third-party cookie will be blocked. Learn more in the Issues tab.
Third-party cookie will be blocked. Learn more in the Issues tab.
Third-party cookie will be blocked. Learn more in the Issues tab.
Third-party cookie will be blocked. Learn more in the Issues tab.
Third-party cookie will be blocked. Learn more in the Issues tab.
Third-party cookie will be blocked. Learn more in the Issues tab.
StructuredQuery.ts:368 Warning: can't clean query without metadata!
value @ StructuredQuery.ts:368
value @ Question.ts:1143
f @ urls.ts:42
k @ questions.ts:106
(anonymous) @ NewItemMenu.tsx:79
ya @ react-dom.production.min.js:162
t.useMemo @ react.production.min.js:25
$i @ NewItemMenu.tsx:72
ta @ react-dom.production.min.js:153
ja @ react-dom.production.min.js:175
xs @ react-dom.production.min.js:263
Sc @ react-dom.production.min.js:246
_c @ react-dom.production.min.js:246
gc @ react-dom.production.min.js:239
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Ji @ react-dom.production.min.js:123
Zi @ react-dom.production.min.js:122
mc @ react-dom.production.min.js:240
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
(anonymous) @ utils.js:200
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
m @ promise.ts:61
a @ promise.ts:61
Promise.then (async)
m @ promise.ts:61
a @ promise.ts:61
(anonymous) @ promise.ts:61
(anonymous) @ promise.ts:61
(anonymous) @ utils.js:196
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:111
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
C @ PaginationState.jsx:8
a @ EntityListLoader.jsx:107
(anonymous) @ EntityListLoader.jsx:107
(anonymous) @ EntityListLoader.jsx:107
(anonymous) @ EntityListLoader.jsx:106
value @ EntityListLoader.jsx:130
hs @ react-dom.production.min.js:212
kc @ react-dom.production.min.js:255
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Rc @ react-dom.production.min.js:248
gc @ react-dom.production.min.js:239
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Ji @ react-dom.production.min.js:123
Zi @ react-dom.production.min.js:122
dc @ react-dom.production.min.js:230
enqueueSetState @ react-dom.production.min.js:132
y.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ AsyncUtils.js:80
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:30
(anonymous) @ AsyncUtils.js:79
m @ AsyncUtils.js:78
x @ getComponents.js:29
u @ createTransitionManager.js:77
l @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
(anonymous) @ routes.jsx:124
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
hVt @ route-guards.jsx:76
a @ routes.jsx:121
Promise.then (async)
hVt @ route-guards.jsx:76
a @ routes.jsx:121
(anonymous) @ routes.jsx:121
(anonymous) @ routes.jsx:121
(anonymous) @ routes.jsx:121
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
l @ AsyncUtils.js:34
g @ AsyncUtils.js:51
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
l @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
l @ AsyncUtils.js:41
g @ AsyncUtils.js:51
N @ matchRoutes.js:231
c @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
So @ react-dom.production.min.js:137
Ua @ react-dom.production.min.js:176
xs @ react-dom.production.min.js:263
Sc @ react-dom.production.min.js:246
_c @ react-dom.production.min.js:246
gc @ react-dom.production.min.js:239
dc @ react-dom.production.min.js:230
el @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
Mc @ react-dom.production.min.js:240
al @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
YI @ app.js:73
(anonymous) @ app.js:106
Show 92 more frames
Show less
metadata.js:333 loadMetadataForQueries: type question not implemented
(anonymous) @ metadata.js:333
Qt @ map.js:13
Pn.ue.<computed> @ mixin.js:14
(anonymous) @ metadata.js:321
(anonymous) @ index.js:16
dispatch @ redux.js:691
(anonymous) @ actions.ts:22
(anonymous) @ index.js:16
dispatch @ redux.js:691
(anonymous) @ initializeQB.ts:303
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
cr @ parameterUtils.ts:104
a @ parameterUtils.ts:104
Promise.then (async)
cr @ parameterUtils.ts:104
a @ parameterUtils.ts:104
(anonymous) @ parameterUtils.ts:104
(anonymous) @ parameterUtils.ts:104
kr @ initializeQB.ts:237
Sr @ initializeQB.ts:237
(anonymous) @ initializeQB.ts:374
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
cr @ parameterUtils.ts:104
a @ parameterUtils.ts:104
(anonymous) @ parameterUtils.ts:104
(anonymous) @ parameterUtils.ts:104
(anonymous) @ initializeQB.ts:371
(anonymous) @ index.js:16
n.<computed> @ bindActionCreators.js:8
(anonymous) @ QueryBuilder.jsx:293
(anonymous) @ useMount.js:4
ds @ react-dom.production.min.js:211
Bc @ react-dom.production.min.js:257
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Cc @ react-dom.production.min.js:257
gc @ react-dom.production.min.js:239
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Ji @ react-dom.production.min.js:123
Zi @ react-dom.production.min.js:122
mc @ react-dom.production.min.js:240
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
(anonymous) @ utils.js:238
setTimeout (async)
(anonymous) @ utils.js:238
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
m @ promise.ts:61
a @ promise.ts:61
Promise.then (async)
m @ promise.ts:61
a @ promise.ts:61
(anonymous) @ promise.ts:61
(anonymous) @ promise.ts:61
(anonymous) @ utils.js:225
(anonymous) @ utils.js:310
(anonymous) @ utils.js:198
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
m @ promise.ts:61
a @ promise.ts:61
(anonymous) @ promise.ts:61
(anonymous) @ promise.ts:61
(anonymous) @ utils.js:196
(anonymous) @ index.js:16
(anonymous) @ redux.js:578
(anonymous) @ EntityListLoader.jsx:111
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
C @ PaginationState.jsx:8
a @ EntityListLoader.jsx:107
(anonymous) @ EntityListLoader.jsx:107
(anonymous) @ EntityListLoader.jsx:107
(anonymous) @ EntityListLoader.jsx:106
value @ EntityListLoader.jsx:130
hs @ react-dom.production.min.js:212
kc @ react-dom.production.min.js:255
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Rc @ react-dom.production.min.js:248
gc @ react-dom.production.min.js:239
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Ji @ react-dom.production.min.js:123
Zi @ react-dom.production.min.js:122
dc @ react-dom.production.min.js:230
enqueueSetState @ react-dom.production.min.js:132
y.setState @ react.production.min.js:12
(anonymous) @ Router.js:109
(anonymous) @ createTransitionManager.js:228
(anonymous) @ createTransitionManager.js:83
(anonymous) @ AsyncUtils.js:74
(anonymous) @ AsyncUtils.js:80
(anonymous) @ getComponents.js:6
(anonymous) @ getComponents.js:30
(anonymous) @ AsyncUtils.js:79
m @ AsyncUtils.js:78
x @ getComponents.js:29
u @ createTransitionManager.js:77
l @ AsyncUtils.js:47
(anonymous) @ TransitionUtils.js:88
(anonymous) @ TransitionUtils.js:110
(anonymous) @ routes.jsx:124
u @ runtime.js:63
(anonymous) @ runtime.js:293
(anonymous) @ runtime.js:118
hVt @ route-guards.jsx:76
a @ routes.jsx:121
Promise.then (async)
hVt @ route-guards.jsx:76
a @ routes.jsx:121
(anonymous) @ routes.jsx:121
(anonymous) @ routes.jsx:121
(anonymous) @ routes.jsx:121
o @ TransitionUtils.js:43
(anonymous) @ TransitionUtils.js:114
(anonymous) @ TransitionUtils.js:84
l @ AsyncUtils.js:34
g @ AsyncUtils.js:51
r @ TransitionUtils.js:83
runEnterHooks @ TransitionUtils.js:107
(anonymous) @ createTransitionManager.js:70
r @ TransitionUtils.js:74
runChangeHooks @ TransitionUtils.js:131
l @ createTransitionManager.js:67
(anonymous) @ createTransitionManager.js:45
l @ AsyncUtils.js:41
g @ AsyncUtils.js:51
N @ matchRoutes.js:231
c @ createTransitionManager.js:41
r @ createTransitionManager.js:222
listen @ createTransitionManager.js:246
componentWillMount @ Router.js:102
So @ react-dom.production.min.js:137
Ua @ react-dom.production.min.js:176
xs @ react-dom.production.min.js:263
Sc @ react-dom.production.min.js:246
_c @ react-dom.production.min.js:246
gc @ react-dom.production.min.js:239
dc @ react-dom.production.min.js:230
el @ react-dom.production.min.js:281
(anonymous) @ react-dom.production.min.js:284
Mc @ react-dom.production.min.js:240
al @ react-dom.production.min.js:284
t.render @ react-dom.production.min.js:290
YI @ app.js:73
(anonymous) @ app.js:106
Show 108 more frames
Show less
object-detail.js:27 Error: Minified React error #31; visit https://reactjs.org/docs/error-decoder.html?invariant=31&args[]=object%20with%20keys%20%7Bmax_threads%2C%20connect_timeout_with_failover_secure_ms%2C%20idle_connection_timeout%2C%20s3_min_upload_part_size%2C%20s3_max_single_part_upload_size%2C%20distributed_directory_monitor_batch_inserts%2C%20do_not_merge_across_partitions_select_final%2C%20os_thread_priority%2C%20log_queries%2C%20log_queries_cut_to_length%2C%20distributed_product_mode%2C%20max_concurrent_queries_for_user%2C%20any_join_distinct_right_table_keys%2C%20insert_distributed_sync%2C%20joined_subquery_requires_alias%2C%20max_bytes_before_external_group_by%2C%20max_bytes_before_external_sort%2C%20timeout_before_checking_execution_speed%2C%20join_algorithm%2C%20max_memory_usage%2C%20send_logs_level%2C%20max_partitions_per_insert_block%2C%20allow_drop_detached%2C%20database_atomic_wait_for_drop_and_detach_synchronously%2C%20cast_ipv4_ipv6_default_on_conversion_error%2C%20kafka_disable_num_consumers_limit%2C%20force_remove_data_recursively_on_drop%7D&args[]= for the full message or use the non-minified dev environment for full errors and additional helpful warnings.
    at Ro (react-dom.production.min.js:139:47)
    at react-dom.production.min.js:149:278
    at Na (react-dom.production.min.js:173:103)
    at xs (react-dom.production.min.js:265:156)
    at Sc (react-dom.production.min.js:246:265)
    at _c (react-dom.production.min.js:246:194)
    at gc (react-dom.production.min.js:239:172)
    at react-dom.production.min.js:123:115
    at t.unstable_runWithPriority (scheduler.production.min.js:19:467)
    at Vi (react-dom.production.min.js:122:325)
cs @ react-dom.production.min.js:209
n.payload @ react-dom.production.min.js:227
mo @ react-dom.production.min.js:129
Ua @ react-dom.production.min.js:177
xs @ react-dom.production.min.js:263
Sc @ react-dom.production.min.js:246
_c @ react-dom.production.min.js:246
gc @ react-dom.production.min.js:239
(anonymous) @ react-dom.production.min.js:123
t.unstable_runWithPriority @ scheduler.production.min.js:19
Vi @ react-dom.production.min.js:122
Ji @ react-dom.production.min.js:123
Zi @ react-dom.production.min.js:122
mc @ react-dom.production.min.js:240
notify @ Subscription.js:16
notifyNestedSubs @ Subscription.js:88
i @ Subscription.js:93
g @ redux.js:296
(anonymous) @ middleware.js:22
(anonymous) @ index.js:28
(anonymous) @ index.js:20
dispatch @ redux.js:691
(anonymous) @ object-detail.js:27
(anonymous) @ index.js:16
onZoomRow @ TableInteractive.jsx:82
(anonymous) @ TableInteractive.jsx:486
Show 23 more frames
Show less
```

paoliniluis on (2024-04-03 13:26:41 UTC): Thanks, can you send a screenshot of some sort? I'm not able to see the error ordered

tritatuy (Issue Creator) on (2024-04-05 12:51:50 UTC): that's how it looks after loading the model:
<img width=""385"" alt=""Screenshot at Apr 05 16-49-56"" src=""https://github.com/metabase/metabase/assets/74110979/7bad094f-7625-48cb-952c-4ad451a22249"">

and this one after clicking on Detailed View:
<img width=""386"" alt=""Screenshot at Apr 05 16-50-20"" src=""https://github.com/metabase/metabase/assets/74110979/1f8bacca-beb4-4c9d-a4c6-e21295db855a"">

kamilmielnik on (2024-11-05 14:56:12 UTC): The important part in logs is this: 

```
object-detail.js:27 Error: Minified React error #31; visit https://reactjs.org/docs/error-decoder.html?invariant=31&args[]=object%20with%20keys%20%7Bmax_threads%2C%20connect_timeout_with_failover_secure_ms%2C%20idle_connection_timeout%2C%20s3_min_upload_part_size%2C%20s3_max_single_part_upload_size%2C%20distributed_directory_monitor_batch_inserts%2C%20do_not_merge_across_partitions_select_final%2C%20os_thread_priority%2C%20log_queries%2C%20log_queries_cut_to_length%2C%20distributed_product_mode%2C%20max_concurrent_queries_for_user%2C%20any_join_distinct_right_table_keys%2C%20insert_distributed_sync%2C%20joined_subquery_requires_alias%2C%20max_bytes_before_external_group_by%2C%20max_bytes_before_external_sort%2C%20timeout_before_checking_execution_speed%2C%20join_algorithm%2C%20max_memory_usage%2C%20send_logs_level%2C%20max_partitions_per_insert_block%2C%20allow_drop_detached%2C%20database_atomic_wait_for_drop_and_detach_synchronously%2C%20cast_ipv4_ipv6_default_on_conversion_error%2C%20kafka_disable_num_consumers_limit%2C%20force_remove_data_recursively_on_drop%7D&args[]= for the full message or use the non-minified dev environment for full errors and additional helpful warnings.
```

Stacktrace indicates that it happens [when `ZOOM_IN_ROW` action is dispatched](https://github.com/metabase/metabase/blob/92d615073a3ba31710e26be9f2e83141352d1d1c/frontend/src/metabase/query_builder/actions/object-detail.js#L27).

Following the link gives us this error:
```
Objects are not valid as a React child (found: object with keys {max_threads, connect_timeout_with_failover_secure_ms, idle_connection_timeout, s3_min_upload_part_size, s3_max_single_part_upload_size, distributed_directory_monitor_batch_inserts, do_not_merge_across_partitions_select_final, os_thread_priority, log_queries, log_queries_cut_to_length, distributed_product_mode, max_concurrent_queries_for_user, any_join_distinct_right_table_keys, insert_distributed_sync, joined_subquery_requires_alias, max_bytes_before_external_group_by, max_bytes_before_external_sort, timeout_before_checking_execution_speed, join_algorithm, max_memory_usage, send_logs_level, max_partitions_per_insert_block, allow_drop_detached, database_atomic_wait_for_drop_and_detach_synchronously, cast_ipv4_ipv6_default_on_conversion_error, kafka_disable_num_consumers_limit, force_remove_data_recursively_on_drop}). If you meant to render a collection of children, use an array instead.
```

Instead of data (text/number) React is given an object to render.
Attributes of this object indicate that this is some kind of clickhouse settings object (see e.g. [1](https://clickhouse.com/docs/en/operations/settings/query-complexity#settings-max_partitions_per_insert_block), [2](https://clickhouse.com/docs/en/engines/table-engines/integrations/s3#settings)).
This makes it look like a BE issue because such object should never reach FE.

----

I failed to reproduce this in `master`.
I used ClickHouse 24.11.1.942.
Note: I had to remove `ProfileEvents.Values[indexOf(ProfileEvents.Names, 'UserTimeMicroseconds')] / 1000 / 1000 AS CPU_load,` because it gave me this error: `Code: 44. DB::Exception: Invalid column type for ColumnUnique::insertRangeFrom. Expected String, got LowCardinality(String). (ILLEGAL_COLUMN)`.
I'll try 0.49 tomorrow.

kamilmielnik on (2024-11-06 08:07:42 UTC): I can't reproduce the issue in 0.49.1, I tried metabase-clickhouse-driver 1.4.0.

"
2202771585,issue,closed,completed,"If a user is a member of multiple groups in the IdP, the user property is comma separated and we default to ""all users""","### Describe the bug

When a user belong to more than 1 group, then the user property of group membership is a comma separated value (with a ""/"" also in Keycloak, don't know how it works in other systems). As we seem to compare against exact matches, then the group mapping doesn't work

### To Reproduce

1) set up the keycloak demo
2) create 2 groups in keycloak
3) add a user to 2 groups
4) set up group mapping in the server and then authenticate with the user
5) see that the user was not mapped to any group, but to all users

### Expected behavior

We should add the user to the combination of all the groups that the user is on

### Logs

NA

### Information about your Metabase installation

```JSON
- v49 but pretty sure it has always been like that
```


### Severity

P2, as only 1 user has reported this

### Additional context

NOTE: AFTER WE SHIP THIS WE SHOULD PUT A NOTE IN THE RELEASE NOTES ABOUT THIS, AS I'M AFRAID THAT CUSTOMERS WITH SSO WILL BE IMPACTED OF THE CHANGE",paoliniluis,2024-03-22 15:33:31+00:00,[],2024-04-22 20:18:39+00:00,2024-04-02 16:16:03+00:00,https://github.com/metabase/metabase/issues/40517,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('Administration/Auth/SSO', 'Enterprise SSO like SAML and JWT'), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Release notes mention', 'Ex. breaking changes, removes functionality, changes API, requires 3rd-party driver changes')]","[{'comment_id': 2025159215, 'issue_id': 2202771585, 'author': 'luizarakaki', 'body': ""We spent a long time trying to reproduce this\r\n[Slack thread](https://metaboat.slack.com/archives/C013N8XL286/p1711532641515569)\r\n\r\nUnless there are better reproduction steps, we can't work on it"", 'created_at': datetime.datetime(2024, 3, 28, 13, 14, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2025757417, 'issue_id': 2202771585, 'author': 'jonmauney', 'body': ""üëã hello @luizarakaki!  I'm the person that reported this.  Thanks for looking into it. Are you able to access the Zendesk ticket we have with @Tony-Metabase on the matter? (looks like ticket ID: 25860.) We've got some details about the config in there- it looks to us like we've followed the docs, and the `metabaseGroups` attr on the SAML assertion that is being sent to Metabase appears to be generating a comma-separated list of groups as expected. Finally, we believe we have group mappings set up correctly on the Metabase SAML config side of things.\r\n\r\nWhat we're seeing is that single group coming from Okta is **correctly** assigning the user to the group, but multiple groups end up **unassigning all groups** (other than All Users, of course), leading us to believe that something is malformed / being processed incorrectly.  I certainly won't rule out it's something on our side that is malformed, but it looks correct from what we can see re: [these](https://www.metabase.com/docs/latest/people-and-groups/saml-okta#example-of-mapping-multiple-groups-to-metabase) docs. I looked through logs and it does not appear the SAML assertions are appearing in there; is there any way we can see what Metabase is receiving to validate that the metabaseGroups attr is structured per the documentation?"", 'created_at': datetime.datetime(2024, 3, 28, 17, 31, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026039585, 'issue_id': 2202771585, 'author': 'luizarakaki', 'body': 'My best hypothesis now is that this is Okta-specific.\r\n\r\nWe tried to reproduce this with Keycloak and it worked as expected (multiple group assignment).\r\nMaybe Okta formats the XML differently from Keycloak.\r\n\r\nDoes this SAML assertion contain sensitive data? Can you send it to us? (can send through zendesk)', 'created_at': datetime.datetime(2024, 3, 28, 20, 16, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2029757077, 'issue_id': 2202771585, 'author': 'jonmauney', 'body': 'Thanks @luizarakaki.  The group names are certainly not sensitive; not sure about the rest of the content, but will examine / post in a redacted form if necessary. I\'ll work with my IT team today to see if we can get a dump of the XML for direct testing / examination (I am unfortunately, but appropriately, not an Okta admin in our org!) In the meantime, here are some details that may help (or perhaps uncover obvious mistakes): \r\n\r\nThe metabaseGroups attr is being generated using  Okta Expression Language (it\'s not manually input):\r\n\r\n<img width=""445"" alt=""image"" src=""https://github.com/metabase/metabase/assets/4520575/3d9118d4-610a-48db-8834-63e66ffea52f"">\r\n\r\nThe full metabaseGroups attr (for this user) looks like this:\r\n\r\n```\r\nMetabase - Admins,Metabase - Owners,Metabase - All Users\r\n```\r\n\r\n...and is generated using Okta Expression Language (group IDs redacted and list is shortened):\r\n```\r\ngetFilteredGroups({""groupID1"", ""groupID2"", ""groupID3"", ""groupID4"", ""groupID5""}, ""[group.name]"", 100)\r\n```\r\n\r\nThe groupIDs are resolving to the list above.\r\n\r\nFinally, we have mappings set up in Metabase:\r\n\r\n![image](https://github.com/metabase/metabase/assets/4520575/0a191999-020f-477b-8366-775f90e4cf63)\r\n\r\n\r\nNote that I thought there could have been an issue with symbol conversion with spaces, but renaming the groups to remove spaces did not exhibit different behavior.', 'created_at': datetime.datetime(2024, 4, 1, 13, 25, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030390525, 'issue_id': 2202771585, 'author': 'luizarakaki', 'body': ""Right... Yeah, my first guess would be special characters causing problems. We had issues in the past with some special characters...\r\n\r\nWe are working internally to try to reproduce this using Okta dev tools. You'll be back to you on your ticket"", 'created_at': datetime.datetime(2024, 4, 1, 19, 16, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030426462, 'issue_id': 2202771585, 'author': 'jonmauney', 'body': '@luizarakaki just got a response back from our IT team, it does look like the shape of the attr coming back from Okta differs from what is expected.\r\n\r\nOkta is producing a comma separated string as a single-element attribute: \r\n\r\n```xml\r\n        <saml2:Attribute Name=""metabaseGroups"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:basic"">\r\n            <saml2:AttributeValue\r\n                xmlns:xs=""http://www.w3.org/2001/XMLSchema""\r\n                xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:type=""xs:string"">Metabase - Admins,MetabaseOwners\r\n            </saml2:AttributeValue>\r\n        </saml2:Attribute>\r\n```\r\n\r\nIn the Metabase[ test](https://github.com/metabase/metabase/blob/80e690534a18ffb666124208e215d68b42182bce/test_resources/saml-test-response-new-user-with-groups.xml#L91) for multiple group assignment, it looks like the attr is an array:\r\n```xml\r\n<saml:Attribute Name=""GroupMembership"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:basic"">\r\n        <saml:AttributeValue xsi:type=""xs:anyType"">group_1</saml:AttributeValue>\r\n        <saml:AttributeValue xsi:type=""xs:anyType"">group_2</saml:AttributeValue>\r\n      </saml:Attribute>\r\n```\r\n\r\nI\'m going to see if there is a different data type we can assign in Okta that will unpack that list into an array rather than a comma-separated string.', 'created_at': datetime.datetime(2024, 4, 1, 19, 37, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030486566, 'issue_id': 2202771585, 'author': 'luizarakaki', 'body': ""Thanks, this is useful. I'll ping the team.\r\nLet me know if you can find a way to change this structure in Okta"", 'created_at': datetime.datetime(2024, 4, 1, 20, 16, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030496311, 'issue_id': 2202771585, 'author': 'luizarakaki', 'body': 'Is there are reason to add `[ ]` around group.name?\r\nFrom above:\r\n`getFilteredGroups({""groupID1"", ""groupID2"", ""groupID3"", ""groupID4"", ""groupID5""}, ""[group.name]"", 100)`\r\n\r\nIn the docs it says it returns an array, but it doesn\'t add these []\r\nhttps://developer.okta.com/docs/reference/okta-expression-language/#group-functions', 'created_at': datetime.datetime(2024, 4, 1, 20, 24, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2031867364, 'issue_id': 2202771585, 'author': 'Tony-metabase', 'body': 'Hey @jonmauney,\r\n\r\nActually it does work. I am not sure how you are configuring users ... but let me share with you what i did. First i create a user and assign departments to it (in my case `Metabase-Admin,Metabase-Test`:\r\n\r\n<img width=""1505"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/d39b6897-a14b-4cf7-9e90-209765d79062"">\r\n\r\nthere are also firstName, lastName and email but those you mentioned you already setup but just for consistency these are part of the User Profile:\r\n\r\n<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/75bc0d0a-9d3c-403a-9204-2a60c482640a"">\r\n\r\n\r\nI then proceed to create the application which is that SAML 2.0 that we will connect to Metabase and setup the following attributes the following:\r\n\r\n<img width=""1507"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/9ffe8946-615d-485f-bccb-1872828b150e"">\r\n\r\nNote that department is the User profile attribute in which i am defining the groups. I need to perform an `Arrays.flatten` else metabase thinks its a string and will not understand multiple groups.\r\n\r\ni then setup authentication with SAML and defining the group mappings:\r\n\r\n<img width=""1255"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/492e52c1-2080-44b6-b2ce-56816f5b9457"">\r\n\r\nThen when i login with this user i can see it being added to both groups:\r\n\r\n<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/342e475e-b5ff-4d0a-b252-c0f0710d7142"">\r\n\r\nSo this seems to be a false alarm or maybe the way we are creating users/groups is different?', 'created_at': datetime.datetime(2024, 4, 2, 12, 7, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032071842, 'issue_id': 2202771585, 'author': 'jonmauney', 'body': 'Thanks both @luizarakaki @Tony-metabase! Will get with our IT team today to try this; will get back to you.', 'created_at': datetime.datetime(2024, 4, 2, 13, 38, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032113383, 'issue_id': 2202771585, 'author': 'jonmauney', 'body': ""Unfortunately I can't get time with IT to test until Thursday afternoon.  One thing I found; it's possible there is an undocumented feature flag that is not enabled in our Okta account called `SAML_SUPPORT_ARRAY_ATTRIBUTES`.\r\n\r\nSimilar Okta support tickets are [here](https://support.okta.com/help/s/question/0D54z00007K7QA4CAN/saml-assertion-memberof-format-issue?language=en_US) and [here](https://support.okta.com/help/s/question/0D51Y00009sknKkSAI/same-variable-name-with-multiple-tags?language=en_US), and recognition in third-party guides [here](https://support.cloudinary.com/hc/en-us/articles/4405194731026-SAML-Provisioning-with-Okta-Tips-for-setting-user-attributes#:~:text=SAML_SUPPORT_ARRAY_ATTRIBUTES) and [here](https://github.com/rapid7/awsaml/blob/master/README.md).  We'll assess that alongside trying your suggestions on Thursday."", 'created_at': datetime.datetime(2024, 4, 2, 13, 56, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032233909, 'issue_id': 2202771585, 'author': 'Tony-metabase', 'body': ""I saw that to be honest and it seems that by default okta will enable it ... I didn't reach out to Okta about that just did a quick trial and i am guessing I was using the default"", 'created_at': datetime.datetime(2024, 4, 2, 14, 43, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032451013, 'issue_id': 2202771585, 'author': 'jonmauney', 'body': 'Agreed that it should be the default @Tony-metabase; only thing is that our Okta account is many years old and I could see them not turning on the flag for older accounts if it could change behavior of existing Apps.  Will report back when we sit down to dig in!', 'created_at': datetime.datetime(2024, 4, 2, 16, 0, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032488512, 'issue_id': 2202771585, 'author': 'Tony-metabase', 'body': ""No worries! I will close this issue for now since it seems that it's working but lets keep the thread open on our ticket :) and we can troubleshoot from there!\r\n\r\nWe can open another one which would be more specific for your usecase if that's not the issue"", 'created_at': datetime.datetime(2024, 4, 2, 16, 16, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2059179624, 'issue_id': 2202771585, 'author': 'bc-rp', 'body': 'Hi,\r\n\r\nWe had the same issue and have resolved it as follows:\r\n\r\n1. Have Okta enable the feature flag SAML_SUPPORT_ARRAY_ATTRIBUTES for your tenant\r\n2. Configure the group attribute statement\r\n- Name: MetabaseGroupName\r\n- Name Format: Basic\r\n- Value: Arrays.flatten(getFilteredGroups({""Grp_1"", ""Grp_2"", ""Grp_3""}, ""group.name"", 100))\r\n\r\nWith the above configuration we are now able to have users assigned to multiple groups.', 'created_at': datetime.datetime(2024, 4, 16, 14, 4, 50, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-28 13:14:20 UTC): We spent a long time trying to reproduce this
[Slack thread](https://metaboat.slack.com/archives/C013N8XL286/p1711532641515569)

Unless there are better reproduction steps, we can't work on it

jonmauney on (2024-03-28 17:31:12 UTC): üëã hello @luizarakaki!  I'm the person that reported this.  Thanks for looking into it. Are you able to access the Zendesk ticket we have with @Tony-Metabase on the matter? (looks like ticket ID: 25860.) We've got some details about the config in there- it looks to us like we've followed the docs, and the `metabaseGroups` attr on the SAML assertion that is being sent to Metabase appears to be generating a comma-separated list of groups as expected. Finally, we believe we have group mappings set up correctly on the Metabase SAML config side of things.

What we're seeing is that single group coming from Okta is **correctly** assigning the user to the group, but multiple groups end up **unassigning all groups** (other than All Users, of course), leading us to believe that something is malformed / being processed incorrectly.  I certainly won't rule out it's something on our side that is malformed, but it looks correct from what we can see re: [these](https://www.metabase.com/docs/latest/people-and-groups/saml-okta#example-of-mapping-multiple-groups-to-metabase) docs. I looked through logs and it does not appear the SAML assertions are appearing in there; is there any way we can see what Metabase is receiving to validate that the metabaseGroups attr is structured per the documentation?

luizarakaki on (2024-03-28 20:16:51 UTC): My best hypothesis now is that this is Okta-specific.

We tried to reproduce this with Keycloak and it worked as expected (multiple group assignment).
Maybe Okta formats the XML differently from Keycloak.

Does this SAML assertion contain sensitive data? Can you send it to us? (can send through zendesk)

jonmauney on (2024-04-01 13:25:53 UTC): Thanks @luizarakaki.  The group names are certainly not sensitive; not sure about the rest of the content, but will examine / post in a redacted form if necessary. I'll work with my IT team today to see if we can get a dump of the XML for direct testing / examination (I am unfortunately, but appropriately, not an Okta admin in our org!) In the meantime, here are some details that may help (or perhaps uncover obvious mistakes): 

The metabaseGroups attr is being generated using  Okta Expression Language (it's not manually input):

<img width=""445"" alt=""image"" src=""https://github.com/metabase/metabase/assets/4520575/3d9118d4-610a-48db-8834-63e66ffea52f"">

The full metabaseGroups attr (for this user) looks like this:

```
Metabase - Admins,Metabase - Owners,Metabase - All Users
```

...and is generated using Okta Expression Language (group IDs redacted and list is shortened):
```
getFilteredGroups({""groupID1"", ""groupID2"", ""groupID3"", ""groupID4"", ""groupID5""}, ""[group.name]"", 100)
```

The groupIDs are resolving to the list above.

Finally, we have mappings set up in Metabase:

![image](https://github.com/metabase/metabase/assets/4520575/0a191999-020f-477b-8366-775f90e4cf63)


Note that I thought there could have been an issue with symbol conversion with spaces, but renaming the groups to remove spaces did not exhibit different behavior.

luizarakaki on (2024-04-01 19:16:31 UTC): Right... Yeah, my first guess would be special characters causing problems. We had issues in the past with some special characters...

We are working internally to try to reproduce this using Okta dev tools. You'll be back to you on your ticket

jonmauney on (2024-04-01 19:37:31 UTC): @luizarakaki just got a response back from our IT team, it does look like the shape of the attr coming back from Okta differs from what is expected.

Okta is producing a comma separated string as a single-element attribute: 

```xml
        <saml2:Attribute Name=""metabaseGroups"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:basic"">
            <saml2:AttributeValue
                xmlns:xs=""http://www.w3.org/2001/XMLSchema""
                xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:type=""xs:string"">Metabase - Admins,MetabaseOwners
            </saml2:AttributeValue>
        </saml2:Attribute>
```

In the Metabase[ test](https://github.com/metabase/metabase/blob/80e690534a18ffb666124208e215d68b42182bce/test_resources/saml-test-response-new-user-with-groups.xml#L91) for multiple group assignment, it looks like the attr is an array:
```xml
<saml:Attribute Name=""GroupMembership"" NameFormat=""urn:oasis:names:tc:SAML:2.0:attrname-format:basic"">
        <saml:AttributeValue xsi:type=""xs:anyType"">group_1</saml:AttributeValue>
        <saml:AttributeValue xsi:type=""xs:anyType"">group_2</saml:AttributeValue>
      </saml:Attribute>
```

I'm going to see if there is a different data type we can assign in Okta that will unpack that list into an array rather than a comma-separated string.

luizarakaki on (2024-04-01 20:16:42 UTC): Thanks, this is useful. I'll ping the team.
Let me know if you can find a way to change this structure in Okta

luizarakaki on (2024-04-01 20:24:10 UTC): Is there are reason to add `[ ]` around group.name?
From above:
`getFilteredGroups({""groupID1"", ""groupID2"", ""groupID3"", ""groupID4"", ""groupID5""}, ""[group.name]"", 100)`

In the docs it says it returns an array, but it doesn't add these []
https://developer.okta.com/docs/reference/okta-expression-language/#group-functions

Tony-metabase on (2024-04-02 12:07:09 UTC): Hey @jonmauney,

Actually it does work. I am not sure how you are configuring users ... but let me share with you what i did. First i create a user and assign departments to it (in my case `Metabase-Admin,Metabase-Test`:

<img width=""1505"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/d39b6897-a14b-4cf7-9e90-209765d79062"">

there are also firstName, lastName and email but those you mentioned you already setup but just for consistency these are part of the User Profile:

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/75bc0d0a-9d3c-403a-9204-2a60c482640a"">


I then proceed to create the application which is that SAML 2.0 that we will connect to Metabase and setup the following attributes the following:

<img width=""1507"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/9ffe8946-615d-485f-bccb-1872828b150e"">

Note that department is the User profile attribute in which i am defining the groups. I need to perform an `Arrays.flatten` else metabase thinks its a string and will not understand multiple groups.

i then setup authentication with SAML and defining the group mappings:

<img width=""1255"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/492e52c1-2080-44b6-b2ce-56816f5b9457"">

Then when i login with this user i can see it being added to both groups:

<img width=""1512"" alt=""image"" src=""https://github.com/metabase/metabase/assets/110378427/342e475e-b5ff-4d0a-b252-c0f0710d7142"">

So this seems to be a false alarm or maybe the way we are creating users/groups is different?

jonmauney on (2024-04-02 13:38:28 UTC): Thanks both @luizarakaki @Tony-metabase! Will get with our IT team today to try this; will get back to you.

jonmauney on (2024-04-02 13:56:03 UTC): Unfortunately I can't get time with IT to test until Thursday afternoon.  One thing I found; it's possible there is an undocumented feature flag that is not enabled in our Okta account called `SAML_SUPPORT_ARRAY_ATTRIBUTES`.

Similar Okta support tickets are [here](https://support.okta.com/help/s/question/0D54z00007K7QA4CAN/saml-assertion-memberof-format-issue?language=en_US) and [here](https://support.okta.com/help/s/question/0D51Y00009sknKkSAI/same-variable-name-with-multiple-tags?language=en_US), and recognition in third-party guides [here](https://support.cloudinary.com/hc/en-us/articles/4405194731026-SAML-Provisioning-with-Okta-Tips-for-setting-user-attributes#:~:text=SAML_SUPPORT_ARRAY_ATTRIBUTES) and [here](https://github.com/rapid7/awsaml/blob/master/README.md).  We'll assess that alongside trying your suggestions on Thursday.

Tony-metabase on (2024-04-02 14:43:40 UTC): I saw that to be honest and it seems that by default okta will enable it ... I didn't reach out to Okta about that just did a quick trial and i am guessing I was using the default

jonmauney on (2024-04-02 16:00:27 UTC): Agreed that it should be the default @Tony-metabase; only thing is that our Okta account is many years old and I could see them not turning on the flag for older accounts if it could change behavior of existing Apps.  Will report back when we sit down to dig in!

Tony-metabase on (2024-04-02 16:16:04 UTC): No worries! I will close this issue for now since it seems that it's working but lets keep the thread open on our ticket :) and we can troubleshoot from there!

We can open another one which would be more specific for your usecase if that's not the issue

bc-rp on (2024-04-16 14:04:50 UTC): Hi,

We had the same issue and have resolved it as follows:

1. Have Okta enable the feature flag SAML_SUPPORT_ARRAY_ATTRIBUTES for your tenant
2. Configure the group attribute statement
- Name: MetabaseGroupName
- Name Format: Basic
- Value: Arrays.flatten(getFilteredGroups({""Grp_1"", ""Grp_2"", ""Grp_3""}, ""group.name"", 100))

With the above configuration we are now able to have users assigned to multiple groups.

"
2202603769,issue,closed,duplicate,Ability to configure model persistence at a per-model level,"**Is your feature request related to a problem? Please describe.**
You might have a use case where different tables update with very different periods of time, and you still want to maintain performance with model caching.

**Describe the solution you'd like**
Ability to set different caching configurations for different at a model level and not only globally

**Describe alternatives you've considered**
Disabling caching, but that is not good for certain use cases.

**How important is this feature to you?**
Requested by a customer, with the following words:

>  I'm talking about the model refresh schedule found in the admin section. We have some monitoring data on one hand (for instance to check for service health) that we would like to refresh often, for instance every 5 to 15min but on the other hand we also have many technical report (some of which take a long time to refresh) that we would like to refresh only once per day for instance. More broadly, we use Metabase as a central data hub where all the data from different team is available but different team have different definition of up to date for their models, in some case 1 day is up to date enough, in others 15 min is preferred.

**Additional context**
Internal ticket [25798](https://metabase.zendesk.com/agent/tickets/25798)
",ignacio-mb,2024-03-22 14:16:42+00:00,[],2025-01-21 10:32:51+00:00,2025-01-21 10:32:50+00:00,https://github.com/metabase/metabase/issues/40514,"[('.Performance', ''), ('Querying/Models', 'aka Datasets'), ('Querying/Cache', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]","[{'comment_id': 2017493212, 'issue_id': 2202603769, 'author': 'darksciencebase', 'body': 'cc @luizarakaki', 'created_at': datetime.datetime(2024, 3, 25, 8, 51, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2049806573, 'issue_id': 2202603769, 'author': 'zhouzian', 'body': 'I found this feature request useful as not all model cache need to be refreshed at the same schedule. Some models are aggregated per week or month, so that we only need to refresh them once a week/month. Other models may need hourly or daily refresh.', 'created_at': datetime.datetime(2024, 4, 11, 14, 19, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2226070908, 'issue_id': 2202603769, 'author': 'paoliniluis', 'body': 'This is also a performance issue, as refreshing all models at the same time can have some very nasty consequences on the DW', 'created_at': datetime.datetime(2024, 7, 12, 17, 41, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575718806, 'issue_id': 2202603769, 'author': 'thebiglabasky', 'body': 'Duplicate of #48743 ?', 'created_at': datetime.datetime(2025, 1, 7, 16, 23, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604334179, 'issue_id': 2202603769, 'author': 'ignacio-mb', 'body': ""Yep. This was opened before but it's the same. So closing in favor of that one"", 'created_at': datetime.datetime(2025, 1, 21, 10, 32, 50, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-03-25 08:51:28 UTC): cc @luizarakaki

zhouzian on (2024-04-11 14:19:59 UTC): I found this feature request useful as not all model cache need to be refreshed at the same schedule. Some models are aggregated per week or month, so that we only need to refresh them once a week/month. Other models may need hourly or daily refresh.

paoliniluis on (2024-07-12 17:41:50 UTC): This is also a performance issue, as refreshing all models at the same time can have some very nasty consequences on the DW

thebiglabasky on (2025-01-07 16:23:01 UTC): Duplicate of #48743 ?

ignacio-mb (Issue Creator) on (2025-01-21 10:32:50 UTC): Yep. This was opened before but it's the same. So closing in favor of that one

"
2202498809,issue,closed,completed,Sort official collections above regular collections,"<img width=""317"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6377293/62681323-d95f-4177-bf09-9e7f6607366e"">

The request is to put all official collections above unofficial collections, as returned from the backend.

Max is using a hack of prepending a ""z_"" to collection names to enforce this sorting and had a sensible idea that we could just naturally sort like this.",dpsutton,2024-03-22 13:29:10+00:00,['johnswanson'],2024-05-13 15:05:48+00:00,2024-05-13 15:05:48+00:00,https://github.com/metabase/metabase/issues/40510,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Organization/Collections', '')]","[{'comment_id': 2107907769, 'issue_id': 2202498809, 'author': 'johnswanson', 'body': 'Resolved by https://github.com/metabase/metabase/pull/40598', 'created_at': datetime.datetime(2024, 5, 13, 15, 5, 48, tzinfo=datetime.timezone.utc)}]","johnswanson (Assginee) on (2024-05-13 15:05:48 UTC): Resolved by https://github.com/metabase/metabase/pull/40598

"
2202440036,issue,open,,"[FE] Nest ""Combine columns"" and ""Extract column"" actions","![image](https://github.com/metabase/metabase/assets/6830683/258a4e1b-7251-44e9-9f4b-f406f1a57471)
",kamilmielnik,2024-03-22 12:56:59+00:00,[],2024-03-22 12:57:12+00:00,,https://github.com/metabase/metabase/issues/40507,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2202437007,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/spacing.module.css`,Closes #40518 ,oisincoveney,2024-03-22 12:55:10+00:00,['oisincoveney'],2024-04-12 08:45:02+00:00,2024-04-12 08:45:02+00:00,https://github.com/metabase/metabase/issues/40506,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]","[{'comment_id': 2051309724, 'issue_id': 2202437007, 'author': 'oisincoveney', 'body': 'Closed with #40518', 'created_at': datetime.datetime(2024, 4, 12, 8, 45, 2, tzinfo=datetime.timezone.utc)}]","oisincoveney (Issue Creator) on (2024-04-12 08:45:02 UTC): Closed with #40518

"
2202337184,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/layout.module.css`,,oisincoveney,2024-03-22 12:00:51+00:00,['oisincoveney'],2024-03-28 12:32:27+00:00,2024-03-28 12:32:27+00:00,https://github.com/metabase/metabase/issues/40502,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2202330036,issue,closed,completed,Implement and test nested field columns,"```[tasklist]
### Tasks
- [x] Initial implementation of nested field columns
- [x] Make existing nested field columns tests work with Druid JDBC
- [ ] https://github.com/metabase/metabase/issues/41094
```
",lbrdnk,2024-03-22 11:56:29+00:00,['lbrdnk'],2024-04-24 18:39:15+00:00,2024-04-24 18:39:15+00:00,https://github.com/metabase/metabase/issues/40501,[],"[{'comment_id': 2075593038, 'issue_id': 2202330036, 'author': 'lbrdnk', 'body': 'Nested field columns tests were ported. Druid testing image got added json tables on build time. Green CI run with nfc tests: https://github.com/metabase/metabase/actions/runs/8811761084.', 'created_at': datetime.datetime(2024, 4, 24, 18, 39, 15, tzinfo=datetime.timezone.utc)}]","lbrdnk (Issue Creator) on (2024-04-24 18:39:15 UTC): Nested field columns tests were ported. Druid testing image got added json tables on build time. Green CI run with nfc tests: https://github.com/metabase/metabase/actions/runs/8811761084.

"
2202274922,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/overflow.module.css`,,oisincoveney,2024-03-22 11:22:22+00:00,['oisincoveney'],2024-04-12 14:11:10+00:00,2024-03-22 13:05:04+00:00,https://github.com/metabase/metabase/issues/40497,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2202267460,issue,closed,completed,Migrate global css in `frontend/src/metabase/containers/SaveQuestionModal.module.css`,,oisincoveney,2024-03-22 11:17:43+00:00,['oisincoveney'],2024-04-12 08:43:39+00:00,2024-04-12 08:43:39+00:00,https://github.com/metabase/metabase/issues/40496,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]","[{'comment_id': 2051306752, 'issue_id': 2202267460, 'author': 'oisincoveney', 'body': 'Looks like `SaveQuestionModal.module.css` has been deleted, so no work needed here üòÑ', 'created_at': datetime.datetime(2024, 4, 12, 8, 43, 39, tzinfo=datetime.timezone.utc)}]","oisincoveney (Issue Creator) on (2024-04-12 08:43:39 UTC): Looks like `SaveQuestionModal.module.css` has been deleted, so no work needed here üòÑ

"
2202181899,issue,closed,completed,Record field usage during query execution,"### What

We want to record how fields are used during query execution. The schema for field usage.

| Column | Type | remark | Example |
| --- | --- | --- | --- |
| field_id | int |  |  |
| query_execution_id | integer | FK to query_execution.id | 
| used_in | varchar(25) |	which part of the query this field is used in | breakout, aggregation, filter |
| created_at | timestamp with timezone |  |  |
| filter_op | varchar(25) | the operator of the filter | > |
| aggregation_function | varchar(25) | name of the aggregation function | :sum, :max |
| breakout_binning_strategy | varchar(25) | breakout binning strategy |  num-bins |
| breakout_binning_num_bins | integer | breakout num bin binning option |  20 |
| breakout_binning_bin_width| integer | breakout bin width binning option |  10 |
| breakout_temporal_unit | text | breakout temporal unit option | |

### Gathering field usage

We‚Äôll rely on our friends over at the QP team and ask them to help us with an API that takes a query and returns field_usage. The schema for the output is:

```clojure
[:and
 [:map
  [:clause-type [:enum :expression :breakout :aggregation :filter]]]
 [:multi {:dispatch :clause-type}
  [:expression  [:map
                 [:type                 [:= :expression]]
                 [:field-id             pos-int?]]
  [:breakout    [:map
                 [:type                 [:= :breakout]]
                 [:field-id             pos-int?]
                 [:breakout-param       [:metabase.lib.schema.ref/field.options]]]]
  [:aggregation [:map
                 [:type                 [:= :aggregation]]
                 [:field-id             pos-int?]
                 [:aggregation-function [:enum :avg :count :cum-count :count-where :distinct :var
                                         :max :median :min :percentile :share :stddev :sum :cum-sum :sum-where]]]]
  [:fitler      [:map
                 [:type                 [:= :filter]]
                 [:field-id             pos-int?]
                 [:filter-args        [:sequential :any]
                 [:filter-op           [:enum := :!= :inside :between :< :> :<= :>= :is-null :not-null :is-empty :not-empty :contains :does-not-contain :starts-with :ends-with]]]]]]
```

### Saving field usage

We already have a process that save query_execution asynchronously in  https://github.com/metabase/metabase/blob/cd1d3c70675c4dc2591dadad3968accbd2531585/src/metabase/query_processor/middleware/process_userland_query.clj#L59

For our task, we‚Äôll extend `save-query-execution!*` to save field_usage.",qnkhuat,2024-03-22 10:28:24+00:00,['qnkhuat'],2024-04-22 10:10:52+00:00,2024-04-17 02:41:58+00:00,https://github.com/metabase/metabase/issues/40494,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2014856343, 'issue_id': 2202181899, 'author': 'calherries', 'body': ""High-level approach looks solid. I have a few ideas:\r\n1. If a column is used in an expression that is then used in a filter or aggregation, do we intend to store that data anywhere? I'm not sure how we'd use it, but want to make sure we're aware of that case.\r\n2. Since we're inserting this record in `save-query-execution!`, we'll have access to the `query_execution` record. If we add a foreign key on this table, we'll have more flexibility in the future to grab things like the `user_id` for personalized recommendations.\r\n3. If we have a foreign key, `context` is not necessary to store here either."", 'created_at': datetime.datetime(2024, 3, 22, 11, 8, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2014886061, 'issue_id': 2202181899, 'author': 'qnkhuat', 'body': ""> If a column is used in an expression that is then used in a filter or aggregation, do we intend to store that data anywhere? I'm not sure how we'd use it, but want to make sure we're aware of that case.\r\n\r\nyep I'm not sure how useful is that either, but if the goal is to find all the fields that were used in the last 15 days then that that should be enough. \r\n\r\n> Since we're inserting this record in save-query-execution!, we'll have access to the query_execution record. If we add a foreign key on this table, we'll have more flexibility in the future to grab things like the user_id for personalized recommendations.\r\n\r\nthat's a good idea ! updated the schema."", 'created_at': datetime.datetime(2024, 3, 22, 11, 29, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2014894816, 'issue_id': 2202181899, 'author': 'calherries', 'body': ""If we're not going to store any expression related data in v1 of this, maybe we should leave it out of the QP API? I imagine we can save us all some time if we don't require it."", 'created_at': datetime.datetime(2024, 3, 22, 11, 35, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2020019781, 'issue_id': 2202181899, 'author': 'qnkhuat', 'body': '~I think saving the expression clause might be useful, wdyt?~\r\n\r\non the second thought, not sure what we can do with it since expression can have a high degree of freedom.', 'created_at': datetime.datetime(2024, 3, 26, 10, 10, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2060236187, 'issue_id': 2202181899, 'author': 'qnkhuat', 'body': 'Implemented in https://github.com/metabase/metabase/pull/39671', 'created_at': datetime.datetime(2024, 4, 17, 2, 41, 58, tzinfo=datetime.timezone.utc)}]","calherries on (2024-03-22 11:08:52 UTC): High-level approach looks solid. I have a few ideas:
1. If a column is used in an expression that is then used in a filter or aggregation, do we intend to store that data anywhere? I'm not sure how we'd use it, but want to make sure we're aware of that case.
2. Since we're inserting this record in `save-query-execution!`, we'll have access to the `query_execution` record. If we add a foreign key on this table, we'll have more flexibility in the future to grab things like the `user_id` for personalized recommendations.
3. If we have a foreign key, `context` is not necessary to store here either.

qnkhuat (Issue Creator) on (2024-03-22 11:29:14 UTC): yep I'm not sure how useful is that either, but if the goal is to find all the fields that were used in the last 15 days then that that should be enough. 


that's a good idea ! updated the schema.

calherries on (2024-03-22 11:35:38 UTC): If we're not going to store any expression related data in v1 of this, maybe we should leave it out of the QP API? I imagine we can save us all some time if we don't require it.

qnkhuat (Issue Creator) on (2024-03-26 10:10:19 UTC): ~I think saving the expression clause might be useful, wdyt?~

on the second thought, not sure what we can do with it since expression can have a high degree of freedom.

qnkhuat (Issue Creator) on (2024-04-17 02:41:58 UTC): Implemented in https://github.com/metabase/metabase/pull/39671

"
2202105417,issue,closed,completed,Date Filtering Bug in v0.49.1 Docker Image with Japanese Locale Settings,"### Describe the bug

A bug occurs in both the v0.49.0 and v0.49.1 Docker images uploaded to DockerHub when the language setting is switched to Japanese. Specifically, when filtering datetime columns by specifying an exact date, the filter incorrectly applies the date subtracted by 2018 years from the chosen date. This issue has been confirmed not to occur in version v0.48.8. Additionally, the bug does not manifest when the language settings are set to English, Chinese, or Korean.

When a date is selected like this:
<img width=""250"" alt=""image"" src=""https://github.com/metabase/metabase/assets/54491901/ccfd3a63-43d7-4218-a88b-e6eac3670b9f"">

The filter incorrectly applies a date subtracted by 2018 years as shown below:
<img width=""250"" alt=""image"" src=""https://github.com/metabase/metabase/assets/54491901/9c1292ed-7876-4777-931a-1bd4ddc96ec7"">


### To Reproduce

1. Use the v0.49.1 image from DockerHub.
2. Change language settings to Japanese.
3. Attempt to filter a datetime column by specifying an exact date.
4. Notice that the applied filter date is 2018 years less than the specified date.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""ja-JP"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.210-201.852.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""8.0.35""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2 - High: Critically blocks data analysis for all Japanese locale users by improperly applying date filters.

### Additional context

_No response_",bell851,2024-03-22 09:47:40+00:00,[],2024-05-02 09:39:21+00:00,2024-04-23 08:31:46+00:00,https://github.com/metabase/metabase/issues/40493,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', '')]","[{'comment_id': 2020414903, 'issue_id': 2202105417, 'author': 'paoliniluis', 'body': 'whoa, sorry about that', 'created_at': datetime.datetime(2024, 3, 26, 13, 20, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2069369828, 'issue_id': 2202105417, 'author': 'zbodi74', 'body': 'Filtering using a date range is also affected.', 'created_at': datetime.datetime(2024, 4, 22, 13, 10, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2070218799, 'issue_id': 2202105417, 'author': 'lbrdnk', 'body': 'It looks as FE issue. The `metabase.lib.fe-util/expression-clause` gets year already shifted.', 'created_at': datetime.datetime(2024, 4, 22, 16, 53, 23, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-26 13:20:36 UTC): whoa, sorry about that

zbodi74 on (2024-04-22 13:10:04 UTC): Filtering using a date range is also affected.

lbrdnk on (2024-04-22 16:53:23 UTC): It looks as FE issue. The `metabase.lib.fe-util/expression-clause` gets year already shifted.

"
2202039325,issue,closed,completed,Error when downloading questions via .csv (java.time.Instant cannot be cast to class java.lang.CharSequence),"### Describe the bug

I have a MongoDB question

I can see the data visually but when I try to download it via .csv

The .csv file has just 1 row that contains the ff:

{""database_id"":10	started_at:""2024-03-22T08:48:39.653432Z""	via:[{""status"":""failed""	class:""class clojure.lang.ExceptionInfo""	
error:""Error reducing result rows: class java.time.Instant cannot be cast to class java.lang.CharSequence (java.time.Instant and java.lang.CharSequence are in module java.base of loader 'bootstrap')""

Here is my query. Database is MongoDB

![image](https://github.com/metabase/metabase/assets/89201548/ebaa13ff-db0f-4dc3-8c59-d81b8965720b)



### To Reproduce

1. Create question for MongoDB Database
2. Download the result via .csv
3. See error


### Expected behavior

_No response_

### Logs

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu222.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu222.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.5.0-1016-azure"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mongo"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-21"",
      ""tag"": ""v0.49.1"",
      ""hash"": ""54ef5e9""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```


### Severity

2

### Additional context

This is working before 0.49.0",jrca025,2024-03-22 09:13:12+00:00,[],2025-01-06 09:34:39+00:00,2025-01-06 09:34:39+00:00,https://github.com/metabase/metabase/issues/40492,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/Mongo', None), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2020416606, 'issue_id': 2202039325, 'author': 'paoliniluis', 'body': 'can you show the data? seems like a data type issue', 'created_at': datetime.datetime(2024, 3, 26, 13, 21, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2021822438, 'issue_id': 2202039325, 'author': 'jrca025', 'body': 'here is a sample document\r\n\r\n{\r\n    ""_id"" : ""123-20240327"",\r\n    ""StockId"" : 123,\r\n    ""Date"" : ISODate(""2024-03-27T00:00:00.000+0000""),\r\n    ""Last"" : { ""$numberDecimal"" : ""0.67"" },\r\n    ""IsLatest"" : true,\r\n    ""LastUpdateTime"" : ISODate(""2024-03-27T10:44:09.000+0000"")\r\n}\r\n\r\n\r\nHowever, I noticed if i exclude the date columns (Date, LastUpdateTime) then I download it via .csv it is working fine.', 'created_at': datetime.datetime(2024, 3, 27, 2, 51, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2021827667, 'issue_id': 2202039325, 'author': 'jrca025', 'body': '@paoliniluis \r\n\r\nCan you try this on your end? It seems like a bug\r\n\r\n1. Select all fields\r\n2. export via .csv\r\n3. the .csv file will contain errors\r\n4. exclude the date fields then export again via .csv\r\n5. the .csv file should be fine\r\n6. re-include the date fields again then export via .csv\r\n7. the .csv is now working with date fields', 'created_at': datetime.datetime(2024, 3, 27, 2, 59, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572260399, 'issue_id': 2202039325, 'author': 'givemesomefaces', 'body': 'It was fixed in 49.3', 'created_at': datetime.datetime(2025, 1, 6, 4, 37, 9, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-26 13:21:27 UTC): can you show the data? seems like a data type issue

jrca025 (Issue Creator) on (2024-03-27 02:51:46 UTC): here is a sample document

{
    ""_id"" : ""123-20240327"",
    ""StockId"" : 123,
    ""Date"" : ISODate(""2024-03-27T00:00:00.000+0000""),
    ""Last"" : { ""$numberDecimal"" : ""0.67"" },
    ""IsLatest"" : true,
    ""LastUpdateTime"" : ISODate(""2024-03-27T10:44:09.000+0000"")
}


However, I noticed if i exclude the date columns (Date, LastUpdateTime) then I download it via .csv it is working fine.

jrca025 (Issue Creator) on (2024-03-27 02:59:12 UTC): @paoliniluis 

Can you try this on your end? It seems like a bug

1. Select all fields
2. export via .csv
3. the .csv file will contain errors
4. exclude the date fields then export again via .csv
5. the .csv file should be fine
6. re-include the date fields again then export via .csv
7. the .csv is now working with date fields

givemesomefaces on (2025-01-06 04:37:09 UTC): It was fixed in 49.3

"
2201850470,issue,closed,completed,"Multiply a negative number by 0.0001, and the display becomes as if multiplied by 0.00000001","### Describe the bug

In a bar chart or waterfall chart, when displaying a negative number, if it is formatted, such as multiplying by 0.0001, this operation is performed twice, and the displayed value will appear as if multiplied by 0.00000001.
![image](https://github.com/metabase/metabase/assets/23210408/66430d44-c457-47a8-afd5-caac2d701c84)


### To Reproduce

In a bar chart or waterfall chart, when displaying a negative number, if it is formatted, such as multiplying by 0.0001, this operation is performed twice, and the displayed value will appear as if multiplied by 0.00000001.

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
database: mysql„ÄÅdoris
metabase version: v0.49.1
```


### Severity

annoying

### Additional context

_No response_",TurboWay,2024-03-22 07:14:40+00:00,['JesseSDevaney'],2024-06-15 01:39:22+00:00,2024-06-15 01:39:17+00:00,https://github.com/metabase/metabase/issues/40490,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2166700833, 'issue_id': 2201850470, 'author': 'JesseSDevaney', 'body': 'Could not reproduce in 50, but found another bug related to the difference between data label values and tool-tip values.\r\n- https://github.com/metabase/metabase/issues/44176\r\n\r\nWill create a separate PR targeting just the v49 branch to fix this behavior.', 'created_at': datetime.datetime(2024, 6, 13, 20, 24, 2, tzinfo=datetime.timezone.utc)}]","JesseSDevaney (Assginee) on (2024-06-13 20:24:02 UTC): Could not reproduce in 50, but found another bug related to the difference between data label values and tool-tip values.
- https://github.com/metabase/metabase/issues/44176

Will create a separate PR targeting just the v49 branch to fix this behavior.

"
2201738341,issue,open,,choose the type of unit when displaying a number,"I use version 0.49, the display of a number can be compressed if it doesn't have enough space. 
The unit is currently imposed. (Metabase is configured in French in the administration menu (Localization))

In France, the metric system is used.
https://en.wikipedia.org/wiki/Metric_prefix

The problem is that you can't choose the unit of compression.

example:
full number
![unity_2](https://github.com/metabase/metabase/assets/66816029/6ca3b992-04d2-4d1e-9148-0d3c6a00b241)

compressed numbers
![unity_1](https://github.com/metabase/metabase/assets/66816029/d490468c-9376-4d21-a87c-7ce205e6a847)


4.1B  => 4.1G

For example, when calculating electricity consumption, we'd like to output our data in watts (base unit) and have it displayed in kW or MW or GW, depending on the number of digits in the base unit. ",Roman2nc,2024-03-22 05:36:38+00:00,[],2024-03-26 13:22:58+00:00,,https://github.com/metabase/metabase/issues/40489,"[('Type:New Feature', ''), ('.Frontend', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges')]",[],
2201432928,issue,closed,completed,Document that we need access to the information_schema in Redshift,"**Is your feature request related to a problem? Please describe.**
Now that we sync faster than ever thanks to seeing the tables in the information schema, we need access to that. We should add that to the documentation",paoliniluis,2024-03-22 00:10:16+00:00,['jeff-bruemmer'],2025-01-03 14:45:21+00:00,2025-01-03 14:45:19+00:00,https://github.com/metabase/metabase/issues/40484,"[('Type:Documentation', ''), ('Database/Redshift', None), ('Type:New Feature', '')]","[{'comment_id': 2215070374, 'issue_id': 2201432928, 'author': 'jeff-bruemmer', 'body': ""@paoliniluis Here's an optimistic PR: https://github.com/metabase/metabase/pull/45244. Is that all we need?"", 'created_at': datetime.datetime(2024, 7, 8, 19, 53, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569340359, 'issue_id': 2201432928, 'author': 'jeff-bruemmer', 'body': 'Closed by https://github.com/metabase/metabase/pull/45244', 'created_at': datetime.datetime(2025, 1, 3, 14, 45, 19, tzinfo=datetime.timezone.utc)}]","jeff-bruemmer (Assginee) on (2024-07-08 19:53:11 UTC): @paoliniluis Here's an optimistic PR: https://github.com/metabase/metabase/pull/45244. Is that all we need?

jeff-bruemmer (Assginee) on (2025-01-03 14:45:19 UTC): Closed by https://github.com/metabase/metabase/pull/45244

"
2201356253,issue,closed,completed,"Downloading results on 1.49 putting double quotes around numbers that are at least 4 digits long, and changes Date format","### Describe the bug

We have a customer who's downloading results to CSV and XLXS, and noticed number data types with 4 digits or more are being placed within double quotes.

""2,450""
vs
872

The date format has also changed on exports where on previous versions such as 1.48.6 it would be **2022-03-30**, and 1.49 it's **‚ÄúMarch 30, 2022‚Äù**.
The Localization settings have not been changed between versions.


I'm using a postgres instance and able to replicate it on 1.49 but just with CSV exports.
Their backend is Athena, on 1.49.1 and it's happening with both exports. I haven't had a chance to test simulating their configuration.

### To Reproduce

Using a postgres db on version 15.3 for these tests.

1. Have a table with a numeric based column. For this test I'm using Integer and Decimal.
2. The table also has a Date type column.
3. Create a question and add it to a dashboard.
4. Download the results to CSV.

Partial results from test to show difference in number format:

> Car Model,Price ($),Color,Date Sold
> Toyota Camry,""20,000"",Red,""January 1, 2023""
> Honda Accord,""25,000"",Blue,""January 2, 2023""
> Ford F-150,""30,000"",Green,""January 3, 2023""
> 
> 1989 Ford Bronco,999,Red,""February 7, 2023""
> 1993 Mazda 626,650,White,""February 8, 2023""
> 1986 Toyota Pickup,800,Black,""February 9, 2023""
> 1992 Subaru Legacy,450,Green,""February 10, 2023""

<br>
<br>

 Partial results from test to show difference in date format:
> Car Model,Price ($),Color,Date Sold
> Toyota Camry,""20,000"",Red,""January 1, 2023""
> Honda Accord,""25,000"",Blue,""January 2, 2023""
> Ford F-150,""30,000"",Green,""January 3, 2023""
> 
> Car Model,Price,Color,Date Sold
> Toyota Camry,20000,Red,2023-01-01
> Honda Accord,25000,Blue,2023-01-02
> Ford F-150,30000,Green,2023-01-03


### Expected behavior

1. Expecting consistency regardless of the length of the number, and no quotes around numbers on the export.
2. Date format to return to how it worked prior to 1.49

### Logs

_No response_

### Information about your Metabase installation

```JSON
My tests:
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.49-linuxkit-pr"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v1.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}

-- -- -- -- -- -- --

Customer:
{\rtf1\ansi\ansicpg1252\cocoartf2709
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;\red59\green68\blue96;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c29804\c34118\c45098;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \{\
  ""browser-info"": \{\
    ""language"": ""en-US"",\
    ""platform"": ""MacIntel"",\
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",\
    ""vendor"": ""Google Inc.""\
  \},\
  ""system-info"": \{\
    ""file.encoding"": ""UTF-8"",\
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\
    ""java.runtime.version"": ""11.0.22+7"",\
    ""java.vendor"": ""Eclipse Adoptium"",\
    ""java.vendor.url"": ""https://adoptium.net/"",\
    ""java.version"": ""11.0.22"",\
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\
    ""java.vm.version"": ""11.0.22+7"",\
    ""os.name"": ""Linux"",\
    ""os.version"": ""5.10.210-201.852.amzn2.x86_64"",\
    ""user.language"": ""en"",\
    ""user.timezone"": ""GMT""\
  \},\
  ""metabase-info"": \{\
    ""databases"": [\
      ""h2"",\
      ""mysql"",\
      ""athena""\
    ],\
    ""hosting-env"": ""unknown"",\
    ""application-database"": ""mysql"",\
    ""application-database-details"": \{\
      ""database"": \{\
        ""name"": ""MySQL"",\
        ""version"": ""8.0.35""\
      \},\
      ""jdbc-driver"": \{\
        ""name"": ""MariaDB Connector/J"",\
        ""version"": ""2.7.10""\
      \}\
    \},\
    ""run-mode"": ""prod"",\
    ""version"": \{\
      ""date"": ""2024-03-21"",\
      ""tag"": ""v1.49.1"",\
      ""hash"": ""54ef5e9""\
    \},\
    ""settings"": \{\
      ""report-timezone"": null\
    \}\
  \}\
\}}
```


### Severity

P2 - Causing an issue for a customer who uses these exports to feed into other systems

### Additional context

_No response_",FilmonK,2024-03-21 23:08:38+00:00,[],2024-08-07 23:34:18+00:00,2024-08-07 23:34:17+00:00,https://github.com/metabase/metabase/issues/40482,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Export', ''), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2016793877, 'issue_id': 2201356253, 'author': 'mkan-su', 'body': 'Also the number having type % are downloaded with % symbol in version 49. For example CSV download has ""50%"" Vs 0.05 in versions before 49. This is causing problems wherever the csv is used. Issue present in open source version as well.', 'created_at': datetime.datetime(2024, 3, 24, 12, 28, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2226538191, 'issue_id': 2201356253, 'author': 'adam-james-v', 'body': ""@FilmonK , if the customer is able, or has already upgraded to a newer minor version (49.10 has format rows options/bug fixes), this should be solved. \n\nIf they use the API to get downloads, there is a query param they can use `format_rows=false` to get downloads in the expected form.\n\nIf they are clicking the download button, they can hold 'Alt' and click the button to get an unformatted download. \nFinally, if they are using subscriptions, there is a checkbox 'use unformatted values in attachments' available.\n\nIf that is a workable solution for the customer, could you close this issue?"", 'created_at': datetime.datetime(2024, 7, 12, 23, 47, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274519143, 'issue_id': 2201356253, 'author': 'adam-james-v', 'body': ""@FilmonK , I'm closing this issue as it's fixed in 49.10 and later."", 'created_at': datetime.datetime(2024, 8, 7, 23, 34, 17, tzinfo=datetime.timezone.utc)}]","mkan-su on (2024-03-24 12:28:50 UTC): Also the number having type % are downloaded with % symbol in version 49. For example CSV download has ""50%"" Vs 0.05 in versions before 49. This is causing problems wherever the csv is used. Issue present in open source version as well.

adam-james-v on (2024-07-12 23:47:04 UTC): @FilmonK , if the customer is able, or has already upgraded to a newer minor version (49.10 has format rows options/bug fixes), this should be solved. 

If they use the API to get downloads, there is a query param they can use `format_rows=false` to get downloads in the expected form.

If they are clicking the download button, they can hold 'Alt' and click the button to get an unformatted download. 
Finally, if they are using subscriptions, there is a checkbox 'use unformatted values in attachments' available.

If that is a workable solution for the customer, could you close this issue?

adam-james-v on (2024-08-07 23:34:17 UTC): @FilmonK , I'm closing this issue as it's fixed in 49.10 and later.

"
2201343601,issue,closed,not_planned,Standalone jar 0.49 version SQL editor broken visually,"### Describe the bug

Every time I go into the SQL editor the cursor position is no where near the text being edited.  I would guess that the text pane is using a proportional font and the editor is expecting to position by a fixed width font. Notice the cursor mark to the far right from where I added the text.
<img width=""1251"" alt=""Screenshot 2024-03-21 at 4 35 04 PM"" src=""https://github.com/metabase/metabase/assets/36056663/97d51b6c-8880-48a0-b81d-25c0254f816c"">


### To Reproduce

1. Using standalone .jar file for 0.49
2. Open query and edit with SQL editor
3. Click anywhere in the text of the query and start typing, it will show up in the wrong position in the text.
4. Thanks for using Metabase!
You're on version v0.49.0
Built on 2024-03-14

### Expected behavior

Editor position visually should be next to the text being edited.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/115.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-LTS"",
    ""java.vendor"": ""Amazon.com Inc."",
    ""java.vendor.url"": ""https://aws.amazon.com/corretto/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-LTS"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.79-99.164.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.6""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High blocking all users of SQL queries

### Additional context

I'm trying to show this to a client for them to consider using however running into things that make this an annoyance to try to actually use.  We have a real copy of production data to develop against.  The popup to ""Click here to be notified..."" is a given, any query takes one minute and 17 seconds as there are 1.52 billion records in the table.  Greenplum database is working just fine at 9.1 million records/second, would like to put a pretty UI on it and am evaluating Metabase.",wkvolkman,2024-03-21 23:02:58+00:00,[],2024-04-03 08:46:59+00:00,2024-04-03 08:46:59+00:00,https://github.com/metabase/metabase/issues/40481,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2032562377, 'issue_id': 2201343601, 'author': 'wkvolkman', 'body': ""The editor has this as it's font choices:\r\nfont: 12px/normal 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'Source Code Pro', 'source-code-pro', monospace;\r\nNone of those were available on CentOS 7, I installed the source-code-pro one and it seemed to get corrected.\r\nYour textarea has a font_size: 1px which seems to be incorrect and would be a problem with people who cannot use small fonts, I certainly find the font size in the editor too small.  Make your web designer stand at least 4' away from the screen to see it it's readable."", 'created_at': datetime.datetime(2024, 4, 2, 16, 48, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032567535, 'issue_id': 2201343601, 'author': 'wkvolkman', 'body': 'Oh, FYI, I had also tried to look at it on a Macbook Pro and it had the same issue, that font list does not appears to be a good default.', 'created_at': datetime.datetime(2024, 4, 2, 16, 51, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032573920, 'issue_id': 2201343601, 'author': 'wkvolkman', 'body': 'So on the .ace_editor class I would want a 16px font however a 14kpx font looks ok, the 12px is too small.  And shouldn\'t that be ""pt"".', 'created_at': datetime.datetime(2024, 4, 2, 16, 55, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032578271, 'issue_id': 2201343601, 'author': 'wkvolkman', 'body': 'Yep, this looks much better, and with ""pt"" instead of ""px"" it\'s display independent:\r\n12pt/normal \'Monaco\', \'Menlo\', \'Ubuntu Mono\', \'Consolas\', \'Source Code Pro\', \'source-code-pro\', monospace', 'created_at': datetime.datetime(2024, 4, 2, 16, 57, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032712874, 'issue_id': 2201343601, 'author': 'paoliniluis', 'body': 'So it was because of fonts not installed in the operating system?', 'created_at': datetime.datetime(2024, 4, 2, 18, 2, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032875108, 'issue_id': 2201343601, 'author': 'wkvolkman', 'body': ""The font list provided is Windows and Apple specific with some allowance for Ubuntu, Linux Redhat will not have those fonts.  The Source Code Pro fonts are Adobe proprietary though free for use, not installed by default.   The aren't OS specific per se however do have to be available."", 'created_at': datetime.datetime(2024, 4, 2, 19, 13, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032884920, 'issue_id': 2201343601, 'author': 'wkvolkman', 'body': ""I am curious why the Apple font, Menlo didn't seem to work on Apple, they may have shifted as they like to keep people guessing as to what is compatible."", 'created_at': datetime.datetime(2024, 4, 2, 19, 15, 42, tzinfo=datetime.timezone.utc)}]","wkvolkman (Issue Creator) on (2024-04-02 16:48:40 UTC): The editor has this as it's font choices:
font: 12px/normal 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'Source Code Pro', 'source-code-pro', monospace;
None of those were available on CentOS 7, I installed the source-code-pro one and it seemed to get corrected.
Your textarea has a font_size: 1px which seems to be incorrect and would be a problem with people who cannot use small fonts, I certainly find the font size in the editor too small.  Make your web designer stand at least 4' away from the screen to see it it's readable.

wkvolkman (Issue Creator) on (2024-04-02 16:51:26 UTC): Oh, FYI, I had also tried to look at it on a Macbook Pro and it had the same issue, that font list does not appears to be a good default.

wkvolkman (Issue Creator) on (2024-04-02 16:55:15 UTC): So on the .ace_editor class I would want a 16px font however a 14kpx font looks ok, the 12px is too small.  And shouldn't that be ""pt"".

wkvolkman (Issue Creator) on (2024-04-02 16:57:50 UTC): Yep, this looks much better, and with ""pt"" instead of ""px"" it's display independent:
12pt/normal 'Monaco', 'Menlo', 'Ubuntu Mono', 'Consolas', 'Source Code Pro', 'source-code-pro', monospace

paoliniluis on (2024-04-02 18:02:56 UTC): So it was because of fonts not installed in the operating system?

wkvolkman (Issue Creator) on (2024-04-02 19:13:34 UTC): The font list provided is Windows and Apple specific with some allowance for Ubuntu, Linux Redhat will not have those fonts.  The Source Code Pro fonts are Adobe proprietary though free for use, not installed by default.   The aren't OS specific per se however do have to be available.

wkvolkman (Issue Creator) on (2024-04-02 19:15:42 UTC): I am curious why the Apple font, Menlo didn't seem to work on Apple, they may have shifted as they like to keep people guessing as to what is compatible.

"
2201285340,issue,closed,completed,Missing series name in legend,"### Describe the bug

[Original report](https://metaboat.slack.com/archives/C064QMXEV9N/p1711050044682409).
<img width=""756"" alt=""Screenshot 2024-03-21 at 7 13 14‚ÄØPM"" src=""https://github.com/metabase/metabase/assets/14301985/08bba443-e584-4922-a374-3d7430d9f5d9"">


### To Reproduce

1. ...
2. ...


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Latest master?
```


### Severity

Average bug

### Additional context

_No response_",alxnddr,2024-03-21 22:14:15+00:00,['alxnddr'],2024-06-10 17:17:33+00:00,2024-06-10 17:17:33+00:00,https://github.com/metabase/metabase/issues/40478,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Regression/master', 'Regression that is only present on master, or bug in new upcoming feature'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2158905610, 'issue_id': 2201285340, 'author': 'alxnddr', 'body': 'Could not reproduce, cartesian charts and legends have been fully reworked in v50.', 'created_at': datetime.datetime(2024, 6, 10, 17, 17, 33, tzinfo=datetime.timezone.utc)}]","alxnddr (Issue Creator) on (2024-06-10 17:17:33 UTC): Could not reproduce, cartesian charts and legends have been fully reworked in v50.

"
2201257469,issue,open,,Wrong name used for auto-joined table after changing join key,"### Describe the bug

In table metadata, I have a Ticket table with 3 foreign keys (Assignee ID, Requester ID, Submitter ID) that maps to the same User table. 

When creating a new question on Ticket  that joins User, it automatically joined them based using the first key Assignee ID, and the joined table is named ""User - Assignee"". 

However, when changing the join key to Requester ID, the joined table name stays the same. While it does do the right thing, but it is confusing to the users and looks like it may be using the incorrect fields (therefore can't trust the data). 

### To Reproduce

1. Map several fields from one table to another with foreign key relationship
2. Create question that joins the two tables -- it will auto-join on first key
3. Do a basic count that groups by a field in the joined table -- notice name of the joined table
4. Change join key to another one and notice the joined table name stays the same, which is confusing to users. 

### Expected behavior

Joined table name should update based on the joined key -- and not the first one from auto-join. 

### Logs

n/a

### Information about your Metabase installation

```JSON
master @ Postgres
```


### Severity

Cosmetic but bumping to medium as it is confusing to users / breaks trust in field name

### Additional context

Notice the join field and group by have different names (group by is using original auto-joined name and didn't change after changing the join key). 

<img width=""1697"" alt=""Screenshot 2024-03-20 at 3 42 47 PM"" src=""https://github.com/metabase/metabase/assets/9684260/07e2adea-d745-47e1-9ab0-867e02055884"">
",maxzheng,2024-03-21 21:52:30+00:00,[],2025-02-04 20:27:14+00:00,,https://github.com/metabase/metabase/issues/40477,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/MBQL', ''), ('.Correctness', ''), ('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Team/Querying', '')]","[{'comment_id': 2018944077, 'issue_id': 2201257469, 'author': 'bshepherdson', 'body': ""That looks like it might be the wrong screenshot?\r\n\r\nThis seems like an MLv2 issue rather than FE proper, since MLv2 is generally responsible for join aliases and display names on queries.\r\n\r\nThe logic for naming joins is just `Foreign Table` by default, but if there are multiple FKs pointing at the same table it defaults to `Foreign Table - FK Column` like that. That value should be updated when the condition is changed, but the join alias (which the display name is based on) doesn't change."", 'created_at': datetime.datetime(2024, 3, 25, 21, 24, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2075604734, 'issue_id': 2201257469, 'author': 'lbrdnk', 'body': ""Sql for reproduction:\r\n\r\n```\r\ncreate database wrong_name_joined_table_db;\r\n\r\ncreate table core_user (\r\n    id serial primary key,\r\n    user_name varchar\r\n);\r\n\r\ncreate table core_ticket (\r\n    id serial primary key,\r\n    asignee_id int,\r\n    requester_id int,\r\n    submitter_id int,\r\n    ticket_name varchar\r\n);\r\n\r\nalter table core_ticket add constraint fk_asignee_core_user foreign key (asignee_id) references core_user(id);\r\nalter table core_ticket add constraint fk_requester_core_user foreign key (requester_id) references core_user(id);\r\nalter table core_ticket add constraint fk_submitter_core_user foreign key (submitter_id) references core_user(id);\r\n\r\ninsert into core_user (user_name) values ('a');\r\ninsert into core_user (user_name) values ('b');\r\ninsert into core_user (user_name) values ('c');\r\n\r\ninsert into core_ticket (asignee_id, requester_id, submitter_id, ticket_name) values (1, 2, 3, 'x');\r\n```"", 'created_at': datetime.datetime(2024, 4, 24, 18, 45, 42, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-03-25 21:24:14 UTC): That looks like it might be the wrong screenshot?

This seems like an MLv2 issue rather than FE proper, since MLv2 is generally responsible for join aliases and display names on queries.

The logic for naming joins is just `Foreign Table` by default, but if there are multiple FKs pointing at the same table it defaults to `Foreign Table - FK Column` like that. That value should be updated when the condition is changed, but the join alias (which the display name is based on) doesn't change.

lbrdnk on (2024-04-24 18:45:42 UTC): Sql for reproduction:

```
create database wrong_name_joined_table_db;

create table core_user (
    id serial primary key,
    user_name varchar
);

create table core_ticket (
    id serial primary key,
    asignee_id int,
    requester_id int,
    submitter_id int,
    ticket_name varchar
);

alter table core_ticket add constraint fk_asignee_core_user foreign key (asignee_id) references core_user(id);
alter table core_ticket add constraint fk_requester_core_user foreign key (requester_id) references core_user(id);
alter table core_ticket add constraint fk_submitter_core_user foreign key (submitter_id) references core_user(id);

insert into core_user (user_name) values ('a');
insert into core_user (user_name) values ('b');
insert into core_user (user_name) values ('c');

insert into core_ticket (asignee_id, requester_id, submitter_id, ticket_name) values (1, 2, 3, 'x');
```

"
2201234221,issue,open,,Learn about my data is super slow on big databases,"### Describe the bug

For some reason we're doing a very weird query to get the metadata on the ""learn about my data"" section

### To Reproduce

1) set up Metabase v49
2) use this little script to connect to the db and create massive amount of schemas and fields
(works with Bun runtime)
```
const { Sequelize } = require('sequelize');
import { generate } from ""random-words"";
// add your db details here
const config = {
  dialect: 'postgres',
  host: 'localhost',
  port: 5433,
  database: 'sample',
  username: 'metabase',
  password: 'metasample123',
};


const sequelize = new Sequelize(config);

let counter = 0;
let schema_name = generate().concat(""_1"");

while (true) {
  try {
    if (counter == 10) {
      counter = 0;
      schema_name = generate().concat(Math.floor(Math.random() * 100) + 1);
    }
    let table_name = generate().concat(Math.floor(Math.random() * 100) + 1);
    await sequelize.query(`CREATE SCHEMA IF NOT EXISTS ""${schema_name}"";`);
    await sequelize.query(`CREATE TABLE IF NOT EXISTS ""${schema_name}"".""${table_name}"" (
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" SMALLINT,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" VARCHAR(255),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" CHAR(10),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" BIGINT,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" SMALLINT,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DECIMAL(10,2),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" REAL,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DOUBLE PRECISION,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" BOOLEAN,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" DATE,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" TIMESTAMP,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" TIMESTAMPTZ,
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" VARCHAR(10),
      ""${generate().concat(Math.floor(Math.random() * 100) + 1)}"" CHAR(10)
    );`);
    await sequelize.query(`INSERT INTO ""${schema_name}"".""${table_name}"" VALUES 
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test'),
    (1, 'test', 'test', 1, 1, 1.1, 1.1, 1.1, true, '2021-01-01', '2021-01-01 00:00:00', '2021-01-01 00:00:00', 'test', 'test')
    ;`);
    counter++;
  } catch (err) {
    console.log(err);
  }
}
```

3) sync the db
4) go to learn about my table in any table and see what query we fire

### Expected behavior

_No response_

### Logs

```
SELECT * FROM ""metabase_field"" WHERE (""active"" = TRUE) AND (""table_id"" IN ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21, $22, $23, $24, $25, $26, $27, $28, $29, $30, $31, $32, $33, $34, $35, $36, $37, $38, $39, $40, $41, $42, $43, $44, $45, $46, $47, $48, $49, $50, $51, $52, $53, $54, $55, $56, $57, $58, $59, $60, $61, $62, $63, $64, $65, $66, $67, $68, $69, $70, $71, $72, $73, $74, $75, $76, $77, $78, $79, $80, $81, $82, $83, $84, $85, $86, $87, $88, $89, $90, $91, $92, $93, $94, $95, $96, $97, $98, $99, $100, $101, $102, $103, $104, $105, $106, $107, $108, $109, $110, $111, $112, $113, $114, $115, $116, $117, $118, $119, $120, $121, $122, $123, $124, $125, $126, $127, $128, $129, $130, $131, $132, $133, $134, $135, $136, $137, $138, $139, $140, $141, $142, $143, $144, $145, $146, $147, $148, $149, $150, $151, $152, $153, $154, $155, $156, $157, $158, $159, $160, $161, $162, $163, $164, $165, $166, $167, $168, $169, $170, $171, $172, $173, $174, $175, $176, $177, $178, $179, $180, $181, $182, $183, $184, $185, $186, $187, $188, $189, $190, $191, $192, $193, $194, $195, $196, $197, $198, $199, $200, $201, $202, $203, $204, $205, $206, $207, $208, $209, $210, $211, $212, $213, $214, $215, $216, $217, $218, $219, $220, $221, $222, $223, $224, $225, $226, $227, $228, $229, $230, $231, $232, $233, $234, $235, $236, $237, $238, $239, $240, $241, $242, $243, $244, $245, $246, $247, $248, $249, $250, $251, $252, $253, $254, $255, $256, $257, $258, $259, $260, $261, $262, $263, $264, $265, $266, $267, $268, $269, $270, $271, $272, $273, $274, $275, $276, $277, $278, $279, $280, $281, $282, $283, $284, $285, $286, $287, $288, $289, $290, $291, $292, $293, $294, $295, $296, $297, $298, $299, $300, $301, $302, $303, $304, $305, $306, $307, $308, $309, $310, $311, $312, $313, $314, $315, $316, $317, $318, $319, $320, $321, $322, $323, $324, $325, $326, $327, $328, $329, $330, $331, $332, $333, $334, $335, $336, $337, $338, $339, $340, $341, $342, $343, $344, $345, $346, $347, $348, $349, $350, $351, $352, $353, $354, $355, $356, $357, $358, $359, $360, $361, $362, $363, $364, $365, $366, $367, $368, $369, $370, $371, $372, $373, $374, $375, $376, $377, $378, $379, $380, $381, $382, $383, $384, $385, $386, $387, $388, $389, $390, $391, $392, $393, $394, $395, $396, $397, $398, $399, $400, $401, $402, $403, $404, $405, $406, $407, $408, $409, $410, $411, $412, $413, $414, $415, $416, $417, $418, $419, $420, $421, $422, $423, $424, $425, $426, $427, $428, $429, $430, $431, $432, $433, $434, $435, $436, $437, $438, $439, $440, $441, $442, $443, $444, $445, $446, $447, $448, $449, $450, $451, $452, $453, $454, $455, $456, $457, $458, $459, $460, $461, $462, $463, $464, $465, $466, $467, $468, $469, $470, $471, $472, $473, $474, $475, $476, $477, $478, $479, $480, $481, $482, $483, $484, $485, $486, $487, $488, $489, $490, $491, $492, $493, $494, $495, $496, $497, $498, $499, $500, $501, $502, $503, $504, $505, $506, $507, $508, $509, $510, $511, $512, $513, $514, $515, $516, $517, $518, $519, $520, $521, $522, $523, $524, $525, $526, $527, $528, $529, $530, $531, $532, $533, $534, $535, $536, $537, $538, $539, $540, $541, $542, $543, $544, $545, $546, $547, $548, $549, $550, $551, $552, $553, $554, $555, $556, $557, $558, $559, $560, $561, $562, $563, $564, $565, $566, $567, $568, $569, $570, $571, $572, $573, $574, $575, $576, $577, $578, $579, $580, $581, $582, $583, $584, $585, $586, $587, $588, $589, $590, $591, $592, $593, $594, $595, $596, $597, $598, $599, $600, $601, $602, $603, $604, $605, $606, $607, $608, $609, $610, $611, $612, $613, $614, $615, $616, $617, $618, $619, $620, $621, $622, $623, $624, $625, $626, $627, $628, $629, $630, $631, $632, $633, $634, $635, $636, $637, $638, $639, $640, $641, $642, $643, $644, $645, $646, $647, $648, $649, $650, $651, $652, $653, $654, $655, $656, $657, $658, $659, $660, $661, $662, $663, $664, $665, $666, $667, $668, $669, $670, $671, $672, $673, $674, $675, $676, $677, $678, $679, $680, $681, $682, $683, $684, $685, $686, $687, $688, $689, $690, $691, $692, $693, $694, $695, $696, $697, $698, $699, $700, $701, $702, $703, $704, $705, $706, $707, $708, $709, $710, $711, $712, $713, $714, $715, $716, $717, $718, $719, $720, $721, $722, $723, $724, $725, $726, $727, $728, $729, $730, $731, $732, $733, $734, $735, $736, $737, $738, $739, $740, $741, $742, $743, $744, $745, $746, $747, $748, $749, $750, $751, $752, $753, $754, $755, $756, $757, $758, $759, $760, $761, $762, $763, $764, $765, $766, $767, $768, $769, $770, $771, $772, $773, $774, $775, $776, $777, $778, $779, $780, $781, $782, $783, $784, $785, $786, $787, $788, $789, $790, $791, $792, $793, $794, $795, $796, $797, $798, $799, $800, $801, $802, $803, $804, $805, $806, $807, $808, $809, $810, $811, $812, $813, $814, $815, $816, $817, $818, $819, $820, $821, $822, $823, $824, $825, $826, $827, $828, $829, $830, $831, $832, $833, $834, $835, $836, $837, $838, $839, $840, $841, $842, $843, $844, $845, $846, $847, $848, $849, $850, $851, $852, $853, $854, $855, $856, $857, $858, $859, $860, $861, $862, $863, $864, $865, $866, $867, $868, $869, $870, $871, $872, $873, $874, $875, $876, $877, $878, $879, $880, $881, $882, $883, $884, $885, $886, $887, $888, $889, $890, $891, $892, $893, $894, $895, $896, $897, $898, $899, $900, $901, $902, $903, $904, $905, $906, $907, $908, $909, $910, $911, $912, $913, $914, $915, $916, $917, $918, $919, $920, $921, $922, $923, $924, $925, $926, $927, $928, $929, $930, $931, $932, $933, $934, $935, $936, $937, $938, $939, $940, $941, $942, $943, $944, $945, $946, $947, $948, $949, $950, $951, $952, $953, $954, $955, $956, $957, $958, $959, $960, $961, $962, $963, $964, $965, $966, $967, $968, $969, $970, $971, $972, $973, $974, $975, $976, $977, $978, $979, $980, $981, $982, $983, $984, $985, $986, $987, $988, $989, $990, $991, $992, $993, $994, $995, $996, $997, $998, $999, $1000, $1001, $1002, $1003, $1004, $1005, $1006, $1007, $1008, $1009, $1010, $1011, $1012, $1013, $1014, $1015, $1016, $1017, $1018, $1019, $1020, $1021, $1022, $1023, $1024, $1025, $1026, $1027, $1028, $1029, $1030, $1031,  ....
```

### Information about your Metabase installation

```JSON
v49, but pretty sure this comes from a few versions ago
```


### Severity

P3

### Additional context

Why are we asking for all those fields? most definitely the problem is that we're calling /api/database/2/metadata",paoliniluis,2024-03-21 21:36:07+00:00,[],2024-06-20 16:10:49+00:00,,https://github.com/metabase/metabase/issues/40476,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Performance', ''), ('Organization/Data Reference', ''), ('.Frontend', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2150517148, 'issue_id': 2201234221, 'author': 'luizarakaki', 'body': 'Removing this from the board as we are intentionally not prioritizing data reference work now.\r\nWe will likely revamp the feature completely and fix many bugs/opportunities', 'created_at': datetime.datetime(2024, 6, 5, 16, 48, 2, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-06-05 16:48:02 UTC): Removing this from the board as we are intentionally not prioritizing data reference work now.
We will likely revamp the feature completely and fix many bugs/opportunities

"
2201142515,issue,closed,completed,Attaching CSV files to a subscription leads to a NullPointerException,"### Describe the bug

Generating a subscription and adding attachments to it will generate a stack trace

### To Reproduce

1) start v49
2) generate a dashboard with an x-ray (e.g. accounts table)
3) add a subscription
4) make it send with attachments (only with CSV)
5) click save

### Expected behavior

subscription should send

### Logs

```
{
    ""via"": [
        {
            ""type"": ""java.lang.NullPointerException"",
            ""at"": [
                ""clojure.lang.RT"",
                ""doubleCast"",
                ""RT.java"",
                1353
            ]
        }
    ],
    ""trace"": [
        [
            ""clojure.lang.RT"",
            ""doubleCast"",
            ""RT.java"",
            1353
        ],
        [
            ""metabase.formatter$format_geographic_coordinates"",
            ""invoke"",
            ""formatter.clj"",
            -1
        ],
        [
            ""clojure.core$partial$fn__5908"",
            ""invoke"",
            ""core.clj"",
            2641
        ],
        [
            ""metabase.query_processor.streaming.csv$fn$reify__52333$fn__52352"",
            ""invoke"",
            ""csv.clj"",
            46
        ],
        [
            ""clojure.core$map$fn__5939"",
            ""invoke"",
            ""core.clj"",
            2777
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            51
        ],
        [
            ""clojure.lang.RT"",
            ""seq"",
            ""RT.java"",
            535
        ],
        [
            ""clojure.core$seq__5467"",
            ""invokeStatic"",
            ""core.clj"",
            139
        ],
        [
            ""clojure.core$seq__5467"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""clojure.data.csv$write_record"",
            ""invokeStatic"",
            ""csv.clj"",
            113
        ],
        [
            ""clojure.data.csv$write_record"",
            ""invoke"",
            ""csv.clj"",
            111
        ],
        [
            ""clojure.data.csv$write_csv_STAR_"",
            ""invokeStatic"",
            ""csv.clj"",
            123
        ],
        [
            ""clojure.data.csv$write_csv_STAR_"",
            ""invoke"",
            ""csv.clj"",
            119
        ],
        [
            ""clojure.data.csv$write_csv"",
            ""invokeStatic"",
            ""csv.clj"",
            141
        ],
        [
            ""clojure.data.csv$write_csv"",
            ""doInvoke"",
            ""csv.clj"",
            127
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            425
        ],
        [
            ""metabase.query_processor.streaming.csv$fn$reify__52333"",
            ""write_row_BANG_"",
            ""csv.clj"",
            45
        ],
        [
            ""metabase.email.messages$stream_api_results_to_export_format$fn__76000$fn__76001$fn__76005"",
            ""invoke"",
            ""messages.clj"",
            425
        ],
        [
            ""clojure.core$map_indexed$mapi__8638$fn__8639"",
            ""invoke"",
            ""core.clj"",
            7377
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            51
        ],
        [
            ""clojure.lang.ChunkedCons"",
            ""chunkedNext"",
            ""ChunkedCons.java"",
            59
        ],
        [
            ""clojure.lang.ChunkedCons"",
            ""next"",
            ""ChunkedCons.java"",
            43
        ],
        [
            ""clojure.lang.RT"",
            ""next"",
            ""RT.java"",
            713
        ],
        [
            ""clojure.core$next__5451"",
            ""invokeStatic"",
            ""core.clj"",
            64
        ],
        [
            ""clojure.core$dorun"",
            ""invokeStatic"",
            ""core.clj"",
            3144
        ],
        [
            ""clojure.core$dorun"",
            ""invoke"",
            ""core.clj"",
            3135
        ],
        [
            ""metabase.email.messages$stream_api_results_to_export_format$fn__76000$fn__76001"",
            ""invoke"",
            ""messages.clj"",
            422
        ],
        [
            ""metabase.query_processor.store$do_with_metadata_provider"",
            ""invokeStatic"",
            ""store.clj"",
            169
        ],
        [
            ""metabase.query_processor.store$do_with_metadata_provider"",
            ""invoke"",
            ""store.clj"",
            150
        ],
        [
            ""metabase.query_processor.store$do_with_metadata_provider"",
            ""invokeStatic"",
            ""store.clj"",
            158
        ],
        [
            ""metabase.query_processor.store$do_with_metadata_provider"",
            ""invoke"",
            ""store.clj"",
            150
        ],
        [
            ""metabase.email.messages$stream_api_results_to_export_format$fn__76000"",
            ""invoke"",
            ""messages.clj"",
            412
        ],
        [
            ""metabase.driver$do_with_driver"",
            ""invokeStatic"",
            ""driver.clj"",
            97
        ],
        [
            ""metabase.driver$do_with_driver"",
            ""invoke"",
            ""driver.clj"",
            92
        ],
        [
            ""metabase.email.messages$stream_api_results_to_export_format"",
            ""invokeStatic"",
            ""messages.clj"",
            411
        ],
        [
            ""metabase.email.messages$stream_api_results_to_export_format"",
            ""invoke"",
            ""messages.clj"",
            399
        ],
        [
            ""metabase.email.messages$result_attachment$fn__76015"",
            ""invoke"",
            ""messages.clj"",
            435
        ],
        [
            ""metabase.email.messages$result_attachment"",
            ""invokeStatic"",
            ""messages.clj"",
            434
        ],
        [
            ""metabase.email.messages$result_attachment"",
            ""invoke"",
            ""messages.clj"",
            429
        ],
        [
            ""clojure.core$map$fn__5935"",
            ""invoke"",
            ""core.clj"",
            2772
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            51
        ],
        [
            ""clojure.lang.Cons"",
            ""next"",
            ""Cons.java"",
            39
        ],
        [
            ""clojure.lang.RT"",
            ""next"",
            ""RT.java"",
            713
        ],
        [
            ""clojure.core$next__5451"",
            ""invokeStatic"",
            ""core.clj"",
            64
        ],
        [
            ""clojure.core$concat$cat__5560$fn__5561"",
            ""invoke"",
            ""core.clj"",
            744
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            58
        ],
        [
            ""clojure.lang.RT"",
            ""seq"",
            ""RT.java"",
            535
        ],
        [
            ""clojure.core$seq__5467"",
            ""invokeStatic"",
            ""core.clj"",
            139
        ],
        [
            ""clojure.core$filter$fn__5962"",
            ""invoke"",
            ""core.clj"",
            2826
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            51
        ],
        [
            ""clojure.lang.RT"",
            ""seq"",
            ""RT.java"",
            535
        ],
        [
            ""clojure.core$seq__5467"",
            ""invokeStatic"",
            ""core.clj"",
            139
        ],
        [
            ""clojure.core$concat$cat__5560$fn__5561"",
            ""invoke"",
            ""core.clj"",
            736
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            51
        ],
        [
            ""clojure.lang.ChunkedCons"",
            ""chunkedNext"",
            ""ChunkedCons.java"",
            59
        ],
        [
            ""clojure.lang.ChunkedCons"",
            ""next"",
            ""ChunkedCons.java"",
            43
        ],
        [
            ""clojure.lang.PersistentVector"",
            ""create"",
            ""PersistentVector.java"",
            73
        ],
        [
            ""clojure.lang.LazilyPersistentVector"",
            ""create"",
            ""LazilyPersistentVector.java"",
            44
        ],
        [
            ""clojure.core$vec"",
            ""invokeStatic"",
            ""core.clj"",
            379
        ],
        [
            ""clojure.core$vec"",
            ""invoke"",
            ""core.clj"",
            369
        ],
        [
            ""metabase.email.messages$render_message_body"",
            ""invokeStatic"",
            ""messages.clj"",
            514
        ],
        [
            ""metabase.email.messages$render_message_body"",
            ""invoke"",
            ""messages.clj"",
            500
        ],
        [
            ""metabase.email.messages$render_pulse_email"",
            ""invokeStatic"",
            ""messages.clj"",
            529
        ],
        [
            ""metabase.email.messages$render_pulse_email"",
            ""invoke"",
            ""messages.clj"",
            526
        ],
        [
            ""metabase.pulse$fn__99478"",
            ""invokeStatic"",
            ""pulse.clj"",
            442
        ],
        [
            ""metabase.pulse$fn__99478"",
            ""invoke"",
            ""pulse.clj"",
            431
        ],
        [
            ""clojure.lang.MultiFn"",
            ""invoke"",
            ""MultiFn.java"",
            239
        ],
        [
            ""metabase.pulse$parts__GT_notifications$iter__99553__99557$fn__99558$fn__99559"",
            ""invoke"",
            ""pulse.clj"",
            513
        ],
        [
            ""metabase.pulse$parts__GT_notifications$iter__99553__99557$fn__99558"",
            ""invoke"",
            ""pulse.clj"",
            511
        ],
        [
            ""clojure.lang.LazySeq"",
            ""sval"",
            ""LazySeq.java"",
            42
        ],
        [
            ""clojure.lang.LazySeq"",
            ""seq"",
            ""LazySeq.java"",
            51
        ],
        [
            ""clojure.lang.RT"",
            ""seq"",
            ""RT.java"",
            535
        ],
        [
            ""clojure.core$seq__5467"",
            ""invokeStatic"",
            ""core.clj"",
            139
        ],
        [
            ""clojure.core$seq__5467"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""metabase.pulse$send_notifications_BANG_"",
            ""invokeStatic"",
            ""pulse.clj"",
            566
        ],
        [
            ""metabase.pulse$send_notifications_BANG_"",
            ""invoke"",
            ""pulse.clj"",
            565
        ],
        [
            ""metabase.pulse$send_pulse_BANG_"",
            ""invokeStatic"",
            ""pulse.clj"",
            593
        ],
        [
            ""metabase.pulse$send_pulse_BANG_"",
            ""doInvoke"",
            ""pulse.clj"",
            574
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            410
        ],
        [
            ""metabase.api.pulse$fn__101746"",
            ""invokeStatic"",
            ""pulse.clj"",
            349
        ],
        [
            ""metabase.api.pulse$fn__101746"",
            ""invoke"",
            ""pulse.clj"",
            331
        ],
        [
            ""compojure.core$wrap_response$fn__44651"",
            ""invoke"",
            ""core.clj"",
            160
        ],
        [
            ""compojure.core$wrap_route_middleware$fn__44635"",
            ""invoke"",
            ""core.clj"",
            132
        ],
        [
            ""compojure.core$wrap_route_info$fn__44640"",
            ""invoke"",
            ""core.clj"",
            139
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            151
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            152
        ],
        [
            ""clojure.lang.Var"",
            ""invoke"",
            ""Var.java"",
            393
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.pulse.preview$style_tag_nonce_middleware$fn__99898"",
            ""invoke"",
            ""preview.clj"",
            165
        ],
        [
            ""metabase.server.middleware.auth$enforce_authentication$fn__94374"",
            ""invoke"",
            ""auth.clj"",
            17
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44691"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.api.routes$fn__102349$fn__102350"",
            ""invoke"",
            ""routes.clj"",
            65
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""clojure.lang.AFn"",
            ""applyToHelper"",
            ""AFn.java"",
            160
        ],
        [
            ""clojure.lang.AFn"",
            ""applyTo"",
            ""AFn.java"",
            144
        ],
        [
            ""clojure.core$apply"",
            ""invokeStatic"",
            ""core.clj"",
            667
        ],
        [
            ""clojure.core$apply"",
            ""invoke"",
            ""core.clj"",
            662
        ],
        [
            ""metabase.server.routes$fn__102514$fn__102515"",
            ""doInvoke"",
            ""routes.clj"",
            72
        ],
        [
            ""clojure.lang.RestFn"",
            ""invoke"",
            ""RestFn.java"",
            436
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44691"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$wrap_route_matches$fn__44644"",
            ""invoke"",
            ""core.clj"",
            153
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            199
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$make_context$handler__44691"",
            ""invoke"",
            ""core.clj"",
            290
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            300
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664$respond_SINGLEQUOTE___44665"",
            ""invoke"",
            ""core.clj"",
            197
        ],
        [
            ""compojure.core$make_context$fn__44695"",
            ""invoke"",
            ""core.clj"",
            301
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""compojure.core$routes$fn__44663$f__44664"",
            ""invoke"",
            ""core.clj"",
            198
        ],
        [
            ""compojure.core$routes$fn__44663"",
            ""invoke"",
            ""core.clj"",
            200
        ],
        [
            ""metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__99129"",
            ""invoke"",
            ""exceptions.clj"",
            108
        ],
        [
            ""metabase.server.middleware.exceptions$catch_api_exceptions$fn__99126"",
            ""invoke"",
            ""exceptions.clj"",
            96
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__104827$fn__104828$fn__104829"",
            ""invoke"",
            ""log.clj"",
            216
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invokeStatic"",
            ""diagnostic.clj"",
            18
        ],
        [
            ""metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info"",
            ""invoke"",
            ""diagnostic.clj"",
            12
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__104827$fn__104828"",
            ""invoke"",
            ""log.clj"",
            208
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invokeStatic"",
            ""execute.clj"",
            112
        ],
        [
            ""toucan2.execute$do_with_call_counts"",
            ""invoke"",
            ""execute.clj"",
            103
        ],
        [
            ""metabase.server.middleware.log$log_api_call$fn__104827"",
            ""invoke"",
            ""log.clj"",
            207
        ],
        [
            ""metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__109617"",
            ""invoke"",
            ""browser_cookie.clj"",
            40
        ],
        [
            ""metabase.server.middleware.security$add_security_headers$fn__85263"",
            ""invoke"",
            ""security.clj"",
            182
        ],
        [
            ""metabase.server.middleware.json$wrap_json_body$fn__46008"",
            ""invoke"",
            ""json.clj"",
            67
        ],
        [
            ""metabase.server.middleware.offset_paging$handle_paging$fn__85287"",
            ""invoke"",
            ""offset_paging.clj"",
            45
        ],
        [
            ""metabase.server.middleware.json$wrap_streamed_json_response$fn__46026"",
            ""invoke"",
            ""json.clj"",
            103
        ],
        [
            ""ring.middleware.keyword_params$wrap_keyword_params$fn__109884"",
            ""invoke"",
            ""keyword_params.clj"",
            55
        ],
        [
            ""ring.middleware.params$wrap_params$fn__109903"",
            ""invoke"",
            ""params.clj"",
            77
        ],
        [
            ""metabase.server.middleware.misc$maybe_set_site_url$fn__66974"",
            ""invoke"",
            ""misc.clj"",
            61
        ],
        [
            ""metabase.server.middleware.session$reset_session_timeout$fn__72389"",
            ""invoke"",
            ""session.clj"",
            543
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__72355$fn__72356"",
            ""invoke"",
            ""session.clj"",
            438
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invokeStatic"",
            ""session.clj"",
            417
        ],
        [
            ""metabase.server.middleware.session$do_with_current_user"",
            ""invoke"",
            ""session.clj"",
            401
        ],
        [
            ""metabase.server.middleware.session$bind_current_user$fn__72355"",
            ""invoke"",
            ""session.clj"",
            437
        ],
        [
            ""metabase.server.middleware.session$wrap_current_user_info$fn__72338"",
            ""invoke"",
            ""session.clj"",
            376
        ],
        [
            ""metabase.server.middleware.session$wrap_session_id$fn__72310"",
            ""invoke"",
            ""session.clj"",
            255
        ],
        [
            ""metabase.server.middleware.auth$wrap_static_api_key$fn__94382"",
            ""invoke"",
            ""auth.clj"",
            30
        ],
        [
            ""ring.middleware.cookies$wrap_cookies$fn__109804"",
            ""invoke"",
            ""cookies.clj"",
            194
        ],
        [
            ""metabase.server.middleware.misc$add_content_type$fn__66956"",
            ""invoke"",
            ""misc.clj"",
            29
        ],
        [
            ""metabase.server.middleware.misc$disable_streaming_buffering$fn__66982"",
            ""invoke"",
            ""misc.clj"",
            78
        ],
        [
            ""ring.middleware.gzip$wrap_gzip$fn__109846"",
            ""invoke"",
            ""gzip.clj"",
            86
        ],
        [
            ""metabase.server.middleware.misc$bind_request$fn__66985"",
            ""invoke"",
            ""misc.clj"",
            95
        ],
        [
            ""metabase.server.middleware.ssl$redirect_to_https_middleware$fn__109633"",
            ""invoke"",
            ""ssl.clj"",
            51
        ],
        [
            ""metabase.server$async_proxy_handler$fn__67396"",
            ""invoke"",
            ""server.clj"",
            78
        ],
        [
            ""metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a"",
            ""handle"",
            null,
            -1
        ],
        [
            ""org.eclipse.jetty.server.handler.StatisticsHandler"",
            ""handle"",
            ""StatisticsHandler.java"",
            173
        ],
        [
            ""org.eclipse.jetty.server.handler.HandlerWrapper"",
            ""handle"",
            ""HandlerWrapper.java"",
            122
        ],
        [
            ""org.eclipse.jetty.server.Server"",
            ""handle"",
            ""Server.java"",
            563
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel$RequestDispatchable"",
            ""dispatch"",
            ""HttpChannel.java"",
            1598
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""dispatch"",
            ""HttpChannel.java"",
            753
        ],
        [
            ""org.eclipse.jetty.server.HttpChannel"",
            ""handle"",
            ""HttpChannel.java"",
            501
        ],
        [
            ""org.eclipse.jetty.server.HttpConnection"",
            ""onFillable"",
            ""HttpConnection.java"",
            287
        ],
        [
            ""org.eclipse.jetty.io.AbstractConnection$ReadCallback"",
            ""succeeded"",
            ""AbstractConnection.java"",
            314
        ],
        [
            ""org.eclipse.jetty.io.FillInterest"",
            ""fillable"",
            ""FillInterest.java"",
            100
        ],
        [
            ""org.eclipse.jetty.io.SelectableChannelEndPoint$1"",
            ""run"",
            ""SelectableChannelEndPoint.java"",
            53
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""runTask"",
            ""AdaptiveExecutionStrategy.java"",
            421
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""consumeTask"",
            ""AdaptiveExecutionStrategy.java"",
            390
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""tryProduce"",
            ""AdaptiveExecutionStrategy.java"",
            277
        ],
        [
            ""org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy"",
            ""run"",
            ""AdaptiveExecutionStrategy.java"",
            199
        ],
        [
            ""org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread"",
            ""run"",
            ""ReservedThreadExecutor.java"",
            411
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool"",
            ""runJob"",
            ""QueuedThreadPool.java"",
            969
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""doRunJob"",
            ""QueuedThreadPool.java"",
            1194
        ],
        [
            ""org.eclipse.jetty.util.thread.QueuedThreadPool$Runner"",
            ""run"",
            ""QueuedThreadPool.java"",
            1149
        ],
        [
            ""java.lang.Thread"",
            ""run"",
            ""Thread.java"",
            829
        ]
    ],
    ""message"": null
}
```

### Information about your Metabase installation

```JSON
v49
postgres
brave
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-03-21 20:41:36+00:00,['crisptrutski'],2024-03-25 13:58:10+00:00,2024-03-25 11:22:52+00:00,https://github.com/metabase/metabase/issues/40472,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Workflows', 'aka BEC')]",[],
2201091603,issue,closed,completed,CSV Replacement Frontend,,iethree,2024-03-21 20:14:21+00:00,['iethree'],2024-03-26 17:08:20+00:00,2024-03-26 17:08:20+00:00,https://github.com/metabase/metabase/issues/40469,"[('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2201081319,issue,closed,completed,Data Picker,,iethree,2024-03-21 20:09:22+00:00,[],2024-12-20 14:49:52+00:00,2024-12-20 14:49:52+00:00,https://github.com/metabase/metabase/issues/40468,[],[],
2200750572,issue,open,,Option to hide a column with all nulls in Table Visualization,"Example:
Let's say we have a Table Visualization for car brand sales in different countries and cities like below:

| Country      | City | Toyota | Izera | Tesla | Tata |
| - | - | -| -|-|-|
| India | Mumbai | 123 | null | 111 | 333 | 
| India | Delhi | 321 | null | 322 | 123 |
| Poland | Warsaw | 232 | 123 | 112 | null |
| Poland | Krakow |  131 | 111 | 88 | null |

Now if we filter by country and select e.g. India we get a useless column for Izera which isn't selling in this country. Same thing for Tata in Poland.

It would be lovely to have an option in Visualization config to hide a column with all nulls when displaying filtered results. This would be useful both on Question/Query level as well as in Dashboards. Even better if we could specify a value other than null for that.

With such an option a dashboard user could use a filter to select Poland and have Tata column hidden or select India and have Izera column hidden, making the visualization much more clear.",michal-billtech,2024-03-21 17:14:38+00:00,[],2024-03-26 13:25:42+00:00,,https://github.com/metabase/metabase/issues/40460,"[('Type:New Feature', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]","[{'comment_id': 2020423605, 'issue_id': 2200750572, 'author': 'paoliniluis', 'body': ""The issue is that we'll have to auto-adapt the entire frontend as tables might or might not have columns with this"", 'created_at': datetime.datetime(2024, 3, 26, 13, 24, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2020425961, 'issue_id': 2200750572, 'author': 'paoliniluis', 'body': 'What I would do is pivot the brands as rows and then use the normal table viz that should not show values that are null', 'created_at': datetime.datetime(2024, 3, 26, 13, 25, 41, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-26 13:24:38 UTC): The issue is that we'll have to auto-adapt the entire frontend as tables might or might not have columns with this

paoliniluis on (2024-03-26 13:25:41 UTC): What I would do is pivot the brands as rows and then use the normal table viz that should not show values that are null

"
2200414415,issue,open,,Add NETWORKDAYS Function,"**Is your feature request related to a problem? Please describe.**
Metabase allows you to convert dates to days of week but does not have an easy way to build custom columns that show the difference between two dates only counting weekdays. 

**Describe the solution you'd like**
I would like a similar function to excels ""NETWORKDAYS"" that allows you to input 2 dates and calculate workdays in between. 

**Describe alternatives you've considered**
It's possible currently but involves a mess of SQL

**How important is this feature to you?**
Would improve ease of use considerably.

**Additional context**
https://support.microsoft.com/en-us/office/networkdays-function-48e717bf-a7a3-495f-969e-5005e3eb18e7",nstanton,2024-03-21 14:54:26+00:00,[],2024-03-21 15:46:24+00:00,,https://github.com/metabase/metabase/issues/40449,"[('Type:New Feature', ''), ('Querying/Notebook/Custom Column', '')]",[],
2200290265,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/flex.module.css`,,oisincoveney,2024-03-21 14:05:22+00:00,['oisincoveney'],2024-03-22 16:02:15+00:00,2024-03-22 16:02:15+00:00,https://github.com/metabase/metabase/issues/40444,[],[],
2199944827,issue,closed,completed,Replace `CollectionDatasetOrDataSourceSelector` in `DataStep` (starting data picker in notebook editor),https://metaboat.slack.com/archives/C064EB1UE5P/p1710512707342349,kamilmielnik,2024-03-21 11:37:34+00:00,[],2024-03-21 11:42:20+00:00,2024-03-21 11:42:12+00:00,https://github.com/metabase/metabase/issues/40437,[],[],
2199833500,issue,closed,completed,"If there are new columns in the data source after the question was saved, they are hidden by default","https://metaboat.slack.com/archives/C01LQQ2UW03/p1710866450928429

To reproduce:
- New -> Question -> Orders -> Pick ID and User ID -> Save
- Visualize
- Hide & show columns in the table viz settings
- Go to notebook -> Fields -> Enable Product ID -> Save without visualizing
- Visualize
- Only 2 columns would be visible by default - ID and User ID

Expected:
- Product ID should be visible unless explicitly hidden",ranquild,2024-03-21 10:49:49+00:00,['ranquild'],2024-03-21 15:08:22+00:00,2024-03-21 15:07:42+00:00,https://github.com/metabase/metabase/issues/40435,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]",[],
2199695452,issue,closed,not_planned,No table are read in Starrocks ,"### Describe the bug

I have created connection to Starrocks 3.2.3 and Metabase 49.x, 48.x
They all failed to read tables in Starrocks. 
But in Starrocks 3.2.2, Metabase read data normally.

I'm not sure it could be Metabase's bug or Starrocks's bug.



### To Reproduce

1. Add database connection to  Starrocks 3.2.3 
2. No tables are read even I have clicked 'Sync database schema now' several times.


### Expected behavior

It should read all table.

### Logs

![image](https://github.com/metabase/metabase/assets/16459517/c514d90d-b89d-4432-b6a2-b5ef492982bd)


```
2024-03-21 18:54:28,563 WARN driver.mysql :: 

********************************************************************************
WARNING: Metabase only officially supports MySQL 5.7/MariaDB 10.2 and above.
All Metabase features may not work properly when using an unsupported version.
********************************************************************************

2024-03-21 18:54:28,564 INFO sync.util :: STARTING: Sync metadata for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,564 DEBUG middleware.log :: POST /api/database/2/sync_schema 200 26.6 ms (3 DB calls) App DB connections: 1/7 Jetty threads: 8/50 (8 idle, 0 queued) (51 total active threads) Queries in flight: 0 (0 queued)
2024-03-21 18:54:28,623 INFO sync.util :: STARTING: step ''sync-dbms-version'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,626 INFO sync.util :: FINISHED: step ''sync-dbms-version'' for mysql Database 2 ''Starrocks'' (2.6 ms)
2024-03-21 18:54:28,626 INFO sync.util :: STARTING: step ''sync-timezone'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,629 WARN sync.util :: Error running step ''sync-timezone'' for mysql Database 2 ''Starrocks''
java.sql.SQLTransientConnectionException: (conn=89) Getting analyzing error from line 1, column 73 to line 1, column 173. Detail message: No matching function with signature: time_format(TIME, varchar).
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.createException(ExceptionFactory.java:79)
        at org.mariadb.jdbc.internal.util.exceptions.ExceptionFactory.create(ExceptionFactory.java:158)
        at org.mariadb.jdbc.MariaDbStatement.executeExceptionEpilogue(MariaDbStatement.java:262)
        at org.mariadb.jdbc.ClientSidePreparedStatement.executeInternal(ClientSidePreparedStatement.java:229)
        at org.mariadb.jdbc.ClientSidePreparedStatement.execute(ClientSidePreparedStatement.java:149)
        at org.mariadb.jdbc.ClientSidePreparedStatement.executeQuery(ClientSidePreparedStatement.java:163)
        at com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeQuery(NewProxyPreparedStatement.java:1471)
        at clojure.java.jdbc$execute_query_with_params.invokeStatic(jdbc.clj:1090)
        at clojure.java.jdbc$execute_query_with_params.invoke(jdbc.clj:1084)
        at clojure.java.jdbc$db_query_with_resultset_STAR_.invokeStatic(jdbc.clj:1113)
        at clojure.java.jdbc$db_query_with_resultset_STAR_.invoke(jdbc.clj:1093)
        at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1182)
        at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
        at clojure.java.jdbc$query.invokeStatic(jdbc.clj:1160)
        at clojure.java.jdbc$query.invoke(jdbc.clj:1144)
        at metabase.driver.mysql$fn__103596.invokeStatic(mysql.clj:232)
        at metabase.driver.mysql$fn__103596.invoke(mysql.clj:222)
        at clojure.lang.MultiFn.invoke(MultiFn.java:234)
        at metabase.driver.sql_jdbc$fn__106405.invokeStatic(sql_jdbc.clj:72)
        at metabase.driver.sql_jdbc$fn__106405.invoke(sql_jdbc.clj:67)
        at clojure.lang.MultiFn.invoke(MultiFn.java:234)
        at metabase.sync.sync_metadata.sync_timezone$sync_timezone_BANG_.invokeStatic(sync_timezone.clj:41)
        at metabase.sync.sync_metadata.sync_timezone$sync_timezone_BANG_.invoke(sync_timezone.clj:36)
        at clojure.lang.AFn.applyToHelper(AFn.java:154)
        at clojure.lang.AFn.applyTo(AFn.java:144)
        at clojure.core$apply.invokeStatic(core.clj:669)
        at clojure.core$apply.invoke(core.clj:662)
        at metabase.sync.util$run_step_with_metadata$fn__60171.doInvoke(util.clj:462)
        at clojure.lang.RestFn.invoke(RestFn.java:397)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:131)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:125)
        at metabase.sync.util$with_start_and_finish_debug_logging.invokeStatic(util.clj:149)
        at metabase.sync.util$with_start_and_finish_debug_logging.invoke(util.clj:145)
        at metabase.sync.util$run_step_with_metadata.invokeStatic(util.clj:457)
        at metabase.sync.util$run_step_with_metadata.invoke(util.clj:452)
        at metabase.sync.util$run_sync_operation$fn__60250.invoke(util.clj:568)
        at metabase.sync.util$run_sync_operation.invokeStatic(util.clj:566)
        at metabase.sync.util$run_sync_operation.invoke(util.clj:560)
        at metabase.sync.sync_metadata$sync_db_metadata_BANG_$fn__82158.invoke(sync_metadata.clj:70)
        at metabase.sync.util$do_with_error_handling.invokeStatic(util.clj:190)
        at metabase.sync.util$do_with_error_handling.invoke(util.clj:183)
        at clojure.core$partial$fn__5910.invoke(core.clj:2647)
        at metabase.driver$fn__49757.invokeStatic(driver.clj:778)
        at metabase.driver$fn__49757.invoke(driver.clj:778)
        at clojure.lang.MultiFn.invoke(MultiFn.java:239)
        at metabase.sync.util$sync_in_context$fn__60085.invoke(util.clj:166)
        at metabase.sync.util$with_db_logging_disabled$fn__60082.invoke(util.clj:158)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invokeStatic(util.clj:131)
        at metabase.sync.util$with_start_and_finish_logging_STAR_.invoke(util.clj:125)
        at metabase.sync.util$with_start_and_finish_logging$fn__60069.invoke(util.clj:143)
        at metabase.sync.util$with_sync_events$fn__60064.invoke(util.clj:117)
        at metabase.sync.util$with_duplicate_ops_prevented$fn__60051.invoke(util.clj:89)
        at metabase.sync.util$do_sync_operation.invokeStatic(util.clj:215)
        at metabase.sync.util$do_sync_operation.invoke(util.clj:209)
        at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invokeStatic(sync_metadata.clj:68)
        at metabase.sync.sync_metadata$sync_db_metadata_BANG_.invoke(sync_metadata.clj:65)
        at metabase.api.database$fn__98315$fn__98320.invoke(database.clj:1010)
        at clojure.core$binding_conveyor_fn$fn__5823.invoke(core.clj:2047)
        at clojure.lang.AFn.call(AFn.java:18)
        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
        at java.base/java.lang.Thread.run(Thread.java:833)
Caused by: org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException: Getting analyzing error from line 1, column 73 to line 1, column 173. Detail message: No matching function with signature: time_format(TIME, varchar).
        at org.mariadb.jdbc.internal.util.exceptions.MariaDbSqlException.of(MariaDbSqlException.java:34)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:195)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.exceptionWithQuery(AbstractQueryProtocol.java:178)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:322)
        at org.mariadb.jdbc.ClientSidePreparedStatement.executeInternal(ClientSidePreparedStatement.java:220)
        ... 59 more
Caused by: java.sql.SQLException: Getting analyzing error from line 1, column 73 to line 1, column 173. Detail message: No matching function with signature: time_format(TIME, varchar).
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readErrorPacket(AbstractQueryProtocol.java:1693)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1555)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)
        at org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:319)
        ... 60 more
2024-03-21 18:54:28,629 INFO sync.util :: FINISHED: step ''sync-timezone'' for mysql Database 2 ''Starrocks'' (3.0 ms)
2024-03-21 18:54:28,630 INFO sync.util :: STARTING: step ''sync-tables'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,632 INFO sync.util :: FINISHED: step ''sync-tables'' for mysql Database 2 ''Starrocks'' (2.5 ms)
2024-03-21 18:54:28,632 INFO sync.util :: STARTING: step ''sync-fields'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,633 INFO sync.util :: FINISHED: step ''sync-fields'' for mysql Database 2 ''Starrocks'' (1.1 ms)
2024-03-21 18:54:28,633 INFO sync.util :: STARTING: step ''sync-fks'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,636 INFO sync.util :: FINISHED: step ''sync-fks'' for mysql Database 2 ''Starrocks'' (2.1 ms)
2024-03-21 18:54:28,636 INFO sync.util :: STARTING: step ''sync-indexes'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,637 INFO sync.util :: FINISHED: step ''sync-indexes'' for mysql Database 2 ''Starrocks'' (907.4 Œºs)
2024-03-21 18:54:28,637 INFO sync.util :: STARTING: step ''sync-metabase-metadata'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,637 INFO sync.util :: FINISHED: step ''sync-metabase-metadata'' for mysql Database 2 ''Starrocks'' (78.2 Œºs)
2024-03-21 18:54:28,637 INFO sync.util :: STARTING: step ''sync-table-privileges'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,637 INFO sync.util :: FINISHED: step ''sync-table-privileges'' for mysql Database 2 ''Starrocks'' (81.7 Œºs)
2024-03-21 18:54:28,648 INFO sync.util :: FINISHED: Sync metadata for mysql Database 2 ''Starrocks'' (83.9 ms)
2024-03-21 18:54:28,649 INFO sync.util :: STARTING: Analyze data for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,650 INFO sync.util :: STARTING: step ''fingerprint-fields'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,652 INFO sync.util :: FINISHED: step ''fingerprint-fields'' for mysql Database 2 ''Starrocks'' (1.9 ms)
2024-03-21 18:54:28,652 INFO sync.util :: STARTING: step ''classify-fields'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,652 INFO sync.util :: FINISHED: step ''classify-fields'' for mysql Database 2 ''Starrocks'' (62.9 Œºs)
2024-03-21 18:54:28,652 INFO sync.util :: STARTING: step ''classify-tables'' for mysql Database 2 ''Starrocks''
2024-03-21 18:54:28,652 INFO sync.util :: FINISHED: step ''classify-tables'' for mysql Database 2 ''Starrocks'' (72.4 Œºs)
2024-03-21 18:54:28,664 INFO sync.util :: FINISHED: Analyze data for mysql Database 2 ''Starrocks'' (8.3 ms)

```

![image](https://github.com/metabase/metabase/assets/16459517/347fcf28-9e4f-485a-8397-3be81766918b)


### Information about your Metabase installation

```JSON
- Metabase version : v0.49.1
- OS : Red Hat Enterprise Linux release 8.8 (Ootpa)
- Installation : Jar file downloaded
- Chrome browser
- Starrocks version 3.2.3
```


### Severity

No starrocks table can be used.

### Additional context

_No response_",moweonlee,2024-03-21 09:55:22+00:00,[],2024-03-21 22:44:04+00:00,2024-03-21 11:54:56+00:00,https://github.com/metabase/metabase/issues/40433,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2012073147, 'issue_id': 2199695452, 'author': 'paoliniluis', 'body': 'If Metabase can‚Äôt use a function that should be there then we can‚Äôt read the tables. Seems you already put this on the starrocks GitHub issue tracker.\r\n\r\nif starrocks is different from Mariadb or MySQL we can‚Äôt do nothing https://github.com/StarRocks/starrocks/issues/41951', 'created_at': datetime.datetime(2024, 3, 21, 11, 54, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2013962719, 'issue_id': 2199695452, 'author': 'moweonlee', 'body': '@paoliniluis \r\n\r\n> If Metabase can‚Äôt use a function that should be there then we can‚Äôt read the tables.\r\n\r\n In Starrocks 3.2.2, I was able to read tables even though there were same time_format() function missing error. \r\nSo I thought there are another issues behind it.\r\n\r\nI started to see source code from now.\r\nDo  you think Starrocks 3.2.3 can read data if I replace missing function with alternatives that Starrocks supports ?\r\n\r\nI need Metabase + Starrocks :)', 'created_at': datetime.datetime(2024, 3, 21, 22, 29, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2013977568, 'issue_id': 2199695452, 'author': 'paoliniluis', 'body': 'This is weird as the sync finishes, even if the timezone thing fails. Do you see any column in the metabase_tables table in the application database?', 'created_at': datetime.datetime(2024, 3, 21, 22, 44, 3, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-21 11:54:56 UTC): If Metabase can‚Äôt use a function that should be there then we can‚Äôt read the tables. Seems you already put this on the starrocks GitHub issue tracker.

if starrocks is different from Mariadb or MySQL we can‚Äôt do nothing https://github.com/StarRocks/starrocks/issues/41951

moweonlee (Issue Creator) on (2024-03-21 22:29:45 UTC): @paoliniluis 


 In Starrocks 3.2.2, I was able to read tables even though there were same time_format() function missing error. 
So I thought there are another issues behind it.

I started to see source code from now.
Do  you think Starrocks 3.2.3 can read data if I replace missing function with alternatives that Starrocks supports ?

I need Metabase + Starrocks :)

paoliniluis on (2024-03-21 22:44:03 UTC): This is weird as the sync finishes, even if the timezone thing fails. Do you see any column in the metabase_tables table in the application database?

"
2199543195,issue,open,,Show region display name when hovering over a map region that has no associated values,"**Is your feature request related to a problem? Please describe.**
I sometimes want to see the name of a region that is underperforming when viewing a question in map view.
Currently metabase only shows me the context bubble (that displays the region name and data values) when hovering over a map region that has associated values. I cannot view the region name for regions that don't have associated values in the current question (the greyed out regions).


![Recording-2024-03-21-173236](https://github.com/metabase/metabase/assets/76549682/3892617d-ad0f-457e-936b-1fca9b127a01)



I can't recall the names of certain US states and Canadian provinces based on the position on the map and the shape alone. So I have to open and refer to a different map that has the labels.

**Describe the solution you'd like**
Also show the context bubble when hovering over a map region that doesn't have associated values in the current question so I can see the region name.

**Describe alternatives you've considered**
I can't think of a better or more elegant way to solve the issue.

**How important is this feature to you?**
It's definitely not the end of the world if this does not get implemented, but I think it will make the map UI more intuitive if implemented and allow users to save effort and time by not having to open another map to find the name of a region on the map.

**Additional context**
-
",andrewler,2024-03-21 08:40:20+00:00,[],2025-02-04 20:31:52+00:00,,https://github.com/metabase/metabase/issues/40429,"[('Type:New Feature', ''), ('Visualization/Maps', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2199425943,issue,closed,not_planned,CSV date,"### Describe the bug

When I try to download this question in CSV format the date is incorrect. I try to download 2024 but in the csv it shows as 2025

https://luxury-tenerife.metabase.wavyssa.com/question#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

<img width=""1234"" alt=""333"" src=""https://github.com/metabase/metabase/assets/163538527/8dec0260-0175-4a51-a61a-08721329964f"">



### To Reproduce

1. Go to the link above
2. Click on download csv
3. See error


### Expected behavior

Show correct date

### Logs

_No response_

### Information about your Metabase installation

```JSON
edge
```


### Severity

High

### Additional context

_No response_",Alejandrasm1,2024-03-21 07:46:02+00:00,[],2024-03-21 08:20:35+00:00,2024-03-21 08:20:28+00:00,https://github.com/metabase/metabase/issues/40426,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2011612506, 'issue_id': 2199425943, 'author': 'calherries', 'body': 'Assuming this is version 0.49.0, this is probably a duplicate of https://github.com/metabase/metabase/issues/40306. Please reopen if this is an older version', 'created_at': datetime.datetime(2024, 3, 21, 8, 20, 28, tzinfo=datetime.timezone.utc)}]","calherries on (2024-03-21 08:20:28 UTC): Assuming this is version 0.49.0, this is probably a duplicate of https://github.com/metabase/metabase/issues/40306. Please reopen if this is an older version

"
2199229172,issue,closed,completed,"Use ""contains"" and ""between"" as default filter operators for non-PK/FK/Category string and numeric columns","Demo https://www.loom.com/share/055371be545444829eb48a5042aa9869

Before:
- New filters for string columns got `=` operator in all cases
- New filters for numeric columns got `=` in all places except the filter modal where we used `between` if the column is not PK/FK

Now:
- PK/FK/Category string columns get `=`, other types get `contains`
- PK/FK/Category numeric columns get `=`, other types get `between`",ranquild,2024-03-21 06:13:23+00:00,[],2024-03-21 08:30:14+00:00,2024-03-21 08:30:13+00:00,https://github.com/metabase/metabase/issues/40424,"[('Type:New Feature', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]",[],
2199122139,issue,closed,completed,Cannot save a question based on another question after converting to SQL,"### Describe the bug

After converting a saved question which is based on another saved question to SQL, it's impossible to save the question.

### To Reproduce

1. New -> Question -> Orders -> Save as Q1
2. New -> Question -> Q1 -> Save as Q2
3. Convert to SQL
4. See the save button is greyed out


### Expected behavior

It should be possible to save the question after converting

### Logs

_No response_

### Information about your Metabase installation

```JSON
49.0-49.1
```


### Severity

P1

### Additional context

_No response_",ranquild,2024-03-21 04:59:39+00:00,['ranquild'],2024-03-26 11:34:02+00:00,2024-03-21 08:01:08+00:00,https://github.com/metabase/metabase/issues/40422,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Reproduced', 'Issues reproduced in test (usually Cypress)'), ('.Team/Querying', '')]",[],
2199069305,issue,closed,completed,Should not use formatting for JSON results downloads,"### Describe the bug

Hi,

When downloading a query result of rows containing numbers or nullable columns, the new version 0.49 will format the data columns.

Example:

header:  col1 | col2 | col3
Row1:    1  |  ""hello"" | null

will be formatted as 

```json
{
""col1"": ""1"",
""col2"": ""hello"",
""col3"": """"
}
```

which will break down stream processing pipeline.

### To Reproduce

1. Create a table containing various columns types.
2. Insert dummy data
3. Download query result as json

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64; rv:124.0) Gecko/20100101 Firefox/124.0"",
    ""vendor"": """"
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.134-16.1.al8.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""PRC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.5""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High

### Additional context

And we failed to downgrade.. ",wooparadog,2024-03-21 04:03:02+00:00,['adam-james-v'],2024-04-06 00:10:50+00:00,2024-03-28 17:59:23+00:00,https://github.com/metabase/metabase/issues/40420,[],"[{'comment_id': 2012264361, 'issue_id': 2199069305, 'author': 'paoliniluis', 'body': '@wooparadog this was made to make the exports consistent to what you see in the frontend. Why do you want us to give you a format in the browser but then change the format in the export?', 'created_at': datetime.datetime(2024, 3, 21, 13, 14, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2013038303, 'issue_id': 2199069305, 'author': 'adam-james-v', 'body': ""Yes, @wooparadog a little more information would be helpful for us. I'm wondering these things:\r\n\r\n1. What is your expected output, given your example. Perhaps you could also provide another example or two to further clarify?\r\n2. Are you doing this via the download results in a dashboard? API? subscription attachment?\r\n\r\nThis information can help me decide on a good approach to help :)"", 'created_at': datetime.datetime(2024, 3, 21, 17, 4, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2040804666, 'issue_id': 2199069305, 'author': 'wooparadog', 'body': 'Sorry..just saw 0.49.3 release notes, and came back to say thanks..\r\n\r\nThe use case:\r\n\r\nJson output is almost always for post processing, like by other programs.\r\nIMO, in this case, the formatting should be handled by the down stream app.\r\n\r\nAgain, amazing job, and huge thanks.', 'created_at': datetime.datetime(2024, 4, 6, 0, 10, 50, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-21 13:14:05 UTC): @wooparadog this was made to make the exports consistent to what you see in the frontend. Why do you want us to give you a format in the browser but then change the format in the export?

adam-james-v (Assginee) on (2024-03-21 17:04:27 UTC): Yes, @wooparadog a little more information would be helpful for us. I'm wondering these things:

1. What is your expected output, given your example. Perhaps you could also provide another example or two to further clarify?
2. Are you doing this via the download results in a dashboard? API? subscription attachment?

This information can help me decide on a good approach to help :)

wooparadog (Issue Creator) on (2024-04-06 00:10:50 UTC): Sorry..just saw 0.49.3 release notes, and came back to say thanks..

The use case:

Json output is almost always for post processing, like by other programs.
IMO, in this case, the formatting should be handled by the down stream app.

Again, amazing job, and huge thanks.

"
2198991917,issue,closed,not_planned,Tell variables not to automatically add quotation marks,How to tell variables not to automatically add quotation marks when using SQL queries,Avey777,2024-03-21 02:50:40+00:00,[],2025-01-23 17:18:01+00:00,2024-03-26 13:39:36+00:00,https://github.com/metabase/metabase/issues/40419,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2011167234, 'issue_id': 2198991917, 'author': 'Avey777', 'body': 'Or can you tell me which file I should go to to modify the code to remove the function of setting variables to strings!', 'created_at': datetime.datetime(2024, 3, 21, 3, 46, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2012262209, 'issue_id': 2198991917, 'author': 'paoliniluis', 'body': ""@Avey777 can you please give us some hint of what you're trying to achieve here so we can help you better?"", 'created_at': datetime.datetime(2024, 3, 21, 13, 13, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2020458472, 'issue_id': 2198991917, 'author': 'paoliniluis', 'body': 'closing due to lack of response/issue not correctly filled', 'created_at': datetime.datetime(2024, 3, 26, 13, 39, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610469493, 'issue_id': 2198991917, 'author': 'ksnyder', 'body': ""The question is how to use a Metabase variable without it automatically being wrapped in quotes.  Sometimes the text variable set by the user needs to be manipulated as a string so that a query like this would work:\n\n```\nSELECT\n  *\nFROM\n  plus.get_policy_chars_snapshot_in_time (\n    '2025-01-01 00:00 America/Los_Angeles',\n    '{{timestamp}} 00:00 America/Los_Angeles',\n    TRUE\n  )\n```\n\nCurrently this query will be interpolated as: \n```\nSELECT\n  *\nFROM\n  plus.get_policy_chars_snapshot_in_time (\n    '2025-01-01 00:00 America/Los_Angeles',\n    ''2025-01-21' 00:00 America/Los_Angeles',\n    TRUE\n  )\n```\nand clearly it should not have the quotes around the date.  Where is it documented what can be done with string variables, it's a very common need to be able to manipulate them rather than having them go straight from user input into the query."", 'created_at': datetime.datetime(2025, 1, 23, 17, 17, 38, tzinfo=datetime.timezone.utc)}]","Avey777 (Issue Creator) on (2024-03-21 03:46:46 UTC): Or can you tell me which file I should go to to modify the code to remove the function of setting variables to strings!

paoliniluis on (2024-03-21 13:13:06 UTC): @Avey777 can you please give us some hint of what you're trying to achieve here so we can help you better?

paoliniluis on (2024-03-26 13:39:36 UTC): closing due to lack of response/issue not correctly filled

ksnyder on (2025-01-23 17:17:38 UTC): The question is how to use a Metabase variable without it automatically being wrapped in quotes.  Sometimes the text variable set by the user needs to be manipulated as a string so that a query like this would work:

```
SELECT
  *
FROM
  plus.get_policy_chars_snapshot_in_time (
    '2025-01-01 00:00 America/Los_Angeles',
    '{{timestamp}} 00:00 America/Los_Angeles',
    TRUE
  )
```

Currently this query will be interpolated as: 
```
SELECT
  *
FROM
  plus.get_policy_chars_snapshot_in_time (
    '2025-01-01 00:00 America/Los_Angeles',
    ''2025-01-21' 00:00 America/Los_Angeles',
    TRUE
  )
```
and clearly it should not have the quotes around the date.  Where is it documented what can be done with string variables, it's a very common need to be able to manipulate them rather than having them go straight from user input into the query.

"
2198844779,issue,open,,Customize homepage at the user level,"**Is your feature request related to a problem? Please describe.**
The custom home page is currently set at a site level, via the 'General' page in  Admin settings. However, that assumes everyone using an instance of Metabase is interested in the same thing

**Describe the solution you'd like**
Allow each user to set what they want as their home page

**Describe alternatives you've considered**
none that I can see There doesn't seem to be any way of setting things up so a user sees a different homepage than what is set for the instance as a whole.

**How important is this feature to you?**
Very.

**Additional context**

",kranskydog,2024-03-21 00:32:41+00:00,[],2025-02-04 20:30:16+00:00,,https://github.com/metabase/metabase/issues/40414,"[('Type:New Feature', ''), ('Organization/Homepage', '')]","[{'comment_id': 2012260828, 'issue_id': 2198844779, 'author': 'paoliniluis', 'body': 'How should we handle the situation where an admin set a homepage for the entire instance? @kranskydog', 'created_at': datetime.datetime(2024, 3, 21, 13, 12, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2013973272, 'issue_id': 2198844779, 'author': 'kranskydog', 'body': ""@paoliniluis \r\nRight now, if I don't have permission to see the one the admin has set, I get the default home page. So, in that case, I can *only* get the default\r\n\r\nIf I have one set for me, I should see that one. If I don't have one set for me, it should work exactly the way it does now."", 'created_at': datetime.datetime(2024, 3, 21, 22, 39, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2013977019, 'issue_id': 2198844779, 'author': 'kranskydog', 'body': ""and if, for whatever reason, the admin doesn't want to allow users to be able to set their own homepage, and only see the one the admin has set, then make it an admin option as the whether to allow users to set their own home page."", 'created_at': datetime.datetime(2024, 3, 21, 22, 43, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2252901923, 'issue_id': 2198844779, 'author': 'Caerbannog', 'body': ""As an admin I would like users to be able to set their own homepage, but also I would like to be able to change it for them.\r\nI would set a specific homepage for Alice, different from Bob's."", 'created_at': datetime.datetime(2024, 7, 26, 14, 34, 19, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-21 13:12:24 UTC): How should we handle the situation where an admin set a homepage for the entire instance? @kranskydog

kranskydog (Issue Creator) on (2024-03-21 22:39:25 UTC): @paoliniluis 
Right now, if I don't have permission to see the one the admin has set, I get the default home page. So, in that case, I can *only* get the default

If I have one set for me, I should see that one. If I don't have one set for me, it should work exactly the way it does now.

kranskydog (Issue Creator) on (2024-03-21 22:43:29 UTC): and if, for whatever reason, the admin doesn't want to allow users to be able to set their own homepage, and only see the one the admin has set, then make it an admin option as the whether to allow users to set their own home page.

Caerbannog on (2024-07-26 14:34:19 UTC): As an admin I would like users to be able to set their own homepage, but also I would like to be able to change it for them.
I would set a specific homepage for Alice, different from Bob's.

"
2198720162,issue,closed,completed,Hovering over column header in preview errors out,"### Describe the bug

When building a new question, I am previewing a model (Retention Analysis), and when you hover some column headers (is_churn or plan_name), it would error out. 


### To Reproduce

1. Create new question, select model and preview
2. Move mouse over a field header to see description. Works for some but not for others. 

### Expected behavior

Hover over field header should show field description 

### Logs

TypeError: Cannot read properties of null (reading 'fingerprint')
    at E (CategoryFingerprint.jsx:66:31)
    at is (react-dom.production.min.js:157:137)
    at c (react-dom.production.min.js:267:460)
    at a6 (react-dom.production.min.js:250:347)
    at react-dom.production.min.js:250:278
    at a4 (react-dom.production.min.js:250:283)
    at aK (react-dom.production.min.js:243:163)
    at react-dom.production.min.js:123:115
    at t.unstable_runWithPriority (scheduler.production.min.js:18:343)
    at on (react-dom.production.min.js:122:325)

### Information about your Metabase installation

```JSON
master @ Postgres
```


### Severity

Minor as I can find the info from elsewhere / in another tab

### Additional context

<img width=""1697"" alt=""Screenshot 2024-03-20 at 3 42 47 PM"" src=""https://github.com/metabase/metabase/assets/9684260/93e30634-5ae6-44ee-8744-21390cc2666c"">
",maxzheng,2024-03-20 22:46:28+00:00,['uladzimirdev'],2024-07-01 22:24:04+00:00,2024-06-25 12:40:08+00:00,https://github.com/metabase/metabase/issues/40412,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2188721475, 'issue_id': 2198720162, 'author': 'uladzimirdev', 'body': 'old line (before refactoring) points out to the line https://github.com/metabase/metabase/blob/78cb28816a2c19848bd7cbf7fba15335e02fc270/frontend/src/metabase/components/MetadataInfo/ColumnFingerprintInfo/CategoryFingerprint.jsx#L66C1-L66C8\r\n\r\nand here is a fix https://github.com/metabase/metabase/pull/40861/files#diff-07deab5053c31264958d3c1ea24da910e84f27cc40eeed62f3cb5ae8dd3547e5L53', 'created_at': datetime.datetime(2024, 6, 25, 11, 43, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2188829487, 'issue_id': 2198720162, 'author': 'uladzimirdev', 'body': 'works fine on stats ([video](https://metaboat.slack.com/archives/C0645JP1W81/p1719318865540089)), using latest master, 49.8+ and 50 contain that fix, test is added in [the original fix](https://github.com/metabase/metabase/pull/40861)', 'created_at': datetime.datetime(2024, 6, 25, 12, 40, 8, tzinfo=datetime.timezone.utc)}]","uladzimirdev (Assginee) on (2024-06-25 11:43:48 UTC): old line (before refactoring) points out to the line https://github.com/metabase/metabase/blob/78cb28816a2c19848bd7cbf7fba15335e02fc270/frontend/src/metabase/components/MetadataInfo/ColumnFingerprintInfo/CategoryFingerprint.jsx#L66C1-L66C8

and here is a fix https://github.com/metabase/metabase/pull/40861/files#diff-07deab5053c31264958d3c1ea24da910e84f27cc40eeed62f3cb5ae8dd3547e5L53

uladzimirdev (Assginee) on (2024-06-25 12:40:08 UTC): works fine on stats ([video](https://metaboat.slack.com/archives/C0645JP1W81/p1719318865540089)), using latest master, 49.8+ and 50 contain that fix, test is added in [the original fix](https://github.com/metabase/metabase/pull/40861)

"
2198320079,issue,closed,completed,Result inconsistencies with Preview in GUI editor,"### Describe the bug

When using the GUI builder and Preview functionality, filters are inconsistently applied to layers above in the Question.

### To Reproduce

Here's a recording of the issue
https://github.com/metabase/metabase/assets/17398657/b86c9e5d-39d2-4442-9e99-9971de365ae8

<br />
<br />

Using Sample Database
1. Create a question with Products table and click on Preview 
<img width=""975"" alt=""Screenshot 2024-03-20 at 1 08 11 PM"" src=""https://github.com/metabase/metabase/assets/17398657/996369ab-1c34-497f-b798-797147183761"">

<br>
<br>

2. Join Reviews table

<br>
<br>

3. Add a filter based on a column from Products table such as Category
<img width=""999"" alt=""Screenshot 2024-03-20 at 1 08 50 PM"" src=""https://github.com/metabase/metabase/assets/17398657/d7ff4fa4-5d30-4b77-8fe7-ce08513bd750"">

<br>
<br>

4. Refresh the preview for the Products section above and notice the Category filter from below is being applied
<img width=""941"" alt=""Screenshot 2024-03-20 at 1 09 17 PM"" src=""https://github.com/metabase/metabase/assets/17398657/e0656242-d0e3-4927-a404-7af989129a55"">

<br>
<br>

<img width=""745"" alt=""Screenshot 2024-03-20 at 1 09 51 PM"" src=""https://github.com/metabase/metabase/assets/17398657/11e01c5a-0871-4899-a6f0-e5d782b6168c"">

<br>
<br>

5. Click on Preview for the joined section for Products and Reviews and notice Category filter from below is NOT being applied.
<img width=""945"" alt=""Screenshot 2024-03-20 at 1 10 56 PM"" src=""https://github.com/metabase/metabase/assets/17398657/438fcce6-d90b-46b1-a63b-b2f64a3e96d5"">

<br>
<br>


### Expected behavior

Preview shows data relevant to the filters and aggregations applied to that particular layer.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.49-linuxkit-pr"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v1.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P2 - Affects users making use of previews in GUI builder

### Additional context

_No response_",FilmonK,2024-03-20 18:57:34+00:00,['romeovs'],2024-06-27 10:09:26+00:00,2024-06-25 12:21:05+00:00,https://github.com/metabase/metabase/issues/40399,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]","[{'comment_id': 2194299164, 'issue_id': 2198320079, 'author': 'github-actions[bot]', 'body': 'üöÄ This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)', 'created_at': datetime.datetime(2024, 6, 27, 10, 9, 25, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-06-27 10:09:25 UTC): üöÄ This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)

"
2198215938,issue,closed,completed,Cannot filter on enum fields on dashboards,"### Describe the bug

When selecting a meta type of ""enum"" (which is assumed to be a known list of values), the text filters cannot be applied on metabase dashbaords

![Screenshot 2024-03-20 at 19 00 57](https://github.com/metabase/metabase/assets/7388889/1591440d-793c-44cd-9cb5-b61631718e7c)


![Screenshot 2024-03-20 at 19 00 52](https://github.com/metabase/metabase/assets/7388889/c7b7d0d1-8fad-4585-b734-d96477ddd9eb)


### To Reproduce

1. Go to the admin, table metadata, and pick any ""enum"" column
2. Click on type > enum
3. Add a question containing this field on a dashboard
4. Try to filter on the enum value


### Expected behavior

The enum field is filterable. Optionally, the list of all possible values is scanned once during metabase values scan and not refreshed on any queries. The list can be assumed to be short (?) and eager loaded so autocompletion is done on the frontend side

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Metabase 0.49.0 self hosted on kubernetes with Helm chart
```


### Severity

low

### Additional context

Can switch back to category type to find",Startouf,2024-03-20 18:04:36+00:00,['ranquild'],2025-02-04 17:29:32+00:00,2025-01-23 18:24:48+00:00,https://github.com/metabase/metabase/issues/40396,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Database/BigQuery', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2134773032, 'issue_id': 2198215938, 'author': 'stutimohindra', 'body': 'hey can i be assigned this bug please', 'created_at': datetime.datetime(2024, 5, 28, 9, 37, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2142709685, 'issue_id': 2198215938, 'author': 'bshepherdson', 'body': 'This might be related to other recent enum-related filtering issues? Worth trying to repro on `master` after #43274 .', 'created_at': datetime.datetime(2024, 5, 31, 17, 40, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596897094, 'issue_id': 2198215938, 'author': 'ranquild', 'body': 'Check postgres and mysql enums', 'created_at': datetime.datetime(2025, 1, 16, 21, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597856248, 'issue_id': 2198215938, 'author': 'Startouf', 'body': ""Hello, I forgot to mention but we are using BigQuery, I'm not sure if this changes anything"", 'created_at': datetime.datetime(2025, 1, 17, 9, 56, 54, tzinfo=datetime.timezone.utc)}]","stutimohindra on (2024-05-28 09:37:05 UTC): hey can i be assigned this bug please

bshepherdson on (2024-05-31 17:40:31 UTC): This might be related to other recent enum-related filtering issues? Worth trying to repro on `master` after #43274 .

ranquild (Assginee) on (2025-01-16 21:12:00 UTC): Check postgres and mysql enums

Startouf (Issue Creator) on (2025-01-17 09:56:54 UTC): Hello, I forgot to mention but we are using BigQuery, I'm not sure if this changes anything

"
2198215886,issue,closed,completed,Location on search endpoint,"For [collection moving](https://github.com/metabase/metabase/issues/37833) to work correctly with search results, we need to be able to disable search items that are inside any moving collection so that you can't move a collection into itself or its children.

To accomplish this, we need `location` and/or `effective_location` populated in search to be able to know whether a given search result is a valid move target for collections
",iethree,2024-03-20 18:04:34+00:00,['johnswanson'],2024-04-03 09:07:43+00:00,2024-03-28 22:43:22+00:00,https://github.com/metabase/metabase/issues/40395,"[('Organization/Collections', ''), ('.Backend', '')]",[],
2198207696,issue,closed,completed,Metric with ID xx does not exist,"**Describe the bug**
When creating a Metabase question, selecting a Common Metric and creating a summary, we lose the Common Metrics group and if we pick the initial Common Metric added Metabase shows a error message. The console log displays a ""metric with id xx not found"" issue. 

We've recorded the following Loom to show the issue: https://www.loom.com/share/a3775a517dc3402ba4e37bd1e4e7fdb0?sid=b196bff3-b455-40dc-8348-a94d9b3663b6 

If we pick all the Common Metrics we are summarizing and then the Dimensions, Metabase outputs the result properly. However, we lose the ability to edit the question.


**Logs**
metric with ID does not exist : 32 > react-dom.prodcution.min.js:209 
Error app.ts:30

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'New > Question'
2. Select a Table with Metrics (Common Metrics)
3. Scroll down to and add one Common Metric and a Dimension to group by
4. Try to add another Common Metric (doesn't show)
5. Click on the initial common metric
6. Error

https://www.loom.com/share/a3775a517dc3402ba4e37bd1e4e7fdb0?sid=b196bff3-b455-40dc-8348-a94d9b3663b6 

**Expected behavior**
Expectation is to continue to see the Common Metrics group and be able to click on it these metrics to edit its definition 

**Screenshots**
<img width=""516"" alt=""image"" src=""https://github.com/metabase/metabase/assets/136714486/d0ea4cc4-7ffc-402e-979e-165a5301f54c"">

**Severity**
blocking usage of metabase

**Additional context**
metabase 0.49, self hosted

**Metabase Diagnostic Info**

```json
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.205-195.804.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```",cgg-pwdt,2024-03-20 18:01:30+00:00,[],2024-03-27 07:15:41+00:00,2024-03-27 07:15:41+00:00,https://github.com/metabase/metabase/issues/40393,[],"[{'comment_id': 2010282392, 'issue_id': 2198207696, 'author': 'cgg-pwdt', 'body': 'apologies I forgot to label this issue \r\n\r\nI guess it should be `.Needs Triage` and `Type:Bug`', 'created_at': datetime.datetime(2024, 3, 20, 18, 6, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2022102627, 'issue_id': 2198207696, 'author': 'uladzimirdev', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/40553', 'created_at': datetime.datetime(2024, 3, 27, 7, 15, 41, tzinfo=datetime.timezone.utc)}]","cgg-pwdt (Issue Creator) on (2024-03-20 18:06:12 UTC): apologies I forgot to label this issue 

I guess it should be `.Needs Triage` and `Type:Bug`

uladzimirdev on (2024-03-27 07:15:41 UTC): Duplicate of https://github.com/metabase/metabase/issues/40553

"
2197914492,issue,closed,completed,Field filter breaks native question on dashboard,"### Describe the bug

Field filters break native question on a dashboard

### To Reproduce

1. Create a native question: sample database, `select * from products where {{ title }}`, set the variable type to Field Filter, wire it to `Products.Title`. 
2. Save it, add to a dashboard.
3. Add a dashboard filter and wire it to `Title`.
4(!) Set a value for the title, and see the error
<img width=""496"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/39b75449-e13c-42eb-98a8-86f3bc4c9d04"">

.../query api response: `""error"": ""Error compiling HoneySQL form: These SQL clauses are unknown or have nil values: :case-sensitive"",
`

### Expected behavior

It should work.

### Logs

`.../query` response: [query_response.json](https://github.com/metabase/metabase/files/14669136/query_response.json)



### Information about your Metabase installation
Appears to be broken on stats as of 2024-03-20 / `4eea910`, `1.48.8`, `1.48.9` and `1.49.0`.


### Severity

P1

### Additional context

_No response_",zbodi74,2024-03-20 16:01:30+00:00,['snoe'],2024-08-28 02:10:36+00:00,2024-03-25 21:23:55+00:00,https://github.com/metabase/metabase/issues/40383,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/Querying', '')]",[],
2197694124,issue,closed,not_planned,Display of multiple rows when several Excel cells are copied and pasted simultaneously into an SQL Query column filter,"### Describe the bug

I am referring to the version v0.49.0 in the description below:

Before the last update, when I copied several Excel cells together and pasted them into an SQL Query column filter, they were read separately (as they should be as they are different pieces of data) and I got all the information I needed for each one of the cells I was using as inputs. However, the update to the version v0.49.0 deleted this feature. Now, when I try to copy and paste multiple Excel cells into an SQL Query column filter simultaneously, they are read as they were only one piece of data (instead of separately as before), which doesn't make sense.

### To Reproduce

1. Create an SQL Query referring to a specific database
2. Chose a specific column of the table displayed by this SQL Query
3. In a separate Excel sheet, write down, in different subsequent cells in the same Excel column, some of the pieces of data contained in the chosen column from the SQL Query table in step 2
4. Copy all the data you wrote down in step 3 from the Excel sheet
5. In one of the columns of the table displayed by this SQL Query, apply a filter (type ""equal to""/""is"") and paste the content copied from multiple Excel cells in step 4
6. See error (the data will be displayed as it was only one Excel cell, not as several cells as it should be)

### Expected behavior

After the filter described above is applied, the table should display all the data referring to each one of the Excel cells, which is not happening any more in this new version of Metabase (v0.49.0).

### Logs

_No response_

### Information about your Metabase installation

```JSON
- My browser and the version: Microsoft Edge - Version 122.0.2365.80 (Official build) (64-bit)
- My operating system: Windows 11 Enterprise
- My databases: PostgreSQL
- Metabase version: 0.49.0
- Metabase hosting environment: Azure
- Metabase internal database: PostgreSQL
```


### Severity

Blocking some important daily activities

### Additional context

![image (1)](https://github.com/metabase/metabase/assets/153678884/26883d6d-31b1-46df-9cf9-e45ba9d5193d)
![image](https://github.com/metabase/metabase/assets/153678884/a0b8cfd9-f3eb-4889-82dd-f2899a0ac544)

As you can see, all the 12 Excel cells I copied and pasted into the SQL Query column filter were read as only one cell, which blocked me from getting the information I needed from the other columns of the SQL Query table referring to these 12 cells.",Deco1998,2024-03-20 14:33:06+00:00,[],2024-03-20 14:51:33+00:00,2024-03-20 14:51:32+00:00,https://github.com/metabase/metabase/issues/40376,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2009759916, 'issue_id': 2197694124, 'author': 'paoliniluis', 'body': 'duplicate of https://github.com/metabase/metabase/issues/40265, already fixed in 49.1', 'created_at': datetime.datetime(2024, 3, 20, 14, 51, 32, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-20 14:51:32 UTC): duplicate of https://github.com/metabase/metabase/issues/40265, already fixed in 49.1

"
2197681489,issue,open,,Scrolling bug when timeseries series in a bar chart is used,"### Describe the bug

Scrolling bug when timeseries series in a bar chart is used. When you have a dashboard that doesn't allow drilling down, or any clicking behavior, the cursor is stille changed, and scrolling behavior blocks when clicking on the chart. I understand that this is something minor, but it is not handy when you have multiple charts underneath each other in an embedded view.

### To Reproduce

1. Add some timeseries charts underneath each other in a dashboard
2. Embed it in an application where you need to scroll
3. Click in the chart (not on the data)
4. Try scrolling. This doesn't work

### Expected behavior

Scrolling should still be possible

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.198-187.748.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v1.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

minor

### Additional context

_No response_",vinceve,2024-03-20 14:28:14+00:00,[],2024-05-20 14:03:30+00:00,,https://github.com/metabase/metabase/issues/40375,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2009928269, 'issue_id': 2197681489, 'author': 'paoliniluis', 'body': 'metabase version? please complete the troubleshooting info...', 'created_at': datetime.datetime(2024, 3, 20, 16, 0, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2011612948, 'issue_id': 2197681489, 'author': 'vinceve', 'body': ""Latest version, I'll add the details."", 'created_at': datetime.datetime(2024, 3, 21, 8, 20, 46, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-20 16:00:42 UTC): metabase version? please complete the troubleshooting info...

vinceve (Issue Creator) on (2024-03-21 08:20:46 UTC): Latest version, I'll add the details.

"
2197531987,issue,closed,completed,Comprehensive tests for CSV Replacement,"For Appends the end-to-end testing is pretty thin. We've matched it, but maybe we want more?

As far as component-level Integration tests, there a lot to do. 

We should match and even improve on the Append coverage at least.",crisptrutski,2024-03-20 13:25:59+00:00,['crisptrutski'],2024-04-04 11:50:48+00:00,2024-04-04 11:50:47+00:00,https://github.com/metabase/metabase/issues/40368,"[('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2018401191, 'issue_id': 2197531987, 'author': 'crisptrutski', 'body': '~~We should also add some e2e tests. We might as well cover TSVs at the same time.~~\r\n\r\nWe have e2e coverage for both of these now.', 'created_at': datetime.datetime(2024, 3, 25, 16, 24, 45, tzinfo=datetime.timezone.utc)}]","crisptrutski (Issue Creator) on (2024-03-25 16:24:45 UTC): ~~We should also add some e2e tests. We might as well cover TSVs at the same time.~~

We have e2e coverage for both of these now.

"
2197459087,issue,closed,completed,Naive CSV Replacement," Like Append, but it empties the table prior to insertion.",crisptrutski,2024-03-20 12:50:09+00:00,['crisptrutski'],2024-03-25 13:59:57+00:00,2024-03-22 11:40:51+00:00,https://github.com/metabase/metabase/issues/40365,"[('.Team/Workflows', 'aka BEC')]",[],
2197458906,issue,closed,completed,Create CSV Replacement endpoint,"```
POST ""/table/:id/replace-csv"" {:id, :file}
```",crisptrutski,2024-03-20 12:50:03+00:00,['crisptrutski'],2024-03-22 11:40:50+00:00,2024-03-22 11:40:50+00:00,https://github.com/metabase/metabase/issues/40364,"[('.Team/Workflows', 'aka BEC')]",[],
2197363113,issue,closed,completed,Migrate global css in `frontend/src/metabase/css/core/colors.module.css`,,oisincoveney,2024-03-20 12:02:22+00:00,['oisincoveney'],2024-04-11 09:14:38+00:00,2024-04-11 09:14:38+00:00,https://github.com/metabase/metabase/issues/40357,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2197339565,issue,closed,completed,"Filtering by Aggregated Common Metrics fails with ""column not found""","### Describe the bug

We are using  Metabase (self-hosted) v0.49.0 with AWS Athena and noticed an issue with Common Metrics and Filtering by these aggregations. 

When we try to filter after summarising by a **common metric**, we get a ""COLUMN NOT FOUND"" error

When we Convert the question to SQL we see that the filter is referencing the original column name and not the alias created by the Common Metric. I'm attaching the SQL generated where you can see the last WHERE referring ""__sessions"" instead of ""# Sessions"".

We have tested this by naming the metric ""Number of Sessions"" to test if the problem was the ""#"". Didn't work either.

### To Reproduce

1. Go to 'New > Question'
2. Click on 'Summarize by > Select a common metric'
3. Scroll down to 'filter (by aggregation) > select common metric and pick any value'
4. See error (column not found)


### Expected behavior

Expected behavior would be to generate a question sucessfully. Underneath the hood I believe the expected behavior would be generating a SQL code referencing the new Column Alias instead of the original one.

### Logs

[40661243-a7fa-444f-afce-ff115265bdc4] 2024-03-20T11:46:37+00:00 WARN metabase.query-processor.middleware.upgrade-field-literals Warning: clause [:field ""__sessions"" {:base-type :type/Integer}] refers to a Field that may not be present in the source query. Query may not work as expected. Found: #{""location_name"" ""# sessions"" ""# Sessions""}
[40661243-a7fa-444f-afce-ff115265bdc4] 2024-03-20T11:46:40+00:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: [Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. COLUMN_NOT_FOUND: line 2:464: Column 'source.__sessions' cannot be resolved or requester is not authorized to access requested resources [Execution ID: 5e6493f8-e91f-4451-a56c-4c5a17b2a618]
{:database_id 2,
 :started_at #t ""2024-03-20T11:46:37.504065Z[GMT]"",
 :via
 [{:status :failed,
   :class java.sql.SQLException,
   :error
   ""[Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. COLUMN_NOT_FOUND: line 2:464: Column 'source.__sessions' cannot be resolved or requester is not authorized to access requested resources [Execution ID: 5e6493f8-e91f-4451-a56c-4c5a17b2a618]"",
   :stacktrace
   [""com.simba.athena.athena.api.AJClient.executeQuery(Unknown Source)""
    ""com.simba.athena.athena.dataengine.AJQueryExecutor.execute(Unknown Source)""
    ""com.simba.athena.jdbc.common.SStatement.executeNoParams(Unknown Source)""
    ""com.simba.athena.jdbc.common.BaseStatement.execute(Unknown Source)""
    ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
    ""--> driver.sql_jdbc.execute$fn__78950.invokeStatic(execute.clj:560)""
    ""driver.sql_jdbc.execute$fn__78950.invoke(execute.clj:558)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:568)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:565)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79031$fn__79032.invoke(execute.clj:699)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79031.invoke(execute.clj:698)""
    ""driver.sql_jdbc.execute$fn__78824$fn__78825.invoke(execute.clj:388)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
    ""driver.sql_jdbc.execute$fn__78824.invokeStatic(execute.clj:382)""
    ""driver.sql_jdbc.execute$fn__78824.invoke(execute.clj:380)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:692)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc$fn__106344.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__106344.invoke(sql_jdbc.clj:76)""
    ""driver.athena$fn__115542.invokeStatic(athena.clj:445)""
    ""driver.athena$fn__115542.invoke(athena.clj:443)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71961.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66347.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71782.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71792.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)""
    ""query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70935.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72105.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72706.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93567.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135$fn__53137.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43750.invoke(streaming_response.clj:88)""],
   :state ""HY000""}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: [Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. COLUMN_NOT_FOUND: line 2:464: Column 'source.__sessions' cannot be resolved or requester is not authorized to access requested resources [Execution ID: 5e6493f8-e91f-4451-a56c-4c5a17b2a618]"",
   :stacktrace
   [""--> driver.sql_jdbc.execute$execute_reducible_query$fn__79031$fn__79032.invoke(execute.clj:701)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__79031.invoke(execute.clj:698)""
    ""driver.sql_jdbc.execute$fn__78824$fn__78825.invoke(execute.clj:388)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
    ""driver.sql_jdbc.execute$fn__78824.invokeStatic(execute.clj:382)""
    ""driver.sql_jdbc.execute$fn__78824.invoke(execute.clj:380)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:692)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc$fn__106344.invokeStatic(sql_jdbc.clj:78)""
    ""driver.sql_jdbc$fn__106344.invoke(sql_jdbc.clj:76)""
    ""driver.athena$fn__115542.invokeStatic(athena.clj:445)""
    ""driver.athena$fn__115542.invoke(athena.clj:443)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71961.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66347.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71782.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71792.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)""
    ""query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70935.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72105.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72706.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93567.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135$fn__53137.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43750.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:driver :athena,
    :sql
    [""-- Metabase:: userID: 5 queryType: MBQL queryHash: 2a70304564a1d4b61ad2845c31f310c6d6b3709fa714df0715d8f44b991105cf""
     ""SELECT""
     ""  \""source\"".\""location_name\"" AS \""location_name\"",""
     ""  \""source\"".\""# Sessions\"" AS \""# Sessions\""""
     ""FROM""
     ""  (""
     ""    SELECT""
     ""      \""reporting\"".\""charging_point_performance\"".\""location_name\"" AS \""location_name\"",""
     ""      SUM(""
     ""        \""reporting\"".\""charging_point_performance\"".\""number_of_session\""""
     ""      ) AS \""# Sessions\""""
     ""    FROM""
     ""      \""reporting\"".\""charging_point_performance\""""
     ""    GROUP BY""
     ""      \""reporting\"".\""charging_point_performance\"".\""location_name\""""
     ""    ORDER BY""
     ""      \""reporting\"".\""charging_point_performance\"".\""location_name\"" ASC""
     ""  ) AS \""source\""""
     ""WHERE""
     ""  \""source\"".\""__sessions\"" = 0""
     ""LIMIT""
     ""  2000""],
    :params nil,
    :type :invalid-query}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:database 2,
  :type ""query"",
  :query
  {:filter [""="" [""field"" ""__sessions"" {:base-type ""type/Integer""}] 0],
   :source-query
   {:source-table 214, :aggregation [[""metric"" 13]], :breakout [[""field"" 4941 {:base-type ""type/Text""}]]}},
  :parameters [],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:query
  ""SELECT \""source\"".\""location_name\"" AS \""location_name\"", \""source\"".\""# Sessions\"" AS \""# Sessions\"" FROM (SELECT \""reporting\"".\""charging_point_performance\"".\""location_name\"" AS \""location_name\"", SUM(\""reporting\"".\""charging_point_performance\"".\""number_of_session\"") AS \""# Sessions\"" FROM \""reporting\"".\""charging_point_performance\"" GROUP BY \""reporting\"".\""charging_point_performance\"".\""location_name\"" ORDER BY \""reporting\"".\""charging_point_performance\"".\""location_name\"" ASC) AS \""source\"" WHERE \""source\"".\""__sessions\"" = 0 LIMIT 1048575"",
  :params nil},
 :status :failed,
 :class com.simba.athena.support.exceptions.GeneralException,
 :stacktrace
 [""com.simba.athena.athena.api.AJClient.executeQuery(Unknown Source)""
  ""com.simba.athena.athena.dataengine.AJQueryExecutor.execute(Unknown Source)""
  ""com.simba.athena.jdbc.common.SStatement.executeNoParams(Unknown Source)""
  ""com.simba.athena.jdbc.common.BaseStatement.execute(Unknown Source)""
  ""com.mchange.v2.c3p0.impl.NewProxyStatement.execute(NewProxyStatement.java:75)""
  ""--> driver.sql_jdbc.execute$fn__78950.invokeStatic(execute.clj:560)""
  ""driver.sql_jdbc.execute$fn__78950.invoke(execute.clj:558)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:568)""
  ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:565)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__79031$fn__79032.invoke(execute.clj:699)""
  ""driver.sql_jdbc.execute$execute_reducible_query$fn__79031.invoke(execute.clj:698)""
  ""driver.sql_jdbc.execute$fn__78824$fn__78825.invoke(execute.clj:388)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
  ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
  ""driver.sql_jdbc.execute$fn__78824.invokeStatic(execute.clj:382)""
  ""driver.sql_jdbc.execute$fn__78824.invoke(execute.clj:380)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:692)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
  ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
  ""driver.sql_jdbc$fn__106344.invokeStatic(sql_jdbc.clj:78)""
  ""driver.sql_jdbc$fn__106344.invoke(sql_jdbc.clj:76)""
  ""driver.athena$fn__115542.invokeStatic(athena.clj:445)""
  ""driver.athena$fn__115542.invoke(athena.clj:443)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71961.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66347.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71782.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71792.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)""
  ""query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70935.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72105.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72706.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__93567.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53135$fn__53137.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53135.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43750.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""[Simba][AthenaJDBC](100071) An error has been thrown from the AWS Athena client. COLUMN_NOT_FOUND: line 2:464: Column 'source.__sessions' cannot be resolved or requester is not authorized to access requested resources [Execution ID: 5e6493f8-e91f-4451-a56c-4c5a17b2a618]"",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 2,
  :type :query,
  :query
  {:filter [:= [:field ""__sessions"" {:base-type :type/Integer}] [:value 0 {:base_type :type/Integer}]],
   :source-metadata
   [{:semantic_type :type/Category,
     :table_id 214,
     :coercion_strategy nil,
     :name ""location_name"",
     :settings nil,
     :field_ref [:field 4941 {:base-type :type/Text}],
     :effective_type :type/Text,
     :nfc_path nil,
     :parent_id nil,
     :id 4941,
     :display_name ""Location Name"",
     :fingerprint
     {:global {:distinct-count 1243, :nil% 0.0},
      :type
      {:type/Text
       {:percent-json 0.0, :percent-url 0.0, :percent-email 0.0, :percent-state 0.0, :average-length 22.1776}}},
     :base_type :type/Text}
    {:name ""# Sessions"",
     :display_name ""# Sessions"",
     :base_type :type/Integer,
     :semantic_type :type/Quantity,
     :settings nil,
     :field_ref [:aggregation 0]}],
   :fields [[:field 4941 {:base-type :type/Text}] [:field ""# Sessions"" {:base-type :type/Integer}]],
   :source-query
   {:source-table 214,
    :aggregation
    [[:aggregation-options
      [:sum [:field 4955 {:base-type :type/Integer}]]
      {:name ""# Sessions"", :display-name ""# Sessions""}]],
    :breakout [[:field 4941 {:base-type :type/Text}]],
    :order-by [[:asc [:field 4941 {:base-type :type/Text}]]]},
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil},
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 5, :context :ad-hoc}},
 :data {:rows [], :cols []}}

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.205-195.804.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""postgres"",
      ""athena""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

blocking some users

### Additional context

SELECT
  ""source"".""location_name"" AS ""location_name"",
  ""source"".""# Sessions"" AS ""# Sessions""
FROM
  (
    SELECT
      ""reporting"".""charging_point_performance"".""location_name"" AS ""location_name"",
      SUM(
        ""reporting"".""charging_point_performance"".""number_of_session""
      ) AS ""# Sessions""
    FROM
      ""reporting"".""charging_point_performance""
   
GROUP BY
      ""reporting"".""charging_point_performance"".""location_name""
   
ORDER BY
      ""reporting"".""charging_point_performance"".""location_name"" ASC
  ) AS ""source""
WHERE
  ""source"".""__sessions"" = 0
LIMIT
  1048575",cgg-pwdt,2024-03-20 11:49:57+00:00,['metamben'],2024-09-02 08:40:30+00:00,2024-09-02 08:40:30+00:00,https://github.com/metabase/metabase/issues/40355,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2009929718, 'issue_id': 2197339565, 'author': 'paoliniluis', 'body': '@zbodi74 tagging you since I think you went through this', 'created_at': datetime.datetime(2024, 3, 20, 16, 1, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2012187119, 'issue_id': 2197339565, 'author': 'zbodi74', 'body': 'Reproducible on `1.49.1`\r\n1. Create metric: Sample database, Orders, Sum of Total, save it as OrderSumOfTotals\r\n2. Create a question: Orders, Summarize: OrderSumOfTotals, group by: Created at: Month, \r\n3. Add a filter: OrderSumOfTotals > 1\r\n4. See the error: \r\nColumn ""source.ordersumoftotals"" not found; SQL statement:\r\n```\r\nSELECT\r\n  ""source"".""CREATED_AT"" AS ""CREATED_AT"",\r\n  ""source"".""sum"" AS ""sum""\r\nFROM\r\n  (\r\n    SELECT\r\n      DATE_TRUNC(\'month\', ""PUBLIC"".""ORDERS"".""CREATED_AT"") AS ""CREATED_AT"",\r\n      SUM(""PUBLIC"".""ORDERS"".""TOTAL"") AS ""sum""\r\n    FROM\r\n      ""PUBLIC"".""ORDERS""\r\n   \r\nGROUP BY\r\n      DATE_TRUNC(\'month\', ""PUBLIC"".""ORDERS"".""CREATED_AT"")\r\n   \r\nORDER BY\r\n      DATE_TRUNC(\'month\', ""PUBLIC"".""ORDERS"".""CREATED_AT"") ASC\r\n  ) AS ""source""\r\nWHERE\r\n  ""source"".""ordersumoftotals"" = 1\r\n```', 'created_at': datetime.datetime(2024, 3, 21, 12, 41, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2122797006, 'issue_id': 2197339565, 'author': 'ViniAppel', 'body': 'Hello guys.\r\nWe are experiencing the same problem here. We updated from version 0.48.1 to 0.49.10 yesterday and started having this issue for users who use no-code.\r\nBelow is an example screenshot and the query generated by Metabase.\r\n\r\n![image](https://github.com/metabase/metabase/assets/68851613/60a3cc6c-2218-4f21-8ab5-e5d12afe0ff3)\r\n\r\n```\r\nSELECT\r\n  ""source"".""dim_investor_relations__via__fk_investor_relations__b578e382"" AS ""dim_investor_relations__via__fk_investor_relations__b578e382"",\r\n  ""source"".""dim_investor_relations__via__fk_investor_relations__43b4316e"" AS ""dim_investor_relations__via__fk_investor_relations__43b4316e"",\r\n  ""source"".""Tier WuM"" AS ""Tier WuM"",\r\n  SUM(""source"".""WuM"") AS ""WuM""\r\nFROM\r\n  (\r\n    SELECT\r\n      ""source"".""WuM"" AS ""WuM"",\r\n      CASE\r\n        WHEN ""source"".""WuM"" >= 10000000 THEN \'5. 10M+\'\r\n        ELSE CASE\r\n          WHEN ""source"".""WuM"" >= 1000000 THEN \'4. 1-10M\'\r\n          ELSE CASE\r\n            WHEN ""source"".""WuM"" >= 500000 THEN \'3. 500k-1M\'\r\n            ELSE CASE\r\n              WHEN ""source"".""WuM"" >= 100000 THEN \'2. 100-500k\'\r\n              ELSE CASE\r\n                WHEN ""source"".""WuM"" >= 0 THEN \'1. 0-100k\'\r\n                ELSE \'0. Inactive\'\r\n              END\r\n            END\r\n          END\r\n        END\r\n      END AS ""Tier WuM""\r\n    FROM\r\n      (\r\n        SELECT\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""nk_investor_api_id"" AS ""dim_investor_relations__via__fk_investor_relations__b8278d3c"",\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""office_name"" AS ""dim_investor_relations__via__fk_investor_relations__43b4316e"",\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" AS ""dim_investor_relations__via__fk_investor_relations__b578e382"",\r\n          SUM(""gold"".""fact_balance"".""gross_balance"") AS ""WuM""\r\n        FROM\r\n          ""gold"".""fact_balance""\r\n         \r\nLEFT JOIN ""gold"".""dim_investor_relations"" AS ""dim_investor_relations__via__fk_investor_relations_key"" ON ""gold"".""fact_balance"".""fk_investor_relations_key"" = ""dim_investor_relations__via__fk_investor_relations_key"".""sk_investor_relations_key""\r\n          LEFT JOIN ""gold"".""dim_calendar"" AS ""dim_calendar__via__fk_calendar_key"" ON ""gold"".""fact_balance"".""fk_calendar_key"" = ""dim_calendar__via__fk_calendar_key"".""sk_calendar_key""\r\n       \r\nWHERE\r\n          (\r\n            ""dim_calendar__via__fk_calendar_key"".""is_month_closure"" = TRUE\r\n          )\r\n         \r\n   AND (\r\n            ""gold"".""fact_balance"".""date_balance"" >= DATE_TRUNC(\'month\', NOW())\r\n          )\r\n          AND (\r\n            ""gold"".""fact_balance"".""date_balance"" < DATE_TRUNC(\'month\', DATE_ADD(\'month\', 1, NOW()))\r\n          )\r\n          AND (\r\n            ""dim_investor_relations__via__fk_investor_relations_key"".""channel"" = \'Warren W\'\r\n          )\r\n          AND (\r\n            ""dim_investor_relations__via__fk_investor_relations_key"".""is_active"" = TRUE\r\n          )\r\n          AND (\r\n            ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" IS NOT NULL\r\n          )\r\n          AND (\r\n            (\r\n              ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" <> \'\'\r\n            )\r\n           \r\n    OR (\r\n              ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" IS NULL\r\n            )\r\n          )\r\n       \r\nGROUP BY\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""nk_investor_api_id"",\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""office_name"",\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name""\r\n       \r\nORDER BY\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""nk_investor_api_id"" ASC,\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""office_name"" ASC,\r\n          ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" ASC\r\n      ) AS ""source""\r\n  ) AS ""source""\r\nGROUP BY\r\n  ""source"".""dim_investor_relations__via__fk_investor_relations__b578e382"",\r\n  ""source"".""dim_investor_relations__via__fk_investor_relations__43b4316e"",\r\n  ""source"".""Tier WuM""\r\nORDER BY\r\n  ""source"".""dim_investor_relations__via__fk_investor_relations__b578e382"" ASC,\r\n  ""source"".""dim_investor_relations__via__fk_investor_relations__43b4316e"" ASC,\r\n  ""source"".""Tier WuM"" ASC\r\n```', 'created_at': datetime.datetime(2024, 5, 21, 14, 41, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2255987099, 'issue_id': 2197339565, 'author': 'cgg-pwdt', 'body': ""@ViniAppel we found a workaround. this seems to happen only when we have spaces on the metrics / dimensions. if we don't, it works."", 'created_at': datetime.datetime(2024, 7, 29, 13, 43, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2321439807, 'issue_id': 2197339565, 'author': 'mngr', 'body': 'Can we close this?', 'created_at': datetime.datetime(2024, 8, 30, 14, 28, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2324157784, 'issue_id': 2197339565, 'author': 'NevRA', 'body': 'Closing this one, it looks like some issue with automation, PR was merged', 'created_at': datetime.datetime(2024, 9, 2, 8, 40, 30, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-20 16:01:21 UTC): @zbodi74 tagging you since I think you went through this

zbodi74 on (2024-03-21 12:41:46 UTC): Reproducible on `1.49.1`
1. Create metric: Sample database, Orders, Sum of Total, save it as OrderSumOfTotals
2. Create a question: Orders, Summarize: OrderSumOfTotals, group by: Created at: Month, 
3. Add a filter: OrderSumOfTotals > 1
4. See the error: 
Column ""source.ordersumoftotals"" not found; SQL statement:
```
SELECT
  ""source"".""CREATED_AT"" AS ""CREATED_AT"",
  ""source"".""sum"" AS ""sum""
FROM
  (
    SELECT
      DATE_TRUNC('month', ""PUBLIC"".""ORDERS"".""CREATED_AT"") AS ""CREATED_AT"",
      SUM(""PUBLIC"".""ORDERS"".""TOTAL"") AS ""sum""
    FROM
      ""PUBLIC"".""ORDERS""
   
GROUP BY
      DATE_TRUNC('month', ""PUBLIC"".""ORDERS"".""CREATED_AT"")
   
ORDER BY
      DATE_TRUNC('month', ""PUBLIC"".""ORDERS"".""CREATED_AT"") ASC
  ) AS ""source""
WHERE
  ""source"".""ordersumoftotals"" = 1
```

ViniAppel on (2024-05-21 14:41:45 UTC): Hello guys.
We are experiencing the same problem here. We updated from version 0.48.1 to 0.49.10 yesterday and started having this issue for users who use no-code.
Below is an example screenshot and the query generated by Metabase.

![image](https://github.com/metabase/metabase/assets/68851613/60a3cc6c-2218-4f21-8ab5-e5d12afe0ff3)

```
SELECT
  ""source"".""dim_investor_relations__via__fk_investor_relations__b578e382"" AS ""dim_investor_relations__via__fk_investor_relations__b578e382"",
  ""source"".""dim_investor_relations__via__fk_investor_relations__43b4316e"" AS ""dim_investor_relations__via__fk_investor_relations__43b4316e"",
  ""source"".""Tier WuM"" AS ""Tier WuM"",
  SUM(""source"".""WuM"") AS ""WuM""
FROM
  (
    SELECT
      ""source"".""WuM"" AS ""WuM"",
      CASE
        WHEN ""source"".""WuM"" >= 10000000 THEN '5. 10M+'
        ELSE CASE
          WHEN ""source"".""WuM"" >= 1000000 THEN '4. 1-10M'
          ELSE CASE
            WHEN ""source"".""WuM"" >= 500000 THEN '3. 500k-1M'
            ELSE CASE
              WHEN ""source"".""WuM"" >= 100000 THEN '2. 100-500k'
              ELSE CASE
                WHEN ""source"".""WuM"" >= 0 THEN '1. 0-100k'
                ELSE '0. Inactive'
              END
            END
          END
        END
      END AS ""Tier WuM""
    FROM
      (
        SELECT
          ""dim_investor_relations__via__fk_investor_relations_key"".""nk_investor_api_id"" AS ""dim_investor_relations__via__fk_investor_relations__b8278d3c"",
          ""dim_investor_relations__via__fk_investor_relations_key"".""office_name"" AS ""dim_investor_relations__via__fk_investor_relations__43b4316e"",
          ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" AS ""dim_investor_relations__via__fk_investor_relations__b578e382"",
          SUM(""gold"".""fact_balance"".""gross_balance"") AS ""WuM""
        FROM
          ""gold"".""fact_balance""
         
LEFT JOIN ""gold"".""dim_investor_relations"" AS ""dim_investor_relations__via__fk_investor_relations_key"" ON ""gold"".""fact_balance"".""fk_investor_relations_key"" = ""dim_investor_relations__via__fk_investor_relations_key"".""sk_investor_relations_key""
          LEFT JOIN ""gold"".""dim_calendar"" AS ""dim_calendar__via__fk_calendar_key"" ON ""gold"".""fact_balance"".""fk_calendar_key"" = ""dim_calendar__via__fk_calendar_key"".""sk_calendar_key""
       
WHERE
          (
            ""dim_calendar__via__fk_calendar_key"".""is_month_closure"" = TRUE
          )
         
   AND (
            ""gold"".""fact_balance"".""date_balance"" >= DATE_TRUNC('month', NOW())
          )
          AND (
            ""gold"".""fact_balance"".""date_balance"" < DATE_TRUNC('month', DATE_ADD('month', 1, NOW()))
          )
          AND (
            ""dim_investor_relations__via__fk_investor_relations_key"".""channel"" = 'Warren W'
          )
          AND (
            ""dim_investor_relations__via__fk_investor_relations_key"".""is_active"" = TRUE
          )
          AND (
            ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" IS NOT NULL
          )
          AND (
            (
              ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" <> ''
            )
           
    OR (
              ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" IS NULL
            )
          )
       
GROUP BY
          ""dim_investor_relations__via__fk_investor_relations_key"".""nk_investor_api_id"",
          ""dim_investor_relations__via__fk_investor_relations_key"".""office_name"",
          ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name""
       
ORDER BY
          ""dim_investor_relations__via__fk_investor_relations_key"".""nk_investor_api_id"" ASC,
          ""dim_investor_relations__via__fk_investor_relations_key"".""office_name"" ASC,
          ""dim_investor_relations__via__fk_investor_relations_key"".""advisor_name"" ASC
      ) AS ""source""
  ) AS ""source""
GROUP BY
  ""source"".""dim_investor_relations__via__fk_investor_relations__b578e382"",
  ""source"".""dim_investor_relations__via__fk_investor_relations__43b4316e"",
  ""source"".""Tier WuM""
ORDER BY
  ""source"".""dim_investor_relations__via__fk_investor_relations__b578e382"" ASC,
  ""source"".""dim_investor_relations__via__fk_investor_relations__43b4316e"" ASC,
  ""source"".""Tier WuM"" ASC
```

cgg-pwdt (Issue Creator) on (2024-07-29 13:43:04 UTC): @ViniAppel we found a workaround. this seems to happen only when we have spaces on the metrics / dimensions. if we don't, it works.

mngr on (2024-08-30 14:28:22 UTC): Can we close this?

NevRA on (2024-09-02 08:40:30 UTC): Closing this one, it looks like some issue with automation, PR was merged

"
2197334841,issue,closed,completed,Start of 50 Cycle Routine Clojure Dependency Bump,"[Notion doc about dependency bumping](https://www.notion.so/metabase/Dependency-Bumping-8ab452bbfc1f4131addd1653235c1b0f?pvs=4)

Subtasks:

- [x] Update all minor and patch versions and test. Revert breakage.
- [x] Update minor versions in modules
- [x] Determine whether we want to upgrade the Mongo driver to version 5
- [x] Anything else, TBD",tsmacdonald,2024-03-20 11:47:18+00:00,['tsmacdonald'],2024-04-09 13:36:06+00:00,2024-03-25 08:32:58+00:00,https://github.com/metabase/metabase/issues/40354,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Team/Workflows', 'aka BEC')]",[],
2197161412,issue,closed,not_planned,Region map supports scaling size,"For a basic map of a country's city, it appears very low on the map. Incomplete metabase cannot zoom in on a specific city or the entire map",Avey777,2024-03-20 10:17:30+00:00,[],2024-03-27 12:19:39+00:00,2024-03-27 12:19:39+00:00,https://github.com/metabase/metabase/issues/40350,"[('Type:New Feature', ''), ('.Needs Triage', '')]","[{'comment_id': 2022631888, 'issue_id': 2197161412, 'author': 'ignacio-mb', 'body': 'Dupe of https://github.com/metabase/metabase/issues/33928', 'created_at': datetime.datetime(2024, 3, 27, 12, 19, 39, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-03-27 12:19:39 UTC): Dupe of https://github.com/metabase/metabase/issues/33928

"
2197125241,issue,closed,completed,Migrate global css in `frontend/src/metabase/components/Calendar/Calendar.module.css`,,oisincoveney,2024-03-20 09:59:30+00:00,['oisincoveney'],2024-03-22 13:40:48+00:00,2024-03-22 13:40:48+00:00,https://github.com/metabase/metabase/issues/40349,[],[],
2196891739,issue,open,,[Driver] Doris,"**Is your feature request related to a problem? Please describe.**
For example, the decimal type in Doris cannot be parsed as the decimal type in MySQL.

**Describe the solution you'd like**
![image](https://github.com/metabase/metabase/assets/37656068/a40c2975-5ebe-4c1b-8d6a-db0f158f44c8)

**Describe alternatives you've considered**

**How important is this feature to you?**
support  Doris type

**Additional context**

",15767714253,2024-03-20 07:57:34+00:00,[],2025-02-04 20:30:17+00:00,,https://github.com/metabase/metabase/issues/40343,"[('Database/', ''), ('Type:New Feature', '')]",[],
2196850745,issue,closed,completed,Language version switching issues,"### Describe the bug

When I log in to metabase, I set the language version to English, but sometimes when I log in, it still displays Chinese text. No one else is using my account, just me logging in.
![image](https://github.com/metabase/metabase/assets/59472399/59a6a82a-5047-42a4-b92c-e08801bc3863)
![image](https://github.com/metabase/metabase/assets/59472399/4e73ab55-2979-409b-851b-b2aeab81cd37)



### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
metabase VersionÔºö v0.47.7
databaseÔºö PostgreSQL
```


### Severity

My users are so frustrated that they have to switch again each time

### Additional context

_No response_",sccll,2024-03-20 07:28:05+00:00,['npfitz'],2024-06-09 15:08:42+00:00,2024-06-09 15:08:29+00:00,https://github.com/metabase/metabase/issues/40342,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2147743434, 'issue_id': 2196850745, 'author': 'npfitz', 'body': ""@sccll I took a look at this in both the latest version, as well as 47.4, and I don't seem to be able to reproduce the issue. Do you know what the language setting for the instance is?"", 'created_at': datetime.datetime(2024, 6, 4, 14, 53, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2148124041, 'issue_id': 2196850745, 'author': 'npfitz', 'body': ""@sccll I was actually able to reproduce. I'm going to work on a fix, but for now refreshing the page after you log in should ensure that translations are correct across the app"", 'created_at': datetime.datetime(2024, 6, 4, 18, 11, 43, tzinfo=datetime.timezone.utc)}]","npfitz (Assginee) on (2024-06-04 14:53:34 UTC): @sccll I took a look at this in both the latest version, as well as 47.4, and I don't seem to be able to reproduce the issue. Do you know what the language setting for the instance is?

npfitz (Assginee) on (2024-06-04 18:11:43 UTC): @sccll I was actually able to reproduce. I'm going to work on a fix, but for now refreshing the page after you log in should ensure that translations are correct across the app

"
2196776922,issue,closed,completed,Getting `.csv` and `.xlsx` both in dashboard subscriptions,"### Describe the bug

When selected to send email attachment format as `.xlsx`, the `.csv` attachments are also sent. 
1. Selected `.xlsx`
<img width=""386"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/aefa07d3-0fc6-4d8b-8f39-8d269ee558dd"">

attachments in mail
<img width=""524"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/2b9336d1-4970-41ad-a0d5-bf3aa94cde9c"">

2. Selected `.csv`
<img width=""385"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/6445bd8d-461a-44be-9b3a-86d24d4c3411"">

attachments in mail
<img width=""544"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/dd660e12-e448-4a94-870d-58bcb7ea3b49"">

3. Also, not a blocker for us, but if anyone was downloading email reports using the name of attachments, their names has changed as well.
Previously it used to be the name of the report itself. 
<img width=""544"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/8115384f-76d8-41e1-b34e-d14aa9552d16"">




### To Reproduce

1. Go to 'Subscriptions'
2. Click on 'Set up a new schedule'
3. Select 'Email it'
4. Enter your email address
5. Scroll down to 'Attach results' and enable attachments.
6. Select `.xlsx` file format
7. Scroll up and click on 'Send now'
8. Check mail for double attachments.


### Expected behavior

There should be only `.xlsx` files, preferably with the report name as the filename. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.3.39-MariaDB-0ubuntu0.20.04.2""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Calcutta""
    }
  }
}
```


### Severity

P3, just bloating up emails

### Additional context

Not sure if the query is ran once or twice to send two email attachments. If query is also ran twice then this might be a P2 as it is increasing the query costs as well.",abhishek-superk,2024-03-20 06:47:37+00:00,[],2025-01-30 07:33:30+00:00,2025-01-30 07:33:28+00:00,https://github.com/metabase/metabase/issues/40340,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Reporting/Pulses', 'Now called Subscriptions'), ('Reporting/Export', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2010381112, 'issue_id': 2196776922, 'author': 'luizarakaki', 'body': 'Is this a regression? Pretty sure this was always like this. We always send tables as csv regardless of the attachment setting.\r\nIt is weird tho', 'created_at': datetime.datetime(2024, 3, 20, 19, 0, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2011100533, 'issue_id': 2196776922, 'author': 'abhishek-superk', 'body': 'Not sure, @luizarakaki. But something must have changed in the backend since 1 & 3 are the email attachments from v0.49 and v0.48 respectively for the same dashboard. The reports were, and are still, a table visualisation only.', 'created_at': datetime.datetime(2024, 3, 21, 3, 1, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620125375, 'issue_id': 2196776922, 'author': 'tsplude', 'body': 'Hey @abhishek-superk, I am unable to reproduce this on 52.8 - are you still seeing this?', 'created_at': datetime.datetime(2025, 1, 28, 21, 48, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2623746677, 'issue_id': 2196776922, 'author': 'abhishek-superk', 'body': 'Hi @tsplude, thanks for getting back on this. This was fixed back in May itself around with the release of v0.49.9 or v49.10.', 'created_at': datetime.datetime(2025, 1, 30, 7, 33, 29, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-20 19:00:43 UTC): Is this a regression? Pretty sure this was always like this. We always send tables as csv regardless of the attachment setting.
It is weird tho

abhishek-superk (Issue Creator) on (2024-03-21 03:01:02 UTC): Not sure, @luizarakaki. But something must have changed in the backend since 1 & 3 are the email attachments from v0.49 and v0.48 respectively for the same dashboard. The reports were, and are still, a table visualisation only.

tsplude on (2025-01-28 21:48:42 UTC): Hey @abhishek-superk, I am unable to reproduce this on 52.8 - are you still seeing this?

abhishek-superk (Issue Creator) on (2025-01-30 07:33:29 UTC): Hi @tsplude, thanks for getting back on this. This was fixed back in May itself around with the release of v0.49.9 or v49.10.

"
2196324079,issue,closed,completed,postgresql tables that are visible through column grants aren't available for simple questions,"### Describe the bug

As part of CSV uploads introduced in 0.47 via https://github.com/metabase/metabase/pull/33415 metabase began excluding postgresql tables that have only a subset of their columns selectable from the schema for simple questions (you can still query them via native sql). This appears to have been unintentional since scanning for permissions looks to have been to determine which tables are writable by csv upload and tables that aren't even in the list, like the known limitation for foreign tables, are still included in the database schema sync for building simple questions on. 

This is a serious security limitation as it's the safest way to remove access for particular columns from even metabase users constructing native sql, and it is the only way to achieve this with postgres:

https://www.postgresql.org/docs/current/sql-grant.html
""Granting the privilege at the table level and then revoking it for one column will not do what one might wish: the table-level grant is unaffected by a column-level operation.""

### To Reproduce

Grant access to only some columns of a table that doesn't have a full table grant, e.g. GRANT SELECT (id) ON foo and when metabase syncs the database schema it will be missing for simple questions.  

### Expected behavior

Tables with only a subset of columns available should be usable in simple questions.  

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase versions 0.47 and up talking to a postgres database
```


### Severity

blocking users of tables with limited permissions

### Additional context

A fix is available in https://github.com/metabase/metabase/pull/40034",ericcj,2024-03-20 00:24:04+00:00,[],2024-03-25 08:15:58+00:00,2024-03-25 08:15:58+00:00,https://github.com/metabase/metabase/issues/40338,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Database/Postgres', None), ('Database/Redshift', None), ('Administration/Metadata & Sync', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.')]",[],
2196300698,issue,closed,not_planned,Custom Logo Prevents Access to Hamburger Menu for left Nav,"### Describe the bug

When a custom logo is added to Metabase in v49 the hamburger menu may become unusable in some browsers. 

- The behavior seems to be specific to SVG files where the viewBox attribute isn't being utilized
- SVG files without the viewBox attribute set expand over the top of the menu

This issue did not present in Firefox for me but it's observable in current versions of Chrome and Edge browsers.

### To Reproduce

1. Launch Metabase Version 49 in Chrome or Edge
2. Upload custom SVG logo without viewBox attribute set (attached my test files)
3. Exit Admin
4. Try to collapse left hand nav

[
![test_logo_with_viewbox](https://github.com/metabase/metabase/assets/13661163/bd7fcf83-5292-4bab-af31-247cfaad8fac)
![test_logo_no_viewbox](https://github.com/metabase/metabase/assets/13661163/3629e607-0efd-4181-abf0-dfd67383d42f)
](url)

### Expected behavior

The hamburger menu should be accessible

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133.1-microsoft-standard-WSL2"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22 (Debian 11.22-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v1.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Severe - if someone upgrades with a logo file that creates this nav issue it could be really impactful

### Additional context

_No response_",ixipixi,2024-03-20 00:05:41+00:00,['rafpaf'],2024-03-20 15:36:04+00:00,2024-03-20 14:51:57+00:00,https://github.com/metabase/metabase/issues/40337,"[('Type:Bug', 'Product defects'), ('Browser:Chrome', ''), ('.Frontend', ''), ('.Needs Triage', ''), ('.Escalation', '')]","[{'comment_id': 2008379605, 'issue_id': 2196300698, 'author': 'paoliniluis', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/40153', 'created_at': datetime.datetime(2024, 3, 20, 0, 11, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2009760923, 'issue_id': 2196300698, 'author': 'paoliniluis', 'body': 'fixed', 'created_at': datetime.datetime(2024, 3, 20, 14, 51, 57, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-20 00:11:41 UTC): Duplicate of https://github.com/metabase/metabase/issues/40153

paoliniluis on (2024-03-20 14:51:57 UTC): fixed

"
2196115994,issue,closed,completed,QB header jumps when switching between a simple and a notebook modes,"### Describe the bug

Due to the computed CSS styles, a query builder header is jumping when switching between its modes (simple / notebook). This creates visually displeasing and slightly annoying effect because all textual elements move with the header.


### To Reproduce

1. Open any table and toggle the notebook view on and off
![Kapture 2024-03-19 at 23 04 10](https://github.com/metabase/metabase/assets/31325167/80a8a62c-b34b-4646-8fdc-97bffd7b69f8)

### Expected behavior

Query builder header should have a fixed height, and all its elements should render in a same position every time, regardless of the chosen mode.

### Severity
It can be quite annoying, but it doesn't obstruct the work on QB.
",nemanjaglumac,2024-03-19 22:07:20+00:00,['nemanjaglumac'],2024-03-22 07:13:49+00:00,2024-03-20 12:18:53+00:00,https://github.com/metabase/metabase/issues/40334,"[('.CSS', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode')]","[{'comment_id': 2014486994, 'issue_id': 2196115994, 'author': 'asimumba', 'body': 'Hi,\r\n\r\nI am getting this effect but on filters on a question written in SQL. When I apply a filter I get a jump that re-aligns the order of the filters. I am using Metabase V0.49.1, equally on v0.49.0.', 'created_at': datetime.datetime(2024, 3, 22, 7, 13, 48, tzinfo=datetime.timezone.utc)}]","asimumba on (2024-03-22 07:13:48 UTC): Hi,

I am getting this effect but on filters on a question written in SQL. When I apply a filter I get a jump that re-aligns the order of the filters. I am using Metabase V0.49.1, equally on v0.49.0.

"
2196099954,issue,closed,completed,There is an additional border between the notebook and the query builder header,"### Describe the bug

You may have noticed that the border between the query builder header and the notebook is thicker than the border between the header and the simple mode.

This is due to the superfluous border top on the notebook container.

### To Reproduce

1. Open any table
(Look how thin this line is)
![image](https://github.com/metabase/metabase/assets/31325167/bc5103d2-082c-40c5-9fcd-2ac8e231a565)

2. Switch to the notebook mode
![image](https://github.com/metabase/metabase/assets/31325167/c0e7a01c-94c7-4385-aa50-3e450ea84f14)

Notice the thicker line.

### Expected behavior

The line thickness should be consistent between the query builder header and the body, regardless of the view (simple vs notebook)

### Severity

Just a visual annoyance. Unless you have OCD, very hard to notice.
",nemanjaglumac,2024-03-19 21:59:07+00:00,['nemanjaglumac'],2024-03-20 10:12:12+00:00,2024-03-20 09:40:07+00:00,https://github.com/metabase/metabase/issues/40333,"[('.CSS', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder')]",[],
2196098367,issue,closed,completed,Specific date filter shifts dates by one day,"### Describe the bug

When creating a question with the Metabase editor and setting a filter on a range of specific dates as shown

![image](https://github.com/metabase/metabase/assets/16065058/3801586e-8f39-4fba-8db5-ac8808bb6a11)


the results returned are shifted one day 'forward' (spanning Feb 2 through Feb 8) as shown

![image](https://github.com/metabase/metabase/assets/16065058/4a91c32b-2bed-493a-8d0f-68c16795ca0b)

What is most puzzling is that that the generated SQL from the editor appears to be correct
```
SELECT
  DATE_TRUNC(""day"", ""_DIM_DATES__via___DIM_DATE_KEY"".""DATE"") AS ""_DIM_DATES__via___DIM_DATE_KEY__DATE"",
  COUNT(*) AS ""count""
FROM
  ""ANALYTICS"".""PUBLIC"".""_REDACTED_""
 
LEFT JOIN ""ANALYTICS"".""PUBLIC"".""_DIM_DATES"" AS ""_DIM_DATES__via___DIM_DATE_KEY"" ON ""PUBLIC"".""_REDACTED_"".""_DIM_DATE_KEY"" = ""_DIM_DATES__via___DIM_DATE_KEY"".""_DIM_DATE_KEY""
WHERE
  (
    ""_DIM_DATES__via___DIM_DATE_KEY"".""DATE"" >= '2024-02-01 00:00 Z':: timestamp_tz
  )
 
   AND (
    ""_DIM_DATES__via___DIM_DATE_KEY"".""DATE"" < '2024-02-08 00:00 Z':: timestamp_tz
  )
GROUP BY
  DATE_TRUNC(""day"", ""_DIM_DATES__via___DIM_DATE_KEY"".""DATE"")
ORDER BY
  DATE_TRUNC(""day"", ""_DIM_DATES__via___DIM_DATE_KEY"".""DATE"") ASC
  ```
  
  And, indeed, if I take the above SQL and create a new SQL query in Metabase, I get the correct range of dates
  
  
![image](https://github.com/metabase/metabase/assets/16065058/19122bf2-cea5-43b0-a743-a81be5d13cb0)


### To Reproduce

Unfortunately, I am not able to reproduce with an equivalent query in the sample database. One potential difference is that the  sample database uses colums of type DateTime, whereas the date dimension in my example is of type Date. But it's still baffling why the same SQL generated by the question editor works when submitted as SQL.

### Expected behavior

I would expect the Metabase question to return the same set of rows as the SQL query does, for a set of dates that match what was selected in the date picker.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.210-201.852.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""America/New_York""
  },
  ""metabase-info"": {
    ""databases"": [
      ""snowflake"",
      ""materialize""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.11""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""UTC""
    }
  }
}
```


### Severity

Severely degrading the trust our stakeholders place in Metabase

### Additional context

This example is running against Snowflake.",jonathan-k-shapiro,2024-03-19 21:58:10+00:00,['camsaul'],2024-08-28 02:10:36+00:00,2024-03-26 19:57:53+00:00,https://github.com/metabase/metabase/issues/40332,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Processor', ''), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 2009088564, 'issue_id': 2196098367, 'author': 'darksciencebase', 'body': 'is this https://github.com/metabase/metabase/issues/39769 ?', 'created_at': datetime.datetime(2024, 3, 20, 9, 12, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2012505662, 'issue_id': 2196098367, 'author': 'jonathan-k-shapiro', 'body': '> is this https://github.com/metabase/metabase/issues/39769 ?\r\n\r\nNot sure but tracking PR #40416 mentioned there with hope.', 'created_at': datetime.datetime(2024, 3, 21, 14, 49, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-03-20 09:12:30 UTC): is this https://github.com/metabase/metabase/issues/39769 ?

jonathan-k-shapiro (Issue Creator) on (2024-03-21 14:49:00 UTC): Not sure but tracking PR #40416 mentioned there with hope.

"
2196083772,issue,open,,Option to take out the date reference in Trend viz,"**Is your feature request related to a problem? Please describe.**
Previously, the date wasn't there in the Trend viz

**Describe the solution you'd like**
Ability to toggle on/off the appearance of the date reference 

**Describe alternatives you've considered**
Not available

**How important is this feature to you?**
Requested by a customer that says it confuses their users (internal ticket: [25799](https://metabase.zendesk.com/agent/tickets/25799))

**Additional context**
Related to https://github.com/metabase/metabase/issues/39277
",ignacio-mb,2024-03-19 21:47:21+00:00,[],2025-02-04 20:31:50+00:00,,https://github.com/metabase/metabase/issues/40330,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges')]","[{'comment_id': 2560170933, 'issue_id': 2196083772, 'author': 'ixipixi', 'body': 'https://github.com/metabase/metabase/issues/51641', 'created_at': datetime.datetime(2024, 12, 23, 19, 1, 40, tzinfo=datetime.timezone.utc)}]","ixipixi on (2024-12-23 19:01:40 UTC): https://github.com/metabase/metabase/issues/51641

"
2196083452,issue,closed,completed,Group managers can't add people to groups,"### Describe the bug

A group manager is unable to add people to groups.  This is a key function of the group manager feature.

### To Reproduce


1. Go to your Metabase
2. Create two new users:
a Cynthia GroupManager
b Cynthia NotInAgroup
4. Create a new group, TestyTest
5. Add Cynthia GroupManager to TestyTest
6. Make Cynthia GroupManager the manager of TestyTest
7. Log in as CynthiaGroupManager and navigate to the Groups tab
8. Click on the group TestyTest
9. Press Add People
10. Attempt to Add Cynthia NotinAgroup



### Expected behavior

You should be able to add Cynthia Notinagroup, but you can't

### Logs

_No response_

### Information about your Metabase installation

```JSON
Seen in 48.8
```


### Severity

This is entire point of the feature, and it doesn't work

### Additional context

Related to https://github.com/metabase/metabase/issues/40328",cbalusek,2024-03-19 21:47:12+00:00,[],2024-04-03 17:57:33+00:00,2024-04-01 21:19:15+00:00,https://github.com/metabase/metabase/issues/40329,"[('Type:Bug', 'Product defects'), ('Administration/People', 'and Groups. Also user Account Settings')]","[{'comment_id': 2030573905, 'issue_id': 2196083452, 'author': 'luizarakaki', 'body': 'Fixed by https://github.com/metabase/metabase/pull/40619', 'created_at': datetime.datetime(2024, 4, 1, 21, 19, 15, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-04-01 21:19:15 UTC): Fixed by https://github.com/metabase/metabase/pull/40619

"
2196075813,issue,closed,completed,Group managers cannot view all people ,"### Describe the bug

A group manager is unable to view all People on the People tab.  Per the [docs](https://www.metabase.com/docs/latest/people-and-groups/managing#group-managers), a group manager should be able to view all people

### To Reproduce

1. Go to your Metabase
2. Create two new users:
a Cynthia GroupManager
b Cynthia NotInAgroup
4. Create a new group, TestyTest
5. Add Cynthia GroupManager to TestyTest
6. Make Cynthia GroupManager the manager of TestyTest
7. Log in as CynthiaGroupManager and navigate to the People tab


### Expected behavior

Cynthia GroupManager should be able to view Cynthia NotInAGroup.  She can't.  All she can see is Cynthia GroupManager

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Seen in version 48.8
```


### Severity

Feature is broken

### Additional context

_No response_",cbalusek,2024-03-19 21:42:20+00:00,['johnswanson'],2024-03-28 10:08:23+00:00,2024-03-27 15:40:29+00:00,https://github.com/metabase/metabase/issues/40328,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Administration/People', 'and Groups. Also user Account Settings'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2008211278, 'issue_id': 2196075813, 'author': 'cbalusek', 'body': 'Also related:  https://github.com/metabase/metabase/issues/40329', 'created_at': datetime.datetime(2024, 3, 19, 22, 3, 10, tzinfo=datetime.timezone.utc)}]","cbalusek (Issue Creator) on (2024-03-19 22:03:10 UTC): Also related:  https://github.com/metabase/metabase/issues/40329

"
2195871311,issue,closed,completed,Missing Description for MariaDB Connector in Data Source Documentation,"### Describe the bug

Respectfully, I'd like to bring attention to the absence of a description for the MariaDB connectivity within the data source documentation on the [Metabase website](https://www.metabase.com/data_sources/), despite its compatibility with Metabase through the MariaDB connector. Additionally, it's worth noting that even MySQL connectivity utilizes the MariaDB connector, as indicated in the documentation found at [connecting-to-mysql-8-servers](https://www.metabase.com/docs/latest/databases/connections/mysql#connecting-to-mysql-8-servers).

I could not find the website source code on GitHub. Thus, I'm raising this issue to request for adding MariaDB in the documentation.

### To Reproduce

1. Go to main data source page https://www.metabase.com/data_sources/
2. There's no MariaDB database connectivity mentioned.
3. Go to https://www.metabase.com/data_sources/mysql
4. It only mentioned `Connect Metabase to your MySQL database`

### Expected behavior

1. The main data source page https://www.metabase.com/data_sources/ should include MariaDB database.
2. MariaDB should likewise be mentioned in the sub-page of ""MYSQL connector"" https://www.metabase.com/data_sources/mysql.


### Logs

N/A

### Information about your Metabase installation

N/A


### Severity

Documentation Only

### Additional context

_No response_",HugoWenTD,2024-03-19 19:56:00+00:00,[],2024-08-07 21:08:49+00:00,2024-08-07 21:08:49+00:00,https://github.com/metabase/metabase/issues/40325,"[('Type:Documentation', ''), ('Database/MySQL', None)]","[{'comment_id': 2008109908, 'issue_id': 2195871311, 'author': 'paoliniluis', 'body': 'Hi @HugoWenTD, you\'re right, we only say that we connect to MariaDB on ""Metabase uses the MariaDB connector to connect to MariaDB and MySQL servers""', 'created_at': datetime.datetime(2024, 3, 19, 20, 52, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2008363707, 'issue_id': 2195871311, 'author': 'HugoWenTD', 'body': '> Hi @HugoWenTD, you\'re right, we only say that we connect to MariaDB on ""Metabase uses the MariaDB connector to connect to MariaDB and MySQL servers""\r\n\r\nyeah, as a new user begin to use Metabase, I refer to the main data sources page at https://www.metabase.com/data_sources/ to check for compatibility with my database. However, it\'s unfortunate that MariaDB is not listed there, nor is it specifically mentioned on its direct sub-page at https://www.metabase.com/data_sources/mysql. The description simply states:\r\n`Connect Metabase to your **MySQL** database, and empower your team to explore, visualize, and publish insights in just five minutes.`\r\n\r\nUntil I reached the third level of detailed documentation I can eventually see something related to MariaDB:\r\nhttps://www.metabase.com/docs/latest/databases/connections/mysql#connecting-to-mysql-8-servers\r\n\r\nSo IMO for better user experience and facilitate adoption among MariaDB users, it would be beneficial for Metabase to include mention of MariaDB on the main data sources page at https://www.metabase.com/data_sources. Or at least a simple change on https://www.metabase.com/data_sources/mysql could be:\r\n> \\- ""Connect Metabase to your **MySQL** database, and empower your team to explore, visualize, and publish insights in just five minutes.""\r\n> \\+ ""Connect Metabase to your **MySQL or MariaDB** database, and empower your team to explore, visualize, and publish insights in just five minutes.""', 'created_at': datetime.datetime(2024, 3, 19, 23, 56, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2078559276, 'issue_id': 2195871311, 'author': 'ottok', 'body': ""@paoliniluis This has 10 +1's - could you please considering merging this?"", 'created_at': datetime.datetime(2024, 4, 26, 3, 15, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2078849863, 'issue_id': 2195871311, 'author': 'paoliniluis', 'body': ""@ottok there's no PR to merge"", 'created_at': datetime.datetime(2024, 4, 26, 8, 5, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2079533430, 'issue_id': 2195871311, 'author': 'ottok', 'body': 'Is the website source code somewhere on GitHub? Can anyone fix this by\ncontributing a PR instead to close this Issue?', 'created_at': datetime.datetime(2024, 4, 26, 14, 42, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2219148240, 'issue_id': 2195871311, 'author': 'ottok', 'body': '@paoliniluis Is the website source code somewhere on GitHub? Can anyone fix this by contributing a PR?', 'created_at': datetime.datetime(2024, 7, 10, 0, 25, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273714458, 'issue_id': 2195871311, 'author': 'jeff-bruemmer', 'body': ""@HugoWenTD \r\n\r\nWe have an open issue to create a separate driver for MariaDB: https://github.com/metabase/metabase/issues/35242. See the description for the rationale.\r\n\r\nIn the meantime, I spoke with the team and we agreed that we should include MariaDB in our list of officially supported databases.\r\n\r\nI've updated:\r\n\r\n- https://www.metabase.com/data_sources/\r\n- https://www.metabase.com/docs/latest/databases/connecting#connecting-to-supported-databases\r\n\r\nAnd added:\r\n\r\n- https://www.metabase.com/docs/latest/databases/connections/mariadb\r\n\r\nLet me know if these changes close this issue, and thanks for reporting!\r\n\r\nCC @ottok"", 'created_at': datetime.datetime(2024, 8, 7, 15, 14, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274351143, 'issue_id': 2195871311, 'author': 'HugoWenTD', 'body': '@jeff-bruemmer Great! Thank you for adding the MariaDB documentation. It looks good to me!', 'created_at': datetime.datetime(2024, 8, 7, 21, 8, 49, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-19 20:52:36 UTC): Hi @HugoWenTD, you're right, we only say that we connect to MariaDB on ""Metabase uses the MariaDB connector to connect to MariaDB and MySQL servers""

HugoWenTD (Issue Creator) on (2024-03-19 23:56:18 UTC): yeah, as a new user begin to use Metabase, I refer to the main data sources page at https://www.metabase.com/data_sources/ to check for compatibility with my database. However, it's unfortunate that MariaDB is not listed there, nor is it specifically mentioned on its direct sub-page at https://www.metabase.com/data_sources/mysql. The description simply states:
`Connect Metabase to your **MySQL** database, and empower your team to explore, visualize, and publish insights in just five minutes.`

Until I reached the third level of detailed documentation I can eventually see something related to MariaDB:
https://www.metabase.com/docs/latest/databases/connections/mysql#connecting-to-mysql-8-servers

So IMO for better user experience and facilitate adoption among MariaDB users, it would be beneficial for Metabase to include mention of MariaDB on the main data sources page at https://www.metabase.com/data_sources. Or at least a simple change on https://www.metabase.com/data_sources/mysql could be:

ottok on (2024-04-26 03:15:01 UTC): @paoliniluis This has 10 +1's - could you please considering merging this?

paoliniluis on (2024-04-26 08:05:19 UTC): @ottok there's no PR to merge

ottok on (2024-04-26 14:42:21 UTC): Is the website source code somewhere on GitHub? Can anyone fix this by
contributing a PR instead to close this Issue?

ottok on (2024-07-10 00:25:34 UTC): @paoliniluis Is the website source code somewhere on GitHub? Can anyone fix this by contributing a PR?

jeff-bruemmer on (2024-08-07 15:14:04 UTC): @HugoWenTD 

We have an open issue to create a separate driver for MariaDB: https://github.com/metabase/metabase/issues/35242. See the description for the rationale.

In the meantime, I spoke with the team and we agreed that we should include MariaDB in our list of officially supported databases.

I've updated:

- https://www.metabase.com/data_sources/
- https://www.metabase.com/docs/latest/databases/connecting#connecting-to-supported-databases

And added:

- https://www.metabase.com/docs/latest/databases/connections/mariadb

Let me know if these changes close this issue, and thanks for reporting!

CC @ottok

HugoWenTD (Issue Creator) on (2024-08-07 21:08:49 UTC): @jeff-bruemmer Great! Thank you for adding the MariaDB documentation. It looks good to me!

"
2195628886,issue,closed,completed,Convert Settings to FC,,npfitz,2024-03-19 18:00:26+00:00,[],2024-03-20 14:53:18+00:00,2024-03-20 14:53:18+00:00,https://github.com/metabase/metabase/issues/40317,[],[],
2195572736,issue,closed,completed,[Epic] Time over time comparisons - Cumulative and Offset Window functions,"## Offset function bugs
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/42509
- [ ] https://github.com/metabase/metabase/issues/42764
- [ ] https://github.com/metabase/metabase/issues/42726
- [ ] https://github.com/metabase/metabase/issues/42725
- [ ] https://github.com/metabase/metabase/issues/42739
- [ ] https://github.com/metabase/metabase/issues/42323
- [ ] https://github.com/metabase/metabase/issues/40711
- [ ] https://github.com/metabase/metabase/issues/42377
- [ ] https://github.com/metabase/metabase/issues/42554
```

## Offset function implementation
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/42752
- [ ] https://github.com/metabase/metabase/issues/42511
- [ ] https://github.com/metabase/metabase/issues/5817
- [ ] https://github.com/metabase/metabase/issues/42908
- [ ] https://github.com/metabase/metabase/issues/42318
- [ ] https://github.com/metabase/metabase/issues/42452
- [ ] https://github.com/metabase/metabase/issues/9170
- [ ] https://github.com/metabase/metabase/issues/42753
- [ ] https://github.com/metabase/metabase/issues/9393
```

## Cumulative sum and count
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/40991
- [ ] https://github.com/metabase/metabase/issues/41000
- [ ] https://github.com/metabase/metabase/issues/13634
- [ ] https://github.com/metabase/metabase/issues/2862
- [ ] https://github.com/metabase/metabase/issues/40990
- [ ] https://github.com/metabase/metabase/issues/40992
- [ ] https://github.com/metabase/metabase/issues/15118
```",perivamsi,2024-03-19 17:32:48+00:00,['camsaul'],2024-05-20 17:09:50+00:00,2024-05-20 17:09:49+00:00,https://github.com/metabase/metabase/issues/40313,"[('Querying/Processor', ''), ('.Backend', ''), ('Querying/', ''), ('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2120855940, 'issue_id': 2195572736, 'author': 'camsaul', 'body': 'Closing this out since the feature implementation is done and all that is left now is tests and cleanup', 'created_at': datetime.datetime(2024, 5, 20, 17, 9, 50, tzinfo=datetime.timezone.utc)}]","camsaul (Assginee) on (2024-05-20 17:09:50 UTC): Closing this out since the feature implementation is done and all that is left now is tests and cleanup

"
2195493064,issue,closed,completed,Move modals out of NewItemMenu,,npfitz,2024-03-19 16:59:53+00:00,[],2024-03-20 12:19:07+00:00,2024-03-20 12:19:07+00:00,https://github.com/metabase/metabase/issues/40312,[],[],
2195413250,issue,closed,completed,Exporting date values changes the year,"### Describe the bug

Error notced after metabase update to 0.49.0.
When exporting a report with a date of 12/31/2023 (in short format 'M/D/YYYY') to .csv or .json the year gets exported as 2024.
Oddly, the same error does not occur for 12/31/2022.

### To Reproduce

1. Run SQL Code that generates the date e.g. `SELECT TO_DATE('20231231', 'YYYYMMDD')`
2. Set the Column Formatting  - Date style as M/D/YYYY
3. Export the value as .csv or .json


### Expected behavior

To export the date with the accurate year.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- browser: Brave 1.63.174
- OS: Windows 11
- databases: Redshift, PostgreSQL
- Metabase version: 0.49.0
- hosting: AWS
- internal DB: PostgeSQL
```


### Severity

impacting our data integrity

### Additional context

_No response_",hs-nborjanovic,2024-03-19 16:20:41+00:00,['adam-james-v'],2024-03-21 22:36:55+00:00,2024-03-21 15:09:19+00:00,https://github.com/metabase/metabase/issues/40306,"[('Type:Bug', 'Product defects'), ('.Correctness', ''), ('Reporting/Export', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2009574280, 'issue_id': 2195413250, 'author': 'mudge', 'body': 'We have seen the same issue with a BigQuery `DATE` column with the value `31/12/2023` appearing correctly in the UI but exporting to CSV or JSON (but not XSLX) will produce `31/12/2024`.\r\n\r\nFor reference:\r\n\r\n* Browser: Safari 17.4\r\n* OS: macOS 14.4\r\n* Database: BigQuery\r\n* Metabase version: 0.49.0\r\n* Hosting: Self-hosted on Heroku\r\n* Internal DB: PostgreSQL\r\n\r\nOur BigQuery, PostgreSQL and server timezones are all set to UTC.', 'created_at': datetime.datetime(2024, 3, 20, 13, 32, 2, tzinfo=datetime.timezone.utc)}]","mudge on (2024-03-20 13:32:02 UTC): We have seen the same issue with a BigQuery `DATE` column with the value `31/12/2023` appearing correctly in the UI but exporting to CSV or JSON (but not XSLX) will produce `31/12/2024`.

For reference:

* Browser: Safari 17.4
* OS: macOS 14.4
* Database: BigQuery
* Metabase version: 0.49.0
* Hosting: Self-hosted on Heroku
* Internal DB: PostgreSQL

Our BigQuery, PostgreSQL and server timezones are all set to UTC.

"
2195342741,issue,closed,not_planned,Can not use variable in question: Packets out of order when reading field packets,"### Describe the bug

when I use mysql database type to connect starrocks3.2.4 , and I created a question with variable.but error occured.

<img width=""849"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1222123/a1cd0972-50a6-46df-859b-273536a18e2d"">

But if I do not use variable ,then everything is ok.

<img width=""709"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1222123/55d06a1d-6a13-4450-a6ed-07b0bb833398"">




### To Reproduce

1. create datasource connect to starrocks 3.2.4
2. create question with variable
3. preview, See error


### Expected behavior

_No response_

### Logs

[46dc2f81-30a1-4dcb-8993-277c7e7a1b1f] 2024-03-19T23:32:01+08:00 ERROR metabase.query-processor.middleware.catch-exceptions Error processing query: Packets out of order when reading field packets, expected was EOF stream.Packet contents (hex) = 
+--------------------------------------------------+
|  0  1  2  3  4  5  6  7   8  9  a  b  c  d  e  f |
+--------------------------------------------------+------------------+
| 03 64 65 66 00 00 00 0F  E5 88 86 E6 A1 88 E5 90 | .def............ |
| 8D E5 8D 95 E9 87 8F 0F  E5 88 86 E6 A1 88 E5 90 | ................ |
| 8D E5 8D 95 E9 87 8F 0C  3F 00 14 00 00 00 08 00 | ........?....... |
| 00 00 00 00                                      | ....             |
+--------------------------------------------------+------------------+

{:database_id 35,
 :started_at #t ""2024-03-19T23:31:59.722911+08:00[Asia/Shanghai]"",
 :via
 [{:status :failed,
   :class java.sql.SQLNonTransientConnectionException,
   :error
   ""Packets out of order when reading field packets, expected was EOF stream.Packet contents (hex) = \n+--------------------------------------------------+\n|  0  1  2  3  4  5  6  7   8  9  a  b  c  d  e  f |\n+--------------------------------------------------+------------------+\n| 03 64 65 66 00 00 00 0F  E5 88 86 E6 A1 88 E5 90 | .def............ |\n| 8D E5 8D 95 E9 87 8F 0F  E5 88 86 E6 A1 88 E5 90 | ................ |\n| 8D E5 8D 95 E9 87 8F 0C  3F 00 14 00 00 00 08 00 | ........?....... |\n| 00 00 00 00                                      | ....             |\n+--------------------------------------------------+------------------+\n"",
   :stacktrace
   [""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.handleIoException(AbstractQueryProtocol.java:2089)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readResultSet(AbstractQueryProtocol.java:1861)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.readPacket(AbstractQueryProtocol.java:1568)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.getResult(AbstractQueryProtocol.java:1518)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:257)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.executeQuery(AbstractQueryProtocol.java:235)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.setMaxRows(AbstractQueryProtocol.java:1421)""
    ""org.mariadb.jdbc.internal.protocol.AbstractQueryProtocol.prolog(AbstractQueryProtocol.java:1901)""
    ""org.mariadb.jdbc.MariaDbStatement.executeQueryPrologue(MariaDbStatement.java:214)""
    ""org.mariadb.jdbc.ClientSidePreparedStatement.executeInternal(ClientSidePreparedStatement.java:201)""
    ""org.mariadb.jdbc.ClientSidePreparedStatement.execute(ClientSidePreparedStatement.java:149)""
    ""org.mariadb.jdbc.ClientSidePreparedStatement.executeQuery(ClientSidePreparedStatement.java:163)""
    ""com.mchange.v2.c3p0.impl.NewProxyPreparedStatement.executeQuery(NewProxyPreparedStatement.java:1471)""
    ""--> driver.sql_jdbc.execute$fn__77780.invokeStatic(execute.clj:556)""
    ""driver.sql_jdbc.execute$fn__77780.invoke(execute.clj:554)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invokeStatic(execute.clj:569)""
    ""driver.sql_jdbc.execute$execute_statement_or_prepared_statement_BANG_.invoke(execute.clj:565)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__77863$fn__77864.invoke(execute.clj:696)""
    ""driver.sql_jdbc.execute$execute_reducible_query$fn__77863.invoke(execute.clj:695)""
    ""driver.sql_jdbc.execute$fn__77656$fn__77657.invoke(execute.clj:388)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invokeStatic(execute.clj:334)""
    ""driver.sql_jdbc.execute$do_with_resolved_connection.invoke(execute.clj:317)""
    ""driver.sql_jdbc.execute$fn__77656.invokeStatic(execute.clj:382)""
    ""driver.sql_jdbc.execute$fn__77656.invoke(execute.clj:380)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:689)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invokeStatic(execute.clj:686)""
    ""driver.sql_jdbc.execute$execute_reducible_query.invoke(execute.clj:678)""
    ""driver.sql_jdbc$fn__105637.invokeStatic(sql_jdbc.clj:82)""
    ""driver.sql_jdbc$fn__105637.invoke(sql_jdbc.clj:80)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$run_query_with_cache.invokeStatic(cache.clj:202)""
    ""query_processor.middleware.cache$run_query_with_cache.invoke(cache.clj:186)""


### Information about your Metabase installation

```JSON
- metabase version 0.48.8
- metabase run as jar file in centos
- metabase database: mysql 8.0.30
- datasource: starrocks 3.2.4 with datatype mysql
```


### Severity

blocking

### Additional context

while connect to other starrocks version ,everything is ok.",yuyii,2024-03-19 15:48:50+00:00,[],2024-03-20 03:09:46+00:00,2024-03-19 16:40:14+00:00,https://github.com/metabase/metabase/issues/40305,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2007653465, 'issue_id': 2195342741, 'author': 'paoliniluis', 'body': 'seems like an issue with starrocks, have you checked https://docs.starrocks.io/docs/reference/System_variable/#max_allowed_packet?', 'created_at': datetime.datetime(2024, 3, 19, 16, 40, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2008598266, 'issue_id': 2195342741, 'author': 'yuyii', 'body': ""I've try to edit  max_allowed_packet = 67108864,but no effects, same error..."", 'created_at': datetime.datetime(2024, 3, 20, 3, 9, 45, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-19 16:40:10 UTC): seems like an issue with starrocks, have you checked https://docs.starrocks.io/docs/reference/System_variable/#max_allowed_packet?

yuyii (Issue Creator) on (2024-03-20 03:09:45 UTC): I've try to edit  max_allowed_packet = 67108864,but no effects, same error...

"
2195267000,issue,open,,„ÄêBug in metabase v0.48.8„ÄëThe visualization charts template AREA rendering mismatch betweeen color and variable.,"### Describe the bug

I have an idea to rending my data with date as X-axis, and with two custom variables as Y-axis on metabase. Yes, it did it. BUT, I find something WRONG with the AREA chart. As in the first picture, the variable putA's value is larger than the variable putKS's value. But, the color and the varible is mismath. In the chart's visualization, we can see the putKS is larger than the putA. So, I hope this BUG can be solved in the next version. Thank you for your attentions!
<img width=""1669"" alt=""Êà™Â±è2024-03-19 ‰∏ãÂçà10 47 39"" src=""https://github.com/metabase/metabase/assets/18346105/fdfeebaf-4343-4aa8-b678-8bfc604d5859"">
<img width=""1658"" alt=""Êà™Â±è2024-03-19 ‰∏ãÂçà11 03 22"" src=""https://github.com/metabase/metabase/assets/18346105/a9d80baa-1da9-42ca-8681-368d5005df20"">


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Chrome 122.0.6261.94ÔºàOffitial versionÔºâ (x86_64)
- Metabase version v0.48.8 Built on 2024-03-04
- Installation by docker image on docker hub with metabase/metabase:v0.48.8 ON ubuntu 22.02
```


### Severity

annoying

### Additional context

<img width=""1669"" alt=""Êà™Â±è2024-03-19 ‰∏ãÂçà10 47 39"" src=""https://github.com/metabase/metabase/assets/18346105/ff1de909-40ad-45f9-a758-2c8985dbf66f"">
",david11rsww,2024-03-19 15:19:31+00:00,[],2024-05-20 14:04:40+00:00,,https://github.com/metabase/metabase/issues/40303,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2007650197, 'issue_id': 2195267000, 'author': 'paoliniluis', 'body': ""can you give us steps to reproduce this with the sample dataset? if we can't reproduce this we can't fix it"", 'created_at': datetime.datetime(2024, 3, 19, 16, 38, 27, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-19 16:38:27 UTC): can you give us steps to reproduce this with the sample dataset? if we can't reproduce this we can't fix it

"
2195122004,issue,closed,completed,Table Picker,Data Picker boilerplate with Table Picker implemented,iethree,2024-03-19 14:24:23+00:00,['kamilmielnik'],2024-04-09 11:11:19+00:00,2024-04-09 11:11:18+00:00,https://github.com/metabase/metabase/issues/40298,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2044755942, 'issue_id': 2195122004, 'author': 'kamilmielnik', 'body': 'Closed by #40509', 'created_at': datetime.datetime(2024, 4, 9, 11, 11, 18, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Assginee) on (2024-04-09 11:11:18 UTC): Closed by #40509

"
2195119727,issue,closed,completed,fix extra padding in entitypicker search component,"![Screen Shot 2024-03-19 at 8 22 47 AM](https://github.com/metabase/metabase/assets/30528226/72f8d038-7210-4bb5-8a61-be592257f32b)

padding should be inside the scroll container",iethree,2024-03-19 14:23:28+00:00,['iethree'],2024-04-19 21:44:01+00:00,2024-04-19 21:43:53+00:00,https://github.com/metabase/metabase/issues/40297,[],"[{'comment_id': 2067318566, 'issue_id': 2195119727, 'author': 'iethree', 'body': 'fixed in  <a href=""https://github.com/metabase/metabase/pull/40207"" target=""_blank"">[Question + Model Picker](https://github.com/metabase/metabase/pull/40207)</a>', 'created_at': datetime.datetime(2024, 4, 19, 21, 43, 53, tzinfo=datetime.timezone.utc)}]","iethree (Issue Creator) on (2024-04-19 21:43:53 UTC): fixed in  <a href=""https://github.com/metabase/metabase/pull/40207"" target=""_blank"">[Question + Model Picker](https://github.com/metabase/metabase/pull/40207)</a>

"
2195059345,issue,closed,completed,Metabase version upgrade issue from v1.44.0 to v1.48.8,"After updating Metabase version we are facing below errors
1) Email subscriptions are stopped, we are not getting any emails.
2) Users are not 
![image - 2024-03-19T192931 201](https://github.com/metabase/metabase/assets/124993472/dd112137-973c-4b03-a533-75b46b055fd6)
able to login
3) Json values are not properly populated in some tables
4) Question ID's are get removed

**Logs**
Added screenshot for the same

**Screenshots**
Screenshots added

**Severity**
blocking our usage of Metabase entirely


![image - 2024-03-19T184121 845](https://github.com/metabase/metabase/assets/124993472/f9474d03-b2a0-4b6a-a542-896f4e465120)
![image - 2024-03-19T192319 066](https://github.com/metabase/metabase/assets/124993472/611d9389-14fc-4e92-a840-d1b0b2356329)


```[tasklist]
### Tasks
```
",Nitinsodel,2024-03-19 14:00:01+00:00,[],2024-03-20 14:32:53+00:00,2024-03-20 10:26:49+00:00,https://github.com/metabase/metabase/issues/40296,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2007616311, 'issue_id': 2195059345, 'author': 'paoliniluis', 'body': 'It seems that you upgraded and then downgraded WITHOUT restoring a database backup, as the database is returning ""core_user.google_auth"" does not exist.\r\n\r\nwhat\'s your version right now?', 'created_at': datetime.datetime(2024, 3, 19, 16, 21, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2008702347, 'issue_id': 2195059345, 'author': 'Nitinsodel', 'body': 'We downgraded to previous version that is v1.44.0\r\n\r\n\r\n\r\nThanks & Regards\r\nNitinkumar Rathod\r\nWe\r\n\r\n\r\nOn Tue, Mar 19, 2024 at 9:52\u202fPM Luis Paolini ***@***.***>\r\nwrote:\r\n\r\n> It seems that you upgraded and then downgraded WITHOUT restoring a\r\n> database backup, as the database is returning ""core_user.google_auth"" does\r\n> not exist.\r\n>\r\n> what\'s your version right now?\r\n>\r\n> ‚Äî\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/40296#issuecomment-2007616311>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/A5ZT7QDORUUU3PJXEBJOUH3YZBQ3HAVCNFSM6AAAAABE5T5UJKVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDAMBXGYYTMMZRGE>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>', 'created_at': datetime.datetime(2024, 3, 20, 5, 54, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2009222016, 'issue_id': 2195059345, 'author': 'Nitinsodel', 'body': 'can you please provide steps to upgrade Metabase ?', 'created_at': datetime.datetime(2024, 3, 20, 10, 26, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2009718230, 'issue_id': 2195059345, 'author': 'paoliniluis', 'body': ""@Nitinsodel please check the documentation, if you're a paid customer, please contact support"", 'created_at': datetime.datetime(2024, 3, 20, 14, 32, 41, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-19 16:21:48 UTC): It seems that you upgraded and then downgraded WITHOUT restoring a database backup, as the database is returning ""core_user.google_auth"" does not exist.

what's your version right now?

Nitinsodel (Issue Creator) on (2024-03-20 05:54:28 UTC): We downgraded to previous version that is v1.44.0



Thanks & Regards
Nitinkumar Rathod
We


On Tue, Mar 19, 2024 at 9:52‚ÄØPM Luis Paolini ***@***.***>
wrote:

Nitinsodel (Issue Creator) on (2024-03-20 10:26:49 UTC): can you please provide steps to upgrade Metabase ?

paoliniluis on (2024-03-20 14:32:41 UTC): @Nitinsodel please check the documentation, if you're a paid customer, please contact support

"
2194874991,issue,closed,completed,Static embedding - setting empty value for a locked filter prevents linked filters to be populated,"### Describe the bug

In a dashboard shared with static embedding when an empty value is set for a locked filter, no filter values will be returned for any linked filters that depend on the locked filter.


### To Reproduce

1. Create a GUI question: Sample Database, select Products.
2. Save, and add it to a dashboard.
3. Set up filters for `Category` and `Title`. Link the `Title` filter to `Category`, so that only relevant titles are returned in the drop down.
4. Set up the dashboard for static embedding:
  * set `Category` parameter to Locked
  * leave `Title` as Editable

In the embedding application, set the `category` parameter in the JWT token to the following values, and load the page:
6. sending ({...,  ""params"":{""category"":[""Widget""] }} ) --> works ok (viz displays, Title dropdown has the proper values)
7. do not send the parameter --> works ok (results in a visualization error, API response: You must specify a value for :category in the JWT)
8(!) sending ({...,  ""params"":{""category"":null}} ) --> viz displays, but the Title dropdown has no values
9(!) sending ({...,  ""params"":{""category"":[] }} ) --> viz displays, but the Title dropdown has no values

### Expected behavior

In steps 8 and 9, the Title dropdown should be populated.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.210-201.852.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""snowflake"",
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.10""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v1.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""America/Los_Angeles""
    }
  }
}
```


### Severity

P1 - affects customers and I am not aware of a workaround.

### Additional context

Customer reported a similar error with v1.48.7, I used v1.49.0 to reproduce.",zbodi74,2024-03-19 12:45:19+00:00,['adam-james-v'],2024-07-24 19:21:51+00:00,2024-07-24 14:44:35+00:00,https://github.com/metabase/metabase/issues/40292,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('Embedding/Static', 'Static embedding, previously known as signed embedding'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2203581803, 'issue_id': 2194874991, 'author': 'WiNloSt', 'body': 'This seems to be a BE issue.\r\n\r\nI found [a comment from Flamber](https://github.com/metabase/metabase/issues/7306#issuecomment-1296243924) stating that passing `[]` used to work.\r\n\r\n#### On 1.49.1 and 1.49.13\r\n- The dashboard loads with `params: { category: [] }`\r\n- But when calling parameter values (`GET /api/embed/dashboard/:jwt/params/:param-id/values`) we got `Invalid query: {:query {:filter [nil nil [""end of input""]]}}`\r\n\r\n#### On 1.50.9\r\n- The dashboard loads with `params: { category: [] }`\r\n- Parameter values endpoint works as expected.\r\n\r\n#### On master @ 213b6d2c81fbcb4805fa2ac071de1c5e8ea431a1\r\n- The dashboard will fail to load with `params: { category: [] }` with this error on BE\r\n    <details>\r\n    <summary>Stack trace</summary>\r\n    \r\n    ```\r\n    2024-07-02 15:39:20,602 ERROR middleware.catch-exceptions :: Error processing query: Invalid output: [nil nil [""end of input, got: nil""]]\r\n    {:database_id 1,\r\n     :started_at #t ""2024-07-02T15:39:20.588024Z[UTC]"",\r\n     :via\r\n     [{:status :failed,\r\n       :class clojure.lang.ExceptionInfo,\r\n       :error\r\n       ""Error preprocessing query in metabase.query_processor.preprocess$ensure_legacy$fn__98301@2ea8854e: Invalid output: [nil nil [\\""end of input, got: nil\\""]]"",\r\n       :stacktrace\r\n       [""--> query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311$fn__98312.invoke(preprocess.clj:133)""\r\n        ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311.invoke(preprocess.clj:119)""\r\n        ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:225)""\r\n        ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""\r\n        ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310.invoke(preprocess.clj:118)""\r\n        ""query_processor.preprocess$fn__98309$fn__98318.invoke(preprocess.clj:114)""\r\n        ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)""\r\n        ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""\r\n        ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$eval145868$handle_audit_app_internal_queries__145869$fn__145870.invoke(handle_audit_queries.clj:145)""\r\n        ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__93554.invoke(enterprise.clj:103)""\r\n        ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$_AMPERSAND_f__99144.invoke(process_userland_query.clj:182)""\r\n        ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$fn__99150.invoke(process_userland_query.clj:166)""\r\n        ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$_AMPERSAND_f__98848.invoke(catch_exceptions.clj:128)""\r\n        ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$fn__98860.invoke(catch_exceptions.clj:118)""\r\n        ""query_processor$fn__99487$_AMPERSAND_f__99488$fn__99489.invoke(query_processor.clj:78)""\r\n        ""query_processor.setup$fn__98266$_AMPERSAND_f__98267$fn__98268.invoke(setup.clj:189)""\r\n        ""query_processor.setup$fn__98256$_AMPERSAND_f__98257$fn__98258.invoke(setup.clj:181)""\r\n        ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248$fn__98249.invoke(setup.clj:166)""\r\n        ""driver$do_with_driver.invokeStatic(driver.clj:104)""\r\n        ""driver$do_with_driver.invoke(driver.clj:99)""\r\n        ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248.invoke(setup.clj:165)""\r\n        ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236$fn__98239.invoke(setup.clj:151)""\r\n        ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:171)""\r\n        ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""\r\n        ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:160)""\r\n        ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""\r\n        ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236.invoke(setup.clj:150)""\r\n        ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$_AMPERSAND_f__98218.invoke(setup.clj:128)""\r\n        ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$fn__98221.invoke(setup.clj:122)""\r\n        ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:232)""\r\n        ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""\r\n        ""query_processor$fn__99487$_AMPERSAND_f__99488.invoke(query_processor.clj:76)""\r\n        ""query_processor$fn__99487$fn__99493.invoke(query_processor.clj:69)""\r\n        ""query_processor.card$fn__110725$_AMPERSAND_f__110726.invoke(card.clj:170)""\r\n        ""query_processor.card$fn__110725$fn__110728.invoke(card.clj:166)""\r\n        ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389$fn__129390.invoke(public.clj:140)""\r\n        ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""\r\n        ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""\r\n        ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389.invoke(public.clj:139)""\r\n        ""query_processor.streaming$_streaming_response$fn__89760$fn__89761$fn__89762.invoke(streaming.clj:175)""\r\n        ""query_processor.streaming$_streaming_response$fn__89760$fn__89761.invoke(streaming.clj:174)""\r\n        ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""\r\n        ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""\r\n        ""query_processor.streaming$_streaming_response$fn__89760.invoke(streaming.clj:171)""\r\n        ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""\r\n        ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""\r\n        ""async.streaming_response$do_f_async$task__49332.invoke(streaming_response.clj:87)""],\r\n       :error_type :qp,\r\n       :ex-data\r\n       {:fn\r\n        #object[metabase.query_processor.preprocess$ensure_legacy$fn__98301 0x2ea8854e ""metabase.query_processor.preprocess$ensure_legacy$fn__98301@2ea8854e""],\r\n        :query\r\n        {:constraints {:max-results 10000, :max-results-bare-rows 2000},\r\n         :lib/type :mbql/query,\r\n         :lib/metadata\r\n         (metabase.lib.metadata.invocation-tracker/invocation-tracker-provider (metabase.lib.metadata.cached-provider/cached-metadata-provider (metabase.lib.metadata.jvm/->UncachedApplicationDatabaseMetadataProvider 1))),\r\n         :stages [{:lib/type :mbql.stage/mbql, :source-table 1}],\r\n         :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},\r\n         :viz-settings {},\r\n         :lib.convert/converted? true,\r\n         :info\r\n         {:context :embedded-dashboard,\r\n          :card-id 2258,\r\n          :card-name ""Products"",\r\n          :dashboard-id 667,\r\n          :query-hash #object[""[B"" 0x4b0a7681 ""[B@4b0a7681""]},\r\n         :database 1,\r\n         :parameters\r\n         [{:value nil,\r\n           :type :string/=,\r\n           :slug ""title"",\r\n           :id ""39fbce6a"",\r\n           :target [:dimension [:field 8 {:base-type :type/Text}]]}\r\n          {:value [],\r\n           :type :string/=,\r\n           :slug ""category"",\r\n           :id ""7990be10"",\r\n           :target [:dimension [:field 1 {:base-type :type/Text}]]}]},\r\n        :type :qp}}],\r\n     :action_id nil,\r\n     :error_type :qp,\r\n     :json_query\r\n     {:constraints {:max-results 10000, :max-results-bare-rows 2000},\r\n      :type :query,\r\n      :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},\r\n      :cache-strategy nil,\r\n      :viz-settings {},\r\n      :database 1,\r\n      :query {:source-table 1},\r\n      :parameters\r\n      [{:type :string/=, :value nil, :slug ""title"", :id ""39fbce6a"", :target [:dimension [:field 8 {:base-type :type/Text}]]}\r\n       {:type :string/=,\r\n        :value [],\r\n        :slug ""category"",\r\n        :id ""7990be10"",\r\n        :target [:dimension [:field 1 {:base-type :type/Text}]]}]},\r\n     :native nil,\r\n     :status :failed,\r\n     :class clojure.lang.ExceptionInfo,\r\n     :stacktrace\r\n     [""--> driver.common.parameters.operators$fn__97359$fn__97371.invoke(operators.clj:66)""\r\n      ""query_processor.middleware.parameters.mbql$fn__97416$_AMPERSAND_f__97418.invoke(mbql.clj:66)""\r\n      ""query_processor.middleware.parameters.mbql$fn__97416$fn__97438.invoke(mbql.clj:62)""\r\n      ""query_processor.middleware.parameters.mbql$expand.invokeStatic(mbql.clj:119)""\r\n      ""query_processor.middleware.parameters.mbql$expand.invoke(mbql.clj:101)""\r\n      ""query_processor.middleware.parameters$expand_mbql_params.invokeStatic(parameters.clj:38)""\r\n      ""query_processor.middleware.parameters$expand_mbql_params.invoke(parameters.clj:34)""\r\n      ""query_processor.middleware.parameters$expand_one.invokeStatic(parameters.clj:50)""\r\n      ""query_processor.middleware.parameters$expand_one.invoke(parameters.clj:42)""\r\n      ""query_processor.middleware.parameters$expand_all$replace_97513__97514.invoke(parameters.clj:60)""\r\n      ""lib.util.match.impl$replace_in_collection$iter__38373__38377$fn__38378.invoke(impl.cljc:45)""\r\n      ""lib.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)""\r\n      ""lib.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""\r\n      ""query_processor.middleware.parameters$expand_all$replace_97513__97514.invoke(parameters.clj:60)""\r\n      ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:60)""\r\n      ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:54)""\r\n      ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:57)""\r\n      ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:54)""\r\n      ""query_processor.middleware.parameters$expand_parameters.invokeStatic(parameters.clj:84)""\r\n      ""query_processor.middleware.parameters$expand_parameters.invoke(parameters.clj:79)""\r\n      ""query_processor.middleware.parameters$fn__97534$_AMPERSAND_f__97535.invoke(parameters.clj:93)""\r\n      ""query_processor.middleware.parameters$fn__97534$fn__97540.invoke(parameters.clj:90)""\r\n      ""query_processor.middleware.parameters$substitute_parameters.invokeStatic(parameters.clj:120)""\r\n      ""query_processor.middleware.parameters$substitute_parameters.invoke(parameters.clj:111)""\r\n      ""query_processor.preprocess$ensure_legacy$fn__98301.invoke(preprocess.clj:62)""\r\n      ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311$fn__98312.invoke(preprocess.clj:128)""\r\n      ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311.invoke(preprocess.clj:119)""\r\n      ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:225)""\r\n      ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""\r\n      ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310.invoke(preprocess.clj:118)""\r\n      ""query_processor.preprocess$fn__98309$fn__98318.invoke(preprocess.clj:114)""\r\n      ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)""\r\n      ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""\r\n      ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$eval145868$handle_audit_app_internal_queries__145869$fn__145870.invoke(handle_audit_queries.clj:145)""\r\n      ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__93554.invoke(enterprise.clj:103)""\r\n      ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$_AMPERSAND_f__99144.invoke(process_userland_query.clj:182)""\r\n      ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$fn__99150.invoke(process_userland_query.clj:166)""\r\n      ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$_AMPERSAND_f__98848.invoke(catch_exceptions.clj:128)""\r\n      ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$fn__98860.invoke(catch_exceptions.clj:118)""\r\n      ""query_processor$fn__99487$_AMPERSAND_f__99488$fn__99489.invoke(query_processor.clj:78)""\r\n      ""query_processor.setup$fn__98266$_AMPERSAND_f__98267$fn__98268.invoke(setup.clj:189)""\r\n      ""query_processor.setup$fn__98256$_AMPERSAND_f__98257$fn__98258.invoke(setup.clj:181)""\r\n      ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248$fn__98249.invoke(setup.clj:166)""\r\n      ""driver$do_with_driver.invokeStatic(driver.clj:104)""\r\n      ""driver$do_with_driver.invoke(driver.clj:99)""\r\n      ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248.invoke(setup.clj:165)""\r\n      ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236$fn__98239.invoke(setup.clj:151)""\r\n      ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:171)""\r\n      ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""\r\n      ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:160)""\r\n      ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""\r\n      ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236.invoke(setup.clj:150)""\r\n      ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$_AMPERSAND_f__98218.invoke(setup.clj:128)""\r\n      ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$fn__98221.invoke(setup.clj:122)""\r\n      ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:232)""\r\n      ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""\r\n      ""query_processor$fn__99487$_AMPERSAND_f__99488.invoke(query_processor.clj:76)""\r\n      ""query_processor$fn__99487$fn__99493.invoke(query_processor.clj:69)""\r\n      ""query_processor.card$fn__110725$_AMPERSAND_f__110726.invoke(card.clj:170)""\r\n      ""query_processor.card$fn__110725$fn__110728.invoke(card.clj:166)""\r\n      ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389$fn__129390.invoke(public.clj:140)""\r\n      ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""\r\n      ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""\r\n      ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389.invoke(public.clj:139)""\r\n      ""query_processor.streaming$_streaming_response$fn__89760$fn__89761$fn__89762.invoke(streaming.clj:175)""\r\n      ""query_processor.streaming$_streaming_response$fn__89760$fn__89761.invoke(streaming.clj:174)""\r\n      ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""\r\n      ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""\r\n      ""query_processor.streaming$_streaming_response$fn__89760.invoke(streaming.clj:171)""\r\n      ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""\r\n      ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""\r\n      ""async.streaming_response$do_f_async$task__49332.invoke(streaming_response.clj:87)""],\r\n     :card_id 2258,\r\n     :context :embedded-dashboard,\r\n     :error ""Invalid output: [nil nil [\\""end of input, got: nil\\""]]"",\r\n     :row_count 0,\r\n     :running_time 0,\r\n     :preprocessed nil,\r\n     :ex-data\r\n     {:type :metabase.util.malli.fn/invalid-output,\r\n      :error\r\n      {:schema [:ref :metabase.legacy-mbql.schema/Filter],\r\n       :value [:= [:field 1 {:base-type :type/Text}]],\r\n       :errors\r\n       ({:path [0 :boolean 0 := 0 1 ""value-or-field""],\r\n         :in [2],\r\n         :schema [:ref :metabase.legacy-mbql.schema/EqualityComparable],\r\n         :value nil,\r\n         :type :malli.core/end-of-input})},\r\n      :humanized [nil nil [""end of input, got: nil""]],\r\n      :schema [:ref :metabase.legacy-mbql.schema/Filter],\r\n      :value [:= [:field 1 {:base-type :type/Text}]],\r\n      :fn-name to-clause},\r\n     :data {:rows [], :cols []}}\r\n    ```\r\n    </details>', 'created_at': datetime.datetime(2024, 7, 2, 15, 41, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206012598, 'issue_id': 2194874991, 'author': 'NevRA', 'body': 'thread https://metaboat.slack.com/archives/C063Q3F1HPF/p1719935985293099', 'created_at': datetime.datetime(2024, 7, 3, 12, 54, 53, tzinfo=datetime.timezone.utc)}]","WiNloSt on (2024-07-02 15:41:01 UTC): This seems to be a BE issue.

I found [a comment from Flamber](https://github.com/metabase/metabase/issues/7306#issuecomment-1296243924) stating that passing `[]` used to work.

#### On 1.49.1 and 1.49.13
- The dashboard loads with `params: { category: [] }`
- But when calling parameter values (`GET /api/embed/dashboard/:jwt/params/:param-id/values`) we got `Invalid query: {:query {:filter [nil nil [""end of input""]]}}`

#### On 1.50.9
- The dashboard loads with `params: { category: [] }`
- Parameter values endpoint works as expected.

#### On master @ 213b6d2c81fbcb4805fa2ac071de1c5e8ea431a1
- The dashboard will fail to load with `params: { category: [] }` with this error on BE
    <details>
    <summary>Stack trace</summary>
    
    ```
    2024-07-02 15:39:20,602 ERROR middleware.catch-exceptions :: Error processing query: Invalid output: [nil nil [""end of input, got: nil""]]
    {:database_id 1,
     :started_at #t ""2024-07-02T15:39:20.588024Z[UTC]"",
     :via
     [{:status :failed,
       :class clojure.lang.ExceptionInfo,
       :error
       ""Error preprocessing query in metabase.query_processor.preprocess$ensure_legacy$fn__98301@2ea8854e: Invalid output: [nil nil [\""end of input, got: nil\""]]"",
       :stacktrace
       [""--> query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311$fn__98312.invoke(preprocess.clj:133)""
        ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311.invoke(preprocess.clj:119)""
        ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:225)""
        ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""
        ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310.invoke(preprocess.clj:118)""
        ""query_processor.preprocess$fn__98309$fn__98318.invoke(preprocess.clj:114)""
        ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)""
        ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
        ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$eval145868$handle_audit_app_internal_queries__145869$fn__145870.invoke(handle_audit_queries.clj:145)""
        ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__93554.invoke(enterprise.clj:103)""
        ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$_AMPERSAND_f__99144.invoke(process_userland_query.clj:182)""
        ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$fn__99150.invoke(process_userland_query.clj:166)""
        ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$_AMPERSAND_f__98848.invoke(catch_exceptions.clj:128)""
        ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$fn__98860.invoke(catch_exceptions.clj:118)""
        ""query_processor$fn__99487$_AMPERSAND_f__99488$fn__99489.invoke(query_processor.clj:78)""
        ""query_processor.setup$fn__98266$_AMPERSAND_f__98267$fn__98268.invoke(setup.clj:189)""
        ""query_processor.setup$fn__98256$_AMPERSAND_f__98257$fn__98258.invoke(setup.clj:181)""
        ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248$fn__98249.invoke(setup.clj:166)""
        ""driver$do_with_driver.invokeStatic(driver.clj:104)""
        ""driver$do_with_driver.invoke(driver.clj:99)""
        ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248.invoke(setup.clj:165)""
        ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236$fn__98239.invoke(setup.clj:151)""
        ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:171)""
        ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""
        ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:160)""
        ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""
        ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236.invoke(setup.clj:150)""
        ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$_AMPERSAND_f__98218.invoke(setup.clj:128)""
        ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$fn__98221.invoke(setup.clj:122)""
        ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:232)""
        ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""
        ""query_processor$fn__99487$_AMPERSAND_f__99488.invoke(query_processor.clj:76)""
        ""query_processor$fn__99487$fn__99493.invoke(query_processor.clj:69)""
        ""query_processor.card$fn__110725$_AMPERSAND_f__110726.invoke(card.clj:170)""
        ""query_processor.card$fn__110725$fn__110728.invoke(card.clj:166)""
        ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389$fn__129390.invoke(public.clj:140)""
        ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
        ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
        ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389.invoke(public.clj:139)""
        ""query_processor.streaming$_streaming_response$fn__89760$fn__89761$fn__89762.invoke(streaming.clj:175)""
        ""query_processor.streaming$_streaming_response$fn__89760$fn__89761.invoke(streaming.clj:174)""
        ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
        ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
        ""query_processor.streaming$_streaming_response$fn__89760.invoke(streaming.clj:171)""
        ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
        ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
        ""async.streaming_response$do_f_async$task__49332.invoke(streaming_response.clj:87)""],
       :error_type :qp,
       :ex-data
       {:fn
        #object[metabase.query_processor.preprocess$ensure_legacy$fn__98301 0x2ea8854e ""metabase.query_processor.preprocess$ensure_legacy$fn__98301@2ea8854e""],
        :query
        {:constraints {:max-results 10000, :max-results-bare-rows 2000},
         :lib/type :mbql/query,
         :lib/metadata
         (metabase.lib.metadata.invocation-tracker/invocation-tracker-provider (metabase.lib.metadata.cached-provider/cached-metadata-provider (metabase.lib.metadata.jvm/->UncachedApplicationDatabaseMetadataProvider 1))),
         :stages [{:lib/type :mbql.stage/mbql, :source-table 1}],
         :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
         :viz-settings {},
         :lib.convert/converted? true,
         :info
         {:context :embedded-dashboard,
          :card-id 2258,
          :card-name ""Products"",
          :dashboard-id 667,
          :query-hash #object[""[B"" 0x4b0a7681 ""[B@4b0a7681""]},
         :database 1,
         :parameters
         [{:value nil,
           :type :string/=,
           :slug ""title"",
           :id ""39fbce6a"",
           :target [:dimension [:field 8 {:base-type :type/Text}]]}
          {:value [],
           :type :string/=,
           :slug ""category"",
           :id ""7990be10"",
           :target [:dimension [:field 1 {:base-type :type/Text}]]}]},
        :type :qp}}],
     :action_id nil,
     :error_type :qp,
     :json_query
     {:constraints {:max-results 10000, :max-results-bare-rows 2000},
      :type :query,
      :middleware {:js-int-to-string? true, :ignore-cached-results? false, :userland-query? true},
      :cache-strategy nil,
      :viz-settings {},
      :database 1,
      :query {:source-table 1},
      :parameters
      [{:type :string/=, :value nil, :slug ""title"", :id ""39fbce6a"", :target [:dimension [:field 8 {:base-type :type/Text}]]}
       {:type :string/=,
        :value [],
        :slug ""category"",
        :id ""7990be10"",
        :target [:dimension [:field 1 {:base-type :type/Text}]]}]},
     :native nil,
     :status :failed,
     :class clojure.lang.ExceptionInfo,
     :stacktrace
     [""--> driver.common.parameters.operators$fn__97359$fn__97371.invoke(operators.clj:66)""
      ""query_processor.middleware.parameters.mbql$fn__97416$_AMPERSAND_f__97418.invoke(mbql.clj:66)""
      ""query_processor.middleware.parameters.mbql$fn__97416$fn__97438.invoke(mbql.clj:62)""
      ""query_processor.middleware.parameters.mbql$expand.invokeStatic(mbql.clj:119)""
      ""query_processor.middleware.parameters.mbql$expand.invoke(mbql.clj:101)""
      ""query_processor.middleware.parameters$expand_mbql_params.invokeStatic(parameters.clj:38)""
      ""query_processor.middleware.parameters$expand_mbql_params.invoke(parameters.clj:34)""
      ""query_processor.middleware.parameters$expand_one.invokeStatic(parameters.clj:50)""
      ""query_processor.middleware.parameters$expand_one.invoke(parameters.clj:42)""
      ""query_processor.middleware.parameters$expand_all$replace_97513__97514.invoke(parameters.clj:60)""
      ""lib.util.match.impl$replace_in_collection$iter__38373__38377$fn__38378.invoke(impl.cljc:45)""
      ""lib.util.match.impl$replace_in_collection.invokeStatic(impl.cljc:44)""
      ""lib.util.match.impl$replace_in_collection.invoke(impl.cljc:39)""
      ""query_processor.middleware.parameters$expand_all$replace_97513__97514.invoke(parameters.clj:60)""
      ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:60)""
      ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:54)""
      ""query_processor.middleware.parameters$expand_all.invokeStatic(parameters.clj:57)""
      ""query_processor.middleware.parameters$expand_all.invoke(parameters.clj:54)""
      ""query_processor.middleware.parameters$expand_parameters.invokeStatic(parameters.clj:84)""
      ""query_processor.middleware.parameters$expand_parameters.invoke(parameters.clj:79)""
      ""query_processor.middleware.parameters$fn__97534$_AMPERSAND_f__97535.invoke(parameters.clj:93)""
      ""query_processor.middleware.parameters$fn__97534$fn__97540.invoke(parameters.clj:90)""
      ""query_processor.middleware.parameters$substitute_parameters.invokeStatic(parameters.clj:120)""
      ""query_processor.middleware.parameters$substitute_parameters.invoke(parameters.clj:111)""
      ""query_processor.preprocess$ensure_legacy$fn__98301.invoke(preprocess.clj:62)""
      ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311$fn__98312.invoke(preprocess.clj:128)""
      ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310$fn__98311.invoke(preprocess.clj:119)""
      ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:225)""
      ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""
      ""query_processor.preprocess$fn__98309$_AMPERSAND_f__98310.invoke(preprocess.clj:118)""
      ""query_processor.preprocess$fn__98309$fn__98318.invoke(preprocess.clj:114)""
      ""query_processor$process_query_STAR__STAR_.invokeStatic(query_processor.clj:44)""
      ""query_processor$process_query_STAR__STAR_.invoke(query_processor.clj:43)""
      ""metabase_enterprise.audit_app.query_processor.middleware.handle_audit_queries$eval145868$handle_audit_app_internal_queries__145869$fn__145870.invoke(handle_audit_queries.clj:145)""
      ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__93554.invoke(enterprise.clj:103)""
      ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$_AMPERSAND_f__99144.invoke(process_userland_query.clj:182)""
      ""query_processor.middleware.process_userland_query$fn__99142$_AMPERSAND_f__99143$fn__99150.invoke(process_userland_query.clj:166)""
      ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$_AMPERSAND_f__98848.invoke(catch_exceptions.clj:128)""
      ""query_processor.middleware.catch_exceptions$fn__98846$_AMPERSAND_f__98847$fn__98860.invoke(catch_exceptions.clj:118)""
      ""query_processor$fn__99487$_AMPERSAND_f__99488$fn__99489.invoke(query_processor.clj:78)""
      ""query_processor.setup$fn__98266$_AMPERSAND_f__98267$fn__98268.invoke(setup.clj:189)""
      ""query_processor.setup$fn__98256$_AMPERSAND_f__98257$fn__98258.invoke(setup.clj:181)""
      ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248$fn__98249.invoke(setup.clj:166)""
      ""driver$do_with_driver.invokeStatic(driver.clj:104)""
      ""driver$do_with_driver.invoke(driver.clj:99)""
      ""query_processor.setup$fn__98246$_AMPERSAND_f__98247$fn__98248.invoke(setup.clj:165)""
      ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236$fn__98239.invoke(setup.clj:151)""
      ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:171)""
      ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""
      ""query_processor.store$fn__78888$_AMPERSAND_f__78889.invoke(store.clj:160)""
      ""query_processor.store$fn__78888$fn__78892.invoke(store.clj:151)""
      ""query_processor.setup$fn__98234$_AMPERSAND_f__98235$fn__98236.invoke(setup.clj:150)""
      ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$_AMPERSAND_f__98218.invoke(setup.clj:128)""
      ""query_processor.setup$fn__98216$_AMPERSAND_f__98217$fn__98221.invoke(setup.clj:122)""
      ""query_processor.setup$fn__98274$_AMPERSAND_f__98275.invoke(setup.clj:232)""
      ""query_processor.setup$fn__98274$fn__98279.invoke(setup.clj:216)""
      ""query_processor$fn__99487$_AMPERSAND_f__99488.invoke(query_processor.clj:76)""
      ""query_processor$fn__99487$fn__99493.invoke(query_processor.clj:69)""
      ""query_processor.card$fn__110725$_AMPERSAND_f__110726.invoke(card.clj:170)""
      ""query_processor.card$fn__110725$fn__110728.invoke(card.clj:166)""
      ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389$fn__129390.invoke(public.clj:140)""
      ""server.middleware.session$do_with_current_user.invokeStatic(session.clj:425)""
      ""server.middleware.session$do_with_current_user.invoke(session.clj:408)""
      ""api.public$process_query_for_card_with_id_run_fn$run__129388$fn__129389.invoke(public.clj:139)""
      ""query_processor.streaming$_streaming_response$fn__89760$fn__89761$fn__89762.invoke(streaming.clj:175)""
      ""query_processor.streaming$_streaming_response$fn__89760$fn__89761.invoke(streaming.clj:174)""
      ""query_processor.streaming$do_with_streaming_rff.invokeStatic(streaming.clj:165)""
      ""query_processor.streaming$do_with_streaming_rff.invoke(streaming.clj:152)""
      ""query_processor.streaming$_streaming_response$fn__89760.invoke(streaming.clj:171)""
      ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:68)""
      ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:66)""
      ""async.streaming_response$do_f_async$task__49332.invoke(streaming_response.clj:87)""],
     :card_id 2258,
     :context :embedded-dashboard,
     :error ""Invalid output: [nil nil [\""end of input, got: nil\""]]"",
     :row_count 0,
     :running_time 0,
     :preprocessed nil,
     :ex-data
     {:type :metabase.util.malli.fn/invalid-output,
      :error
      {:schema [:ref :metabase.legacy-mbql.schema/Filter],
       :value [:= [:field 1 {:base-type :type/Text}]],
       :errors
       ({:path [0 :boolean 0 := 0 1 ""value-or-field""],
         :in [2],
         :schema [:ref :metabase.legacy-mbql.schema/EqualityComparable],
         :value nil,
         :type :malli.core/end-of-input})},
      :humanized [nil nil [""end of input, got: nil""]],
      :schema [:ref :metabase.legacy-mbql.schema/Filter],
      :value [:= [:field 1 {:base-type :type/Text}]],
      :fn-name to-clause},
     :data {:rows [], :cols []}}
    ```
    </details>

NevRA on (2024-07-03 12:54:53 UTC): thread https://metaboat.slack.com/archives/C063Q3F1HPF/p1719935985293099

"
2193630275,issue,closed,completed,Upgrade react testing library to version 12 (latest pre-React 18 release),,sloansparger,2024-03-18 23:08:36+00:00,[],2024-04-08 10:44:30+00:00,2024-04-08 10:44:30+00:00,https://github.com/metabase/metabase/issues/40267,[],[],
2193561763,issue,closed,completed,Copying and pasting values from a spreadsheet to a filter and insert a unique value,"### Describe the bug

This is a regression from v47. We used to allow copy-paste from spreadsheets, e.g.:
![image](https://github.com/metabase/metabase/assets/1711649/52adc3b6-40aa-48ab-b207-7921b3bb9b5e)
```
<google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>
Gizmo
--
Gadget


```

In v47 we used to insert values like:
![filter47](https://github.com/metabase/metabase/assets/1711649/9869f3f7-d226-4efe-ba28-751857b40f46)

But now in v49 we do:
![filterv49](https://github.com/metabase/metabase/assets/1711649/230241be-aac5-4531-97ce-5d65cc00df0c)

This is a step back in ergonomics

### To Reproduce

1) create a spreadsheet with 2 values on different rows: Gizmo and Gadget
2) go to metabase product table and try filtering on the category field, see the difference

### Expected behavior

We should provide the same behavior as v47

### Logs

NA

### Information about your Metabase installation

```JSON
v49
```


### Severity

P2 (lost ergonomics)

### Additional context

_No response_",paoliniluis,2024-03-18 22:39:50+00:00,['ranquild'],2024-04-08 08:47:14+00:00,2024-04-08 08:47:14+00:00,https://github.com/metabase/metabase/issues/40265,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', '')]","[{'comment_id': 2006264831, 'issue_id': 2193561763, 'author': 'darksciencebase', 'body': 'also https://github.com/metabase/metabase/issues/40224', 'created_at': datetime.datetime(2024, 3, 19, 8, 22, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2020115106, 'issue_id': 2193561763, 'author': 'alexandroabalo', 'body': 'Sorry about reopening the thread but in 0.49.1 it seems to not be working properly. \r\n![filterNotWorking](https://github.com/metabase/metabase/assets/85824168/6ca9d0fd-7c36-451b-9951-80794b68cdda)', 'created_at': datetime.datetime(2024, 3, 26, 10, 55, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2022556101, 'issue_id': 2193561763, 'author': 'hss-iullah', 'body': ""Hi this still doesn't appear to work. If I copy and paste a batch of cells fom CSV/Excel/G.Sheet, only the last cell pasted returns a result. All cells / value before appear to be getting a CRLF added to the end which seems to be causing the issue. When I fire the SQL created by MB, it's definitely adding a CR to the end of each value.\r\nOddly, if I copy and paste the cells which someone has sent to me via Teams, it works.\r\n\r\n3rd value returns, values 1 and 2 don't as a CRLF is being added and passed down to the SQL.\r\n![image](https://github.com/metabase/metabase/assets/149382782/ca58a3ea-db11-41be-b586-95895f81bc9e)\r\n\r\nNot sure how this was working before as I believe a CR is always needed?"", 'created_at': datetime.datetime(2024, 3, 27, 11, 35, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2039322135, 'issue_id': 2193561763, 'author': 'hss-iullah', 'body': '0.49.3 - still not fixed.\r\n\r\n![image](https://github.com/metabase/metabase/assets/149382782/3a8ec6fe-07a4-4373-991b-cccb42cf5ab4)', 'created_at': datetime.datetime(2024, 4, 5, 9, 28, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2039650421, 'issue_id': 2193561763, 'author': 'paoliniluis', 'body': '@hss-iullah please post reproduction steps, otherwise we can‚Äôt fix what we can‚Äôt hit', 'created_at': datetime.datetime(2024, 4, 5, 12, 16, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2039890925, 'issue_id': 2193561763, 'author': 'hss-iullah', 'body': ""I simply copied cells from Excel and pasted into the filter. It didn't work against a Redshift database. You can clearly see the carriage return which is being passed into the SQL from Metabase  (the screenshot I supplied earlier)."", 'created_at': datetime.datetime(2024, 4, 5, 14, 2, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2040055474, 'issue_id': 2193561763, 'author': 'ranquild', 'body': ""@hss-iullah are you absolutely sure you're on 49.3? We can't repro with 49.3 and an excel spreadsheet. If yes, could you provide an example of data you're pasting to your filter? The behavior you show is what you'd get on 49.1"", 'created_at': datetime.datetime(2024, 4, 5, 15, 11, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2042186378, 'issue_id': 2193561763, 'author': 'hss-iullah', 'body': 'OK sorted. Some caching at play. Confirmed working. Thanks.', 'created_at': datetime.datetime(2024, 4, 8, 8, 40, 20, tzinfo=datetime.timezone.utc)}]","darksciencebase on (2024-03-19 08:22:41 UTC): also https://github.com/metabase/metabase/issues/40224

alexandroabalo on (2024-03-26 10:55:13 UTC): Sorry about reopening the thread but in 0.49.1 it seems to not be working properly. 
![filterNotWorking](https://github.com/metabase/metabase/assets/85824168/6ca9d0fd-7c36-451b-9951-80794b68cdda)

hss-iullah on (2024-03-27 11:35:32 UTC): Hi this still doesn't appear to work. If I copy and paste a batch of cells fom CSV/Excel/G.Sheet, only the last cell pasted returns a result. All cells / value before appear to be getting a CRLF added to the end which seems to be causing the issue. When I fire the SQL created by MB, it's definitely adding a CR to the end of each value.
Oddly, if I copy and paste the cells which someone has sent to me via Teams, it works.

3rd value returns, values 1 and 2 don't as a CRLF is being added and passed down to the SQL.
![image](https://github.com/metabase/metabase/assets/149382782/ca58a3ea-db11-41be-b586-95895f81bc9e)

Not sure how this was working before as I believe a CR is always needed?

hss-iullah on (2024-04-05 09:28:08 UTC): 0.49.3 - still not fixed.

![image](https://github.com/metabase/metabase/assets/149382782/3a8ec6fe-07a4-4373-991b-cccb42cf5ab4)

paoliniluis (Issue Creator) on (2024-04-05 12:16:52 UTC): @hss-iullah please post reproduction steps, otherwise we can‚Äôt fix what we can‚Äôt hit

hss-iullah on (2024-04-05 14:02:26 UTC): I simply copied cells from Excel and pasted into the filter. It didn't work against a Redshift database. You can clearly see the carriage return which is being passed into the SQL from Metabase  (the screenshot I supplied earlier).

ranquild (Assginee) on (2024-04-05 15:11:46 UTC): @hss-iullah are you absolutely sure you're on 49.3? We can't repro with 49.3 and an excel spreadsheet. If yes, could you provide an example of data you're pasting to your filter? The behavior you show is what you'd get on 49.1

hss-iullah on (2024-04-08 08:40:20 UTC): OK sorted. Some caching at play. Confirmed working. Thanks.

"
2193163206,issue,open,,Ability to define the default dashboard width at the instance level,"**Is your feature request related to a problem? Please describe.**
Some customers where confused about the recent change in 49 regarding the default width for dashboards.

**Describe the solution you'd like**
Ability to change this default to the user/instance preference

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
internal ticket: [25771](https://metabase.zendesk.com/agent/tickets/25771)

**Additional context**
N/A
",ignacio-mb,2024-03-18 19:56:51+00:00,[],2024-03-18 19:57:33+00:00,,https://github.com/metabase/metabase/issues/40258,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]",[],
2193096025,issue,closed,not_planned,e=>e?l.t page title showing up in browser tab when question/table is loading,"### Describe the bug

This message appears after loading a table/question
![Screenshot 2024-03-18 at 4 30 16‚ÄØPM](https://github.com/metabase/metabase/assets/132273646/91429e02-622d-485e-b7c7-bc6b6d2fcfbb)


### To Reproduce

1. Just load any question on 49 and see the browser tab



### Expected behavior

Should be regular ""Waiting for results...""

### Logs

_No response_

### Information about your Metabase installation

```JSON
- 49
```


### Severity

P3

### Additional context

_No response_",ignacio-mb,2024-03-18 19:31:23+00:00,[],2024-03-18 20:37:15+00:00,2024-03-18 20:37:15+00:00,https://github.com/metabase/metabase/issues/40257,"[('Type:Bug', 'Product defects'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2004942082, 'issue_id': 2193096025, 'author': 'ignacio-mb', 'body': 'dupe of https://github.com/metabase/metabase/issues/40051', 'created_at': datetime.datetime(2024, 3, 18, 20, 37, 15, tzinfo=datetime.timezone.utc)}]","ignacio-mb (Issue Creator) on (2024-03-18 20:37:15 UTC): dupe of https://github.com/metabase/metabase/issues/40051

"
2193020219,issue,open,,"Used to be able to do ""percent of previous step"" on funnel charts","### Describe the bug

* When you make a ""funnel"" chart, we used to be able to toggle between ""percent of start"" vs. ""percent of previous step""
* Now im unable to configure this and the only option is to show ""percent of start""
* Can we add this configuration back in?

### To Reproduce

* Create some steps
* Select funnel visualisation
* Click around and cannot change visualisation to ""percent of previous step""

### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.10.209-198.858.amzn2.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""snowflake"",
      ""redshift""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.7""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Annoying, blocking interpretation and insights on which step is the biggest drop off

### Additional context

_No response_",aarthi-subramanian,2024-03-18 18:54:59+00:00,[],2025-02-04 20:31:24+00:00,,https://github.com/metabase/metabase/issues/40256,"[('Priority:P2', 'Average run of the mill bug'), ('Type:New Feature', ''), ('.Frontend', ''), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2080246153, 'issue_id': 2193020219, 'author': 'aarthi-subramanian', 'body': 'Hi any word on this? This one/issue keeps popping up and is quite annoying', 'created_at': datetime.datetime(2024, 4, 26, 23, 59, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2117015069, 'issue_id': 2193020219, 'author': 'levon-sib', 'body': 'Any news on this? Looks like a crucial feature.', 'created_at': datetime.datetime(2024, 5, 17, 8, 24, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2120869572, 'issue_id': 2193020219, 'author': 'EmmadUsmani', 'body': '@aarthi-subramanian @levon-sib Which version of Metabase were you on in which you were able to toggle between ""percent of start"" vs. ""percent of previous step"" on funnel charts?', 'created_at': datetime.datetime(2024, 5, 20, 17, 17, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2437989446, 'issue_id': 2193020219, 'author': 'zbodi74', 'body': 'Updated the issue type to Feature Request, as I could not find the functionality in earlier versions (I tested 1.40.x onwards).', 'created_at': datetime.datetime(2024, 10, 25, 14, 35, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438098783, 'issue_id': 2193020219, 'author': 'ohadw', 'body': 'Relative conversation rates per steps will enable comparison between cohorts that have different characteristics in certain steps. Looking forward to this feature', 'created_at': datetime.datetime(2024, 10, 25, 15, 17, 1, tzinfo=datetime.timezone.utc)}]","aarthi-subramanian (Issue Creator) on (2024-04-26 23:59:40 UTC): Hi any word on this? This one/issue keeps popping up and is quite annoying

levon-sib on (2024-05-17 08:24:50 UTC): Any news on this? Looks like a crucial feature.

EmmadUsmani on (2024-05-20 17:17:40 UTC): @aarthi-subramanian @levon-sib Which version of Metabase were you on in which you were able to toggle between ""percent of start"" vs. ""percent of previous step"" on funnel charts?

zbodi74 on (2024-10-25 14:35:02 UTC): Updated the issue type to Feature Request, as I could not find the functionality in earlier versions (I tested 1.40.x onwards).

ohadw on (2024-10-25 15:17:01 UTC): Relative conversation rates per steps will enable comparison between cohorts that have different characteristics in certain steps. Looking forward to this feature

"
2192943213,issue,closed,completed,[Epic] Show generated SQL in a side bar automatically,"**Links**
- [Product doc](https://www.notion.so/metabase/Show-generated-SQL-in-a-side-bar-automatically-b56dbea3ece942ac981ee0326e5867c8)
- [Eng doc](https://www.notion.so/metabase/Tech-Show-generated-SQL-in-a-side-bar-automatically-febee0259d2d40e294a06d2f4930122e?pvs=4)
- Feature branch:  check under each of the milestones
- [Figma](https://www.figma.com/file/TZseFDIOAhNU6ArKtFmxBx/Show-generated-SQL-in-a-side-bar-automatically?type=design&node-id=1-286&mode=design&t=ptjbABjX6rJIqwRt-0)
- Testing plan: https://github.com/metabase/metabase/issues/40579

# Implementation Plan

## Milestone 0
Good litmus test for the scope of this milestone is that all steps in it should easily be merged into `master` and even backported.
```[tasklist]
## Prep and necessary cleanup
- [ ] #40136
- [ ] https://github.com/metabase/metabase/pull/40268
- [ ] https://github.com/metabase/metabase/pull/40286
- [ ] https://github.com/metabase/metabase/pull/40316
```

## Milestone 1
For the proof of concept, our goal is to have a SQL preview that automatically updates with each new step being added/removed in the Notebook GUI editor. Code highlighting, line numbering, and the ability to resize the sidebar are not important for this phase.

Feature branch: https://github.com/metabase/metabase/tree/sql-sidebar-preview-poc
```[tasklist]
## Working Prototype
- [x] Show SQL preview in the sidebar and update synchronously with steps in the notebook GUI editor (#40279)
- [x] Hook the sidebar to the toggle query button and preserve the preference in the Redux store `uiState`  (#40327)
- [x] Convert to the native query (#40362)
- [x] Make minimal necessary CSS tweaks (#40463)
- [x] Adjust the sidebar to work with small screens (#40463)
- [x] Cover with E2E tests before merging (https://github.com/metabase/metabase/pull/40540)
```

```[tasklist]
## Extras
- [x] #40430
```

## Milestone 2
Tasks that should happen after we gather some initial feedback on PoC from the product, design, and from the users.
```[tasklist]
## Visual tweaks
- [ ] https://github.com/metabase/metabase/issues/40668
- [ ] https://github.com/metabase/metabase/issues/40697
```

```[tasklist]
## Follow ups after M1
- [ ] https://github.com/metabase/metabase/pull/40630
```

## Milestone 3
```[tasklist]
- [ ] https://github.com/metabase/metabase/issues/40948
- [ ] https://github.com/metabase/metabase/pull/40984
- [ ] https://github.com/metabase/metabase/issues/41058
```

```[tasklist]
### Follow ups
- [ ] Unit tests
- [ ] https://github.com/metabase/metabase/pull/41082
- [ ] https://github.com/metabase/metabase/pull/41141
- [ ] https://github.com/metabase/metabase/pull/41877
- [ ] https://github.com/metabase/metabase/pull/41881
```

## Post-development checklist
```[tasklist]
- [x] Delete code related to the previous modal
- [x] Potentially move some related components around if they need to live closer to the notebook
```



",nemanjaglumac,2024-03-18 18:18:12+00:00,['nemanjaglumac'],2024-04-26 12:51:35+00:00,2024-04-22 15:30:59+00:00,https://github.com/metabase/metabase/issues/40254,"[('.Epic', 'Feature Implementation or Project')]",[],
2192825905,issue,closed,completed,GUI model joining native ones break with column not found error,"### Describe the bug

After updating its metadata, GUI based model joining native models break with a column not found error.

### To Reproduce
(See a simpler way to reproduce in the comments below).

1. Create a native model `wcount`: 
```
select year(created_at), count(*) as WidgetCount from products where category = 'Widget' group by year(created_at)
```

2. Create a native model `gcount`: 
```
select year(created_at), count(*) as GadgetCount from products where category = 'Gadget' group by year(created_at)
```
3. Create a GUI model `joined`: inner join models created on step 1 and 2, on the year column. Save it.

4. Edit the metadata of `joined`, and rename the count(*) fields: WidgetCount, GadgetCount. Save it.

5. See it break:
<img width=""363"" alt=""image"" src=""https://github.com/metabase/metabase/assets/11080638/e6b926a1-3e40-478c-a71d-5b7cc61fddae"">


### Expected behavior

It should work.

### Logs

n/a

### Information about your Metabase installation
Seen this on master (stats) as of:
```
Built on 2024-03-18
Hash: 6710930
```
I could not reproduce this on v1.49.0, so I also added the .Regression label.


### Severity

Probably P2 - I found it while troubleshooting something else), it might be a regression though.

### Additional context

SQL generated:
```
SELECT
  ""source"".""EXTRACT(YEAR
FROM CREATED_AT)"" AS ""EXTRACT(YEAR FROM CREATED_AT)"",
  ""source"".""GADGETCOUNT"" AS ""GADGETCOUNT"",
  ""wcount - EXTRACT(YEAR FROM CREATED_AT)"".""EXTRACT(YEAR FROM CREATED_AT)"" AS ""wcount - EXTRACT(YEAR FROM CREATED_AT)__EXTRACT(YEA_8b131169"",
  ""wcount - EXTRACT(YEAR FROM CREATED_AT)"".""WIDGETCOUNT"" AS ""wcount - EXTRACT(YEAR FROM CREATED_AT)__WIDGETCOUNT""
FROM
  (
    select
      year(created_at),
      count(*) as GadgetCount
    from
      products
    where
      category = 'Gadget'
    group by
      year(created_at)
  ) AS ""source""
 
LEFT JOIN (
    select
      year(created_at),
      count(*) as WidgetCount
    from
      products
    where
      category = 'Widget'
    group by
      year(created_at)
  ) AS ""wcount - EXTRACT(YEAR FROM CREATED_AT)"" ON ""source"".""EXTRACT(YEAR FROM CREATED_AT)"" = ""wcount - EXTRACT(YEAR FROM CREATED_AT)"".""EXTRACT(YEAR FROM CREATED_AT)""
LIMIT
  1048575
 ```",zbodi74,2024-03-18 17:20:36+00:00,['bshepherdson'],2024-04-03 22:01:45+00:00,2024-04-03 22:01:45+00:00,https://github.com/metabase/metabase/issues/40252,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Nested Queries', 'Questions based on other saved questions'), ('Querying/', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', '')]","[{'comment_id': 2013161329, 'issue_id': 2192825905, 'author': 'zbodi74', 'body': 'This is now broken on `49.1`. Here is a simpler reproduction:\r\n1. create native model `A`: `select 1 as a1, 2 as a2`\r\n2. create native model `B`: `select 1 as b1, 2 as b2`\r\n3. create GUI model A+B: A inner join B, on A.A1=B.B1\r\n4. edit the metadata of A+B: rename the third column from B - A1->B1 to anything else\r\n5.(!) save it and see the error:\r\n\r\nColumn ""source.B1"" not found; SQL statement:\r\n```\r\nSELECT ""source"".""A1"" AS ""A1"",\r\n       ""source"".""A2"" AS ""A2"",\r\n       ""source"".""B1"" AS ""B1"",\r\n       ""source"".""B2"" AS ""B2""\r\nFROM (\r\n    SELECT ""source"".""A1"" AS ""A1"",\r\n           ""source"".""A2"" AS ""A2"",\r\n            ""B - A1"".""B1"" AS ""B - A1__B1"",\r\n            ""B - A1"".""B2"" AS ""B - A1__B2""\r\n    FROM (\r\n        select 1 as a1,\r\n               2 as a2 ) AS ""source""\r\n    LEFT JOIN (\r\n        select 1 as b1, \r\n               2 as b2 ) AS ""B - A1"" \r\n    ON ""source"".""A1"" = ""B - A1"".""B1""\r\n) AS ""source""\r\nLIMIT 2000\r\n```', 'created_at': datetime.datetime(2024, 3, 21, 17, 45, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026768422, 'issue_id': 2192825905, 'author': 'uladzimirdev', 'body': ""It's broken on 49.1 but works fine on 49.2\r\n\r\n@zbodi74 could you please confirm?"", 'created_at': datetime.datetime(2024, 3, 29, 6, 52, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026800179, 'issue_id': 2192825905, 'author': 'zbodi74', 'body': '@uladzimirdev - confirmed, it works fine on 49.2.', 'created_at': datetime.datetime(2024, 3, 29, 7, 23, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027038393, 'issue_id': 2192825905, 'author': 'uladzimirdev', 'body': 'The issue still exists, the key point is `inner join`', 'created_at': datetime.datetime(2024, 3, 29, 10, 26, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027187403, 'issue_id': 2192825905, 'author': 'uladzimirdev', 'body': 'I added a repro test for this issue https://github.com/metabase/metabase/pull/40772\r\n\r\nalso the test passed at CI and in simulating fast 3g, but fails when you run it locally on full speed (the issue comes from BE), maybe some race condition.\r\n\r\nStacktrace is added to the repro issue', 'created_at': datetime.datetime(2024, 3, 29, 12, 38, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030431694, 'issue_id': 2192825905, 'author': 'bshepherdson', 'body': 'For some reason this wouldn\'t repro for me on the first edit of the column name in the metadata. I edited it again and saw the issue.\r\n\r\nThe generated SQL shows the issue fairly plainly:\r\n\r\n```sql\r\nSELECT\r\n  ""source"".""A1"" AS ""A1"",\r\n  ""source"".""A2"" AS ""A2"",\r\n  ""source"".""B1"" AS ""B1"",\r\n  ""source"".""B2"" AS ""B2""\r\nFROM (\r\n  SELECT\r\n    ""source"".""A1"" AS ""A1"",\r\n    ""source"".""A2"" AS ""A2"",\r\n    ""B - A1"".""B1"" AS ""B - A1__B1"",\r\n    ""B - A1"".""B2"" AS ""B - A1__B2""\r\n  FROM (select 1 as a1, 2 as a2) AS ""source""\r\n  INNER JOIN (select 1 as b1, 2 as b2) AS ""B - A1""\r\n  ON ""source"".""A1"" = ""B - A1"".""B1""\r\n) AS ""source""\r\nLIMIT 2000\r\n```\r\n\r\nThe outermost layer\'s `""source"".""B1""` references (`source-alias`) don\'t agree with the inner layer\'s `AS ""B - A1__B1""` outputs (`desired-alias`). We\'re failing to match up the outer layer\'s incoming fields with the inner layer\'s output fields, so we lose track of the naming and default to just `""B1""`, resulting in the error.\r\n\r\nI\'ve got a fix on the way for this.', 'created_at': datetime.datetime(2024, 4, 1, 19, 41, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2030564121, 'issue_id': 2192825905, 'author': 'uladzimirdev', 'body': '@bshepherdson have you tried running the linked repro e2e?', 'created_at': datetime.datetime(2024, 4, 1, 21, 11, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032086835, 'issue_id': 2192825905, 'author': 'bshepherdson', 'body': ""Not yet, but I'll be sure to test it as part of the PR."", 'created_at': datetime.datetime(2024, 4, 2, 13, 44, 50, tzinfo=datetime.timezone.utc)}]","zbodi74 (Issue Creator) on (2024-03-21 17:45:47 UTC): This is now broken on `49.1`. Here is a simpler reproduction:
1. create native model `A`: `select 1 as a1, 2 as a2`
2. create native model `B`: `select 1 as b1, 2 as b2`
3. create GUI model A+B: A inner join B, on A.A1=B.B1
4. edit the metadata of A+B: rename the third column from B - A1->B1 to anything else
5.(!) save it and see the error:

Column ""source.B1"" not found; SQL statement:
```
SELECT ""source"".""A1"" AS ""A1"",
       ""source"".""A2"" AS ""A2"",
       ""source"".""B1"" AS ""B1"",
       ""source"".""B2"" AS ""B2""
FROM (
    SELECT ""source"".""A1"" AS ""A1"",
           ""source"".""A2"" AS ""A2"",
            ""B - A1"".""B1"" AS ""B - A1__B1"",
            ""B - A1"".""B2"" AS ""B - A1__B2""
    FROM (
        select 1 as a1,
               2 as a2 ) AS ""source""
    LEFT JOIN (
        select 1 as b1, 
               2 as b2 ) AS ""B - A1"" 
    ON ""source"".""A1"" = ""B - A1"".""B1""
) AS ""source""
LIMIT 2000
```

uladzimirdev on (2024-03-29 06:52:03 UTC): It's broken on 49.1 but works fine on 49.2

@zbodi74 could you please confirm?

zbodi74 (Issue Creator) on (2024-03-29 07:23:09 UTC): @uladzimirdev - confirmed, it works fine on 49.2.

uladzimirdev on (2024-03-29 10:26:23 UTC): The issue still exists, the key point is `inner join`

uladzimirdev on (2024-03-29 12:38:01 UTC): I added a repro test for this issue https://github.com/metabase/metabase/pull/40772

also the test passed at CI and in simulating fast 3g, but fails when you run it locally on full speed (the issue comes from BE), maybe some race condition.

Stacktrace is added to the repro issue

bshepherdson (Assginee) on (2024-04-01 19:41:07 UTC): For some reason this wouldn't repro for me on the first edit of the column name in the metadata. I edited it again and saw the issue.

The generated SQL shows the issue fairly plainly:

```sql
SELECT
  ""source"".""A1"" AS ""A1"",
  ""source"".""A2"" AS ""A2"",
  ""source"".""B1"" AS ""B1"",
  ""source"".""B2"" AS ""B2""
FROM (
  SELECT
    ""source"".""A1"" AS ""A1"",
    ""source"".""A2"" AS ""A2"",
    ""B - A1"".""B1"" AS ""B - A1__B1"",
    ""B - A1"".""B2"" AS ""B - A1__B2""
  FROM (select 1 as a1, 2 as a2) AS ""source""
  INNER JOIN (select 1 as b1, 2 as b2) AS ""B - A1""
  ON ""source"".""A1"" = ""B - A1"".""B1""
) AS ""source""
LIMIT 2000
```

The outermost layer's `""source"".""B1""` references (`source-alias`) don't agree with the inner layer's `AS ""B - A1__B1""` outputs (`desired-alias`). We're failing to match up the outer layer's incoming fields with the inner layer's output fields, so we lose track of the naming and default to just `""B1""`, resulting in the error.

I've got a fix on the way for this.

uladzimirdev on (2024-04-01 21:11:40 UTC): @bshepherdson have you tried running the linked repro e2e?

bshepherdson (Assginee) on (2024-04-02 13:44:50 UTC): Not yet, but I'll be sure to test it as part of the PR.

"
2192697043,issue,closed,completed,Allow running native queries with required parameters and no defaults,"### Describe the bug

Our devops upgraded our metabase last week to 0.49.0 and since then any report that has a required field (but no default) will not run!.  No matter what we set the value to in the input fields it *thinks* the field is not set and refuses to run the report.

We have to toggle the require property of the variable and then the report will run. 

### To Reproduce

1. Have a  SQL report with a required parameter variable
2. have that variable be required, but with no default value.
3. specify a value for the property
4. the ""run"" icon is NOT clickable (remains disabled)

### Expected behavior

To be able to run the report as in previous metabase versions.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- browser - Firefox 123.0.1
- browser OS macOS 12
- DBs for queries (doesnt matter) redshfit & postgresql
- Metabase 0.49.0
- hosting AWS
- internal DB postgresql
```


### Severity

annoying and semi-blocking

### Additional context

_No response_",urkle,2024-03-18 16:29:17+00:00,['oleggromov'],2024-03-29 18:52:14+00:00,2024-03-20 09:48:42+00:00,https://github.com/metabase/metabase/issues/40250,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Reporting/Dashboards', ''), ('.Frontend', '')]","[{'comment_id': 2004393790, 'issue_id': 2192697043, 'author': 'paoliniluis', 'body': 'We need to force the user to set up a default value here', 'created_at': datetime.datetime(2024, 3, 18, 16, 31, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2004412274, 'issue_id': 2192697043, 'author': 'urkle', 'body': '@paoliniluis why do we need to force them to setup a default value? What is the reasoning behind that requirement?  We have many reports with required params that we do NOT want a default value as it makes zero sense to do that.   e.g. a required organization_id parameter, or a required start date parameter..  In many cases these queries are slow and we do not want a default that is STALE or long-ago since it will cause the report to run needlessly when first opened for data the user does not need.\r\n\r\nAlso in the reports we have this even if the param is specified on the URL the report still refuses to run.', 'created_at': datetime.datetime(2024, 3, 18, 16, 39, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2004698226, 'issue_id': 2192697043, 'author': 'oleggromov', 'body': '@urkle hi, the author of this new feature here. I am sorry that you\'ve experienced a regression! \r\nTo help us resolve the issue quickly, could you please confirm that you are blocked by what\'s explained on the screenshot?\r\n\r\n<img width=""1280"" alt=""Screenshot 2024-03-18 at 18 54 50"" src=""https://github.com/metabase/metabase/assets/2196347/13e6aaaf-ebc4-4e45-a820-87d229f122ce"">\r\n\r\nThis is SQL query editing mode, in case this happens on a dashboard or in a different context, please let me know.', 'created_at': datetime.datetime(2024, 3, 18, 18, 57, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2004912209, 'issue_id': 2192697043, 'author': 'urkle', 'body': '@oleggromov yes, that is what we are encountering (in sql query mode).', 'created_at': datetime.datetime(2024, 3, 18, 20, 25, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2009161842, 'issue_id': 2192697043, 'author': 'oleggromov', 'body': 'Hi @urkle the problem was fixed, please expect it to be shipped with the `0.49.1` version, which is due on March 28.', 'created_at': datetime.datetime(2024, 3, 20, 9, 53, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2011940718, 'issue_id': 2192697043, 'author': 'darksciencebase', 'body': ""@urkle we've actually just released 49.1, a bit ahead of the schedule."", 'created_at': datetime.datetime(2024, 3, 21, 10, 59, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027282714, 'issue_id': 2192697043, 'author': 'cbalusek', 'body': 'This issue is not resolved in 49.1, but in 49.3, which will be released early next week', 'created_at': datetime.datetime(2024, 3, 29, 13, 55, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027534517, 'issue_id': 2192697043, 'author': 'urkle', 'body': 'Thanks @cbalusek I noticed the issue was only partially fixed in 0.49.1 (I could run them but not save them)', 'created_at': datetime.datetime(2024, 3, 29, 17, 39, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027604498, 'issue_id': 2192697043, 'author': 'danielcarletti', 'body': 'With this fix, every question with mandatory parameters now also requires a default value. Before, we could leave it empty so the user had to fill in the parameter. Is that an intended change or an unwanted side effect?', 'created_at': datetime.datetime(2024, 3, 29, 18, 52, 13, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-18 16:31:38 UTC): We need to force the user to set up a default value here

urkle (Issue Creator) on (2024-03-18 16:39:12 UTC): @paoliniluis why do we need to force them to setup a default value? What is the reasoning behind that requirement?  We have many reports with required params that we do NOT want a default value as it makes zero sense to do that.   e.g. a required organization_id parameter, or a required start date parameter..  In many cases these queries are slow and we do not want a default that is STALE or long-ago since it will cause the report to run needlessly when first opened for data the user does not need.

Also in the reports we have this even if the param is specified on the URL the report still refuses to run.

oleggromov (Assginee) on (2024-03-18 18:57:02 UTC): @urkle hi, the author of this new feature here. I am sorry that you've experienced a regression! 
To help us resolve the issue quickly, could you please confirm that you are blocked by what's explained on the screenshot?

<img width=""1280"" alt=""Screenshot 2024-03-18 at 18 54 50"" src=""https://github.com/metabase/metabase/assets/2196347/13e6aaaf-ebc4-4e45-a820-87d229f122ce"">

This is SQL query editing mode, in case this happens on a dashboard or in a different context, please let me know.

urkle (Issue Creator) on (2024-03-18 20:25:19 UTC): @oleggromov yes, that is what we are encountering (in sql query mode).

oleggromov (Assginee) on (2024-03-20 09:53:49 UTC): Hi @urkle the problem was fixed, please expect it to be shipped with the `0.49.1` version, which is due on March 28.

darksciencebase on (2024-03-21 10:59:28 UTC): @urkle we've actually just released 49.1, a bit ahead of the schedule.

cbalusek on (2024-03-29 13:55:57 UTC): This issue is not resolved in 49.1, but in 49.3, which will be released early next week

urkle (Issue Creator) on (2024-03-29 17:39:19 UTC): Thanks @cbalusek I noticed the issue was only partially fixed in 0.49.1 (I could run them but not save them)

danielcarletti on (2024-03-29 18:52:13 UTC): With this fix, every question with mandatory parameters now also requires a default value. Before, we could leave it empty so the user had to fill in the parameter. Is that an intended change or an unwanted side effect?

"
2192441262,issue,closed,completed,[ParseSQL] Support `*`,"Part of [parsing SQL](https://github.com/metabase/metabase/issues/36911)

Support `select *` and `select table_name.*` in Macaw; return some sort of sentinel value that can be understood by Metabase; update column matching as appropriate.

Probably need to come up with a new column in QueryField that tracks whether this is a direct ref (by column name) or not (by star)",tsmacdonald,2024-03-18 14:52:24+00:00,['tsmacdonald'],2024-04-30 09:23:26+00:00,2024-03-28 09:00:59+00:00,https://github.com/metabase/metabase/issues/40247,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]",[],
2192403926,issue,open,,Automatically deactivate users who haven't logged in since a certain date,"**Is your feature request related to a problem? Please describe.**
Some organizations may have people who have inactive users and don't want to do the manual task of checking 

**Describe the solution you'd like**
For billing purposes, it would be helpful for some customers to deactivate a user who hasn't logged in since a specific/relative date. 

**Describe alternatives you've considered**
It can be done manually now with Metabase Analytics, but it would be nice to have it as a feature inside the product.

**How important is this feature to you?**
Requested by a customer, internal ticket: [25488](https://metabase.zendesk.com/agent/tickets/)

**Additional context**
N/A
",ignacio-mb,2024-03-18 14:38:09+00:00,[],2024-03-18 14:38:10+00:00,,https://github.com/metabase/metabase/issues/40244,"[('Type:New Feature', ''), ('Administration/People', 'and Groups. Also user Account Settings')]",[],
2192363601,issue,closed,completed,[Epic] Embedding SDK ‚Äì Finalize build,"**Links**
- eng doc: https://www.notion.so/metabase/Embedding-SDK-Roadmap-02d1fba72171455bb3496d7d996cd302?pvs=4#48c82a0e4b45469fa14ef7e3c40e1d7d
- feature branch: `branch-name` _this should be the feature branch where this work will be done in. PRs will be delivered against this branch_
- issue links: _related issues if any_

**Implementation Plan**

```[tasklist]
### Integrate SDK PoC code
- [ ] https://github.com/metabase/metabase/pull/39941
- [x] Move host app example into a separate repo - https://github.com/metabase/embedding-sdk-customer-zero/tree/pre-alpha
- [ ] https://github.com/metabase/metabase/pull/40394
- [ ] https://github.com/metabase/metabase/pull/40198
- [ ] https://github.com/metabase/metabase/pull/40629
- [ ] #41179
- [ ] https://github.com/metabase/metabase/pull/40902
```


",deniskaber,2024-03-18 14:22:28+00:00,['deniskaber'],2024-04-25 23:10:22+00:00,2024-04-25 23:10:22+00:00,https://github.com/metabase/metabase/issues/40241,"[('.Epic', 'Feature Implementation or Project')]",[],
2192334454,issue,closed,not_planned,Problem with MongoDB connection,"### Describe the bug

All MongoDB databases that were working before has stopped working over the weekend.

I receive the following error:

The connection string contains an empty host '[]'. 

### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

_No response_

### Logs

{:database_id 3,
 :started_at #t ""2024-03-18T14:09:27.598241Z[GMT]"",
 :action_id nil,
 :json_query
 {:database 3,
  :query
  {:expressions
   {:Product
    [""case"" [[[""="" [""field"" 468 nil] ""adult""] ""VMA""]] {:default [""case"" [[[""="" [""field"" 468 nil] ""vmc""] ""VMC""]]]}]},
   :fields
   [[""field"" 472 nil]
    [""field"" 480 {:base-type ""type/Text""}]
    [""field"" 468 nil]
    [""field"" 478 nil]
    [""field"" 473 {:temporal-unit ""default""}]
    [""field"" 2002 {:base-type ""type/Text""}]
    [""expression"" ""Product"" {:base-type ""type/Text""}]],
   :filter [""="" [""field"" 1740 nil] false],
   :source-table 65},
  :type ""query"",
  :parameters
  [{:id ""74ba1e3c"", :type ""string/="", :value nil, :target [""dimension"" [""field"" 480 nil]]}
   {:id ""d8c5d488"", :type ""string/="", :value nil, :target [""dimension"" [""field"" 2002 nil]]}
   {:id ""6ffa3994"", :type ""string/="", :value nil, :target [""dimension"" [""expression"" ""Product""]]}],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :native
 {:projections (""_id"" ""name"" ""source"" ""client_id"" ""created_at"" ""trading_name"" ""Product""),
  :query
  [{""$match"" {""test_business"" false}}
   {""$project""
    {""_id"" ""$_id"",
     ""name"" ""$name"",
     ""source"" ""$source"",
     ""client_id"" ""$client_id"",
     ""created_at"" ""$created_at"",
     ""trading_name"" ""$trading_name"",
     ""Product""
     {:$switch
      {:branches [{:case {""$eq"" [""$source"" ""adult""]}, :then ""VMA""}],
       :default {:$switch {:branches [{:case {""$eq"" [""$source"" ""vmc""]}, :then ""VMC""}], :default nil}}}}}}
   {""$limit"" 1048575}],
  :collection ""business"",
  :mbql? true},
 :status :failed,
 :class java.lang.IllegalArgumentException,
 :stacktrace
 [""com.mongodb.ConnectionString.parseHosts(ConnectionString.java:1150)""
  ""com.mongodb.ConnectionString.<init>(ConnectionString.java:396)""
  ""com.mongodb.ConnectionString.<init>(ConnectionString.java:321)""
  ""--> driver.mongo.connection$db_details__GT_mongo_client_settings.invokeStatic(connection.clj:67)""
  ""driver.mongo.connection$db_details__GT_mongo_client_settings.invoke(connection.clj:61)""
  ""driver.mongo.connection$do_with_mongo_client$fn__121852.invoke(connection.clj:91)""
  ""util.ssh$do_with_ssh_tunnel.invokeStatic(ssh.clj:165)""
  ""util.ssh$do_with_ssh_tunnel.invoke(ssh.clj:154)""
  ""driver.mongo.connection$do_with_mongo_client.invokeStatic(connection.clj:90)""
  ""driver.mongo.connection$do_with_mongo_client.invoke(connection.clj:86)""
  ""driver.mongo$fn__125623.invokeStatic(mongo.clj:319)""
  ""driver.mongo$fn__125623.invoke(mongo.clj:317)""
  ""query_processor.context$executef.invokeStatic(context.clj:60)""
  ""query_processor.context$executef.invoke(context.clj:49)""
  ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
  ""query_processor.context.default$default_runf.invoke(default.clj:42)""
  ""query_processor.context$runf.invokeStatic(context.clj:46)""
  ""query_processor.context$runf.invoke(context.clj:40)""
  ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
  ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
  ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71961.invoke(cache.clj:229)""
  ""query_processor.middleware.permissions$check_query_permissions$fn__66347.invoke(permissions.clj:140)""
  ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71782.invoke(enterprise.clj:51)""
  ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71792.invoke(enterprise.clj:64)""
  ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:24)""
  ""query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)""
  ""query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)""
  ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)""
  ""driver$do_with_driver.invokeStatic(driver.clj:97)""
  ""driver$do_with_driver.invoke(driver.clj:92)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)""
  ""query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
  ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
  ""query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)""
  ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)""
  ""query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)""
  ""query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)""
  ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)""
  ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70935.invoke(constraints.clj:104)""
  ""query_processor.middleware.process_userland_query$process_userland_query$fn__72105.invoke(process_userland_query.clj:156)""
  ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72706.invoke(catch_exceptions.clj:171)""
  ""query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)""
  ""query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)""
  ""query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)""
  ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
  ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
  ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
  ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
  ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
  ""api.dataset$run_query_async$fn__93567.invoke(dataset.clj:79)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53135$fn__53137.invoke(streaming.clj:168)""
  ""query_processor.streaming$streaming_response_STAR_$fn__53135.invoke(streaming.clj:167)""
  ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
  ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
  ""async.streaming_response$do_f_async$task__43750.invoke(streaming_response.clj:88)""],
 :card_id nil,
 :context :ad-hoc,
 :error ""The connection string contains an empty host '[]'. "",
 :row_count 0,
 :running_time 0,
 :preprocessed
 {:database 3,
  :query
  {:expressions
   {""Product""
    [:case
     [[[:=
        [:field 468 nil]
        [:value
         ""adult""
         {:base_type :type/Text,
          :effective_type :type/Text,
          :coercion_strategy nil,
          :semantic_type :type/Source,
          :database_type ""java.lang.String"",
          :name ""source""}]]
       ""VMA""]]
     {:default
      [:case
       [[[:=
          [:field 468 nil]
          [:value
           ""vmc""
           {:base_type :type/Text,
            :effective_type :type/Text,
            :coercion_strategy nil,
            :semantic_type :type/Source,
            :database_type ""java.lang.String"",
            :name ""source""}]]
         ""VMC""]]]}]},
   :fields
   [[:field 472 nil]
    [:field 480 {:base-type :type/Text}]
    [:field 468 nil]
    [:field 478 nil]
    [:field 473 {:temporal-unit :default}]
    [:field 2002 {:base-type :type/Text}]
    [:expression ""Product"" {:base-type :type/Text}]],
   :filter
   [:=
    [:field 1740 nil]
    [:value
     false
     {:base_type :type/Boolean,
      :effective_type :type/Boolean,
      :coercion_strategy nil,
      :semantic_type :type/Category,
      :database_type ""java.lang.Boolean"",
      :name ""test_business""}]],
   :source-table 65,
   :limit 1048575,
   :metabase.query-processor.middleware.limit/original-limit nil},
  :type :query,
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true},
  :info {:executed-by 26, :context :ad-hoc},
  :user-parameters
  [{:id ""74ba1e3c"", :type :string/=, :target [:dimension [:field 480 nil]]}
   {:id ""d8c5d488"", :type :string/=, :target [:dimension [:field 2002 nil]]}
   {:id ""6ffa3994"", :type :string/=, :target [:dimension [:expression ""Product""]]}]},
 :data {:rows [], :cols []}}

### Information about your Metabase installation

```JSON
Chrome Version 122.0.6261.129
macOS 14.3.1 (23D60)
MySQL
Metabase 0.49
```


### Severity

Blocking all the users

### Additional context

_No response_",poldal12,2024-03-18 14:10:34+00:00,[],2024-03-19 15:11:28+00:00,2024-03-19 15:11:28+00:00,https://github.com/metabase/metabase/issues/40240,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2004932622, 'issue_id': 2192334454, 'author': 'paoliniluis', 'body': ""@poldal12 Go to settings->admin->database-> and check if the connection string on Mongo is there, pretty sure it's not"", 'created_at': datetime.datetime(2024, 3, 18, 20, 31, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007405624, 'issue_id': 2192334454, 'author': 'poldal12', 'body': '@paoliniluis Thank you, this was the issue.', 'created_at': datetime.datetime(2024, 3, 19, 14, 56, 32, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-18 20:31:36 UTC): @poldal12 Go to settings->admin->database-> and check if the connection string on Mongo is there, pretty sure it's not

poldal12 (Issue Creator) on (2024-03-19 14:56:32 UTC): @paoliniluis Thank you, this was the issue.

"
2192309199,issue,closed,completed,Date filter variable not working in native query,"### Describe the bug

All the questions that uses field filter variable in native query with 'Updated_at' column has stopped working over the weekend. Metabase version 0.49.
When I don't set a date range, it works.

I receive the following error:

400 Bad Request POST https://www.googleapis.com/bigquery/v2/projects/xxxxxxxx/queries { ""code"": 400, ""errors"": [ { ""domain"": ""global"", ""location"": ""q"", ""locationType"": ""parameter"", ""message"": ""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"", ""reason"": ""invalidQuery"" } ], ""message"": ""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"", ""status"": ""INVALID_ARGUMENT"" }

### To Reproduce

1. Create a native query
2. Add a field filter which is mapped to the Updated at Timestamp column
3. Set it to Date Range


### Expected behavior

_No response_

### Logs

POST https://www.googleapis.com/bigquery/v2/projects/nucleus-commons-316113/queries
{
  ""code"": 400,
  ""errors"": [
    {
      ""domain"": ""global"",
      ""location"": ""q"",
      ""locationType"": ""parameter"",
      ""message"": ""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"",
      ""reason"": ""invalidQuery""
    }
  ],
  ""message"": ""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"",
  ""status"": ""INVALID_ARGUMENT""
}
{:database_id 30,
 :started_at #t ""2024-03-18T14:00:17.568861Z[GMT]"",
 :via
 [{:status :failed,
   :class com.google.cloud.bigquery.BigQueryException,
   :error
   ""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"",
   :stacktrace
   [""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.translate(HttpBigQueryRpc.java:114)""
    ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:728)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
    ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
    ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
    ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
    ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
    ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__128490.invoke(bigquery_cloud_sdk.clj:343)""]}
  {:status :failed,
   :class java.util.concurrent.ExecutionException,
   :error
   ""com.google.cloud.bigquery.BigQueryException: No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"",
   :stacktrace
   [""java.base/java.util.concurrent.FutureTask.report(Unknown Source)""
    ""java.base/java.util.concurrent.FutureTask.get(Unknown Source)""
    ""clojure.core$deref_future.invokeStatic(core.clj:2317)""
    ""clojure.core$future_call$reify__8544.deref(core.clj:7042)""
    ""clojure.core$deref.invokeStatic(core.clj:2337)""
    ""clojure.core$deref.invoke(core.clj:2323)""
    ""--> driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:331)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:327)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:371)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:369)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__128534.invoke(bigquery_cloud_sdk.clj:419)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:427)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:412)""
    ""driver.bigquery_cloud_sdk$fn__128541.invokeStatic(bigquery_cloud_sdk.clj:448)""
    ""driver.bigquery_cloud_sdk$fn__128541.invoke(bigquery_cloud_sdk.clj:440)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71961.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66347.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71782.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71792.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)""
    ""query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70935.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72105.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72706.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93567.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135$fn__53137.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43750.invoke(streaming_response.clj:88)""]}
  {:status :failed,
   :class clojure.lang.ExceptionInfo,
   :error
   ""Error executing query: com.google.cloud.bigquery.BigQueryException: No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]"",
   :stacktrace
   [""--> driver.bigquery_cloud_sdk$throw_invalid_query.invokeStatic(bigquery_cloud_sdk.clj:323)""
    ""driver.bigquery_cloud_sdk$throw_invalid_query.invoke(bigquery_cloud_sdk.clj:322)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invokeStatic(bigquery_cloud_sdk.clj:367)""
    ""driver.bigquery_cloud_sdk$execute_bigquery.invoke(bigquery_cloud_sdk.clj:327)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invokeStatic(bigquery_cloud_sdk.clj:371)""
    ""driver.bigquery_cloud_sdk$execute_bigquery_on_db.invoke(bigquery_cloud_sdk.clj:369)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_$thunk__128534.invoke(bigquery_cloud_sdk.clj:419)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invokeStatic(bigquery_cloud_sdk.clj:427)""
    ""driver.bigquery_cloud_sdk$_STAR_process_native_STAR_.invoke(bigquery_cloud_sdk.clj:412)""
    ""driver.bigquery_cloud_sdk$fn__128541.invokeStatic(bigquery_cloud_sdk.clj:448)""
    ""driver.bigquery_cloud_sdk$fn__128541.invoke(bigquery_cloud_sdk.clj:440)""
    ""query_processor.context$executef.invokeStatic(context.clj:60)""
    ""query_processor.context$executef.invoke(context.clj:49)""
    ""query_processor.context.default$default_runf.invokeStatic(default.clj:44)""
    ""query_processor.context.default$default_runf.invoke(default.clj:42)""
    ""query_processor.context$runf.invokeStatic(context.clj:46)""
    ""query_processor.context$runf.invoke(context.clj:40)""
    ""query_processor.reducible$identity_qp.invokeStatic(reducible.clj:39)""
    ""query_processor.reducible$identity_qp.invoke(reducible.clj:36)""
    ""query_processor.middleware.cache$maybe_return_cached_results$maybe_return_cached_results_STAR___71961.invoke(cache.clj:229)""
    ""query_processor.middleware.permissions$check_query_permissions$fn__66347.invoke(permissions.clj:140)""
    ""query_processor.middleware.enterprise$check_download_permissions_middleware$fn__71782.invoke(enterprise.clj:51)""
    ""query_processor.middleware.enterprise$maybe_apply_column_level_perms_check_middleware$fn__71792.invoke(enterprise.clj:64)""
    ""query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:24)""
    ""query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)""
    ""query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)""
    ""query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)""
    ""driver$do_with_driver.invokeStatic(driver.clj:97)""
    ""driver$do_with_driver.invoke(driver.clj:92)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)""
    ""query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)""
    ""query_processor.store$do_with_metadata_provider.invoke(store.clj:150)""
    ""query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)""
    ""query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)""
    ""query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)""
    ""query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)""
    ""query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)""
    ""query_processor.middleware.constraints$mark_needs_default_userland_constraints$fn__70935.invoke(constraints.clj:104)""
    ""query_processor.middleware.process_userland_query$process_userland_query$fn__72105.invoke(process_userland_query.clj:156)""
    ""query_processor.middleware.catch_exceptions$catch_exceptions$fn__72706.invoke(catch_exceptions.clj:171)""
    ""query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)""
    ""query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)""
    ""query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)""
    ""query_processor$process_userland_query.invokeStatic(query_processor.clj:402)""
    ""query_processor$process_userland_query.doInvoke(query_processor.clj:398)""
    ""query_processor$process_query_and_save_execution_BANG_.invokeStatic(query_processor.clj:416)""
    ""query_processor$process_query_and_save_execution_BANG_.invoke(query_processor.clj:406)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invokeStatic(query_processor.clj:431)""
    ""query_processor$process_query_and_save_with_max_results_constraints_BANG_.invoke(query_processor.clj:421)""
    ""api.dataset$run_query_async$fn__93567.invoke(dataset.clj:79)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135$fn__53137.invoke(streaming.clj:168)""
    ""query_processor.streaming$streaming_response_STAR_$fn__53135.invoke(streaming.clj:167)""
    ""async.streaming_response$do_f_STAR_.invokeStatic(streaming_response.clj:69)""
    ""async.streaming_response$do_f_STAR_.invoke(streaming_response.clj:67)""
    ""async.streaming_response$do_f_async$task__43750.invoke(streaming_response.clj:88)""],
   :error_type :invalid-query,
   :ex-data
   {:type :invalid-query,
    :sql
    ""-- Metabase:: userID: 26 queryType: native queryHash: b290e98aeae0bc11c3c9613f44b0a487743e5c9f0f0ac663801819c915c47221\nWITH OwnerNames AS (\n  SELECT\n    `VerifyMyContent_PROD.human_moderation_moderation`.`owner_email`AS `Moderator`,\n    SUM(CASE WHEN `VerifyMyContent_PROD.human_moderation_moderation`.`status` IN ('approved', 'rejected') THEN 1 ELSE 0 END) AS `Total Moderation`,\n    SUM(CASE WHEN `VerifyMyContent_PROD.human_moderation_moderation`.`status` = 'approved' THEN 1 ELSE 0 END) AS `Approved`,\n    SUM(CASE WHEN `VerifyMyContent_PROD.human_moderation_moderation`.`status` = 'rejected' THEN 1 ELSE 0 END) AS `Rejected`\n  FROM\n    `VerifyMyContent_PROD.human_moderation_moderation`\n  WHERE\n    (\n      `VerifyMyContent_PROD.human_moderation_moderation`.`status` IN ('approved', 'rejected')\n      AND (\n        NOT (\n          LOWER(`VerifyMyContent_PROD.human_moderation_moderation`.`owner_email`) LIKE '%verifymy%'\n        )\n        OR `VerifyMyContent_PROD.human_moderation_moderation`.`owner_email` IS NULL\n      )\n      AND (\n        `VerifyMyContent_PROD.human_moderation_moderation`.`step` <> 'supervisor'\n        OR `VerifyMyContent_PROD.human_moderation_moderation`.`step` IS NULL\n      )\n      AND `VerifyMyContent_PROD.human_moderation_moderation`.`moderation_type` = 'video'\n      AND TIMESTAMP_TRUNC(`VerifyMyContent_PROD.human_moderation_moderation`.`updated_at`, day) BETWEEN ? AND ?\n    )\n  GROUP BY\n    `Moderator`\n)\n\nSELECT\n  `o`.`Moderator` AS `Moderator`,\n  SUM(`o`.`Total Moderation`) AS `Total Moderation`,\n  SUM(`o`.`Approved`) AS `Approved`,\n  SUM(`o`.`Rejected`) AS `Rejected`,\n  IF(SUM(`o`.`Total Moderation`) > 0, ROUND((SUM(`o`.`Rejected`) / SUM(`o`.`Total Moderation`)), 5), NULL) AS `Rejection Ratio`\nFROM OwnerNames `o`\nWHERE\n  (\n    `o`.`Moderator` IS NOT NULL\n    AND (\n      `o`.`Moderator` <> ''\n      OR `o`.`Moderator` IS NULL\n    )\n  )\nGROUP BY `o`.`Moderator`\nORDER BY `Moderator` ASC;"",
    :parameters [#t ""2024-02-05T00:00"" #t ""2024-02-11T00:00""]}}],
 :action_id nil,
 :error_type :invalid-query,
 :json_query
 {:native
  {:collection ""human_moderation_moderation"",
   :template-tags
   {:date_range
    {:type ""dimension"",
     :name ""date_range"",
     :id ""09f2e6c1-d90e-4e58-8ee5-27c71e094461"",
     :display-name ""Date Range"",
     :dimension [""field"" 71554 nil],
     :widget-type ""date/range""}},
   :query
   ""WITH OwnerNames AS (\n  SELECT\n    `VerifyMyContent_PROD.human_moderation_moderation`.`owner_email`AS `Moderator`,\n    SUM(CASE WHEN `VerifyMyContent_PROD.human_moderation_moderation`.`status` IN ('approved', 'rejected') THEN 1 ELSE 0 END) AS `Total Moderation`,\n    SUM(CASE WHEN `VerifyMyContent_PROD.human_moderation_moderation`.`status` = 'approved' THEN 1 ELSE 0 END) AS `Approved`,\n    SUM(CASE WHEN `VerifyMyContent_PROD.human_moderation_moderation`.`status` = 'rejected' THEN 1 ELSE 0 END) AS `Rejected`\n  FROM\n    `VerifyMyContent_PROD.human_moderation_moderation`\n  WHERE\n    (\n      `VerifyMyContent_PROD.human_moderation_moderation`.`status` IN ('approved', 'rejected')\n      AND (\n        NOT (\n          LOWER(`VerifyMyContent_PROD.human_moderation_moderation`.`owner_email`) LIKE '%verifymy%'\n        )\n        OR `VerifyMyContent_PROD.human_moderation_moderation`.`owner_email` IS NULL\n      )\n      AND (\n        `VerifyMyContent_PROD.human_moderation_moderation`.`step` <> 'supervisor'\n        OR `VerifyMyContent_PROD.human_moderation_moderation`.`step` IS NULL\n      )\n      AND `VerifyMyContent_PROD.human_moderation_moderation`.`moderation_type` = 'video'\n      AND {{date_range}}\n    )\n  GROUP BY\n    `Moderator`\n)\n\nSELECT\n  `o`.`Moderator` AS `Moderator`,\n  SUM(`o`.`Total Moderation`) AS `Total Moderation`,\n  SUM(`o`.`Approved`) AS `Approved`,\n  SUM(`o`.`Rejected`) AS `Rejected`,\n  IF(SUM(`o`.`Total Moderation`) > 0, ROUND((SUM(`o`.`Rejected`) / SUM(`o`.`Total Moderation`)), 5), NULL) AS `Rejection Ratio`\nFROM OwnerNames `o`\nWHERE\n  (\n    `o`.`Moderator` IS NOT NULL\n    AND (\n      `o`.`Moderator` <> ''\n      OR `o`.`Moderator` IS NULL\n    )\n  )\nGROUP BY `o`.`Moderator`\nORDER BY `Moderator` ASC;\n""},
  :database 30,
  :type ""native"",
  :parameters
  [{:id ""09f2e6c1-d90e-4e58-8ee5-27c71e094461"",
    :type ""date/range"",
    :value ""2024-02-05~2024-02-11"",
    :target [""dimension"" [""template-tag"" ""date_range""]]}],
  :middleware {:js-int-to-string? true, :add-default-userland-constraints? true}},
 :status :failed,
 :class com.google.api.client.googleapis.json.GoogleJsonResponseException,
 :stacktrace
 [""com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:146)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:118)""
  ""com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:37)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest$3.interceptResponse(AbstractGoogleClientRequest.java:466)""
  ""com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1111)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:552)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:493)""
  ""com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:603)""
  ""com.google.cloud.bigquery.spi.v2.HttpBigQueryRpc.queryRpc(HttpBigQueryRpc.java:726)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1358)""
  ""com.google.cloud.bigquery.BigQueryImpl$35.call(BigQueryImpl.java:1355)""
  ""com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.run(BigQueryRetryHelper.java:86)""
  ""com.google.cloud.bigquery.BigQueryRetryHelper.runWithRetries(BigQueryRetryHelper.java:49)""
  ""com.google.cloud.bigquery.BigQueryImpl.queryRpc(BigQueryImpl.java:1354)""
  ""com.google.cloud.bigquery.BigQueryImpl.query(BigQueryImpl.java:1342)""
  ""--> driver.bigquery_cloud_sdk$execute_bigquery$fn__128490.invoke(bigquery_cloud_sdk.clj:343)""],
 :card_id nil,
 :context :ad-hoc,
 :error
 ""400 Bad Request\nPOST https://www.googleapis.com/bigquery/v2/projects/nucleus-commons-316113/queries\n{\n  \""code\"": 400,\n  \""errors\"": [\n    {\n      \""domain\"": \""global\"",\n      \""location\"": \""q\"",\n      \""locationType\"": \""parameter\"",\n      \""message\"": \""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]\"",\n      \""reason\"": \""invalidQuery\""\n    }\n  ],\n  \""message\"": \""No matching signature for operator BETWEEN for argument types: TIMESTAMP, DATETIME, DATETIME. Supported signature: (ANY) BETWEEN (ANY) AND (ANY) at [24:97]\"",\n  \""status\"": \""INVALID_ARGUMENT\""\n}"",
 :row_count 0,
 :running_time 0,
 :data {:rows [], :cols []}}

### Information about your Metabase installation

```JSON
Chrome Version 122.0.6261.129
macOS 14.3.1 (23D60)
MySQL
Metabase 0.49
```


### Severity

Blocking some users

### Additional context

_No response_",poldal12,2024-03-18 14:01:08+00:00,[],2024-03-19 15:14:53+00:00,2024-03-19 15:14:53+00:00,https://github.com/metabase/metabase/issues/40239,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]",[],
2192103462,issue,closed,completed,Parameter filter widget jumps and doesn't allow to pick a value,"### Describe the bug

Instead of allowing to pick the value for the filter, the widget jumps (as if sorting has begun) and does nothing.

https://github.com/metabase/metabase/assets/2196347/96c8f918-c677-47df-b0bc-15a41642e60d

Must be related to `Sortable` because when I comment it out, the bug no longer exists. https://github.com/metabase/metabase/blob/master/frontend/src/metabase/parameters/components/ParametersList.jsx#L53-L59

### To Reproduce

1. Create a native query with a template tag. Literlaly `{{ x }}` will work
2. Set it to a list of values (shouldn't contain actual values)
3. Try clicking the filter widget, entering a value and clicking ""add"" or ""update""

May not be 100% reproducible every time but at some point you'll see awkward jumping and the actual adding/change won't happen.

### Expected behavior

The value should be selectable. 
It shouldn't ""jump"" without actual dragging happening. 

### Logs

_No response_

### Information about your Metabase installation

```JSON
True as of `6fe41dd4379f4476b3eb78215b600393dd34474d`
```


### Severity

P3

### Additional context

_No response_",oleggromov,2024-03-18 12:42:46+00:00,['npfitz'],2024-03-28 10:05:01+00:00,2024-03-21 21:21:38+00:00,https://github.com/metabase/metabase/issues/40232,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Native', 'The SQL/native query editor'), ('.Frontend', '')]","[{'comment_id': 2008164258, 'issue_id': 2192103462, 'author': 'brianschillaci', 'body': ""I'm getting this exact same issue in my instance. I just upgraded to version v0.49.0"", 'created_at': datetime.datetime(2024, 3, 19, 21, 26, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2010554246, 'issue_id': 2192103462, 'author': 'urkle', 'body': 'The issue seems to be that the popup filter chooser is draggable and drags the field to a different order.\r\n\r\ne.g. I have a question with 2 date filters and I try to ""select"" the date text and instead it MOVES the filter to a different position instead of selecting the text.   and clicking + dragging anywhere on the popup drags the field instead.\r\n\r\nThis is a new issues in 0.49.0 (did not exist in 0.48.9 or lower)', 'created_at': datetime.datetime(2024, 3, 20, 20, 21, 9, tzinfo=datetime.timezone.utc)}]","brianschillaci on (2024-03-19 21:26:39 UTC): I'm getting this exact same issue in my instance. I just upgraded to version v0.49.0

urkle on (2024-03-20 20:21:09 UTC): The issue seems to be that the popup filter chooser is draggable and drags the field to a different order.

e.g. I have a question with 2 date filters and I try to ""select"" the date text and instead it MOVES the filter to a different position instead of selecting the text.   and clicking + dragging anywhere on the popup drags the field instead.

This is a new issues in 0.49.0 (did not exist in 0.48.9 or lower)

"
2192078570,issue,closed,completed,"Migrate global css in `frontend/src/metabase/css/core/animation.module.css`, `frontend/src/metabase/css/core/arrow.module.css`",,oisincoveney,2024-03-18 12:30:54+00:00,['oisincoveney'],2024-04-12 14:10:13+00:00,2024-03-21 14:04:17+00:00,https://github.com/metabase/metabase/issues/40231,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2191948558,issue,closed,not_planned,ParameterValuePicker improvements,"### Better UX
`ParameterValuePicker`:
- setting default value on blur/closing picker
- showing error states
- filter values for numbers
- remove `<ListPickerWrapper>`, which is a hacky fix for the unnecessary 0.25rem top margin

`ListPicker`:
- show ""remove"" button when typing when values are coming from static list

#### Misc 
- RTL languages support

### Implementation quirks
`ParameterValuePicker`:
- values transformation: get rid of `getSingleString`, `getFlattenedStrings` conversion
- use Select instead of input

`OwnDatePicker`:
- remove `useClickOutside`
- figure out what to do with the `Parameter` type
- remove non-Mantine popups to stop setting `z-index` 
- move `getInitialDateValue` and `getIsoDate` outside

### Possible bugs
- duplicate values in custom list break search",oleggromov,2024-03-18 11:29:14+00:00,['oleggromov'],2024-07-31 10:54:38+00:00,2024-07-31 10:54:38+00:00,https://github.com/metabase/metabase/issues/40226,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2191804629,issue,open,,"Add support for non-aggregating ""greatest"" expression","I have a metric that involves selecting the maximum of two aggregated values: `Max(Sum(Col1), Sum(Col2))`. Unfortunately, I am unable to write this custom expression with Metabase GUI. Using `Case(Sum(Col1) > Sum(Col2), ...)` does not work either, because aggregations in the condition argument are not supported.

**Describe the solution you'd like**
It would be great if Metabase supported a method like Bigquery's [GREATEST](https://cloud.google.com/bigquery/docs/reference/standard-sql/mathematical_functions#greatest)

**Describe alternatives you've considered**
`Case`, as described above. An SQL question is possible, but we try to avoid making them.

**How important is this feature to you?**
It limits how well our organization can use all the features of metabase.

",mmmatthew,2024-03-18 10:23:37+00:00,[],2024-03-20 12:49:33+00:00,,https://github.com/metabase/metabase/issues/40225,"[('Querying/Processor', ''), ('Type:New Feature', ''), ('Querying/Notebook/Custom Column', '')]",[],
2191754231,issue,closed,not_planned,Unable to filter for multiple values,"### Describe the bug

Previously we used to filter for multiple values in a column by copying multiple cell from a sheet and just pasting them in the column filter. All the values (separated by newline character) would be automatically selected.

A few versions ago, some datatype drop-downs became checkbox -- the option of copying and pasting was not there anymore. However, most of the tables were still working fine if the columns were not linked as a foreign key at least.

We recently updated to `v0.49` and since then no table can be filtered by a simple copy paste anymore.

<img width=""1480"" alt=""image"" src=""https://github.com/metabase/metabase/assets/73629665/0f377ed0-72d4-40bc-a25c-2d07097d29c2"">


### To Reproduce

1. Go to any table in your database
2. Click on any column and select filter by this column
3. Paste multiple values together
4. No result would come


### Expected behavior

Values separated by newlines should all be selected in the filter

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""mysql"",
      ""bigquery-cloud-sdk""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MariaDB"",
        ""version"": ""10.3.39-MariaDB-0ubuntu0.20.04.2""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.10""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Calcutta""
    }
  }
}
```


### Severity

P1, unable to use metabase

### Additional context

We use metabase to look at a lot of business data, and a lot of usecases involve filtering for a list of products (100-200) and then applying additional filters on a few other columns to identify any abnormal behaviour flags.

Multiple people looking at different sets of products use the same reports or tables and just change the filters. With this new update, we are unable to filter on so many products at once and we can't ask users to manually do 100+ copy-pastes.",abhishek-superk,2024-03-18 10:01:07+00:00,[],2024-03-19 11:32:23+00:00,2024-03-19 11:32:22+00:00,https://github.com/metabase/metabase/issues/40224,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2003530455, 'issue_id': 2191754231, 'author': 'MathiasGr', 'body': '+1 from our team at Bigblue, we got many complaints about this already.', 'created_at': datetime.datetime(2024, 3, 18, 10, 34, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2003749505, 'issue_id': 2191754231, 'author': 'abhishek-superk', 'body': 'Thanks @MathiasGr, please react with üëç so that this gets prioritized.', 'created_at': datetime.datetime(2024, 3, 18, 12, 12, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2006942841, 'issue_id': 2191754231, 'author': 'paoliniluis', 'body': 'We‚Äôre tracking this issue in the linked one, closing this as duplicate', 'created_at': datetime.datetime(2024, 3, 19, 11, 32, 22, tzinfo=datetime.timezone.utc)}]","MathiasGr on (2024-03-18 10:34:05 UTC): +1 from our team at Bigblue, we got many complaints about this already.

abhishek-superk (Issue Creator) on (2024-03-18 12:12:01 UTC): Thanks @MathiasGr, please react with üëç so that this gets prioritized.

paoliniluis on (2024-03-19 11:32:22 UTC): We‚Äôre tracking this issue in the linked one, closing this as duplicate

"
2191718974,issue,closed,completed,"Data picker shows ""Saved Questions"" on an empty *not yet activated* enterprise instance","### Describe the bug

The data picker shows ""Saved Questions"" on an empty enterprise instance that hasn't been activated.

### To Reproduce

1. Start a new Metabase instance from an enterprise JAR or Docker enterprise image and fill out the basic info
2. DO NOT create any questions or models
3. Go to the ""New"" button in the app bar, and select either a ""Question"" or a ""Model""
4. You'll see ""Saved Questions"" in a data picker when there are none on the fresh instance

![image](https://github.com/metabase/metabase/assets/31325167/bba6b58d-a19b-40a8-b970-02edaa83a982)


### Expected behavior

""Saved Questions"" should not be shown in the data picker. For example, this is what happens on an OSS instance: ![image](https://github.com/metabase/metabase/assets/31325167/c055d6b1-416b-4780-824f-6de2af817ad9)

### Logs

_No response_

### Information about your Metabase installation

```JSON
H2, Sample Database, local instance, `master`, c27b676
```


### Severity

P3

### Additional context

can be a duplicate of https://github.com/metabase/metabase/issues/32252

_No response_",nemanjaglumac,2024-03-18 09:47:25+00:00,['uladzimirdev'],2024-06-26 10:08:54+00:00,2024-06-26 10:08:54+00:00,https://github.com/metabase/metabase/issues/40223,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('Querying/Notebook', 'Items specific to the Custom/Notebook query builder'), ('.Team/Querying', '')]","[{'comment_id': 2019702573, 'issue_id': 2191718974, 'author': 'kamilmielnik', 'body': 'I can reproduce it in EE version ~both EE and OSS versions~.\r\nI can reproduce it in OSS version in dev mode only after I first used EE version (this is not a real-world scenario though).\r\n\r\n\r\nGET `/api/database?saved=true` returns ""Saved questions"" even when there are no saved questions.', 'created_at': datetime.datetime(2024, 3, 26, 7, 57, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2188983628, 'issue_id': 2191718974, 'author': 'uladzimirdev', 'body': 'I ran OSS jar 50.6 and got a saved question from the ""examples"" collection, so there is on saved question even on the fresh instance @kamilmielnik @nemanjaglumac', 'created_at': datetime.datetime(2024, 6, 25, 13, 33, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189012230, 'issue_id': 2191718974, 'author': 'uladzimirdev', 'body': '<img width=""803"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/e017d820-fffa-411d-b069-ce2a812fdb22"">\r\nthis is what I see when I run EE version locally for the first time', 'created_at': datetime.datetime(2024, 6, 25, 13, 47, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189044871, 'issue_id': 2191718974, 'author': 'kamilmielnik', 'body': 'With the new default Examples collection I think this issue is not ""valid"" anymore. @nemanjaglumac can you confirm?', 'created_at': datetime.datetime(2024, 6, 25, 14, 1, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2189151258, 'issue_id': 2191718974, 'author': 'nemanjaglumac', 'body': 'Yep, if we ship ""Examples"" by default, this whole issue doesn\'t make sense.', 'created_at': datetime.datetime(2024, 6, 25, 14, 41, 16, tzinfo=datetime.timezone.utc)}]","kamilmielnik on (2024-03-26 07:57:01 UTC): I can reproduce it in EE version ~both EE and OSS versions~.
I can reproduce it in OSS version in dev mode only after I first used EE version (this is not a real-world scenario though).


GET `/api/database?saved=true` returns ""Saved questions"" even when there are no saved questions.

uladzimirdev (Assginee) on (2024-06-25 13:33:59 UTC): I ran OSS jar 50.6 and got a saved question from the ""examples"" collection, so there is on saved question even on the fresh instance @kamilmielnik @nemanjaglumac

uladzimirdev (Assginee) on (2024-06-25 13:47:14 UTC): <img width=""803"" alt=""image"" src=""https://github.com/metabase/metabase/assets/125459446/e017d820-fffa-411d-b069-ce2a812fdb22"">
this is what I see when I run EE version locally for the first time

kamilmielnik on (2024-06-25 14:01:34 UTC): With the new default Examples collection I think this issue is not ""valid"" anymore. @nemanjaglumac can you confirm?

nemanjaglumac (Issue Creator) on (2024-06-25 14:41:16 UTC): Yep, if we ship ""Examples"" by default, this whole issue doesn't make sense.

"
2191612139,issue,closed,completed,Format of datetime in normal YYYY-MM-DD,"### Describe the bug

We updated to v0.49.0 and starting getting formated numbers, dates and datetimes in API calls for data - not only in shown frontend tables.

Numbers were fixed by setting localize format, but in date and datetimes is missing standard format YYYY-MM-DD.
Timepart is in 12 hour mode and 24 hour mode, but it puts comma between date and time.

This is what we are getting from API: **2023-7-18, 14:15**
Where is standard format **yyyy-mm-dd hh-mm-ss**?

Should be readable format for tables used also in API calls for data?
In my state of opinion format should be applied only on frontend tables to display data.

![Sn√≠mka obrazovky 2024-03-18 094720](https://github.com/metabase/metabase/assets/20593907/b789506d-604d-4b49-af6f-731c3370fe01)
![Sn√≠mka obrazovky 2024-03-18 094738](https://github.com/metabase/metabase/assets/20593907/c3455e3b-8bcc-4747-b81f-d8a6e6fdfc82)


### To Reproduce

1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error


### Expected behavior

Datetime format: yyyy-mm-dd hh-mm-ss (without comma and with 2 digits for month and day part)

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-GB"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.4.0-152-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3 (Debian 15.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Bratislava""
    }
  }
}
```


### Severity

4

### Additional context

_No response_",tavarez992,2024-03-18 09:06:11+00:00,[],2024-06-11 08:34:44+00:00,2024-03-20 17:09:00+00:00,https://github.com/metabase/metabase/issues/40221,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 2007665638, 'issue_id': 2191612139, 'author': 'paoliniluis', 'body': 'Hi, can you give us some reproduction steps?', 'created_at': datetime.datetime(2024, 3, 19, 16, 46, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2008994841, 'issue_id': 2191612139, 'author': 'tavarez992', 'body': ""Set up localization options like this for example:\r\n![image](https://github.com/metabase/metabase/assets/20593907/6cb9de2e-fed1-44a0-b09f-c96aaced7261)\r\n\r\nIn my opinion this should only affect table cells like here - it's nice formatted\r\n![image](https://github.com/metabase/metabase/assets/20593907/7aa7aee9-d56f-4d32-84f0-493866c42d67)\r\n\r\nThen call API\r\nAPI path: /api/card/{questionId}/query/json\r\nWhen you get reasource it will return thouse 2 columns in this format in Metabase v0.48.5 (we were forced to downgrade)\r\n```\r\narray(\r\n   'date_updated' => '2023-07-18T14:15:37',\r\n   'date_contract_first' => '2017-08-22',\r\n)\r\n```\r\n\r\nIn v0.49.0 API response contains formated cells like:\r\n```\r\narray(\r\n   'date_updated' => '18.7.2023, 14:15',\r\n   'date_contract_first' => '22.8.2017',\r\n)\r\n```\r\n\r\nBut our system works with normal format of dates (yyyy-mm-dd hh-mm-ss) so we found it out really quickly :)\r\nIt is same with number formats - if you have separator in thousands API call return reasource with spaces in value and it's string."", 'created_at': datetime.datetime(2024, 3, 20, 8, 9, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2010084386, 'issue_id': 2191612139, 'author': 'paoliniluis', 'body': 'Hi, this is an API change that I just documented here https://github.com/metabase/metabase/pull/40389', 'created_at': datetime.datetime(2024, 3, 20, 17, 6, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2016741244, 'issue_id': 2191612139, 'author': 'tavarez992', 'body': 'Could we at least add new formats? \r\nOr get rid off column in date time part?', 'created_at': datetime.datetime(2024, 3, 24, 9, 1, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2032107626, 'issue_id': 2191612139, 'author': 'guybowden', 'body': 'The change of formats without the option to either revert back to an unformatted version or set a more ISO friendly format like `YYYY-MM-DD` is causing havoc with my users who are using downloads in Google Sheets.', 'created_at': datetime.datetime(2024, 4, 2, 13, 53, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2096636286, 'issue_id': 2191612139, 'author': 'hjc', 'body': ""Being unable to set a format that's more predictable, like `YYYY-MM-DD` is also causing havoc for my customers who go through a manual export flow (to .json or .csv) before importing into other tools and databases.\r\n\r\nWould love to see some commentary here."", 'created_at': datetime.datetime(2024, 5, 6, 18, 16, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2100843321, 'issue_id': 2191612139, 'author': 'ember-zhang', 'body': ""The downloaded csv got problems with this. Some apps ( such as Apple Numbers ) can't sort the date colume correctly."", 'created_at': datetime.datetime(2024, 5, 8, 15, 27, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2158647160, 'issue_id': 2191612139, 'author': 'tadeumaia', 'body': 'Anyone got a solution for this? This broke all my api <> google sheets integrations', 'created_at': datetime.datetime(2024, 6, 10, 15, 21, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2160121801, 'issue_id': 2191612139, 'author': 'tavarez992', 'body': ""Unfortunately we were forced to run over all report questions and format date columns with\r\n`DATE_FORMAT(xyz, '%Y-%m-%d')`"", 'created_at': datetime.datetime(2024, 6, 11, 8, 34, 43, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-19 16:46:36 UTC): Hi, can you give us some reproduction steps?

tavarez992 (Issue Creator) on (2024-03-20 08:09:44 UTC): Set up localization options like this for example:
![image](https://github.com/metabase/metabase/assets/20593907/6cb9de2e-fed1-44a0-b09f-c96aaced7261)

In my opinion this should only affect table cells like here - it's nice formatted
![image](https://github.com/metabase/metabase/assets/20593907/7aa7aee9-d56f-4d32-84f0-493866c42d67)

Then call API
API path: /api/card/{questionId}/query/json
When you get reasource it will return thouse 2 columns in this format in Metabase v0.48.5 (we were forced to downgrade)
```
array(
   'date_updated' => '2023-07-18T14:15:37',
   'date_contract_first' => '2017-08-22',
)
```

In v0.49.0 API response contains formated cells like:
```
array(
   'date_updated' => '18.7.2023, 14:15',
   'date_contract_first' => '22.8.2017',
)
```

But our system works with normal format of dates (yyyy-mm-dd hh-mm-ss) so we found it out really quickly :)
It is same with number formats - if you have separator in thousands API call return reasource with spaces in value and it's string.

paoliniluis on (2024-03-20 17:06:02 UTC): Hi, this is an API change that I just documented here https://github.com/metabase/metabase/pull/40389

tavarez992 (Issue Creator) on (2024-03-24 09:01:25 UTC): Could we at least add new formats? 
Or get rid off column in date time part?

guybowden on (2024-04-02 13:53:59 UTC): The change of formats without the option to either revert back to an unformatted version or set a more ISO friendly format like `YYYY-MM-DD` is causing havoc with my users who are using downloads in Google Sheets.

hjc on (2024-05-06 18:16:31 UTC): Being unable to set a format that's more predictable, like `YYYY-MM-DD` is also causing havoc for my customers who go through a manual export flow (to .json or .csv) before importing into other tools and databases.

Would love to see some commentary here.

ember-zhang on (2024-05-08 15:27:15 UTC): The downloaded csv got problems with this. Some apps ( such as Apple Numbers ) can't sort the date colume correctly.

tadeumaia on (2024-06-10 15:21:33 UTC): Anyone got a solution for this? This broke all my api <> google sheets integrations

tavarez992 (Issue Creator) on (2024-06-11 08:34:43 UTC): Unfortunately we were forced to run over all report questions and format date columns with
`DATE_FORMAT(xyz, '%Y-%m-%d')`

"
2190919744,issue,closed,completed,Bug when filtering on a date (empty or not) on a model,"### Describe the bug

I wanted to test my model. One of the column is a date and I wanted to have all rows which have the column as non-null (not empty). Thus, I create a new filter, select my column, click 
When i want to filter a date by its emptiness, it does the contrary.

### To Reproduce

1. Go to a model which include a colmun with date datatype
2. Add a filter on this column
3. Click on ""Exclude"" (""Exclure"" in french)
4. Click on ""Is empty""
-> the filter ""is not empty"" is put


### Expected behavior

The filter ""is empty"" should have been selected instead.

### Logs

_No response_

### Information about your Metabase installation

```JSON
- Windows 10
- Firefox version 115
- Database : postgreSQL
- Metabase version : v1.48.4 (released on 2024-01-29)
- French version
```


### Severity

Minor

### Additional context

Thank you in advance for your work.",Pierre-PSUD,2024-03-17 23:21:10+00:00,[],2024-03-19 17:24:24+00:00,2024-03-19 17:24:24+00:00,https://github.com/metabase/metabase/issues/40218,"[('Type:Bug', 'Product defects')]","[{'comment_id': 2007745137, 'issue_id': 2190919744, 'author': 'paoliniluis', 'body': 'this works fine (testing in v49), but the problem is https://github.com/metabase/metabase/issues/26771', 'created_at': datetime.datetime(2024, 3, 19, 17, 24, 24, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-19 17:24:24 UTC): this works fine (testing in v49), but the problem is https://github.com/metabase/metabase/issues/26771

"
2189694875,issue,closed,completed,we're waiting till the end of the /database endpoint to return to load the saved questions,"### Describe the bug

Seems that for some reason we're waiting till the end of the /databases endpoint call to complete the load of the saved questions in the question builder

### To Reproduce

1) reduce the speed of your browser
2) go to the question builder on stats
3) see the load cadence

### Expected behavior

We should load everything asynchronously

### Logs

NA

### Information about your Metabase installation

```JSON
v48+
```


### Severity

P2

### Additional context

![Peek 2024-03-15 22-58](https://github.com/metabase/metabase/assets/1711649/0ee39708-3bc1-4cab-999e-4dcc1d5af705)
",paoliniluis,2024-03-16 02:02:13+00:00,[],2024-07-03 12:57:41+00:00,2024-07-03 12:57:13+00:00,https://github.com/metabase/metabase/issues/40216,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Performance', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Already Fixed', 'will apear in ""Already Fixed"" in the release notes (not ""Bug Fixes"" that we actively fixed)'), ('.Team/Querying', '')]","[{'comment_id': 2205636967, 'issue_id': 2189694875, 'author': 'nemanjaglumac', 'body': '@paoliniluis not sure exactly what you meant by ""waiting till the end of the /database endpoint` because I can see TWO calls to that endpoint in your recording.\r\n\r\nThe first one calls `GET /api/database`, and then the last one calls `GET /api/database?saved=true`.\r\n\r\nIn any case, this is not reproducible anymore because we switched to the new EntityPicker.\r\nLeaving the issue open until we figure out whether or not to fix it specifically for v49.', 'created_at': datetime.datetime(2024, 7, 3, 10, 2, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206013062, 'issue_id': 2189694875, 'author': 'paoliniluis', 'body': 'If this is no longer happening then feel free to close it', 'created_at': datetime.datetime(2024, 7, 3, 12, 55, 7, tzinfo=datetime.timezone.utc)}]","nemanjaglumac on (2024-07-03 10:02:18 UTC): @paoliniluis not sure exactly what you meant by ""waiting till the end of the /database endpoint` because I can see TWO calls to that endpoint in your recording.

The first one calls `GET /api/database`, and then the last one calls `GET /api/database?saved=true`.

In any case, this is not reproducible anymore because we switched to the new EntityPicker.
Leaving the issue open until we figure out whether or not to fix it specifically for v49.

paoliniluis (Issue Creator) on (2024-07-03 12:55:07 UTC): If this is no longer happening then feel free to close it

"
2189677094,issue,closed,completed,[dc.js migration] emphasis state on single series histograms highlights incorrect element,"https://github.com/metabase/metabase/assets/37751258/085b6f97-9ade-4ec6-a040-7deab3484387

https://metabase-echarts.hosted.staging.metabase.com/question/2772-number-of-orders-by-tax

I think this may be an issue with the echarts library itself. Our own tooltip and click behavior has the correct data index, and this bug doesn't happen when the `emphasis` option is set to `series` instead of `self` (e.g. on multi-series histograms).",EmmadUsmani,2024-03-16 01:19:29+00:00,['JesseSDevaney'],2024-03-22 18:35:22+00:00,2024-03-22 18:35:22+00:00,https://github.com/metabase/metabase/issues/40215,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189652214,issue,closed,completed,[dc.js migration] waterfall does not show `(empty)` label for null dimension values,"<img width=""929"" alt=""Screenshot 2024-03-15 at 5 23 27 PM"" src=""https://github.com/metabase/metabase/assets/37751258/193ed119-10f4-4c8d-9cdf-1f0e878a501b"">

Like other charts, we should show `(empty)` as the label instead of showing no label on the x-axis.",EmmadUsmani,2024-03-16 00:24:35+00:00,['alxnddr'],2024-04-03 00:17:36+00:00,2024-04-03 00:17:36+00:00,https://github.com/metabase/metabase/issues/40214,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189648618,issue,closed,completed,[dc.js migration] waterfall data label shows `0` instead of no label for null values,"<img width=""1884"" alt=""Screenshot 2024-03-15 at 5 18 05 PM"" src=""https://github.com/metabase/metabase/assets/37751258/72ce9802-4bd9-4542-a8e4-93a101dbc016"">

http://localhost:3000/question/205-waterfall-example-nulls

We shouldn't show `0` for the data label when a metric value is null on the waterfall chart. Instead we should not show any label at all.
",EmmadUsmani,2024-03-16 00:19:45+00:00,['EmmadUsmani'],2024-03-19 19:47:15+00:00,2024-03-19 19:47:15+00:00,https://github.com/metabase/metabase/issues/40213,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189643978,issue,closed,completed,[dc.js migration] log y-axis scale looks wrong on stacked charts,"https://github.com/metabase/metabase/assets/37751258/ca0396a0-8317-46e4-8f2d-55b6199f9a51

http://localhost:3000/question/283-bar-log-y-axis-scale-looks-wrong-on-stacked-charts

One thing to note about this question is that some series values are null for some dimensions, e.g. there is no pokemon with type 1 equal to flying in generation 1.


",EmmadUsmani,2024-03-16 00:15:49+00:00,['EmmadUsmani'],2024-03-27 20:29:47+00:00,2024-03-27 20:29:47+00:00,https://github.com/metabase/metabase/issues/40212,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189633589,issue,closed,completed,[dc.js migration] missing series on normalized stacked charts with power y-axis scale,"<img width=""1897"" alt=""Screenshot 2024-03-15 at 4 55 04 PM"" src=""https://github.com/metabase/metabase/assets/37751258/ef81f00f-15c0-43fa-818e-23720b787516"">

http://localhost:3000/question/282

We don't allow log y-axis scales for normalized stacked charts, so I'm not sure why on master we currently allow the power y-axis scale for it. Perhaps we should disallow the power y-axis for normalized stacked charts as well. ",EmmadUsmani,2024-03-16 00:05:50+00:00,['EmmadUsmani'],2024-04-05 18:19:22+00:00,2024-04-05 18:19:15+00:00,https://github.com/metabase/metabase/issues/40211,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2040375749, 'issue_id': 2189633589, 'author': 'EmmadUsmani', 'body': '<img width=""1866"" alt=""Screenshot 2024-04-05 at 11 18 53 AM"" src=""https://github.com/metabase/metabase/assets/37751258/f5fcf930-86ce-4ac3-abc9-219580849ab6"">\r\n\r\nJust confirmed this was fixed by https://github.com/metabase/metabase/pull/40413', 'created_at': datetime.datetime(2024, 4, 5, 18, 19, 13, tzinfo=datetime.timezone.utc)}]","EmmadUsmani (Issue Creator) on (2024-04-05 18:19:13 UTC): <img width=""1866"" alt=""Screenshot 2024-04-05 at 11 18 53 AM"" src=""https://github.com/metabase/metabase/assets/37751258/f5fcf930-86ce-4ac3-abc9-219580849ab6"">

Just confirmed this was fixed by https://github.com/metabase/metabase/pull/40413

"
2189625384,issue,closed,completed,[dc.js migration] incorrect data on stacked charts with power y-axis scale,"| Linear y-axis scale | Power y-axis scale|
|--------|--------|
| <img width=""1889"" alt=""Screenshot 2024-03-15 at 4 50 38 PM"" src=""https://github.com/metabase/metabase/assets/37751258/95f08b06-5aa8-4b3f-8712-dd85de3499bd""> | <img width=""1887"" alt=""Screenshot 2024-03-15 at 4 50 47 PM"" src=""https://github.com/metabase/metabase/assets/37751258/8780a300-c49f-4e85-b747-70016d62eb6c""> | 

http://localhost:3000/question/187-bar-multiseries-ordinal-stacked-poke-avg-of-base-stats-by-gen
",EmmadUsmani,2024-03-15 23:57:40+00:00,['EmmadUsmani'],2024-03-20 23:39:50+00:00,2024-03-20 23:39:50+00:00,https://github.com/metabase/metabase/issues/40210,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189613219,issue,closed,completed,[dc.js migration] areas render under bars in combo charts,"<img width=""1888"" alt=""Screenshot 2024-03-15 at 4 38 02 PM"" src=""https://github.com/metabase/metabase/assets/37751258/a02e5dde-94f3-4519-b2a6-720a719944de"">

http://localhost:3000/question/281-combo-40209-areas-render-under-bars-in-combo-charts

The fix is to set the `z` property of the line/area series to always be greater than the `z` of the bar series.",EmmadUsmani,2024-03-15 23:38:53+00:00,['kulyk'],2024-03-21 11:12:09+00:00,2024-03-21 11:12:09+00:00,https://github.com/metabase/metabase/issues/40209,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189564397,issue,closed,completed,[dc.js migration] uncentered x-axis tick labels on waterfall chart,"question/15060
https://metaboat.slack.com/archives/C06G94JTWBS/p1710361804033919

<img width=""1589"" alt=""Screenshot 2024-03-15 at 3 30 45 PM"" src=""https://github.com/metabase/metabase/assets/37751258/8f7a4d64-869d-46c2-9e5d-9ec3cfa930eb"">
",EmmadUsmani,2024-03-15 22:31:07+00:00,['alxnddr'],2024-03-22 18:05:08+00:00,2024-03-22 18:05:08+00:00,https://github.com/metabase/metabase/issues/40208,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189536741,issue,closed,completed,[dc.js migration] dashcards look wonky after resizing,"dashboard/1907
https://metaboat.slack.com/archives/C06G94JTWBS/p1710540091417669?thread_ts=1710343866.091029&cid=C06G94JTWBS
",EmmadUsmani,2024-03-15 22:02:42+00:00,['kulyk'],2024-04-04 20:57:06+00:00,2024-04-04 20:57:06+00:00,https://github.com/metabase/metabase/issues/40206,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2021560497, 'issue_id': 2189536741, 'author': 'JesseSDevaney', 'body': 'Could reproduce on the original dashboard, but I could not reproduce the behavior locally. Also, after duplicating the wonky dashboard, removing all but 2 of the wonky dash-cards, and refreshing the page, it appears that the behavior no longer occurs. So I think the issue has something to do with the number of dash-cards being rendered. \r\n\r\nSpent quite some time on this, so I am going to move on from this issue for now.\r\n\r\n---\r\n**Summary**: When resizing a large dashboard, it appears that dash-cards are undergoing 2 or more rendering cycles. We get the weird visualizations displayed when the dash-card is not able to complete the 2nd or last rendering cycle. If you look at the width of the x-axis for the dash-card when the wonky resizing occurs, you can see that the x-axis/visualization is not taking up the full-space it has available, potentially part of the problem.\r\n\r\n**Duplicated Dashboard**: `dashboard/2236-testing-duplicate`\r\n- This is a duplicate of `dashboard/1907` with all but two of the dash-cards removed. If you load up this dashboard, you can see that the behavior no longer occurs. And all I did was remove other dash-cards.', 'created_at': datetime.datetime(2024, 3, 26, 22, 13, 41, tzinfo=datetime.timezone.utc)}]","JesseSDevaney on (2024-03-26 22:13:41 UTC): Could reproduce on the original dashboard, but I could not reproduce the behavior locally. Also, after duplicating the wonky dashboard, removing all but 2 of the wonky dash-cards, and refreshing the page, it appears that the behavior no longer occurs. So I think the issue has something to do with the number of dash-cards being rendered. 

Spent quite some time on this, so I am going to move on from this issue for now.

---
**Summary**: When resizing a large dashboard, it appears that dash-cards are undergoing 2 or more rendering cycles. We get the weird visualizations displayed when the dash-card is not able to complete the 2nd or last rendering cycle. If you look at the width of the x-axis for the dash-card when the wonky resizing occurs, you can see that the x-axis/visualization is not taking up the full-space it has available, potentially part of the problem.

**Duplicated Dashboard**: `dashboard/2236-testing-duplicate`
- This is a duplicate of `dashboard/1907` with all but two of the dash-cards removed. If you load up this dashboard, you can see that the behavior no longer occurs. And all I did was remove other dash-cards.

"
2189522374,issue,closed,not_planned,[dc.js migration] y-axis ticks missing formatting,"question/5961
https://metaboat.slack.com/archives/C06G94JTWBS/p1710343761630119",EmmadUsmani,2024-03-15 21:53:45+00:00,[],2024-03-15 22:23:11+00:00,2024-03-15 22:00:32+00:00,https://github.com/metabase/metabase/issues/40205,[],"[{'comment_id': 2000538085, 'issue_id': 2189522374, 'author': 'alxnddr', 'body': 'Not a bug, the staging instance have different column metadata', 'created_at': datetime.datetime(2024, 3, 15, 22, 0, 32, tzinfo=datetime.timezone.utc)}]","alxnddr on (2024-03-15 22:00:32 UTC): Not a bug, the staging instance have different column metadata

"
2189517068,issue,closed,completed,[dc.js migration] timeline event renders on the wrong date,"question/6025
https://metaboat.slack.com/archives/C06G94JTWBS/p1710342227856639

It is a timezone issue",EmmadUsmani,2024-03-15 21:47:46+00:00,['alxnddr'],2024-03-28 22:37:56+00:00,2024-03-28 22:37:56+00:00,https://github.com/metabase/metabase/issues/40204,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189275076,issue,closed,completed,[dc.js migration] data labels too dense with large single series,"question/12014

![image](https://github.com/metabase/metabase/assets/22608765/583c2ebf-dc95-412d-89da-22a6b4cd9c7f)

---
Relevant files for calculating how dense labels should be
- [chart_values.js (master)](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/lib/chart_values.js#L319-L346)
- [buildEChartsLabelOptions (ECharts)](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/option/series.ts#L120)
- [getDataLabelFormatter (ECharts)](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/option/series.ts#L92)
",JesseSDevaney,2024-03-15 18:52:16+00:00,['JesseSDevaney'],2024-10-08 17:09:36+00:00,2024-06-01 06:05:24+00:00,https://github.com/metabase/metabase/issues/40196,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.Team/DashViz', 'Dashboard and Viz team'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2000273927, 'issue_id': 2189275076, 'author': 'JesseSDevaney', 'body': 'Relevant files for calculating how dense labels should be\r\n- [chart_values.js (master)](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/lib/chart_values.js#L319-L346)\r\n- [buildEChartsLabelOptions (ECharts)](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/option/series.ts#L120)\r\n- [getDataLabelFormatter (ECharts)](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/option/series.ts#L92)', 'created_at': datetime.datetime(2024, 3, 15, 18, 58, 37, tzinfo=datetime.timezone.utc)}]","JesseSDevaney (Issue Creator) on (2024-03-15 18:58:37 UTC): Relevant files for calculating how dense labels should be
- [chart_values.js (master)](https://github.com/metabase/metabase/blob/master/frontend/src/metabase/visualizations/lib/chart_values.js#L319-L346)
- [buildEChartsLabelOptions (ECharts)](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/option/series.ts#L120)
- [getDataLabelFormatter (ECharts)](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/option/series.ts#L92)

"
2189235216,issue,open,,"Filters in model replies with ""You don't have permissions to do that"" (403)","### Describe the bug

Interesting case also on the edumation demo: if you try filtering on a column on a specific model you won't be able to as it returns a 403

### To Reproduce

1) go to the edumation demo
2) create a gui question
3) use the assignments model and try a filter in the status column
4) see the error

### Expected behavior

It should show the values

### Logs

NA

### Information about your Metabase installation

```JSON
v49
```


### Severity

P2ish

### Additional context

This model is corrupted in some way as it's also the same as https://github.com/metabase/metabase/issues/40191 and https://github.com/metabase/metabase/issues/40193",paoliniluis,2024-03-15 18:25:17+00:00,[],2025-02-04 20:31:06+00:00,,https://github.com/metabase/metabase/issues/40194,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', ''), ('Semantic Model', ''), ('Semantic Model/Models', '')]",[],
2189228178,issue,closed,completed,Model does not bring the options in filters although the api responds with a 200 and the values,"### Describe the bug

If you try to filter on a column that has synced values, the values won't appear although the endpoint returns those values

### To Reproduce

1) go to our edumation demo and log in
2) go to the assignments model
3) try filtering on the status column


### Expected behavior

It should show the values

### Logs

No logs on BE or FE

### Information about your Metabase installation

```JSON
- v49
```


### Severity

P2ish

### Additional context

![image](https://github.com/metabase/metabase/assets/1711649/a51aba70-5510-443e-ad03-7ef0ebe021fe)
![image](https://github.com/metabase/metabase/assets/1711649/a31d8f0f-1d0e-4157-8fab-8a1f527e1747)
",paoliniluis,2024-03-15 18:21:02+00:00,['ranquild'],2024-06-27 14:39:50+00:00,2024-06-27 14:39:44+00:00,https://github.com/metabase/metabase/issues/40193,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Unable to Reproduce', ''), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Frontend', ''), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2194909692, 'issue_id': 2189228178, 'author': 'ranquild', 'body': ""Couldn't repro nowdays. I believe it was solved by this PR https://github.com/metabase/metabase/pull/44440"", 'created_at': datetime.datetime(2024, 6, 27, 14, 39, 44, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-06-27 14:39:44 UTC): Couldn't repro nowdays. I believe it was solved by this PR https://github.com/metabase/metabase/pull/44440

"
2189199466,issue,closed,not_planned,Model loses metadata in query builder,"### Describe the bug

Seems that we're losing metadata in some models (reasons unknown)

### To Reproduce

1) go to https://embedding-demo.metabaseapp.com/
2) log in and go to the assignments model
3) edit the model query, see that the query builder is completely empty

### Expected behavior

You should see the question definition there

### Logs

nothing on the FE or BE which is interesting

### Information about your Metabase installation

```JSON
I don't know if this is v49 or what, don't think so...
Using brave latest on pop-os
```


### Severity

P2'ish

### Additional context

Other models work, don't why this one specifically does not",paoliniluis,2024-03-15 18:03:17+00:00,['ranquild'],2024-07-17 21:42:53+00:00,2024-07-17 21:42:52+00:00,https://github.com/metabase/metabase/issues/40191,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2234372275, 'issue_id': 2189199466, 'author': 'ranquild', 'body': 'Duplicate of https://github.com/metabase/metabase/issues/26755', 'created_at': datetime.datetime(2024, 7, 17, 21, 42, 52, tzinfo=datetime.timezone.utc)}]","ranquild (Assginee) on (2024-07-17 21:42:52 UTC): Duplicate of https://github.com/metabase/metabase/issues/26755

"
2189195813,issue,open,,"Columns with the ""Avatar IMG URL"" Semantic type will display the url instead of an image when sent out in Subscriptions","### Describe the bug

Hello Team,
Please feel free to convert this to a feature request if this is functioning as expected.

Columns with the ""Avatar IMG URL"" Semantic type will display the url instead of an image when sent out in Subscriptions.
Tested this in 1.48.6 and 1.49.0 with similar results.

### To Reproduce

1. Create a question with a column of the Avatar IMG URL Semantic type and add to a dashboard.
<img width=""1017"" alt=""steph_lebron_url"" src=""https://github.com/metabase/metabase/assets/17398657/9164c621-19c4-44d8-8c3a-4c08cc7500e5"">

<br />

<img width=""1068"" alt=""avatar_imgurl"" src=""https://github.com/metabase/metabase/assets/17398657/d554c4a9-12b9-4955-86f4-8c8252ef6ec8"">


<br />
<br />

2. Dashboard should display the images.
<img width=""880"" alt=""steph_lebron"" src=""https://github.com/metabase/metabase/assets/17398657/468e8eac-f862-4003-b907-f402af05a896"">


<br />
<br />

3. Send the dashboard as a subscription.
![subscription_result](https://github.com/metabase/metabase/assets/17398657/c471a907-cc57-4c1a-8084-ab5aaa354306)



### Expected behavior

Customer would like the preview in the subscription to display the images

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.49-linuxkit-pr"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres"",
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.1 (Debian 15.1-1.pgdg110+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v1.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

P3

### Additional context

_No response_",FilmonK,2024-03-15 18:00:55+00:00,[],2025-02-04 20:29:29+00:00,,https://github.com/metabase/metabase/issues/40189,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]",[],
2189124280,issue,open,,"Settings toast stuck on ""Saving..."" when response is 403 forbidden","### Describe the bug

For errors such as 403 forbidden, the toasts used in the admin settings are stuck on ""Saving..."" and no error is shown.

### To Reproduce

Not sure if there are other ways to repro this, this is how I did
- login with admin
- go to any admin setting that would show the toast (I used Localization > Fist day of the week)
- in another tab, use jwt login to login as another user that doesn't have admin access
- on the first tab, try to change the setting
- the toast is stuck on ""Saving...""  with no error shown, even though the request failed
<img width=""1282"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/437266b9-be66-49f9-bcab-321e509665fa"">

I tried to reproduce this without the jwt flow but when I log out on one tab, the other tabs refresh too, so this may be a very edge case


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Repro-ed on 35cf89a5918a8cb06ae84408fe5d8974ce790429
```


### Severity

low

### Additional context

_No response_",npretto,2024-03-15 17:15:53+00:00,[],2025-02-04 20:24:43+00:00,,https://github.com/metabase/metabase/issues/40186,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/Settings', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2061649967, 'issue_id': 2189124280, 'author': 'sloansparger', 'body': ""@npretto is this another tab in the same browser? if so you're 403ing in the first tab because you've signed out when signing into the first tab, right?"", 'created_at': datetime.datetime(2024, 4, 17, 16, 1, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2061651722, 'issue_id': 2189124280, 'author': 'sloansparger', 'body': ""I'm struggling to repro this, when hard coding the endpoint to return 403 it works as expected."", 'created_at': datetime.datetime(2024, 4, 17, 16, 2, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2063345248, 'issue_id': 2189124280, 'author': 'npretto', 'body': 'Just repro-ed again:\r\n<img width=""1406"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/19145b75-2f56-419e-ab0b-3d7caed23146"">\r\n<img width=""1363"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/240bf8f2-5757-4eb3-8406-015eaa4a5818"">\r\n\r\nIf you need a quick way to setup SSO to repro it, I recently updated my embedding playground and it just needs a few envs to setup: https://github.com/npretto/metabase-embedding-playground\r\n\r\nFeel free to ping me on slack if you need help with reproducing this', 'created_at': datetime.datetime(2024, 4, 18, 8, 43, 39, tzinfo=datetime.timezone.utc)}]","sloansparger on (2024-04-17 16:01:52 UTC): @npretto is this another tab in the same browser? if so you're 403ing in the first tab because you've signed out when signing into the first tab, right?

sloansparger on (2024-04-17 16:02:45 UTC): I'm struggling to repro this, when hard coding the endpoint to return 403 it works as expected.

npretto (Issue Creator) on (2024-04-18 08:43:39 UTC): Just repro-ed again:
<img width=""1406"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/19145b75-2f56-419e-ab0b-3d7caed23146"">
<img width=""1363"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1914270/240bf8f2-5757-4eb3-8406-015eaa4a5818"">

If you need a quick way to setup SSO to repro it, I recently updated my embedding playground and it just needs a few envs to setup: https://github.com/npretto/metabase-embedding-playground

Feel free to ping me on slack if you need help with reproducing this

"
2189112901,issue,open,,Incorrect question metadata after Update,"### Describe the bug

![image](https://github.com/metabase/metabase/assets/7417323/4a35a65c-ea0d-4434-ae07-ea5843099369)

Version: 0.48.2

Description:

After updating to version 0.48.2, I've noticed an issue with the history of my questions. It appears that some questions have incorrect creation dates, showing the update date instead.

![image](https://github.com/metabase/metabase/assets/7417323/d7f93569-c1c8-4644-8660-a1c7ea0b7a88)


Additional context: The affected user account had been disabled years ago.


![image](https://github.com/metabase/metabase/assets/7417323/2e5a0602-7646-4aca-9780-2cf0d1971e02)

Other questions are experiencing the same issue.

![image](https://github.com/metabase/metabase/assets/7417323/1c713b7c-1ec8-46fd-94ad-e7785396ee3c)


### To Reproduce

1. Update to 0.48.2
2. Check on metadata questions.
4. See error


### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
0.48.2 with MariaDB
```


### Severity

annoying only

### Additional context

_No response_",tomeli5n,2024-03-15 17:09:25+00:00,[],2024-05-20 15:13:59+00:00,,https://github.com/metabase/metabase/issues/40185,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Organization/', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2000201061, 'issue_id': 2189112901, 'author': 'paoliniluis', 'body': 'Can you move to 48.8?', 'created_at': datetime.datetime(2024, 3, 15, 18, 16, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2018044932, 'issue_id': 2189112901, 'author': 'tomeli5n', 'body': ""We continue to experience the error after updating to 48.8.\r\n\r\nAnalyzing the issue with the team, we see that it's not with all the questions, but with all those that have not been modified in the last few months and therefore do not have a change history. It seems that the bug created extra modification movements. For example, this question was definitely not modified.\r\n\r\n![image](https://github.com/metabase/metabase/assets/7417323/7493d7df-8cee-486b-8635-041d1d366652)"", 'created_at': datetime.datetime(2024, 3, 25, 13, 46, 54, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-15 18:16:52 UTC): Can you move to 48.8?

tomeli5n (Issue Creator) on (2024-03-25 13:46:54 UTC): We continue to experience the error after updating to 48.8.

Analyzing the issue with the team, we see that it's not with all the questions, but with all those that have not been modified in the last few months and therefore do not have a change history. It seems that the bug created extra modification movements. For example, this question was definitely not modified.

![image](https://github.com/metabase/metabase/assets/7417323/7493d7df-8cee-486b-8635-041d1d366652)

"
2189085287,issue,closed,completed,[dc.js migration] data labels should not be blurred,"<img width=""859"" alt=""Screenshot 2024-03-15 at 9 52 18 AM"" src=""https://github.com/metabase/metabase/assets/37751258/71c3d336-f454-41c3-adfd-7960393d1a7c"">

question/3406
https://metaboat.slack.com/archives/C06G94JTWBS/p1710341761604819",EmmadUsmani,2024-03-15 16:53:24+00:00,['alxnddr'],2024-03-29 21:24:04+00:00,2024-03-29 21:24:04+00:00,https://github.com/metabase/metabase/issues/40183,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189055843,issue,closed,completed,[dc.js migration] tooltip shows date instead of date range,"question/12744
https://metaboat.slack.com/archives/C06G94JTWBS/p1710341443435089",EmmadUsmani,2024-03-15 16:36:23+00:00,['alxnddr'],2024-03-22 18:05:06+00:00,2024-03-22 18:05:06+00:00,https://github.com/metabase/metabase/issues/40182,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2189001784,issue,closed,completed,[dc.js migration] timeline event line renders on top of bars,"question/13475
https://metaboat.slack.com/archives/C06G94JTWBS/p1710341008223099",EmmadUsmani,2024-03-15 16:14:24+00:00,['alxnddr'],2024-04-03 21:05:32+00:00,2024-04-03 21:05:32+00:00,https://github.com/metabase/metabase/issues/40180,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]","[{'comment_id': 2000440377, 'issue_id': 2189001784, 'author': 'JesseSDevaney', 'body': 'Attempted the fix for this, but because `markLine` is being used here, it does not respect the z-index given. `markLine` has a fixed z value of 5 ([see ECharts src](https://github.com/apache/echarts/blob/fbee94d5dd3fe8a957524620eb3657145670bd50/src/component/marker/MarkLineModel.ts#L116)). This value is greater than the series `z-index: 2`, so it appears in front of the data points/bars. This fix seems more involved than an on-boarding/easy fix should require.\r\n\r\nRelevant Files\r\n- [timeline-events/options.ts](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/timeline-events/option.ts#L52-L103)\r\n- [styles.ts/CHART_STYLE](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/constants/style.ts#L32-L37)\r\n  - See [line #3](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/constants/style.ts#L3) for the comment talking about `markLine` having a fixed z-index value of 5\r\n\r\n---\r\n**Note:** We cannot just bump up the z-indexes relative to one another, because the goal line also uses a `markLine`. If we updated the series and trend lines to fix the timeline events problem, it would introduce a problem for the goal line, which would now be behind the data points/bars.', 'created_at': datetime.datetime(2024, 3, 15, 21, 7, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2000623244, 'issue_id': 2189001784, 'author': 'alxnddr', 'body': 'We need to submit a PR to ECharts and create a local patch to fix this', 'created_at': datetime.datetime(2024, 3, 15, 23, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2014099661, 'issue_id': 2189001784, 'author': 'JesseSDevaney', 'body': 'I attempted making a local patch for this, but I ended up in a rabbit hole of JavaScript class inheritance while trying to figure out where options are getting merged and why the `z` option is not being overwritten when explicitly provided a custom value.\r\n\r\nPerhaps someone else will have better luck here, or I may figure out more about option merging as I complete other issues.\r\n\r\nBut for now, I am moving on from this.', 'created_at': datetime.datetime(2024, 3, 22, 0, 25, 49, tzinfo=datetime.timezone.utc)}]","JesseSDevaney on (2024-03-15 21:07:01 UTC): Attempted the fix for this, but because `markLine` is being used here, it does not respect the z-index given. `markLine` has a fixed z value of 5 ([see ECharts src](https://github.com/apache/echarts/blob/fbee94d5dd3fe8a957524620eb3657145670bd50/src/component/marker/MarkLineModel.ts#L116)). This value is greater than the series `z-index: 2`, so it appears in front of the data points/bars. This fix seems more involved than an on-boarding/easy fix should require.

Relevant Files
- [timeline-events/options.ts](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/timeline-events/option.ts#L52-L103)
- [styles.ts/CHART_STYLE](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/constants/style.ts#L32-L37)
  - See [line #3](https://github.com/metabase/metabase/blob/echarts/frontend/src/metabase/visualizations/echarts/cartesian/constants/style.ts#L3) for the comment talking about `markLine` having a fixed z-index value of 5

---
**Note:** We cannot just bump up the z-indexes relative to one another, because the goal line also uses a `markLine`. If we updated the series and trend lines to fix the timeline events problem, it would introduce a problem for the goal line, which would now be behind the data points/bars.

alxnddr (Assginee) on (2024-03-15 23:25:00 UTC): We need to submit a PR to ECharts and create a local patch to fix this

JesseSDevaney on (2024-03-22 00:25:49 UTC): I attempted making a local patch for this, but I ended up in a rabbit hole of JavaScript class inheritance while trying to figure out where options are getting merged and why the `z` option is not being overwritten when explicitly provided a custom value.

Perhaps someone else will have better luck here, or I may figure out more about option merging as I complete other issues.

But for now, I am moving on from this.

"
2188983488,issue,closed,completed,[dc.js migration] chart error when duplicate series in dimension setting,"question/5321
https://metaboat.slack.com/archives/C06G94JTWBS/p1710340820812469",EmmadUsmani,2024-03-15 16:06:59+00:00,['alxnddr'],2024-03-29 21:03:45+00:00,2024-03-29 21:03:45+00:00,https://github.com/metabase/metabase/issues/40179,"[('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2188982814,issue,closed,completed,Upgrade to React 17,,sloansparger,2024-03-15 16:06:44+00:00,['sloansparger'],2024-03-18 14:11:36+00:00,2024-03-18 14:11:36+00:00,https://github.com/metabase/metabase/issues/40178,[],[],
2188968459,issue,closed,completed,[dc.js migration] legend selects the wrong series in stacked charts,"<img width=""1894"" alt=""Screenshot 2024-03-15 at 8 59 46 AM"" src=""https://github.com/metabase/metabase/assets/37751258/8810ad85-3151-48b2-934c-6e84ad508ccf"">",EmmadUsmani,2024-03-15 16:01:03+00:00,['alxnddr'],2024-03-22 16:50:37+00:00,2024-03-22 16:50:37+00:00,https://github.com/metabase/metabase/issues/40177,"[('Priority:P2', 'Average run of the mill bug'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.'), ('.echarts-regression', 'Issues in the echarts feature branch that were not broken in the previous dc.js implementation')]",[],
2188956992,issue,closed,completed,Filtering Issue on UUID Column in Version 0.49.0,"### Describe the bug

When attempting to apply a filter on a UUID column within a table in our database, the operation consistently fails, and the error message ""Something's gone wrong"" is displayed. This issue appears to specifically affect the filtering functionality on UUID columns.

Actual Behavior:
Upon attempting to filter the UUID column, the system immediately returns an error message ""Something's gone wrong"", and no filtering action is completed. This indicates a malfunction in the filtering capability for UUID columns.

### To Reproduce

1. Go to ""Browse Databases""
2. Click on a Database et select a table with a uuid column
3. Try to filter on ""uuid"" column 
4. See warning logo (an error occured) =< Something's gone wrong

---- 

Navigate to the table containing the UUID column in the database.
Attempt to apply a filter to the UUID column (e.g., filtering for a specific UUID value).
Observe the error message that appears.



### Expected behavior

The filter operation should successfully apply to the UUID column, allowing records that match the filter criteria to be displayed without any error.

### Logs

In logs, we have error ""Erreur dans la recherche des valeurs des champs,java.lang.IllegalArgumentException: UUID string too large,	at java.base/java.util.UUID.fromString(UUID.java:199),	at metabase.driver.postgres$fn__83669.invokeStatic(postgres.clj:363),""

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.75+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""11.22""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-14"",
      ""tag"": ""v0.49.0"",
      ""hash"": ""46c668b""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    }
  }
}
```


### Severity

Block usage when filtering on a UUID column

### Additional context

This issue was not present in the previous version (V0.48.8), indicating a regression introduced in V0.49.0.",jeromedumas-peekin,2024-03-15 15:57:52+00:00,['metamben'],2024-05-31 14:56:31+00:00,2024-05-31 11:45:24+00:00,https://github.com/metabase/metabase/issues/40176,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Processor', ''), ('.Backend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.')]","[{'comment_id': 1999969677, 'issue_id': 2188956992, 'author': 'paoliniluis', 'body': 'What is the actual data type in the db?', 'created_at': datetime.datetime(2024, 3, 15, 15, 59, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999985655, 'issue_id': 2188956992, 'author': 'jeromedumas-peekin', 'body': '""id"" uuid DEFAULT uuid_generate_v4(),', 'created_at': datetime.datetime(2024, 3, 15, 16, 8, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2006397049, 'issue_id': 2188956992, 'author': 'nofalx', 'body': 'Facing the same issue, filtering on UUID is broken\r\n\r\n![image](https://github.com/metabase/metabase/assets/42375159/8997e4f7-0711-4d2f-acad-248fd2c2f076)\r\n\r\nhere is the console log issue\r\n\r\n![image](https://github.com/metabase/metabase/assets/42375159/96a4e307-266c-4112-8aa5-1cd177512c64)\r\n\r\ntroubleshoot logs\r\n\r\n```\r\n\r\n[062d3890-bd99-45ef-9fa4-5306289b765b] 2024-03-19T12:59:04+04:00 ERROR metabase.api.field Error searching field values\r\njava.lang.IllegalArgumentException: Invalid UUID string: %xx%\r\n\tat java.base/java.util.UUID.fromString1(UUID.java:280)\r\n\tat java.base/java.util.UUID.fromString(UUID.java:258)\r\n\tat metabase.driver.postgres$fn__83669.invokeStatic(postgres.clj:363)\r\n\tat metabase.driver.postgres$fn__83669.invoke(postgres.clj:357)\r\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:234)\r\n\tat metabase.driver.sql.query_processor$generate_pattern.invokeStatic(query_processor.clj:1082)\r\n\tat metabase.driver.sql.query_processor$generate_pattern.invoke(query_processor.clj:1074)\r\n\tat metabase.driver.sql.query_processor$fn__65879.invokeStatic(query_processor.clj:1095)\r\n\tat metabase.driver.sql.query_processor$fn__65879.invoke(query_processor.clj:1093)\r\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:234)\r\n\tat metabase.driver.sql.query_processor$fn__65967.invokeStatic(query_processor.clj:1166)\r\n\tat metabase.driver.sql.query_processor$fn__65967.invoke(query_processor.clj:1164)\r\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:244)\r\n\tat metabase.driver.sql.query_processor$apply_top_level_clauses$fn__66073.invoke(query_processor.clj:1405)\r\n\tat clojure.lang.ArraySeq.reduce(ArraySeq.java:119)\r\n\tat clojure.core$transduce.invokeStatic(core.clj:6947)\r\n\tat clojure.core$transduce.invoke(core.clj:6934)\r\n\tat metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1399)\r\n\tat metabase.driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1392)\r\n\tat metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1396)\r\n\tat metabase.driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1392)\r\n\tat metabase.driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1442)\r\n\tat metabase.driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1430)\r\n\tat metabase.driver.sql.query_processor$mbql__GT_honeysql.invokeStatic(query_processor.clj:1462)\r\n\tat metabase.driver.sql.query_processor$mbql__GT_honeysql.invoke(query_processor.clj:1456)\r\n\tat metabase.driver.sql.query_processor$mbql__GT_native.invokeStatic(query_processor.clj:1471)\r\n\tat metabase.driver.sql.query_processor$mbql__GT_native.invoke(query_processor.clj:1467)\r\n\tat metabase.driver.sql$fn__82935.invokeStatic(sql.clj:49)\r\n\tat metabase.driver.sql$fn__82935.invoke(sql.clj:47)\r\n\tat clojure.lang.MultiFn.invoke(MultiFn.java:234)\r\n\tat metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invokeStatic(mbql_to_native.clj:14)\r\n\tat metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invoke(mbql_to_native.clj:9)\r\n\tat metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:21)\r\n\tat metabase.query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)\r\n\tat metabase.query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)\r\n\tat metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)\r\n\tat metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)\r\n\tat metabase.driver$do_with_driver.invokeStatic(driver.clj:97)\r\n\tat metabase.driver$do_with_driver.invoke(driver.clj:92)\r\n\tat metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)\r\n\tat metabase.query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)\r\n\tat metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)\r\n\tat metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)\r\n\tat metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)\r\n\tat metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)\r\n\tat metabase.query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)\r\n\tat metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)\r\n\tat metabase.query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)\r\n\tat metabase.query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)\r\n\tat metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)\r\n\tat metabase.query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)\r\n\tat metabase.query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.core$apply.invokeStatic(core.clj:667)\r\n\tat clojure.core$apply.invoke(core.clj:662)\r\n\tat metabase.query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat metabase.query_processor$process_query.invokeStatic(query_processor.clj:311)\r\n\tat metabase.query_processor$process_query.invoke(query_processor.clj:291)\r\n\tat metabase.query_processor$process_query.invokeStatic(query_processor.clj:299)\r\n\tat metabase.query_processor$process_query.invoke(query_processor.clj:291)\r\n\tat metabase.query_processor$process_query.invokeStatic(query_processor.clj:296)\r\n\tat metabase.query_processor$process_query.invoke(query_processor.clj:291)\r\n\tat metabase.api.field$search_values.invokeStatic(field.clj:418)\r\n\tat metabase.api.field$search_values.invoke(field.clj:390)\r\n\tat metabase.api.field$fn__93510.invokeStatic(field.clj:435)\r\n\tat metabase.api.field$fn__93510.invoke(field.clj:424)\r\n\tat compojure.core$wrap_response$fn__44642.invoke(core.clj:160)\r\n\tat compojure.core$wrap_route_middleware$fn__44626.invoke(core.clj:132)\r\n\tat compojure.core$wrap_route_info$fn__44631.invoke(core.clj:139)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:151)\r\n\tat clojure.lang.Var.invoke(Var.java:393)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)\r\n\tat clojure.lang.Var.invoke(Var.java:393)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)\r\n\tat clojure.lang.Var.invoke(Var.java:393)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)\r\n\tat clojure.lang.Var.invoke(Var.java:393)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)\r\n\tat clojure.lang.Var.invoke(Var.java:393)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654.invoke(core.clj:200)\r\n\tat metabase.server.middleware.auth$enforce_authentication$fn__93651.invoke(auth.clj:17)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654.invoke(core.clj:200)\r\n\tat compojure.core$make_context$handler__44682.invoke(core.clj:290)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:300)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:301)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat metabase.api.routes$fn__101626$fn__101629.invoke(routes.clj:67)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654.invoke(core.clj:200)\r\n\tat clojure.lang.AFn.applyToHelper(AFn.java:160)\r\n\tat clojure.lang.AFn.applyTo(AFn.java:144)\r\n\tat clojure.core$apply.invokeStatic(core.clj:667)\r\n\tat clojure.core$apply.invoke(core.clj:662)\r\n\tat metabase.server.routes$fn__101791$fn__101792.doInvoke(routes.clj:72)\r\n\tat clojure.lang.RestFn.invoke(RestFn.java:436)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654.invoke(core.clj:200)\r\n\tat compojure.core$make_context$handler__44682.invoke(core.clj:290)\r\n\tat compojure.core$make_context$fn__44686.invoke(core.clj:300)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:152)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:152)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:152)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)\r\n\tat metabase.server.routes$fn__101776$fn__101778.invoke(routes.clj:49)\r\n\tat compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)\r\n\tat compojure.core$routes$fn__44654.invoke(core.clj:200)\r\n\tat metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98406.invoke(exceptions.clj:108)\r\n\tat metabase.server.middleware.exceptions$catch_api_exceptions$fn__98403.invoke(exceptions.clj:96)\r\n\tat metabase.server.middleware.log$log_api_call$fn__102059$fn__102060$fn__102061.invoke(log.clj:216)\r\n\tat metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)\r\n\tat metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)\r\n\tat metabase.server.middleware.log$log_api_call$fn__102059$fn__102060.invoke(log.clj:208)\r\n\tat toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)\r\n\tat toucan2.execute$do_with_call_counts.invoke(execute.clj:103)\r\n\tat metabase.server.middleware.log$log_api_call$fn__102059.invoke(log.clj:207)\r\n\tat metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104095.invoke(browser_cookie.clj:40)\r\n\tat metabase.server.middleware.security$add_security_headers$fn__84540.invoke(security.clj:182)\r\n\tat metabase.server.middleware.json$wrap_json_body$fn__45999.invoke(json.clj:67)\r\n\tat metabase.server.middleware.offset_paging$handle_paging$fn__84564.invoke(offset_paging.clj:62)\r\n\tat metabase.server.middleware.json$wrap_streamed_json_response$fn__46017.invoke(json.clj:103)\r\n\tat ring.middleware.keyword_params$wrap_keyword_params$fn__104362.invoke(keyword_params.clj:55)\r\n\tat ring.middleware.params$wrap_params$fn__104381.invoke(params.clj:77)\r\n\tat metabase.server.middleware.misc$maybe_set_site_url$fn__66965.invoke(misc.clj:61)\r\n\tat metabase.server.middleware.session$reset_session_timeout$fn__72380.invoke(session.clj:543)\r\n\tat metabase.server.middleware.session$bind_current_user$fn__72346$fn__72347.invoke(session.clj:438)\r\n\tat metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:417)\r\n\tat metabase.server.middleware.session$do_with_current_user.invoke(session.clj:401)\r\n\tat metabase.server.middleware.session$bind_current_user$fn__72346.invoke(session.clj:437)\r\n\tat metabase.server.middleware.session$wrap_current_user_info$fn__72329.invoke(session.clj:376)\r\n\tat metabase.server.middleware.session$wrap_session_id$fn__72301.invoke(session.clj:255)\r\n\tat metabase.server.middleware.auth$wrap_static_api_key$fn__93659.invoke(auth.clj:30)\r\n\tat ring.middleware.cookies$wrap_cookies$fn__104282.invoke(cookies.clj:194)\r\n\tat metabase.server.middleware.misc$add_content_type$fn__66947.invoke(misc.clj:29)\r\n\tat metabase.server.middleware.misc$disable_streaming_buffering$fn__66973.invoke(misc.clj:78)\r\n\tat ring.middleware.gzip$wrap_gzip$fn__104324.invoke(gzip.clj:86)\r\n\tat metabase.server.middleware.misc$bind_request$fn__66976.invoke(misc.clj:95)\r\n\tat metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104111.invoke(ssl.clj:51)\r\n\tat metabase.server$async_proxy_handler$fn__67387.invoke(server.clj:78)\r\n\tat metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)\r\n\tat org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)\r\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)\r\n\tat org.eclipse.jetty.server.Server.handle(Server.java:563)\r\n\tat org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)\r\n\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)\r\n\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)\r\n\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)\r\n\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)\r\n\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)\r\n\tat org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)\r\n\tat org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)\r\n\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)\r\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)\r\n\tat java.base/java.lang.Thread.run(Thread.java:840)\r\n```', 'created_at': datetime.datetime(2024, 3, 19, 9, 1, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2006561111, 'issue_id': 2188956992, 'author': 'robinshin', 'body': 'Same issue here, here is the troubleshooting log I get:\r\n\r\n```\r\njava.lang.IllegalArgumentException: UUID string too large\r\n\r\nat metabase.driver.postgres$fn__83669.invokeStatic ( metabase/driver/postgres.clj:363 )\r\nat metabase.driver.postgres$fn__83669.invoke ( metabase/driver/postgres.clj:357 )\r\nat clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:234 )\r\nat metabase.driver.sql.query_processor$generate_pattern.invokeStatic ( metabase/driver.sql/query_processor.clj:1082 )\r\nat metabase.driver.sql.query_processor$generate_pattern.invoke ( metabase/driver.sql/query_processor.clj:1074 )\r\nat metabase.driver.sql.query_processor$fn__65879.invokeStatic ( metabase/driver.sql/query_processor.clj:1095 )\r\nat metabase.driver.sql.query_processor$fn__65879.invoke ( metabase/driver.sql/query_processor.clj:1093 )\r\nat clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:234 )\r\nat metabase.driver.sql.query_processor$fn__65967.invokeStatic ( metabase/driver.sql/query_processor.clj:1166 )\r\nat metabase.driver.sql.query_processor$fn__65967.invoke ( metabase/driver.sql/query_processor.clj:1164 )\r\nat clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:244 )\r\nat metabase.driver.sql.query_processor$apply_top_level_clauses$fn__66073.invoke ( metabase/driver.sql/query_processor.clj:1405 )\r\nat clojure.lang.ArraySeq.reduce ( clojure/lang/ArraySeq.java:119 )\r\nat clojure.core$transduce.invokeStatic ( clojure/core.clj:6947 )\r\nat clojure.core$transduce.invoke ( clojure/core.clj:6934 )\r\nat metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic ( metabase/driver.sql/query_processor.clj:1399 )\r\nat metabase.driver.sql.query_processor$apply_top_level_clauses.invoke ( metabase/driver.sql/query_processor.clj:1392 )\r\nat metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic ( metabase/driver.sql/query_processor.clj:1396 )\r\nat metabase.driver.sql.query_processor$apply_top_level_clauses.invoke ( metabase/driver.sql/query_processor.clj:1392 )\r\nat metabase.driver.sql.query_processor$apply_clauses.invokeStatic ( metabase/driver.sql/query_processor.clj:1442 )\r\nat metabase.driver.sql.query_processor$apply_clauses.invoke ( metabase/driver.sql/query_processor.clj:1430 )\r\nat metabase.driver.sql.query_processor$mbql__GT_honeysql.invokeStatic ( metabase/driver.sql/query_processor.clj:1462 )\r\nat metabase.driver.sql.query_processor$mbql__GT_honeysql.invoke ( metabase/driver.sql/query_processor.clj:1456 )\r\nat metabase.driver.sql.query_processor$mbql__GT_native.invokeStatic ( metabase/driver.sql/query_processor.clj:1471 )\r\nat metabase.driver.sql.query_processor$mbql__GT_native.invoke ( metabase/driver.sql/query_processor.clj:1467 )\r\nat metabase.driver.sql$fn__82935.invokeStatic ( metabase/driver/sql.clj:49 )\r\nat metabase.driver.sql$fn__82935.invoke ( metabase/driver/sql.clj:47 )\r\nat clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:234 )\r\nat metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invokeStatic ( metabase/query_processor.middleware/mbql_to_native.clj:14 )\r\nat metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invoke ( metabase/query_processor.middleware/mbql_to_native.clj:9 )\r\nat metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke ( metabase/query_processor.middleware/mbql_to_native.clj:21 )\r\nat metabase.query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke ( metabase/query_processor.clj:262 )\r\nat metabase.query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke ( metabase/query_processor.clj:259 )\r\nat metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke ( metabase/query_processor.middleware/fetch_source_query.clj:303 )\r\nat metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke ( metabase/query_processor.middleware/resolve_database_and_driver.clj:77 )\r\nat metabase.driver$do_with_driver.invokeStatic ( metabase/driver.clj:97 )\r\nat metabase.driver$do_with_driver.invoke ( metabase/driver.clj:92 )\r\nat metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke ( metabase/query_processor.middleware/resolve_database_and_driver.clj:76 )\r\nat metabase.query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke ( metabase/query_processor.middleware/store.clj:14 )\r\nat metabase.query_processor.store$do_with_metadata_provider.invokeStatic ( metabase/query_processor/store.clj:169 )\r\nat metabase.query_processor.store$do_with_metadata_provider.invoke ( metabase/query_processor/store.clj:150 )\r\nat metabase.query_processor.store$do_with_metadata_provider.invokeStatic ( metabase/query_processor/store.clj:158 )\r\nat metabase.query_processor.store$do_with_metadata_provider.invoke ( metabase/query_processor/store.clj:150 )\r\nat metabase.query_processor.middleware.store$initialize_store$fn__67050.invoke ( metabase/query_processor.middleware/store.clj:13 )\r\nat metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke ( metabase/query_processor.middleware/resolve_database_and_driver.clj:60 )\r\nat metabase.query_processor.middleware.normalize_query$normalize$fn__72174.invoke ( metabase/query_processor.middleware/normalize_query.clj:38 )\r\nat metabase.query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke ( metabase/query_processor.middleware/enterprise.clj:96 )\r\nat metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke ( metabase/query_processor.middleware/enterprise.clj:103 )\r\nat metabase.query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke ( metabase/query_processor/reducible.clj:126 )\r\nat metabase.query_processor.reducible$async_qp$qp_STAR___62605.invoke ( metabase/query_processor/reducible.clj:132 )\r\nat clojure.lang.AFn.applyToHelper ( clojure/lang/AFn.java:160 )\r\nat clojure.lang.AFn.applyTo ( clojure/lang/AFn.java:144 )\r\nat clojure.core$apply.invokeStatic ( clojure/core.clj:667 )\r\nat clojure.core$apply.invoke ( clojure/core.clj:662 )\r\nat metabase.query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke ( metabase/query_processor/reducible.clj:153 )\r\nat clojure.lang.RestFn.invoke ( clojure/lang/RestFn.java:436 )\r\nat metabase.query_processor$process_query.invokeStatic ( metabase/query_processor.clj:311 )\r\nat metabase.query_processor$process_query.invoke ( metabase/query_processor.clj:291 )\r\nat metabase.query_processor$process_query.invokeStatic ( metabase/query_processor.clj:299 )\r\nat metabase.query_processor$process_query.invoke ( metabase/query_processor.clj:291 )\r\nat metabase.query_processor$process_query.invokeStatic ( metabase/query_processor.clj:296 )\r\nat metabase.query_processor$process_query.invoke ( metabase/query_processor.clj:291 )\r\nat metabase.api.field$search_values.invokeStatic ( metabase/api/field.clj:418 )\r\nat metabase.api.field$search_values.invoke ( metabase/api/field.clj:390 )\r\nat metabase.api.field$fn__93510.invokeStatic ( metabase/api/field.clj:435 )\r\nat metabase.api.field$fn__93510.invoke ( metabase/api/field.clj:424 )\r\nat compojure.core$wrap_response$fn__44642.invoke ( compojure/core.clj:160 )\r\nat compojure.core$wrap_route_middleware$fn__44626.invoke ( compojure/core.clj:132 )\r\nat compojure.core$wrap_route_info$fn__44631.invoke ( compojure/core.clj:139 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:151 )\r\nat clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )\r\nat clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )\r\nat clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )\r\nat clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )\r\nat clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )\r\nat metabase.server.middleware.auth$enforce_authentication$fn__93651.invoke ( metabase/server.middleware/auth.clj:17 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )\r\nat compojure.core$make_context$handler__44682.invoke ( compojure/core.clj:290 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:300 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat metabase.api.routes$fn__101626$fn__101629.invoke ( metabase/api/routes.clj:67 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )\r\nat clojure.lang.AFn.applyToHelper ( clojure/lang/AFn.java:160 )\r\nat clojure.lang.AFn.applyTo ( clojure/lang/AFn.java:144 )\r\nat clojure.core$apply.invokeStatic ( clojure/core.clj:667 )\r\nat clojure.core$apply.invoke ( clojure/core.clj:662 )\r\nat metabase.server.routes$fn__101791$fn__101792.doInvoke ( metabase/server/routes.clj:72 )\r\nat clojure.lang.RestFn.invoke ( clojure/lang/RestFn.java:436 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )\r\nat compojure.core$make_context$handler__44682.invoke ( compojure/core.clj:290 )\r\nat compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:300 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:152 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:152 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:152 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )\r\nat metabase.server.routes$fn__101776$fn__101778.invoke ( metabase/server/routes.clj:49 )\r\nat compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )\r\nat compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )\r\nat metabase.server.middleware.exceptions$catch_api_exceptions$fn__98403.invoke ( metabase/server.middleware/exceptions.clj:96 )\r\nat metabase.server.middleware.log$log_api_call$fn__102059$fn__102060$fn__102061.invoke ( metabase/server.middleware/log.clj:216 )\r\nat metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic ( metabase/driver.sql_jdbc.execute/diagnostic.clj:18 )\r\nat metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke ( metabase/driver.sql_jdbc.execute/diagnostic.clj:12 )\r\nat metabase.server.middleware.log$log_api_call$fn__102059$fn__102060.invoke ( metabase/server.middleware/log.clj:208 )\r\nat toucan2.execute$do_with_call_counts.invokeStatic ( toucan2/execute.clj:112 )\r\nat toucan2.execute$do_with_call_counts.invoke ( toucan2/execute.clj:103 )\r\nat metabase.server.middleware.log$log_api_call$fn__102059.invoke ( metabase/server.middleware/log.clj:207 )\r\nat metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104095.invoke ( metabase/server.middleware/browser_cookie.clj:40 )\r\nat metabase.server.middleware.security$add_security_headers$fn__84540.invoke ( metabase/server.middleware/security.clj:182 )\r\nat metabase.server.middleware.json$wrap_json_body$fn__45999.invoke ( metabase/server.middleware/json.clj:67 )\r\nat metabase.server.middleware.offset_paging$handle_paging$fn__84564.invoke ( metabase/server.middleware/offset_paging.clj:62 )\r\nat metabase.server.middleware.json$wrap_streamed_json_response$fn__46017.invoke ( metabase/server.middleware/json.clj:103 )\r\nat ring.middleware.keyword_params$wrap_keyword_params$fn__104362.invoke ( ring/middleware/keyword_params.clj:55 )\r\nat ring.middleware.params$wrap_params$fn__104381.invoke ( ring/middleware/params.clj:77 )\r\nat metabase.server.middleware.misc$maybe_set_site_url$fn__66965.invoke ( metabase/server.middleware/misc.clj:61 )\r\nat metabase.server.middleware.session$reset_session_timeout$fn__72380.invoke ( metabase/server.middleware/session.clj:543 )\r\nat metabase.server.middleware.session$bind_current_user$fn__72346$fn__72347.invoke ( metabase/server.middleware/session.clj:438 )\r\nat metabase.server.middleware.session$do_with_current_user.invokeStatic ( metabase/server.middleware/session.clj:417 )\r\nat metabase.server.middleware.session$do_with_current_user.invoke ( metabase/server.middleware/session.clj:401 )\r\nat metabase.server.middleware.session$bind_current_user$fn__72346.invoke ( metabase/server.middleware/session.clj:437 )\r\nat metabase.server.middleware.session$wrap_current_user_info$fn__72329.invoke ( metabase/server.middleware/session.clj:376 )\r\nat metabase.server.middleware.session$wrap_session_id$fn__72301.invoke ( metabase/server.middleware/session.clj:255 )\r\nat metabase.server.middleware.auth$wrap_static_api_key$fn__93659.invoke ( metabase/server.middleware/auth.clj:30 )\r\nat ring.middleware.cookies$wrap_cookies$fn__104282.invoke ( ring/middleware/cookies.clj:194 )\r\nat metabase.server.middleware.misc$add_content_type$fn__66947.invoke ( metabase/server.middleware/misc.clj:29 )\r\nat metabase.server.middleware.misc$disable_streaming_buffering$fn__66973.invoke ( metabase/server.middleware/misc.clj:78 )\r\nat ring.middleware.gzip$wrap_gzip$fn__104324.invoke ( ring/middleware/gzip.clj:86 )\r\nat metabase.server.middleware.misc$bind_request$fn__66976.invoke ( metabase/server.middleware/misc.clj:95 )\r\nat metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104111.invoke ( metabase/server.middleware/ssl.clj:51 )\r\nat metabase.server$async_proxy_handler$fn__67387.invoke ( metabase/server.clj:78 )\r\nat metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle\r\n```\r\n\r\nWith a uuid field of type `type/UUID`\r\n<img width=""428"" alt=""Capture d‚ÄôeÃÅcran 2024-03-19 aÃÄ 10 49 17"" src=""https://github.com/metabase/metabase/assets/17989553/1c2b6c3c-16fb-4d39-95d5-6ce2f239994f"">', 'created_at': datetime.datetime(2024, 3, 19, 9, 48, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2008248929, 'issue_id': 2188956992, 'author': 'damienpuig', 'body': 'Hi - We have this exact same issue 0.49.0 - Can it be prioritised?\r\nThanks a lot', 'created_at': datetime.datetime(2024, 3, 19, 22, 16, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2010286663, 'issue_id': 2188956992, 'author': 'smithcoin', 'body': 'I too am getting the same issue after upgrading to v49:\r\n\r\n```\r\nMar 20 18:04:35 metabase metabase[2317]: java.lang.IllegalArgumentException: UUID string too large\r\nMar 20 18:04:35 metabase metabase[2317]: #011at java.base/java.util.UUID.fromString(UUID.java:199)\r\nMar 20 18:04:35 metabase metabase[2317]: #011at metabase.driver.postgres$fn__83669.invokeStatic(postgres.clj:363)\r\nMar 20 18:04:35 metabase metabase[2317]: #011at metabase.driver.postgres$fn__83669.invoke(postgres.clj:357)\r\n```\r\n\r\nThis comes from this SQL:\r\n\r\n```\r\nSELECT\r\n  ""public"".""transactions"".""uuid"",\r\nFROM\r\n  ""public"".""transactions""\r\n\r\nLEFT JOIN ""public"".""accounts"" AS ""Account"" ON ""public"".""transactions"".""account_id"" = ""Account"".""id""\r\nWHERE\r\n  (\r\n    ""Account"".""hash"" = \'360d00d2-2bc7-4a9e-956e-09d4f955643e\' :: uuid\r\n  )\r\n\r\nGROUP BY\r\n  ""public"".""transactions"".""uuid"",\r\n  ```', 'created_at': datetime.datetime(2024, 3, 20, 18, 8, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2011903285, 'issue_id': 2188956992, 'author': 'nofalx', 'body': '@paoliniluis\r\n\r\nCan we please treat this as high priority item? For many people they use uuid as their primay id.\r\n\r\nI test with v0.49.1 and the issue is still there. Im not able to downgrade back to 0.48 for some reason (cause major version?). Our ability to explore the data is stopped right now under your mercy.', 'created_at': datetime.datetime(2024, 3, 21, 10, 44, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2012962291, 'issue_id': 2188956992, 'author': 'MBM-2024', 'body': 'Hi - We have this exact same issue 0.49.0 - Can it be prioritized?\r\nThanks a lot', 'created_at': datetime.datetime(2024, 3, 21, 16, 45, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2017964758, 'issue_id': 2188956992, 'author': 'damienpuig', 'body': 'Hi - we still cannot filter UUIDs with 49.1 and cannot bring back .48 (major version downgrade does not work)\r\n\r\nThanks again for prioritising this item', 'created_at': datetime.datetime(2024, 3, 25, 13, 4, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2018018173, 'issue_id': 2188956992, 'author': 'jeromedumas-peekin', 'body': 'Following the update to version 49.1, we are still encountering the previously reported issue. Could we prioritize its resolution?', 'created_at': datetime.datetime(2024, 3, 25, 13, 32, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024495042, 'issue_id': 2188956992, 'author': 'hnb2', 'body': 'Hi guys, there is a temporary fix which can be applied through the Metabase Admin. Go to ""Table Metadata"", select your table and field, then change ""Filtering on this field"" from ""Search Box"" to ""Plain input box"".:\r\n![2024-03-27_15-51_1](https://github.com/metabase/metabase/assets/3678416/34bcfed8-e7da-438e-aa1b-4eb5e97e2989)\r\n\r\nObviously it won\'t do a like search anymore, but you will be able to enter a single ID and your editor won\'t break - which is what we do 99% of the time with UUIDs anyway.\r\n\r\nHope this helps a bit while we get a fix.', 'created_at': datetime.datetime(2024, 3, 28, 6, 31, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024520333, 'issue_id': 2188956992, 'author': 'wowi42', 'body': ""To enhance efficiency and automation of the process outlined by @hnb2 , the following SQL command is crafted for direct execution in your Metabase database:\r\n\r\n```sql\r\nUPDATE metabase_field \r\nSET has_field_values = 'none' \r\nWHERE has_field_values IS NULL \r\nAND effective_type = 'type/UUID' \r\nAND semantic_type = 'type/PK';\r\n```\r\n\r\nThis approach has been proven effective in our operational context."", 'created_at': datetime.datetime(2024, 3, 28, 6, 51, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2027071440, 'issue_id': 2188956992, 'author': 'damienpuig', 'body': 'Thanks @hnb2 But we need the actual fix as we have tons of databases connected, and altering the metadata for all of them is not a viable options for us', 'created_at': datetime.datetime(2024, 3, 29, 10, 55, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2059271297, 'issue_id': 2188956992, 'author': 'kevbarns', 'body': ""Hello, following the update to 0.49.5, I still have the issue, clicking on the filter option from a PK column do nothing, search box doesn't show up"", 'created_at': datetime.datetime(2024, 4, 16, 14, 44, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2059958593, 'issue_id': 2188956992, 'author': 'smithcoin', 'body': ""This issue shouldn't be closed as it still exists in both the v48 and v49 releases."", 'created_at': datetime.datetime(2024, 4, 16, 21, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2126490915, 'issue_id': 2188956992, 'author': 'crisptrutski', 'body': 'Removed the milestone since this is still an issue. Have not made it a blocker for the next release (happening today)', 'created_at': datetime.datetime(2024, 5, 23, 8, 8, 30, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-15 15:59:47 UTC): What is the actual data type in the db?

jeromedumas-peekin (Issue Creator) on (2024-03-15 16:08:39 UTC): ""id"" uuid DEFAULT uuid_generate_v4(),

nofalx on (2024-03-19 09:01:58 UTC): Facing the same issue, filtering on UUID is broken

![image](https://github.com/metabase/metabase/assets/42375159/8997e4f7-0711-4d2f-acad-248fd2c2f076)

here is the console log issue

![image](https://github.com/metabase/metabase/assets/42375159/96a4e307-266c-4112-8aa5-1cd177512c64)

troubleshoot logs

```

[062d3890-bd99-45ef-9fa4-5306289b765b] 2024-03-19T12:59:04+04:00 ERROR metabase.api.field Error searching field values
java.lang.IllegalArgumentException: Invalid UUID string: %xx%
	at java.base/java.util.UUID.fromString1(UUID.java:280)
	at java.base/java.util.UUID.fromString(UUID.java:258)
	at metabase.driver.postgres$fn__83669.invokeStatic(postgres.clj:363)
	at metabase.driver.postgres$fn__83669.invoke(postgres.clj:357)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.sql.query_processor$generate_pattern.invokeStatic(query_processor.clj:1082)
	at metabase.driver.sql.query_processor$generate_pattern.invoke(query_processor.clj:1074)
	at metabase.driver.sql.query_processor$fn__65879.invokeStatic(query_processor.clj:1095)
	at metabase.driver.sql.query_processor$fn__65879.invoke(query_processor.clj:1093)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.driver.sql.query_processor$fn__65967.invokeStatic(query_processor.clj:1166)
	at metabase.driver.sql.query_processor$fn__65967.invoke(query_processor.clj:1164)
	at clojure.lang.MultiFn.invoke(MultiFn.java:244)
	at metabase.driver.sql.query_processor$apply_top_level_clauses$fn__66073.invoke(query_processor.clj:1405)
	at clojure.lang.ArraySeq.reduce(ArraySeq.java:119)
	at clojure.core$transduce.invokeStatic(core.clj:6947)
	at clojure.core$transduce.invoke(core.clj:6934)
	at metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1399)
	at metabase.driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1392)
	at metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic(query_processor.clj:1396)
	at metabase.driver.sql.query_processor$apply_top_level_clauses.invoke(query_processor.clj:1392)
	at metabase.driver.sql.query_processor$apply_clauses.invokeStatic(query_processor.clj:1442)
	at metabase.driver.sql.query_processor$apply_clauses.invoke(query_processor.clj:1430)
	at metabase.driver.sql.query_processor$mbql__GT_honeysql.invokeStatic(query_processor.clj:1462)
	at metabase.driver.sql.query_processor$mbql__GT_honeysql.invoke(query_processor.clj:1456)
	at metabase.driver.sql.query_processor$mbql__GT_native.invokeStatic(query_processor.clj:1471)
	at metabase.driver.sql.query_processor$mbql__GT_native.invoke(query_processor.clj:1467)
	at metabase.driver.sql$fn__82935.invokeStatic(sql.clj:49)
	at metabase.driver.sql$fn__82935.invoke(sql.clj:47)
	at clojure.lang.MultiFn.invoke(MultiFn.java:234)
	at metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invokeStatic(mbql_to_native.clj:14)
	at metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invoke(mbql_to_native.clj:9)
	at metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke(mbql_to_native.clj:21)
	at metabase.query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke(query_processor.clj:262)
	at metabase.query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke(query_processor.clj:259)
	at metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke(fetch_source_query.clj:303)
	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke(resolve_database_and_driver.clj:77)
	at metabase.driver$do_with_driver.invokeStatic(driver.clj:97)
	at metabase.driver$do_with_driver.invoke(driver.clj:92)
	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke(resolve_database_and_driver.clj:76)
	at metabase.query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke(store.clj:14)
	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:169)
	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
	at metabase.query_processor.store$do_with_metadata_provider.invokeStatic(store.clj:158)
	at metabase.query_processor.store$do_with_metadata_provider.invoke(store.clj:150)
	at metabase.query_processor.middleware.store$initialize_store$fn__67050.invoke(store.clj:13)
	at metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke(resolve_database_and_driver.clj:60)
	at metabase.query_processor.middleware.normalize_query$normalize$fn__72174.invoke(normalize_query.clj:38)
	at metabase.query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke(enterprise.clj:96)
	at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke(enterprise.clj:103)
	at metabase.query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke(reducible.clj:126)
	at metabase.query_processor.reducible$async_qp$qp_STAR___62605.invoke(reducible.clj:132)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke(reducible.clj:153)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at metabase.query_processor$process_query.invokeStatic(query_processor.clj:311)
	at metabase.query_processor$process_query.invoke(query_processor.clj:291)
	at metabase.query_processor$process_query.invokeStatic(query_processor.clj:299)
	at metabase.query_processor$process_query.invoke(query_processor.clj:291)
	at metabase.query_processor$process_query.invokeStatic(query_processor.clj:296)
	at metabase.query_processor$process_query.invoke(query_processor.clj:291)
	at metabase.api.field$search_values.invokeStatic(field.clj:418)
	at metabase.api.field$search_values.invoke(field.clj:390)
	at metabase.api.field$fn__93510.invokeStatic(field.clj:435)
	at metabase.api.field$fn__93510.invoke(field.clj:424)
	at compojure.core$wrap_response$fn__44642.invoke(core.clj:160)
	at compojure.core$wrap_route_middleware$fn__44626.invoke(core.clj:132)
	at compojure.core$wrap_route_info$fn__44631.invoke(core.clj:139)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:151)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:153)
	at clojure.lang.Var.invoke(Var.java:393)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654.invoke(core.clj:200)
	at metabase.server.middleware.auth$enforce_authentication$fn__93651.invoke(auth.clj:17)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654.invoke(core.clj:200)
	at compojure.core$make_context$handler__44682.invoke(core.clj:290)
	at compojure.core$make_context$fn__44686.invoke(core.clj:300)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$make_context$fn__44686.invoke(core.clj:301)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at metabase.api.routes$fn__101626$fn__101629.invoke(routes.clj:67)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654.invoke(core.clj:200)
	at clojure.lang.AFn.applyToHelper(AFn.java:160)
	at clojure.lang.AFn.applyTo(AFn.java:144)
	at clojure.core$apply.invokeStatic(core.clj:667)
	at clojure.core$apply.invoke(core.clj:662)
	at metabase.server.routes$fn__101791$fn__101792.doInvoke(routes.clj:72)
	at clojure.lang.RestFn.invoke(RestFn.java:436)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654.invoke(core.clj:200)
	at compojure.core$make_context$handler__44682.invoke(core.clj:290)
	at compojure.core$make_context$fn__44686.invoke(core.clj:300)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:152)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:152)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at compojure.core$wrap_route_matches$fn__44635.invoke(core.clj:152)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke(core.clj:197)
	at metabase.server.routes$fn__101776$fn__101778.invoke(routes.clj:49)
	at compojure.core$routes$fn__44654$f__44655.invoke(core.clj:198)
	at compojure.core$routes$fn__44654.invoke(core.clj:200)
	at metabase.server.middleware.exceptions$catch_uncaught_exceptions$fn__98406.invoke(exceptions.clj:108)
	at metabase.server.middleware.exceptions$catch_api_exceptions$fn__98403.invoke(exceptions.clj:96)
	at metabase.server.middleware.log$log_api_call$fn__102059$fn__102060$fn__102061.invoke(log.clj:216)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic(diagnostic.clj:18)
	at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke(diagnostic.clj:12)
	at metabase.server.middleware.log$log_api_call$fn__102059$fn__102060.invoke(log.clj:208)
	at toucan2.execute$do_with_call_counts.invokeStatic(execute.clj:112)
	at toucan2.execute$do_with_call_counts.invoke(execute.clj:103)
	at metabase.server.middleware.log$log_api_call$fn__102059.invoke(log.clj:207)
	at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104095.invoke(browser_cookie.clj:40)
	at metabase.server.middleware.security$add_security_headers$fn__84540.invoke(security.clj:182)
	at metabase.server.middleware.json$wrap_json_body$fn__45999.invoke(json.clj:67)
	at metabase.server.middleware.offset_paging$handle_paging$fn__84564.invoke(offset_paging.clj:62)
	at metabase.server.middleware.json$wrap_streamed_json_response$fn__46017.invoke(json.clj:103)
	at ring.middleware.keyword_params$wrap_keyword_params$fn__104362.invoke(keyword_params.clj:55)
	at ring.middleware.params$wrap_params$fn__104381.invoke(params.clj:77)
	at metabase.server.middleware.misc$maybe_set_site_url$fn__66965.invoke(misc.clj:61)
	at metabase.server.middleware.session$reset_session_timeout$fn__72380.invoke(session.clj:543)
	at metabase.server.middleware.session$bind_current_user$fn__72346$fn__72347.invoke(session.clj:438)
	at metabase.server.middleware.session$do_with_current_user.invokeStatic(session.clj:417)
	at metabase.server.middleware.session$do_with_current_user.invoke(session.clj:401)
	at metabase.server.middleware.session$bind_current_user$fn__72346.invoke(session.clj:437)
	at metabase.server.middleware.session$wrap_current_user_info$fn__72329.invoke(session.clj:376)
	at metabase.server.middleware.session$wrap_session_id$fn__72301.invoke(session.clj:255)
	at metabase.server.middleware.auth$wrap_static_api_key$fn__93659.invoke(auth.clj:30)
	at ring.middleware.cookies$wrap_cookies$fn__104282.invoke(cookies.clj:194)
	at metabase.server.middleware.misc$add_content_type$fn__66947.invoke(misc.clj:29)
	at metabase.server.middleware.misc$disable_streaming_buffering$fn__66973.invoke(misc.clj:78)
	at ring.middleware.gzip$wrap_gzip$fn__104324.invoke(gzip.clj:86)
	at metabase.server.middleware.misc$bind_request$fn__66976.invoke(misc.clj:95)
	at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104111.invoke(ssl.clj:51)
	at metabase.server$async_proxy_handler$fn__67387.invoke(server.clj:78)
	at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle(Unknown Source)
	at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:173)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:122)
	at org.eclipse.jetty.server.Server.handle(Server.java:563)
	at org.eclipse.jetty.server.HttpChannel$RequestDispatchable.dispatch(HttpChannel.java:1598)
	at org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:753)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:501)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:287)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:314)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:100)
	at org.eclipse.jetty.io.SelectableChannelEndPoint$1.run(SelectableChannelEndPoint.java:53)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.runTask(AdaptiveExecutionStrategy.java:421)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.consumeTask(AdaptiveExecutionStrategy.java:390)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.tryProduce(AdaptiveExecutionStrategy.java:277)
	at org.eclipse.jetty.util.thread.strategy.AdaptiveExecutionStrategy.run(AdaptiveExecutionStrategy.java:199)
	at org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:411)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:969)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.doRunJob(QueuedThreadPool.java:1194)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1149)
	at java.base/java.lang.Thread.run(Thread.java:840)
```

robinshin on (2024-03-19 09:48:28 UTC): Same issue here, here is the troubleshooting log I get:

```
java.lang.IllegalArgumentException: UUID string too large

at metabase.driver.postgres$fn__83669.invokeStatic ( metabase/driver/postgres.clj:363 )
at metabase.driver.postgres$fn__83669.invoke ( metabase/driver/postgres.clj:357 )
at clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:234 )
at metabase.driver.sql.query_processor$generate_pattern.invokeStatic ( metabase/driver.sql/query_processor.clj:1082 )
at metabase.driver.sql.query_processor$generate_pattern.invoke ( metabase/driver.sql/query_processor.clj:1074 )
at metabase.driver.sql.query_processor$fn__65879.invokeStatic ( metabase/driver.sql/query_processor.clj:1095 )
at metabase.driver.sql.query_processor$fn__65879.invoke ( metabase/driver.sql/query_processor.clj:1093 )
at clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:234 )
at metabase.driver.sql.query_processor$fn__65967.invokeStatic ( metabase/driver.sql/query_processor.clj:1166 )
at metabase.driver.sql.query_processor$fn__65967.invoke ( metabase/driver.sql/query_processor.clj:1164 )
at clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:244 )
at metabase.driver.sql.query_processor$apply_top_level_clauses$fn__66073.invoke ( metabase/driver.sql/query_processor.clj:1405 )
at clojure.lang.ArraySeq.reduce ( clojure/lang/ArraySeq.java:119 )
at clojure.core$transduce.invokeStatic ( clojure/core.clj:6947 )
at clojure.core$transduce.invoke ( clojure/core.clj:6934 )
at metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic ( metabase/driver.sql/query_processor.clj:1399 )
at metabase.driver.sql.query_processor$apply_top_level_clauses.invoke ( metabase/driver.sql/query_processor.clj:1392 )
at metabase.driver.sql.query_processor$apply_top_level_clauses.invokeStatic ( metabase/driver.sql/query_processor.clj:1396 )
at metabase.driver.sql.query_processor$apply_top_level_clauses.invoke ( metabase/driver.sql/query_processor.clj:1392 )
at metabase.driver.sql.query_processor$apply_clauses.invokeStatic ( metabase/driver.sql/query_processor.clj:1442 )
at metabase.driver.sql.query_processor$apply_clauses.invoke ( metabase/driver.sql/query_processor.clj:1430 )
at metabase.driver.sql.query_processor$mbql__GT_honeysql.invokeStatic ( metabase/driver.sql/query_processor.clj:1462 )
at metabase.driver.sql.query_processor$mbql__GT_honeysql.invoke ( metabase/driver.sql/query_processor.clj:1456 )
at metabase.driver.sql.query_processor$mbql__GT_native.invokeStatic ( metabase/driver.sql/query_processor.clj:1471 )
at metabase.driver.sql.query_processor$mbql__GT_native.invoke ( metabase/driver.sql/query_processor.clj:1467 )
at metabase.driver.sql$fn__82935.invokeStatic ( metabase/driver/sql.clj:49 )
at metabase.driver.sql$fn__82935.invoke ( metabase/driver/sql.clj:47 )
at clojure.lang.MultiFn.invoke ( clojure/lang/MultiFn.java:234 )
at metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invokeStatic ( metabase/query_processor.middleware/mbql_to_native.clj:14 )
at metabase.query_processor.middleware.mbql_to_native$query__GT_native_form.invoke ( metabase/query_processor.middleware/mbql_to_native.clj:9 )
at metabase.query_processor.middleware.mbql_to_native$mbql__GT_native$fn__71224.invoke ( metabase/query_processor.middleware/mbql_to_native.clj:21 )
at metabase.query_processor$fn__73106$combined_post_process__73111$combined_post_process_STAR___73112.invoke ( metabase/query_processor.clj:262 )
at metabase.query_processor$fn__73106$combined_pre_process__73107$combined_pre_process_STAR___73108.invoke ( metabase/query_processor.clj:259 )
at metabase.query_processor.middleware.fetch_source_query$resolve_card_id_source_tables$fn__66444.invoke ( metabase/query_processor.middleware/fetch_source_query.clj:303 )
at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872$fn__71876.invoke ( metabase/query_processor.middleware/resolve_database_and_driver.clj:77 )
at metabase.driver$do_with_driver.invokeStatic ( metabase/driver.clj:97 )
at metabase.driver$do_with_driver.invoke ( metabase/driver.clj:92 )
at metabase.query_processor.middleware.resolve_database_and_driver$resolve_driver_and_database_local_values$fn__71872.invoke ( metabase/query_processor.middleware/resolve_database_and_driver.clj:76 )
at metabase.query_processor.middleware.store$initialize_store$fn__67050$fn__67051.invoke ( metabase/query_processor.middleware/store.clj:14 )
at metabase.query_processor.store$do_with_metadata_provider.invokeStatic ( metabase/query_processor/store.clj:169 )
at metabase.query_processor.store$do_with_metadata_provider.invoke ( metabase/query_processor/store.clj:150 )
at metabase.query_processor.store$do_with_metadata_provider.invokeStatic ( metabase/query_processor/store.clj:158 )
at metabase.query_processor.store$do_with_metadata_provider.invoke ( metabase/query_processor/store.clj:150 )
at metabase.query_processor.middleware.store$initialize_store$fn__67050.invoke ( metabase/query_processor.middleware/store.clj:13 )
at metabase.query_processor.middleware.resolve_database_and_driver$resolve_database$fn__71869.invoke ( metabase/query_processor.middleware/resolve_database_and_driver.clj:60 )
at metabase.query_processor.middleware.normalize_query$normalize$fn__72174.invoke ( metabase/query_processor.middleware/normalize_query.clj:38 )
at metabase.query_processor.middleware.enterprise$fn__71809$handle_audit_app_internal_queries__71810$fn__71812.invoke ( metabase/query_processor.middleware/enterprise.clj:96 )
at metabase.query_processor.middleware.enterprise$handle_audit_app_internal_queries_middleware$fn__71820.invoke ( metabase/query_processor.middleware/enterprise.clj:103 )
at metabase.query_processor.reducible$async_qp$qp_STAR___62605$thunk__62607.invoke ( metabase/query_processor/reducible.clj:126 )
at metabase.query_processor.reducible$async_qp$qp_STAR___62605.invoke ( metabase/query_processor/reducible.clj:132 )
at clojure.lang.AFn.applyToHelper ( clojure/lang/AFn.java:160 )
at clojure.lang.AFn.applyTo ( clojure/lang/AFn.java:144 )
at clojure.core$apply.invokeStatic ( clojure/core.clj:667 )
at clojure.core$apply.invoke ( clojure/core.clj:662 )
at metabase.query_processor.reducible$sync_qp$qp_STAR___62617.doInvoke ( metabase/query_processor/reducible.clj:153 )
at clojure.lang.RestFn.invoke ( clojure/lang/RestFn.java:436 )
at metabase.query_processor$process_query.invokeStatic ( metabase/query_processor.clj:311 )
at metabase.query_processor$process_query.invoke ( metabase/query_processor.clj:291 )
at metabase.query_processor$process_query.invokeStatic ( metabase/query_processor.clj:299 )
at metabase.query_processor$process_query.invoke ( metabase/query_processor.clj:291 )
at metabase.query_processor$process_query.invokeStatic ( metabase/query_processor.clj:296 )
at metabase.query_processor$process_query.invoke ( metabase/query_processor.clj:291 )
at metabase.api.field$search_values.invokeStatic ( metabase/api/field.clj:418 )
at metabase.api.field$search_values.invoke ( metabase/api/field.clj:390 )
at metabase.api.field$fn__93510.invokeStatic ( metabase/api/field.clj:435 )
at metabase.api.field$fn__93510.invoke ( metabase/api/field.clj:424 )
at compojure.core$wrap_response$fn__44642.invoke ( compojure/core.clj:160 )
at compojure.core$wrap_route_middleware$fn__44626.invoke ( compojure/core.clj:132 )
at compojure.core$wrap_route_info$fn__44631.invoke ( compojure/core.clj:139 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:151 )
at clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )
at clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )
at clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )
at clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:153 )
at clojure.lang.Var.invoke ( clojure/lang/Var.java:393 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )
at metabase.server.middleware.auth$enforce_authentication$fn__93651.invoke ( metabase/server.middleware/auth.clj:17 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )
at compojure.core$make_context$handler__44682.invoke ( compojure/core.clj:290 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:300 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:301 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at metabase.api.routes$fn__101626$fn__101629.invoke ( metabase/api/routes.clj:67 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )
at clojure.lang.AFn.applyToHelper ( clojure/lang/AFn.java:160 )
at clojure.lang.AFn.applyTo ( clojure/lang/AFn.java:144 )
at clojure.core$apply.invokeStatic ( clojure/core.clj:667 )
at clojure.core$apply.invoke ( clojure/core.clj:662 )
at metabase.server.routes$fn__101791$fn__101792.doInvoke ( metabase/server/routes.clj:72 )
at clojure.lang.RestFn.invoke ( clojure/lang/RestFn.java:436 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )
at compojure.core$make_context$handler__44682.invoke ( compojure/core.clj:290 )
at compojure.core$make_context$fn__44686.invoke ( compojure/core.clj:300 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:152 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:152 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at compojure.core$wrap_route_matches$fn__44635.invoke ( compojure/core.clj:152 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654$f__44655$respond_SINGLEQUOTE___44656.invoke ( compojure/core.clj:197 )
at metabase.server.routes$fn__101776$fn__101778.invoke ( metabase/server/routes.clj:49 )
at compojure.core$routes$fn__44654$f__44655.invoke ( compojure/core.clj:198 )
at compojure.core$routes$fn__44654.invoke ( compojure/core.clj:200 )
at metabase.server.middleware.exceptions$catch_api_exceptions$fn__98403.invoke ( metabase/server.middleware/exceptions.clj:96 )
at metabase.server.middleware.log$log_api_call$fn__102059$fn__102060$fn__102061.invoke ( metabase/server.middleware/log.clj:216 )
at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invokeStatic ( metabase/driver.sql_jdbc.execute/diagnostic.clj:18 )
at metabase.driver.sql_jdbc.execute.diagnostic$do_with_diagnostic_info.invoke ( metabase/driver.sql_jdbc.execute/diagnostic.clj:12 )
at metabase.server.middleware.log$log_api_call$fn__102059$fn__102060.invoke ( metabase/server.middleware/log.clj:208 )
at toucan2.execute$do_with_call_counts.invokeStatic ( toucan2/execute.clj:112 )
at toucan2.execute$do_with_call_counts.invoke ( toucan2/execute.clj:103 )
at metabase.server.middleware.log$log_api_call$fn__102059.invoke ( metabase/server.middleware/log.clj:207 )
at metabase.server.middleware.browser_cookie$ensure_browser_id_cookie$fn__104095.invoke ( metabase/server.middleware/browser_cookie.clj:40 )
at metabase.server.middleware.security$add_security_headers$fn__84540.invoke ( metabase/server.middleware/security.clj:182 )
at metabase.server.middleware.json$wrap_json_body$fn__45999.invoke ( metabase/server.middleware/json.clj:67 )
at metabase.server.middleware.offset_paging$handle_paging$fn__84564.invoke ( metabase/server.middleware/offset_paging.clj:62 )
at metabase.server.middleware.json$wrap_streamed_json_response$fn__46017.invoke ( metabase/server.middleware/json.clj:103 )
at ring.middleware.keyword_params$wrap_keyword_params$fn__104362.invoke ( ring/middleware/keyword_params.clj:55 )
at ring.middleware.params$wrap_params$fn__104381.invoke ( ring/middleware/params.clj:77 )
at metabase.server.middleware.misc$maybe_set_site_url$fn__66965.invoke ( metabase/server.middleware/misc.clj:61 )
at metabase.server.middleware.session$reset_session_timeout$fn__72380.invoke ( metabase/server.middleware/session.clj:543 )
at metabase.server.middleware.session$bind_current_user$fn__72346$fn__72347.invoke ( metabase/server.middleware/session.clj:438 )
at metabase.server.middleware.session$do_with_current_user.invokeStatic ( metabase/server.middleware/session.clj:417 )
at metabase.server.middleware.session$do_with_current_user.invoke ( metabase/server.middleware/session.clj:401 )
at metabase.server.middleware.session$bind_current_user$fn__72346.invoke ( metabase/server.middleware/session.clj:437 )
at metabase.server.middleware.session$wrap_current_user_info$fn__72329.invoke ( metabase/server.middleware/session.clj:376 )
at metabase.server.middleware.session$wrap_session_id$fn__72301.invoke ( metabase/server.middleware/session.clj:255 )
at metabase.server.middleware.auth$wrap_static_api_key$fn__93659.invoke ( metabase/server.middleware/auth.clj:30 )
at ring.middleware.cookies$wrap_cookies$fn__104282.invoke ( ring/middleware/cookies.clj:194 )
at metabase.server.middleware.misc$add_content_type$fn__66947.invoke ( metabase/server.middleware/misc.clj:29 )
at metabase.server.middleware.misc$disable_streaming_buffering$fn__66973.invoke ( metabase/server.middleware/misc.clj:78 )
at ring.middleware.gzip$wrap_gzip$fn__104324.invoke ( ring/middleware/gzip.clj:86 )
at metabase.server.middleware.misc$bind_request$fn__66976.invoke ( metabase/server.middleware/misc.clj:95 )
at metabase.server.middleware.ssl$redirect_to_https_middleware$fn__104111.invoke ( metabase/server.middleware/ssl.clj:51 )
at metabase.server$async_proxy_handler$fn__67387.invoke ( metabase/server.clj:78 )
at metabase.server.proxy$org.eclipse.jetty.server.handler.AbstractHandler$ff19274a.handle
```

With a uuid field of type `type/UUID`
<img width=""428"" alt=""Capture d‚ÄôeÃÅcran 2024-03-19 aÃÄ 10 49 17"" src=""https://github.com/metabase/metabase/assets/17989553/1c2b6c3c-16fb-4d39-95d5-6ce2f239994f"">

damienpuig on (2024-03-19 22:16:58 UTC): Hi - We have this exact same issue 0.49.0 - Can it be prioritised?
Thanks a lot

smithcoin on (2024-03-20 18:08:22 UTC): I too am getting the same issue after upgrading to v49:

```
Mar 20 18:04:35 metabase metabase[2317]: java.lang.IllegalArgumentException: UUID string too large
Mar 20 18:04:35 metabase metabase[2317]: #011at java.base/java.util.UUID.fromString(UUID.java:199)
Mar 20 18:04:35 metabase metabase[2317]: #011at metabase.driver.postgres$fn__83669.invokeStatic(postgres.clj:363)
Mar 20 18:04:35 metabase metabase[2317]: #011at metabase.driver.postgres$fn__83669.invoke(postgres.clj:357)
```

This comes from this SQL:

```
SELECT
  ""public"".""transactions"".""uuid"",
FROM
  ""public"".""transactions""

LEFT JOIN ""public"".""accounts"" AS ""Account"" ON ""public"".""transactions"".""account_id"" = ""Account"".""id""
WHERE
  (
    ""Account"".""hash"" = '360d00d2-2bc7-4a9e-956e-09d4f955643e' :: uuid
  )

GROUP BY
  ""public"".""transactions"".""uuid"",
  ```

nofalx on (2024-03-21 10:44:14 UTC): @paoliniluis

Can we please treat this as high priority item? For many people they use uuid as their primay id.

I test with v0.49.1 and the issue is still there. Im not able to downgrade back to 0.48 for some reason (cause major version?). Our ability to explore the data is stopped right now under your mercy.

MBM-2024 on (2024-03-21 16:45:25 UTC): Hi - We have this exact same issue 0.49.0 - Can it be prioritized?
Thanks a lot

damienpuig on (2024-03-25 13:04:09 UTC): Hi - we still cannot filter UUIDs with 49.1 and cannot bring back .48 (major version downgrade does not work)

Thanks again for prioritising this item

jeromedumas-peekin (Issue Creator) on (2024-03-25 13:32:49 UTC): Following the update to version 49.1, we are still encountering the previously reported issue. Could we prioritize its resolution?

hnb2 on (2024-03-28 06:31:21 UTC): Hi guys, there is a temporary fix which can be applied through the Metabase Admin. Go to ""Table Metadata"", select your table and field, then change ""Filtering on this field"" from ""Search Box"" to ""Plain input box"".:
![2024-03-27_15-51_1](https://github.com/metabase/metabase/assets/3678416/34bcfed8-e7da-438e-aa1b-4eb5e97e2989)

Obviously it won't do a like search anymore, but you will be able to enter a single ID and your editor won't break - which is what we do 99% of the time with UUIDs anyway.

Hope this helps a bit while we get a fix.

wowi42 on (2024-03-28 06:51:29 UTC): To enhance efficiency and automation of the process outlined by @hnb2 , the following SQL command is crafted for direct execution in your Metabase database:

```sql
UPDATE metabase_field 
SET has_field_values = 'none' 
WHERE has_field_values IS NULL 
AND effective_type = 'type/UUID' 
AND semantic_type = 'type/PK';
```

This approach has been proven effective in our operational context.

damienpuig on (2024-03-29 10:55:05 UTC): Thanks @hnb2 But we need the actual fix as we have tons of databases connected, and altering the metadata for all of them is not a viable options for us

kevbarns on (2024-04-16 14:44:52 UTC): Hello, following the update to 0.49.5, I still have the issue, clicking on the filter option from a PK column do nothing, search box doesn't show up

smithcoin on (2024-04-16 21:34:00 UTC): This issue shouldn't be closed as it still exists in both the v48 and v49 releases.

crisptrutski on (2024-05-23 08:08:30 UTC): Removed the milestone since this is still an issue. Have not made it a blocker for the next release (happening today)

"
2188739030,issue,closed,completed,Don't allow entity names of more than 254 chars,"### Describe the bug

If you create an entity with a name bigger than 254 chars then the DB will return a
ERROR: value too long for type character varying(254)

### To Reproduce

1) create an entity with a name like
Orders + People + People + People + People + People + People + Orders, Average of Discount, Grouped by People - User_2_2_2 ‚Üí State and People - User_2_2_2 ‚Üí Source and People - User_2_2 ‚Üí Source and Product ‚Üí Category, Average of Average of Discount, Grouped by People - User_2_2 ‚Üí Source and Product ‚Üí Category
2) try to save it

### Expected behavior

We should prevent this from the FE

### Logs

NA

### Information about your Metabase installation

```JSON
it has always been like this for sure
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-03-15 14:54:39+00:00,['ranquild'],2025-01-29 21:33:19+00:00,2025-01-29 20:13:33+00:00,https://github.com/metabase/metabase/issues/40175,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Difficulty:Easy', ''), ('.Frontend', ''), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Team/Querying', '')]",[],
2188667900,issue,closed,completed,[Epic] Enable drill-thru for single-row aggregates,"This may not deserve an Epic; it's a modest bug in the logic for when particular drill-thrus should appear.

**Links**
- [product doc](https://www.notion.so/metabase/Enable-drill-thru-for-single-row-aggregates-437fc82fb0e546569086cfe73307e339)
- eng doc: none needed; this is straightforward.
- feature branch: mblib-drills-single-row-aggregates

```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/40462
```
",luizarakaki,2024-03-15 14:33:33+00:00,['bshepherdson'],2024-03-26 18:59:45+00:00,2024-03-26 18:54:18+00:00,https://github.com/metabase/metabase/issues/40174,"[('.Epic', 'Feature Implementation or Project'), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('Querying/Drill Thrus', 'Refining existing queries with Drill Thrus'), ('.Team/Querying', '')]",[],
2188351812,issue,open,,URL edit in tables is too small,"**Is your feature request related to a problem? Please describe.**
The space to edit a link in a question can be small and difficult to read. If you are adding variables or just want to see what link you've put, it's difficult.
![Screenshot 2024-03-15 at 8 55 34‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/7817a93b-733b-4856-80b8-07cdb4e212b1)

**Describe the solution you'd like**
We should consider making it larger or making it easier to edit

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket: [25663](https://metabase.zendesk.com/agent/tickets/25663)

**Additional context**
N/A
",ignacio-mb,2024-03-15 11:57:58+00:00,[],2024-03-15 11:57:59+00:00,,https://github.com/metabase/metabase/issues/40164,"[('Type:New Feature', ''), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('Visualization/Tables', 'raw, summarized and tabular visualizations')]",[],
2188292014,issue,closed,not_planned,Upgrade Error - Migration fails to start,"### Describe the bug

I'm upgrading from v0.47.8 to metabase v0.49.0, but my database username is ""metabase-user"" is it has a ""-"" char, so the migration fails on a SET SEARCH_PATH TO command that has not beeing correctly escaped


### To Reproduce


Attempt to upgrade from v0.47.8 to v0.49.0.
See the error message displayed.

### Expected behavior

The upgrade process should proceed smoothly without encountering any errors.

### Logs

2024-03-15 11:15:28,078 INFO db.liquibase :: Checking if Database has unrun migrations... 
2024-03-15 11:15:29,627 INFO db.liquibase :: Database has unrun migrations. Checking if migraton lock is taken... 
2024-03-15 11:15:29,648 INFO db.liquibase :: No migration lock found. 
2024-03-15 11:15:30,518 INFO db.liquibase :: Running 110 migrations ... 
2024-03-15 11:15:31,266 ERROR liquibase.command :: Could not release lock 
liquibase.exception.LockException: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""-"" 
  Position: 28 [Failed SQL: (0) SET SEARCH_PATH TO metabase-user, ""$user"",""public""] 
	at liquibase.lockservice.StandardLockService.releaseLock(StandardLockService.java:407) 
	at liquibase.command.core.AbstractUpdateCommandStep.run(AbstractUpdateCommandStep.java:140) 
	at liquibase.command.core.UpdateCommandStep.run(UpdateCommandStep.java:105) 
	at liquibase.command.CommandScope.execute(CommandScope.java:217) 
	at liquibase.Liquibase.lambda$update$0(Liquibase.java:245) 
	at liquibase.Scope.lambda$child$0(Scope.java:186) 
	at liquibase.Scope.child(Scope.java:195) 
	at liquibase.Scope.child(Scope.java:185) 
	at liquibase.Scope.child(Scope.java:164) 
	at liquibase.Liquibase.runInScope(Liquibase.java:1419) 
	at liquibase.Liquibase.update(Liquibase.java:234) 
	at liquibase.Liquibase.update(Liquibase.java:212) 
	at liquibase.Liquibase.update(Liquibase.java:194) 



### Information about your Metabase installation

```JSON
Version: v0.47.8
Upgrade Target Version: v0.49.0
Environment: Kubernetes (k8s)
Database Username: metabase-user (contains ""-"")
```


### Severity

High

### Additional context

ERROR: syntax error at or near ""-"" Position: 28 [Failed SQL: (0) SET SEARCH_PATH TO metabase-user, ""$user"",""public""]
",renatocron,2024-03-15 11:22:25+00:00,[],2025-02-05 20:43:32+00:00,2025-02-05 20:43:32+00:00,https://github.com/metabase/metabase/issues/40161,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Operation/Database Migrations', 'Issues with application DB migrations when launching Metabase'), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1999708681, 'issue_id': 2188292014, 'author': 'paoliniluis', 'body': 'oh this is fun, which database are you using?', 'created_at': datetime.datetime(2024, 3, 15, 13, 49, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999892925, 'issue_id': 2188292014, 'author': 'renatocron', 'body': 'It\'s DigitalOcean managed database, it just ocurred that that the user had ""metabase-user"" with - in it\'s name\r\n\r\nI ended up doing this to fix the issue:\r\n\r\nGet the views that depends on citext extension.\r\n\r\n\r\npg_dump -h <hostname> -U <username> -d <database_name> -n metabase-user -t metabase_user.v_subscriptions -t metabase_user.v_alerts -t metabase_user.v_users --schema-only -f views_backup.sql\r\n\r\n```sql\r\n\r\nalter table   metabase_user.core_user  alter column email type varchar;\r\ndrop view metabase_user.v_subscriptions;\r\ndrop view metabase_user.v_alerts;\r\ndrop view metabase_user.v_users;\r\ndrop extension citext;\r\n\r\ncreate extension citext with schema metabase_user;\r\n\r\nDO\r\n$$\r\nDECLARE\r\n    rec record;\r\nBEGIN\r\n    -- Loop through all tables in ""metabase-user"" schema\r\n    FOR rec IN SELECT tablename FROM pg_tables WHERE schemaname = \'metabase-user\' LOOP\r\n        EXECUTE format(\'ALTER TABLE ""metabase-user"".%I SET SCHEMA metabase_user\', rec.tablename);\r\n    END LOOP;\r\n\r\n    -- Loop through all sequences in ""metabase-user"" schema\r\n    FOR rec IN SELECT sequence_name FROM information_schema.sequences WHERE sequence_schema = \'metabase-user\' LOOP\r\n        EXECUTE format(\'ALTER SEQUENCE ""metabase-user"".%I SET SCHEMA metabase_user\', rec.sequence_name);\r\n    END LOOP;\r\n\r\n    -- Loop through all views in ""metabase-user"" schema\r\n    FOR rec IN SELECT table_name FROM information_schema.views WHERE table_schema = \'metabase-user\' LOOP\r\n        EXECUTE format(\'ALTER VIEW ""metabase-user"".%I SET SCHEMA metabase_user\', rec.table_name);\r\n    END LOOP;\r\nEND;\r\n$$;\r\n\r\ndrop schema ""metabase-metastore"";\r\nalter table   metabase_user.core_user  alter column email type citext;\r\n\r\n```\r\n\r\nrestore the view', 'created_at': datetime.datetime(2024, 3, 15, 15, 19, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999993783, 'issue_id': 2188292014, 'author': 'paoliniluis', 'body': ""What's the engine of the DO managed database? postgres or mysql?"", 'created_at': datetime.datetime(2024, 3, 15, 16, 13, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2000043430, 'issue_id': 2188292014, 'author': 'renatocron', 'body': ""postgresql 15,\r\nsorry, I thought there was only set path in postgres\r\n\r\nOn Fri, Mar 15, 2024, 13:13 Luis Paolini ***@***.***> wrote:\r\n\r\n> What's the engine of the DO managed database? postgres or mysql?\r\n>\r\n> ‚Äî\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/40161#issuecomment-1999993783>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AAOUQZAID3XHZGOLKZZSLVLYYMM2RAVCNFSM6AAAAABEX2DVOGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJZHE4TGNZYGM>\r\n> .\r\n> You are receiving this because you authored the thread.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2024, 3, 15, 16, 40, 32, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-15 13:49:26 UTC): oh this is fun, which database are you using?

renatocron (Issue Creator) on (2024-03-15 15:19:54 UTC): It's DigitalOcean managed database, it just ocurred that that the user had ""metabase-user"" with - in it's name

I ended up doing this to fix the issue:

Get the views that depends on citext extension.


pg_dump -h <hostname> -U <username> -d <database_name> -n metabase-user -t metabase_user.v_subscriptions -t metabase_user.v_alerts -t metabase_user.v_users --schema-only -f views_backup.sql

```sql

alter table   metabase_user.core_user  alter column email type varchar;
drop view metabase_user.v_subscriptions;
drop view metabase_user.v_alerts;
drop view metabase_user.v_users;
drop extension citext;

create extension citext with schema metabase_user;

DO
$$
DECLARE
    rec record;
BEGIN
    -- Loop through all tables in ""metabase-user"" schema
    FOR rec IN SELECT tablename FROM pg_tables WHERE schemaname = 'metabase-user' LOOP
        EXECUTE format('ALTER TABLE ""metabase-user"".%I SET SCHEMA metabase_user', rec.tablename);
    END LOOP;

    -- Loop through all sequences in ""metabase-user"" schema
    FOR rec IN SELECT sequence_name FROM information_schema.sequences WHERE sequence_schema = 'metabase-user' LOOP
        EXECUTE format('ALTER SEQUENCE ""metabase-user"".%I SET SCHEMA metabase_user', rec.sequence_name);
    END LOOP;

    -- Loop through all views in ""metabase-user"" schema
    FOR rec IN SELECT table_name FROM information_schema.views WHERE table_schema = 'metabase-user' LOOP
        EXECUTE format('ALTER VIEW ""metabase-user"".%I SET SCHEMA metabase_user', rec.table_name);
    END LOOP;
END;
$$;

drop schema ""metabase-metastore"";
alter table   metabase_user.core_user  alter column email type citext;

```

restore the view

paoliniluis on (2024-03-15 16:13:06 UTC): What's the engine of the DO managed database? postgres or mysql?

renatocron (Issue Creator) on (2024-03-15 16:40:32 UTC): postgresql 15,
sorry, I thought there was only set path in postgres

On Fri, Mar 15, 2024, 13:13 Luis Paolini ***@***.***> wrote:

"
2187522030,issue,closed,completed,Rename `metabase.mbql.*` namespaces to `metabase.legacy-mbql.*` and mark deprecated?,except for maybe the match stuff (which should probably get moved into `metabase.lib`),camsaul,2024-03-15 01:00:45+00:00,['camsaul'],2024-04-11 17:14:08+00:00,2024-04-11 17:14:07+00:00,https://github.com/metabase/metabase/issues/40156,"[('Type:Tech Debt', 'or Refactoring'), ('Querying/Processor', ''), ('.Backend', '')]","[{'comment_id': 2023454935, 'issue_id': 2187522030, 'author': 'camsaul', 'body': 'Implemented by #40158', 'created_at': datetime.datetime(2024, 3, 27, 18, 5, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2050146605, 'issue_id': 2187522030, 'author': 'camsaul', 'body': 'Implemented by https://github.com/metabase/metabase/pull/40158', 'created_at': datetime.datetime(2024, 4, 11, 17, 14, 8, tzinfo=datetime.timezone.utc)}]","camsaul (Issue Creator) on (2024-03-27 18:05:47 UTC): Implemented by #40158

camsaul (Issue Creator) on (2024-04-11 17:14:08 UTC): Implemented by https://github.com/metabase/metabase/pull/40158

"
2187436849,issue,closed,completed,Wide logos cover the icon to collapse the sidebar,"### Describe the bug

When using custom logos, if your logo is too big it will cover the icon to collapse the sidebar

### To Reproduce

1) add this logo
![images (2)](https://github.com/metabase/metabase/assets/1711649/c01b697b-8041-48e3-9db2-33c5ba7ef113)
2) see how it looks

### Expected behavior

We shouldn't cover the logo

### Logs

_No response_

### Information about your Metabase installation

```JSON
v49
```


### Severity

P2

### Additional context

P2 as you're forced to wipe the logo",paoliniluis,2024-03-14 23:17:45+00:00,['rafpaf'],2024-03-21 07:51:27+00:00,2024-03-20 19:58:31+00:00,https://github.com/metabase/metabase/issues/40153,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2187430300,issue,open,,DB names overflow on browse data,"### Describe the bug

See it for yourself

### To Reproduce

1) create a DB
2) set the name as a_db_with_a_long_long_long_long_long_name_for_overflow

### Expected behavior

We should wrap

### Logs

NA

### Information about your Metabase installation

```JSON
v49
```


### Severity

P3

### Additional context

![image](https://github.com/metabase/metabase/assets/1711649/bf515b1f-6700-48cc-998b-051b5d2dbb1d)
",paoliniluis,2024-03-14 23:10:37+00:00,[],2024-06-20 16:14:47+00:00,,https://github.com/metabase/metabase/issues/40152,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('Administration/', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2187150028,issue,open,,Titles and other strings are difficult to read in Dark Mode - Full Screen,"**Is your feature request related to a problem? Please describe.**
Can be an accessibility issue to some users. See the ""Test"" name of the dashboard and tabs and column names. 
<img width=""950"" alt=""Screenshot 2024-03-14 at 4 39 35‚ÄØPM"" src=""https://github.com/metabase/metabase/assets/132273646/926cfbe4-dfda-4acc-9774-e606aa42660e"">

**Describe the solution you'd like**
Some way to change this (related to https://github.com/metabase/metabase/issues/34294) or, by default, set a brighter color for strings

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer in internal ticket [25635](https://metabase.zendesk.com/agent/tickets/25635)

**Additional context**
N/A
",ignacio-mb,2024-03-14 19:48:15+00:00,[],2025-02-04 20:30:54+00:00,,https://github.com/metabase/metabase/issues/40146,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Customization/i18n', ''), ('Design System', 'Overall UI patterns and components, not specific to a single part of the product')]",[],
2187132861,issue,closed,completed,[dc.js migration] move trend line computations to the chart model,"Instead of computing trend lines data with the echarts options, do it in the model:
- add `trendLinesDataset: ChartDataset`
- add `trendLinesSeries: SeriesModel[]`

---
When fixing this, it would be nice to also fix: https://github.com/metabase/metabase/issues/39604",alxnddr,2024-03-14 19:37:23+00:00,['kulyk'],2024-03-29 17:07:53+00:00,2024-03-29 17:07:53+00:00,https://github.com/metabase/metabase/issues/40145,"[('Type:Tech Debt', 'or Refactoring'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.echarts-scope', 'Issues related to chart types that have already been or will be migrated to echarts.')]",[],
2186674706,issue,open,,Cannot create new collection in Metabase analytics / Custom reports,"### Describe the bug

I tried to create a new collection via the Collection Picker but I got a 400 and this response: `{""errors"":{""location"":""Collection must be in the same namespace as its parent""}}`

### To Reproduce

1. Click the blue ""New +"" button, then ""New collection"".
2. Click ""Collection it's saved in"". This opens a dialog.
3. Click ""Metabase analytics"", then ""Custom reports"".
4. Click ""Create a new collection"", type a name, and click ""Create"".

[Loom](https://www.loom.com/share/8b30f53bcaf74366991bf36de96cf860?sid=5f8c5f99-2584-4a55-a04b-57ec889d9317)

### Expected behavior

A new collection should be created

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""Java(TM) SE Runtime Environment"",
    ""java.runtime.version"": ""21.0.1+12-LTS-29"",
    ""java.vendor"": ""Oracle Corporation"",
    ""java.vendor.url"": ""https://java.oracle.com/"",
    ""java.version"": ""21.0.1"",
    ""java.vm.name"": ""Java HotSpot(TM) 64-Bit Server VM"",
    ""java.vm.version"": ""21.0.1+12-LTS-29"",
    ""os.name"": ""Mac OS X"",
    ""os.version"": ""14.1"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""sqlite"",
      ""postgres"",
      ""h2"",
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.11 (Homebrew)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""dev"",
    ""version"": {
      ""date"": ""2024-03-10"",
      ""src_hash"": ""76372557c5118a0d77b6d330c56ce9462bc2302d"",
      ""tag"": ""v1.48.1-SNAPSHOT"",
      ""hash"": ""578c268""
    },
    ""settings"": {
      ""report-timezone"": ""America/New_York""
    }
  }
}
```


### Severity

not severe

### Additional context

_No response_",rafpaf,2024-03-14 15:32:52+00:00,['noahmoss'],2024-05-06 20:35:54+00:00,,https://github.com/metabase/metabase/issues/40138,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Administration/Usage analytics', 'Pro and Enterprise meta analytics, fka audit'), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2096866814, 'issue_id': 2186674706, 'author': 'dpsutton', 'body': 'This could be a FE or a BE bug, not entirely clear.\n\nCreating a collection in the ""Custom Reports"" (id 3) collection\n```clojure\ncollection=> (metabase.test/with-current-user 1\n               (create-collection! {:name ""in custom""\n                                    :parent_id 3}))\nExecution error (ExceptionInfo) at metabase.models.collection/assert-valid-namespace (collection.clj:212).\nCollection must be in the same namespace as its parent\n```\n\nIdentical code succeeds in any other collection.\n\nError is thrown in \n\n```clojure\n(defn- assert-valid-namespace\n  ""Check that the namespace of this Collection is valid -- it must belong to the same namespace as its parent\n  Collection.""\n```\n\nAnd that\'s clear from this:\n```sql\nclean=# select id, name, namespace from collection;\n    id    |                     name                     | namespace\n----------+----------------------------------------------+-----------\n        1 | Examples                                     | [null]\n        2 | Metabase analytics                           | analytics\n        3 | Custom reports                               | analytics\n        4 | dan sutton\'s Personal Collection             | [null]\n 13371339 | Trash                                        | [null]\n        5 | Automatically Generated Dashboards           | [null]\n        6 | A look at Invoices                           | [null]\n        7 | A look at Orders                             | [null]\n        8 | A look at Products                           | [null]\n        9 | duplicate@metabase.com\'s Personal Collection | [null]\n       10 | invited invited\'s Personal Collection        | [null]\n       11 | A look at Products                           | [null]\n       12 | not in custom                                | [null]\n       13 | not custom                                   | [null]\n(14 rows)\n```\n\nBackground:\nhttps://metaboat.slack.com/archives/C064EB1UE5P/p1701814539639079\nhttps://metaboat.slack.com/archives/C064EB1UE5P/p1699943256345509', 'created_at': datetime.datetime(2024, 5, 6, 20, 35, 53, tzinfo=datetime.timezone.utc)}]","dpsutton on (2024-05-06 20:35:53 UTC): This could be a FE or a BE bug, not entirely clear.

Creating a collection in the ""Custom Reports"" (id 3) collection
```clojure
collection=> (metabase.test/with-current-user 1
               (create-collection! {:name ""in custom""
                                    :parent_id 3}))
Execution error (ExceptionInfo) at metabase.models.collection/assert-valid-namespace (collection.clj:212).
Collection must be in the same namespace as its parent
```

Identical code succeeds in any other collection.

Error is thrown in 

```clojure
(defn- assert-valid-namespace
  ""Check that the namespace of this Collection is valid -- it must belong to the same namespace as its parent
  Collection.""
```

And that's clear from this:
```sql
clean=# select id, name, namespace from collection;
    id    |                     name                     | namespace
----------+----------------------------------------------+-----------
        1 | Examples                                     | [null]
        2 | Metabase analytics                           | analytics
        3 | Custom reports                               | analytics
        4 | dan sutton's Personal Collection             | [null]
 13371339 | Trash                                        | [null]
        5 | Automatically Generated Dashboards           | [null]
        6 | A look at Invoices                           | [null]
        7 | A look at Orders                             | [null]
        8 | A look at Products                           | [null]
        9 | duplicate@metabase.com's Personal Collection | [null]
       10 | invited invited's Personal Collection        | [null]
       11 | A look at Products                           | [null]
       12 | not in custom                                | [null]
       13 | not custom                                   | [null]
(14 rows)
```

Background:
https://metaboat.slack.com/archives/C064EB1UE5P/p1701814539639079
https://metaboat.slack.com/archives/C064EB1UE5P/p1699943256345509

"
2186191608,issue,closed,completed,"Migrate global css in `frontend/src/metabase/css/admin.module.css`, `frontend/src/metabase/css/pulse.module.css`, `frontend/src/metabase/css/core/inputs.module.css`",,deniskaber,2024-03-14 12:13:17+00:00,['oisincoveney'],2024-04-12 14:10:28+00:00,2024-03-19 12:08:33+00:00,https://github.com/metabase/metabase/issues/40129,"[('.CSS', ''), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Team/Embedding', '')]",[],
2186191290,issue,closed,completed,Isolate global css-variables by adding a common prefix,"e.g. Change `--color-brand` to `--mb-color-brand`.

List of all CSS custom properties query with
```sh
 rg ""(var\(--.*?\))"" -o -N frontend --no-filename | sort | uniq
```

```
var(--border-size)
var(--border-size-medium)
var(--border-style)
var(--breadcrumb-divider-spacing)
var(--breadcrumb-page-color)
var(--breadcrumbs-color)
var(--color-bg-black)
var(--color-bg-dark)
var(--color-bg-light)
var(--color-bg-medium)
var(--color-bg-white)
var(--color-border)
var(--color-brand)
var(--color-brand-alpha-04)
var(--color-brand-alpha-88)
var(--color-error)
var(--color-focus)
var(--color-shadow)
var(--color-success)
var(--color-text-dark)
var(--color-text-default)
var(--color-text-light)
var(--color-text-medium)
var(--color-text-white)
var(--color-white)
var(--default-border-radius)
var(--default-button-border-radius)
var(--default-font-family)
var(--default-font-size)
var(--default-header-margin)
var(--gap-1)
var(--icon-width)
var(--input-border-color)
var(--input-border-radius)
var(--margin-1)
var(--margin-2)
var(--margin-3)
var(--margin-4)
var(--muted-color)
var(--padding-1)
var(--padding-2)
var(--padding-3)
var(--padding-4)
var(--page-header-padding)
var(--sidebar-breadcrumbs-color)
var(--subtitle-color)
var(--title-color)
```",deniskaber,2024-03-14 12:13:06+00:00,['WiNloSt'],2024-04-19 11:18:51+00:00,2024-04-19 11:18:51+00:00,https://github.com/metabase/metabase/issues/40128,[],[],
2186190607,issue,closed,completed,"Isolate global third-party stylesheets - leaflet, ace-builds, tippy.js for Embedding SDK + migrate `frontend/src/metabase/visualizations/components/LeafletMap.module.css`","```[tasklist]
### Tasks
- [ ] leaflet
- [ ] ace-builds
- [ ] tippy.js
- [ ] `frontend/src/metabase/visualizations/components/LeafletMap.module.css`
```
",deniskaber,2024-03-14 12:12:43+00:00,['WiNloSt'],2024-04-18 12:32:34+00:00,2024-04-18 12:32:33+00:00,https://github.com/metabase/metabase/issues/40127,[],"[{'comment_id': 2063758685, 'issue_id': 2186190607, 'author': 'WiNloSt', 'body': ""We'll not have to complete these tasks. https://metaboat.slack.com/archives/C063Q3F1HPF/p1713443488111869?thread_ts=1713434991.027859&cid=C063Q3F1HPF"", 'created_at': datetime.datetime(2024, 4, 18, 12, 32, 34, tzinfo=datetime.timezone.utc)}]","WiNloSt (Assginee) on (2024-04-18 12:32:34 UTC): We'll not have to complete these tasks. https://metaboat.slack.com/archives/C063Q3F1HPF/p1713443488111869?thread_ts=1713434991.027859&cid=C063Q3F1HPF

"
2186169841,issue,closed,not_planned,Visualization differs after converting question to SQL,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/0a9b596a-cfd3-4d4d-85f6-cd4c8ea09148



### To Reproduce

1. Start a question [like this](https://github.com/metabase/metabase/assets/6830683/3ff5a0fa-a37a-471e-b935-a586a3a18e02)
2. Visualize it - it works
3. Save it
4. Open notebook
5. Convert question to SQL
6. Run query

Visualization differs

### Expected behavior

Visualization looks the same as in step 2


### Information about your Metabase installation

master at 45a2e8689f


### Severity

P2

### Additional context

Similar to #40124",kamilmielnik,2024-03-14 12:01:19+00:00,[],2024-06-17 11:12:15+00:00,2024-06-17 11:12:09+00:00,https://github.com/metabase/metabase/issues/40126,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Visualization/Chart Settings', ''), ('.Frontend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1999459573, 'issue_id': 2186169841, 'author': 'ranquild', 'body': 'column ""keys"" differ between MBQL and SQL questions, so that\'s expected. I don\'t see how we can convert visualization_settings between the questions', 'created_at': datetime.datetime(2024, 3, 15, 11, 27, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173104683, 'issue_id': 2186169841, 'author': 'kulyk', 'body': 'As @ranquild pointed out, this is expected for native queries at this point. Fixing this would require SQL parsing, so closing the issue for now', 'created_at': datetime.datetime(2024, 6, 17, 11, 12, 9, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-03-15 11:27:16 UTC): column ""keys"" differ between MBQL and SQL questions, so that's expected. I don't see how we can convert visualization_settings between the questions

kulyk on (2024-06-17 11:12:09 UTC): As @ranquild pointed out, this is expected for native queries at this point. Fixing this would require SQL parsing, so closing the issue for now

"
2186165662,issue,closed,completed,Limit list of temporal units based on the column type,Context https://metaboat.slack.com/archives/C04CYTEL9N2/p1709822681074449,ranquild,2024-03-14 11:59:00+00:00,['bshepherdson'],2024-03-15 11:01:16+00:00,2024-03-15 11:01:16+00:00,https://github.com/metabase/metabase/issues/40125,[],[],
2186160355,issue,closed,not_planned,Visualization disappears after converting question to SQL,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/bae65d3d-7a00-43be-8c74-8bfe79da2ea9



### To Reproduce

1. Start a question [like this](https://github.com/metabase/metabase/assets/6830683/2ba420e5-4970-4014-afa0-f0953561a5cf)
2. Visualize it - it works
3. Open notebook
4. Convert question to SQL
5. Run query

Visualization disappeared.
Saving the question and refreshing the page does not help.

### Expected behavior

Visualization is shown

### Information about your Metabase installation

master at 45a2e8689f

### Severity

P2

### Additional context

Similar to #40126",kamilmielnik,2024-03-14 11:55:55+00:00,[],2024-06-17 11:13:07+00:00,2024-06-17 11:13:07+00:00,https://github.com/metabase/metabase/issues/40124,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Native', 'The SQL/native query editor'), ('Visualization/Charts', 'Line, area, bar, combo, and scatter charts.'), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 2126650116, 'issue_id': 2186160355, 'author': 'kamilmielnik', 'body': 'Simpler question for repro: [image](https://github.com/metabase/metabase/assets/6830683/a5495a34-995f-4013-8265-086876b7cafc)', 'created_at': datetime.datetime(2024, 5, 23, 9, 28, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2173106451, 'issue_id': 2186160355, 'author': 'kulyk', 'body': ""Similarly to #40126, this is expected for native queries at this point. Closing as it'd require more advanced SQL parsing"", 'created_at': datetime.datetime(2024, 6, 17, 11, 13, 7, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-05-23 09:28:35 UTC): Simpler question for repro: [image](https://github.com/metabase/metabase/assets/6830683/a5495a34-995f-4013-8265-086876b7cafc)

kulyk on (2024-06-17 11:13:07 UTC): Similarly to #40126, this is expected for native queries at this point. Closing as it'd require more advanced SQL parsing

"
2185866412,issue,closed,not_planned,Problem in LDAP (AD) integration ,"Hi Team,
I am facing problem in LDAP (AD) integration. Please find below screenshot and let me know where is wrong. 

![image](https://github.com/metabase/metabase/assets/106506928/39fd4418-5df0-431d-bf91-2bfb45108e47)
",gopal-faircent,2024-03-14 09:25:47+00:00,[],2024-03-15 15:23:30+00:00,2024-03-15 00:01:36+00:00,https://github.com/metabase/metabase/issues/40121,[],"[{'comment_id': 1997006906, 'issue_id': 2185866412, 'author': 'gopal-faircent', 'body': '{\r\n  ""browser-info"": {\r\n    ""language"": ""en-US"",\r\n    ""platform"": ""Win32"",\r\n    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.21+9"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.21"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.21+9"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""6.2.0-1017-aws"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""GMT""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""redshift"",\r\n      ""mysql"",\r\n      ""mongo""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""15.3 (Debian 15.3-1.pgdg120+1)""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.5.4""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""version"": {\r\n      ""date"": ""2023-11-07"",\r\n      ""tag"": ""v0.47.7"",\r\n      ""branch"": ""?"",\r\n      ""hash"": ""dd51fd4""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": ""Asia/Kolkata""\r\n    }\r\n  }\r\n}', 'created_at': datetime.datetime(2024, 3, 14, 9, 26, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998669047, 'issue_id': 2185866412, 'author': 'paoliniluis', 'body': 'what problem are you facing? please post this in the forums', 'created_at': datetime.datetime(2024, 3, 15, 0, 1, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998914779, 'issue_id': 2185866412, 'author': 'gopal-faircent', 'body': 'Problem is Metbase - LDAP (Active Directory) integration is not working properly.', 'created_at': datetime.datetime(2024, 3, 15, 4, 26, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999863599, 'issue_id': 2185866412, 'author': 'paoliniluis', 'body': '@gopal-faircent ""not working properly"", do you have logs? as you can imagine we can\'t do nothing without logs', 'created_at': datetime.datetime(2024, 3, 15, 15, 5, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999899507, 'issue_id': 2185866412, 'author': 'gopal-faircent', 'body': 'Let me know how to provide specific logs.. I checked u Der Troubleshooting\r\n> Logs but no such a error or information found.\r\n\r\n- Sent from mobile. Pls excuse any typos!\r\n\r\nOn Fri, 15 Mar, 2024, 8:35 pm Luis Paolini, ***@***.***>\r\nwrote:\r\n\r\n> @gopal-faircent <https://github.com/gopal-faircent> ""not working\r\n> properly"", do you have logs? as you can imagine we can\'t do nothing without\r\n> logs\r\n>\r\n> ‚Äî\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/metabase/metabase/issues/40121#issuecomment-1999863599>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AZMSVMAJW66Y3EKDCTQYWSTYYME43AVCNFSM6AAAAABEVW3WOOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSOJZHA3DGNJZHE>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n\r\n-- \r\n\r\n\r\n*Did you know you could earn returns upto 12% pa\xa0on Faircent?\xa0**Use the \r\npower of P2P Lending to earn stable returns on your investment. Sign up \r\nNow! \r\n<https://www.faircent.in/lender_registration_v2/step1?utm_source=fcmail&utm_medium=internal&utm_campaign=email>*\r\n\r\n* T&C Apply. Legal Disclaimer: - The content of this e-mail message is \r\nintended only for the confidential use of the person(s) to whom it is \r\naddressed above. If the reader of this message is not the designated person \r\nto whom it is addressed, you are hereby notified that you have received \r\nthis communication in error and that reading it, copying it, or in any way \r\ndisseminating its content to any other person, is strictly prohibited. If \r\nyou have received this e-mail in error, please notify the author by using \r\nthe reply key immediately.', 'created_at': datetime.datetime(2024, 3, 15, 15, 23, 29, tzinfo=datetime.timezone.utc)}]","gopal-faircent (Issue Creator) on (2024-03-14 09:26:08 UTC): {
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""Win32"",
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.2.0-1017-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""redshift"",
      ""mysql"",
      ""mongo""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""15.3 (Debian 15.3-1.pgdg120+1)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.4""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-11-07"",
      ""tag"": ""v0.47.7"",
      ""branch"": ""?"",
      ""hash"": ""dd51fd4""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Kolkata""
    }
  }
}

paoliniluis on (2024-03-15 00:01:37 UTC): what problem are you facing? please post this in the forums

gopal-faircent (Issue Creator) on (2024-03-15 04:26:02 UTC): Problem is Metbase - LDAP (Active Directory) integration is not working properly.

paoliniluis on (2024-03-15 15:05:27 UTC): @gopal-faircent ""not working properly"", do you have logs? as you can imagine we can't do nothing without logs

gopal-faircent (Issue Creator) on (2024-03-15 15:23:29 UTC): Let me know how to provide specific logs.. I checked u Der Troubleshooting

- Sent from mobile. Pls excuse any typos!

On Fri, 15 Mar, 2024, 8:35 pm Luis Paolini, ***@***.***>
wrote:


-- 


*Did you know you could earn returns upto 12% pa¬†on Faircent?¬†**Use the 
power of P2P Lending to earn stable returns on your investment. Sign up 
Now! 
<https://www.faircent.in/lender_registration_v2/step1?utm_source=fcmail&utm_medium=internal&utm_campaign=email>*

* T&C Apply. Legal Disclaimer: - The content of this e-mail message is 
intended only for the confidential use of the person(s) to whom it is 
addressed above. If the reader of this message is not the designated person 
to whom it is addressed, you are hereby notified that you have received 
this communication in error and that reading it, copying it, or in any way 
disseminating its content to any other person, is strictly prohibited. If 
you have received this e-mail in error, please notify the author by using 
the reply key immediately.

"
2185789545,issue,closed,not_planned,Can't connect to Athena using IAM Role / Profile,"### Describe the bug

I am able to connect to Amazon Athena from DBeaver using this trick, but can't do the same in Metabase

1. Do your normal AWS login process to refresh your credentials (in our case, we use okta + gimme_aws_creds for this).
2. Go to driver properties on your DBeaver Athena connection and set:

- AwsCredentialsProviderClass to com.simba.athena.amazonaws.auth.profile.ProfileCredentialsProvider
- AwsCredentialsProviderArguments equal to the name of the profile you want to use (see ~/.aws/config to see which profiles you have) ‚Äì we use ‚Äúdefault‚Äù.

3. Test Connection and it should work.

(from [Using Athena From DBeaver with your IAM Role / Profile | Coding Stream of Consciousness](https://coding-stream-of-consciousness.com/2021/11/16/using-athena-from-dbeaver-with-your-iam-role-profile/))


### To Reproduce

1. Run Metabase in Docker (in my case in MacOS)
2. Try to add a connection to Athena using the IAM role
<img width=""921"" alt=""image"" src=""https://github.com/metabase/metabase/assets/1760612/b52442ea-f572-4f38-af92-05eb174c0bf2"">




### Expected behavior

Connection is successul

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.6.12-linuxkit"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""h2"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""H2"",
        ""version"": ""2.1.214 (2022-06-13)""
      },
      ""jdbc-driver"": {
        ""name"": ""H2 JDBC Driver"",
        ""version"": ""2.1.214 (2022-06-13)""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

High

### Additional context

_No response_",iholoviy,2024-03-14 08:54:38+00:00,[],2024-03-27 14:09:34+00:00,2024-03-15 13:50:19+00:00,https://github.com/metabase/metabase/issues/40120,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1998670132, 'issue_id': 2185789545, 'author': 'paoliniluis', 'body': 'have you created your data lake with lake formation?', 'created_at': datetime.datetime(2024, 3, 15, 0, 3, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999161681, 'issue_id': 2185789545, 'author': 'iholoviy', 'body': '> have you created your data lake with lake formation?\r\n\r\nyes, data lake with lake formation was created', 'created_at': datetime.datetime(2024, 3, 15, 8, 30, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999710588, 'issue_id': 2185789545, 'author': 'paoliniluis', 'body': 'please read the last line of https://www.metabase.com/docs/latest/databases/connections/athena#permissions-and-iam-policies', 'created_at': datetime.datetime(2024, 3, 15, 13, 50, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 1999727521, 'issue_id': 2185789545, 'author': 'iholoviy', 'body': ""@paoliniluis all these policies are configured. I am able to query data via DBeaver, so I don't think it's a permission issue. I guess that here should be an option to use com.simba.athena.amazonaws.auth.profile.ProfileCredentialsProvider\r\n\r\n![image](https://github.com/metabase/metabase/assets/1760612/f072d01c-4596-4cd1-8977-cc8b3d16d195)"", 'created_at': datetime.datetime(2024, 3, 15, 13, 58, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2007444985, 'issue_id': 2185789545, 'author': 'paoliniluis', 'body': '@iholoviy have you been able to connect after going to AWS Lake Formation > Permissions > Data Lake Permissions > Grant data lake permissions; the role Metabase uses needs SELECT and DESCRIBE table permissions?', 'created_at': datetime.datetime(2024, 3, 19, 15, 7, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2022868365, 'issue_id': 2185789545, 'author': 'iholoviy', 'body': ""@paoliniluis \r\nwhy can't I query data from Athena via DBeaver but can't access the same data via Metabase?  Both tools use JDBC connection, both tools should query data via SQL. What is the difference here?"", 'created_at': datetime.datetime(2024, 3, 27, 14, 9, 32, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-15 00:03:01 UTC): have you created your data lake with lake formation?

iholoviy (Issue Creator) on (2024-03-15 08:30:25 UTC): yes, data lake with lake formation was created

paoliniluis on (2024-03-15 13:50:19 UTC): please read the last line of https://www.metabase.com/docs/latest/databases/connections/athena#permissions-and-iam-policies

iholoviy (Issue Creator) on (2024-03-15 13:58:46 UTC): @paoliniluis all these policies are configured. I am able to query data via DBeaver, so I don't think it's a permission issue. I guess that here should be an option to use com.simba.athena.amazonaws.auth.profile.ProfileCredentialsProvider

![image](https://github.com/metabase/metabase/assets/1760612/f072d01c-4596-4cd1-8977-cc8b3d16d195)

paoliniluis on (2024-03-19 15:07:51 UTC): @iholoviy have you been able to connect after going to AWS Lake Formation > Permissions > Data Lake Permissions > Grant data lake permissions; the role Metabase uses needs SELECT and DESCRIBE table permissions?

iholoviy (Issue Creator) on (2024-03-27 14:09:32 UTC): @paoliniluis 
why can't I query data from Athena via DBeaver but can't access the same data via Metabase?  Both tools use JDBC connection, both tools should query data via SQL. What is the difference here?

"
2185204726,issue,open,,Getting the table list on browse data can take a lot of time on big databases,"### Describe the bug

Seems that when we build that view we do:
For every single table on the database:
`SELECT * FROM `metabase_field` WHERE (`table_id` = xxxxx) AND (`active` = TRUE) AND (`visibility_type` <> 'retired') ORDER BY `position` ASC, LOWER(`name`) ASC` (why do we want to get the fields when we should be listing the tables?)
`SELECT * FROM `segment` WHERE (`table_id` IN (xxxxx, yyyyy)) AND (`archived` = FALSE) ORDER BY `name` ASC` (why do we want to list the segments there?

### To Reproduce

1) build a database with 10 thousand tables
2) go to browse data

### Expected behavior

We should only get the table names, when we click on a table, we get the fields

### Logs

NA

### Information about your Metabase installation

```JSON
v48.8
mysql 8 as the App DB
```


### Severity

P3

### Additional context

_No response_",paoliniluis,2024-03-14 01:30:58+00:00,[],2024-06-20 16:15:24+00:00,,https://github.com/metabase/metabase/issues/40117,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Performance', ''), ('.Frontend', ''), ('.Backend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]",[],
2184874920,issue,open,,"Add information about sync to the Admin Settings > Database page, when syncs happen","**Is your feature request related to a problem? Please describe.**
Requested by some customers who wants to know what new tables got synced, what tables got updated, etc., and information about how much time it took, how much time is taking/percentage of completion for manual syncs, etc.

**Describe the solution you'd like**
Described above

**Describe alternatives you've considered**
Checking the logs, but not friendly

**How important is this feature to you?**
Requested by some customers in the last month

**Additional context**
N/A
",ignacio-mb,2024-03-13 20:58:36+00:00,[],2025-02-04 20:31:01+00:00,,https://github.com/metabase/metabase/issues/40109,"[('Administration/Metadata & Sync', ''), ('Type:New Feature', ''), ('Administration/Settings', '')]",[],
2184823435,issue,closed,completed,[Epic] Upgrade to React 18,"**Links**
- feature branch: `update-react-18`

**Implementation Plan**
This is subject to change (and has already changed), but the current implementation plan revolves around migrating away from libraries that are known to not fully work with react 18, and then start addressing issues that CI and Unit tests catch.

```[tasklist]
### Upgrade secondary dependencies
- [ ] https://github.com/metabase/metabase/issues/39714
- [ ] https://github.com/metabase/metabase/issues/37921
- [x] Update user-auth-wrapper to v2
- [x] Update react-draggable
```
```[tasklist]
### Pre-18 Work (required things we can get done prior to actual package upgrade)
- [ ] https://github.com/metabase/metabase/issues/40178
- [ ] https://github.com/metabase/metabase/issues/41271
- [ ] https://github.com/metabase/metabase/issues/40267
- [ ] https://github.com/metabase/metabase/issues/41208
```

```[tasklist]
### React 18 Upgrade
- [x] Update react to v18
- [x] Migration types for props to contain definition for `children`
- [x] Update react library to latest version
- [x] table headers issue (drag start to end < 5px is considered a click)
- [x] Fix e2e tests
- [ ] https://github.com/metabase/metabase/issues/43373
```
",npfitz,2024-03-13 20:22:30+00:00,"['npfitz', 'sloansparger']",2024-05-31 15:06:21+00:00,2024-05-31 15:06:20+00:00,https://github.com/metabase/metabase/issues/40107,"[('.Epic', 'Feature Implementation or Project')]",[],
2184557744,issue,closed,completed,Feature parity of Druid JDBC with the non-JDBC driver.,"Existing Druid driver supports following feature flags.

From `metabase.driver`:
- `:basic-aggregations`
- `:case-sensitivity-string-filter-options`
- `:date-arithmetics`
- `:temporal-extract`
- `:schemas`
- `:test/jvm-timezone-setting`.

From `metabase.driver.druid`:
- `:set-timezone`
-  `:expression-aggregations`.

Tests that ensure it does work correctly are in `./modules/drivers/druid/test` and also tests in `./test`, that are guarded by `metabase.timeseries-query-processor-test.util/timeseries-drivers`. Set of time series drivers should be extended with JDBC driver.

Timesries tests should be adjusted to work with JDBC driver. Tests in existing Druid driver should be examined and ported to JDBC driver.

That should ensure feature parity of JDBC and non-jdbc driver.",lbrdnk,2024-03-13 17:37:47+00:00,['lbrdnk'],2024-05-05 14:04:10+00:00,2024-05-05 14:04:10+00:00,https://github.com/metabase/metabase/issues/40096,[],"[{'comment_id': 2094821871, 'issue_id': 2184557744, 'author': 'lbrdnk', 'body': 'Closing with PR https://github.com/metabase/metabase/pull/40293 merged into master.', 'created_at': datetime.datetime(2024, 5, 5, 14, 4, 10, tzinfo=datetime.timezone.utc)}]","lbrdnk (Issue Creator) on (2024-05-05 14:04:10 UTC): Closing with PR https://github.com/metabase/metabase/pull/40293 merged into master.

"
2184540783,issue,closed,completed,PNG dashboard card download doesn't do anything in MacOS Safari,"### Describe the bug

When viewing a dashboard card with a visualization, attempting to download it as a PNG does nothing (no file downloaded, no prompt to allow downloads) in MacOS Safari

### To Reproduce

1. Using Safari and MacOS and full app embedding, go to a dashboard that includes a card with a visualization
2. Attempt to download the card as JSON, note that it works
3. Attempt to download the card as PNG, note that nothing happens

### Expected behavior

It should download a PNG

### Logs

Console in the browser shows:

```[Debug] #3 ‚Äì ""1ms"" ‚Äì ""Starting document clone with size 1792x646 scrolled to 0,0"" (vendor.a42b74c52173b8154879.js, line 97)
[Error] Refused to apply a stylesheet because its hash, its nonce, or 'unsafe-inline' does not appear in the style-src directive of the Content Security Policy. (11-account-snapshot, line 1)
[Debug] #3 ‚Äì ""211ms"" ‚Äì ""Document cloned, element located at 592,223 with size 1168x197 using computed rendering"" (vendor.a42b74c52173b8154879.js, line 97)
[Debug] #3 ‚Äì ""211ms"" ‚Äì ""Starting DOM parsing"" (vendor.a42b74c52173b8154879.js, line 97)
[Debug] #3 ‚Äì ""243ms"" ‚Äì ""Added image data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20data-testid%3D%22pie-chart%22%20width%3D%22159p‚Ä¶"" (vendor.a42b74c52173b8154879.js, line 97)
""Added image data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20data-testid%3D%22pie-chart%22%20width%3D%22159px%22%20height%3D%22159px%22%20style%3D%22max-width%3A%20550px%3B%20transition%3A%20all%3B%20--color-brand-alpha-88%3A%20rgba(0%2""
[Debug] #3 ‚Äì ""246ms"" ‚Äì ""Starting renderer for element at 592,223 with size 1168x197"" (vendor.a42b74c52173b8154879.js, line 97)
[Debug] #3 ‚Äì ""247ms"" ‚Äì ""Canvas renderer initialized (1168x197) with scale 2"" (vendor.a42b74c52173b8154879.js, line 97)
[Debug] #3 ‚Äì ""262ms"" ‚Äì ""Finished rendering"" (vendor.a42b74c52173b8154879.js, line 97)
[Error] Refused to load data:image/octet-stream;base64,iVBORw0KGgoAAAANSUhEUgAACSAAAAGKCAYAAAAWx31NAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAJIKADAAQAAAABAAABigAAAAClTi6MAABAAElEQVR4AezdB3wb15Xo4UMS7F2iepdlyZZlW+6We6+JnTjFiZ22cTblbcpmX7Zls/s2m83blE3d1BfbqS5JbMe9yVUusprVexclUYW9o797RgY4A4AkCAIkhvhf/2BMuXPnzjcDEMIcnJsXNkUoCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggEAKAvkpbMMmCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggAACCCCAAAIIIIAAAggggIAlQAASFwICCCCAAAIIIIAAAggggAACCCCA...pANAUBAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgACBUgUEkErtvLoJECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQI1CAggFQDoikIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIlCoggFRq59VNgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAoAYBAaQaEE1BgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAoFQBAaRSO69uAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAjUICCDVgGgKAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAqUKCCCV2nl1EyBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIEKhB4P8AEeY6X3AIh3YAAAAASUVORK5CYII= because it does not appear in the frame-src directive of the Content Security Policy.```

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-AU"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3.1 Safari/605.1.15"",
    ""vendor"": ""Apple Computer, Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""mysql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v1.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

annoying

### Additional context

_No response_",rognstad,2024-03-13 17:27:47+00:00,['ranquild'],2024-03-15 11:14:05+00:00,2024-03-15 11:13:51+00:00,https://github.com/metabase/metabase/issues/40095,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]",[],
2184536780,issue,closed,completed,Make sync work correctly in Druid JDBC,"That would entail at least porting sync tests from non-JDBC Druid driver.

At the time of writing `:schema` sync _seems_ to work correctly. There's a non handeled exception during `:full` sync.",lbrdnk,2024-03-13 17:25:24+00:00,['lbrdnk'],2024-03-19 22:36:06+00:00,2024-03-19 22:36:05+00:00,https://github.com/metabase/metabase/issues/40094,[],"[{'comment_id': 2008278106, 'issue_id': 2184536780, 'author': 'lbrdnk', 'body': 'Sync works as of https://github.com/metabase/metabase/commit/caf836f51240f2b18e6a29dd68ab33b46db2f727. Also full sync passes without exception.', 'created_at': datetime.datetime(2024, 3, 19, 22, 36, 5, tzinfo=datetime.timezone.utc)}]","lbrdnk (Issue Creator) on (2024-03-19 22:36:05 UTC): Sync works as of https://github.com/metabase/metabase/commit/caf836f51240f2b18e6a29dd68ab33b46db2f727. Also full sync passes without exception.

"
2184529008,issue,closed,completed,DateTime fields formatted inconsistently with CSV/XLSX/JSON downloads and email subscriptions,"### Describe the bug

I have a dashboard that includes a question with two DateTime fields. They are configured like this:
<img width=""293"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6739933/60e68d11-a712-4183-9a16-5983305d5911"">

When viewed within the Metabase application, they render as expected:
<img width=""461"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6739933/13877d0c-5f7d-4ff0-ac57-3911b4a4032c"">

When downloading the card's data from the dashboard, Excel correctly renders the second column but not the first:
<img width=""726"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6739933/bbc1dcb4-14ae-401c-8a7a-1de02e184b3c"">
The data is all there for the first column, though. If I manually change the formatting of the cells to include the time, then it displays as expected.

CSV and JSON download results in text that doesn't match my chosen format at all. Instead the DateTimes are formatted like  YYYY-MM-DDTHH:MM:SS:
<img width=""375"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6739933/7c59d858-a8eb-4335-95d4-cebae14ff326"">

If instead of using the download card feature I setup a subscription for the dashboard, I get a 4th format in the email that only shows the date, no time information:
<img width=""443"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6739933/158ee755-9f66-4a8f-b316-442242e3106a"">

If I look at the attachment to that email, I get a 5th format:
<img width=""317"" alt=""image"" src=""https://github.com/metabase/metabase/assets/6739933/d487948d-72df-4a8b-ab59-952f34e9f651"">
Like with CSV, it is using YYYY-MM-DDTHH:MM:SS, but it adds a Z at the end, indicating that this is in UTC (though it still shows the same hour as in all the other contexts, which have been localized to the user's timezone).

### To Reproduce

1. Format a DateTime field on a card on a dashboard
2. Download as CSV
3. Download as JSON
4. Download as Excel
5. Check the HTML body and attachment of an emailed subscription to the dashboard

You will see many different formats for the column

### Expected behavior

The text in all contexts should match the way it displays within the Metabase application (i.e. the way the column is configured)

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""en-US"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""java.vendor"": ""Ubuntu"",
    ""java.vendor.url"": ""https://ubuntu.com/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7-post-Ubuntu-0ubuntu220.04.1"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-1052-aws"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Etc/UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""bigquery-cloud-sdk"",
      ""mysql"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""13.13""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v1.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

It is merely annoying, but we're getting enough customer complaints that I need to update the cards to have columns formatted in SQL instead of relying on Metabase to do it

### Additional context

_No response_",rognstad,2024-03-13 17:20:47+00:00,[],2024-08-07 23:33:14+00:00,2024-08-07 23:32:14+00:00,https://github.com/metabase/metabase/issues/40093,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Reporting/Pulses', 'Now called Subscriptions'), ('.Backend', ''), ('.Team/DashViz', 'Dashboard and Viz team')]","[{'comment_id': 1995183890, 'issue_id': 2184529008, 'author': 'paoliniluis', 'body': ""I'm 95% sure this is fixed in v49 @rognstad"", 'created_at': datetime.datetime(2024, 3, 13, 17, 55, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274516774, 'issue_id': 2184529008, 'author': 'adam-james-v', 'body': '@rognstad, this is fixed in 49.3 (or later), but 49.10 or later contains a few fixes. So, I recommend upgrading to v49 if you can.', 'created_at': datetime.datetime(2024, 8, 7, 23, 32, 14, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-13 17:55:30 UTC): I'm 95% sure this is fixed in v49 @rognstad

adam-james-v on (2024-08-07 23:32:14 UTC): @rognstad, this is fixed in 49.3 (or later), but 49.10 or later contains a few fixes. So, I recommend upgrading to v49 if you can.

"
2184516548,issue,closed,not_planned,"[Epic] Let admins disable scheduled sync and manually trigger sync (for dbs, schemas, and tables)",[Product doc](https://www.notion.so/metabase/Grant-granular-sync-controls-to-admins-b9b465b09d53427996ff3f9f4ffd2f42?pvs=4),luizarakaki,2024-03-13 17:13:35+00:00,[],2025-01-06 14:57:03+00:00,2025-01-06 14:57:03+00:00,https://github.com/metabase/metabase/issues/40091,"[('Administration/Table Metadata', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2184302996,issue,closed,completed,Download Updated Translations for v49,,iethree,2024-03-13 15:30:34+00:00,['iethree'],2024-03-13 18:18:56+00:00,2024-03-13 18:18:56+00:00,https://github.com/metabase/metabase/issues/40086,[],[],
2184163830,issue,closed,not_planned,Invalid migration - Upgrade to v0.48 impossible when backed by MySQL database,"### Describe the bug

The MySQL migration file https://github.com/metabase/metabase/blob/master/resources/migrations/instance_analytics_views/subscriptions/v1/mysql-subscriptions.sql is not valid MySQL and breaks upgrading to v0.48.8 when backed by a MySQL database.

### To Reproduce

Copy paste migration SQL from https://github.com/metabase/metabase/blob/master/resources/migrations/instance_analytics_views/subscriptions/v1/mysql-subscriptions.sql in https://www.eversql.com/sql-syntax-check-validator/
> You have an error in your SQL syntax; it seems the error is around: 'CREATE OR REPLACE view v_subscriptions as ( select public_channel_id, ' at line 1

### Expected behavior

Database migration should be valid MySQL and work 

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""MacIntel"",
    ""userAgent"": ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.133+"",
    ""user.language"": ""en"",
    ""user.timezone"": ""UTC""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql"",
      ""bigquery-cloud-sdk"",
      ""postgres""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""mysql"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""MySQL"",
        ""version"": ""5.7.44-google""
      },
      ""jdbc-driver"": {
        ""name"": ""MariaDB Connector/J"",
        ""version"": ""2.7.6""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2023-12-01"",
      ""tag"": ""v0.47.9"",
      ""branch"": ""?"",
      ""hash"": ""d05b06e""
    },
    ""settings"": {
      ""report-timezone"": ""Europe/Berlin""
    }
  }
}
```


### Severity

Medium

### Additional context

qsd",cdaguerre,2024-03-13 14:31:43+00:00,[],2024-03-13 16:42:42+00:00,2024-03-13 14:39:52+00:00,https://github.com/metabase/metabase/issues/40080,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1994555674, 'issue_id': 2184163830, 'author': 'paoliniluis', 'body': ""you need to jump to v48.8, don't go through each minor version"", 'created_at': datetime.datetime(2024, 3, 13, 14, 39, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 1994570557, 'issue_id': 2184163830, 'author': 'cdaguerre', 'body': ""@paoliniluis sorry for the typo but that's of course what I'm doing. I'm trying to upgrade from 0.47.7 to 0.48.8. Regardless, migrations of minor versions are still being run and invalid SQL will break upgrade to any version after 0.48... Could you re-open?"", 'created_at': datetime.datetime(2024, 3, 13, 14, 46, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 1994887618, 'issue_id': 2184163830, 'author': 'noahmoss', 'body': '@cdaguerre MySQL 5.7 is no longer supported by Metabase as its EOL was October 2023. Please upgrade to MySQL 8', 'created_at': datetime.datetime(2024, 3, 13, 16, 28, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 1994937968, 'issue_id': 2184163830, 'author': 'cdaguerre', 'body': 'ok thanks @noahmoss', 'created_at': datetime.datetime(2024, 3, 13, 16, 42, 40, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-13 14:39:52 UTC): you need to jump to v48.8, don't go through each minor version

cdaguerre (Issue Creator) on (2024-03-13 14:46:54 UTC): @paoliniluis sorry for the typo but that's of course what I'm doing. I'm trying to upgrade from 0.47.7 to 0.48.8. Regardless, migrations of minor versions are still being run and invalid SQL will break upgrade to any version after 0.48... Could you re-open?

noahmoss on (2024-03-13 16:28:44 UTC): @cdaguerre MySQL 5.7 is no longer supported by Metabase as its EOL was October 2023. Please upgrade to MySQL 8

cdaguerre (Issue Creator) on (2024-03-13 16:42:40 UTC): ok thanks @noahmoss

"
2184122555,issue,open,,Ability to choose text/number size on Number viz type,"**Is your feature request related to a problem? Please describe.**
If you want to increase the size of the font, you need to increase the size of the card, but that doesn't scale to the expectations of some customers, specially when they want to put the dashboards in TVs around the office, for example. The following dashboard 
The following dashboard has a number card whose number can be much bigger than what it is:
![Screenshot 2024-03-13 at 11 10 28‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/d5afc433-5823-4137-8f10-ce1d965c0a59)

 but if you increase the card size, that doesn't make it much bigger and now you don't have space for other charts.

![Screenshot 2024-03-13 at 11 12 08‚ÄØAM](https://github.com/metabase/metabase/assets/132273646/5f018a63-a92f-4ad7-85ea-8404383f080d)

**Describe the solution you'd like**
Ability to choose the size of the font at a dashboard or question level

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer, internal ticket [25618](https://metabase.zendesk.com/agent/tickets/25618)

**Additional context**
N/A",ignacio-mb,2024-03-13 14:13:13+00:00,[],2024-07-05 18:29:52+00:00,,https://github.com/metabase/metabase/issues/40077,"[('Reporting/Dashboards', ''), ('Type:New Feature', ''), ('Visualization/Scalars', 'Numbers, progress bars, gauges')]","[{'comment_id': 2211264998, 'issue_id': 2184122555, 'author': 'yurioliveira3', 'body': 'I have the same trouble, but in my case, the font size is too large üò¢', 'created_at': datetime.datetime(2024, 7, 5, 18, 29, 51, tzinfo=datetime.timezone.utc)}]","yurioliveira3 on (2024-07-05 18:29:51 UTC): I have the same trouble, but in my case, the font size is too large üò¢

"
2184012429,issue,closed,completed,Apply Filters button cropped when a lot of values,"### Describe the bug

When there are a lot of values in the filter, the Apply Filters button is not visible until you scroll the whole lost and then scroll the second scroller to see it. This happens because form element is cropped by enclosing div.
<img width=""607"" alt=""Captura de ecraÃÉ 2024-03-13, aÃÄs 13 09 47"" src=""https://github.com/metabase/metabase/assets/777800/c919c572-8f94-4978-b7a2-013a5a37a048"">


### To Reproduce

1. Start new question
2. Choose Sample Database -> Accounts
3. Click on Filter button
4. Choose Country
5. You'll see a modal with filter values with 2 vertical scrollers, the second one will be scrolled to show the inactive Add Filter button, but the header will be cropped 
<img width=""376"" alt=""Captura de ecraÃÉ 2024-03-13, aÃÄs 13 14 30"" src=""https://github.com/metabase/metabase/assets/777800/8821fe67-3396-4248-8c78-0e6279079b67"">
6. Select any value and click on Add Filter, the modal will be closed
7. Click on the added filter button
8. You'll see a modal without Update Filter button visible, you have to scroll the whole list of values and scroll again to see it
<img width=""454"" alt=""Captura de ecraÃÉ 2024-03-13, aÃÄs 13 22 57"" src=""https://github.com/metabase/metabase/assets/777800/887fc1f6-b3cd-4130-8cae-76de335db7d9"">

### Expected behavior

The form with should not be cropped and put in the scroller at all, it should be visible full with the header and the button (Add Filter or Update Filter)

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

Might be blocking people from adding / editing filters

### Additional context

_No response_",mngr,2024-03-13 13:23:09+00:00,['ranquild'],2024-03-13 15:23:23+00:00,2024-03-13 15:20:18+00:00,https://github.com/metabase/metabase/issues/40071,"[('Type:Bug', 'Product defects'), ('.Needs Triage', ''), ('.Team/Querying', '')]",[],
2183936007,issue,closed,not_planned,Command run `java -jar metabase.jar` cannot get access to default H2 database,"### Describe the bug

I am unable to connect to the local database on Metabase hosting. It means I cannot host the web server instance. The log is below:  [metabase_log.txt](https://github.com/metabase/metabase/files/14587786/metabase_log.txt). It relates to following issue: https://github.com/metabase/metabase/issues/7700


### To Reproduce

1. Download metabase.jar from the URL: https://www.metabase.com/docs/latest/installation-and-operation/running-the-metabase-jar-file 
2. On Windows, search for the command prompt 'cmd';
3. Run the command 'java -jar metabase.jar' on the respective folder


### Expected behavior

Metabase must host using java

### Logs

I set the logs on file [metabase_log.txt](https://github.com/metabase/metabase/files/14587492/metabase_log.txt) on available bash logs.


### Information about your Metabase installation

```JSON
- Your operating system: Windows 11
- Metabase version: Latest jar file
- Metabase hosting environment: Jar-file on Windows
- Metabase internal database: default
```


### Severity

Silly

### Additional context

_No response_",brunolnetto,2024-03-13 12:47:51+00:00,[],2024-03-13 16:49:13+00:00,2024-03-13 12:59:22+00:00,https://github.com/metabase/metabase/issues/40068,"[('Type:Bug', 'Product defects'), ('.Needs Triage', '')]","[{'comment_id': 1994351826, 'issue_id': 2183936007, 'author': 'paoliniluis', 'body': 'this has been fixed in the last few days, so you should try with WSL 2 or wait till we release the new version', 'created_at': datetime.datetime(2024, 3, 13, 12, 59, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 1994376484, 'issue_id': 2183936007, 'author': 'brunolnetto', 'body': '1. Do you have any good tutorials to try with WSL 2? \r\n2. When will the next release happen?\r\n\r\nNote: Thanks for the presentation ""Metabase for Advanced Users"". :)', 'created_at': datetime.datetime(2024, 3, 13, 13, 12, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 1994961059, 'issue_id': 2183936007, 'author': 'darksciencebase', 'body': '@brunolnetto the next minor release with [this fix](https://github.com/metabase/metabase/pull/39739) is expected next week if nothing horrible happens', 'created_at': datetime.datetime(2024, 3, 13, 16, 49, 12, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-13 12:59:22 UTC): this has been fixed in the last few days, so you should try with WSL 2 or wait till we release the new version

brunolnetto (Issue Creator) on (2024-03-13 13:12:11 UTC): 1. Do you have any good tutorials to try with WSL 2? 
2. When will the next release happen?

Note: Thanks for the presentation ""Metabase for Advanced Users"". :)

darksciencebase on (2024-03-13 16:49:12 UTC): @brunolnetto the next minor release with [this fix](https://github.com/metabase/metabase/pull/39739) is expected next week if nothing horrible happens

"
2183845371,issue,closed,completed,[Epic] Seed new instances w/ an example dashboard,"**Links**
- product doc: [Seed new instances w/ an example dashboard](https://www.notion.so/metabase/Seed-new-instances-w-an-example-dashboard-18571f9ab18d41f882c39db92de3634d)
- eng doc: 
- feature branch: 

[Slack thread with some context](https://metaboat.slack.com/archives/C063Q3F1HPF/p1707322667352249)

**Implementation Plan**



```[tasklist]
### Tasks
- [ ] https://github.com/metabase/metabase/pull/40753
- [x] Add a setting with the sample dashboard ID for embedding use
- [ ] https://github.com/metabase/metabase/pull/41512
- [ ] https://github.com/metabase/metabase/pull/41519
```

The dashboard's ID will be 1.",npretto,2024-03-13 12:09:47+00:00,['calherries'],2024-04-24 12:22:15+00:00,2024-04-15 12:35:50+00:00,https://github.com/metabase/metabase/issues/40066,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2024802941, 'issue_id': 2183845371, 'author': 'npretto', 'body': 'Hey @crisptrutski, for the second part `Expose example dashboard to the frontend`  we were thinking about putting the id of the dashboard on a nullable admin-only setting, it should be the simplest solution for both the BE and the FE, let me know what you think.', 'created_at': datetime.datetime(2024, 3, 28, 9, 53, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2024865293, 'issue_id': 2183845371, 'author': 'crisptrutski', 'body': '@npretto yes I saw that in the product doc, and it makes sense to me. it could also help with filtering out the corresponding audit events.\r\n\r\nFYI @calherries has picked up the task from me', 'created_at': datetime.datetime(2024, 3, 28, 10, 28, 18, tzinfo=datetime.timezone.utc)}]","npretto (Issue Creator) on (2024-03-28 09:53:02 UTC): Hey @crisptrutski, for the second part `Expose example dashboard to the frontend`  we were thinking about putting the id of the dashboard on a nullable admin-only setting, it should be the simplest solution for both the BE and the FE, let me know what you think.

crisptrutski on (2024-03-28 10:28:18 UTC): @npretto yes I saw that in the product doc, and it makes sense to me. it could also help with filtering out the corresponding audit events.

FYI @calherries has picked up the task from me

"
2183774090,issue,closed,completed,Cannot edit a custom field named like the column it's referencing,"### Describe the bug


https://github.com/metabase/metabase/assets/6830683/79b1d8a3-767e-4d8f-bf32-6ec7c5c8cf93



### To Reproduce

1. Start a new question based on Orders table from Sample DB
2. Add a custom column referencing the Tax field (example expression: `[Tax] * 100`), call it ""Tax"", click ""Done""
3. Click to edit that custom column
4. Focus the name input

Error is displayed under custom expression input


### Expected behavior

Either:
- the error should not be displayed, or
- it should not be possible to add a custom column named like the column it's referencing

If the second bullet point is how it should work, then we should also make sure this works when a column name is changed via Admin > Table Metadata to a name that is used by an existing custom expression.

### Information about your Metabase installation

master, f0afae8ca7


### Severity

P2
",kamilmielnik,2024-03-13 11:33:26+00:00,['ranquild'],2024-06-27 10:09:27+00:00,2024-06-25 13:25:44+00:00,https://github.com/metabase/metabase/issues/40064,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Frontend', ''), ('Querying/Notebook/Custom Expression', ''), ('.Team/Querying', '')]","[{'comment_id': 1994506136, 'issue_id': 2183774090, 'author': 'bshepherdson', 'body': ""There's been some other bugs related to custom column name collisions lately. I thought it should be renaming them to `tax_2`?\r\n\r\nActually I think I'm remembering that from the `Extract` drill thru; that logic should just go in `Lib.expression` for any added expression."", 'created_at': datetime.datetime(2024, 3, 13, 14, 14, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2194299190, 'issue_id': 2183774090, 'author': 'github-actions[bot]', 'body': 'üöÄ This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)', 'created_at': datetime.datetime(2024, 6, 27, 10, 9, 26, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-03-13 14:14:51 UTC): There's been some other bugs related to custom column name collisions lately. I thought it should be renaming them to `tax_2`?

Actually I think I'm remembering that from the `Extract` drill thru; that logic should just go in `Lib.expression` for any added expression.

github-actions[bot] on (2024-06-27 10:09:26 UTC): üöÄ This should also be released by [v0.50.8](https://github.com/metabase/metabase/milestone/246)

"
2183607908,issue,open,,Extracting dates based on a custom column breakout does not work,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/2c92525e-a2e0-49f1-bc76-515e822e4c9b



### To Reproduce

1. Create a question based on Orders table from Sample DB
2. Add a custom column with expression `[Created At]`, name it whatever you want
3. Add a ""Count"" aggregation
4. Add a breakout based on the custom column
5. Visualize the query
6. Change visualization to table
7. Use extract year drill on the breakout column


### Expected behavior

Query should not fail

### Logs

```
Column ""source.""""Created at 2"""""" must be in the GROUP BY list; SQL statement:
-- Metabase:: userID: 1 queryType: MBQL queryHash: 0bf70dd352618614c25ef1b38008b67256fe556e7960dcc69f434545bb253e2d
SELECT ""source"".""Created at 2"" AS ""Created at 2"", ""source"".""count"" AS ""count"", ""source"".""Year"" AS ""Year"" FROM (SELECT ""source"".""Created at 2"" AS ""Created at 2"", ""source"".""count"" AS ""count"", CAST(extract(year from ""source"".""Created at 2"") AS integer) AS ""Year"" FROM (SELECT CAST(""source"".""Created at 2"" AS date) AS ""Created at 2"", COUNT(*) AS ""count"" FROM (SELECT ""PUBLIC"".""ORDERS"".""CREATED_AT"" AS ""CREATED_AT"", ""PUBLIC"".""ORDERS"".""CREATED_AT"" AS ""Created at 2"" FROM ""PUBLIC"".""ORDERS"" LEFT JOIN ""PUBLIC"".""PEOPLE"" AS ""PEOPLE__via__USER_ID"" ON ""PUBLIC"".""ORDERS"".""USER_ID"" = ""PEOPLE__via__USER_ID"".""ID"") AS ""source"" GROU [90016-214]
```

### Information about your Metabase installation

`master` at fd6fab28ca


### Severity

P2
",kamilmielnik,2024-03-13 10:12:56+00:00,[],2025-02-04 20:27:36+00:00,,https://github.com/metabase/metabase/issues/40061,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('.Backend', ''), ('Querying/', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Wanted: MLv2', 'Issues that will be fixed (or easier to fix, or possible to fix) when we have MLv2'), ('.Team/Querying', '')]","[{'comment_id': 1994479661, 'issue_id': 2183607908, 'author': 'bshepherdson', 'body': ""This is not actually related to the new drill, it's a separate and long-standing bug.\r\n\r\nYou can reproduce it like this as well, without the Extract action:\r\n![2024-03-13-100037_1417x1222_scrot](https://github.com/metabase/metabase/assets/157812/21c8a04a-8e6f-4494-bc17-2d184084f541)\r\n![2024-03-13-100053_920x496_scrot](https://github.com/metabase/metabase/assets/157812/b51cb153-13ff-4902-994c-f6c6cb88b999)\r\ngives the same error.\r\n\r\nThis is a QP issue, and we should fix it someday, but it's for Bug Mountain and not for the Extract epic, I think."", 'created_at': datetime.datetime(2024, 3, 13, 14, 1, 57, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-03-13 14:01:57 UTC): This is not actually related to the new drill, it's a separate and long-standing bug.

You can reproduce it like this as well, without the Extract action:
![2024-03-13-100037_1417x1222_scrot](https://github.com/metabase/metabase/assets/157812/21c8a04a-8e6f-4494-bc17-2d184084f541)
![2024-03-13-100053_920x496_scrot](https://github.com/metabase/metabase/assets/157812/b51cb153-13ff-4902-994c-f6c6cb88b999)
gives the same error.

This is a QP issue, and we should fix it someday, but it's for Bug Mountain and not for the Extract epic, I think.

"
2183448321,issue,closed,not_planned,Chinese(China) Translation error,"### Describe the bug

There are some poor translation errors in the zh-CN.po file.

### To Reproduce

For example, 'msgstr[0] ""{0} Ë°å' has been translated as 'msgstr[0] ""{0} Ë°å\n""
""Â§çÊï∞Ôºö{0} Ë°å""'



### Expected behavior

_No response_

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase version 0.48.4
```


### Severity

I wrote a patch file based on the master branch.

### Additional context

[diff.patch](https://github.com/metabase/metabase/files/14585013/diff.patch)
",cnhongwei,2024-03-13 08:57:46+00:00,[],2025-01-10 18:31:18+00:00,2025-01-10 18:27:45+00:00,https://github.com/metabase/metabase/issues/40059,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Customization/i18n', ''), ('.Frontend', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 2583501237, 'issue_id': 2183448321, 'author': 'iethree', 'body': 'Thanks for noting this @cnhongwei ! Can you please submit translations through our [PoEditor Project](https://poeditor.com/join/project/ynjQmwSsGh)? Anything you update there will make it into our next major release.', 'created_at': datetime.datetime(2025, 1, 10, 18, 27, 45, tzinfo=datetime.timezone.utc)}]","iethree on (2025-01-10 18:27:45 UTC): Thanks for noting this @cnhongwei ! Can you please submit translations through our [PoEditor Project](https://poeditor.com/join/project/ynjQmwSsGh)? Anything you update there will make it into our next major release.

"
2183447781,issue,closed,completed,Proposal to make redshift testing more robust,"Currently, each test run on Redshift is isolated to the schema level, meaning all tests will operate on a single schema.

During testing we create a lot of datasets (test-data, sample-dataset, Tupac-insights... etc.); this leads to a problem in that these databases, when synced, will include all the tables in the current schema. 

E.g.: if you need a test that operates on a custom dataset ( defined by `mt/defdataset`), the database for this custom dataset, when synced, will contain all the tables that were created from other `deftest` (tables from test data, sample-dataset ... etc.). This is not ideal; each database for a custom dataset should only contain tables of that custom dataset.

Some ideas to tackle this:
1. Increase the isolation level to DB: make each test run(aka CI job) operate a newly created database. Each custom dataset should be created with a new schema. 
  - One downside of this is that we can only create 100 DBs per cluster, so it might not be enough if we have too many parallel runs.
2. Modify the sync code during the test so that when it syncs, it only includes tables from the current dataset. ",qnkhuat,2024-03-13 08:57:30+00:00,[],2024-03-20 19:57:05+00:00,2024-03-20 19:57:05+00:00,https://github.com/metabase/metabase/issues/40058,"[('Type:Tech Debt', 'or Refactoring'), ('.Performance', ''), ('Database/Redshift', None), ('.CI & Tests', ''), ('flaky-test-fix', '')]","[{'comment_id': 1993858406, 'issue_id': 2183447781, 'author': 'qnkhuat', 'body': ""IIRC, we have the same problem with any cloud DBs(bigquery, snowflake), so it's good to fix those too"", 'created_at': datetime.datetime(2024, 3, 13, 8, 58, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 1993986530, 'issue_id': 2183447781, 'author': 'tsmacdonald', 'body': 'NB: once this is fixed, respond to the comment in [the impersonation test](https://github.com/metabase/metabase/blob/f5cbb2078bb4ffd0c82a1083e216aff9667350e4/enterprise/backend/test/metabase_enterprise/advanced_permissions/driver/impersonation_test.clj#L133-L134) and the redshift test introduced in #40060.', 'created_at': datetime.datetime(2024, 3, 13, 9, 53, 39, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-03-13 08:58:07 UTC): IIRC, we have the same problem with any cloud DBs(bigquery, snowflake), so it's good to fix those too

tsmacdonald on (2024-03-13 09:53:39 UTC): NB: once this is fixed, respond to the comment in [the impersonation test](https://github.com/metabase/metabase/blob/f5cbb2078bb4ffd0c82a1083e216aff9667350e4/enterprise/backend/test/metabase_enterprise/advanced_permissions/driver/impersonation_test.clj#L133-L134) and the redshift test introduced in #40060.

"
2182918303,issue,closed,completed,Waiting for result tab title contains js code,"### Describe the bug

When opening a question that takes a while to load, the tab title is `e=>e?Z.t`Waiting for result...`
![Screenshot 2024-03-13 at 08 02 42](https://github.com/metabase/metabase/assets/25661381/4ff67a32-6408-493c-bdc6-3ac154d530af)
### To Reproduce

1. Create a long-running question or find one on starts
2. Open it
3. Check the tab title

### Expected behavior

Should be `Waiting for result` without the js code


### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

cosmetic

### Additional context

_No response_",qnkhuat,2024-03-13 01:02:21+00:00,['uladzimirdev'],2024-04-03 13:18:37+00:00,2024-04-03 10:48:40+00:00,https://github.com/metabase/metabase/issues/40051,"[('Type:Bug', 'Product defects'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Frontend', ''), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('.Team/Querying', '')]",[],
2182775218,issue,closed,completed,Fields are seemingly references by their position in an array,"### Describe the bug

When doing operations post-summarize, fields are seemingly references by their position in an array. This means that if you delete fields that were summarized, all of the fields that you reference beneath the summary are now potentially offset and wrong.


### To Reproduce

![image](https://github.com/metabase/metabase/assets/9262738/a722930b-2450-43ba-8d8f-ed37290dce1a)
`board_name` custom field is set to [Max of Board Name]
I deleted the `Max of Task Status` field from the summarization section
![image](https://github.com/metabase/metabase/assets/9262738/5e723364-d54d-4179-b5e2-1af6f574d5af)
now it's set to [max_3]
which doesn't reconcile
![image](https://github.com/metabase/metabase/assets/9262738/ffe8363f-37a0-463a-840a-f77241123b30)
and things that referenced [Max of Status Changed at] now reference [Max of Board Name]
Things that referenced [Max of Task Status] now reference [Max of Status Changed At] 
basically, instead of referencing a field name or some unique identifier, they're referencing by position in the summarized fields array
and so when you delete one, everything equal or higher in the array becomes offset

### Expected behavior

References should point to the right fields

### Logs

_No response_

### Information about your Metabase installation

```JSON
Metabase v46.2
```


### Severity

annoying

### Additional context

_No response_",meldiner,2024-03-12 22:09:22+00:00,['lbrdnk'],2024-08-20 19:25:21+00:00,2024-08-20 16:18:03+00:00,https://github.com/metabase/metabase/issues/40046,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/MBQL', ''), ('.Backend', ''), ('.Escalation', ''), ('.Team/Querying', '')]","[{'comment_id': 1994500111, 'issue_id': 2182775218, 'author': 'bshepherdson', 'body': ""You're exactly right about what's going on here. In legacy MBQL, aggregation references are done by an index into the aggregations list.\r\n\r\nMLv2 (new library and MBQL format) use UUIDs to reference aggregations, avoiding this problem. But legacy is still the source of truth in the appdb and on the wire, so we're not free of this bug yet."", 'created_at': datetime.datetime(2024, 3, 13, 14, 11, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995753024, 'issue_id': 2182775218, 'author': 'meldiner', 'body': '@bshepherdson, thanks for confirming. Do you expect updating metabase version to resolve this?', 'created_at': datetime.datetime(2024, 3, 13, 20, 46, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2005050709, 'issue_id': 2182775218, 'author': 'bshepherdson', 'body': 'I regret to say ""not yet"". I just checked this with the 0.49 RC and while the behavior has changed slightly (the expression is less broken after making the edit), this has not been fixed.\r\n\r\nThis is one of the diverse symptoms of a fundamental issue #36185 with how Metabase handles similar but not identical columns. There are lots of other ways to trip over this bug, such as joining the same table twice, or naming a custom column the same as a column from an earlier stage.\r\n\r\nWhen the first aggregation `max` is deleted, the two surviving ones are renamed from `max_2` and `max_3` to `max` and `max_2`. The expression in the second stage of the query has a reference like `[:field ""max_2""]`, which is still valid. We don\'t currently connect the dots that the ~artist~ column formerly known as `max_2` is now known as `max`.\r\n\r\nSo this won\'t be fixed in 49 or 50, but fixing that issue is one of my long-term goals. Much of the groundwork for it has landed over the past six months or so, but we\'re not ready to eliminate this issue yet.', 'created_at': datetime.datetime(2024, 3, 18, 21, 32, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284598597, 'issue_id': 2182775218, 'author': 'meldiner', 'body': 'Hello, @bshepherdson. Our customers are repeatedly encountering this issue, which makes the data in Metabase perceived as unreliable. This is a high-priority bug for us to fix.', 'created_at': datetime.datetime(2024, 8, 12, 17, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299271051, 'issue_id': 2182775218, 'author': 'meldiner', 'body': ""@lbrdnk, it looks like a fix for this one was merged. That's great!\r\n\r\nHow can I check the Metabase version where the fix will be available?"", 'created_at': datetime.datetime(2024, 8, 20, 16, 28, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299603738, 'issue_id': 2182775218, 'author': 'lbrdnk', 'body': ""@meldiner, backport was merged, hence the milestone was added to the issue. That's the version in which the fix will be present."", 'created_at': datetime.datetime(2024, 8, 20, 19, 25, 20, tzinfo=datetime.timezone.utc)}]","bshepherdson on (2024-03-13 14:11:59 UTC): You're exactly right about what's going on here. In legacy MBQL, aggregation references are done by an index into the aggregations list.

MLv2 (new library and MBQL format) use UUIDs to reference aggregations, avoiding this problem. But legacy is still the source of truth in the appdb and on the wire, so we're not free of this bug yet.

meldiner (Issue Creator) on (2024-03-13 20:46:47 UTC): @bshepherdson, thanks for confirming. Do you expect updating metabase version to resolve this?

bshepherdson on (2024-03-18 21:32:41 UTC): I regret to say ""not yet"". I just checked this with the 0.49 RC and while the behavior has changed slightly (the expression is less broken after making the edit), this has not been fixed.

This is one of the diverse symptoms of a fundamental issue #36185 with how Metabase handles similar but not identical columns. There are lots of other ways to trip over this bug, such as joining the same table twice, or naming a custom column the same as a column from an earlier stage.

When the first aggregation `max` is deleted, the two surviving ones are renamed from `max_2` and `max_3` to `max` and `max_2`. The expression in the second stage of the query has a reference like `[:field ""max_2""]`, which is still valid. We don't currently connect the dots that the ~artist~ column formerly known as `max_2` is now known as `max`.

So this won't be fixed in 49 or 50, but fixing that issue is one of my long-term goals. Much of the groundwork for it has landed over the past six months or so, but we're not ready to eliminate this issue yet.

meldiner (Issue Creator) on (2024-08-12 17:52:00 UTC): Hello, @bshepherdson. Our customers are repeatedly encountering this issue, which makes the data in Metabase perceived as unreliable. This is a high-priority bug for us to fix.

meldiner (Issue Creator) on (2024-08-20 16:28:07 UTC): @lbrdnk, it looks like a fix for this one was merged. That's great!

How can I check the Metabase version where the fix will be available?

lbrdnk (Assginee) on (2024-08-20 19:25:20 UTC): @meldiner, backport was merged, hence the milestone was added to the issue. That's the version in which the fix will be present.

"
2182640880,issue,closed,completed,Default value are not respected in cards (from 0.47.12 to 0.48.8 or 0.49.8),"### Describe the bug

I was following this bug because I though I had the same : https://github.com/metabase/metabase/issues/37831

But after upgrading I'm still experiencing similar issue.

I have a dashboard with several filters and no default values, it includes a card that have default values for one of these filters, it's working well in 0.47.12 but in 0.48.8 default values for the card is lost.

v0.47.12
- Dashboard filter : ""activity"" (dropdown, multiple values, not mandatory) that send it's values to each card filter ""activity""
- Card filter : ""activity"" (field filter mapped to relevant table/field, string, dropdown list, mandatory, 3 default values)

 v0.48.8
- Dashboard filter : ""activity"" (dropdown, multiple values, not mandatory) that send it's values to each card filter ""activity""
- Card filter : ""activity"" (field filter mapped to relevant table/field, string, dropdown list, mandatory, **no default values**)



### To Reproduce

1. Lauch a v0.47.12 instance
2. Create a card with a field filter and 3 default values
3. Add this card to a dashboard
4. Add a filter to this dashboard mapped to the card and the filter with default values
5. Test : the dashboard with no filter should show the card and results are filtered with default values
6. Upgrade to 0.48.8
7. Test : the dashboard show an error, the card can't display the result
8. Edit the card : default values are lost.
9. Rollaback to 0.47.12 (and restore a dump from this version)
10. Test : it's working again.

### Expected behavior

Default values should remain.

### Logs

_No response_

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.21+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.21"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.21+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""4.15.18-2-pve"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.2""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.5.4""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-01-16"",
      ""tag"": ""v0.47.12"",
      ""branch"": ""?"",
      ""hash"": ""bddbc8f""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```


### Severity

Blocking

### Additional context

Imo related to https://github.com/metabase/metabase/issues/37831
",prigal,2024-03-12 20:46:05+00:00,['wzimrin'],2025-01-22 15:56:26+00:00,2025-01-16 23:00:30+00:00,https://github.com/metabase/metabase/issues/40038,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('.Backend', ''), ('.Team/Querying', '')]","[{'comment_id': 1992584021, 'issue_id': 2182640880, 'author': 'paoliniluis', 'body': 'You‚Äôre saying that the fix didn‚Äôt work?', 'created_at': datetime.datetime(2024, 3, 12, 21, 2, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 1993965961, 'issue_id': 2182640880, 'author': 'perivamsi', 'body': ""I don't think we backported https://github.com/metabase/metabase/pull/39156 to 48.8, only to 49"", 'created_at': datetime.datetime(2024, 3, 13, 9, 42, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 1994354164, 'issue_id': 2182640880, 'author': 'paoliniluis', 'body': 'gotcha, closing then', 'created_at': datetime.datetime(2024, 3, 13, 13, 0, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995086840, 'issue_id': 2182640880, 'author': 'prigal', 'body': '@paoliniluis  the issue is linked to milestone 0.48.8 and you put it in the official release changelog.\r\n\r\n-> https://github.com/metabase/metabase/releases/tag/v0.48.8\r\n\r\n> Default values are not respected for pinned questions in collections in v48 (https://github.com/metabase/metabase/issues/37831)\r\n\r\n_Note : This is why I did my upgrade initially, I was following the issue._', 'created_at': datetime.datetime(2024, 3, 13, 17, 26, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995878334, 'issue_id': 2182640880, 'author': 'perivamsi', 'body': '@prigal that might have been linked to 0.48.8 by mistake, sorry about that.', 'created_at': datetime.datetime(2024, 3, 13, 21, 25, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995908884, 'issue_id': 2182640880, 'author': 'perivamsi', 'body': 'Actually, @iethree found this commit which should have fixed this issue in 48.8 https://github.com/metabase/metabase/pull/39072\r\n\r\nreopening this issue', 'created_at': datetime.datetime(2024, 3, 13, 21, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2098238812, 'issue_id': 2182640880, 'author': 'prigal', 'body': 'Hi all.\r\n\r\nI did a new test today migrating from 0.47.12 to 0.49.8, problem is exactly the same.\r\n\r\n@perivamsi you linked this with #39072 but in my case it\'s not a pinned question, it\'s a question in a dashboard.\r\n\r\nDashboard view of the question : \r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/1a152326-9d6f-4470-835b-05437954e17e)\r\n\r\nWhen clicking on question title to see more things : \r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/fbf2f961-c950-4d8d-9066-11344a9b2342)\r\n\r\n\r\n```json\r\n{\r\n  ""browser-info"": {\r\n    ""language"": ""fr-FR"",\r\n    ""platform"": ""Linux x86_64"",\r\n    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",\r\n    ""vendor"": ""Google Inc.""\r\n  },\r\n  ""system-info"": {\r\n    ""file.encoding"": ""UTF-8"",\r\n    ""java.runtime.name"": ""OpenJDK Runtime Environment"",\r\n    ""java.runtime.version"": ""11.0.23+9"",\r\n    ""java.vendor"": ""Eclipse Adoptium"",\r\n    ""java.vendor.url"": ""https://adoptium.net/"",\r\n    ""java.version"": ""11.0.23"",\r\n    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",\r\n    ""java.vm.version"": ""11.0.23+9"",\r\n    ""os.name"": ""Linux"",\r\n    ""os.version"": ""6.1.56-82.125.amzn2023.x86_64"",\r\n    ""user.language"": ""en"",\r\n    ""user.timezone"": ""Europe/Monaco""\r\n  },\r\n  ""metabase-info"": {\r\n    ""databases"": [\r\n      ""mysql""\r\n    ],\r\n    ""hosting-env"": ""unknown"",\r\n    ""application-database"": ""postgres"",\r\n    ""application-database-details"": {\r\n      ""database"": {\r\n        ""name"": ""PostgreSQL"",\r\n        ""version"": ""14.3""\r\n      },\r\n      ""jdbc-driver"": {\r\n        ""name"": ""PostgreSQL JDBC Driver"",\r\n        ""version"": ""42.7.2""\r\n      }\r\n    },\r\n    ""run-mode"": ""prod"",\r\n    ""version"": {\r\n      ""date"": ""2024-05-02"",\r\n      ""tag"": ""v0.49.8"",\r\n      ""hash"": ""38cb850""\r\n    },\r\n    ""settings"": {\r\n      ""report-timezone"": null\r\n    }\r\n  }\r\n}\r\n```', 'created_at': datetime.datetime(2024, 5, 7, 11, 59, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2114795645, 'issue_id': 2182640880, 'author': 'zbodi74', 'body': 'I reproduced this via a migration from 47.12 --> 49.10 . It seems this is more of a change in behavior, than a migration issue. Likely related to this one: https://github.com/metabase/metabase/issues/38857\r\n\r\nIn 47.12 i set up:\r\n* native question: `select * from people where {{ state }}`, field filter, state is ...; default - selected 3 values\r\n* dashboard: added the native question, added a dashboard filter wired to `state`, did not specify a default value for the filter\r\n\r\nBehavior in 47.12:\r\n* dashboard behavior when the filter is not used:\r\n   * card is shown with the card default filter values applied\r\n   * clicking on the card leads to: http://localhost:14712/question/1-gh37831-q?state=AL&state=AR&state=AZ\r\n\r\nAfter migration to 49.10:\r\n* native question: correctly migrated, default values are kept\r\n* dashboard: correctly migrated, no default values\r\n* dashboard behavior when the filter is not used:\r\n   * original dashboard URL gets rewritten as: http://localhost:14910/dashboard/1-gh37831-db?location=\r\n   * card is shown without any filtering (card default filter is not applied)\r\n   * clicking on the card leads to: http://localhost:14910/question/1-gh37831-q?state=\r\n\r\nIn 49.10, creating a new dashboard, adding the migrated question leads to the same behavior.', 'created_at': datetime.datetime(2024, 5, 16, 10, 13, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2165458189, 'issue_id': 2182640880, 'author': 'prigal', 'body': ""@zbodi74 Hi, I just would like to know if you have an idea when this issue will be adressed ?\r\n\r\nNote : I understand it's an open source project and I'm not blaming at all your work and the whole team work. I also understand it's often not appropriate to ask for delay in community projects but I'm stuck on 0.47.12 because of this issue and I really want to update and benefit from other new feature :) \r\n\r\nThank you !"", 'created_at': datetime.datetime(2024, 6, 13, 12, 2, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2183779089, 'issue_id': 2182640880, 'author': 'ranquild', 'body': 'The issue was introduced by https://github.com/metabase/metabase/pull/31891. It seems it was intentionally implemented.', 'created_at': datetime.datetime(2024, 6, 22, 4, 32, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2187068821, 'issue_id': 2182640880, 'author': 'calherries', 'body': ""@prigal While we sort this out here's a workaround that might work for you:\r\n\r\nAnywhere you have a required filter like\r\n```\r\nselect * from people where state = {{ state }}\r\n```\r\nYou should be able to use an optional filter to set a default value with the default values after the `--`:\r\n```\r\nselect * from people where state = [[{{ state }} --]] 'NY'\r\n```\r\n\r\nSetting defaults like this is documented [here in the docs](https://www.metabase.com/docs/latest/questions/native-editor/sql-parameters.html#setting-complex-default-values-in-the-query), except the docs don't explain how this can be used for setting defaults for cards in dashboards like this."", 'created_at': datetime.datetime(2024, 6, 24, 17, 29, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2197212731, 'issue_id': 2182640880, 'author': 'prigal', 'body': '@calherries thank you but I don\'t get how to do it with field filters. \r\n\r\nWith sample database : \r\n\r\n```\r\nSELECT\r\n  COUNT(*) AS ""count""\r\nFROM\r\n  ""PUBLIC"".""ORDERS""\r\nLEFT JOIN ""PUBLIC"".""PRODUCTS"" ON ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" = ""PRODUCTS"".""ID""\r\nWHERE\r\n 1=1 \r\n and {{categ}}\r\n```\r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/3959e783-7d55-4154-b424-bcd9f7f3ea6c)\r\n\r\nThis is my use case.', 'created_at': datetime.datetime(2024, 6, 28, 15, 47, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2218748579, 'issue_id': 2182640880, 'author': 'ixipixi', 'body': '@prigal You can do something like this with field filters:\r\n\r\n```\r\nSELECT\r\n  ""PUBLIC"".""ORDERS"".""ID"" AS ""ID"",\r\n  ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" AS ""PRODUCT_ID"",\r\n  ""PUBLIC"".""ORDERS"".""TOTAL"" AS ""TOTAL"",\r\nFROM\r\n  ""PUBLIC"".""ORDERS""\r\n  where [[{{field_filter }} --]] ""PUBLIC"".""ORDERS"".""ID""=0\r\n```\r\n\r\nSo if no value is provided to the field filter everything in the square brackets is omitted and the rest of the statement is evaluated.', 'created_at': datetime.datetime(2024, 7, 9, 21, 18, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2220357309, 'issue_id': 2182640880, 'author': 'prigal', 'body': '@ixipixi  This is working but very unclear / not suitable for end users.\r\n\r\nThis is the code : \r\n\r\n```\r\nSELECT\r\n  COUNT(*) AS ""count""\r\nFROM\r\n  ""PUBLIC"".""ORDERS""\r\nLEFT JOIN ""PUBLIC"".""PRODUCTS"" ON ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" = ""PRODUCTS"".""ID""\r\nWHERE\r\n 1=1 \r\n[[ and {{categ}} --]] and PRODUCTS.CATEGORY in (\'Gizmo\',\'Gadget\')\r\n```\r\n\r\nThis is what they see : \r\n![image](https://github.com/metabase/metabase/assets/895267/4a00afef-281b-4931-b0e9-d85bc4d1cff7)\r\n\r\nThey will think that we only have 9723 products in database because no selection is made. \r\n\r\nThey will have to select them all to have the correct count (this is not how metabase work on the other questions and that will be for sure confusing)\r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/3e235b36-0218-4f72-af07-44ab3be75a4e)\r\n\r\nIt\'s a workaround but not a suitable one, I will have to alter hundreds of questions to do this hack and when it will be correctly fixed, I will have to rollback all my modifications (and explain how to understand the result)\r\n\r\nI think this definitely need a real fix.', 'created_at': datetime.datetime(2024, 7, 10, 12, 15, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2221605663, 'issue_id': 2182640880, 'author': 'calherries', 'body': '@prigal can you describe exactly what behaviour you would like to see? Because the issues you described in the screenshots above are exactly how it used to work before in 0.47.12 and earlier.', 'created_at': datetime.datetime(2024, 7, 10, 22, 3, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2223408102, 'issue_id': 2182640880, 'author': 'prigal', 'body': ""What I want (what it use to be on 0.47.x) :\r\n\r\n- Create a question that count orders in my database using SQL and a field filter for product categories (count : 18760).\r\n![image](https://github.com/metabase/metabase/assets/895267/165b6e26-47b7-46bc-9953-db9dc49c00f7)\r\n\r\n\r\n- Define default filter on category on this question (Gizmo and Gadget), so when it's loaded, it's executed with this filter but the user can remove them or add filters with the UI. (9723)\r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/dc164e46-61de-448e-abd8-4e062e3b180f)\r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/d905f41e-9148-41e5-a60e-85a2a61760bd)\r\n\r\n- Then add this question to a dashboard\r\n![image](https://github.com/metabase/metabase/assets/895267/6dc724ce-2c27-41e9-ba72-eb2347122826)\r\n\r\neverything is good so far, question use the default values of category filter defined in the question.\r\n\r\n- Now add a dashboard filter mapped to this variable with no (default) value : \r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/05b399bd-1da5-4145-8386-6861a8f5ec60)\r\n\r\nNothing should have changed but when you validate you have this : \r\n\r\n![image](https://github.com/metabase/metabase/assets/895267/8cc80909-e45b-465e-b9d7-ed8f1c962b63)\r\n\r\ndefault filter set in question is no more respected..."", 'created_at': datetime.datetime(2024, 7, 11, 16, 41, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2224080924, 'issue_id': 2182640880, 'author': 'calherries', 'body': 'Thanks for adding this detail. I\'m trying to figure out if there\'s anything we can do here without breaking existing behaviour any more. \r\n\r\nIn the last screenshot, that\'s actually how we designed it to work in order to support clearing filters with default values. This was the issue that we solved by making this breaking change: https://github.com/metabase/metabase/issues/13961. In short, we don\'t apply the default values of the question in the last screenshot because we want to allow dashboard users to clear the filter. If we ""respected"" the question\'s defaults in the dashboard too it would be impossible to clear the filter values. And we can\'t make the dashboard filter magically inherit its connected question\'s default values because filters can be connected to two or more questions, each with different defaults.\r\n\r\nIn the screenshot without the dashboard filter, that\'s a different case. We chose to apply the question\'s default values as we did before, to preserve existing behaviour and avoid breaking more dashboards. In this case we don\'t have the problems I mentioned in the previous paragraph, because there\'s no dashboard filter:\r\n![image](https://github.com/user-attachments/assets/175304d4-b217-4aba-864e-287f744d38c4)\r\n\r\nIt\'s inconsistent for sure, and definitely confusing. But this is the design we came to that minimises breaking changes while solving the issue of not being able to clear filters in dashboards when question filters have default values.', 'created_at': datetime.datetime(2024, 7, 11, 22, 49, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2225245338, 'issue_id': 2182640880, 'author': 'prigal', 'body': ""I understand your point of view.\r\n\r\nMaybe I can add more context on why it's usefull actually for us, we have a main dashboard for our business : \r\n\r\n# My Business dahsboard\r\n\r\nFilter : Product Category \r\n\r\n## Q1 Total \r\n| Products sold  | Revenue |\r\n| ------------- | ------------- |\r\n| 127887  | 2 650 454 ‚Ç¨  |\r\n\r\n## Q2 Category Gizmo  \r\n| Products sold  | Revenue |\r\n| ------------- | ------------- |\r\n| 15487  | 1 650 454 ‚Ç¨  |\r\n\r\n## Q3 Category Gadget \r\n| Products sold  | Revenue |\r\n| ------------- | ------------- |\r\n| 15487  | 1 650 454 ‚Ç¨  |\r\n\r\n## Q4 By salesmen \r\n|   | Products sold  | Revenue |\r\n| ------------- | ------------- | ------------- |\r\n| Alan | 145  | 1 454 ‚Ç¨  |\r\n| Peter | 4555  | 12 454 ‚Ç¨  |\r\n| Hecto | 897845  | 1 125 454 ‚Ç¨  |\r\n\r\n## Q5 By channel \r\n|  | Products sold  | Revenue |\r\n| ------------- | ------------- | ------------- |\r\n| Facebook | 145  | 1 454 ‚Ç¨  |\r\n| Instagram | 4555  | 12 454 ‚Ç¨  |\r\n| Tiktok | 897845  | 1 125 454 ‚Ç¨  |\r\n\r\n\r\nThe Activity is not really relevant for the second and third question because they are already filtered, but can be usefull for by salesmen or by channel stats. This is why we use default filters for question 2 and 3."", 'created_at': datetime.datetime(2024, 7, 12, 10, 3, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442090139, 'issue_id': 2182640880, 'author': 'ranquild', 'body': ""@prigal We could use the default value from the native question if all of these following conditions are met:\n1. There is no default value for the dashboard parameter\n2. There is a default value for the question‚Äôs parameter\n3. The question‚Äôs parameter is **required**\n\nWould it solve your case? You won't need to modify SQL queries but you would have to make parameters in these queries explicitly required."", 'created_at': datetime.datetime(2024, 10, 28, 16, 38, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458041279, 'issue_id': 2182640880, 'author': 'ranquild', 'body': 'I think the fix should be on the BE instead. The reason is that if I do it on the FE, we would still to duplicate it on the BE for notifications.', 'created_at': datetime.datetime(2024, 11, 5, 19, 57, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458131395, 'issue_id': 2182640880, 'author': 'prigal', 'body': '@ranquild your proposition should work ! This is already the case on all my questions (required parameter with default value)', 'created_at': datetime.datetime(2024, 11, 5, 20, 53, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472919690, 'issue_id': 2182640880, 'author': 'prigal', 'body': ""@ranquild do you know if your suggestion has been discussed and will be implemented in a future version ? You gave me some hope :) Thank you ! \n\nEdit : I missed the link to the PR, that's great ! Thanks."", 'created_at': datetime.datetime(2024, 11, 13, 9, 12, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607624538, 'issue_id': 2182640880, 'author': 'prigal', 'body': ""@wzimrin üëç \n\nThank you, almost a year without updating Metabase, can't wait for 0.52.7.\n\nWe will try a migration from 0.47.12 on a staging env to check if everything is still ok !"", 'created_at': datetime.datetime(2025, 1, 22, 15, 56, 25, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-12 21:02:23 UTC): You‚Äôre saying that the fix didn‚Äôt work?

perivamsi on (2024-03-13 09:42:53 UTC): I don't think we backported https://github.com/metabase/metabase/pull/39156 to 48.8, only to 49

paoliniluis on (2024-03-13 13:00:32 UTC): gotcha, closing then

prigal (Issue Creator) on (2024-03-13 17:26:52 UTC): @paoliniluis  the issue is linked to milestone 0.48.8 and you put it in the official release changelog.

-> https://github.com/metabase/metabase/releases/tag/v0.48.8


_Note : This is why I did my upgrade initially, I was following the issue._

perivamsi on (2024-03-13 21:25:18 UTC): @prigal that might have been linked to 0.48.8 by mistake, sorry about that.

perivamsi on (2024-03-13 21:37:54 UTC): Actually, @iethree found this commit which should have fixed this issue in 48.8 https://github.com/metabase/metabase/pull/39072

reopening this issue

prigal (Issue Creator) on (2024-05-07 11:59:14 UTC): Hi all.

I did a new test today migrating from 0.47.12 to 0.49.8, problem is exactly the same.

@perivamsi you linked this with #39072 but in my case it's not a pinned question, it's a question in a dashboard.

Dashboard view of the question : 

![image](https://github.com/metabase/metabase/assets/895267/1a152326-9d6f-4470-835b-05437954e17e)

When clicking on question title to see more things : 

![image](https://github.com/metabase/metabase/assets/895267/fbf2f961-c950-4d8d-9066-11344a9b2342)


```json
{
  ""browser-info"": {
    ""language"": ""fr-FR"",
    ""platform"": ""Linux x86_64"",
    ""userAgent"": ""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.23+9"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.23"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.23+9"",
    ""os.name"": ""Linux"",
    ""os.version"": ""6.1.56-82.125.amzn2023.x86_64"",
    ""user.language"": ""en"",
    ""user.timezone"": ""Europe/Monaco""
  },
  ""metabase-info"": {
    ""databases"": [
      ""mysql""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""14.3""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.7.2""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-05-02"",
      ""tag"": ""v0.49.8"",
      ""hash"": ""38cb850""
    },
    ""settings"": {
      ""report-timezone"": null
    }
  }
}
```

zbodi74 on (2024-05-16 10:13:59 UTC): I reproduced this via a migration from 47.12 --> 49.10 . It seems this is more of a change in behavior, than a migration issue. Likely related to this one: https://github.com/metabase/metabase/issues/38857

In 47.12 i set up:
* native question: `select * from people where {{ state }}`, field filter, state is ...; default - selected 3 values
* dashboard: added the native question, added a dashboard filter wired to `state`, did not specify a default value for the filter

Behavior in 47.12:
* dashboard behavior when the filter is not used:
   * card is shown with the card default filter values applied
   * clicking on the card leads to: http://localhost:14712/question/1-gh37831-q?state=AL&state=AR&state=AZ

After migration to 49.10:
* native question: correctly migrated, default values are kept
* dashboard: correctly migrated, no default values
* dashboard behavior when the filter is not used:
   * original dashboard URL gets rewritten as: http://localhost:14910/dashboard/1-gh37831-db?location=
   * card is shown without any filtering (card default filter is not applied)
   * clicking on the card leads to: http://localhost:14910/question/1-gh37831-q?state=

In 49.10, creating a new dashboard, adding the migrated question leads to the same behavior.

prigal (Issue Creator) on (2024-06-13 12:02:14 UTC): @zbodi74 Hi, I just would like to know if you have an idea when this issue will be adressed ?

Note : I understand it's an open source project and I'm not blaming at all your work and the whole team work. I also understand it's often not appropriate to ask for delay in community projects but I'm stuck on 0.47.12 because of this issue and I really want to update and benefit from other new feature :) 

Thank you !

ranquild on (2024-06-22 04:32:13 UTC): The issue was introduced by https://github.com/metabase/metabase/pull/31891. It seems it was intentionally implemented.

calherries on (2024-06-24 17:29:32 UTC): @prigal While we sort this out here's a workaround that might work for you:

Anywhere you have a required filter like
```
select * from people where state = {{ state }}
```
You should be able to use an optional filter to set a default value with the default values after the `--`:
```
select * from people where state = [[{{ state }} --]] 'NY'
```

Setting defaults like this is documented [here in the docs](https://www.metabase.com/docs/latest/questions/native-editor/sql-parameters.html#setting-complex-default-values-in-the-query), except the docs don't explain how this can be used for setting defaults for cards in dashboards like this.

prigal (Issue Creator) on (2024-06-28 15:47:42 UTC): @calherries thank you but I don't get how to do it with field filters. 

With sample database : 

```
SELECT
  COUNT(*) AS ""count""
FROM
  ""PUBLIC"".""ORDERS""
LEFT JOIN ""PUBLIC"".""PRODUCTS"" ON ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" = ""PRODUCTS"".""ID""
WHERE
 1=1 
 and {{categ}}
```

![image](https://github.com/metabase/metabase/assets/895267/3959e783-7d55-4154-b424-bcd9f7f3ea6c)

This is my use case.

ixipixi on (2024-07-09 21:18:38 UTC): @prigal You can do something like this with field filters:

```
SELECT
  ""PUBLIC"".""ORDERS"".""ID"" AS ""ID"",
  ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" AS ""PRODUCT_ID"",
  ""PUBLIC"".""ORDERS"".""TOTAL"" AS ""TOTAL"",
FROM
  ""PUBLIC"".""ORDERS""
  where [[{{field_filter }} --]] ""PUBLIC"".""ORDERS"".""ID""=0
```

So if no value is provided to the field filter everything in the square brackets is omitted and the rest of the statement is evaluated.

prigal (Issue Creator) on (2024-07-10 12:15:30 UTC): @ixipixi  This is working but very unclear / not suitable for end users.

This is the code : 

```
SELECT
  COUNT(*) AS ""count""
FROM
  ""PUBLIC"".""ORDERS""
LEFT JOIN ""PUBLIC"".""PRODUCTS"" ON ""PUBLIC"".""ORDERS"".""PRODUCT_ID"" = ""PRODUCTS"".""ID""
WHERE
 1=1 
[[ and {{categ}} --]] and PRODUCTS.CATEGORY in ('Gizmo','Gadget')
```

This is what they see : 
![image](https://github.com/metabase/metabase/assets/895267/4a00afef-281b-4931-b0e9-d85bc4d1cff7)

They will think that we only have 9723 products in database because no selection is made. 

They will have to select them all to have the correct count (this is not how metabase work on the other questions and that will be for sure confusing)

![image](https://github.com/metabase/metabase/assets/895267/3e235b36-0218-4f72-af07-44ab3be75a4e)

It's a workaround but not a suitable one, I will have to alter hundreds of questions to do this hack and when it will be correctly fixed, I will have to rollback all my modifications (and explain how to understand the result)

I think this definitely need a real fix.

calherries on (2024-07-10 22:03:43 UTC): @prigal can you describe exactly what behaviour you would like to see? Because the issues you described in the screenshots above are exactly how it used to work before in 0.47.12 and earlier.

prigal (Issue Creator) on (2024-07-11 16:41:44 UTC): What I want (what it use to be on 0.47.x) :

- Create a question that count orders in my database using SQL and a field filter for product categories (count : 18760).
![image](https://github.com/metabase/metabase/assets/895267/165b6e26-47b7-46bc-9953-db9dc49c00f7)


- Define default filter on category on this question (Gizmo and Gadget), so when it's loaded, it's executed with this filter but the user can remove them or add filters with the UI. (9723)

![image](https://github.com/metabase/metabase/assets/895267/dc164e46-61de-448e-abd8-4e062e3b180f)

![image](https://github.com/metabase/metabase/assets/895267/d905f41e-9148-41e5-a60e-85a2a61760bd)

- Then add this question to a dashboard
![image](https://github.com/metabase/metabase/assets/895267/6dc724ce-2c27-41e9-ba72-eb2347122826)

everything is good so far, question use the default values of category filter defined in the question.

- Now add a dashboard filter mapped to this variable with no (default) value : 

![image](https://github.com/metabase/metabase/assets/895267/05b399bd-1da5-4145-8386-6861a8f5ec60)

Nothing should have changed but when you validate you have this : 

![image](https://github.com/metabase/metabase/assets/895267/8cc80909-e45b-465e-b9d7-ed8f1c962b63)

default filter set in question is no more respected...

calherries on (2024-07-11 22:49:44 UTC): Thanks for adding this detail. I'm trying to figure out if there's anything we can do here without breaking existing behaviour any more. 

In the last screenshot, that's actually how we designed it to work in order to support clearing filters with default values. This was the issue that we solved by making this breaking change: https://github.com/metabase/metabase/issues/13961. In short, we don't apply the default values of the question in the last screenshot because we want to allow dashboard users to clear the filter. If we ""respected"" the question's defaults in the dashboard too it would be impossible to clear the filter values. And we can't make the dashboard filter magically inherit its connected question's default values because filters can be connected to two or more questions, each with different defaults.

In the screenshot without the dashboard filter, that's a different case. We chose to apply the question's default values as we did before, to preserve existing behaviour and avoid breaking more dashboards. In this case we don't have the problems I mentioned in the previous paragraph, because there's no dashboard filter:
![image](https://github.com/user-attachments/assets/175304d4-b217-4aba-864e-287f744d38c4)

It's inconsistent for sure, and definitely confusing. But this is the design we came to that minimises breaking changes while solving the issue of not being able to clear filters in dashboards when question filters have default values.

prigal (Issue Creator) on (2024-07-12 10:03:53 UTC): I understand your point of view.

Maybe I can add more context on why it's usefull actually for us, we have a main dashboard for our business : 

# My Business dahsboard

Filter : Product Category 

## Q1 Total 
| Products sold  | Revenue |
| ------------- | ------------- |
| 127887  | 2 650 454 ‚Ç¨  |

## Q2 Category Gizmo  
| Products sold  | Revenue |
| ------------- | ------------- |
| 15487  | 1 650 454 ‚Ç¨  |

## Q3 Category Gadget 
| Products sold  | Revenue |
| ------------- | ------------- |
| 15487  | 1 650 454 ‚Ç¨  |

## Q4 By salesmen 
|   | Products sold  | Revenue |
| ------------- | ------------- | ------------- |
| Alan | 145  | 1 454 ‚Ç¨  |
| Peter | 4555  | 12 454 ‚Ç¨  |
| Hecto | 897845  | 1 125 454 ‚Ç¨  |

## Q5 By channel 
|  | Products sold  | Revenue |
| ------------- | ------------- | ------------- |
| Facebook | 145  | 1 454 ‚Ç¨  |
| Instagram | 4555  | 12 454 ‚Ç¨  |
| Tiktok | 897845  | 1 125 454 ‚Ç¨  |


The Activity is not really relevant for the second and third question because they are already filtered, but can be usefull for by salesmen or by channel stats. This is why we use default filters for question 2 and 3.

ranquild on (2024-10-28 16:38:02 UTC): @prigal We could use the default value from the native question if all of these following conditions are met:
1. There is no default value for the dashboard parameter
2. There is a default value for the question‚Äôs parameter
3. The question‚Äôs parameter is **required**

Would it solve your case? You won't need to modify SQL queries but you would have to make parameters in these queries explicitly required.

ranquild on (2024-11-05 19:57:01 UTC): I think the fix should be on the BE instead. The reason is that if I do it on the FE, we would still to duplicate it on the BE for notifications.

prigal (Issue Creator) on (2024-11-05 20:53:26 UTC): @ranquild your proposition should work ! This is already the case on all my questions (required parameter with default value)

prigal (Issue Creator) on (2024-11-13 09:12:10 UTC): @ranquild do you know if your suggestion has been discussed and will be implemented in a future version ? You gave me some hope :) Thank you ! 

Edit : I missed the link to the PR, that's great ! Thanks.

prigal (Issue Creator) on (2025-01-22 15:56:25 UTC): @wzimrin üëç 

Thank you, almost a year without updating Metabase, can't wait for 0.52.7.

We will try a migration from 0.47.12 on a staging env to check if everything is still ok !

"
2182632848,issue,closed,completed,Remove browse data > models from the release,"**Context**
[Slack thread](https://metaboat.slack.com/archives/C064EB1UE5P/p1710275830063739)
",luizarakaki,2024-03-12 20:40:35+00:00,['rafpaf'],2024-03-13 23:09:22+00:00,2024-03-13 23:09:21+00:00,https://github.com/metabase/metabase/issues/40037,"[('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/AdminWebapp', 'Admin and Webapp team'), ('Organization/Browse Data', '')]",[],
2182544878,issue,open,,Continue running queries even if they didn't finish when switching in between tabs,"**Is your feature request related to a problem? Please describe.**
A user may want to switch tabs when the cards in the current tab are not loading or taking some time to load and expect that when they switch tabs, the cards that didn't finish loading continue loading in the background. This is not the case currently:

https://www.loom.com/share/4ddaa2c09620449784004339efed4778?sid=4409470b-cc91-4f1d-ad5a-98572aa14059
What you should be seeing in this video is that cards in Tab 2 don't finish loading even if all cards in Tab 1 finished loading. Reproduction is in `49`.

**Describe the solution you'd like**
Queries to continue to run in the background even if you are not in the same tab, after you visited that tab you want the queries to run.

**Describe alternatives you've considered**
N/A

**How important is this feature to you?**
Requested by a customer in internal ticket [25488](https://metabase.zendesk.com/agent/tickets/25488)

**Additional context**
N/A
",ignacio-mb,2024-03-12 19:43:17+00:00,[],2024-06-05 14:40:14+00:00,,https://github.com/metabase/metabase/issues/40035,"[('Reporting/Dashboards', ''), ('Type:New Feature', '')]","[{'comment_id': 1992420323, 'issue_id': 2182544878, 'author': 'ignacio-mb', 'body': 'related to https://github.com/metabase/metabase/issues/39863', 'created_at': datetime.datetime(2024, 3, 12, 19, 46, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2150224884, 'issue_id': 2182544878, 'author': 'ignacio-mb', 'body': 'Strictly related to https://github.com/metabase/metabase/issues/40035 but not exactly the same. https://github.com/metabase/metabase/issues/33770 expects to run queries of other tabs after the first one finished loading, and this one expects to finish loading already executed queries from other tabs.', 'created_at': datetime.datetime(2024, 6, 5, 14, 40, 12, tzinfo=datetime.timezone.utc)}]","ignacio-mb (Issue Creator) on (2024-03-12 19:46:20 UTC): related to https://github.com/metabase/metabase/issues/39863

ignacio-mb (Issue Creator) on (2024-06-05 14:40:12 UTC): Strictly related to https://github.com/metabase/metabase/issues/40035 but not exactly the same. https://github.com/metabase/metabase/issues/33770 expects to run queries of other tabs after the first one finished loading, and this one expects to finish loading already executed queries from other tabs.

"
2182442052,issue,closed,completed,Add a route for getting collection perm graph by id," /api/collection/graph/collection/:collection-id. This route must also return a warnings key, a sibling to `:graph`, which indicates what sub-collections should show `read` or `edit` warnings.
 
 A warning should occur when the group is lacking access to a collection, but can `read` or `edit` one of its subcollections.
 
 Open Question: Should `edit` override `read` if we find both warnings in a non-accessable-collection's subcollections?",npfitz,2024-03-12 18:46:59+00:00,['escherize'],2024-07-15 16:53:03+00:00,2024-07-15 16:53:03+00:00,https://github.com/metabase/metabase/issues/40032,[],"[{'comment_id': 2228963288, 'issue_id': 2182442052, 'author': 'escherize', 'body': 'We moved away from this approach, and fixed it another way.', 'created_at': datetime.datetime(2024, 7, 15, 16, 53, 3, tzinfo=datetime.timezone.utc)}]","escherize (Assginee) on (2024-07-15 16:53:03 UTC): We moved away from this approach, and fixed it another way.

"
2182425892,issue,closed,completed,[Epic] Fix huge collection permission graphs,"There is some extra complexity here in that we must show a warning when the user has `read` or `edit` permissions to a sub collection with `none` permissions.

We are tackling this with multiple fixes:

**Implementation Plan**


- [x] parallelize permission graph lookup with a bounded thread pool
- [x] make collection permission graph revisions be recorded async
- [x] do not send back the entire perm graph on a PUT request
",escherize,2024-03-12 18:38:43+00:00,['escherize'],2024-07-15 21:02:41+00:00,2024-07-15 21:02:41+00:00,https://github.com/metabase/metabase/issues/40030,"[('.Epic', 'Feature Implementation or Project')]","[{'comment_id': 2080131149, 'issue_id': 2182425892, 'author': 'perivamsi', 'body': 'can be closed, duplicate of https://github.com/metabase/metabase/issues/36647', 'created_at': datetime.datetime(2024, 4, 26, 21, 18, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2081444218, 'issue_id': 2182425892, 'author': 'paoliniluis', 'body': '@perivamsi nope, this is for collection graphs, the other one is for data graphs', 'created_at': datetime.datetime(2024, 4, 28, 11, 37, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2081446995, 'issue_id': 2182425892, 'author': 'perivamsi', 'body': 'Are you sure? Both say permissions\r\n\r\n@escherize to confirm', 'created_at': datetime.datetime(2024, 4, 28, 11, 50, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2081639559, 'issue_id': 2182425892, 'author': 'paoliniluis', 'body': 'The 2 permission graphs are different', 'created_at': datetime.datetime(2024, 4, 28, 20, 15, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229429850, 'issue_id': 2182425892, 'author': 'escherize', 'body': 'This has been addressed by multiple recently merged PRs. \r\n\r\n- [Async coll perm graph revision](https://github.com/metabase/metabase/pull/45258)\r\n- [parallelize coll perm graph group lookup](https://github.com/metabase/metabase/pull/45256)\r\n- [add skip_graph to coll perm PUT](https://github.com/metabase/metabase/pull/45438)', 'created_at': datetime.datetime(2024, 7, 15, 21, 2, 41, tzinfo=datetime.timezone.utc)}]","perivamsi on (2024-04-26 21:18:47 UTC): can be closed, duplicate of https://github.com/metabase/metabase/issues/36647

paoliniluis on (2024-04-28 11:37:19 UTC): @perivamsi nope, this is for collection graphs, the other one is for data graphs

perivamsi on (2024-04-28 11:50:08 UTC): Are you sure? Both say permissions

@escherize to confirm

paoliniluis on (2024-04-28 20:15:20 UTC): The 2 permission graphs are different

escherize (Issue Creator) on (2024-07-15 21:02:41 UTC): This has been addressed by multiple recently merged PRs. 

- [Async coll perm graph revision](https://github.com/metabase/metabase/pull/45258)
- [parallelize coll perm graph group lookup](https://github.com/metabase/metabase/pull/45256)
- [add skip_graph to coll perm PUT](https://github.com/metabase/metabase/pull/45438)

"
2182331007,issue,open,,Todos in sql/query_processor: query correctness escaping `%` in `LIKE` clauses,"https://github.com/metabase/metabase/blob/e03cc6735bcff688950f5e97419200a809ecf836/src/metabase/driver/sql/query_processor.clj#L1057

and that usage in druid:
https://github.com/metabase/metabase/blob/4756228932a5ece8b2c714c0838611a4e2341f7b/modules/drivers/druid/src/metabase/driver/druid/query_processor.clj#L208",dpsutton,2024-03-12 17:54:50+00:00,[],2024-03-12 17:54:50+00:00,,https://github.com/metabase/metabase/issues/40025,"[('Type:Tech Debt', 'or Refactoring'), ('Querying/Processor', ''), ('.Correctness', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2182302400,issue,open,,Todos in sql/query_processor: assert and verify,"Some todos relating to asserting of the data flowing through. Let's investigate, assert, and add some tests

https://github.com/metabase/metabase/blob/e03cc6735bcff688950f5e97419200a809ecf836/src/metabase/driver/sql/query_processor.clj#L859

https://github.com/metabase/metabase/blob/e03cc6735bcff688950f5e97419200a809ecf836/src/metabase/driver/sql/query_processor.clj#L1377",dpsutton,2024-03-12 17:41:43+00:00,[],2024-03-12 17:41:43+00:00,,https://github.com/metabase/metabase/issues/40024,"[('Type:Tech Debt', 'or Refactoring'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2182285073,issue,open,,Clean up Schema Use in `models.dashboard-card`,"Several of the todos in comments in `metabase.models.dashboard-card` relate to using or improving our Malli schema use:

- [ ] validate `target` in `ParamMapping` schema
- [ ] use `ParamMapping` in the `NewDashboardCard` schema
- [ ] make the options for `NewDashboardCard` schema explicit

Since they're all related schema changes they should realistically be clustered together along with fixing any tests that start failing due to the schema tightening.",adam-james-v,2024-03-12 17:33:49+00:00,[],2024-03-12 17:33:49+00:00,,https://github.com/metabase/metabase/issues/40021,[],[],
2182274809,issue,open,,Todos in sql/query_processor: refactor,"Two refactor changes to `metabase.driver.sql.query-processor`

https://github.com/metabase/metabase/blob/e03cc6735bcff688950f5e97419200a809ecf836/src/metabase/driver/sql/query_processor.clj#L914

https://github.com/metabase/metabase/blob/e03cc6735bcff688950f5e97419200a809ecf836/src/metabase/driver/sql/query_processor.clj#L1343",dpsutton,2024-03-12 17:29:06+00:00,[],2024-03-12 17:29:07+00:00,,https://github.com/metabase/metabase/issues/40018,"[('Type:Tech Debt', 'or Refactoring'), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]",[],
2182268067,issue,open,,`metabase.models.pulse` address todos,"There are 2 todos in comments in `metabase.models.pulse`:

- [ ] we can use `t2/select` and `hydrate` directly instead of making a function `retrieve-pulse` - we can remove this fn
- [ ] validate everything like we do with pulse creation for alert creation too

Makes sense to cluster these 2 smaller changes into one PR, I think.",adam-james-v,2024-03-12 17:26:35+00:00,[],2024-03-12 17:26:36+00:00,,https://github.com/metabase/metabase/issues/40016,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', '')]",[],
2182264415,issue,open,,Consider removal of `metabase.query-processor.interface` namespace.,"Based on TODOs in `src/metabase/query_processor/interface.clj` complete removal of namespace residing in that file should be considered.

There are 2 vars only:
- `absolute-max-results`: this may be moved to `metabase.query-processor.middleware.limit`.
- `*disable-qp-logging*` is ""more trouble than it's worth"" according to comment. As it is in use, other way of handling for that would have to be found.
",lbrdnk,2024-03-12 17:24:50+00:00,[],2025-02-04 20:29:47+00:00,,https://github.com/metabase/metabase/issues/40015,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2182262837,issue,open,,Disable autoCommit inside `do-with-connection-with-options` for write connection options,"We set autoCommit to true for `(not write?)` but we should set it to false for `write?`

See this TODO
https://github.com/metabase/metabase/blob/2421226810087efc22ab5e6ce5b270836ec42686/src/metabase/driver/sql_jdbc/execute.clj#L364-L366",calherries,2024-03-12 17:24:06+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/40014,"[('Type:Tech Debt', 'or Refactoring'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2182255216,issue,open,,`metabase.models.card` todos - Slight refactoring + verifying permissions checks,"The `metabase.models.card` namespace has 4 todos which result in 4 tasks:

- [ ] moving `template-tag-parameters` somewhere that it can be used by both the backend and frontend
- [ ] decide if we should do verification of a card's query on `pre-insert`
- [ ] in the pre-insert, add a check to see if all id in `:parameter_mappings` are in `:parameters`
- [ ] check if we need to do a permissions check in `pre-update` OR if its done in the `PUT` endpoint?

These tasks are all independent, but might be nice to cluster together.",adam-james-v,2024-03-12 17:20:36+00:00,[],2024-03-12 17:20:36+00:00,,https://github.com/metabase/metabase/issues/40013,"[('Type:Tech Debt', 'or Refactoring'), ('.Backend', '')]",[],
2182244374,issue,closed,not_planned,Remove `set-best-transaction-level!`,"See this TODO: 
https://github.com/metabase/metabase/blob/2421226810087efc22ab5e6ce5b270836ec42686/src/metabase/driver/sql_jdbc/execute.clj#L233-L234",calherries,2024-03-12 17:15:44+00:00,[],2024-07-02 21:09:58+00:00,2024-07-02 21:09:57+00:00,https://github.com/metabase/metabase/issues/40012,"[('Type:Tech Debt', 'or Refactoring'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('Querying/', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template')]","[{'comment_id': 1992586962, 'issue_id': 2182244374, 'author': 'paoliniluis', 'body': 'Related to https://github.com/metabase/metabase/issues/39130', 'created_at': datetime.datetime(2024, 3, 12, 21, 4, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2204429834, 'issue_id': 2182244374, 'author': 'camsaul', 'body': 'Merging into #39130', 'created_at': datetime.datetime(2024, 7, 2, 21, 9, 57, tzinfo=datetime.timezone.utc)}]","paoliniluis on (2024-03-12 21:04:33 UTC): Related to https://github.com/metabase/metabase/issues/39130

camsaul on (2024-07-02 21:09:57 UTC): Merging into #39130

"
2182242151,issue,closed,not_planned,"[QP] [MLv2] Native models in dashboards can be linked to dashboard filters, but they don't actually filter","### Describe the bug

If I put a native model in a dashboard and link it to a dashboard filter, it won't actually have the filter applied. This can lead to subtly incorrect results!

### To Reproduce

1. Create a native model, say `SELECT * FROM Orders;`
2. Match the ID column in the model's metadata to the underlying `Orders.ID` field.
3. Add the model to a dashboard.
4. Add an ID filter with a default value, eg. `5`.
5. The model can be linked to that filter (it even auto-links!)
6. Save the dashboard so it runs the queries.
7. The query is not filtered; all rows are returned.

### Expected behavior

The model's results are properly filtered - in this case, returning just one row.

### Logs

_No response_

### Information about your Metabase installation

```JSON
master
```


### Severity

P2 - significant and should-fix for 0.50

### Additional context

Not a regression; same logic in 48.

Much easier to fix after `metabase.query-processor.middleware.parameters` is ported to MLv2.",bshepherdson,2024-03-12 17:14:42+00:00,[],2024-08-28 02:10:35+00:00,2024-07-10 18:18:57+00:00,https://github.com/metabase/metabase/issues/40011,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/Models', 'aka Datasets'), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib'), ('.Wanted: MLv2', 'Issues that will be fixed (or easier to fix, or possible to fix) when we have MLv2'), ('.Team/Querying', '')]","[{'comment_id': 2221159158, 'issue_id': 2182242151, 'author': 'ranquild', 'body': 'We disabled mapping of parameters to native models in dashboards in https://github.com/metabase/metabase/pull/44372', 'created_at': datetime.datetime(2024, 7, 10, 18, 18, 57, tzinfo=datetime.timezone.utc)}]","ranquild on (2024-07-10 18:18:57 UTC): We disabled mapping of parameters to native models in dashboards in https://github.com/metabase/metabase/pull/44372

"
2182238002,issue,open,,Create `do-with-(prepared-)statement` methods instead of using (prepared-)statement directly,"See this TODO

https://github.com/metabase/metabase/blob/2421226810087efc22ab5e6ce5b270836ec42686/src/metabase/driver/sql_jdbc/execute.clj#L125-L127",calherries,2024-03-12 17:12:47+00:00,[],2025-02-04 20:29:49+00:00,,https://github.com/metabase/metabase/issues/40010,"[('Type:Tech Debt', 'or Refactoring'), ('Priority:P3', 'Cosmetic bugs, minor bugs with a clear workaround'), ('.Backend', ''), ('Querying/', ''), ('.Task', 'Not a part of any Epic, used by the Task Issue Template'), ('.Team/Querying', '')]",[],
2182102004,issue,closed,completed,[Epic] Initial homepage experience for embedding admins,"**Links**
- product doc: [Initial homepage experience for embedding admins](https://www.notion.so/metabase/Initial-homepage-experience-for-embedding-admins-9431f50fdf3a4f63b291dc801349c335)
- eng doc: [Initial homepage experience for embedding admins](https://www.notion.so/metabase/Initial-homepage-experience-for-embedding-admins-was-Meet-embedders-at-the-door-full-version-63fa3a8e07634c9faf67d5bdd5a2df08)
- feature branch: `embed-homepage` / https://github.com/metabase/metabase/pull/40382



**Implementation Plan**

MS1: https://github.com/metabase/metabase/pull/40382

```[tasklist]
### MS 1 - Homepage without example dashboard -`embed-homepage`
- [ ] https://github.com/metabase/metabase/pull/40251
- [ ] https://github.com/metabase/metabase/pull/40455
- [ ] https://github.com/metabase/metabase/pull/40528
- [ ] https://github.com/metabase/metabase/pull/40587
- [x] double check unit tests and e2es (I'm actually writing them as I go)
- [ ] https://github.com/metabase/metabase/pull/40638
- [ ] https://github.com/metabase/metabase/pull/40813
```

MS2: https://github.com/metabase/metabase/pull/41180

```[tasklist]
### MS 2 - Add example dashboard reference
- [x] dependency on https://github.com/metabase/metabase/issues/40066
- [ ] https://github.com/metabase/metabase/pull/41138
```

```[tasklist]
### MS 3 - Dismiss with feedback - `embed-homepage-ms3`
- [x] dependency on https://github.com/metabase/harbormaster/issues/4783
- [ ] https://github.com/metabase/harbormaster/issues/4814
- [ ] https://github.com/metabase/metabase/pull/40746
- [ ] https://github.com/metabase/metabase/pull/40974
```

MS4: https://github.com/metabase/metabase/pull/41990
```[tasklist]
### MS 4 - Analytics + polishment - `embed-homepage-milestone4`
- [ ] https://github.com/metabase/metabase/pull/41575
- [ ] https://github.com/metabase/metabase/pull/41638
- [ ] https://github.com/metabase/metabase/pull/41644
- [ ] https://github.com/metabase/metabase/pull/41725
- [ ] https://github.com/metabase/metabase/pull/41784
- [ ] https://github.com/metabase/metabase/pull/42042
- [ ] https://github.com/metabase/metabase/pull/42200
- [x] [AFTER MERGING ON MASTER] snowplow ping about schema changes
```
",npretto,2024-03-12 16:21:15+00:00,['npretto'],2024-05-06 14:53:35+00:00,2024-05-06 14:53:34+00:00,https://github.com/metabase/metabase/issues/40005,"[('.Epic', 'Feature Implementation or Project'), ('.Team/Embedding', '')]",[],
2181895883,issue,closed,completed,Inconsistent spacing around table and schema divider,"Due to the way this component is structured, we have some inconsistent spacing in the data selector between the table name and the schema name.

Here it is zoomed in.
![image](https://github.com/metabase/metabase/assets/31325167/2b52b16d-a923-4d1b-9d7c-743929074649)

Notice the bigger gap on the left side of the `-`.
The text color is also different but this might have been intentional. I'll check with the design team.

",nemanjaglumac,2024-03-12 15:17:00+00:00,['nemanjaglumac'],2024-03-15 09:45:36+00:00,2024-03-15 09:16:30+00:00,https://github.com/metabase/metabase/issues/39999,"[('.CSS', ''), ('.Frontend', ''), ('.Team/Querying', '')]",[],
2181730130,issue,closed,completed,Backfilll QueryFields for existing cards,"Part of [ParseSQL](https://github.com/metabase/metabase/issues/36911).

We need a one-off task to create `QueryField` entries for cards. Currently QueryFields are only created when a card is created or its query is updated.

Open questions:

* Should this be done as part of the DB migration flow? Or elsewhere? Do we have prior art for one-off potentially-long-running tasks?
* Should we have any restrictions on this _not_ running? Cards that are old or not recently viewed or something?
* Any perms considerations? (I don't think so, but...)",tsmacdonald,2024-03-12 14:13:37+00:00,['piranha'],2024-04-30 09:24:05+00:00,2024-04-10 17:01:20+00:00,https://github.com/metabase/metabase/issues/39998,"[('.Team/Workflows', 'aka BEC'), ('Querying/Native/Parser', '')]","[{'comment_id': 1991844197, 'issue_id': 2181730130, 'author': 'luizarakaki', 'body': ""> Should this be done as part of the DB migration flow? Or elsewhere? Do we have prior art for one-off potentially-long-running tasks?\r\n\r\nI think so... This doesn't feel that bad performance-wise. _I think_ we did larger migrations on audit_log in the past\r\nVery large instances have ~100k questions (only a fraction are native queries). \r\n\r\n> Should we have any restrictions on this not running? Cards that are old or not recently viewed or something?\r\n\r\nI think we can safely ignore archived cards\r\n\r\n> Any perms considerations? (I don't think so, but...)\r\n\r\nYeah, I don't see any issue. This is also internal"", 'created_at': datetime.datetime(2024, 3, 12, 14, 54, 48, tzinfo=datetime.timezone.utc)}]","luizarakaki on (2024-03-12 14:54:48 UTC): I think so... This doesn't feel that bad performance-wise. _I think_ we did larger migrations on audit_log in the past
Very large instances have ~100k questions (only a fraction are native queries). 


I think we can safely ignore archived cards


Yeah, I don't see any issue. This is also internal

"
2181639301,issue,closed,completed,"Collection permission graph is slow because the collection perm graph response, and revision info are very large","### Describe the bug

The size of the the collection permissions graph grows quadratically with the number permission groups, and collections. So it can get rather large.

That slows things down when:

1) returning the entire collection permission graph
2) writing the json blob to the revisions table (see @escherize's comment below).

### To Reproduce

1) create a metabase instance with 5000 collections and probably 5000 groups and then make permissions change to these collections

### Expected behavior

Getting and setting permissions should be fast

### Logs

Same thing as data permissions, you can't insert or get permissions to collections

### Information about your Metabase installation

```JSON
Always been like this
```


### Severity

P1

### Additional context

_No response_",paoliniluis,2024-03-12 13:33:51+00:00,"['escherize', 'sloansparger']",2024-07-16 18:49:37+00:00,2024-07-16 03:26:44+00:00,https://github.com/metabase/metabase/issues/39997,"[('Type:Bug', 'Product defects'), ('Priority:P1', 'Security holes w/o exploit, crashing, setup/upgrade, login, broken common features, correctness'), ('.Performance', ''), ('Misc/API', ''), ('Administration/Permissions', 'Collection or Data permissions'), ('.Backend', ''), ('.Escalation', ''), ('.Team/AdminWebapp', 'Admin and Webapp team')]","[{'comment_id': 1998251288, 'issue_id': 2181639301, 'author': 'paoliniluis', 'body': ""A few tests and where it struggles:\r\n![image](https://github.com/metabase/metabase/assets/1711649/b084d598-b4ed-4bdf-989a-cdcdc18b4066)\r\n\r\nThe most interesting part of the entire issue: when we're doing this a single CPU is at 100%, when the container has 8vcpu's\r\n![image](https://github.com/metabase/metabase/assets/1711649/7c9a3517-d681-415f-a204-70fae8d3ce5a)"", 'created_at': datetime.datetime(2024, 3, 14, 19, 23, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998565334, 'issue_id': 2181639301, 'author': 'paoliniluis', 'body': ""Note for the MySQL people: as we're inserting a JSON in the database which can get pretty big, make sure that your MySQL will allow that"", 'created_at': datetime.datetime(2024, 3, 14, 22, 10, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998854200, 'issue_id': 2181639301, 'author': 'escherize', 'body': ""We found that this happens when inserting (in this case) 65mb string of json into the collection_permission_graph_revision table. That happens on every collection permissions update, in lock-step with revision number generation. \r\n\r\nIt is redundant and expensive: usually there's one or 2 changes per update, but we rewrite a new complete json string with the whole collection perm graph in there every time. I don't know what (if any) value we are getting from keep the prior versions of the permission graph around, otherwise we could outright remove it."", 'created_at': datetime.datetime(2024, 3, 15, 2, 59, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207434554, 'issue_id': 2181639301, 'author': 'escherize', 'body': 'Hey @paoliniluis, We\'ve audited the codebase and there isn\'t any code that reads the saved collection perm-graph out of the `collection_permission_graph_revision` table. Since it\'s the before column that can get very large with many `(permission-groups * collections)`, we are considering simply not updating it anymore.\r\n\r\nBut we need to be sure noone uses it. Do you know of anyone who _might_ use it?\r\n\r\n\r\nThe table for reference:\r\n```\r\n                       Table ""public.collection_permission_graph_revision""\r\n   Column   |           Type           | Collation | Nullable |             Default\r\n------------+--------------------------+-----------+----------+----------------------------------\r\n id         | integer                  |           | not null | generated by default as identity\r\n before     | text                     |           | not null |\r\n after      | text                     |           | not null |\r\n user_id    | integer                  |           | not null |\r\n created_at | timestamp with time zone |           | not null |\r\n remark     | text                     |           |          |\r\nIndexes:\r\n    ""collection_revision_pkey"" PRIMARY KEY, btree (id)\r\n    ""idx_collection_permission_graph_revision_user_id"" btree (user_id)\r\nForeign-key constraints:\r\n    ""fk_collection_revision_user_id"" FOREIGN KEY (user_id) REFERENCES core_user(id) ON DELETE CASCADE\r\n```', 'created_at': datetime.datetime(2024, 7, 3, 22, 49, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2207504015, 'issue_id': 2181639301, 'author': 'paoliniluis', 'body': '@escherize seems reasonable but let‚Äôs make sure that there‚Äôs audit info somewhere so we know who did what', 'created_at': datetime.datetime(2024, 7, 3, 23, 31, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2215478242, 'issue_id': 2181639301, 'author': 'escherize', 'body': ""@paoliniluis do you know how much faster this needs to be to actually fix the issue?\r\n\r\nIn any case, here are some low hanging fruits we can use to improve the performance on this endpoint:\r\n\r\n\r\n- [x] parallelize group permission lookups\r\n    - [x] [parallelize coll perm graph group lookup](https://github.com/metabase/metabase/pull/45256)\r\n- [x] use partial graph PUTs with the `skip_graph` query param\r\n    - [x] [add skip_graph to coll perm PUT](https://github.com/metabase/metabase/pull/45438)\r\n- [x] make coll perm graph revisions async\r\n    - [x] [Async coll perm graph revision](https://github.com/metabase/metabase/pull/45258)\r\n    \r\n    \r\nThis has been addressed by multiple recently merged PRs. While these changes greatly improve the performance for the collection permission graph endpoints, I can't say for certain that it will solve the customer's issue without more information."", 'created_at': datetime.datetime(2024, 7, 8, 22, 48, 16, tzinfo=datetime.timezone.utc)}]","paoliniluis (Issue Creator) on (2024-03-14 19:23:37 UTC): A few tests and where it struggles:
![image](https://github.com/metabase/metabase/assets/1711649/b084d598-b4ed-4bdf-989a-cdcdc18b4066)

The most interesting part of the entire issue: when we're doing this a single CPU is at 100%, when the container has 8vcpu's
![image](https://github.com/metabase/metabase/assets/1711649/7c9a3517-d681-415f-a204-70fae8d3ce5a)

paoliniluis (Issue Creator) on (2024-03-14 22:10:31 UTC): Note for the MySQL people: as we're inserting a JSON in the database which can get pretty big, make sure that your MySQL will allow that

escherize (Assginee) on (2024-03-15 02:59:42 UTC): We found that this happens when inserting (in this case) 65mb string of json into the collection_permission_graph_revision table. That happens on every collection permissions update, in lock-step with revision number generation. 

It is redundant and expensive: usually there's one or 2 changes per update, but we rewrite a new complete json string with the whole collection perm graph in there every time. I don't know what (if any) value we are getting from keep the prior versions of the permission graph around, otherwise we could outright remove it.

escherize (Assginee) on (2024-07-03 22:49:07 UTC): Hey @paoliniluis, We've audited the codebase and there isn't any code that reads the saved collection perm-graph out of the `collection_permission_graph_revision` table. Since it's the before column that can get very large with many `(permission-groups * collections)`, we are considering simply not updating it anymore.

But we need to be sure noone uses it. Do you know of anyone who _might_ use it?


The table for reference:
```
                       Table ""public.collection_permission_graph_revision""
   Column   |           Type           | Collation | Nullable |             Default
------------+--------------------------+-----------+----------+----------------------------------
 id         | integer                  |           | not null | generated by default as identity
 before     | text                     |           | not null |
 after      | text                     |           | not null |
 user_id    | integer                  |           | not null |
 created_at | timestamp with time zone |           | not null |
 remark     | text                     |           |          |
Indexes:
    ""collection_revision_pkey"" PRIMARY KEY, btree (id)
    ""idx_collection_permission_graph_revision_user_id"" btree (user_id)
Foreign-key constraints:
    ""fk_collection_revision_user_id"" FOREIGN KEY (user_id) REFERENCES core_user(id) ON DELETE CASCADE
```

paoliniluis (Issue Creator) on (2024-07-03 23:31:18 UTC): @escherize seems reasonable but let‚Äôs make sure that there‚Äôs audit info somewhere so we know who did what

escherize (Assginee) on (2024-07-08 22:48:16 UTC): @paoliniluis do you know how much faster this needs to be to actually fix the issue?

In any case, here are some low hanging fruits we can use to improve the performance on this endpoint:


- [x] parallelize group permission lookups
    - [x] [parallelize coll perm graph group lookup](https://github.com/metabase/metabase/pull/45256)
- [x] use partial graph PUTs with the `skip_graph` query param
    - [x] [add skip_graph to coll perm PUT](https://github.com/metabase/metabase/pull/45438)
- [x] make coll perm graph revisions async
    - [x] [Async coll perm graph revision](https://github.com/metabase/metabase/pull/45258)
    
    
This has been addressed by multiple recently merged PRs. While these changes greatly improve the performance for the collection permission graph endpoints, I can't say for certain that it will solve the customer's issue without more information.

"
2181484545,issue,closed,completed,Model's column order not saved,"### Describe the bug

https://github.com/metabase/metabase/assets/6830683/2f2e07c2-3b48-4039-b949-2c9df4e544d8



### To Reproduce

1. Create and save a new GUI question based on Accounts table from Sample DB
2. Turn the question into a model
3. Edit query definition
4. Add a custom column, e.g. using `1 + 1` expression
5. Run the query
6. Switch to Metadata tab
7. Drag & drop the new custom column and change its order
8. Save model
9. Visualization is opened

The new custom column is shown as last.

### Expected behavior

New custom column should be positioned according to order set in step 7

### Information about your Metabase installation

Reproducible in `master` at da96c24f80 and 0.49.0-RC2

Works in 0.48.7.

### Severity

P2
",kamilmielnik,2024-03-12 12:21:21+00:00,['ranquild'],2024-07-15 21:00:41+00:00,2024-07-05 19:41:38+00:00,https://github.com/metabase/metabase/issues/39993,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/GUI', 'Query builder catch-all, including simple mode'), ('.Regression', 'Bugs that were previously fixed and/or bugs unintentionally shipped with new features.'), ('Querying/Models', 'aka Datasets'), ('.Team/Querying', '')]","[{'comment_id': 2022744809, 'issue_id': 2181484545, 'author': 'uladzimirdev', 'body': ""~works fine for me on master a6684ac137 and in v49.0 (and even v49.0.RC2)~\r\n\r\nI still can reproduce it, I didn't follow one step during testing - that's why I got the correct result"", 'created_at': datetime.datetime(2024, 3, 27, 13, 17, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2206512403, 'issue_id': 2181484545, 'author': 'ranquild', 'body': 'So what happens is that in metadata editor we operate on field_refs within the query itself, but in chill mode we work with an ad-hoc questions. Field refs are different and that causes issues with matching viz settings.\r\n1 - Metadata editor\r\n<img width=""443"" alt=""Screenshot 2024-07-03 at 11 16 33"" src=""https://github.com/metabase/metabase/assets/8542534/8ee28504-617c-4710-bbf5-164a1813ad09"">\r\n2 - Chill mode\r\n<img width=""786"" alt=""Screenshot 2024-07-03 at 11 16 49"" src=""https://github.com/metabase/metabase/assets/8542534/f75fa1c5-fffe-44e2-8040-351048b6bb43"">', 'created_at': datetime.datetime(2024, 7, 3, 15, 18, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2229426536, 'issue_id': 2181484545, 'author': 'github-actions[bot]', 'body': 'üöÄ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)', 'created_at': datetime.datetime(2024, 7, 15, 21, 0, 40, tzinfo=datetime.timezone.utc)}]","uladzimirdev on (2024-03-27 13:17:59 UTC): ~works fine for me on master a6684ac137 and in v49.0 (and even v49.0.RC2)~

I still can reproduce it, I didn't follow one step during testing - that's why I got the correct result

ranquild (Assginee) on (2024-07-03 15:18:02 UTC): So what happens is that in metadata editor we operate on field_refs within the query itself, but in chill mode we work with an ad-hoc questions. Field refs are different and that causes issues with matching viz settings.
1 - Metadata editor
<img width=""443"" alt=""Screenshot 2024-07-03 at 11 16 33"" src=""https://github.com/metabase/metabase/assets/8542534/8ee28504-617c-4710-bbf5-164a1813ad09"">
2 - Chill mode
<img width=""786"" alt=""Screenshot 2024-07-03 at 11 16 49"" src=""https://github.com/metabase/metabase/assets/8542534/f75fa1c5-fffe-44e2-8040-351048b6bb43"">

github-actions[bot] on (2024-07-15 21:00:40 UTC): üöÄ This should also be released by [v0.50.14](https://github.com/metabase/metabase/milestone/254)

"
2181443751,issue,closed,completed,[E2E] Fix the flake `question/caching.cy.spec.js`,Failed job: https://github.com/metabase/metabase/actions/runs/8247731157/job/22556914384?pr=38946#step:13:194,qnkhuat,2024-03-12 12:00:39+00:00,['WiNloSt'],2024-04-04 09:18:41+00:00,2024-04-04 09:18:41+00:00,https://github.com/metabase/metabase/issues/39991,"[('.CI & Tests', ''), ('.Frontend', ''), ('flaky-test-fix', '')]","[{'comment_id': 2017403782, 'issue_id': 2181443751, 'author': 'qnkhuat', 'body': 'seeing this again https://github.com/metabase/metabase/actions/runs/8416379324/job/23043193372?pr=40547#step:13:198', 'created_at': datetime.datetime(2024, 3, 25, 7, 48, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2033998544, 'issue_id': 2181443751, 'author': 'WiNloSt', 'body': 'I have also been experiencing this quite often lately. My example run https://github.com/metabase/metabase/actions/runs/8535342374/job/23381923689?pr=40681#step:12:394', 'created_at': datetime.datetime(2024, 4, 3, 9, 11, tzinfo=datetime.timezone.utc)}]","qnkhuat (Issue Creator) on (2024-03-25 07:48:51 UTC): seeing this again https://github.com/metabase/metabase/actions/runs/8416379324/job/23043193372?pr=40547#step:13:198

WiNloSt (Assginee) on (2024-04-03 09:11:00 UTC): I have also been experiencing this quite often lately. My example run https://github.com/metabase/metabase/actions/runs/8535342374/job/23381923689?pr=40681#step:12:394

"
2181154286,issue,closed,completed,[Epic] Faster sync,"Sync is slower than it could be. There's a ton of work we could do to optimize it. This issue tracks what we've done and what we can do (note: we're not necessarily going to do all of this).

```[tasklist]
### Redshift sync-fields and sync-fks
- [ ] https://github.com/metabase/metabase/issues/38492
- [ ] https://github.com/metabase/metabase/pull/38828
- [ ] https://github.com/metabase/metabase/pull/38970
- [ ] https://github.com/metabase/metabase/pull/41068
```
```[tasklist]
### Follow up tasks
- [ ] https://github.com/metabase/metabase/pull/41588
- [ ] https://github.com/metabase/metabase/pull/41375
- [ ] https://github.com/metabase/metabase/pull/41528
```",calherries,2024-03-12 09:39:26+00:00,['calherries'],2024-04-25 16:22:10+00:00,2024-04-25 15:40:40+00:00,https://github.com/metabase/metabase/issues/39986,"[('Administration/Metadata & Sync', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Workflows', 'aka BEC')]","[{'comment_id': 2077601979, 'issue_id': 2181154286, 'author': 'calherries', 'body': 'Closing this as completed because the rest will be prioritized by https://www.notion.so/metabase/Faster-sync-for-more-drivers-d5b657aba7354a19bf89d62f1038a8ff', 'created_at': datetime.datetime(2024, 4, 25, 15, 40, 41, tzinfo=datetime.timezone.utc)}]","calherries (Issue Creator) on (2024-04-25 15:40:41 UTC): Closing this as completed because the rest will be prioritized by https://www.notion.so/metabase/Faster-sync-for-more-drivers-d5b657aba7354a19bf89d62f1038a8ff

"
2180998144,issue,closed,not_planned, [E2E] Fix the flake `admin-2/whitelabel.cy.spec.js`,CI: https://github.com/metabase/metabase/actions/runs/8243194312/job/22543984466#step:13:340,qnkhuat,2024-03-12 08:20:00+00:00,[],2024-12-13 16:46:16+00:00,2024-12-13 16:46:16+00:00,https://github.com/metabase/metabase/issues/39985,"[('.CI & Tests', ''), ('.Frontend', ''), ('flaky-test-fix', '')]",[],
2180993639,issue,closed,completed,[Testing plan] Make it easy to combine columns in chill mode,"Testing plan for #39977

### Drills (CLJS)

- String column **header**
  - Can combine with other string columns
  - Cannot combine columns if there are no other string columns
  - Default separator is ` ` (space)
- URL column **header**
  - Can combine with other string columns
  - Cannot combine columns if there are no other string columns
  - Default separator is `/`
- Name of combined column defaults to the names of the merged column names separated with spaces
- Adding the same combination twice is possible, and names of columns are unique (e.g. ""URL Login"" and ""URL Login (2)"")
- Drill is not offered for cells of string columns (only headers)
- Drill is not offered for non-string columns (e.g. timestamp, number)
- Drill is not offered for pivot tables
- Preview handles `null` values as empty strings

### Combined columns (e2e)

- Combined column is added as the last column
- Combined column can be edited in the GUI editor
- Combined column name defaults to the names of the merged column names separated with spaces
- Adding the same combination twice is possible, and names of combined columns are unique (e.g. ""URL Login"" and ""URL Login (2)"")
- String column as a source
  - Default separator is ` ` (space)
- URL column as a source
  - Combined column is displayed as a link (viz settings)
  - Default separator is `/`
- Preview is updated after each change
  - after changing separator
  - after adding/removing/changing column
- Preview handles `null` values as empty strings
- Can combine multiple columns using different separators
  - Empty separator works (`separator === """"`)",kamilmielnik,2024-03-12 08:17:11+00:00,[],2024-05-10 14:48:15+00:00,2024-05-10 14:48:15+00:00,https://github.com/metabase/metabase/issues/39984,"[('.Epic', 'Feature Implementation or Project'), ('.TestingStrategy/FE', ''), ('.TestingStrategy/BE', '')]",[],
2180983949,issue,closed,completed,"[FE] ""Combine columns"" preview",Depends on #39979,kamilmielnik,2024-03-12 08:11:24+00:00,['kamilmielnik'],2024-03-14 14:11:38+00:00,2024-03-14 14:11:38+00:00,https://github.com/metabase/metabase/issues/39983,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 1997552546, 'issue_id': 2180983949, 'author': 'kamilmielnik', 'body': 'I decided to do it in #39980. Closing', 'created_at': datetime.datetime(2024, 3, 14, 14, 11, 38, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-03-14 14:11:38 UTC): I decided to do it in #39980. Closing

"
2180968098,issue,closed,completed,Make the created column appear to the right of the selected one in table viz,,kamilmielnik,2024-03-12 08:01:56+00:00,['ranquild'],2024-04-18 10:31:06+00:00,2024-03-14 11:57:42+00:00,https://github.com/metabase/metabase/issues/39982,"[('.Frontend', ''), ('.Team/Querying', '')]","[{'comment_id': 2063545419, 'issue_id': 2180968098, 'author': 'kamilmielnik', 'body': 'Closed by #39958', 'created_at': datetime.datetime(2024, 4, 18, 10, 31, 5, tzinfo=datetime.timezone.utc)}]","kamilmielnik (Issue Creator) on (2024-04-18 10:31:05 UTC): Closed by #39958

"
2180968013,issue,closed,not_planned,[FE] Combined column visualization settings,"Depends on #39980.
Depends on #39982 - it's similar, so we should solve #39982 first, and then apply the same solution here (edit: see #39958 for reference implementation).

Goals:
- Format the created column as link if the source column is a URL column

This issue is blocked as per this [slack thread](https://metaboat.slack.com/archives/C0645JP1W81/p1714749376873719): 
> Alex P.: I think it‚Äôs very-very hard to do nowadays
> Alex P.: I probably would skip it",kamilmielnik,2024-03-12 08:01:53+00:00,['romeovs'],2024-05-10 14:21:37+00:00,2024-05-10 14:21:37+00:00,https://github.com/metabase/metabase/issues/39981,"[('.Frontend', ''), ('.Team/Querying', '')]",[],
2180967946,issue,closed,completed,"[FE] ""Combine columns"" drill thru",Depends on #39978.,kamilmielnik,2024-03-12 08:01:50+00:00,"['romeovs', 'kamilmielnik']",2024-05-03 08:56:41+00:00,2024-05-01 16:22:12+00:00,https://github.com/metabase/metabase/issues/39980,"[('.Frontend', ''), ('visual', 'Run Percy visual testing'), ('.Team/Querying', '')]",[],
2180967879,issue,closed,completed,"[BE] Preview ""Combine columns"" drill thru","[Eng doc](https://www.notion.so/metabase/Tech-Make-it-easy-to-combine-columns-in-chill-mode-df6957f2e4974b30a4b8d5184c52c3b5?d=af7de82f635645dea009484f6481f4ed)

Add `Lib.combineColumnsDrillExpression` + `Lib.previewExpression`",kamilmielnik,2024-03-12 08:01:47+00:00,[],2024-05-01 16:22:13+00:00,2024-05-01 16:22:13+00:00,https://github.com/metabase/metabase/issues/39979,"[('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib')]",[],
2180967781,issue,closed,completed,"[BE] ""Combine columns"" drill thru","[Eng doc](https://www.notion.so/metabase/Tech-Make-it-easy-to-combine-columns-in-chill-mode-df6957f2e4974b30a4b8d5184c52c3b5?d=af7de82f635645dea009484f6481f4ed)

- Add new drill type `""drill-thru/combine-columns""`
  - Return it from `Lib.availableDrillThrus`
  - Overload `Lib.displayInfo` to get info for this drill
  - Overload `Lib.drillThru` for this drill
- Use ` ` (space) as `defaultSeparator` for text columns
- Use `/` as `defaultSeparator` for URL columns",kamilmielnik,2024-03-12 08:01:43+00:00,['bshepherdson'],2024-04-15 21:21:31+00:00,2024-04-15 21:21:31+00:00,https://github.com/metabase/metabase/issues/39978,"[('.Backend', ''), ('.metabase-lib', 'Label for tracking all issues related to the shared CLJC metabase-lib')]",[],
2180959542,issue,closed,completed,[Epic] Make it easy to combine columns in chill mode,"# Links
- [Product doc](https://www.notion.so/metabase/Make-it-easy-to-combine-columns-in-chill-mode-08c91f890d92452bb672591c7812f9e9)
- [Eng doc](https://www.notion.so/metabase/Tech-Make-it-easy-to-combine-columns-in-chill-mode-df6957f2e4974b30a4b8d5184c52c3b5?d=af7de82f635645dea009484f6481f4ed)
- [Figma](https://www.figma.com/file/mdsv3PhsTo9VZd3uAY0naT/Make-it-easy-to-combine-columns-in-chill-mode?type=design&node-id=7952-9453&mode=design&t=l3oa5aDe95AmvFKn-0)
- [Testing plan](https://github.com/metabase/metabase/issues/39984)
- Feature branch: `combine-columns`

# Implementation Plan

## Milestone 1 - Column header

```[tasklist]
### Backend
- [ ] https://github.com/metabase/metabase/issues/39978
```

```[tasklist]
### Frontend
- [ ] https://github.com/metabase/metabase/issues/39980
- [ ] https://github.com/metabase/metabase/issues/39981
- [ ] https://github.com/metabase/metabase/issues/41350
- [ ] https://github.com/metabase/metabase/issues/41353
```

# Testing plan

#39984",kamilmielnik,2024-03-12 07:56:28+00:00,"['bshepherdson', 'romeovs', 'kamilmielnik']",2024-05-10 14:22:25+00:00,2024-05-10 14:22:24+00:00,https://github.com/metabase/metabase/issues/39977,"[('Querying/', ''), ('.Epic', 'Feature Implementation or Project'), ('.Team/Querying', '')]",[],
2180633036,issue,open,,Track DB calls for sync processes,"Some places in our sync process have N+1 queries:
- in checking select privileges (PR: https://github.com/metabase/metabase/pull/37439)
- in syncing FKs (PR: https://github.com/metabase/metabase/pull/38970/files)
- in syncing fields (PR: https://github.com/metabase/metabase/pull/38828)

And I suspect there is probably more.
Let's start tracking the number of DB calls for the sync process as we do for API calls; this will help us identify these spots.
",qnkhuat,2024-03-12 03:11:03+00:00,[],2024-03-12 09:50:26+00:00,,https://github.com/metabase/metabase/issues/39971,"[('Type:Tech Debt', 'or Refactoring'), ('.Performance', ''), ('Administration/Metadata & Sync', ''), ('.Backend', '')]","[{'comment_id': 1991211304, 'issue_id': 2180633036, 'author': 'calherries', 'body': '100%. We should probably count the two types of calls separately: App DB calls and customer DB calls. Customer DB calls are more likely to be slow so we should prioritize fixing them.\r\n\r\nWe also fire a query per table for sync-indexes on the customer DB.\r\n\r\nWe should also to measure calls for initial sync vs subsequent syncs, because they are likely to differ substantially depending on whether we are creating new records vs updating existing records.', 'created_at': datetime.datetime(2024, 3, 12, 9, 49, 46, tzinfo=datetime.timezone.utc)}]","calherries on (2024-03-12 09:49:46 UTC): 100%. We should probably count the two types of calls separately: App DB calls and customer DB calls. Customer DB calls are more likely to be slow so we should prioritize fixing them.

We also fire a query per table for sync-indexes on the customer DB.

We should also to measure calls for initial sync vs subsequent syncs, because they are likely to differ substantially depending on whether we are creating new records vs updating existing records.

"
2180629004,issue,closed,not_planned,Whether to add AI conversation function to generate reports based on AI conversation,"**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**How important is this feature to you?**
Note: the more honest and specific you are here the more we will take you seriously. 

**Additional context**
Add any other context or screenshots about the feature request here.

```[tasklist]
### Tasks
```
",sea-007,2024-03-12 03:06:20+00:00,[],2024-03-12 14:13:07+00:00,2024-03-12 14:13:07+00:00,https://github.com/metabase/metabase/issues/39970,"[('Type:New Feature', ''), ('.Needs Triage', '')]",[],
2180546094,issue,closed,completed,Specific dates filter incorrect result,"### Describe the bug

Hi! I create a new question and select a table from my MS SQL db.
Add a filter by date. Specific dates... Between March 1 - 2.
Preview and visualization in table shows wrong result.
Dates are displayed that do not match the filter March 1-2, 2024, shows 3 Jan - 2 March 2024 (1,154 rows).
The DateTakeoff field with SMALLDATETIME type contains local time, same as on a virtual machine with Docker, Metabase + Postgres containers.
In previous releases everything worked correctly, and then, after several updates, I noticed that my dashboard was displaying incorrect information with this specific date filter.
I'm sure that in version 0.48.1 everything worked correctly.

Preview of Specific dates show incorrect result:
![1](https://github.com/metabase/metabase/assets/28322040/967b20ee-fbea-4bac-8e1d-8b74522e4b66)

Visualization with Specific dates filter show 3 Jan - 2 March 2024 (1,154 rows)
instead of March 1-2, 2024 (31 rows):
![2](https://github.com/metabase/metabase/assets/28322040/f87f4d5d-4e2d-44ac-b2c8-bb9f8d1cce30)

Also here is the query generated in the question:
![3](https://github.com/metabase/metabase/assets/28322040/6df5bb84-aa22-417f-8743-adb15d726acf)

And here is the result of this query in HeidiSQL
which makes the selection correctly March 1-2, 2024 (31 rows)
I tried to create +New -> SQL Query in Metabase and insert the same query and result shows the wrong...
![4](https://github.com/metabase/metabase/assets/28322040/9a7e042a-fcd6-4604-9566-488ae6fa55aa)

Yesteday and others date filters works fine, problem with Specific dates...
![5](https://github.com/metabase/metabase/assets/28322040/24f0ce2c-7853-4b28-847a-2244bab74971)

I tried to select only March 15th and got the following error:
![6](https://github.com/metabase/metabase/assets/28322040/e93532c3-2d50-4a16-be92-3952064cae7f)


### To Reproduce

1. Login in
2. Click on + New
3. Select Question
4. Pick starting data (MS SQL db)
5. Select table
6. Click add filters
7. Select column
8. Click Specific dates...
9. Choose dates 1 March, 2024 - 2 March, 2024
10. Click Add filter
11. Click Preview
12. See incorrect result
13. Click Visualize
14. See incorrect result


### Expected behavior

After filtering by Specific dates, a result should be displayed that corresponds to the filter by a Specific date

### Logs

WARN metabase.driver.sql-jdbc.sync.describe-table Don't know how to map column type 'tinyint identity' to a Field base_type, falling back to :type/*
WARN metabase.driver.sql-jdbc.sync.describe-table Don't know how to map column type 'smallint identity' to a Field base_type, falling back to :type/*
WARN metabase.driver.sql-jdbc.sync.describe-table Don't know how to map column type 'sysname' to a Field base_type, falling back to :type/*
WARN metabase.driver.sql.query-processor.deprecated Warning: The :sqlserver driver uses Honey SQL 1. This method was deprecated in 0.46.0 and will be removed in a future release

### Information about your Metabase installation

```JSON
{
  ""browser-info"": {
    ""userAgent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"",
    ""vendor"": ""Google Inc.""
  },
  ""system-info"": {
    ""file.encoding"": ""UTF-8"",
    ""java.runtime.name"": ""OpenJDK Runtime Environment"",
    ""java.runtime.version"": ""11.0.22+7"",
    ""java.vendor"": ""Eclipse Adoptium"",
    ""java.vendor.url"": ""https://adoptium.net/"",
    ""java.version"": ""11.0.22"",
    ""java.vm.name"": ""OpenJDK 64-Bit Server VM"",
    ""java.vm.version"": ""11.0.22+7"",
    ""os.name"": ""Linux"",
    ""os.version"": ""5.15.0-84-generic"",
    ""user.language"": ""en"",
    ""user.timezone"": ""GMT""
  },
  ""metabase-info"": {
    ""databases"": [
      ""h2"",
      ""sqlserver""
    ],
    ""hosting-env"": ""unknown"",
    ""application-database"": ""postgres"",
    ""application-database-details"": {
      ""database"": {
        ""name"": ""PostgreSQL"",
        ""version"": ""16.2 (Debian 16.2-1.pgdg120+2)""
      },
      ""jdbc-driver"": {
        ""name"": ""PostgreSQL JDBC Driver"",
        ""version"": ""42.6.0""
      }
    },
    ""run-mode"": ""prod"",
    ""version"": {
      ""date"": ""2024-03-04"",
      ""tag"": ""v0.48.8"",
      ""hash"": ""a900c85""
    },
    ""settings"": {
      ""report-timezone"": ""Asia/Sakhalin""
    }
  }
}
```


### Severity

Broken dashboard with incorrect results

### Additional context

Metabase Discuss link: https://discourse.metabase.com/t/specific-dates-filter-bug/85926",SeshTiliRest,2024-03-12 01:30:13+00:00,[],2024-04-03 12:32:06+00:00,2024-04-03 12:32:06+00:00,https://github.com/metabase/metabase/issues/39968,"[('Type:Bug', 'Product defects'), ('Priority:P2', 'Average run of the mill bug'), ('Querying/Parameters & Variables', 'Filter widgets, field filters, variables etc.'), ('Querying/GUI', 'Query builder catch-all, including simple mode')]","[{'comment_id': 1992280989, 'issue_id': 2180546094, 'author': 'ignacio-mb', 'body': ""@SeshTiliRest I'm not able to reproduce. Can you post a screenshot of the query in the browser developer tools? inspect > Network tab > clear the previous >rerun the query with the filter > {;} dataset"", 'created_at': datetime.datetime(2024, 3, 12, 18, 18, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 1992640453, 'issue_id': 2180546094, 'author': 'SeshTiliRest', 'body': ""@ignacio-mb Thanks for your reply! Which tab exactly?\r\n\r\nLooks like month and day in the date format are reversed.\r\nIn my db all datetime fields in this format YYYY-MM-DD.\r\nBut it seems the query processes the date in the format YYYY-DD-MM.\r\n\r\nMaybe that's why I get this error when I try to filter by dates for example 20 February, 2024 - 21 February, 2024:\r\n`Converting an nvarchar data type to a smalldatetime data type caused the value to be out of range.`\r\n\r\nHere is the result in the Response tab:\r\n![123](https://github.com/metabase/metabase/assets/28322040/52746b50-2752-42bc-95ec-461f22eaac21)"", 'created_at': datetime.datetime(2024, 3, 12, 21, 46, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 1993979747, 'issue_id': 2180546094, 'author': 'AndrewMBaines', 'body': ""Try this in SSMS, then in Metabase. You'll soon see the problem:\r\n```\r\nselect month(cast('2024-03-01 00:00:00' as datetime)) as full_date_time,  month(cast('2024-03-01' as date)) as just_date\r\n```\r\nCorrect answer is 3,3 and that's what SSMS gives.\r\nMetabase give 1,3!"", 'created_at': datetime.datetime(2024, 3, 13, 9, 50, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 1995853034, 'issue_id': 2180546094, 'author': 'SeshTiliRest', 'body': ""Hi! You are wright.\r\n\r\nMetabase SQL query shows full_date_time 1 and just_date 3 :\r\n![metabase](https://github.com/metabase/metabase/assets/28322040/6e3035d4-f3be-4d61-8d8b-828969a1f9d2)\r\n\r\nHeidiSQL shows full_date_time 3 and just_date 3:\r\n![heidisql](https://github.com/metabase/metabase/assets/28322040/0c6a3660-0f5a-477d-9da0-57a44892e149)\r\n\r\nIn Metabase this SQL query shows 1 and 3:\r\n\r\n```\r\nSELECT\r\n  DATEPART(MONTH, CAST('2024-03-01 00:00:00' AS DATETIME)) AS full_date_time,\r\n  DATEPART(MONTH, CAST('2024-03-01' AS DATE)) AS just_date\r\n```\r\n\r\nAnd in Metabase this SQL query shows 3 and 3:\r\n\r\n```\r\nSELECT\r\n  MONTH(CONVERT(datetime, '2024-03-01 00:00:00', 120)) AS full_date_time,\r\n  MONTH(CONVERT(date, '2024-03-01', 120)) AS just_date\r\n```\r\nIn this query, the `CONVERT()` function takes a third parameter - the style of the date format.\r\nStyle `120` is used for the universal datetime format (YYYY-MM-DD HH:MI:SS), which should be recognized independently of regional settings."", 'created_at': datetime.datetime(2024, 3, 13, 21, 17, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998111655, 'issue_id': 2180546094, 'author': 'ignacio-mb', 'body': 'May be related to https://github.com/metabase/metabase/issues/39769', 'created_at': datetime.datetime(2024, 3, 14, 18, 52, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998439564, 'issue_id': 2180546094, 'author': 'notrom', 'body': 'Just a bit more context from the discourse thread linked in the issue which has some really good info from @AndrewMBaines and @SeshTiliRest ...\r\n\r\nI\'m not seeing this issue either using filters in the GUI or when using that SQL, both SSMS and Metabase (v0.48.8) give me the correct answer 3,3.\r\n\r\nSSMS:\r\n![image](https://github.com/metabase/metabase/assets/4504437/502b3cd2-c6bf-4668-88d9-135b64a1c0e5)\r\n\r\nMetabase:\r\n![image](https://github.com/metabase/metabase/assets/4504437/6744d2df-f32f-4d3a-a977-1ef7b0ce1a0c)\r\n\r\nSo although it\'s clearly wrong, it doesn\'t appear to be universally wrong, there must be something else going on.\r\n\r\nMy SQL Server language (both default and user) is ""English (United States)"" (standard, we don\'t change that), my client\'s Windows locale is ""United States"" (again standard, we don\'t change that), my Windows date format is DD/MM/YYYY (as determined by the region settings which is ""New Zealand"").', 'created_at': datetime.datetime(2024, 3, 14, 20, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998457144, 'issue_id': 2180546094, 'author': 'AndrewMBaines', 'body': ""From my post on discourse:\r\nIt looks like it's to do with Metabase and SQL server having different locales or just non-US English for the OS.\r\nIn the UK, SQL Server is normally left at US English as that's the default. That means that formatting a date is mdy.\r\nHowever, the OS and Metabase are both set to use British English giving dmy.\r\nTry this:\r\n```\r\nselect month(cast('2024-03-01 00:00:00' as datetime)) as full_date_time,  month(cast('2024-03-01' as date)) as just_date,month(cast('01-03-2024' as date)) as dateFormatCheck\r\n```\r\n\r\nI get 3,3,1 in SQL\r\nbut 1,3,3 in Metabase.\r\n\r\nMetabase is using the OS locale to cast the dates. Makes sense except that yyyy-dd-mm hh:MM:ss isn't a valid format and that's what Metabase is trying to use.\r\n\r\nIf it makes any difference, my test system is all Windows."", 'created_at': datetime.datetime(2024, 3, 14, 20, 46, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998461959, 'issue_id': 2180546094, 'author': 'AndrewMBaines', 'body': ""For what it's worth, I've been having another date related issue when the FIRSTDAYOFWEEK is anything other than 7:\r\nhttps://discourse.metabase.com/t/different-dates-for-week-graph-vs-table/83187\r\nNot sure if I need to start another issue for that or if it's just a bad release for non-US users of MS SQL."", 'created_at': datetime.datetime(2024, 3, 14, 20, 50, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 1998481950, 'issue_id': 2180546094, 'author': 'SeshTiliRest', 'body': 'Yah, i get same result with this query.\r\n3,3,1 in SQL and 1,3,3 in Metabase.\r\nTesting client OS is Windows with DD-MM-YYYY date format. Same on MS SQL server.', 'created_at': datetime.datetime(2024, 3, 14, 21, 4, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2026267422, 'issue_id': 2180546094, 'author': 'SeshTiliRest', 'body': 'Hi! As far as I can see, after updating to v0.49.2 I no longer see this problem. Thank you!', 'created_at': datetime.datetime(2024, 3, 28, 22, 49, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2034482415, 'issue_id': 2180546094, 'author': 'ignacio-mb', 'body': 'Thanks for following up!', 'created_at': datetime.datetime(2024, 4, 3, 12, 32, 6, tzinfo=datetime.timezone.utc)}]","ignacio-mb on (2024-03-12 18:18:23 UTC): @SeshTiliRest I'm not able to reproduce. Can you post a screenshot of the query in the browser developer tools? inspect > Network tab > clear the previous >rerun the query with the filter > {;} dataset

SeshTiliRest (Issue Creator) on (2024-03-12 21:46:25 UTC): @ignacio-mb Thanks for your reply! Which tab exactly?

Looks like month and day in the date format are reversed.
In my db all datetime fields in this format YYYY-MM-DD.
But it seems the query processes the date in the format YYYY-DD-MM.

Maybe that's why I get this error when I try to filter by dates for example 20 February, 2024 - 21 February, 2024:
`Converting an nvarchar data type to a smalldatetime data type caused the value to be out of range.`

Here is the result in the Response tab:
![123](https://github.com/metabase/metabase/assets/28322040/52746b50-2752-42bc-95ec-461f22eaac21)

AndrewMBaines on (2024-03-13 09:50:17 UTC): Try this in SSMS, then in Metabase. You'll soon see the problem:
```
select month(cast('2024-03-01 00:00:00' as datetime)) as full_date_time,  month(cast('2024-03-01' as date)) as just_date
```
Correct answer is 3,3 and that's what SSMS gives.
Metabase give 1,3!

SeshTiliRest (Issue Creator) on (2024-03-13 21:17:04 UTC): Hi! You are wright.

Metabase SQL query shows full_date_time 1 and just_date 3 :
![metabase](https://github.com/metabase/metabase/assets/28322040/6e3035d4-f3be-4d61-8d8b-828969a1f9d2)

HeidiSQL shows full_date_time 3 and just_date 3:
![heidisql](https://github.com/metabase/metabase/assets/28322040/0c6a3660-0f5a-477d-9da0-57a44892e149)

In Metabase this SQL query shows 1 and 3:

```
SELECT
  DATEPART(MONTH, CAST('2024-03-01 00:00:00' AS DATETIME)) AS full_date_time,
  DATEPART(MONTH, CAST('2024-03-01' AS DATE)) AS just_date
```

And in Metabase this SQL query shows 3 and 3:

```
SELECT
  MONTH(CONVERT(datetime, '2024-03-01 00:00:00', 120)) AS full_date_time,
  MONTH(CONVERT(date, '2024-03-01', 120)) AS just_date
```
In this query, the `CONVERT()` function takes a third parameter - the style of the date format.
Style `120` is used for the universal datetime format (YYYY-MM-DD HH:MI:SS), which should be recognized independently of regional settings.

ignacio-mb on (2024-03-14 18:52:12 UTC): May be related to https://github.com/metabase/metabase/issues/39769

notrom on (2024-03-14 20:38:00 UTC): Just a bit more context from the discourse thread linked in the issue which has some really good info from @AndrewMBaines and @SeshTiliRest ...

I'm not seeing this issue either using filters in the GUI or when using that SQL, both SSMS and Metabase (v0.48.8) give me the correct answer 3,3.

SSMS:
![image](https://github.com/metabase/metabase/assets/4504437/502b3cd2-c6bf-4668-88d9-135b64a1c0e5)

Metabase:
![image](https://github.com/metabase/metabase/assets/4504437/6744d2df-f32f-4d3a-a977-1ef7b0ce1a0c)

So although it's clearly wrong, it doesn't appear to be universally wrong, there must be something else going on.

My SQL Server language (both default and user) is ""English (United States)"" (standard, we don't change that), my client's Windows locale is ""United States"" (again standard, we don't change that), my Windows date format is DD/MM/YYYY (as determined by the region settings which is ""New Zealand"").

AndrewMBaines on (2024-03-14 20:46:57 UTC): From my post on discourse:
It looks like it's to do with Metabase and SQL server having different locales or just non-US English for the OS.
In the UK, SQL Server is normally left at US English as that's the default. That means that formatting a date is mdy.
However, the OS and Metabase are both set to use British English giving dmy.
Try this:
```
select month(cast('2024-03-01 00:00:00' as datetime)) as full_date_time,  month(cast('2024-03-01' as date)) as just_date,month(cast('01-03-2024' as date)) as dateFormatCheck
```

I get 3,3,1 in SQL
but 1,3,3 in Metabase.

Metabase is using the OS locale to cast the dates. Makes sense except that yyyy-dd-mm hh:MM:ss isn't a valid format and that's what Metabase is trying to use.

If it makes any difference, my test system is all Windows.

AndrewMBaines on (2024-03-14 20:50:05 UTC): For what it's worth, I've been having another date related issue when the FIRSTDAYOFWEEK is anything other than 7:
https://discourse.metabase.com/t/different-dates-for-week-graph-vs-table/83187
Not sure if I need to start another issue for that or if it's just a bad release for non-US users of MS SQL.

SeshTiliRest (Issue Creator) on (2024-03-14 21:04:54 UTC): Yah, i get same result with this query.
3,3,1 in SQL and 1,3,3 in Metabase.
Testing client OS is Windows with DD-MM-YYYY date format. Same on MS SQL server.

SeshTiliRest (Issue Creator) on (2024-03-28 22:49:40 UTC): Hi! As far as I can see, after updating to v0.49.2 I no longer see this problem. Thank you!

ignacio-mb on (2024-04-03 12:32:06 UTC): Thanks for following up!

"
2180356510,issue,closed,completed,`Esc` exits both the collection picker and the question save modal,,iethree,2024-03-11 22:15:51+00:00,['iethree'],2024-03-19 22:53:16+00:00,2024-03-19 22:53:16+00:00,https://github.com/metabase/metabase/issues/39966,[],[],
