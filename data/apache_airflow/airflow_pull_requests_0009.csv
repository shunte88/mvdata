id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2492540559,pull_request,closed,,Add return_immediately parameter to PubSubPullSensor class,"Closes: #41838

Add optional `return_immediately` parameter to PubSubPullSensor (default: `True` for backwards compatibility). This allows setting `return_immediately=False` to resolve issue #41838 and improve performance. The parameter was originally removed from the class but hard-coded to True in the PubSubHook.pull call in the poke function in PR #23231. 

Note: SubscriberClient.pull (called by PubSubHook.pull) warns that setting return_immediately=True is discouraged due to performance impact.

```
return_immediately (bool):
    Optional. If this field set to true, the system will
    respond immediately even if it there are no messages
    available to return in the ``Pull`` response. Otherwise,
    the system may wait (for a bounded amount of time) until
    at least one message is available, rather than returning
    no messages. Warning: setting this field to ``true`` is
    discouraged because it adversely impacts the performance
    of ``Pull`` operations. We recommend that users do not
    set this field.
```





<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",arnaubadia,2024-08-28 16:29:29+00:00,[],2024-09-09 16:43:38+00:00,2024-09-09 16:43:34+00:00,https://github.com/apache/airflow/pull/41842,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2315797545, 'issue_id': 2492540559, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 28, 16, 29, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316880711, 'issue_id': 2492540559, 'author': 'eladkal', 'body': ""> The parameter was originally removed from the class but hard-coded to True in the PubSubHook.pull call in the poke function in PR https://github.com/apache/airflow/pull/23231.\r\n\r\nMy PR only removed the deprecated code. it was deprecated 4 years ago in https://github.com/apache/airflow/pull/7766\r\n\r\nThe original PR claims \r\n\r\n\r\n```\r\n    :param return_immediately:\r\n        (Deprecated) This is an underlying PubSub API implementation detail.\r\n        It has no real effect on Sensor behaviour other than some internal wait time before retrying\r\n        on empty queue.\r\n        The Sensor task will (by definition) always wait for a message, regardless of this argument value.\r\n        If you want a non-blocking task that does not to wait for messages, please use\r\n        :class:`airflow.providers.google.cloud.operators.PubSubPullOperator`\r\n        instead.\r\n```\r\n       \r\n       \r\nYou didn't explain why it's not valid any more. Specifically about underlying PubSub API implementation detail and why `PubSubPullOperator` isn't covering the use case (operator instead of sensor)"", 'created_at': datetime.datetime(2024, 8, 29, 7, 16, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317048551, 'issue_id': 2492540559, 'author': 'arnaubadia', 'body': '@eladkal\r\n> You didn\'t explain why it\'s not valid any more. Specifically about underlying PubSub API implementation detail\r\n\r\nThe removed code in PR https://github.com/apache/airflow/pull/23231 claims that return_immediately ""has no effect on PubSubPullSensor behaviour"" and ""It should be left as default value of True.""\r\n\r\nI claim this is not true based on empirical evidence (sometimes the sensor didn\'t pull messages even if there are unacked messages available) and based on the comment in the pull function of SubscriberClient (from google.cloud.pubsub_v1 import SubscriberClient), which is called by PubSubHook.pull in the poke function of the sensor:\r\n\r\n```\r\nreturn_immediately (bool):\r\n    Optional. If this field set to true, the system will\r\n    respond immediately even if it there are no messages\r\n    available to return in the ``Pull`` response. Otherwise,\r\n    the system may wait (for a bounded amount of time) until\r\n    at least one message is available, rather than returning\r\n    no messages. Warning: setting this field to ``true`` is\r\n    discouraged because it adversely impacts the performance\r\n    of ``Pull`` operations. We recommend that users do not\r\n    set this field.\r\n```\r\n\r\n> why PubSubPullOperator isn\'t covering the use case (operator instead of sensor)\r\n\r\nThe PubSubPullOperator doesn\'t cover my use case because I don\'t want to continue with the DAG run if there are no messages available. I want to wait until there\'s a new message available and use the contents of the message in the DAG run.', 'created_at': datetime.datetime(2024, 8, 29, 8, 46, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317482353, 'issue_id': 2492540559, 'author': 'eladkal', 'body': 'Lets wait for review of someone from the Google team cc @VladaZakharova', 'created_at': datetime.datetime(2024, 8, 29, 12, 14, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2338591699, 'issue_id': 2492540559, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 9, 16, 43, 36, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-28 16:29:33 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-08-29 07:16:03 UTC): My PR only removed the deprecated code. it was deprecated 4 years ago in https://github.com/apache/airflow/pull/7766

The original PR claims 


```
    :param return_immediately:
        (Deprecated) This is an underlying PubSub API implementation detail.
        It has no real effect on Sensor behaviour other than some internal wait time before retrying
        on empty queue.
        The Sensor task will (by definition) always wait for a message, regardless of this argument value.
        If you want a non-blocking task that does not to wait for messages, please use
        :class:`airflow.providers.google.cloud.operators.PubSubPullOperator`
        instead.
```
       
       
You didn't explain why it's not valid any more. Specifically about underlying PubSub API implementation detail and why `PubSubPullOperator` isn't covering the use case (operator instead of sensor)

arnaubadia (Issue Creator) on (2024-08-29 08:46:16 UTC): @eladkal

The removed code in PR https://github.com/apache/airflow/pull/23231 claims that return_immediately ""has no effect on PubSubPullSensor behaviour"" and ""It should be left as default value of True.""

I claim this is not true based on empirical evidence (sometimes the sensor didn't pull messages even if there are unacked messages available) and based on the comment in the pull function of SubscriberClient (from google.cloud.pubsub_v1 import SubscriberClient), which is called by PubSubHook.pull in the poke function of the sensor:

```
return_immediately (bool):
    Optional. If this field set to true, the system will
    respond immediately even if it there are no messages
    available to return in the ``Pull`` response. Otherwise,
    the system may wait (for a bounded amount of time) until
    at least one message is available, rather than returning
    no messages. Warning: setting this field to ``true`` is
    discouraged because it adversely impacts the performance
    of ``Pull`` operations. We recommend that users do not
    set this field.
```


The PubSubPullOperator doesn't cover my use case because I don't want to continue with the DAG run if there are no messages available. I want to wait until there's a new message available and use the contents of the message in the DAG run.

eladkal on (2024-08-29 12:14:56 UTC): Lets wait for review of someone from the Google team cc @VladaZakharova

boring-cyborg[bot] on (2024-09-09 16:43:36 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2492524863,pull_request,closed,,Add trace tags to task instances and also support OTEL_RESOURCE_ATTRIBUTES for spans,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

closes: #41840 

This PR addresses features mentioned in above issue, that OTEL traces will now be able to collect user-defined resources via OTEL_RESOURCE_ATTRIBUTES.

Also, in addition to this, the PR also addresses more complete instrumentation that task instance span will also now contain the tags specified via airflow config's `airflow.traces.tags`, providing more ways to instrument spans with less user coding involved.

For more information about the OTEL_RESOURCE_ATTRIBUTES, please visit [here](https://opentelemetry.io/docs/languages/sdk-configuration/general/#otel_resource_attributes)
",howardyoo,2024-08-28 16:20:20+00:00,[],2024-08-30 13:39:52+00:00,2024-08-30 13:39:52+00:00,https://github.com/apache/airflow/pull/41841,[],[],
2492473864,pull_request,closed,,Unpin google-cloud-bigquery package version for Google provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Related to: https://github.com/apache/airflow/issues/39541

Started from `google-cloud-bigquery==3.24.0` version issue https://github.com/apache/airflow/issues/39541 was fixed.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-08-28 15:53:34+00:00,[],2024-08-29 13:06:30+00:00,2024-08-29 13:06:30+00:00,https://github.com/apache/airflow/pull/41839,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2492324958,pull_request,closed,,Fix typo in trace attribute,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This corrects the spelling of the `ququed_by_job_id` span attribute.

Fixes: https://github.com/apache/airflow/issues/41836

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",swythan,2024-08-28 14:47:35+00:00,[],2024-08-30 07:36:32+00:00,2024-08-30 05:40:22+00:00,https://github.com/apache/airflow/pull/41837,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2315573113, 'issue_id': 2492324958, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 28, 14, 47, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320120379, 'issue_id': 2492324958, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 30, 5, 40, 24, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-28 14:47:39 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-08-30 05:40:24 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2492037330,pull_request,closed,,Set end_date and duration for triggers completed with end_from_trigger as True,"port https://github.com/apache/airflow/pull/41754 to v2-10-test

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-28 13:10:09+00:00,[],2024-08-30 11:34:35+00:00,2024-08-28 13:54:57+00:00,https://github.com/apache/airflow/pull/41834,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:Triggerer', '')]","[{'comment_id': 2315278660, 'issue_id': 2492037330, 'author': 'Lee-W', 'body': 'cc @tirkarthi', 'created_at': datetime.datetime(2024, 8, 28, 13, 10, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315501138, 'issue_id': 2492037330, 'author': 'tirkarthi', 'body': 'Thanks @Lee-W . I forgot about the backports policy.', 'created_at': datetime.datetime(2024, 8, 28, 14, 30, 41, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-08-28 13:10:18 UTC): cc @tirkarthi

tirkarthi on (2024-08-28 14:30:41 UTC): Thanks @Lee-W . I forgot about the backports policy.

"
2491982291,pull_request,closed,,fix: rm `skip_if` and `run_if` in python source,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Like `setup` and `teardown`, `skip_if` and `run_if` should also be removed.

### sample dag code
```python
from __future__ import annotations

from pendulum import datetime

from airflow.decorators import dag, task


@dag(start_date=datetime(2024, 1, 1), schedule=None, catchup=False)
def venv_skip_if() -> None:
    @task.skip_if(lambda context: False)
    @task.virtualenv()
    def echo() -> None:
        print(""hello world"")

    echo()


venv_skip_if()
```

#### before in venv
```log
1b4bbddb0c17
*** Found local files:
***   * /root/airflow/logs/dag_id=venv_skip_if/run_id=manual__2024-08-28T12:29:04.469903+00:00/task_id=echo/attempt=1.log
[2024-08-28, 12:29:05 UTC] {local_task_job_runner.py:123} â–¶ Pre task execution logs
[2024-08-28, 12:29:05 UTC] {process_utils.py:186} INFO - Executing cmd: /usr/local/bin/python -m virtualenv /tmp/venv5qst192w --system-site-packages --python=python
[2024-08-28, 12:29:05 UTC] {process_utils.py:190} INFO - Output:
[2024-08-28, 12:29:06 UTC] {process_utils.py:194} INFO - created virtual environment CPython3.8.19.final.0-64 in 276ms
[2024-08-28, 12:29:06 UTC] {process_utils.py:194} INFO -   creator CPython3Posix(dest=/tmp/venv5qst192w, clear=False, no_vcs_ignore=False, global=True)
[2024-08-28, 12:29:06 UTC] {process_utils.py:194} INFO -   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)
[2024-08-28, 12:29:06 UTC] {process_utils.py:194} INFO -     added seed packages: pip==24.1, setuptools==70.1.0, wheel==0.43.0
[2024-08-28, 12:29:06 UTC] {process_utils.py:194} INFO -   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[2024-08-28, 12:29:06 UTC] {process_utils.py:186} INFO - Executing cmd: /tmp/venv5qst192w/bin/pip install -r /tmp/venv5qst192w/requirements.txt
[2024-08-28, 12:29:06 UTC] {process_utils.py:190} INFO - Output:
[2024-08-28, 12:29:10 UTC] {process_utils.py:194} INFO - 
[2024-08-28, 12:29:10 UTC] {process_utils.py:194} INFO - [notice] A new release of pip is available: 24.1 -> 24.2
[2024-08-28, 12:29:10 UTC] {process_utils.py:194} INFO - [notice] To update, run: python -m pip install --upgrade pip
[2024-08-28, 12:29:10 UTC] {process_utils.py:186} INFO - Executing cmd: /tmp/venv5qst192w/bin/python /tmp/venv-callwp2r9u9t/script.py /tmp/venv-callwp2r9u9t/script.in /tmp/venv-callwp2r9u9t/script.out /tmp/venv-callwp2r9u9t/string_args.txt /tmp/venv-callwp2r9u9t/termination.log /tmp/venv-callwp2r9u9t/***_context.json
[2024-08-28, 12:29:10 UTC] {process_utils.py:190} INFO - Output:
[2024-08-28, 12:29:13 UTC] {process_utils.py:194} INFO - Traceback (most recent call last):
[2024-08-28, 12:29:13 UTC] {process_utils.py:194} INFO -   File ""/tmp/venv-callwp2r9u9t/script.py"", line 18, in <module>
[2024-08-28, 12:29:13 UTC] {process_utils.py:194} INFO -     @task.skip_if(lambda context: False)
[2024-08-28, 12:29:13 UTC] {process_utils.py:194} INFO - NameError: name 'task' is not defined
[2024-08-28, 12:29:13 UTC] {taskinstance.py:3167} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 753, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 719, in _execute_callable
    return ExecutionCallableRunner(
  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 402, in wrapper
    return func(self, *args, **kwargs)
  File ""/opt/airflow/airflow/decorators/base.py"", line 266, in execute
    return_value = super().execute(context)
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 402, in wrapper
    return func(self, *args, **kwargs)
  File ""/opt/airflow/airflow/operators/python.py"", line 509, in execute
    return super().execute(context=serializable_context)
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 402, in wrapper
    return func(self, *args, **kwargs)
  File ""/opt/airflow/airflow/operators/python.py"", line 240, in execute
    return_value = self.execute_callable()
  File ""/opt/airflow/airflow/operators/python.py"", line 900, in execute_callable
    result = self._execute_python_callable_in_subprocess(python_path)
  File ""/opt/airflow/airflow/operators/python.py"", line 593, in _execute_python_callable_in_subprocess
    execute_in_subprocess(
  File ""/opt/airflow/airflow/utils/process_utils.py"", line 175, in execute_in_subprocess
    execute_in_subprocess_with_kwargs(cmd, cwd=cwd, env=env)
  File ""/opt/airflow/airflow/utils/process_utils.py"", line 198, in execute_in_subprocess_with_kwargs
    raise subprocess.CalledProcessError(exit_code, cmd)
subprocess.CalledProcessError: Command '['/tmp/venv5qst192w/bin/python', '/tmp/venv-callwp2r9u9t/script.py', '/tmp/venv-callwp2r9u9t/script.in', '/tmp/venv-callwp2r9u9t/script.out', '/tmp/venv-callwp2r9u9t/string_args.txt', '/tmp/venv-callwp2r9u9t/termination.log', '/tmp/venv-callwp2r9u9t/airflow_context.json']' returned non-zero exit status 1.
[2024-08-28, 12:29:13 UTC] {taskinstance.py:1211} INFO - Marking task as FAILED. dag_id=venv_skip_if, task_id=echo, run_id=manual__2024-08-28T12:29:04.469903+00:00, execution_date=20240828T122904, start_date=20240828T122905, end_date=20240828T122913
[2024-08-28, 12:29:13 UTC] {taskinstance.py:337} â–¶ Post task execution logs
```

#### after in venv
```log
5dae42dc6e21
*** Found local files:
***   * /root/airflow/logs/dag_id=venv_skip_if/run_id=manual__2024-08-28T12:39:47.502535+00:00/task_id=echo/attempt=1.log
[2024-08-28, 12:39:48 UTC] {local_task_job_runner.py:123} â–¶ Pre task execution logs
[2024-08-28, 12:39:48 UTC] {process_utils.py:186} INFO - Executing cmd: /usr/local/bin/python -m virtualenv /tmp/venvt7te04zf --system-site-packages --python=python
[2024-08-28, 12:39:48 UTC] {process_utils.py:190} INFO - Output:
[2024-08-28, 12:39:48 UTC] {process_utils.py:194} INFO - created virtual environment CPython3.8.19.final.0-64 in 266ms
[2024-08-28, 12:39:48 UTC] {process_utils.py:194} INFO -   creator CPython3Posix(dest=/tmp/venvt7te04zf, clear=False, no_vcs_ignore=False, global=True)
[2024-08-28, 12:39:48 UTC] {process_utils.py:194} INFO -   seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)
[2024-08-28, 12:39:48 UTC] {process_utils.py:194} INFO -     added seed packages: pip==24.1, setuptools==70.1.0, wheel==0.43.0
[2024-08-28, 12:39:48 UTC] {process_utils.py:194} INFO -   activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
[2024-08-28, 12:39:48 UTC] {process_utils.py:186} INFO - Executing cmd: /tmp/venvt7te04zf/bin/pip install -r /tmp/venvt7te04zf/requirements.txt
[2024-08-28, 12:39:48 UTC] {process_utils.py:190} INFO - Output:
[2024-08-28, 12:39:52 UTC] {process_utils.py:194} INFO - 
[2024-08-28, 12:39:52 UTC] {process_utils.py:194} INFO - [notice] A new release of pip is available: 24.1 -> 24.2
[2024-08-28, 12:39:52 UTC] {process_utils.py:194} INFO - [notice] To update, run: python -m pip install --upgrade pip
[2024-08-28, 12:39:52 UTC] {process_utils.py:186} INFO - Executing cmd: /tmp/venvt7te04zf/bin/python /tmp/venv-call55vo1yul/script.py /tmp/venv-call55vo1yul/script.in /tmp/venv-call55vo1yul/script.out /tmp/venv-call55vo1yul/string_args.txt /tmp/venv-call55vo1yul/termination.log /tmp/venv-call55vo1yul/***_context.json
[2024-08-28, 12:39:52 UTC] {process_utils.py:190} INFO - Output:
[2024-08-28, 12:39:56 UTC] {process_utils.py:194} INFO - hello world
[2024-08-28, 12:39:56 UTC] {python.py:242} INFO - Done. Returned value was: None
[2024-08-28, 12:39:56 UTC] {taskinstance.py:337} â–¶ Post task execution logs
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-28 12:45:47+00:00,[],2025-01-15 18:19:39+00:00,2024-10-02 01:12:30+00:00,https://github.com/apache/airflow/pull/41832,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2315417743, 'issue_id': 2491982291, 'author': 'phi-friday', 'body': ""I'm getting an error related to the open api, I'm not understanding why it's happening, could you please explain?"", 'created_at': datetime.datetime(2024, 8, 28, 14, 5, 21, tzinfo=datetime.timezone.utc)}]","phi-friday (Issue Creator) on (2024-08-28 14:05:21 UTC): I'm getting an error related to the open api, I'm not understanding why it's happening, could you please explain?

"
2491946685,pull_request,closed,,Fix type mismatch issue related to issue https://github.com/apache/aiâ€¦,"â€¦rflow/issues/41821

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gnthibault,2024-08-28 12:29:43+00:00,[],2024-08-28 12:57:48+00:00,2024-08-28 12:57:48+00:00,https://github.com/apache/airflow/pull/41831,[],"[{'comment_id': 2315191569, 'issue_id': 2491946685, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 28, 12, 29, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315244561, 'issue_id': 2491946685, 'author': 'gnthibault', 'body': 'Ok wait I realize maybe I have mixed-up dag_run id and dag run_id. Doing additional checks', 'created_at': datetime.datetime(2024, 8, 28, 12, 55, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315249931, 'issue_id': 2491946685, 'author': 'potiuk', 'body': 'Yep. I think you did.', 'created_at': datetime.datetime(2024, 8, 28, 12, 57, 48, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-28 12:29:47 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

gnthibault (Issue Creator) on (2024-08-28 12:55:20 UTC): Ok wait I realize maybe I have mixed-up dag_run id and dag run_id. Doing additional checks

potiuk on (2024-08-28 12:57:48 UTC): Yep. I think you did.

"
2491818235,pull_request,closed,,Deprected module airflow.providers.cncf.kubernetes.pod_launcher_deprecated removed,Deprected module airflow.providers.cncf.kubernetes.pod_launcher_deprecated removed,dirrao,2024-08-28 11:27:16+00:00,['dirrao'],2024-10-07 15:04:17+00:00,2024-10-07 15:04:17+00:00,https://github.com/apache/airflow/pull/41830,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]","[{'comment_id': 2320748891, 'issue_id': 2491818235, 'author': 'dirrao', 'body': ""> This is provider breaking change not Airflow 3...\r\n> I don't think we have a reason to introduce breaking change of K8s provider right now\r\n\r\nTrue. We can do whenever we do major provider version changes."", 'created_at': datetime.datetime(2024, 8, 30, 10, 11, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397189198, 'issue_id': 2491818235, 'author': 'vincbeck', 'body': 'Closing this one', 'created_at': datetime.datetime(2024, 10, 7, 15, 4, 17, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-30 10:11:11 UTC): True. We can do whenever we do major provider version changes.

vincbeck on (2024-10-07 15:04:17 UTC): Closing this one

"
2491793409,pull_request,closed,,Fix: DAGs are not marked as stale if the dags folder change (#41433),"Fix: DAGs are not marked as stale if the AIRFLOW__CORE__DAGS_FOLDER changes

Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>

* Update if condition for readability

---------

Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>
(cherry picked from commit 9f30a41874454696ae2b215b2d86cb9a62968006)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",utkarsharma2,2024-08-28 11:15:17+00:00,[],2024-08-30 11:34:58+00:00,2024-08-28 12:48:43+00:00,https://github.com/apache/airflow/pull/41829,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2491767371,pull_request,closed,,fix(dag): avoid getting dataset next run info for unresolved dataset alias,"## Why

In https://github.com/apache/airflow/pull/41453, we change the condition to get dataset next run info [from `self.schedule_interval != ""Dataset""` to `self.dataset_expression is None:`](https://github.com/apache/airflow/pull/41453/files#diff-62c8e300ee91e0d59f81e0ea5d30834f04db71ae74f2e155a10b51056b00b59bR3709) which won't work for ""Unresolved Dataset Alias"" as they don't have dataset info to get yet.

## What
Do not get dataset next run info if it's an unresolved dataset alias

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-28 11:03:08+00:00,[],2024-09-20 08:17:48+00:00,2024-09-20 08:17:46+00:00,https://github.com/apache/airflow/pull/41828,[],"[{'comment_id': 2363014873, 'issue_id': 2491767371, 'author': 'Lee-W', 'body': '> Should this have a test?\r\n\r\nsounds good. just added it. will merge this one once CI passed', 'created_at': datetime.datetime(2024, 9, 20, 7, 26, 33, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-09-20 07:26:33 UTC): sounds good. just added it. will merge this one once CI passed

"
2491765379,pull_request,closed,,Update hook-weight to -1 for proper ArgoCD sync,"According to ArgoCD, the pre-install hook-weight should be -1 in order to execute the hook before running the upgrade.
https://argo-cd.readthedocs.io/en/stable/user-guide/helm/#hook-tips",covidium,2024-08-28 11:02:18+00:00,[],2024-09-23 07:30:28+00:00,2024-09-23 07:30:28+00:00,https://github.com/apache/airflow/pull/41827,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2315166162, 'issue_id': 2491765379, 'author': 'covidium', 'body': '> IMHO, this change should be done by introducing a new helm value, with 0 by default.\r\n\r\nWill .Values.preSync.hookWeight be OK as the new var?', 'created_at': datetime.datetime(2024, 8, 28, 12, 17, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2355838492, 'issue_id': 2491765379, 'author': 'tailorck', 'body': '@hussein-awala , are the values that @covidium proposed more appropriate? This PR is blocking some important company initiative on our end and we would like to find a resolution quickly. We appreciate your cooperation.', 'created_at': datetime.datetime(2024, 9, 17, 13, 38, 35, tzinfo=datetime.timezone.utc)}]","covidium (Issue Creator) on (2024-08-28 12:17:12 UTC): Will .Values.preSync.hookWeight be OK as the new var?

tailorck on (2024-09-17 13:38:35 UTC): @hussein-awala , are the values that @covidium proposed more appropriate? This PR is blocking some important company initiative on our end and we would like to find a resolution quickly. We appreciate your cooperation.

"
2491748668,pull_request,closed,,Remove tabular provider from source code,Provider is removed in last wave,eladkal,2024-08-28 10:54:22+00:00,[],2024-08-29 19:09:45+00:00,2024-08-29 16:31:08+00:00,https://github.com/apache/airflow/pull/41826,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:tabular', '')]","[{'comment_id': 2318305365, 'issue_id': 2491748668, 'author': 'potiuk', 'body': 'Open API tests fixed in maine', 'created_at': datetime.datetime(2024, 8, 29, 16, 31, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-29 16:31:01 UTC): Open API tests fixed in maine

"
2491732095,pull_request,closed,,Make latest botocore tests green (#41626),"The latest botocore tests are conflicting with a few requirements and until apache-beam upcoming version is released we need to do some manual exclusions. Those exclusions should make latest botocore test green again.

(cherry picked from commit a13ccbbdec8e59f30218f604fca8cbb999fcb757)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-28 10:46:28+00:00,[],2024-08-30 11:35:37+00:00,2024-08-28 11:04:42+00:00,https://github.com/apache/airflow/pull/41825,"[('area:providers', ''), ('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:opensearch', '')]","[{'comment_id': 2314972175, 'issue_id': 2491732095, 'author': 'potiuk', 'body': 'Bckport #41626', 'created_at': datetime.datetime(2024, 8, 28, 10, 47, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-28 10:47:00 UTC): Bckport #41626

"
2491703852,pull_request,closed,,Update providers metadata 2024-08-28,,eladkal,2024-08-28 10:33:32+00:00,[],2024-08-28 13:20:11+00:00,2024-08-28 11:01:46+00:00,https://github.com/apache/airflow/pull/41823,[],[],
2491631931,pull_request,closed,,Pin universal-pathlib to 0.2.2 as 0.2.3 generates static code check eâ€¦,"â€¦rrors (#41715)

(cherry picked from commit 1c53961fd4cc1f9085680bf22fbe7f57e29948d4)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-28 10:00:41+00:00,[],2024-08-30 11:35:22+00:00,2024-08-28 11:21:07+00:00,https://github.com/apache/airflow/pull/41820,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2314878112, 'issue_id': 2491631931, 'author': 'potiuk', 'body': 'Backport #41715', 'created_at': datetime.datetime(2024, 8, 28, 10, 0, 59, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-28 10:00:59 UTC): Backport #41715

"
2491485348,pull_request,closed,,Drop execution_date unique constraint on DagRun,"The column has also been renamed to logical_date, although the Python model is not changed. This allows us to not need to fix all the Python code at once (we'll do that later), but still do the two changes in one migration instead of two.

Note that this one is not breakingâ€”the metadatabase interface is not user-facing, weâ€™re only removing a check that stopped impossible things.",uranusjr,2024-08-28 08:54:53+00:00,[],2024-09-04 13:29:02+00:00,2024-09-04 13:29:00+00:00,https://github.com/apache/airflow/pull/41818,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-83', 'Remove Execution Date Unique Constraint from DAG Run')]","[{'comment_id': 2327894185, 'issue_id': 2491485348, 'author': 'uranusjr', 'body': 'Fixed. If this passes, I think it can be merged first.', 'created_at': datetime.datetime(2024, 9, 4, 4, 33, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2328633428, 'issue_id': 2491485348, 'author': 'uranusjr', 'body': 'I think it is more appropriate to attach the news fragment on the next PR that will rename the attribute on DagRun instead. That one is the actual breaking change most people will notice.\r\n\r\nThis PR only affects the SQL layer, not Python. Having separate fragments for changes in each layer will likely be a bit confusing.', 'created_at': datetime.datetime(2024, 9, 4, 11, 16, 40, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-09-04 04:33:39 UTC): Fixed. If this passes, I think it can be merged first.

uranusjr (Issue Creator) on (2024-09-04 11:16:40 UTC): I think it is more appropriate to attach the news fragment on the next PR that will rename the attribute on DagRun instead. That one is the actual breaking change most people will notice.

This PR only affects the SQL layer, not Python. Having separate fragments for changes in each layer will likely be a bit confusing.

"
2491343345,pull_request,closed,,Add examples for discussion/vote threads for new providers,,eladkal,2024-08-28 07:49:23+00:00,[],2024-08-28 10:25:03+00:00,2024-08-28 08:57:16+00:00,https://github.com/apache/airflow/pull/41817,[],[],
2490842417,pull_request,closed,,fix test_yandex_lockbox_secret_backend_get_connection_from_json by removing non-json extra,"## Why
non-json extra is not allowed after https://github.com/apache/airflow/pull/41762 which breaks `test_yandex_lockbox_secret_backend_get_connection_from_json`

## What
Change the extra value to json

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-28 02:59:30+00:00,[],2024-08-28 06:22:13+00:00,2024-08-28 06:22:11+00:00,https://github.com/apache/airflow/pull/41815,"[('area:providers', ''), ('area:secrets', ''), ('provider:yandex', '')]",[],
2490824876,pull_request,closed,,feat(datasets): make strict_dataset_uri_validation default to True,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-28 02:45:24+00:00,[],2024-10-09 10:52:13+00:00,2024-10-09 10:52:11+00:00,https://github.com/apache/airflow/pull/41814,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2395655768, 'issue_id': 2490824876, 'author': 'Lee-W', 'body': 'https://cwiki.apache.org/confluence/x/vIz5E', 'created_at': datetime.datetime(2024, 10, 6, 23, 48, 11, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-10-06 23:48:11 UTC): https://cwiki.apache.org/confluence/x/vIz5E

"
2490708595,pull_request,closed,,logout link in no roles error page fix,"closes: #41580

This PR fixes log out link in no roles and permissions error page

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gagan-bhullar-tech,2024-08-28 01:56:20+00:00,[],2024-08-30 09:23:05+00:00,2024-08-28 18:16:19+00:00,https://github.com/apache/airflow/pull/41813,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2313937314, 'issue_id': 2490708595, 'author': 'gagan-bhullar-tech', 'body': '@shahar1 can you please review', 'created_at': datetime.datetime(2024, 8, 28, 1, 57, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315983199, 'issue_id': 2490708595, 'author': 'shahar1', 'body': 'Excellent! Thank you.', 'created_at': datetime.datetime(2024, 8, 28, 18, 16, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315983738, 'issue_id': 2490708595, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 28, 18, 16, 21, tzinfo=datetime.timezone.utc)}]","gagan-bhullar-tech (Issue Creator) on (2024-08-28 01:57:36 UTC): @shahar1 can you please review

shahar1 on (2024-08-28 18:16:02 UTC): Excellent! Thank you.

boring-cyborg[bot] on (2024-08-28 18:16:21 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2490550612,pull_request,closed,,log statements in google dataproc,"closes: #41789 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gagan-bhullar-tech,2024-08-27 23:45:56+00:00,[],2024-10-23 00:15:14+00:00,2024-10-23 00:15:14+00:00,https://github.com/apache/airflow/pull/41812,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2313762680, 'issue_id': 2490550612, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 27, 23, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420906596, 'issue_id': 2490550612, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 18, 0, 15, 1, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-27 23:46:00 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2024-10-18 00:15:01 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2490523224,pull_request,closed,,add flexibility for redis service ,"we are currently experience an issue that requires us to expose redis service through nodeport. update the redis service template so it can accept NodePort as service type

test 1:
default service value
```
  service:
    # service type, default: ClusterIP
    type: ""ClusterIP""
    # if service type is ClusterIP, a clusterIP can be specified
    clusterIP:
    # if service type is NodePort, a nodePort can be specified
    nodePort:
```
service template rendering to the original one
```
apiVersion: v1
kind: Service
metadata:
  name: airflow-redis
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: ""airflow-1.14.0""
    heritage: Helm
spec:
  type: ClusterIP
  selector:
    tier: airflow
    component: redis
    release: airflow
  ports:
    - name: redis-db
      protocol: TCP
      port: 6379
      targetPort: 6379
```
test 2: 
setup clusterIP:
```
  service:
    # service type, default: ClusterIP
    type: ""ClusterIP""
    # if service type is ClusterIP, a clusterIP can be specified
    clusterIP: 127.0.0.1
    # if service type is NodePort, a nodePort can be specified
    nodePort:
```
```
apiVersion: v1
kind: Service
metadata:
  name: airflow-redis
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: ""airflow-1.14.0""
    heritage: Helm
spec:
  type: ClusterIP
  clusterIP: 127.0.0.1
  selector:
    tier: airflow
    component: redis
    release: airflow
  ports:
    - name: redis-db
      protocol: TCP
      port: 6379
      targetPort: 6379
```
test 3:
setup NodePort
```
  service:
    # service type, default: ClusterIP
    type: ""ClusterIP""
    # if service type is ClusterIP, a clusterIP can be specified
    clusterIP:
    # if service type is NodePort, a nodePort can be specified
    nodePort: 11111
```
```
apiVersion: v1
kind: Service
metadata:
  name: airflow-redis
  labels:
    tier: airflow
    component: redis
    release: airflow
    chart: ""airflow-1.14.0""
    heritage: Helm
spec:
  type: NodePort
  selector:
    tier: airflow
    component: redis
    release: airflow
  ports:
    - name: redis-db
      protocol: TCP
      port: 6379
      targetPort: 6379
      nodePort: 11111
```





<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kongdewen,2024-08-27 23:11:30+00:00,[],2024-10-01 06:40:33+00:00,2024-10-01 06:40:33+00:00,https://github.com/apache/airflow/pull/41811,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2490492554,pull_request,closed,,Don't Fail LocalTaskJob on heartbeat (#41704),"(cherry picked from commit 6647610a8e8e3de4d2bfb701e16d1c7b42edd3f8)

Cherry-picking #41704 for 2.10.1.",jedcunningham,2024-08-27 22:44:59+00:00,[],2024-08-30 11:51:34+00:00,2024-08-28 06:34:14+00:00,https://github.com/apache/airflow/pull/41810,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2490394767,pull_request,closed,,Keep FAB compatibility for versions before 1.3.0 in 2.10 (#41549),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
(cherry picked from commit https://github.com/apache/airflow/commit/d7d944e3818baf98c310314e369d767866012939)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",joaopamaral,2024-08-27 21:20:13+00:00,[],2024-08-30 11:36:23+00:00,2024-08-28 10:41:52+00:00,https://github.com/apache/airflow/pull/41809,"[('area:serialization', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2313702842, 'issue_id': 2490394767, 'author': 'joaopamaral', 'body': ""I'm checking the other tests that are failing. ðŸ‘€"", 'created_at': datetime.datetime(2024, 8, 27, 22, 47, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314960941, 'issue_id': 2490394767, 'author': 'potiuk', 'body': 'Back-port of #41549', 'created_at': datetime.datetime(2024, 8, 28, 10, 41, 17, tzinfo=datetime.timezone.utc)}]","joaopamaral (Issue Creator) on (2024-08-27 22:47:46 UTC): I'm checking the other tests that are failing. ðŸ‘€

potiuk on (2024-08-28 10:41:17 UTC): Back-port of #41549

"
2490393780,pull_request,closed,,Remove deprecations in airflow.models.taskreschedule,Code cleanup and removal of deprecations in `airflow.models.taskreschedule`.,jscheffl,2024-08-27 21:19:26+00:00,[],2024-11-21 20:45:54+00:00,2024-08-28 22:26:03+00:00,https://github.com/apache/airflow/pull/41808,[],"[{'comment_id': 2489829891, 'issue_id': 2490393780, 'author': 'vikramkoka', 'body': ""@jscheffl \r\n\r\nIt's not that I disagree with the PR, but I am surprised by the comment in the newsfragment, regarding the use of sqlalchemy. Since we are not disallowing direct access to the DB, wouldn't that be problematic?"", 'created_at': datetime.datetime(2024, 11, 21, 0, 40, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490125408, 'issue_id': 2490393780, 'author': 'jscheffl', 'body': '> @jscheffl\r\n> \r\n> It\'s not that I disagree with the PR, but I am surprised by the comment in the newsfragment, regarding the use of sqlalchemy. Since we are not disallowing direct access to the DB, wouldn\'t that be problematic?\r\n\r\n@vikramkoka The cleanup of the deprecation was not driven by a function or demand to urgently remove it. It was in a batch of ""make the house clean"" rounds in search & remove all deprecations. The both mentioned functions were not used in any area in the code anyway, they just have kept for a long time as legacy interface - with the reason of semantic release and non-breaking.\r\n\r\nI did not check the reason behind it and if there is any benefit in keeping them. Somebody in the past long time ago marked them deprecated and this was just a cleaning exercise. And yes, they were not used internally a long time ago and therefore there was no replacements. Did not make a forensic analysis and I assume everybody using that from the past might just copy the traces and re-implement rather having a public API on these helpers. Also as no forensic... I don\'t see a problem - but this is not a rationale to keep deprecations. I assume they are a leftover trace of a re-factoring which still harm future development.', 'created_at': datetime.datetime(2024, 11, 21, 5, 41, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491137787, 'issue_id': 2490393780, 'author': 'potiuk', 'body': ""Yeah. I think @vikramkoka is right - newsfragment in this one is a bit misleading. Since news fragments are intended for users -  I think we should clean up the description a bit and say 'direct access to DB is discouraged - using REST API is the only way to interact with Airflow'. \n\nThis is our statement for a long time and we captured it in the 'Public Interface'."", 'created_at': datetime.datetime(2024, 11, 21, 13, 22, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492292744, 'issue_id': 2490393780, 'author': 'jscheffl', 'body': '> Yeah. I think @vikramkoka is right - newsfragment in this one is a bit misleading. Since news fragments are intended for users - I think we should clean up the description a bit and say \'direct access to DB is discouraged - using REST API is the only way to interact with Airflow\'.\r\n> \r\n> This is our statement for a long time and we captured it in the \'Public Interface\'.\r\n\r\nSorry took a moment reading it a second time. I interpreted the first remark as a question ""why"" we remove the deprecation and now realized that the point to sqlalchemy was the problem you wanted to highlight :-D', 'created_at': datetime.datetime(2024, 11, 21, 20, 45, 53, tzinfo=datetime.timezone.utc)}]","vikramkoka on (2024-11-21 00:40:34 UTC): @jscheffl 

It's not that I disagree with the PR, but I am surprised by the comment in the newsfragment, regarding the use of sqlalchemy. Since we are not disallowing direct access to the DB, wouldn't that be problematic?

jscheffl (Issue Creator) on (2024-11-21 05:41:09 UTC): @vikramkoka The cleanup of the deprecation was not driven by a function or demand to urgently remove it. It was in a batch of ""make the house clean"" rounds in search & remove all deprecations. The both mentioned functions were not used in any area in the code anyway, they just have kept for a long time as legacy interface - with the reason of semantic release and non-breaking.

I did not check the reason behind it and if there is any benefit in keeping them. Somebody in the past long time ago marked them deprecated and this was just a cleaning exercise. And yes, they were not used internally a long time ago and therefore there was no replacements. Did not make a forensic analysis and I assume everybody using that from the past might just copy the traces and re-implement rather having a public API on these helpers. Also as no forensic... I don't see a problem - but this is not a rationale to keep deprecations. I assume they are a leftover trace of a re-factoring which still harm future development.

potiuk on (2024-11-21 13:22:49 UTC): Yeah. I think @vikramkoka is right - newsfragment in this one is a bit misleading. Since news fragments are intended for users -  I think we should clean up the description a bit and say 'direct access to DB is discouraged - using REST API is the only way to interact with Airflow'. 

This is our statement for a long time and we captured it in the 'Public Interface'.

jscheffl (Issue Creator) on (2024-11-21 20:45:53 UTC): Sorry took a moment reading it a second time. I interpreted the first remark as a question ""why"" we remove the deprecation and now realized that the point to sqlalchemy was the problem you wanted to highlight :-D

"
2490278350,pull_request,closed,,"Add Supervised Fine Tuning Train Operator, Hook, Tests, Docs","This pull request adds the following:

**SupervisedFineTuningHook**: Hook for Google Cloud Vertex AI Supervised Fine Tuning APIs.
**SupervisedFineTuningTrainOperator**: Use the Google Cloud Supervised Fine Tuning API to create a tuning job.

About  [Model tuning](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning): a crucial process in adapting Gemini to perform specific tasks with greater precision and accuracy. Model tuning works by providing a model with a training dataset that contains a set of examples of specific downstream tasks.

A sample DAG containing these operators could look like:
JSONL training data arrives in GCS >> GCSObjectExistenceSensor >> SupervisedFineTuningTrainOperator >> GenerativeModelGenerateContentOperator",CYarros10,2024-08-27 20:32:40+00:00,[],2024-08-30 16:26:14+00:00,2024-08-30 13:52:56+00:00,https://github.com/apache/airflow/pull/41807,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', ''), ('kind:documentation', '')]","[{'comment_id': 2317927047, 'issue_id': 2490278350, 'author': 'MaksYermak', 'body': '@CYarros10 What do you think about adding Links to this Operator and, maybe, for the previous operators related to generative AI? It is an example of code how it looks for PipelineJob https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/operators/vertex_ai/pipeline_job.py#L115 and https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/links/vertex_ai.py#L329', 'created_at': datetime.datetime(2024, 8, 29, 14, 43, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2319478611, 'issue_id': 2490278350, 'author': 'CYarros10', 'body': ""> @CYarros10 What do you think about adding Links to this Operator and, maybe, for the previous operators related to generative AI? It is an example of code how it looks for PipelineJob https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/operators/vertex_ai/pipeline_job.py#L115 and https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/links/vertex_ai.py#L329\r\n\r\nI think this is a great idea, I would love to do this but want to prioritize [CountTokensAPI](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/count-tokens?hl=en) and [EvaluationAPI](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/evaluation?hl=en) as these could be part of a broader LLM pipeline with SupervisedTuningFineTrainOperator and GenerativeModelGenerateContentOperator.  Will work on Links when I've completed those first!"", 'created_at': datetime.datetime(2024, 8, 29, 23, 48, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2319481202, 'issue_id': 2490278350, 'author': 'CYarros10', 'body': 'Refactored the code in this PR to be included in `airflow/airflow/providers/google/cloud/operators/vertex_ai/generative_model.py` - to keep all generative AI / generative model operations in one place. as well as hooks, tests, docs, etc. Feel free to add thoughts @MaksYermak - thank you for the review!', 'created_at': datetime.datetime(2024, 8, 29, 23, 50, 41, tzinfo=datetime.timezone.utc)}]","MaksYermak on (2024-08-29 14:43:38 UTC): @CYarros10 What do you think about adding Links to this Operator and, maybe, for the previous operators related to generative AI? It is an example of code how it looks for PipelineJob https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/operators/vertex_ai/pipeline_job.py#L115 and https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/links/vertex_ai.py#L329

CYarros10 (Issue Creator) on (2024-08-29 23:48:53 UTC): I think this is a great idea, I would love to do this but want to prioritize [CountTokensAPI](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/count-tokens?hl=en) and [EvaluationAPI](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/evaluation?hl=en) as these could be part of a broader LLM pipeline with SupervisedTuningFineTrainOperator and GenerativeModelGenerateContentOperator.  Will work on Links when I've completed those first!

CYarros10 (Issue Creator) on (2024-08-29 23:50:41 UTC): Refactored the code in this PR to be included in `airflow/airflow/providers/google/cloud/operators/vertex_ai/generative_model.py` - to keep all generative AI / generative model operations in one place. as well as hooks, tests, docs, etc. Feel free to add thoughts @MaksYermak - thank you for the review!

"
2490257527,pull_request,closed,,Fix mocking in cncf.kubernetes tests after get_connections removal,"The #41733 removed deprecated get_connections but it was still used in cncf.kubernetes tests.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-27 20:22:59+00:00,[],2024-08-27 20:31:53+00:00,2024-08-27 20:31:52+00:00,https://github.com/apache/airflow/pull/41805,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2490031806,pull_request,closed,,Add FAB migration commands,"This PR adds `migrate`, `upgrade` and `reset` db commands to facilitate migrating FAB DBs.

FAB upgrade is also integrated into Airflow upgrade such that if airflow db is being upgraded to the heads, FAB migration will also upgrade to the heads.

Migration checks to determine if migration has finished now includes checking that FAB migration is also done.

Note that downgrading Airflow does not trigger FAB downgrade. FAB downgrade has to be done with FAB downgrade command.

",ephraimbuddy,2024-08-27 18:07:35+00:00,[],2024-09-19 07:21:34+00:00,2024-09-19 07:21:33+00:00,https://github.com/apache/airflow/pull/41804,"[('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('provider:fab', ''), ('AIP-79', '')]",[],
2489872750,pull_request,closed,,airflow.models.xcom deprecations removed,airflow.models.xcom deprecations removed,dirrao,2024-08-27 16:35:50+00:00,[],2024-09-01 15:49:14+00:00,2024-09-01 15:49:14+00:00,https://github.com/apache/airflow/pull/41803,"[('area:providers', '')]","[{'comment_id': 2314599169, 'issue_id': 2489872750, 'author': 'dirrao', 'body': '@potiuk / @eladkal, \r\nWe have updated Xcoms provider tests. Provider tests are failing on earlier Airflow versions. Do we need to add airflow version condition-based checks? WDYT?', 'created_at': datetime.datetime(2024, 8, 28, 7, 58, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2318533440, 'issue_id': 2489872750, 'author': 'potiuk', 'body': 'Yes. We are running providers with previous Airflow versions - so ideally we should have them succeeded with older airflows as well. Likely a test_compat could be added to make xcom_push test work on both - see the contributing_docs for back-compatibility tests and `tests/test_utils/compat.py`', 'created_at': datetime.datetime(2024, 8, 29, 18, 8, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2322808109, 'issue_id': 2489872750, 'author': 'dirrao', 'body': '@potiuk  / @uranusjr \r\nProvider backward compatibility test is failing. Ideally, it should pass. Something nontrivial to me. Can someone help me with this?', 'created_at': datetime.datetime(2024, 8, 31, 7, 10, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323069602, 'issue_id': 2489872750, 'author': 'potiuk', 'body': 'Looks like `mock_context` in conftest.py should be modified to accept xcom_push with `execution_date` when Airflow < 3.0. Likely could be done by adding `**kwargs` to the xcom_push method and checking if `execution_date` is not passed when Airflow 3 (but passed when Airflow < 3)', 'created_at': datetime.datetime(2024, 8, 31, 23, 25, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323402982, 'issue_id': 2489872750, 'author': 'dirrao', 'body': '> Looks like `mock_context` in conftest.py should be modified to accept xcom_push with `execution_date` when Airflow < 3.0. Likely could be done by adding `**kwargs` to the xcom_push method and checking if `execution_date` is not passed when Airflow 3 (but passed when Airflow < 3)\r\n\r\nFinally all the tests are passing except one unrelated test. Looks good to me.', 'created_at': datetime.datetime(2024, 9, 1, 15, 46, 50, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-28 07:58:15 UTC): @potiuk / @eladkal, 
We have updated Xcoms provider tests. Provider tests are failing on earlier Airflow versions. Do we need to add airflow version condition-based checks? WDYT?

potiuk on (2024-08-29 18:08:21 UTC): Yes. We are running providers with previous Airflow versions - so ideally we should have them succeeded with older airflows as well. Likely a test_compat could be added to make xcom_push test work on both - see the contributing_docs for back-compatibility tests and `tests/test_utils/compat.py`

dirrao (Issue Creator) on (2024-08-31 07:10:30 UTC): @potiuk  / @uranusjr 
Provider backward compatibility test is failing. Ideally, it should pass. Something nontrivial to me. Can someone help me with this?

potiuk on (2024-08-31 23:25:28 UTC): Looks like `mock_context` in conftest.py should be modified to accept xcom_push with `execution_date` when Airflow < 3.0. Likely could be done by adding `**kwargs` to the xcom_push method and checking if `execution_date` is not passed when Airflow 3 (but passed when Airflow < 3)

dirrao (Issue Creator) on (2024-09-01 15:46:50 UTC): Finally all the tests are passing except one unrelated test. Looks good to me.

"
2489859612,pull_request,closed,,"Revert ""Remove deprecated parameters from airflow (core) Operators""","Reverts apache/airflow#41736

We must first get standard provider released https://github.com/apache/airflow/pull/41564
Also, once we migrate all operators to standard provider we won't need this breaking change in core as all the code will be in the provder",eladkal,2024-08-27 16:29:28+00:00,[],2024-09-08 12:16:24+00:00,2024-09-08 12:16:21+00:00,https://github.com/apache/airflow/pull/41801,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2313394852, 'issue_id': 2489859612, 'author': 'jscheffl', 'body': 'As discussed in Slack and the other PR--- we might need to discuss the approach for deprecation vs. separation.', 'created_at': datetime.datetime(2024, 8, 27, 19, 56, 47, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-27 19:56:47 UTC): As discussed in Slack and the other PR--- we might need to discuss the approach for deprecation vs. separation.

"
2489718759,pull_request,closed,,Add feature to read log from opensearch,"Closes #33619 

Airflow currently only supports reading remote log from elasticsearch. This PR adds feature to also allow reading remote logs from opensearch.

Similar to reading remote logs from elasticsearch, users need to use other tools to import logs into Opensearch. 

The set up is very similar to setting up remote logging for Elasticsearch. In the airflow.cfg: 

```
remote_logging = True
remote_log_conn_id = opensearch_default

[opensearch]
host = [OS host name] (e.g. my-opensearch-01)
port = [port number] (e.g. 9200)
username = 
password = 
```

Depending on your Opensearch config, you may also add the following in airflow.cfg :

```
[opensearch_configs]
http_compress = False
use_ssl = False
verify_certs = False
ssl_assert_hostname = False
ssl_show_warn = False
ca_certs = 
```

If you set up everything successfully (And correctly ship your logs to Opensearch), webserver should output logs like the following: 

```
[2024-08-27T15:02:54.611+0000] {base.py:258} INFO - POST http://my-opensearch-01:9200/_all/_count [status:200 request:0.034s]
[2024-08-27T15:02:54.654+0000] {base.py:258} INFO - POST http://my-opensearch-01:9200/_all/_search?size=1000&sort=log&from=0 [status:200 request:0.040s]
192.168.65.1 - - [27/Aug/2024:15:02:54 +0000] ""GET /api/v1/dags/consume_1_or_2_with_dataset_expressions/dagRuns/manual__2024-08-27T15:00:00.024040+00:00/taskInstances/consume_1_or_2_with_dataset_expressions/logs/1?full_content=false HTTP/1.1"" 200 4219 ""http://localhost:28080/dags/consume_1_or_2_with_dataset_expressions/grid?dag_run_id=manual__2024-08-27T15%3A00%3A00.024040%2B00%3A00&task_id=consume_1_or_2_with_dataset_expressions&tab=logs""
``` 
",Owen-CH-Leung,2024-08-27 15:29:22+00:00,[],2024-09-21 07:57:59+00:00,2024-09-21 07:57:58+00:00,https://github.com/apache/airflow/pull/41799,"[('area:providers', ''), ('area:logging', ''), ('kind:documentation', ''), ('provider:opensearch', '')]","[{'comment_id': 2320845239, 'issue_id': 2489718759, 'author': 'Owen-CH-Leung', 'body': '@eladkal can I seek your review for this PR ? Thanks', 'created_at': datetime.datetime(2024, 8, 30, 10, 57, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2363293535, 'issue_id': 2489718759, 'author': 'eladkal', 'body': '@kaxil @ephraimbuddy can you review the core parts of this PR? Given the work for Airflow 3 I am not sure about the provider<->core log integrations. To my understanding it is still coupled with core to some extant', 'created_at': datetime.datetime(2024, 9, 20, 9, 36, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2364288648, 'issue_id': 2489718759, 'author': 'eladkal', 'body': ""Noting: I set Airflow 3 milestone for this PR.\r\nThe provider part will be released in next wave after it's merged but for the core parts we can't release it in 2.10.x as this is feature, we can't also release it in 2.11 as this is a feature that does not serve the porpuse of bridge release as we agreed (reference to https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#developing-for-airflow-3-and-210x--211x )"", 'created_at': datetime.datetime(2024, 9, 20, 18, 23, 18, tzinfo=datetime.timezone.utc)}]","Owen-CH-Leung (Issue Creator) on (2024-08-30 10:57:41 UTC): @eladkal can I seek your review for this PR ? Thanks

eladkal on (2024-09-20 09:36:22 UTC): @kaxil @ephraimbuddy can you review the core parts of this PR? Given the work for Airflow 3 I am not sure about the provider<->core log integrations. To my understanding it is still coupled with core to some extant

eladkal on (2024-09-20 18:23:18 UTC): Noting: I set Airflow 3 milestone for this PR.
The provider part will be released in next wave after it's merged but for the core parts we can't release it in 2.10.x as this is feature, we can't also release it in 2.11 as this is a feature that does not serve the porpuse of bridge release as we agreed (reference to https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#developing-for-airflow-3-and-210x--211x )

"
2489687636,pull_request,closed,,Setup ui rest api,"This is the initial PR for AIP-84, setting up a very basic separate FastAPI API for UI purposes. I wanted to take that incrementally instead of opening a big PR latter. Some steps will require discussions on the implementation (I see different ways of handling things), and I don't want a gigantic PR getting blocked for days/weeks.

The goal at the end of that is to have 1 `object` custom endpoint duplicated to the new `UI REST API` showing how such endpoint are developed and tested as part of the new API.

At the time of airflow 3 release, old endpoint `/object` will simply be deleted, so we do not care at that time about duplication. (old endpoint contribution will be limited / filtered anyway).

To test this very basic endpoint you can for now simply run airflow with breeze. Stop the webserver and start the new UI Rest API manually with `fastapi dev airflow/api_ui/main.py`. Then in another breeze terminal run `curl localhost:8000/ui/next_run_datasets/<your_dag_id_with_datasets>` 

Follow up PRs in the next few days to:
- Integrate the new UI API to the CLI (most likely under a new command `airflow ui-api` or directly under `airflow webserver` ?)
- Integrate the new UI API to Breeze (for developer experience)
- Tests + CI integration (new test type, CI jobs etc.)
- Add permissions and access control
- Contributor documentation for this new API
- dev tools to automatically generate front-end code (typescript types + react queries) based on the API spec
- Clean and modularize code.


![Screenshot 2024-08-27 at 17 50 18](https://github.com/user-attachments/assets/e21503f7-e058-4aff-8e92-30783e36be1b)

",pierrejeambrun,2024-08-27 15:17:06+00:00,['pierrejeambrun'],2024-08-29 23:18:35+00:00,2024-08-29 17:08:56+00:00,https://github.com/apache/airflow/pull/41798,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2314576836, 'issue_id': 2489687636, 'author': 'pierrejeambrun', 'body': 'Special tests with pydantic v1 and no pydantic will break. Can we add `pydantic >2.x.` to airflow 3, I think it is reasonable to make airflow require pydantic v2, WDYT ? \r\n\r\nShould I open another PR that do that and delete the `Pydantic v1 test` and `Pydantic removed tests` as this will not be relevant anymore ?\r\n\r\nFastAPI does not impose pydantic v2 and still works with pydantic v1 (for now), if we really want to, we can still support pydantic v1 for airflow 3 I guess.', 'created_at': datetime.datetime(2024, 8, 28, 7, 48, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314706054, 'issue_id': 2489687636, 'author': 'potiuk', 'body': ""Yes. Just remove the special testa (no Pydantic in main (and relevant code in entrypoint_ci.sh). I think we already know that Pydantic in Airflow 3 is a must with fastapi.\n\nWhen it comes to V2 vs. V1 - I'd be for removing V1 support as well. It still 6 months or so until Airflow 3 is out which will be already almost 2 years of Pydantic V2. \n\nAll our community providers that need Pydantic  already support V2. There are already few dependencies that only work with Pydantic 2 (pyiceberg weaviate-client) and we can expect more dropping it. \n\nThe only problem is when someone uses their own libraries/old versions that support only V1. It's been a problem in the past - but we can expect it to be negligible in the future. \n\nAlso Airflow 3 is a bit delifferrnt beast altogether - when we do task-sdk separation and different set of dependencies (no providers) for scheduler/webserver and workers/processor/triggerer (with providers) the problem will be gone entirely - because Pydantic V2 will only be necessary for webserver/apiserver. If (as I advocate for) we find a way to not have to install providers  in webserver/API server - the problem will be gone entirely - this is yet another reason why I think we should aim for webserver not having to install providers in webserver for base operator links/ connections /log handlers - this way it will not matter if any custom code or providers has conflicting dependencies with webserver or not and we could make such decision without even blinking."", 'created_at': datetime.datetime(2024, 8, 28, 8, 45, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315427587, 'issue_id': 2489687636, 'author': 'vincbeck', 'body': '> If (as I advocate for) we find a way to not have to install providers in webserver/API server - the problem will be gone entirely - this is yet another reason why I think we should aim for webserver not having to install providers in webserver for base operator links/ connections /log handlers - this way it will not matter if any custom code or providers has conflicting dependencies with webserver or not and we could make such decision without even blinking.\r\n\r\nThat would be awesome indeed! But, as mentioned by Ash at the last dev call, we need to find a solution for the auth manager. They are currently in providers and they are used by the webserver', 'created_at': datetime.datetime(2024, 8, 28, 14, 8, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315775269, 'issue_id': 2489687636, 'author': 'potiuk', 'body': '> That would be awesome indeed! But, as mentioned by Ash at the last dev call, we need to find a solution for the auth manager. They are currently in providers and they are used by the webserver\r\n\r\nIt\'s a bit spinning-off the Pydantic discussion but yes - having a ""webserver-only plugin""  or smth would be the best. We could define those independently from providers - same with remote logging. \r\n\r\nI do not think this should be a separate workstream targeted for 3.0 (it could possibly be done later) - but there is nothing wrong in installing ""just"" amazon provider in webserver when you need the loggging/auth - or we could potentially carve-out ""Auth/Logging"" out of provider to separate package. \r\n\r\nCurrently the way airflow webserver works -  you  need to install all providers your DAGs can use, and if you have conflicts with any of them - you have a problem. But if you only install ""amazon auth"" and ""amazon logging"" - (for example) - which might be from amazon provider or it might be from a ""webserver plugin"" - and we do not need to install any other provider - that changes a lot when it comes to conflicting dependencies. \r\n\r\nIf we we could just move connections and base operator links out - that would remove the need to install all the providers you want to use in your DAGs for webserver - and only install single auth/loging that is ""per-installation"".', 'created_at': datetime.datetime(2024, 8, 28, 16, 17, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317226145, 'issue_id': 2489687636, 'author': 'pierrejeambrun', 'body': 'Ok thanks for the details @potiuk, the last commit remove all things related to pydantic v1 vs v2 vs none in the codebase. (dev tools, tests,  utils and more).\r\n\r\nLets see if the CI is happy.\r\n\r\nMaybe I should add a significant newsfragment for `airflow core requiring pydantic >=v2.3` this seems important to users, especially those that relied on v1.x ?', 'created_at': datetime.datetime(2024, 8, 29, 10, 7, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317574151, 'issue_id': 2489687636, 'author': 'potiuk', 'body': 'That looks good - but possibly separating the pydantic removals out is a good idea + there are some test failures - which do not seem related to pydantic removal (another reason why separating is likely a good idea)', 'created_at': datetime.datetime(2024, 8, 29, 12, 52, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317576925, 'issue_id': 2489687636, 'author': 'potiuk', 'body': 'And yes - since pydantic is quite popular and has potential for conflicts- adding a one-line note/newsfragment is likely a good idea.', 'created_at': datetime.datetime(2024, 8, 29, 12, 53, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317629630, 'issue_id': 2489687636, 'author': 'pierrejeambrun', 'body': 'Rebased on top of https://github.com/apache/airflow/pull/41857 that need to be merged first.', 'created_at': datetime.datetime(2024, 8, 29, 13, 15, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2318298063, 'issue_id': 2489687636, 'author': 'potiuk', 'body': 'https://github.com/apache/airflow/pull/41857 merged - merging this one then', 'created_at': datetime.datetime(2024, 8, 29, 16, 27, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2318299136, 'issue_id': 2489687636, 'author': 'potiuk', 'body': '(feel freee to merge it @pierrejeambrun if ready)', 'created_at': datetime.datetime(2024, 8, 29, 16, 28, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2318402062, 'issue_id': 2489687636, 'author': 'pierrejeambrun', 'body': 'Yes ready ty', 'created_at': datetime.datetime(2024, 8, 29, 17, 8, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2319065758, 'issue_id': 2489687636, 'author': 'jscheffl', 'body': ""Ah, late to the party, did not see the PR prior merge... will the new API with FastAPI always be another hosted process next to webserver? Or will FastAPI (later) mode as a new endpoint below? I fear adding a new additional process makes deployment more complex and I'd prefer to host only one web facing server endpoint. (Else I have two host names or need an ingress/application gateway to redirrect sub-path'es to the right process serving content)"", 'created_at': datetime.datetime(2024, 8, 29, 21, 36, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2319359820, 'issue_id': 2489687636, 'author': 'pierrejeambrun', 'body': 'I think that nothing is set in stone. I went with a separate process because I think this is what was originally mentioned and it is easier to iterate and develop, but this is far from production ready and to what it will actually look like when airflow 3 comes out.\r\n\r\nAt some point that might come under the umbrella of a single process with multiple apps running as you mentioned. I know that Ash also has a new API coming for the task interface work.\r\n\r\nI think it is up to us to decide considering other API and AIP. (I just didnâ€™t want this one to get blocked until we find a consensus this is not specific to this AIP particularly but more generally how do we handle our multiple APIs deployment, there is also the internal-44 API too)', 'created_at': datetime.datetime(2024, 8, 29, 23, 13, 59, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-08-28 07:48:26 UTC): Special tests with pydantic v1 and no pydantic will break. Can we add `pydantic >2.x.` to airflow 3, I think it is reasonable to make airflow require pydantic v2, WDYT ? 

Should I open another PR that do that and delete the `Pydantic v1 test` and `Pydantic removed tests` as this will not be relevant anymore ?

FastAPI does not impose pydantic v2 and still works with pydantic v1 (for now), if we really want to, we can still support pydantic v1 for airflow 3 I guess.

potiuk on (2024-08-28 08:45:14 UTC): Yes. Just remove the special testa (no Pydantic in main (and relevant code in entrypoint_ci.sh). I think we already know that Pydantic in Airflow 3 is a must with fastapi.

When it comes to V2 vs. V1 - I'd be for removing V1 support as well. It still 6 months or so until Airflow 3 is out which will be already almost 2 years of Pydantic V2. 

All our community providers that need Pydantic  already support V2. There are already few dependencies that only work with Pydantic 2 (pyiceberg weaviate-client) and we can expect more dropping it. 

The only problem is when someone uses their own libraries/old versions that support only V1. It's been a problem in the past - but we can expect it to be negligible in the future. 

Also Airflow 3 is a bit delifferrnt beast altogether - when we do task-sdk separation and different set of dependencies (no providers) for scheduler/webserver and workers/processor/triggerer (with providers) the problem will be gone entirely - because Pydantic V2 will only be necessary for webserver/apiserver. If (as I advocate for) we find a way to not have to install providers  in webserver/API server - the problem will be gone entirely - this is yet another reason why I think we should aim for webserver not having to install providers in webserver for base operator links/ connections /log handlers - this way it will not matter if any custom code or providers has conflicting dependencies with webserver or not and we could make such decision without even blinking.

vincbeck on (2024-08-28 14:08:19 UTC): That would be awesome indeed! But, as mentioned by Ash at the last dev call, we need to find a solution for the auth manager. They are currently in providers and they are used by the webserver

potiuk on (2024-08-28 16:17:10 UTC): It's a bit spinning-off the Pydantic discussion but yes - having a ""webserver-only plugin""  or smth would be the best. We could define those independently from providers - same with remote logging. 

I do not think this should be a separate workstream targeted for 3.0 (it could possibly be done later) - but there is nothing wrong in installing ""just"" amazon provider in webserver when you need the loggging/auth - or we could potentially carve-out ""Auth/Logging"" out of provider to separate package. 

Currently the way airflow webserver works -  you  need to install all providers your DAGs can use, and if you have conflicts with any of them - you have a problem. But if you only install ""amazon auth"" and ""amazon logging"" - (for example) - which might be from amazon provider or it might be from a ""webserver plugin"" - and we do not need to install any other provider - that changes a lot when it comes to conflicting dependencies. 

If we we could just move connections and base operator links out - that would remove the need to install all the providers you want to use in your DAGs for webserver - and only install single auth/loging that is ""per-installation"".

pierrejeambrun (Issue Creator) on (2024-08-29 10:07:22 UTC): Ok thanks for the details @potiuk, the last commit remove all things related to pydantic v1 vs v2 vs none in the codebase. (dev tools, tests,  utils and more).

Lets see if the CI is happy.

Maybe I should add a significant newsfragment for `airflow core requiring pydantic >=v2.3` this seems important to users, especially those that relied on v1.x ?

potiuk on (2024-08-29 12:52:37 UTC): That looks good - but possibly separating the pydantic removals out is a good idea + there are some test failures - which do not seem related to pydantic removal (another reason why separating is likely a good idea)

potiuk on (2024-08-29 12:53:26 UTC): And yes - since pydantic is quite popular and has potential for conflicts- adding a one-line note/newsfragment is likely a good idea.

pierrejeambrun (Issue Creator) on (2024-08-29 13:15:09 UTC): Rebased on top of https://github.com/apache/airflow/pull/41857 that need to be merged first.

potiuk on (2024-08-29 16:27:44 UTC): https://github.com/apache/airflow/pull/41857 merged - merging this one then

potiuk on (2024-08-29 16:28:15 UTC): (feel freee to merge it @pierrejeambrun if ready)

pierrejeambrun (Issue Creator) on (2024-08-29 17:08:35 UTC): Yes ready ty

jscheffl on (2024-08-29 21:36:49 UTC): Ah, late to the party, did not see the PR prior merge... will the new API with FastAPI always be another hosted process next to webserver? Or will FastAPI (later) mode as a new endpoint below? I fear adding a new additional process makes deployment more complex and I'd prefer to host only one web facing server endpoint. (Else I have two host names or need an ingress/application gateway to redirrect sub-path'es to the right process serving content)

pierrejeambrun (Issue Creator) on (2024-08-29 23:13:59 UTC): I think that nothing is set in stone. I went with a separate process because I think this is what was originally mentioned and it is easier to iterate and develop, but this is far from production ready and to what it will actually look like when airflow 3 comes out.

At some point that might come under the umbrella of a single process with multiple apps running as you mentioned. I know that Ash also has a new API coming for the task interface work.

I think it is up to us to decide considering other API and AIP. (I just didnâ€™t want this one to get blocked until we find a consensus this is not specific to this AIP particularly but more generally how do we handle our multiple APIs deployment, there is also the internal-44 API too)

"
2489679124,pull_request,closed,,"Fix treatment of ""#"" in S3Hook.parse_s3_url()","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
### Apache Airflow version

2.8.4 in my environment, but the issue is still present in main

### What happened

A client submitted an S3 file to my workflow with an octothorpe in the filename, essentially `s3://my-bucket/path/to/key/email campaign - PO# 123456_REPORT.csv`. When my Airflow DAG tried to parse this URL, part of the filename was lost:

```python
>>> s3_key = 's3://my-bucket/path/to/key/email campaign - PO# 123456_REPORT.csv'
>>> S3Hook.parse_s3_url(s3_key)
('my-bucket', 'path/to/key/email campaign - PO')
```
 ### What you think should happen instead

The key should not be truncated. The result of the above example should be `('my-bucket', 'path/to/key/email campaign - PO# 123456_REPORT.csv')`

### How to reproduce:

Call `S3Hook.parse_s3_url()` with a `#` character in the S3 URL. Everything after the `#` is lost, because urllib.parse.urlsplit() is current called with the default option `allow_fragments=True`.

This PR passes `allow_fragments=False` to `urlsplit` to prevent this error. As far as I can tell, there are no valid cases of `#` in an S3 key being treated as a fragment, and no existing GitHub issue to fix this.

### Operating System

Ubuntu 22.04

### Versions of Apache Airflow Providers

|Provider|Version|
|:--|:--|
|apache-airflow-providers-amazon|8.20.0|
|apache-airflow-providers-celery|3.6.2|
|apache-airflow-providers-common-io|1.3.1|
|apache-airflow-providers-common-sql|1.12.0|
|apache-airflow-providers-ftp|3.8.0|
|apache-airflow-providers-http|4.10.1|
|apache-airflow-providers-imap|3.5.0|
|apache-airflow-providers-postgres|5.10.2|
|apache-airflow-providers-sendgrid|3.4.0|
|apache-airflow-providers-sftp|4.9.1|
|apache-airflow-providers-smtp|1.6.1|
|apache-airflow-providers-sqlite|3.7.1|
|apache-airflow-providers-ssh|3.10.1|

### Deployment

This may be reproduced without deploying

### Are you willing to submit PR?
- [x] Yes I am willing to submit a PR!

### Code of Conduct
- [x] I agree to follow this project's [Code of Conduct](https://github.com/apache/airflow/blob/main/CODE_OF_CONDUCT.md)",GlenboLake,2024-08-27 15:13:55+00:00,[],2024-08-29 21:31:46+00:00,2024-08-29 21:31:43+00:00,https://github.com/apache/airflow/pull/41796,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2312843721, 'issue_id': 2489679124, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 27, 15, 14, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316252481, 'issue_id': 2489679124, 'author': 'vincbeck', 'body': 'Static checks are failing, running the pre-commit should auto resolve them', 'created_at': datetime.datetime(2024, 8, 28, 21, 6, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2317715174, 'issue_id': 2489679124, 'author': 'eladkal', 'body': 'static tests are failing', 'created_at': datetime.datetime(2024, 8, 29, 13, 48, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2319054776, 'issue_id': 2489679124, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 29, 21, 31, 45, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-27 15:14:01 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

vincbeck on (2024-08-28 21:06:21 UTC): Static checks are failing, running the pre-commit should auto resolve them

eladkal on (2024-08-29 13:48:35 UTC): static tests are failing

boring-cyborg[bot] on (2024-08-29 21:31:45 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2489660383,pull_request,closed,,Small fix for datafusion system test,"Small fix for Datafusion system test
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-08-27 15:06:53+00:00,[],2024-08-28 12:37:48+00:00,2024-08-28 12:37:48+00:00,https://github.com/apache/airflow/pull/41795,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2489608499,pull_request,closed,,update pattern for dataflow job id extraction,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Dataflow job id is extracted from the logged output of `java` process that starts the Dataflow job, for example, in case of `BeamRunJavaPipelineOperator`.

Currently job id pattern matches characters until first `""` or `\n` is encountered, which is fine for a following case:
- logged line: `[2024-08-27 11:20:22,094] INFO  Submitted job: 2024-08-27_04_20_21-7947372725816706151`
- extracted job id: `2024-08-27_04_20_21-7947372725816706151`

However, if the logger is configured differently, for example, has a whitespace and a suffix at the end with additional information, the pattern extracts the id together with the suffix:
- logged line: `[2024-08-27 11:20:22,094] INFO  Submitted job: 2024-08-27_04_20_21-7947372725816706151 (org.apache.beam.runners.dataflow.DataflowRunner) (main)`
- extracted job id: `2024-08-27_04_20_21-7947372725816706151 (org.apache.beam.runners.dataflow.DataflowRunner) (main)` 

In the previous example suffix `(org.apache.beam.runners.dataflow.DataflowRunner) (main)` should not be extracted as part of the job id.

I updated the pattern by adding the whitespace character `\s` (along side existing `""` and `\n`), indicating the end of job id.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",lukas-mi,2024-08-27 14:48:05+00:00,[],2024-09-13 12:04:33+00:00,2024-09-01 01:16:26+00:00,https://github.com/apache/airflow/pull/41794,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2321040410, 'issue_id': 2489608499, 'author': 'lukas-mi', 'body': '@VladaZakharova when will this be merged? :)', 'created_at': datetime.datetime(2024, 8, 30, 12, 12, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2321377397, 'issue_id': 2489608499, 'author': 'VladaZakharova', 'body': 'Hi @potiuk ! Can you please merge it?', 'created_at': datetime.datetime(2024, 8, 30, 14, 6, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2321383398, 'issue_id': 2489608499, 'author': 'potiuk', 'body': ""> @VladaZakharova when will this be merged? :)\r\n\r\nWhen the test pass and someone will merge it.\r\n\r\nSince you are the first time contributor - we have to manually approve workflows to see if tests pass, then you have to fix them if they don't. but when you submit new version you will have to wait for someone to see it and approve it (you can ask in general without mentioning anyone to approve your workflows) to signal that you **think** you fixed all the tests.\r\n\r\nAlso see the contribution docs that explain the process https://github.com/apache/airflow/tree/main/contributing-docs"", 'created_at': datetime.datetime(2024, 8, 30, 14, 8, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323101309, 'issue_id': 2489608499, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 1, 1, 16, 29, tzinfo=datetime.timezone.utc)}]","lukas-mi (Issue Creator) on (2024-08-30 12:12:29 UTC): @VladaZakharova when will this be merged? :)

VladaZakharova on (2024-08-30 14:06:48 UTC): Hi @potiuk ! Can you please merge it?

potiuk on (2024-08-30 14:08:47 UTC): When the test pass and someone will merge it.

Since you are the first time contributor - we have to manually approve workflows to see if tests pass, then you have to fix them if they don't. but when you submit new version you will have to wait for someone to see it and approve it (you can ask in general without mentioning anyone to approve your workflows) to signal that you **think** you fixed all the tests.

Also see the contribution docs that explain the process https://github.com/apache/airflow/tree/main/contributing-docs

boring-cyborg[bot] on (2024-09-01 01:16:29 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2489490222,pull_request,closed,,Remove deprecation warning for cgitb in Plugins Manager (#41732),"(cherry picked from commit 83ba17f41ee1f88c041289e8b88cf815bc61de7e)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-27 14:08:49+00:00,[],2024-08-30 11:39:48+00:00,2024-08-27 14:44:00+00:00,https://github.com/apache/airflow/pull/41793,"[('area:plugins', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2312681775, 'issue_id': 2489490222, 'author': 'potiuk', 'body': 'Backport of #41732', 'created_at': datetime.datetime(2024, 8, 27, 14, 9, 47, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-27 14:09:47 UTC): Backport of #41732

"
2489403883,pull_request,closed,,Fix: Keep compatibility with old FAB versions (#41549),"(cherry picked from commit d7d944e3818baf98c310314e369d767866012939)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-27 13:38:06+00:00,[],2024-08-28 10:50:31+00:00,2024-08-28 10:50:30+00:00,https://github.com/apache/airflow/pull/41792,[],"[{'comment_id': 2312597497, 'issue_id': 2489403883, 'author': 'potiuk', 'body': 'Backport of #41549', 'created_at': datetime.datetime(2024, 8, 27, 13, 40, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313119916, 'issue_id': 2489403883, 'author': 'joaopamaral', 'body': 'hey @potiuk, here is the test fix https://github.com/joaopamaral/airflow/commit/62709aa59935c94151043b7faa5e3be29794ce81', 'created_at': datetime.datetime(2024, 8, 27, 17, 18, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314979220, 'issue_id': 2489403883, 'author': 'potiuk', 'body': 'Closed in favour of #41809', 'created_at': datetime.datetime(2024, 8, 28, 10, 50, 30, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-27 13:40:36 UTC): Backport of #41549

joaopamaral on (2024-08-27 17:18:34 UTC): hey @potiuk, here is the test fix https://github.com/joaopamaral/airflow/commit/62709aa59935c94151043b7faa5e3be29794ce81

potiuk (Issue Creator) on (2024-08-28 10:50:30 UTC): Closed in favour of #41809

"
2489164779,pull_request,closed,,chore(docs): add an example for auth with keycloak (#41687),"* chore(docs): add an example for auth with keycloak

Added a new section in the authentication documentation that provides a code of configuring Airflow to work with Keycloak.

* chore(docs): add an example for auth with keycloak

Fix spelling and styling

* chore(docs): add an example for auth with keycloak

Fix static checks

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-27 12:10:10+00:00,[],2024-08-30 11:56:09+00:00,2024-08-27 14:02:41+00:00,https://github.com/apache/airflow/pull/41791,"[('area:providers', ''), ('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only'), ('provider:fab', '')]",[],
2489037244,pull_request,closed,,Add ENV_ID for job_name in Cloud Run system tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have added an ENV_ID for job_name variables in Cloud Run system test.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-08-27 11:15:21+00:00,[],2024-09-04 07:36:04+00:00,2024-09-04 07:35:56+00:00,https://github.com/apache/airflow/pull/41788,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]","[{'comment_id': 2328131265, 'issue_id': 2489037244, 'author': 'VladaZakharova', 'body': 'Hi @potiuk ! Can we please merge this?', 'created_at': datetime.datetime(2024, 9, 4, 7, 35, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2328133107, 'issue_id': 2489037244, 'author': 'potiuk', 'body': 'Done.', 'created_at': datetime.datetime(2024, 9, 4, 7, 36, 3, tzinfo=datetime.timezone.utc)}]","VladaZakharova on (2024-09-04 07:35:06 UTC): Hi @potiuk ! Can we please merge this?

potiuk on (2024-09-04 07:36:03 UTC): Done.

"
2488986881,pull_request,closed,,fix: revert behavior of flattening lists in OpenLineage's InfoJsonEncodable,"This reverts back to the behavior that was mistakenly changed in https://github.com/apache/airflow/pull/40371/files#diff-81a199a7e08fbc41cf7960d2725937b3dcfa2694368196681dfe82e3677fed0eL153

This did not match the jsonschema spec of the facet: https://github.com/apache/airflow/blob/9674af5f88929f5057158241330f4ef4fd08beb2/airflow/providers/openlineage/facets/AirflowDagRunFacet.json.

In the near future, we'd like to autogenerate those facets directly from spec as we're already using in `openlineage-python`. However, in the meantime, let's manually fix the error.",mobuchowski,2024-08-27 10:53:52+00:00,[],2024-09-02 11:26:36+00:00,2024-09-02 11:26:36+00:00,https://github.com/apache/airflow/pull/41786,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2323495411, 'issue_id': 2488986881, 'author': 'potiuk', 'body': 'Any more context here? Why that was a mistake?', 'created_at': datetime.datetime(2024, 9, 1, 21, 0, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2324429116, 'issue_id': 2488986881, 'author': 'mobuchowski', 'body': '@potiuk updated the description', 'created_at': datetime.datetime(2024, 9, 2, 10, 51, 37, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-09-01 21:00:59 UTC): Any more context here? Why that was a mistake?

mobuchowski (Issue Creator) on (2024-09-02 10:51:37 UTC): @potiuk updated the description

"
2488423154,pull_request,closed,,openlineage: Bump openlineage-python dependency.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

I'd like to bump minimum supported version of `openlineage-python` for OpenLineage provider so it supports this PR https://github.com/OpenLineage/OpenLineage/pull/2925.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JDarDagran,2024-08-27 06:35:33+00:00,[],2024-09-19 10:21:35+00:00,2024-09-19 10:21:35+00:00,https://github.com/apache/airflow/pull/41785,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2488287008,pull_request,closed,,airflow.models.taskinstance deprecations removed,airflow.models.taskinstance deprecations removed except excution_date. ,dirrao,2024-08-27 05:06:38+00:00,['dirrao'],2024-08-27 14:45:44+00:00,2024-08-27 14:45:44+00:00,https://github.com/apache/airflow/pull/41784,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:logging', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2488276982,pull_request,closed,,Adding rel property to hyperlinks in logs (#41696),"
(cherry picked from commit 79db243d03cc4406290597ad400ab0f514975c79)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-08-27 04:57:48+00:00,[],2024-08-30 11:41:17+00:00,2024-08-27 08:12:31+00:00,https://github.com/apache/airflow/pull/41783,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2487928289,pull_request,closed,,fix: job missing state update on_kill,"maybe close: https://github.com/apache/airflow/discussions/40090

",raphaelauv,2024-08-26 22:55:17+00:00,[],2024-09-02 10:56:23+00:00,2024-09-02 10:56:20+00:00,https://github.com/apache/airflow/pull/41781,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2487877958,pull_request,closed,,Remove deprecations in airflow.models.skipmixin,Code cleanup and removal of deprecations in `airflow.models.skipmixin`,jscheffl,2024-08-26 22:12:27+00:00,[],2024-08-27 12:33:59+00:00,2024-08-27 12:33:59+00:00,https://github.com/apache/airflow/pull/41780,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487861989,pull_request,closed,,Remove deprecations in airflow.models.errors,Code cleanup and removal of deprecations in `airflow.models.errors`,jscheffl,2024-08-26 22:01:23+00:00,[],2024-08-27 12:34:41+00:00,2024-08-27 12:34:41+00:00,https://github.com/apache/airflow/pull/41779,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487846079,pull_request,closed,,Remove deprecations in airflow.models.dagrun,Code cleanup and removal of deprecations in `airflow.models.dagrun`,jscheffl,2024-08-26 21:49:42+00:00,[],2024-08-27 14:15:06+00:00,2024-08-27 14:15:06+00:00,https://github.com/apache/airflow/pull/41778,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487747023,pull_request,closed,,Move `register_views` to auth manager interface,"Auth managers have the possibility of implementing their own views. To do that, it had to be done in the security manager override. The security manager override had been creating to override/customize the security manager. This is something needed by the FAB auth manager, but other than that, the other auth managers should not have the need of creating a security manager override.

To avoid creating security manager override just for the sake of registering views specific to auth manager, moving this method to the interface will simplify things.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-26 20:44:08+00:00,[],2024-09-04 14:32:21+00:00,2024-09-04 14:32:19+00:00,https://github.com/apache/airflow/pull/41777,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2311168893, 'issue_id': 2487747023, 'author': 'jscheffl', 'body': 'I see the interfaces with this PR are much simpler. But for the coupling of Providers and Core, this smells like a breaking change.\r\nDo you have a proposal how to further release updates for provider compatible with Airflow 2.8/2.9/2.10?\r\nIs the core change intended to be for Airflow 3?', 'created_at': datetime.datetime(2024, 8, 26, 21, 54, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312644063, 'issue_id': 2487747023, 'author': 'vincbeck', 'body': ""> I see the interfaces with this PR are much simpler. But for the coupling of Providers and Core, this smells like a breaking change. Do you have a proposal how to further release updates for provider compatible with Airflow 2.8/2.9/2.10? Is the core change intended to be for Airflow 3?\r\n\r\nYes you are right, I should have mentioned it in the PR. I'll take care of that today"", 'created_at': datetime.datetime(2024, 8, 27, 13, 58, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312724262, 'issue_id': 2487747023, 'author': 'vincbeck', 'body': '> Is the core change intended to be for Airflow 3?\r\n\r\nYes', 'created_at': datetime.datetime(2024, 8, 27, 14, 25, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312738769, 'issue_id': 2487747023, 'author': 'vincbeck', 'body': ""> Do you have a proposal how to further release updates for provider compatible with Airflow 2.8/2.9/2.10?\r\n\r\nI dont think this is a problem. The newly created method `register_views` in FAB auth manager calls underneath `register_views` in the security manager. Airflow 2 calls `register_views` from the security manager. Therefore, any modifications in the `register_views` method from security manager will be available in Airflow 2 and 3\r\n\r\nThe issue is all the way around, making sure that Airflow 3 can use older version of FAB provider. I'll handle it"", 'created_at': datetime.datetime(2024, 8, 27, 14, 31, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315893199, 'issue_id': 2487747023, 'author': 'vincbeck', 'body': 'I resolved the backward incompatibility issue. It should be all fine now.', 'created_at': datetime.datetime(2024, 8, 28, 17, 22, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316299463, 'issue_id': 2487747023, 'author': 'vincbeck', 'body': '> Did a review - if we would not want to replace FAB in Airflow 3 I would have made an approve, but as we actually want to get rid of it... Might be we need to introduce another method of integration that is future proof.\r\n> \r\n> Will the AWS Auth Manager render the views inside Airflow UI or just add menu entries which point to an external site?\r\n\r\n100% agree with you but the intent of this PR is not to drop FAB from Airflow. That requires a lot of work and will be done in separate PRs. The way I register views in the auth manager is the way it is done today so I dont add anything new. Definitely this will need to be reworked/redone later to complete AIP-79. And yes likely we will need to leverage the mechanism created in AIP-68 so that the auth manager can add new views to an Airflow environment', 'created_at': datetime.datetime(2024, 8, 28, 21, 42, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316302602, 'issue_id': 2487747023, 'author': 'jscheffl', 'body': '> > Did a review - if we would not want to replace FAB in Airflow 3 I would have made an approve, but as we actually want to get rid of it... Might be we need to introduce another method of integration that is future proof.\r\n> > Will the AWS Auth Manager render the views inside Airflow UI or just add menu entries which point to an external site?\r\n> \r\n> 100% agree with you but the intent of this PR is not to drop FAB from Airflow. That requires a lot of work and will be done in separate PRs. The way I register views in the auth manager is the way it is done today so I dont add anything new. Definitely this will need to be reworked/redone later to complete AIP-79. And yes likely we will need a mechanism similar to AIP-68 will expose for plugins so that the auth manager can add new views to an Airflow environment\r\n\r\nI just want to clarify not to add a new interface and therefore add a new legacy - even if it is used the same way but unclean today.', 'created_at': datetime.datetime(2024, 8, 28, 21, 44, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316303678, 'issue_id': 2487747023, 'author': 'vincbeck', 'body': '> > > Did a review - if we would not want to replace FAB in Airflow 3 I would have made an approve, but as we actually want to get rid of it... Might be we need to introduce another method of integration that is future proof.\r\n> > > Will the AWS Auth Manager render the views inside Airflow UI or just add menu entries which point to an external site?\r\n> > \r\n> > \r\n> > 100% agree with you but the intent of this PR is not to drop FAB from Airflow. That requires a lot of work and will be done in separate PRs. The way I register views in the auth manager is the way it is done today so I dont add anything new. Definitely this will need to be reworked/redone later to complete AIP-79. And yes likely we will need a mechanism similar to AIP-68 will expose for plugins so that the auth manager can add new views to an Airflow environment\r\n> \r\n> I just want to clarify not to add a new interface and therefore add a new legacy - even if it is used the same way but unclean today.\r\n\r\nNop, this already exist today. I just moved some code from security manager to auth manager. If you look [here](https://github.com/apache/airflow/pull/41777/files#diff-de9e81cdf5b00d08ef168c9573bd101f44b626419228d620ad3197c869a3249bR40), we are already using appbuilder to register the view', 'created_at': datetime.datetime(2024, 8, 28, 21, 45, 55, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-26 21:54:53 UTC): I see the interfaces with this PR are much simpler. But for the coupling of Providers and Core, this smells like a breaking change.
Do you have a proposal how to further release updates for provider compatible with Airflow 2.8/2.9/2.10?
Is the core change intended to be for Airflow 3?

vincbeck (Issue Creator) on (2024-08-27 13:58:05 UTC): Yes you are right, I should have mentioned it in the PR. I'll take care of that today

vincbeck (Issue Creator) on (2024-08-27 14:25:47 UTC): Yes

vincbeck (Issue Creator) on (2024-08-27 14:31:39 UTC): I dont think this is a problem. The newly created method `register_views` in FAB auth manager calls underneath `register_views` in the security manager. Airflow 2 calls `register_views` from the security manager. Therefore, any modifications in the `register_views` method from security manager will be available in Airflow 2 and 3

The issue is all the way around, making sure that Airflow 3 can use older version of FAB provider. I'll handle it

vincbeck (Issue Creator) on (2024-08-28 17:22:50 UTC): I resolved the backward incompatibility issue. It should be all fine now.

vincbeck (Issue Creator) on (2024-08-28 21:42:18 UTC): 100% agree with you but the intent of this PR is not to drop FAB from Airflow. That requires a lot of work and will be done in separate PRs. The way I register views in the auth manager is the way it is done today so I dont add anything new. Definitely this will need to be reworked/redone later to complete AIP-79. And yes likely we will need to leverage the mechanism created in AIP-68 so that the auth manager can add new views to an Airflow environment

jscheffl on (2024-08-28 21:44:59 UTC): I just want to clarify not to add a new interface and therefore add a new legacy - even if it is used the same way but unclean today.

vincbeck (Issue Creator) on (2024-08-28 21:45:55 UTC): Nop, this already exist today. I just moved some code from security manager to auth manager. If you look [here](https://github.com/apache/airflow/pull/41777/files#diff-de9e81cdf5b00d08ef168c9573bd101f44b626419228d620ad3197c869a3249bR40), we are already using appbuilder to register the view

"
2487723995,pull_request,closed,,Remove deprecations in airflow.models.param,Code cleanup and removal of deprecations in `airflow.models.param`,jscheffl,2024-08-26 20:31:13+00:00,[],2024-08-27 13:42:37+00:00,2024-08-27 13:42:37+00:00,https://github.com/apache/airflow/pull/41776,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487703552,pull_request,closed,,Update snowflake naming for account names and locators.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This is separate implementation of https://github.com/OpenLineage/OpenLineage/pull/2989 in Snowflake provider.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JDarDagran,2024-08-26 20:21:32+00:00,[],2024-08-27 08:41:30+00:00,2024-08-27 08:41:29+00:00,https://github.com/apache/airflow/pull/41775,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]",[],
2487608431,pull_request,closed,,Remove deprecations in airflow.models.dag,"Code cleanup and removal of deprecations in `airflow.models.dag`

Note: Tests in GCS Operator will probably fail until PR #41773 is merged",jscheffl,2024-08-26 19:28:34+00:00,[],2024-08-28 22:25:33+00:00,2024-08-28 22:25:33+00:00,https://github.com/apache/airflow/pull/41774,"[('area:serialization', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487602555,pull_request,closed,,Move away from deprecated DAG.following_schedule() method,In order to remove deprecations in `airflow.models.dag` the method call `DAG.following_schedule()` must be removed in GCS operator. This PR implements an alternative.,jscheffl,2024-08-26 19:25:02+00:00,[],2024-08-28 21:13:26+00:00,2024-08-28 11:28:59+00:00,https://github.com/apache/airflow/pull/41773,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2312605927, 'issue_id': 2487602555, 'author': 'potiuk', 'body': 'Unfortunately this needs compatibility for providers.', 'created_at': datetime.datetime(2024, 8, 27, 13, 44, 3, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-27 13:44:03 UTC): Unfortunately this needs compatibility for providers.

"
2487550511,pull_request,closed,,Consolidated fix for volumeClaimTemplates (apiVersion and PVC),"Closes: https://github.com/apache/airflow/issues/41766
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",darth-drew,2024-08-26 18:58:37+00:00,[],2024-08-28 22:14:03+00:00,2024-08-28 20:55:11+00:00,https://github.com/apache/airflow/pull/41771,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2310903660, 'issue_id': 2487550511, 'author': 'darth-drew', 'body': '@hussein-awala from earlier convo', 'created_at': datetime.datetime(2024, 8, 26, 19, 18, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311035962, 'issue_id': 2487550511, 'author': 'darth-drew', 'body': 'Much appreciated!', 'created_at': datetime.datetime(2024, 8, 26, 20, 32, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316235853, 'issue_id': 2487550511, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 28, 20, 55, 13, tzinfo=datetime.timezone.utc)}]","darth-drew (Issue Creator) on (2024-08-26 19:18:35 UTC): @hussein-awala from earlier convo

darth-drew (Issue Creator) on (2024-08-26 20:32:44 UTC): Much appreciated!

boring-cyborg[bot] on (2024-08-28 20:55:13 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2487542159,pull_request,closed,,[closed],"- Upgrade `google-cloud-aiplatform` to allow for data store interactions.
- Upgrade docstrings to fill in missing `tools` param
- Add `system_instruction` to `GenerativeModelGenerateContentOperator`
  - [About System Instruction](https://ai.google.dev/gemini-api/docs/system-instructions?lang=python) : System instructions enable you to steer the behavior of the model based on your specific needs and use cases. When you set a system instruction, you give the model additional context to understand the task, provide more customized responses, and adhere to specific guidelines over the full user interaction with the model. You can also specify product-level behavior by setting system instructions, separate from prompts provided by end users.
",CYarros10,2024-08-26 18:53:58+00:00,[],2024-10-11 11:59:35+00:00,2024-09-01 21:10:33+00:00,https://github.com/apache/airflow/pull/41770,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2487437089,pull_request,closed,,Update triggerer-deployment.yaml to include apiVersion and kind: PersistentVolumeClaim,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",darth-drew,2024-08-26 17:58:07+00:00,[],2024-08-26 18:34:13+00:00,2024-08-26 18:34:12+00:00,https://github.com/apache/airflow/pull/41769,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2310824115, 'issue_id': 2487437089, 'author': 'hussein-awala', 'body': 'will be added to https://github.com/apache/airflow/pull/41768', 'created_at': datetime.datetime(2024, 8, 26, 18, 34, 12, tzinfo=datetime.timezone.utc)}]","hussein-awala on (2024-08-26 18:34:12 UTC): will be added to https://github.com/apache/airflow/pull/41768

"
2487434091,pull_request,closed,,Update redis-statefulset.yaml to include apiVersion and kind: PersistentVolumeClaim,"include v1 and PersistentVolumeClaim in volumeClaimTemplate

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",darth-drew,2024-08-26 17:56:33+00:00,[],2024-08-26 19:32:14+00:00,2024-08-26 19:23:35+00:00,https://github.com/apache/airflow/pull/41768,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2310797282, 'issue_id': 2487434091, 'author': 'darth-drew', 'body': 'I should have included Issue# in PR. Please see https://github.com/apache/airflow/issues/41766', 'created_at': datetime.datetime(2024, 8, 26, 18, 19, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310822993, 'issue_id': 2487434091, 'author': 'hussein-awala', 'body': 'I see, and adding them makes sense.\r\n\r\nI will close the other PRs, could you apply the changes in a single PR? (this one)', 'created_at': datetime.datetime(2024, 8, 26, 18, 33, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310871911, 'issue_id': 2487434091, 'author': 'darth-drew', 'body': 'Can you make it work with this: https://github.com/apache/airflow/pull/41771', 'created_at': datetime.datetime(2024, 8, 26, 19, 1, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310912473, 'issue_id': 2487434091, 'author': 'hussein-awala', 'body': 'closed in favor of https://github.com/apache/airflow/pull/41771', 'created_at': datetime.datetime(2024, 8, 26, 19, 23, 35, tzinfo=datetime.timezone.utc)}]","darth-drew (Issue Creator) on (2024-08-26 18:19:06 UTC): I should have included Issue# in PR. Please see https://github.com/apache/airflow/issues/41766

hussein-awala on (2024-08-26 18:33:33 UTC): I see, and adding them makes sense.

I will close the other PRs, could you apply the changes in a single PR? (this one)

darth-drew (Issue Creator) on (2024-08-26 19:01:40 UTC): Can you make it work with this: https://github.com/apache/airflow/pull/41771

hussein-awala on (2024-08-26 19:23:35 UTC): closed in favor of https://github.com/apache/airflow/pull/41771

"
2487390551,pull_request,closed,,Update worker-deployment.yaml to include apiVersion and kind: PersistentVolumeClaim,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",darth-drew,2024-08-26 17:33:33+00:00,[],2024-08-26 18:34:00+00:00,2024-08-26 18:34:00+00:00,https://github.com/apache/airflow/pull/41767,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2310716732, 'issue_id': 2487390551, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 26, 17, 33, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310823776, 'issue_id': 2487390551, 'author': 'hussein-awala', 'body': 'will be added to https://github.com/apache/airflow/pull/41768', 'created_at': datetime.datetime(2024, 8, 26, 18, 34, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-26 17:33:37 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

hussein-awala on (2024-08-26 18:34:00 UTC): will be added to https://github.com/apache/airflow/pull/41768

"
2487296292,pull_request,closed,,Fix a bug in the connection documentation in elasticsearch.rst ,"Changed Azure to Elasticsearch

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",KrunchMuffin,2024-08-26 16:44:23+00:00,[],2024-08-26 20:24:11+00:00,2024-08-26 18:13:29+00:00,https://github.com/apache/airflow/pull/41764,"[('area:providers', ''), ('kind:documentation', ''), ('provider:elasticsearch', '')]","[{'comment_id': 2310630461, 'issue_id': 2487296292, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 26, 16, 44, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310786748, 'issue_id': 2487296292, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 26, 18, 13, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310787697, 'issue_id': 2487296292, 'author': 'hussein-awala', 'body': 'Congrats on your first commit ðŸŽ‰', 'created_at': datetime.datetime(2024, 8, 26, 18, 14, 2, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-26 16:44:27 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-08-26 18:13:32 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

hussein-awala on (2024-08-26 18:14:02 UTC): Congrats on your first commit ðŸŽ‰

"
2487199034,pull_request,closed,,Remove deprecations in Connection for Airflow 3,Cleanup for Airflow 3,jscheffl,2024-08-26 15:58:27+00:00,[],2024-08-27 13:49:19+00:00,2024-08-27 13:49:19+00:00,https://github.com/apache/airflow/pull/41762,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487144134,pull_request,closed,,Remove deprecations in BaseOperator for Airflow 3,Cleanup work for Airflow 3...,jscheffl,2024-08-26 15:29:43+00:00,[],2024-08-27 13:51:03+00:00,2024-08-27 13:51:03+00:00,https://github.com/apache/airflow/pull/41761,"[('area:dev-tools', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487124654,pull_request,closed,,Small fix for datafusion system test,"Small fix of Datafusion system test
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-08-26 15:19:33+00:00,[],2024-08-27 07:28:51+00:00,2024-08-27 07:28:51+00:00,https://github.com/apache/airflow/pull/41760,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2487080184,pull_request,closed,,Feature/add pgbouncer and statsd ingress,"Today pgbouncer and statsd expose /metrics route but we cannot access it outside the cluster.
This PR adds an ingress to pgbouncer and statsd (same as webUI and flower)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-26 14:58:00+00:00,['romsharon98'],2024-09-15 04:35:48+00:00,2024-09-15 04:35:40+00:00,https://github.com/apache/airflow/pull/41759,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2323183912, 'issue_id': 2487080184, 'author': 'romsharon98', 'body': '> @romsharon98 overall the changes look good. Could you add test cases for default values?\r\n\r\nMost of the default values are set to `""""`,making it difficult to test effectively. \r\nDo you have any specific values you\'d like me to check?', 'created_at': datetime.datetime(2024, 9, 1, 6, 5, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2335147544, 'issue_id': 2487080184, 'author': 'amoghrajesh', 'body': '> > @romsharon98 overall the changes look good. Could you add test cases for default values?\r\n> \r\n> Most of the default values are set to `""""`,making it difficult to test effectively. Do you have any specific values you\'d like me to check?\r\n\r\nOn second thought, this is OK. No point of testing empty values', 'created_at': datetime.datetime(2024, 9, 7, 10, 38, 42, tzinfo=datetime.timezone.utc)}]","romsharon98 (Issue Creator) on (2024-09-01 06:05:32 UTC): Most of the default values are set to `""""`,making it difficult to test effectively. 
Do you have any specific values you'd like me to check?

amoghrajesh on (2024-09-07 10:38:42 UTC): On second thought, this is OK. No point of testing empty values

"
2487063941,pull_request,closed,,Remove a set of deprecations in airflow.www module,"Remove a set of deprecations in `airflow.www` module for Airflow 3

Note: PR #41757 must be moved before, there is a leftover import in tests.",jscheffl,2024-08-26 14:50:15+00:00,[],2024-08-27 13:52:38+00:00,2024-08-27 13:52:38+00:00,https://github.com/apache/airflow/pull/41758,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2487054160,pull_request,closed,,Remove one leftover deprecated import from FAB provider test,There is a leftover import in FAB provider test... that module is going to be removed in the _next_ cleanup PR. Changing to another import.,jscheffl,2024-08-26 14:45:55+00:00,[],2024-08-27 13:53:40+00:00,2024-08-27 13:53:40+00:00,https://github.com/apache/airflow/pull/41757,"[('area:providers', ''), ('provider:fab', '')]",[],
2487016143,pull_request,closed,,[WIP] Fix the system test: dataflow_native_java,"This PR is introducing the `DATAFLOW_NATIVE_JAVA_JAR_FILE_PATH` variable to use in distributed environments.
> I will re-open this PR later
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",molcay,2024-08-26 14:28:14+00:00,[],2024-08-26 14:29:40+00:00,2024-08-26 14:28:30+00:00,https://github.com/apache/airflow/pull/41756,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2486999139,pull_request,closed,,Bump micromatch from 4.0.5 to 4.0.8 in /airflow/www (#41726),Backport of #41726 to v2-10-test,jscheffl,2024-08-26 14:20:29+00:00,[],2024-08-30 11:40:31+00:00,2024-08-27 13:11:09+00:00,https://github.com/apache/airflow/pull/41755,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2486937981,pull_request,closed,,Set end_date and duration for triggers completed with end_from_trigger as True,"closes: #41613
related: #41613

Use `set_state` instead of directly setting the state which will set end_date and duration attribute for the task_instance.

",tirkarthi,2024-08-26 13:54:16+00:00,[],2024-08-30 09:22:31+00:00,2024-08-28 13:08:14+00:00,https://github.com/apache/airflow/pull/41754,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:Triggerer', '')]",[],
2486729218,pull_request,closed,,Remove licence from generated ts types interface,"Generated content do not need to have the apache licence.

This will help for generated files of the new `ui` folder. (new modern UI) ",pierrejeambrun,2024-08-26 12:20:50+00:00,[],2024-08-26 15:04:01+00:00,2024-08-26 15:03:59+00:00,https://github.com/apache/airflow/pull/41751,"[('area:dev-tools', '')]","[{'comment_id': 2310076670, 'issue_id': 2486729218, 'author': 'pierrejeambrun', 'body': 'cc: @bbovenzi', 'created_at': datetime.datetime(2024, 8, 26, 12, 21, 26, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-08-26 12:21:26 UTC): cc: @bbovenzi

"
2486585191,pull_request,closed,,Make code style fix in Dataform system test,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have made a small fix in code style for Dataform system test.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-08-26 11:03:26+00:00,[],2024-08-29 07:43:28+00:00,2024-08-29 07:43:28+00:00,https://github.com/apache/airflow/pull/41750,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2486570832,pull_request,closed,,Fix some non-critical pre-commit issues,"I was running `pre-commit run -a` to fix some conflicts on database migration and found some interesting pre-commit failures that only occur in edge cases. Nothing serious, letâ€™s just fix them. I donâ€™t think any of these are common enough to require new checks.

The '.venv' name (common for in-project virtual environments) is not included in rat-excludes, causing a lint failure since a license is not found in it. Since 'venv' (no leading dot) is excluded, let's also add '.venv' to the file.

The 'downgradedb' method of BaseDBManager is declared abstract, but not implemented in FABDBManager. This causes Mypy to error when FABDBManager is instantiated. We don't always need the implement the method, so let's remove the abstractmethod decorator.

Finally (and least critically), when you run pre-commit during a merge, a hook checks if you're committing unresolved conflicts. The check is not particularly smart, however, and can mis-identify header underlines in restructuredText as false positives. This is easy to fix; just add one more character to the underline. It's fine as long as the underline is not EXACTLY SEVEN characters.",uranusjr,2024-08-26 10:55:17+00:00,[],2024-08-28 06:58:12+00:00,2024-08-27 13:13:32+00:00,https://github.com/apache/airflow/pull/41749,"[('area:providers', ''), ('area:dev-tools', ''), ('area:plugins', ''), ('area:secrets', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('area:lineage', ''), ('provider:arangodb', ''), ('provider:github', '')]",[],
2486513931,pull_request,closed,,Module airflow.hooks.dbapi removed,Deprecated module airflow.hooks.dbapi removed,dirrao,2024-08-26 10:24:39+00:00,['dirrao'],2024-08-27 14:13:38+00:00,2024-08-27 14:13:38+00:00,https://github.com/apache/airflow/pull/41748,"[('area:providers', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:common-sql', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2310497332, 'issue_id': 2486513931, 'author': 'jscheffl', 'body': 'Seems we are running over the same work... just did the same a few hours earlier in #41734', 'created_at': datetime.datetime(2024, 8, 26, 15, 33, 26, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-26 15:33:26 UTC): Seems we are running over the same work... just did the same a few hours earlier in #41734

"
2486477754,pull_request,closed,,Removed deprecated method reference airflow.www.auth.has_access when min airflow version >= 2.8.0,"Removed deprecated method reference airflow.www.auth.has_access when min airflow version >= 2.8.0

This should be merged before #41738",dirrao,2024-08-26 10:06:46+00:00,['dirrao'],2024-08-27 12:32:50+00:00,2024-08-27 12:32:49+00:00,https://github.com/apache/airflow/pull/41747,"[('area:providers', ''), ('provider:databricks', '')]",[],
2486369073,pull_request,closed,,Remove Airflow 2.7 support from Kubernetes Provider,"Split of PR #41735 to separate provider changes from adjustments in Airflow Core.

THis removal is mainly in order allowing to remove other deprecates modules files in `airflow.kubernetes` in core for Airflow 3 code line ",jscheffl,2024-08-26 09:16:05+00:00,[],2024-08-26 15:01:01+00:00,2024-08-26 14:38:39+00:00,https://github.com/apache/airflow/pull/41746,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2486328252,pull_request,closed,,Clarify language in BaseOperator docstring about pre_execute and post_execute parameter,"A suggestion to clarify that it is only the parameters that are experimental, not the methods themselves because the current docstring caused confusion around that :) 

I hope my wording makes sense here.",TJaniF,2024-08-26 08:57:56+00:00,[],2024-10-16 00:15:11+00:00,2024-10-16 00:15:10+00:00,https://github.com/apache/airflow/pull/41744,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]","[{'comment_id': 2406264349, 'issue_id': 2486328252, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 11, 0, 14, 59, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-11 00:14:59 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2486214966,pull_request,closed,,revert removing soft_fail from TimeDeltaSensorAsync,"because : https://github.com/apache/airflow/pull/41727#discussion_r1730855155

@eladkal ",raphaelauv,2024-08-26 08:01:53+00:00,[],2024-08-26 08:11:20+00:00,2024-08-26 08:06:14+00:00,https://github.com/apache/airflow/pull/41741,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2309600298, 'issue_id': 2486214966, 'author': 'eladkal', 'body': 'I really recommend to split PRs for core and providers.\r\nIt makes things so much easier...', 'created_at': datetime.datetime(2024, 8, 26, 8, 5, 47, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-26 08:05:47 UTC): I really recommend to split PRs for core and providers.
It makes things so much easier...

"
2486068611,pull_request,closed,,backfill job command cli deperecated options removed,backfill job command cli deperecated options removed,dirrao,2024-08-26 06:46:38+00:00,[],2024-08-27 14:11:09+00:00,2024-08-27 14:11:09+00:00,https://github.com/apache/airflow/pull/41739,"[('area:CLI', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2485943341,pull_request,closed,,Deprecated access method removed,"Removed the following depredated methods
1. Removed deprecated method ``has_access`` from ``airflow.www.auth``
2. Removed deprecated method ``requires_access`` from ``airflow.api_connexion.security``
3. Removed deprecated methods ``get_sensitive_variables_fields`` and ``should_hide_value_for_key`` from ``airflow.www.utils``.",dirrao,2024-08-26 05:32:49+00:00,['dirrao'],2024-08-27 14:42:07+00:00,2024-08-27 14:42:07+00:00,https://github.com/apache/airflow/pull/41738,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('provider:databricks', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2310500099, 'issue_id': 2485943341, 'author': 'jscheffl', 'body': 'Oh and same here - did the same in parallel :-D in PR https://github.com/apache/airflow/pull/41758', 'created_at': datetime.datetime(2024, 8, 26, 15, 34, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312763812, 'issue_id': 2485943341, 'author': 'potiuk', 'body': 'Already merged in #41758 this time', 'created_at': datetime.datetime(2024, 8, 27, 14, 42, 7, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-26 15:34:58 UTC): Oh and same here - did the same in parallel :-D in PR https://github.com/apache/airflow/pull/41758

potiuk on (2024-08-27 14:42:07 UTC): Already merged in #41758 this time

"
2485495476,pull_request,closed,,Removed deprecated TaskStateTrigger from airflow.triggers.external_task module,Cleanup as deprecation promised for Airflow 3,jscheffl,2024-08-25 22:25:17+00:00,[],2024-08-27 13:55:01+00:00,2024-08-27 13:55:01+00:00,https://github.com/apache/airflow/pull/41737,"[('area:Triggerer', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2485490821,pull_request,closed,,Remove deprecated parameters from airflow (core) Operators,"Cleanup as deprecation promised for Airflow 3

Note: Python Operators are already in PR https://github.com/apache/airflow/pull/41493",jscheffl,2024-08-25 22:14:10+00:00,[],2024-08-27 19:46:48+00:00,2024-08-27 13:55:42+00:00,https://github.com/apache/airflow/pull/41736,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2313018734, 'issue_id': 2485490821, 'author': 'eladkal', 'body': ""We need to revert this we can't merge this before we release the standard provider\r\nhttps://github.com/apache/airflow/pull/41564"", 'created_at': datetime.datetime(2024, 8, 27, 16, 26, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313092893, 'issue_id': 2485490821, 'author': 'potiuk', 'body': ""> We need to revert this we can't merge this before we release the standard provider\r\n\r\nWhy ? I thought standard provider will not have deprecated stuff?"", 'created_at': datetime.datetime(2024, 8, 27, 17, 4, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313118570, 'issue_id': 2485490821, 'author': 'eladkal', 'body': ""> Why ? I thought standard provider will not have deprecated stuff?\r\n\r\nWe must have version 1.0.0 or the provider identical to the operator code of 2.10.0\r\nWe can't have the initial version having hidden changes.\r\n\r\nAfter we release provider 1.0.0 we can remove all deprecations and cut 2.0.0\r\nThe only change to main branch should be removing the modules, it shouldn't be about what is changed in the modules this is done from the provider side."", 'created_at': datetime.datetime(2024, 8, 27, 17, 17, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313137550, 'issue_id': 2485490821, 'author': 'potiuk', 'body': '> We must have version 1.0.0 or the provider identical to the operator code of 2.10.0\r\n> We can\'t have the initial version having hidden changes.\r\n\r\nI am not sure if I agree. We have not discussed it, and that\'s why I asked @ashb how he imagines the new ""standard"" provider migration to look like  -  but Airflow 2.10/2.11 will have  ""old"" operators (and people might continue using them - there is no particular need to have ""standard"" provider to be 100% compatible - especially that vast majority of those deprecations is there for a long time (this is in a stark contrast with ""templates"" where we never told our users that they shoudl rewrite their templates and they will not have a way to do it for some time..\r\n\r\nHaving a ""standard"" provider installed ""additionaly"" with all the deprecations removed, will be a great opportunity to not only remove deprecations but make sure the that deprecated parameters are not used. And users will be able to do in Airlfow 2.10 / 2.11 dag-by-dag (because they will have both version of standard operators - one in ""airflow.core"" and one in ""airflow.providers.standard"" - then they will be able to change the imports and make sure all works before they migrate to Airflow 3. \r\n\r\nOr at least that is my thiniking about it.', 'created_at': datetime.datetime(2024, 8, 27, 17, 27, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313180238, 'issue_id': 2485490821, 'author': 'eladkal', 'body': '@potiuk regardless of the greater issue. We cant release the provider without revert this PR.\r\n\r\nThis PR removed code from datetime operators. The removal notice will appear in Airflow 3 changelog. The current provider PR has min airflow version of 2.8\r\nUsers who will start using it will experience breaking changes without notice.\r\n\r\nIn the past everytime we created a new provider we kept consistency between the code from the migrated part to the new provider allowing users to just replace import paths and everything will work out of the box. I am looking to give users the exact same experience.', 'created_at': datetime.datetime(2024, 8, 27, 17, 52, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313190542, 'issue_id': 2485490821, 'author': 'potiuk', 'body': '> This PR removed code from datetime operators. The removal notice will appear in Airflow 3 changelog. The current provider PR has min airflow version of 2.8\r\n\r\nAgain - we have not discussed it, but I see the \'standard"" provider as 3.0 feature coming mostly from the AIP-72 needs (@ashb ?). Or at least this is where the idea was raised. We **might** allow them to be used for Airflow 2 but mostly as a `bridge` to airflow 3 and we are **not** (unlike for other providers) going to remove them from airflow core (or at least I am not awre of that) - so the `airflow.operators.python.Python` might be (and will be) different  than `airflow.providers.standard.python.PythonVirtualenvOperator` in Airflow 2 and they should happily co-exist - which is IMHO a great opportunity to gradually move stuff for user\'s DAGs. \r\n\r\n> In the past everytime we created a new provider we kept consistency between the code from the migrated part to the new provider allowing users to just replace import paths and everything will work out of the box. I am looking to give users the exact same experience.\r\n\r\nI am not sure if this is our goal this time. It might be we decide that, but I am also not sure if we wanted to do it this way. I Thinl we could likely go either way, but I am not sure we agreed to that.', 'created_at': datetime.datetime(2024, 8, 27, 17, 58, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313193168, 'issue_id': 2485490821, 'author': 'potiuk', 'body': 'Simply speaking - I see ""standard"" as very similar thing to `backport` providers we had in Airflow 1 -> Airflow 2... But again, maybe my vision /approach is wrong.', 'created_at': datetime.datetime(2024, 8, 27, 17, 59, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313207050, 'issue_id': 2485490821, 'author': 'potiuk', 'body': ""(also for back-compatibiliity - at least until we move quite some other stuff to the provider, it can't have `>= 2.8` because it currently uses some classes thet have been added in Airflow 2.10 -> see https://github.com/apache/airflow/pull/41564#discussion_r1733028882\r\n\r\nI think we should **really** decide what is the purpose of the `standard` provider.."", 'created_at': datetime.datetime(2024, 8, 27, 18, 8, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313215620, 'issue_id': 2485490821, 'author': 'eladkal', 'body': 'OK. Then we need to discuss...\r\nEven if the provider is 3.0+ only I still think this PR needs to be reverted. Version 1.0.0 of the provider should be identical to the core code. Then 2.0 can remove anything we want.\r\n\r\nThe core change log should not contain anying other than - module is removed.\r\nAll the details of parmaters/function changes should be in provider change log.\r\n\r\ncc @kaxil', 'created_at': datetime.datetime(2024, 8, 27, 18, 13, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313377686, 'issue_id': 2485490821, 'author': 'jscheffl', 'body': '> OK. Then we need to discuss... Even if the provider is 3.0+ only I still think this PR needs to be reverted. Version 1.0.0 of the provider should be identical to the core code. Then 2.0 can remove anything we want.\r\n> \r\n> The core change log should not contain anying other than - module is removed. All the details of parmaters/function changes should be in provider change log.\r\n> \r\n> cc @kaxil\r\n\r\nAlso answered in Slack. I think my opinion is with Jarek. If we spin a new provider we should not carry deprecated legacy with it. Somebody migrating needs yto take care for deprecations.\r\n\r\nAlso I see the new provider earliest in the bridge release as _additional_ package. No need to be make it compatible with 2.8... also nothing speaking against making it compatible with 2.8 but still should not carry deprecated functions.\r\n\r\nSo good that we are not missing agenda items for the Dev calls... :-D', 'created_at': datetime.datetime(2024, 8, 27, 19, 46, 47, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-27 16:26:49 UTC): We need to revert this we can't merge this before we release the standard provider
https://github.com/apache/airflow/pull/41564

potiuk on (2024-08-27 17:04:24 UTC): Why ? I thought standard provider will not have deprecated stuff?

eladkal on (2024-08-27 17:17:50 UTC): We must have version 1.0.0 or the provider identical to the operator code of 2.10.0
We can't have the initial version having hidden changes.

After we release provider 1.0.0 we can remove all deprecations and cut 2.0.0
The only change to main branch should be removing the modules, it shouldn't be about what is changed in the modules this is done from the provider side.

potiuk on (2024-08-27 17:27:59 UTC): I am not sure if I agree. We have not discussed it, and that's why I asked @ashb how he imagines the new ""standard"" provider migration to look like  -  but Airflow 2.10/2.11 will have  ""old"" operators (and people might continue using them - there is no particular need to have ""standard"" provider to be 100% compatible - especially that vast majority of those deprecations is there for a long time (this is in a stark contrast with ""templates"" where we never told our users that they shoudl rewrite their templates and they will not have a way to do it for some time..

Having a ""standard"" provider installed ""additionaly"" with all the deprecations removed, will be a great opportunity to not only remove deprecations but make sure the that deprecated parameters are not used. And users will be able to do in Airlfow 2.10 / 2.11 dag-by-dag (because they will have both version of standard operators - one in ""airflow.core"" and one in ""airflow.providers.standard"" - then they will be able to change the imports and make sure all works before they migrate to Airflow 3. 

Or at least that is my thiniking about it.

eladkal on (2024-08-27 17:52:04 UTC): @potiuk regardless of the greater issue. We cant release the provider without revert this PR.

This PR removed code from datetime operators. The removal notice will appear in Airflow 3 changelog. The current provider PR has min airflow version of 2.8
Users who will start using it will experience breaking changes without notice.

In the past everytime we created a new provider we kept consistency between the code from the migrated part to the new provider allowing users to just replace import paths and everything will work out of the box. I am looking to give users the exact same experience.

potiuk on (2024-08-27 17:58:15 UTC): Again - we have not discussed it, but I see the 'standard"" provider as 3.0 feature coming mostly from the AIP-72 needs (@ashb ?). Or at least this is where the idea was raised. We **might** allow them to be used for Airflow 2 but mostly as a `bridge` to airflow 3 and we are **not** (unlike for other providers) going to remove them from airflow core (or at least I am not awre of that) - so the `airflow.operators.python.Python` might be (and will be) different  than `airflow.providers.standard.python.PythonVirtualenvOperator` in Airflow 2 and they should happily co-exist - which is IMHO a great opportunity to gradually move stuff for user's DAGs. 


I am not sure if this is our goal this time. It might be we decide that, but I am also not sure if we wanted to do it this way. I Thinl we could likely go either way, but I am not sure we agreed to that.

potiuk on (2024-08-27 17:59:49 UTC): Simply speaking - I see ""standard"" as very similar thing to `backport` providers we had in Airflow 1 -> Airflow 2... But again, maybe my vision /approach is wrong.

potiuk on (2024-08-27 18:08:12 UTC): (also for back-compatibiliity - at least until we move quite some other stuff to the provider, it can't have `>= 2.8` because it currently uses some classes thet have been added in Airflow 2.10 -> see https://github.com/apache/airflow/pull/41564#discussion_r1733028882

I think we should **really** decide what is the purpose of the `standard` provider..

eladkal on (2024-08-27 18:13:17 UTC): OK. Then we need to discuss...
Even if the provider is 3.0+ only I still think this PR needs to be reverted. Version 1.0.0 of the provider should be identical to the core code. Then 2.0 can remove anything we want.

The core change log should not contain anying other than - module is removed.
All the details of parmaters/function changes should be in provider change log.

cc @kaxil

jscheffl (Issue Creator) on (2024-08-27 19:46:47 UTC): Also answered in Slack. I think my opinion is with Jarek. If we spin a new provider we should not carry deprecated legacy with it. Somebody migrating needs yto take care for deprecations.

Also I see the new provider earliest in the bridge release as _additional_ package. No need to be make it compatible with 2.8... also nothing speaking against making it compatible with 2.8 but still should not carry deprecated functions.

So good that we are not missing agenda items for the Dev calls... :-D

"
2485481815,pull_request,closed,,Remove deprecated airflow.kubernetes package,"Cleanup as deprecation promised for Airflow 3

Note that the PR will fail as CNCF-Kuberntes Provider still holds a reference to import of `airflow.kubernetes` legacy. THis is removed in PR #41746 and this probably needs to be merged first allowing and then having a rebase here.",jscheffl,2024-08-25 21:53:13+00:00,[],2024-08-27 13:56:44+00:00,2024-08-27 13:56:44+00:00,https://github.com/apache/airflow/pull/41735,"[('area:providers', ''), ('area:serialization', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2485474524,pull_request,closed,,Removed deprecated airflow.hooks.dbapi module,Cleanup as deprecation promised for Airflow 3,jscheffl,2024-08-25 21:33:15+00:00,[],2024-08-27 14:14:09+00:00,2024-08-27 14:14:09+00:00,https://github.com/apache/airflow/pull/41734,"[('area:providers', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:common-sql', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2312695746, 'issue_id': 2485474524, 'author': 'potiuk', 'body': 'Aliread merged in #41748', 'created_at': datetime.datetime(2024, 8, 27, 14, 14, 7, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-27 14:14:07 UTC): Aliread merged in #41748

"
2485471108,pull_request,closed,,Remove deprecated get_connections() function in BaseHook,Cleanup as deprecation promised for Airflow 3 - get_connections() function in BaseHook,jscheffl,2024-08-25 21:24:27+00:00,[],2024-08-27 14:32:38+00:00,2024-08-27 14:32:37+00:00,https://github.com/apache/airflow/pull/41733,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2485449279,pull_request,closed,,Remove deprecation warning for cgitb in Plugins Manager,"Recently when running Airflow (locally but probably also when deployed) a lot of warnings are emitted by Plugins Manager like:
```
/opt/airflow/airflow/plugins_manager.py:30 DeprecationWarning: 'cgitb' is deprecated and slated for removal in Python 3.13
```

This is caused by a import in plugins_manager.py - and surprisingly besides this import all other types of the specified list actually use `HookLineageReader` - unable to trace this down, this PR removes the import and traces. Less noise in logs.

As this also will bother all users in Airfow 2.10, I propose to fix this also in the 2.10 code-line",jscheffl,2024-08-25 20:23:15+00:00,[],2024-08-27 14:06:41+00:00,2024-08-27 14:06:41+00:00,https://github.com/apache/airflow/pull/41732,"[('area:plugins', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2312670511, 'issue_id': 2485449279, 'author': 'potiuk', 'body': "">  surprisingly besides this import all other types of the specified list actually use HookLineageReader\r\n\r\nLikely it's simply a mistake,"", 'created_at': datetime.datetime(2024, 8, 27, 14, 6, 23, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-27 14:06:23 UTC): Likely it's simply a mistake,

"
2485411581,pull_request,closed,,AIP-69: Breeze adjustments for introduction of Edge Executor,"This PR is a companion to PR #41729 and splits the core adjustments from PoC in PR #40224 and ""Mothership"" PR #40900. It should be merged after PR #41729.

The PR adds ""convenience"" to start EdgeExecutor in CLI with breeze.

As a side-work some constants which have been used as ""free"" literals have been consolidated to constant values.",jscheffl,2024-08-25 18:34:06+00:00,[],2024-10-17 23:06:10+00:00,2024-10-17 23:06:10+00:00,https://github.com/apache/airflow/pull/41731,"[('area:dev-tools', ''), ('AIP-69', 'Edge Executor')]","[{'comment_id': 2312400654, 'issue_id': 2485411581, 'author': 'potiuk', 'body': 'see comments https://github.com/apache/airflow/pull/41731#event-14005014379', 'created_at': datetime.datetime(2024, 8, 27, 12, 14, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323102752, 'issue_id': 2485411581, 'author': 'potiuk', 'body': 'Needs to be cherry-picked to v2-10-test I guess', 'created_at': datetime.datetime(2024, 9, 1, 1, 21, 45, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-27 12:14:46 UTC): see comments https://github.com/apache/airflow/pull/41731#event-14005014379

potiuk on (2024-09-01 01:21:45 UTC): Needs to be cherry-picked to v2-10-test I guess

"
2485411425,pull_request,closed,,AIP-69: Airflow Core adjustments for introduction of Edge Executor,"This PR is a companion to PR #41729 and splits the core adjustments from PoC in PR #40224 and ""Mothership"" PR #40900.

The PR carries documentation and a small extension to the variables allowing the core to ""know"" EdgeExecutor. Therefore it is not really a feature but mainly a doc-only change and would propose to add this also to Airflow 2.10 line. Feedback welcome.

Note: Build of docs depends on PR for Provider Package being merged first. (Reference missing)

Note After the discussion the PR is adjusted now from ""Remote Executor"" to ""Edge Executor""",jscheffl,2024-08-25 18:33:41+00:00,[],2024-10-18 05:29:59+00:00,2024-10-18 05:29:59+00:00,https://github.com/apache/airflow/pull/41730,"[('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('AIP-69', 'Edge Executor')]","[{'comment_id': 2312399140, 'issue_id': 2485411425, 'author': 'potiuk', 'body': '> I am -0 on these changes. I will not block them if the community decides this is best, but I think changing a naming paradigm that has been in the community for years is not the best approach if we proceed with the user in mind. I think it\'s incumbent on the new feature to settle on a name that does not clash with existing names. This way users don\'t have the whiplash of a new paradigm to learn at the same time as relearning the old and getting confused between the two. This name change will cause unnecessary confusion, that is simply not needed. I think `distributed` is a good name and works perfectly well for the new feature being delivered.\r\n\r\nAgrew with @vincbeck. Naming is hard but I\'d rather call the new executor ""Distributed"" rather than the reuse ""old"" name for it. Both namings are equally good IMHO and it\'s up to us to define them - so in this case it is the question of either adding new term, or reusing old term for something else and adding the new term for smth else. Sounds it has a lot potential for confusion.;', 'created_at': datetime.datetime(2024, 8, 27, 12, 14, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312526082, 'issue_id': 2485411425, 'author': 'jscheffl', 'body': '> > I am -0 on these changes. I will not block them if the community decides this is best, but I think changing a naming paradigm that has been in the community for years is not the best approach if we proceed with the user in mind. I think it\'s incumbent on the new feature to settle on a name that does not clash with existing names. This way users don\'t have the whiplash of a new paradigm to learn at the same time as relearning the old and getting confused between the two. This name change will cause unnecessary confusion, that is simply not needed. I think `distributed` is a good name and works perfectly well for the new feature being delivered.\r\n> \r\n> Agrew with @vincbeck. Naming is hard but I\'d rather call the new executor ""Distributed"" rather than the reuse ""old"" name for it. Both namings are equally good IMHO and it\'s up to us to define them - so in this case it is the question of either adding new term, or reusing old term for something else and adding the new term for smth else. Sounds it has a lot potential for confusion.;\r\n\r\nI\'m rather for the term `remote` as it is shorter and makes CLI and docs shorter. But not fixed to the name. I can make a bulk search&replace. Shall I call a vot eon the name on the DevList?', 'created_at': datetime.datetime(2024, 8, 27, 13, 11, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312536200, 'issue_id': 2485411425, 'author': 'potiuk', 'body': 'At least discuss - yes. would be good. We did that in recent past.', 'created_at': datetime.datetime(2024, 8, 27, 13, 16, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312588141, 'issue_id': 2485411425, 'author': 'jscheffl', 'body': ""> I'm rather for the term `remote` as it is shorter and makes CLI and docs shorter. But not fixed to the name. I can make a bulk search&replace. Shall I call a vot eon the name on the DevList?\r\n\r\n--> Happy discussion! https://lists.apache.org/thread/br1jfoc8p1wjzk74c09srjgr29spytfy"", 'created_at': datetime.datetime(2024, 8, 27, 13, 36, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323102647, 'issue_id': 2485411425, 'author': 'potiuk', 'body': 'Needs to be cherry-picked to `v2-10-test` I guess', 'created_at': datetime.datetime(2024, 9, 1, 1, 21, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323103017, 'issue_id': 2485411425, 'author': 'potiuk', 'body': '(and tests are failing too)', 'created_at': datetime.datetime(2024, 9, 1, 1, 22, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323201918, 'issue_id': 2485411425, 'author': 'ephraimbuddy', 'body': ""> I am -0 on these changes. I will not block them if the community decides this is best, but I think changing a naming paradigm that has been in the community for years is not the best approach if we proceed with the user in mind. I think it's incumbent on the new feature to settle on a name that does not clash with existing names. This way users don't have the whiplash of a new paradigm to learn at the same time as relearning the old and getting confused between the two. This name change will cause unnecessary confusion, that is simply not needed. I think `distributed` is a good name and works perfectly well for the new feature being delivered.\r\n\r\n+1 on this; I think the `distributed` would be better"", 'created_at': datetime.datetime(2024, 9, 1, 7, 2, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325712385, 'issue_id': 2485411425, 'author': 'potiuk', 'body': 'Hey @jscheffl -> I wanted to make an attempt to remove AIP-44 completely from `main`/ Airflow 3 - which means likely that we will have to do something about those changes for Edge Executor in main. \r\n\r\nDo you think the provider can be impletemented and built in `main` even if we remove all AIP-44-related things from main?', 'created_at': datetime.datetime(2024, 9, 3, 6, 37, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330305096, 'issue_id': 2485411425, 'author': 'jscheffl', 'body': '> Hey @jscheffl -> I wanted to make an attempt to remove AIP-44 completely from `main`/ Airflow 3 - which means likely that we will have to do something about those changes for Edge Executor in main.\r\n> \r\n> Do you think the provider can be impletemented and built in `main` even if we remove all AIP-44-related things from main?\r\n\r\nHi @potiuk AIP-44 is the base for the Executor. If you want to wipe the codebase and slim it down (freshest legacy) then we would need to filter the provider from testing on main - and just keep testing the provider against 2.10 compat. There might be multiple options like (1) filtering it in the list in breeze, (2) Implement a pytest.skip based on the airflow version string.\r\n\r\nI would favor (of course) if we keep AIP-44 at least for a moment until AIP-72 matures a bit to make it usable. I would assume once AIP-72 is available as a first MVP we can change to code in a way that provider loads modules from v2 compat for Airflow 2 and ""new AIP-72"" compatible bindings if Airflow 3 (Similar like we did it in the past with Pydantic 1/2 switch).\r\n\r\nHow much pressure do you feel to remove AIP-44?\r\nI assume your question is also for a full cleaning of all AIP-44 traces? Some ""pieces"" could be removed early like the internal API apiserver - but of course the `@internal_api` decorator logic must be sitting in the core and on the exposed API functions.', 'created_at': datetime.datetime(2024, 9, 4, 23, 13, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331206674, 'issue_id': 2485411425, 'author': 'potiuk', 'body': '> How much pressure do you feel to remove AIP-44?\r\n\r\nI personaly don\'t feel much pressure - other than all the ""peer"" presure where other deprecations being actively removed as we speak. \r\n\r\nAlso I am going for almost 3 weeks holidays after the Summit, so it\'s less for me and more for all the work that is going to happen around AIP-72 especially while I am away. \r\n\r\nThere is quite some overlap - a lot of code for AIP-72 is going to involve refactorings and rewrites of pretty much the same parts as AIP-44 touched - it will be on a higher level than AIP-44 did. While AIP-44 went very ""low level"" - and replaced and extracted individual DB transactions from the code, AIP-72 is going to implement a way higher ""abstraction"" as regular API calls, where the operations - task and daf file parsing, and callbacks - will be wrapped in higher-level API calls. \r\n\r\nBut I imagine a lot of the code/ implementation will be about pretty much the same code (and your concerns about Edge worker switching to using the APIs of AIP-72 are only confirming that) \r\n\r\nI thought that removing AIP-44 code first (and keeping tests running) would remove quite a lot of noise from AIP-72 work, so I think it might be worth doing before.\r\n\r\nBut ultimately, it\'s up to @ashb POC (which we have not seen yet) and details how the implementation of AIP-72 will be done (Replace? Copy? Running old DB functionality and new code in parallel? Duplicating the code first in separate projects before proceeding with AIP-72 implementation). \r\n\r\nSo I think the question ""Should we remove AIP-44 first or is it ok to leave it for now"" is more a question on how AIP-72 process will look like - and as such only @ashb can answer it properly I think.', 'created_at': datetime.datetime(2024, 9, 5, 10, 47, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331245263, 'issue_id': 2485411425, 'author': 'ashb', 'body': ""Certainly leaving AIP-44 in main for now makes total sense.\r\n\r\nOnce I'm back from the Summit I plan on turning my isolated POC code into draft PRs etc for proper review, and then we can decide, but I do think AIP-44 etc should be removed before Airflow 3 hits beta."", 'created_at': datetime.datetime(2024, 9, 5, 11, 8, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2332689029, 'issue_id': 2485411425, 'author': 'jscheffl', 'body': ""> Certainly leaving AIP-44 in main for now makes total sense.\r\n> \r\n> Once I'm back from the Summit I plan on turning my isolated POC code into draft PRs etc for proper review, and then we can decide, but I do think AIP-44 etc should be removed before Airflow 3 hits beta.\r\n\r\n@potiuk @ashb Thanks for the feedback. So if there is no immediate pressure and also some time that would be great. Looking forward for the first AIP-72 impressions and also once migrating over I'd offer to contribute to AIP-44 removal/cleaning. Of course BEFORE any Airflow 3 Beta this should be made."", 'created_at': datetime.datetime(2024, 9, 5, 21, 53, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-27 12:14:02 UTC): Agrew with @vincbeck. Naming is hard but I'd rather call the new executor ""Distributed"" rather than the reuse ""old"" name for it. Both namings are equally good IMHO and it's up to us to define them - so in this case it is the question of either adding new term, or reusing old term for something else and adding the new term for smth else. Sounds it has a lot potential for confusion.;

jscheffl (Issue Creator) on (2024-08-27 13:11:59 UTC): I'm rather for the term `remote` as it is shorter and makes CLI and docs shorter. But not fixed to the name. I can make a bulk search&replace. Shall I call a vot eon the name on the DevList?

potiuk on (2024-08-27 13:16:15 UTC): At least discuss - yes. would be good. We did that in recent past.

jscheffl (Issue Creator) on (2024-08-27 13:36:50 UTC): --> Happy discussion! https://lists.apache.org/thread/br1jfoc8p1wjzk74c09srjgr29spytfy

potiuk on (2024-09-01 01:21:24 UTC): Needs to be cherry-picked to `v2-10-test` I guess

potiuk on (2024-09-01 01:22:42 UTC): (and tests are failing too)

ephraimbuddy on (2024-09-01 07:02:51 UTC): +1 on this; I think the `distributed` would be better

potiuk on (2024-09-03 06:37:07 UTC): Hey @jscheffl -> I wanted to make an attempt to remove AIP-44 completely from `main`/ Airflow 3 - which means likely that we will have to do something about those changes for Edge Executor in main. 

Do you think the provider can be impletemented and built in `main` even if we remove all AIP-44-related things from main?

jscheffl (Issue Creator) on (2024-09-04 23:13:54 UTC): Hi @potiuk AIP-44 is the base for the Executor. If you want to wipe the codebase and slim it down (freshest legacy) then we would need to filter the provider from testing on main - and just keep testing the provider against 2.10 compat. There might be multiple options like (1) filtering it in the list in breeze, (2) Implement a pytest.skip based on the airflow version string.

I would favor (of course) if we keep AIP-44 at least for a moment until AIP-72 matures a bit to make it usable. I would assume once AIP-72 is available as a first MVP we can change to code in a way that provider loads modules from v2 compat for Airflow 2 and ""new AIP-72"" compatible bindings if Airflow 3 (Similar like we did it in the past with Pydantic 1/2 switch).

How much pressure do you feel to remove AIP-44?
I assume your question is also for a full cleaning of all AIP-44 traces? Some ""pieces"" could be removed early like the internal API apiserver - but of course the `@internal_api` decorator logic must be sitting in the core and on the exposed API functions.

potiuk on (2024-09-05 10:47:52 UTC): I personaly don't feel much pressure - other than all the ""peer"" presure where other deprecations being actively removed as we speak. 

Also I am going for almost 3 weeks holidays after the Summit, so it's less for me and more for all the work that is going to happen around AIP-72 especially while I am away. 

There is quite some overlap - a lot of code for AIP-72 is going to involve refactorings and rewrites of pretty much the same parts as AIP-44 touched - it will be on a higher level than AIP-44 did. While AIP-44 went very ""low level"" - and replaced and extracted individual DB transactions from the code, AIP-72 is going to implement a way higher ""abstraction"" as regular API calls, where the operations - task and daf file parsing, and callbacks - will be wrapped in higher-level API calls. 

But I imagine a lot of the code/ implementation will be about pretty much the same code (and your concerns about Edge worker switching to using the APIs of AIP-72 are only confirming that) 

I thought that removing AIP-44 code first (and keeping tests running) would remove quite a lot of noise from AIP-72 work, so I think it might be worth doing before.

But ultimately, it's up to @ashb POC (which we have not seen yet) and details how the implementation of AIP-72 will be done (Replace? Copy? Running old DB functionality and new code in parallel? Duplicating the code first in separate projects before proceeding with AIP-72 implementation). 

So I think the question ""Should we remove AIP-44 first or is it ok to leave it for now"" is more a question on how AIP-72 process will look like - and as such only @ashb can answer it properly I think.

ashb on (2024-09-05 11:08:31 UTC): Certainly leaving AIP-44 in main for now makes total sense.

Once I'm back from the Summit I plan on turning my isolated POC code into draft PRs etc for proper review, and then we can decide, but I do think AIP-44 etc should be removed before Airflow 3 hits beta.

jscheffl (Issue Creator) on (2024-09-05 21:53:15 UTC): @potiuk @ashb Thanks for the feedback. So if there is no immediate pressure and also some time that would be great. Looking forward for the first AIP-72 impressions and also once migrating over I'd offer to contribute to AIP-44 removal/cleaning. Of course BEFORE any Airflow 3 Beta this should be made.

"
2485411279,pull_request,closed,,AIP-69: Adding Edge Provider Package for Edge Executor / Worker,"After a PoC in PR #40224 and the ongoing implementation which in total as ""Mothership"" was tracked in PR #40900 here is the AIP-69 MVP Implementation PR.

UPDATE: After completion of the discussion the ""Remote Executor"" was now renamed to ""Edge Executor"" in the PR.

This PR contains all files needed to make the provider package for AIP-69 a MVP == Minimum Viable Product. Besides (only) provider files the core adjustments are contained which are needed to make CI happy.

As greed in the AIP-69 vote the Edge provider will be marked as pre-release and as experimental. Also docs are pointing to this.

As it is a MVP, it can be started to be experienced and functions are limited to the bare minimum. But as something that is working, further functions can be added. Status of implementation is tracked in `docs/apache-airflow-providers-edge/edge_executor.rst` where also limitations are listed.

As this is a split for the provider-only files as PR from the overall PR #40900, there are two PRs completing the set which are tracked separately:
- PR for changes in Core, independent of the provider package: #41730
- PR for development convenience in Breeze: #41731

If you want to have something ""testable"" being running, please use descriptions and code from PR #40900

FYI @clellmann @wolfdn @AutomationDev85 @OliverWannenwetsch",jscheffl,2024-08-25 18:33:19+00:00,[],2024-10-18 04:45:15+00:00,2024-10-18 04:45:15+00:00,https://github.com/apache/airflow/pull/41729,"[('area:providers', ''), ('area:dev-tools', ''), ('AIP-69', 'Edge Executor')]","[{'comment_id': 2323104051, 'issue_id': 2485411279, 'author': 'potiuk', 'body': ""Maybe we can further split that one? It's a **huge** one"", 'created_at': datetime.datetime(2024, 9, 1, 1, 26, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2332919389, 'issue_id': 2485411279, 'author': 'jscheffl', 'body': '> Maybe we can further split that one? It\'s a **huge** one\r\n\r\nYeah but actually... all individual pieces are pretty ""simple"". Please have a look to the 6 split PRs I cut from this. Needed to cumulate a bit to make tests working with dependencies between the slices though... each PR check only the last commit or in order once merged the LoC is reducing if we rebase incrementally.', 'created_at': datetime.datetime(2024, 9, 5, 23, 59, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421356374, 'issue_id': 2485411279, 'author': 'jscheffl', 'body': 'All pieces of the PR were merged individually, this is now done implicitly!', 'created_at': datetime.datetime(2024, 10, 18, 4, 45, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-09-01 01:26:18 UTC): Maybe we can further split that one? It's a **huge** one

jscheffl (Issue Creator) on (2024-09-05 23:59:52 UTC): Yeah but actually... all individual pieces are pretty ""simple"". Please have a look to the 6 split PRs I cut from this. Needed to cumulate a bit to make tests working with dependencies between the slices though... each PR check only the last commit or in order once merged the LoC is reducing if we rebase incrementally.

jscheffl (Issue Creator) on (2024-10-18 04:45:15 UTC): All pieces of the PR were merged individually, this is now done implicitly!

"
2485376927,pull_request,closed,,Test GHA ARC,,hussein-awala,2024-08-25 17:01:57+00:00,[],2025-01-11 19:42:05+00:00,2025-01-11 19:42:05+00:00,https://github.com/apache/airflow/pull/41728,"[('pinned', 'Protect from Stalebot auto closing'), ('area:dev-tools', ''), ('use self-hosted runners', 'When set on a PR run self-hosted runners will be used by default')]","[{'comment_id': 2482366331, 'issue_id': 2485376927, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 18, 9, 13, 41, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-18 09:13:41 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2485303300,pull_request,closed,,remove deprecated soft_fail from providers part2,following : https://github.com/apache/airflow/pull/41710,raphaelauv,2024-08-25 14:39:01+00:00,[],2024-08-26 08:08:26+00:00,2024-08-25 16:26:15+00:00,https://github.com/apache/airflow/pull/41727,"[('area:providers', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:http', ''), ('provider:ftp', '')]","[{'comment_id': 2308913722, 'issue_id': 2485303300, 'author': 'raphaelauv', 'body': 'only flaky tests\r\n\r\n@potiuk can we merge or you prefer to re-trigger CI ? thanks', 'created_at': datetime.datetime(2024, 8, 25, 16, 23, 55, tzinfo=datetime.timezone.utc)}]","raphaelauv (Issue Creator) on (2024-08-25 16:23:55 UTC): only flaky tests

@potiuk can we merge or you prefer to re-trigger CI ? thanks

"
2485218797,pull_request,closed,,Bump micromatch from 4.0.5 to 4.0.8 in /airflow/www,"Bumps [micromatch](https://github.com/micromatch/micromatch) from 4.0.5 to 4.0.8.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/micromatch/micromatch/blob/4.0.8/CHANGELOG.md"">micromatch's changelog</a>.</em></p>
<blockquote>
<h2>[4.0.8] - 2024-08-22</h2>
<ul>
<li>backported CVE-2024-4067 fix (from v4.0.6) over to 4.x branch</li>
</ul>
<h2>[4.0.7] - 2024-05-22</h2>
<ul>
<li>this is basically v4.0.5, with some README updates</li>
<li><strong>it is vulnerable to CVE-2024-4067</strong></li>
<li>Updated braces to v3.0.3 to avoid CVE-2024-4068</li>
<li>does NOT break API compatibility</li>
</ul>
<h2>[4.0.6] - 2024-05-21</h2>
<ul>
<li>Added <code>hasBraces</code> to check if a pattern contains braces.</li>
<li>Fixes CVE-2024-4067</li>
<li><strong>BREAKS API COMPATIBILITY</strong></li>
<li>Should be labeled as a major release, but it's not.</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/micromatch/micromatch/commit/8bd704ec0d9894693d35da425d827819916be920""><code>8bd704e</code></a> 4.0.8</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/a0e68416a44da10f3e4e30845ab95af4fd286d5a""><code>a0e6841</code></a> run verb to generate README documentation</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/4ec288484f6e8cccf597ad3d43529c31d0f7a02a""><code>4ec2884</code></a> Merge branch 'v4' into hauserkristof-feature/v4.0.8</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/03aa8052171e878897eee5d7bb2ae0ae83ec2ade""><code>03aa805</code></a> Merge pull request <a href=""https://redirect.github.com/micromatch/micromatch/issues/266"">#266</a> from hauserkristof/feature/v4.0.8</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/814f5f70efcd100ca9d29198867812a3d6ab91a8""><code>814f5f7</code></a> lint</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/67fcce6a1077c2faf5ad0c5f998fa70202cc5dae""><code>67fcce6</code></a> fix: CHANGELOG about braces &amp; CVE-2024-4068, v4.0.5</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/113f2e3fa7cb30b429eda7c4c38475a8e8ba1b30""><code>113f2e3</code></a> fix: CVE numbers in CHANGELOG</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/d9dbd9a266686f44afb38da26fe016f96d1ec04f""><code>d9dbd9a</code></a> feat: updated CHANGELOG</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/2ab13157f416679f54e3a32b1425e184bd16749e""><code>2ab1315</code></a> fix: use actions/setup-node@v4</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/1406ea38f3e24b29f4d4f46908d5cffcb3e6c4ce""><code>1406ea3</code></a> feat: rework test to work on macos with node 10,12 and 14</li>
<li>Additional commits viewable in <a href=""https://github.com/micromatch/micromatch/compare/4.0.5...4.0.8"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=micromatch&package-manager=npm_and_yarn&previous-version=4.0.5&new-version=4.0.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-08-25 12:23:26+00:00,[],2024-08-30 09:18:23+00:00,2024-08-26 14:17:24+00:00,https://github.com/apache/airflow/pull/41726,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]","[{'comment_id': 2308934424, 'issue_id': 2485218797, 'author': 'jscheffl', 'body': 'micromatch is a transitive dependency via stylelint - should be safe to update.\r\nProbably needs to be cherry-picket to v2-10-test, correct?', 'created_at': datetime.datetime(2024, 8, 25, 17, 33, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310107567, 'issue_id': 2485218797, 'author': 'pierrejeambrun', 'body': 'Looking good', 'created_at': datetime.datetime(2024, 8, 26, 12, 35, 37, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-25 17:33:10 UTC): micromatch is a transitive dependency via stylelint - should be safe to update.
Probably needs to be cherry-picket to v2-10-test, correct?

pierrejeambrun on (2024-08-26 12:35:37 UTC): Looking good

"
2485128876,pull_request,closed,,Add hostAliases support for Triggerer in helm chart ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Adding support to append extra hosts to the /etc/hosts file in the triggerer pod.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",HassanAlahmed,2024-08-25 08:43:55+00:00,[],2024-08-28 15:23:04+00:00,2024-08-28 15:22:06+00:00,https://github.com/apache/airflow/pull/41725,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2308736574, 'issue_id': 2485128876, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 25, 8, 43, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315661837, 'issue_id': 2485128876, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 28, 15, 22, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315663780, 'issue_id': 2485128876, 'author': 'jedcunningham', 'body': 'Thanks @HassanAlahmed! Congrats on your first commit ðŸŽ‰', 'created_at': datetime.datetime(2024, 8, 28, 15, 23, 3, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-25 08:43:59 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-08-28 15:22:09 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

jedcunningham on (2024-08-28 15:23:03 UTC): Thanks @HassanAlahmed! Congrats on your first commit ðŸŽ‰

"
2485117600,pull_request,closed,,Add comment to issue describing why upath is pinned to 0.2.2,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-25 08:11:29+00:00,[],2024-08-25 08:41:04+00:00,2024-08-25 08:41:02+00:00,https://github.com/apache/airflow/pull/41724,[],[],
2485070918,pull_request,closed,,provider fab auth manager deprecated methods removed,"provider fab auth manager deprecated methods removed
1. get_readable_dags
2. get_editable_dags
3. get_accessible_dags
4. get_accessible_dag_ids
5. get_readable_dag_ids
6. init_role
7. prefixed_dag_id",dirrao,2024-08-25 05:42:40+00:00,['dirrao'],2024-09-02 17:34:40+00:00,2024-08-26 14:51:48+00:00,https://github.com/apache/airflow/pull/41720,"[('area:providers', ''), ('provider:fab', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2309327470, 'issue_id': 2485070918, 'author': 'dirrao', 'body': ""> Static checks are failing, else good to merge.\r\n\r\nIt's resolved."", 'created_at': datetime.datetime(2024, 8, 26, 5, 8, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325017588, 'issue_id': 2485070918, 'author': 'eladkal', 'body': 'This one is not handled properly... It mixes core and provider. Providers dont have newsfragments. It also force us to cut fab provider 2.0.0 is that something we want to do now? (We can but I am not sure we should). Initially  I wanted to handle all providers deprecations together as bulk for 2.11', 'created_at': datetime.datetime(2024, 9, 2, 15, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325132639, 'issue_id': 2485070918, 'author': 'potiuk', 'body': 'Yesl This one should be reverted.', 'created_at': datetime.datetime(2024, 9, 2, 17, 29, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325137430, 'issue_id': 2485070918, 'author': 'potiuk', 'body': 'Revert PR here \r\nhttps://github.com/apache/airflow/pull/41960', 'created_at': datetime.datetime(2024, 9, 2, 17, 34, 38, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-26 05:08:31 UTC): It's resolved.

eladkal on (2024-09-02 15:49:00 UTC): This one is not handled properly... It mixes core and provider. Providers dont have newsfragments. It also force us to cut fab provider 2.0.0 is that something we want to do now? (We can but I am not sure we should). Initially  I wanted to handle all providers deprecations together as bulk for 2.11

potiuk on (2024-09-02 17:29:37 UTC): Yesl This one should be reverted.

potiuk on (2024-09-02 17:34:38 UTC): Revert PR here 
https://github.com/apache/airflow/pull/41960

"
2484898216,pull_request,closed,,Add Airflow 2.10.0 to Provider Compatibility Checks,"I realized that after we released Airflow 2.10 and made main to be the target development for Airflow 3 line... we did not add a Provider Compatibility Check for Airflow 2.10 line. Also the version 2.9 line was never updated to recent patch releases.

This PR Upgrades the compatibility checks from 2.9.1 to 2.9.3 and adds 2.10.0.",jscheffl,2024-08-24 22:20:05+00:00,[],2024-08-25 08:43:33+00:00,2024-08-25 08:43:33+00:00,https://github.com/apache/airflow/pull/41719,"[('area:dev-tools', '')]",[],
2484864562,pull_request,closed,,Improve Mongo connection validation and UI,"This change tightens up the Mongo connection UX:

* The `MongoHook` constructor validates the connection object to ensure it is of the correct `conn_type` (`mongo`), raising an exception otherwise
* If the user have set the scheme/conn_type to `mongodb+srv`, the constructor exception provides an informative message telling the user to use the `mongo` conn_type and set `srv=true` in the `extras`
* The UI has been expanded with special boolean widgets for the supported `srv`, `ssl` and `allow_insecure` extra parameters

This is a replacement for #41371 which aimed to improve the Mongo connection parameters in a different and less-functional way.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",topherinternational,2024-08-24 21:04:06+00:00,[],2024-09-25 04:46:33+00:00,2024-09-17 19:38:38+00:00,https://github.com/apache/airflow/pull/41717,"[('area:providers', ''), ('provider:mongo', '')]","[{'comment_id': 2335894551, 'issue_id': 2484864562, 'author': 'topherinternational', 'body': '@jscheffl @uranusjr anything left to do before getting this merged?', 'created_at': datetime.datetime(2024, 9, 7, 16, 40, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2355535387, 'issue_id': 2484864562, 'author': 'topherinternational', 'body': ""I simplified the failing sensor test which was added by someone else in a different PR. Now it mocks the MongoHook and only tests the interactions between the sensor code and the hook instance inside the sensor, the details of connections etc are not necessary to confirm the sensor is working as designed. (IMO if we do want to test more realistically, we should use mongomock to mock the Mongo endpoint, and have real non-mocked MongoHook and Connection objects, but that's beyond the scope of this PR)."", 'created_at': datetime.datetime(2024, 9, 17, 12, 7, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2372515349, 'issue_id': 2484864562, 'author': 'zeev-finaloop', 'body': 'Hi, I believe that this PR is now breaking the functionality of connections that are imported from env vars for example. When parsing the connection from a uri, in case of mongo, the scheme == conn_type and it will now fail in validations as schema is either `mongodb` or `mongodb+srv`. I guess we need to add a small PR and add additional case in `_normalize_conn_type` method. I am not in the developers community here, so just raising the issue this PR caused.\r\nThis is where a fix is needed: https://github.com/apache/airflow/blob/ab3429c3189ceb244eb3d78062159859dbe611ce/airflow/models/connection.py#L215', 'created_at': datetime.datetime(2024, 9, 24, 22, 44, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2372937939, 'issue_id': 2484864562, 'author': 'jscheffl', 'body': '> Hi, I believe that this PR is now breaking the functionality of connections that are imported from env vars for example. When parsing the connection from a uri, in case of mongo, the scheme == conn_type and it will now fail in validations as schema is either `mongodb` or `mongodb+srv`. I guess we need to add a small PR and add additional case in `_normalize_conn_type` method. I am not in the developers community here, so just raising the issue this PR caused. This is where a fix is needed:\r\n> \r\n> https://github.com/apache/airflow/blob/ab3429c3189ceb244eb3d78062159859dbe611ce/airflow/models/connection.py#L215\r\n\r\nCan you elaborate some details, provide an example and post a separate issue entry as provider bug report? Maybe linking to this PR.', 'created_at': datetime.datetime(2024, 9, 25, 4, 46, 32, tzinfo=datetime.timezone.utc)}]","topherinternational (Issue Creator) on (2024-09-07 16:40:45 UTC): @jscheffl @uranusjr anything left to do before getting this merged?

topherinternational (Issue Creator) on (2024-09-17 12:07:43 UTC): I simplified the failing sensor test which was added by someone else in a different PR. Now it mocks the MongoHook and only tests the interactions between the sensor code and the hook instance inside the sensor, the details of connections etc are not necessary to confirm the sensor is working as designed. (IMO if we do want to test more realistically, we should use mongomock to mock the Mongo endpoint, and have real non-mocked MongoHook and Connection objects, but that's beyond the scope of this PR).

zeev-finaloop on (2024-09-24 22:44:30 UTC): Hi, I believe that this PR is now breaking the functionality of connections that are imported from env vars for example. When parsing the connection from a uri, in case of mongo, the scheme == conn_type and it will now fail in validations as schema is either `mongodb` or `mongodb+srv`. I guess we need to add a small PR and add additional case in `_normalize_conn_type` method. I am not in the developers community here, so just raising the issue this PR caused.
This is where a fix is needed: https://github.com/apache/airflow/blob/ab3429c3189ceb244eb3d78062159859dbe611ce/airflow/models/connection.py#L215

jscheffl on (2024-09-25 04:46:32 UTC): Can you elaborate some details, provide an example and post a separate issue entry as provider bug report? Maybe linking to this PR.

"
2484770125,pull_request,closed,,Pin universal-pathlib to 0.2.2 as 0.2.3 generates static code check errors,"This PR fixes the Mypy Errors I see on my PR since universal-pathlib 0.2.3 has been released:

Manual MyPy Airflow:
```
 airflow/io/path.py:201: error: Unexpected keyword argument ""overwrite"" for
""rename"" of ""UPath""  [call-arg]
            return self.rename(target, overwrite=True)
                   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```
Manual MyPy Providers:
```
airflow/providers/common/io/xcom/backend.py:145: error: Argument 1 to
""joinpath"" of ""UPath"" has incompatible type ""Optional[str]""; expected
""Union[str, PathLike[str]]""  [arg-type]
                p = base_path.joinpath(dag_id, run_id, task_id, f""{uuid.uu...
                                       ^~~~~~
airflow/providers/common/io/xcom/backend.py:145: error: Argument 2 to
""joinpath"" of ""UPath"" has incompatible type ""Optional[str]""; expected
""Union[str, PathLike[str]]""  [arg-type]
                p = base_path.joinpath(dag_id, run_id, task_id, f""{uuid.uu...
                                               ^~~~~~
airflow/providers/common/io/xcom/backend.py:145: error: Argument 3 to
""joinpath"" of ""UPath"" has incompatible type ""Optional[str]""; expected
""Union[str, PathLike[str]]""  [arg-type]
    ...          p = base_path.joinpath(dag_id, run_id, task_id, f""{uuid.uuid...
                                                        ^~~~~~~
```

Where the interface for XCom only allows a pre-raising if params are missing, the error in core with `overwrite` is something where logic might need to be adjusted for a permanent fix. But as this turns all PRs red, proposing to just pin version to 0.2.2 for the moment.

@bolkedebruin Do you have a better idea?",jscheffl,2024-08-24 18:11:14+00:00,[],2024-08-30 09:21:21+00:00,2024-08-24 22:16:49+00:00,https://github.com/apache/airflow/pull/41715,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2308725527, 'issue_id': 2484770125, 'author': 'potiuk', 'body': 'What we usually do in those cases - we create an issue and link URL to that issue in the comment https://github.com/apache/airflow/issues/41723', 'created_at': datetime.datetime(2024, 8, 25, 8, 9, 31, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-25 08:09:31 UTC): What we usually do in those cases - we create an issue and link URL to that issue in the comment https://github.com/apache/airflow/issues/41723

"
2484744069,pull_request,closed,,Prepare docs for Aug 3rd wave of providers,"```
Summary of prepared documentation:

Success: 4

openlineage ssh cncf.kubernetes celery

Scheduled for removal: 1

tabular

```",eladkal,2024-08-24 17:33:20+00:00,[],2024-08-25 07:29:52+00:00,2024-08-25 07:29:49+00:00,https://github.com/apache/airflow/pull/41714,"[('area:providers', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:openlineage', 'AIP-53'), ('provider:celery', ''), ('provider:ssh', ''), ('provider:tabular', '')]",[],
2484607049,pull_request,closed,,Fix poll_interval in GKEJobTrigger,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
closes: #41705
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #41705
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-08-24 13:42:43+00:00,[],2024-11-02 13:06:18+00:00,2024-09-01 18:56:12+00:00,https://github.com/apache/airflow/pull/41712,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2484472640,pull_request,closed,,remove deprecated soft_fail from providers,following work of this PR https://github.com/apache/airflow/pull/41407,raphaelauv,2024-08-24 10:15:59+00:00,[],2024-08-25 12:56:49+00:00,2024-08-25 12:52:55+00:00,https://github.com/apache/airflow/pull/41710,"[('provider:google', 'Google (including GCP) related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:databricks', ''), ('provider:celery', ''), ('provider:ftp', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:datadog', ''), ('provider:dbt-cloud', ''), ('provider:jenkins', ''), ('provider:apache-flink', '')]",[],
2484263910,pull_request,closed,,[doc] Fix broken link in breeze docs and minor grammar updates,"
In Breeze developer tasks, there's a broken image link - [Link](https://github.com/apache/airflow/blob/main/dev/breeze/doc/03_developer_tasks.rst#database-volumes-in-breeze)

This PR fixes it.

Also, minor grammar updates to [Using Airflow Public Interfaces](https://airflow.apache.org/docs/apache-airflow/stable/public-airflow-interface.html#using-airflow-public-interfaces)
",rawwar,2024-08-24 05:51:30+00:00,[],2024-08-24 06:22:26+00:00,2024-08-24 06:22:26+00:00,https://github.com/apache/airflow/pull/41709,"[('area:dev-tools', ''), ('kind:documentation', '')]",[],
2484222515,pull_request,closed,,deprecated fab auth manager removed,deprecated fab auth managers airflow.auth.managers.fab.fab_auth_manager and airflow.auth.managers.fab.security_manager.override removed,dirrao,2024-08-24 05:03:25+00:00,[],2024-08-25 12:03:49+00:00,2024-08-25 12:03:49+00:00,https://github.com/apache/airflow/pull/41708,"[('area:providers', ''), ('kind:documentation', ''), ('provider:fab', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2483833389,pull_request,closed,,Don't Fail LocalTaskJob on heartbeat,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The local task job heartbeat will crash the task if it fails. This is counter to the goal of the heartbeat, which is that it's ok if the task temporarily loses connection to the DB as long as it re-establishes it within the zombie timeout.

I've used an extremely broad exception here. I'm open to something more narrow if we have a smaller error type that will still cover the problems not controllable by the Airflow code, but I think it's reasonable to use a very broad exception.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",collinmcnulty,2024-08-23 20:21:35+00:00,[],2024-08-30 09:19:54+00:00,2024-08-26 15:07:01+00:00,https://github.com/apache/airflow/pull/41704,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2308616592, 'issue_id': 2483833389, 'author': 'collinmcnulty', 'body': 'Sorry Jed and Jarek for the incorrect notification, I messed up the rebase process and included extra changes. Now fixed.', 'created_at': datetime.datetime(2024, 8, 25, 1, 55, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313700480, 'issue_id': 2483833389, 'author': 'jedcunningham', 'body': 'Cherry-pick pr: https://github.com/apache/airflow/pull/41810', 'created_at': datetime.datetime(2024, 8, 27, 22, 45, 15, tzinfo=datetime.timezone.utc)}]","collinmcnulty (Issue Creator) on (2024-08-25 01:55:09 UTC): Sorry Jed and Jarek for the incorrect notification, I messed up the rebase process and included extra changes. Now fixed.

jedcunningham on (2024-08-27 22:45:15 UTC): Cherry-pick pr: https://github.com/apache/airflow/pull/41810

"
2483766146,pull_request,closed,,Fix pinecone PINECONE_DEBUG_CURL unit test,"Previously the unit test was mocking too early and [the code](https://github.com/apache/airflow/blob/2ac4e4dfe324638824a0edd16c6ff6857b053d9b/airflow/providers/pinecone/hooks/pinecone.py#L119) which sets the env variable was not even running. This PR removes the mocking and creates the client only to ensure the env variable is being set.

I'm not entirely sure how this test was ever passing since this code has not changed recently, but our tests on main (within aws and also locally confirmed running the test in Breeze on my laptop) detected this recently and have been consistently failing for a day.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-08-23 19:33:49+00:00,[],2024-08-26 14:11:32+00:00,2024-08-24 03:43:27+00:00,https://github.com/apache/airflow/pull/41703,"[('area:providers', ''), ('provider:pinecone', '')]",[],
2483291487,pull_request,closed,,Update Databricks workflow example DAG,"Update Databricks workflow example DAG
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-08-23 14:37:19+00:00,[],2024-08-26 11:56:56+00:00,2024-08-26 11:56:55+00:00,https://github.com/apache/airflow/pull/41700,"[('area:providers', ''), ('area:system-tests', ''), ('provider:databricks', '')]",[],
2483143039,pull_request,closed,,fix log for notifier(instance) without __name__ (#41591),"cherry-pick 0cd4686c59

cc: @potiuk 
",obarisk,2024-08-23 13:21:57+00:00,[],2024-08-30 11:41:31+00:00,2024-08-23 14:27:54+00:00,https://github.com/apache/airflow/pull/41699,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2483088031,pull_request,closed,,Fix example_bigtable system test,"Fix issues with bigtable system test:

* ensure correct id strings with proper length, as it might be issues depending on length of `SYSTEM_TESTS_ENV_ID` value.
* assign proper id values to resources used
* add constants for resources names limits


",olegkachur-e,2024-08-23 12:53:57+00:00,[],2024-08-23 13:06:53+00:00,2024-08-23 13:06:53+00:00,https://github.com/apache/airflow/pull/41697,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]","[{'comment_id': 2307035696, 'issue_id': 2483088031, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 23, 12, 54, 1, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-23 12:54:01 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2483079349,pull_request,closed,,Adding rel property to hyperlinks in logs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adding `rel=""noopener noreferrer""` as `target=_blank"" is used to be consistent with the codebase


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-08-23 12:49:16+00:00,[],2024-08-30 09:31:31+00:00,2024-08-26 15:15:27+00:00,https://github.com/apache/airflow/pull/41696,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2307076266, 'issue_id': 2483079349, 'author': 'bbovenzi', 'body': 'This is just the test file. Did you mean to add it anywhere else?', 'created_at': datetime.datetime(2024, 8, 23, 13, 16, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307079638, 'issue_id': 2483079349, 'author': 'amoghrajesh', 'body': 'Yeah there are 2 commits, first adds it to airflow/www/static/js/dag/details/taskInstance/Logs/utils.ts', 'created_at': datetime.datetime(2024, 8, 23, 13, 18, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308383706, 'issue_id': 2483079349, 'author': 'amoghrajesh', 'body': '@bbovenzi can you take a look at this one when you have some time?', 'created_at': datetime.datetime(2024, 8, 24, 12, 50, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311570169, 'issue_id': 2483079349, 'author': 'amoghrajesh', 'body': 'We need to backport this to 2.10 branch', 'created_at': datetime.datetime(2024, 8, 27, 4, 54, 20, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-08-23 13:16:43 UTC): This is just the test file. Did you mean to add it anywhere else?

amoghrajesh (Issue Creator) on (2024-08-23 13:18:41 UTC): Yeah there are 2 commits, first adds it to airflow/www/static/js/dag/details/taskInstance/Logs/utils.ts

amoghrajesh (Issue Creator) on (2024-08-24 12:50:28 UTC): @bbovenzi can you take a look at this one when you have some time?

amoghrajesh (Issue Creator) on (2024-08-27 04:54:20 UTC): We need to backport this to 2.10 branch

"
2483025645,pull_request,closed,,Use set instead of list for dags' tags,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: 41420
related: 41420

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


Closes issue [41420](https://github.com/apache/airflow/issues/41420).

Thank you for viewing this PR :)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Avihais12344,2024-08-23 12:21:09+00:00,[],2024-09-21 09:49:42+00:00,2024-09-21 09:30:42+00:00,https://github.com/apache/airflow/pull/41695,"[('area:core', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2306979516, 'issue_id': 2483025645, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 23, 12, 21, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2344609035, 'issue_id': 2483025645, 'author': 'uranusjr', 'body': 'I do not like this, but feel free to merge this without me if others feel more strongly this i beneficial.', 'created_at': datetime.datetime(2024, 9, 11, 20, 8, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2345343338, 'issue_id': 2483025645, 'author': 'Avihais12344', 'body': ""@uranusjr why you don't like this?"", 'created_at': datetime.datetime(2024, 9, 12, 6, 3, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2346877354, 'issue_id': 2483025645, 'author': 'uranusjr', 'body': 'I mostly outlined the reasons above, but to summarise, you want to keep this mutable so you can call `add` after a DAG is created, but by changing this from a list to set, you are also breaking everyone thatâ€™s already adding tags after a DAG is created. The two things you are trying to do (use set instead of list, and keep the attribute mutable) have directly conflicted reasoning. IMO it is simply not worthwhile to break everyone so you can more easily handle duplicated tags. You can just do that easily in your own code.\r\n\r\nWith that said, 3.0 is the exact time to break everyone, so I am still open for this to be merged if people feel fine about it. But I will not approve nor merge this change myself.', 'created_at': datetime.datetime(2024, 9, 12, 17, 37, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2346881586, 'issue_id': 2483025645, 'author': 'jscheffl', 'body': '> I mostly outlined the reasons above, but to summarise, you want to keep this mutable so you can call `add` after a DAG is created, but by changing this from a list to set, you are also breaking everyone thatâ€™s already adding tags after a DAG is created. The two things you are trying to do (use set instead of list, and keep the attribute mutable) have directly conflicted reasoning. IMO it is simply not worthwhile to break everyone so you can more easily handle duplicated tags. You can just do that easily in your own code.\r\n> \r\n> With that said, 3.0 is the exact time to break everyone, so I am still open for this to be merged if people feel fine about it. But I will not approve nor merge this change myself.\r\n\r\nWould it make you more happy if we keep the interface as a list (so: non breaking) but during setting/init it is temporarily converted to a set to ensure no duplicates are in the list?', 'created_at': datetime.datetime(2024, 9, 12, 17, 40, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2351412952, 'issue_id': 2483025645, 'author': 'Avihais12344', 'body': ""@uranusjr I am sorry to hear you don't like my change. I think the solution of @jscheffl is reasonable to handle your conflict, even though I think we should break the interface to a `set`. Due to the release of Airflow 3, it's a great time (that may not come back) to break interfaces.\r\n\r\nBut can you (@uranusjr) at least close your conversations? As it blockes the merge request (that was approved by other people).\r\nThank you for your understanding."", 'created_at': datetime.datetime(2024, 9, 15, 6, 41, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2365104920, 'issue_id': 2483025645, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 21, 9, 30, 44, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-23 12:21:18 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

uranusjr on (2024-09-11 20:08:54 UTC): I do not like this, but feel free to merge this without me if others feel more strongly this i beneficial.

Avihais12344 (Issue Creator) on (2024-09-12 06:03:10 UTC): @uranusjr why you don't like this?

uranusjr on (2024-09-12 17:37:47 UTC): I mostly outlined the reasons above, but to summarise, you want to keep this mutable so you can call `add` after a DAG is created, but by changing this from a list to set, you are also breaking everyone thatâ€™s already adding tags after a DAG is created. The two things you are trying to do (use set instead of list, and keep the attribute mutable) have directly conflicted reasoning. IMO it is simply not worthwhile to break everyone so you can more easily handle duplicated tags. You can just do that easily in your own code.

With that said, 3.0 is the exact time to break everyone, so I am still open for this to be merged if people feel fine about it. But I will not approve nor merge this change myself.

jscheffl on (2024-09-12 17:40:20 UTC): Would it make you more happy if we keep the interface as a list (so: non breaking) but during setting/init it is temporarily converted to a set to ensure no duplicates are in the list?

Avihais12344 (Issue Creator) on (2024-09-15 06:41:18 UTC): @uranusjr I am sorry to hear you don't like my change. I think the solution of @jscheffl is reasonable to handle your conflict, even though I think we should break the interface to a `set`. Due to the release of Airflow 3, it's a great time (that may not come back) to break interfaces.

But can you (@uranusjr) at least close your conversations? As it blockes the merge request (that was approved by other people).
Thank you for your understanding.

boring-cyborg[bot] on (2024-09-21 09:30:44 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2482867778,pull_request,closed,,[Backport] Splitting syspath preparation into stages,This backports #41672.,uranusjr,2024-08-23 10:46:53+00:00,[],2024-08-30 11:42:04+00:00,2024-08-23 11:53:38+00:00,https://github.com/apache/airflow/pull/41694,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2482797847,pull_request,closed,,Deprecated kerberos auth removed,"The following deprecated kerberos auth removed
1. airflow.auth.managers.fab.api.auth.backend.kerberos_auth
2. airflow.api.auth.backend.kerberos_auth",dirrao,2024-08-23 10:07:45+00:00,[],2024-09-17 03:18:11+00:00,2024-09-17 03:18:11+00:00,https://github.com/apache/airflow/pull/41693,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('provider:fab', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2308100546, 'issue_id': 2482797847, 'author': 'dirrao', 'body': '> Breaking change must have news fragment to notify users what was removed and how to mitigate. In this case just alerting about module remove and how to set it up with fab provider\r\n\r\nI have already added the news fragment. Am I missing anything?', 'created_at': datetime.datetime(2024, 8, 24, 4, 58, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312692031, 'issue_id': 2482797847, 'author': 'potiuk', 'body': '@eladkal ?', 'created_at': datetime.datetime(2024, 8, 27, 14, 12, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313550352, 'issue_id': 2482797847, 'author': 'jscheffl', 'body': ""Sorry, need to be another bad guy here. We said for Airflow 3 dev rules we must separate PRs for providers and stuff for the core. Assume we need to split this here as well. (1) for provider update and (2) for removing/breaking change in core.\r\n\r\n(whereas I assume we don't plan to back-port to 2.10 so technically could be one PR?)"", 'created_at': datetime.datetime(2024, 8, 27, 21, 8, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314159388, 'issue_id': 2482797847, 'author': 'dirrao', 'body': '@eladkal \r\nLet me know if you want me to separate core and providers.', 'created_at': datetime.datetime(2024, 8, 28, 3, 52, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323726626, 'issue_id': 2482797847, 'author': 'dirrao', 'body': '@eladkal / @jscheffl \r\nDo you want me to create separate PR for provider changes?', 'created_at': datetime.datetime(2024, 9, 2, 3, 9, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329259445, 'issue_id': 2482797847, 'author': 'vincbeck', 'body': ""Yep I think it is needed. But we might actually want only core changes, breaking change in providers will result in creating major versions which we might not want yet. I'll let @eladkal confirm"", 'created_at': datetime.datetime(2024, 9, 4, 14, 42, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2334520303, 'issue_id': 2482797847, 'author': 'vincbeck', 'body': '@dirrao Could you please update this PR (or create another one) to include only changes from core?', 'created_at': datetime.datetime(2024, 9, 6, 17, 33, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2335107605, 'issue_id': 2482797847, 'author': 'dirrao', 'body': '@vincbeck / @jscheffl \r\nProvider changes are dependent on the core. Not sure how to support the backward compatibility. Please take a look at the provider dependency. Do you want me to add if else conditional based logic?', 'created_at': datetime.datetime(2024, 9, 7, 7, 48, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339084086, 'issue_id': 2482797847, 'author': 'vincbeck', 'body': 'Actually I think your changes are fine. It seems inevitable to force Airflow 3 to use the latest FAB version provider. See comment [here](https://github.com/apache/airflow/pull/42042#issuecomment-2333313742). If that is the case your changes are not breaking for providers. You back ported  `airflow/api/auth/backend/kerberos_auth.py` to `airflow/providers/fab/auth_manager/api/auth/backend/kerberos_auth.py` (am I right?) so FAB provider no longer depend on core Airflow for Kerberos auth (which is good). The only issue would be to use Airflow 3 with current version of FAB provider or earlier but, as mentioned, if this is something that will not be possible, I think these changes are fine. In this sense, these changes are not breaking for FAB provider.', 'created_at': datetime.datetime(2024, 9, 9, 21, 2, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339670429, 'issue_id': 2482797847, 'author': 'dirrao', 'body': '> Actually I think your changes are fine. It seems inevitable to force Airflow 3 to use the latest FAB version provider. See comment [here](https://github.com/apache/airflow/pull/42042#issuecomment-2333313742). If that is the case your changes are not breaking for providers. You back ported `airflow/api/auth/backend/kerberos_auth.py` to `airflow/providers/fab/auth_manager/api/auth/backend/kerberos_auth.py` (am I right?) so FAB provider no longer depend on core Airflow for Kerberos auth (which is good). The only issue would be to use Airflow 3 with current version of FAB provider or earlier but, as mentioned, if this is something that will not be possible, I think these changes are fine. In this sense, these changes are not breaking for FAB provider.\r\n\r\nYes, my changes are backward compatible. They will simply start using the FAB provider module instead of the deprecated core auth module.', 'created_at': datetime.datetime(2024, 9, 10, 5, 44, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339671781, 'issue_id': 2482797847, 'author': 'dirrao', 'body': ""@potiuk / @eladkal\r\nI'm awaiting final approval to proceed with the merge. Could you please take a look when you get a chance?"", 'created_at': datetime.datetime(2024, 9, 10, 5, 45, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354017347, 'issue_id': 2482797847, 'author': 'vincbeck', 'body': '> The commit message says removed deprecation but this PR also adds more functionality to the provider. Is the commit message right?\r\n\r\nThe only code added to the provider is code moved from core to provider. There is no new functionality. I think the message is fair', 'created_at': datetime.datetime(2024, 9, 16, 20, 55, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354406412, 'issue_id': 2482797847, 'author': 'dirrao', 'body': '> > The commit message says removed deprecation but this PR also adds more functionality to the provider. Is the commit message right?\r\n> \r\n> The only code added to the provider is code moved from core to provider. There is no new functionality. I think the message is fair\r\n\r\nYes. No new functionality added.', 'created_at': datetime.datetime(2024, 9, 17, 2, 53, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354425537, 'issue_id': 2482797847, 'author': 'eladkal', 'body': '> The only code added to the provider is code moved from core to provider. There is no new functionality. I think the message is fair\r\n\r\nok then I will modify the provider change log', 'created_at': datetime.datetime(2024, 9, 17, 3, 17, 58, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-24 04:58:52 UTC): I have already added the news fragment. Am I missing anything?

potiuk on (2024-08-27 14:12:45 UTC): @eladkal ?

jscheffl on (2024-08-27 21:08:05 UTC): Sorry, need to be another bad guy here. We said for Airflow 3 dev rules we must separate PRs for providers and stuff for the core. Assume we need to split this here as well. (1) for provider update and (2) for removing/breaking change in core.

(whereas I assume we don't plan to back-port to 2.10 so technically could be one PR?)

dirrao (Issue Creator) on (2024-08-28 03:52:14 UTC): @eladkal 
Let me know if you want me to separate core and providers.

dirrao (Issue Creator) on (2024-09-02 03:09:01 UTC): @eladkal / @jscheffl 
Do you want me to create separate PR for provider changes?

vincbeck on (2024-09-04 14:42:13 UTC): Yep I think it is needed. But we might actually want only core changes, breaking change in providers will result in creating major versions which we might not want yet. I'll let @eladkal confirm

vincbeck on (2024-09-06 17:33:03 UTC): @dirrao Could you please update this PR (or create another one) to include only changes from core?

dirrao (Issue Creator) on (2024-09-07 07:48:18 UTC): @vincbeck / @jscheffl 
Provider changes are dependent on the core. Not sure how to support the backward compatibility. Please take a look at the provider dependency. Do you want me to add if else conditional based logic?

vincbeck on (2024-09-09 21:02:10 UTC): Actually I think your changes are fine. It seems inevitable to force Airflow 3 to use the latest FAB version provider. See comment [here](https://github.com/apache/airflow/pull/42042#issuecomment-2333313742). If that is the case your changes are not breaking for providers. You back ported  `airflow/api/auth/backend/kerberos_auth.py` to `airflow/providers/fab/auth_manager/api/auth/backend/kerberos_auth.py` (am I right?) so FAB provider no longer depend on core Airflow for Kerberos auth (which is good). The only issue would be to use Airflow 3 with current version of FAB provider or earlier but, as mentioned, if this is something that will not be possible, I think these changes are fine. In this sense, these changes are not breaking for FAB provider.

dirrao (Issue Creator) on (2024-09-10 05:44:14 UTC): Yes, my changes are backward compatible. They will simply start using the FAB provider module instead of the deprecated core auth module.

dirrao (Issue Creator) on (2024-09-10 05:45:29 UTC): @potiuk / @eladkal
I'm awaiting final approval to proceed with the merge. Could you please take a look when you get a chance?

vincbeck on (2024-09-16 20:55:43 UTC): The only code added to the provider is code moved from core to provider. There is no new functionality. I think the message is fair

dirrao (Issue Creator) on (2024-09-17 02:53:53 UTC): Yes. No new functionality added.

eladkal on (2024-09-17 03:17:58 UTC): ok then I will modify the provider change log

"
2482781686,pull_request,closed,,pass location correctly to is_dataflow_job_running,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

`is_job_dataflow_running` function (https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/hooks/dataflow.py#L1047C9-L1047C32) is called omitting `location` argument from multiple places (see changes), thus, always the default value of `DEFAULT_DATAFLOW_LOCATION = us-central1` is used.

This causes issues with `BeamRunJavaPipelineOperator`. When a job status is set to success/failure dataflow API is called using `locations/us-central1` even when the operator is configured with another region (for example `europe-west1`), resulting in the job not being found:
```
googleapiclient.errors.HttpError: <HttpError 404 when requesting https://dataflow.googleapis.com/v1b3/projects/<my_gcp_project>/locations/us-central1/jobs/<my_job>%20%28org.apache.beam.runners.dataflow.DataflowRunner%29%20%28main%29?alt=json returned ""(40f1eba84acd2e6a): Information about job <my_job> (org.apache.beam.runners.dataflow.DataflowRunner) (main) could not be found in our system. Please double check that the API being used is projects.locations.jobs.get (https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.locations.jobs/get). If the API being used is projects.locations.jobs.get, please double check the id (<my_job> (org.apache.beam.runners.dataflow.DataflowRunner) (main)) is correct. If it is please contact customer support."". Details: ""(40f1eba84acd2e6a): Information about job <my_job> (org.apache.beam.runners.dataflow.DataflowRunner) (main) could not be found in our system. Please double check that the API being used is projects.locations.jobs.get (https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.locations.jobs/get). If the API being used is projects.locations.jobs.get, please double check the id (<my_job> (org.apache.beam.runners.dataflow.DataflowRunner) (main)) is correct. If it is please contact customer support."">
```
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",lukas-mi,2024-08-23 09:59:32+00:00,[],2024-09-19 08:03:59+00:00,2024-08-30 12:10:37+00:00,https://github.com/apache/airflow/pull/41692,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:apache-beam', '')]","[{'comment_id': 2306741844, 'issue_id': 2482781686, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 23, 9, 59, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2321033689, 'issue_id': 2482781686, 'author': 'lukas-mi', 'body': 'Closing in favor of https://github.com/apache/airflow/pull/41887, which adds additional changes', 'created_at': datetime.datetime(2024, 8, 30, 12, 10, 37, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-23 09:59:37 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

lukas-mi (Issue Creator) on (2024-08-30 12:10:37 UTC): Closing in favor of https://github.com/apache/airflow/pull/41887, which adds additional changes

"
2482770713,pull_request,closed,,docs(deferring): fix missing import in example and remove unnecessary example,"As https://github.com/apache/airflow/pull/40993 has implemented serialization of `StartTriggerArgs`, the original example can now be serialized through Airflow. Also, the original example miss one import

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-23 09:53:30+00:00,[],2024-08-26 08:41:03+00:00,2024-08-26 08:41:02+00:00,https://github.com/apache/airflow/pull/41691,"[('kind:documentation', '')]",[],
2482665428,pull_request,closed,,"feat: notify about potential serialization failures when sending DagRun, don't serialize unnecessary params, guard listener for exceptions","We've moved to a model where DagRun level events utilize ProcessPoolExecutor to send data, to not do this on the direct scheduler process. This PR adds more guards to that model:
- do not send/pickle whole DagRun model to process, since serializing only selected attributes is cheaper and less error prone
- add notification on ProcessPoolExecutor complete - this allows listener to log potential serialization failures.
- guard whole listener with BaseException checks - we don't want errors to bubble to scheduler.",mobuchowski,2024-08-23 08:58:21+00:00,[],2024-09-02 13:59:13+00:00,2024-09-02 13:59:13+00:00,https://github.com/apache/airflow/pull/41690,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2482519012,pull_request,closed,,Update merging instruction for client release guide,,ephraimbuddy,2024-08-23 07:37:18+00:00,[],2024-08-23 08:35:52+00:00,2024-08-23 08:35:50+00:00,https://github.com/apache/airflow/pull/41689,"[('area:dev-tools', '')]",[],
2482191264,pull_request,closed,,Fix callback log,"https://github.com/apache/airflow/pull/41591

cc: @potiuk ",obarisk,2024-08-23 04:01:29+00:00,[],2024-08-23 04:02:04+00:00,2024-08-23 04:02:04+00:00,https://github.com/apache/airflow/pull/41688,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]",[],
2482165797,pull_request,closed,,chore(docs): add an example for auth with keycloak,"Added a new section in the authentication documentation that provides a code of configuring Airflow to work with Keycloak.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hoalongnatsu,2024-08-23 03:30:51+00:00,[],2024-08-27 12:08:01+00:00,2024-08-27 12:07:58+00:00,https://github.com/apache/airflow/pull/41687,"[('area:providers', ''), ('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only'), ('provider:fab', '')]","[{'comment_id': 2308941943, 'issue_id': 2482165797, 'author': 'potiuk', 'body': 'Some static checks need fixing (pre-commit shoudl auto-fix them)', 'created_at': datetime.datetime(2024, 8, 25, 17, 59, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309247194, 'issue_id': 2482165797, 'author': 'hoalongnatsu', 'body': 'Static checks fixed', 'created_at': datetime.datetime(2024, 8, 26, 3, 44, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312386244, 'issue_id': 2482165797, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 27, 12, 8, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-25 17:59:04 UTC): Some static checks need fixing (pre-commit shoudl auto-fix them)

hoalongnatsu (Issue Creator) on (2024-08-26 03:44:59 UTC): Static checks fixed

boring-cyborg[bot] on (2024-08-27 12:08:00 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2482160216,pull_request,closed,,chore(docs): add an example for auth with keycloak,"Added a new section in the authentication documentation that provides a code of configuring Airflow to work with Keycloak.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hoalongnatsu,2024-08-23 03:23:19+00:00,[],2024-08-23 03:28:06+00:00,2024-08-23 03:27:55+00:00,https://github.com/apache/airflow/pull/41686,"[('area:providers', ''), ('kind:documentation', ''), ('provider:fab', '')]","[{'comment_id': 2306108962, 'issue_id': 2482160216, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 23, 3, 23, 22, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-23 03:23:22 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2481311277,pull_request,closed,,update with upstream,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sc250072,2024-08-22 17:00:56+00:00,[],2024-08-22 17:02:33+00:00,2024-08-22 17:02:33+00:00,https://github.com/apache/airflow/pull/41682,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2481073757,pull_request,closed,,Adding url sanitisation for extra links (#41665),"(cherry picked from commit 6c463b3c37fd9aef56ceace7e7b141d892b57054)

",amoghrajesh,2024-08-22 15:17:02+00:00,[],2024-08-30 11:42:42+00:00,2024-08-22 16:04:28+00:00,https://github.com/apache/airflow/pull/41680,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2481010314,pull_request,closed,,Change confirmation text,"**Cherry-pick of #41650 / a11656cc6be3b3381997734ced65f586d57b05ae from main to v2-10-test**

Change confirmation text page to say ""Please confirm"" instead of ""Wait a minute"" and update associated UI-level tests. As a new user to airflow, the text ""Wait a minute"" implied that the user should wait for some background process, whereas the intention is for the user to review the action and confirm it. This is a trivial text change, so extensive testing was not performed, as the UI tests cover the change.

closes: #41649
",kev-the-dev,2024-08-22 14:58:32+00:00,[],2024-08-30 11:43:05+00:00,2024-08-22 16:02:58+00:00,https://github.com/apache/airflow/pull/41679,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2480895963,pull_request,closed,,Fix failing no-pydantic tests for OpenAI.,"The #41554 broke exclusion of openai tests when no pydantic is installed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-22 14:10:00+00:00,[],2024-08-22 14:44:05+00:00,2024-08-22 14:44:03+00:00,https://github.com/apache/airflow/pull/41677,"[('area:providers', ''), ('provider:openai', '')]","[{'comment_id': 2304777123, 'issue_id': 2480895963, 'author': 'potiuk', 'body': 'Fixes https://github.com/apache/airflow/actions/runs/10508777264/job/29113649233?pr=41653', 'created_at': datetime.datetime(2024, 8, 22, 14, 11, 28, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-22 14:11:28 UTC): Fixes https://github.com/apache/airflow/actions/runs/10508777264/job/29113649233?pr=41653

"
2480640005,pull_request,closed,,Reflect in docs that extraInitContainers is supported for jobs,"Just a small PR to add in https://airflow.apache.org/docs/helm-chart/stable/using-additional-containers.html information that the jobs actually support `extraContainers` parameter.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Aakcht,2024-08-22 12:15:45+00:00,[],2024-08-24 02:53:47+00:00,2024-08-23 00:25:55+00:00,https://github.com/apache/airflow/pull/41674,"[('area:helm-chart', 'Airflow Helm Chart'), ('kind:documentation', '')]",[],
2480624654,pull_request,closed,,Splitting syspath preparation into stages,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Splitting the airflow/settings.py#initialize into stages for easier maintainability. 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-08-22 12:08:14+00:00,[],2024-08-30 09:17:28+00:00,2024-08-23 05:47:06+00:00,https://github.com/apache/airflow/pull/41672,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2304611579, 'issue_id': 2480624654, 'author': 'potiuk', 'body': 'a test needs fixing', 'created_at': datetime.datetime(2024, 8, 22, 12, 59, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306098841, 'issue_id': 2480624654, 'author': 'uranusjr', 'body': 'Still a test failing', 'created_at': datetime.datetime(2024, 8, 23, 3, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306757263, 'issue_id': 2480624654, 'author': 'potiuk', 'body': 'This one should also be backported to 2.10.1', 'created_at': datetime.datetime(2024, 8, 23, 10, 7, 4, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-22 12:59:27 UTC): a test needs fixing

uranusjr on (2024-08-23 03:09:00 UTC): Still a test failing

potiuk on (2024-08-23 10:07:04 UTC): This one should also be backported to 2.10.1

"
2480621682,pull_request,closed,,Rename dataset module as asset and dataset manger as asset manager,"As https://github.com/apache/airflow/pull/41348 grows too large already, this is the first 15 commits that only relates to module rename and dataset manager rename

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-22 12:06:48+00:00,[],2024-08-22 15:06:01+00:00,2024-08-22 15:06:00+00:00,https://github.com/apache/airflow/pull/41671,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:lineage', ''), ('provider:openlineage', 'AIP-53'), ('provider:common-io', ''), ('provider:common-compat', ''), ('AIP-74', 'Dataset -> Asset')]","[{'comment_id': 2304914869, 'issue_id': 2480621682, 'author': 'Lee-W', 'body': ""As discussed with @kaxil , to keep the history clean. I'll close this one and use the oringal one"", 'created_at': datetime.datetime(2024, 8, 22, 15, 6, 1, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-08-22 15:06:01 UTC): As discussed with @kaxil , to keep the history clean. I'll close this one and use the oringal one

"
2480491364,pull_request,closed,,Update instructions for removed provider,,eladkal,2024-08-22 10:59:15+00:00,[],2024-08-22 12:48:50+00:00,2024-08-22 11:44:16+00:00,https://github.com/apache/airflow/pull/41669,"[('area:dev-tools', '')]",[],
2480472634,pull_request,closed,,backport: Set better logging level for path wrapper (#41615),This backports #41615 to 2.10.,mobuchowski,2024-08-22 10:49:33+00:00,[],2024-08-30 11:43:32+00:00,2024-08-22 11:42:57+00:00,https://github.com/apache/airflow/pull/41668,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2480470962,pull_request,closed,,backport: Set better logging level for path wrapper,Backport https://github.com/apache/airflow/pull/41615 to 2.10.,mobuchowski,2024-08-22 10:48:47+00:00,[],2024-08-22 10:48:53+00:00,2024-08-22 10:48:53+00:00,https://github.com/apache/airflow/pull/41667,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]",[],
2480451939,pull_request,closed,,Update providers metadata 2024-08-22,,eladkal,2024-08-22 10:40:09+00:00,[],2024-08-22 14:43:15+00:00,2024-08-22 13:26:04+00:00,https://github.com/apache/airflow/pull/41666,[],[],
2480408150,pull_request,closed,,Adding url sanitisation for extra links,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adding url sanitisation for the extra links that can be added and consumed as plugins.
The idea here is to disable the button if there's some violation and the url turns out to be un sanitised.
Before:
![image](https://github.com/user-attachments/assets/56b08d52-1c18-4155-b0d5-1a5a8b86c49a)



After:
![image](https://github.com/user-attachments/assets/563b18b5-baab-4a48-a5af-2e8213e6b5fd)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-08-22 10:20:37+00:00,[],2024-08-30 09:16:57+00:00,2024-08-22 12:53:27+00:00,https://github.com/apache/airflow/pull/41665,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2304840538, 'issue_id': 2480408150, 'author': 'bbovenzi', 'body': 'Good catch! @amoghrajesh can you cherry pick this for `v-2-10-test` too?', 'created_at': datetime.datetime(2024, 8, 22, 14, 37, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304847802, 'issue_id': 2480408150, 'author': 'potiuk', 'body': 'Oh yeah. My Bad not asking for that.', 'created_at': datetime.datetime(2024, 8, 22, 14, 41, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304852952, 'issue_id': 2480408150, 'author': 'potiuk', 'body': 'Marked it as 2.10.1 just in case we miss it accidentally. Also see https://github.com/apache/airflow/pull/41457#discussion_r1727185777 - we should mark all such PRs as `Milestone 2.10.x` and get a final check at release time if all such changes have been merged - otherwise - we can miss some of those', 'created_at': datetime.datetime(2024, 8, 22, 14, 43, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304927677, 'issue_id': 2480408150, 'author': 'amoghrajesh', 'body': '> Good catch! @amoghrajesh can you cherry pick this for `v-2-10-test` too?\r\n\r\nAh thanks. Still getting used to this!', 'created_at': datetime.datetime(2024, 8, 22, 15, 9, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304968153, 'issue_id': 2480408150, 'author': 'amoghrajesh', 'body': ""@bbovenzi @potiuk here's the cherry pick https://github.com/apache/airflow/pull/41680\r\n@potiuk do we ask users to `git cherry-pick -x <hash>`? It is easier to track history with the same hash, or it makes it harder in the long term"", 'created_at': datetime.datetime(2024, 8, 22, 15, 17, 49, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-08-22 14:37:58 UTC): Good catch! @amoghrajesh can you cherry pick this for `v-2-10-test` too?

potiuk on (2024-08-22 14:41:12 UTC): Oh yeah. My Bad not asking for that.

potiuk on (2024-08-22 14:43:27 UTC): Marked it as 2.10.1 just in case we miss it accidentally. Also see https://github.com/apache/airflow/pull/41457#discussion_r1727185777 - we should mark all such PRs as `Milestone 2.10.x` and get a final check at release time if all such changes have been merged - otherwise - we can miss some of those

amoghrajesh (Issue Creator) on (2024-08-22 15:09:01 UTC): Ah thanks. Still getting used to this!

amoghrajesh (Issue Creator) on (2024-08-22 15:17:49 UTC): @bbovenzi @potiuk here's the cherry pick https://github.com/apache/airflow/pull/41680
@potiuk do we ask users to `git cherry-pick -x <hash>`? It is easier to track history with the same hash, or it makes it harder in the long term

"
2480275786,pull_request,closed,,feat: deprecated basic auth airflow.api.auth.backend.basic_auth removed,deprecated basic auth airflow.api.auth.backend.basic_auth removed,dirrao,2024-08-22 09:24:31+00:00,['dirrao'],2024-08-22 14:29:22+00:00,2024-08-22 14:29:22+00:00,https://github.com/apache/airflow/pull/41663,"[('area:providers', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('provider:fab', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2304277298, 'issue_id': 2480275786, 'author': 'potiuk', 'body': 'I think there is a problem to fix in our docker-compose as well - tests seem to be failing after that change', 'created_at': datetime.datetime(2024, 8, 22, 10, 6, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304411451, 'issue_id': 2480275786, 'author': 'dirrao', 'body': '> I think there is a problem to fix in our docker-compose as well - tests seem to be failing after that change\r\n\r\nFixed. Waiting for the tests to pass.', 'created_at': datetime.datetime(2024, 8, 22, 11, 15, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304820543, 'issue_id': 2480275786, 'author': 'potiuk', 'body': 'The failing test is from main and fixed in https://github.com/apache/airflow/pull/41677', 'created_at': datetime.datetime(2024, 8, 22, 14, 29, 17, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-22 10:06:06 UTC): I think there is a problem to fix in our docker-compose as well - tests seem to be failing after that change

dirrao (Issue Creator) on (2024-08-22 11:15:45 UTC): Fixed. Waiting for the tests to pass.

potiuk on (2024-08-22 14:29:17 UTC): The failing test is from main and fixed in https://github.com/apache/airflow/pull/41677

"
2479953578,pull_request,closed,,stackdriver task_handler deprecated name arg removed,stackdriver task_handler deprecated name arg removed,dirrao,2024-08-22 06:33:13+00:00,['dirrao'],2025-01-11 00:15:27+00:00,2025-01-11 00:15:27+00:00,https://github.com/apache/airflow/pull/41659,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:logging', '')]","[{'comment_id': 2303919770, 'issue_id': 2479953578, 'author': 'uranusjr', 'body': 'This is a provider change and shouldnâ€™t be tied with Airflow 3.0. It should be tied to when we want to bump the providerâ€™s major version, but that should likely not be the same time as Airflow 3.0 (bumping major in both would make user migration difficult).', 'created_at': datetime.datetime(2024, 8, 22, 6, 55, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304110531, 'issue_id': 2479953578, 'author': 'potiuk', 'body': ""Yes. If we make provider breaking change, this requires adding a comment in CHANGELOG for that provider and bumping the major version in provider.yaml (see comment in provider's CHANGELOG at the top). And since this is a google provider - it should be coordinated with other breaking changes removal - this is being currently disucssed in https://github.com/apache/airflow/pull/41637 with @moiseenkov"", 'created_at': datetime.datetime(2024, 8, 22, 8, 43, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304199332, 'issue_id': 2479953578, 'author': 'moiseenkov', 'body': ""Yes\r\n\r\n> Yes. If we make provider breaking change, this requires adding a comment in CHANGELOG for that provider and bumping the major version in provider.yaml (see comment in provider's CHANGELOG at the top). And since this is a google provider - it should be coordinated with other breaking changes removal - this is being currently disucssed in #41637 with @moiseenkov\r\n\r\nAgree with @potiuk . Let's wait for the #41637 resolution and then adjust the depreciation warning here accordingly with a proper sunset date, so users would have time to migrate their code. And once the sunset is reached, we can remove this parameter along with other stuff."", 'created_at': datetime.datetime(2024, 8, 22, 9, 27, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455962966, 'issue_id': 2479953578, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 5, 0, 15, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462887114, 'issue_id': 2479953578, 'author': 'shahar1', 'body': 'Just recalling that https://github.com/apache/airflow/pull/41637 was resolved.\r\n@dirrao do you want to continue working on that?', 'created_at': datetime.datetime(2024, 11, 7, 17, 55, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466023627, 'issue_id': 2479953578, 'author': 'dirrao', 'body': '> Just recalling that #41637 was resolved.\r\n> @dirrao do you want to continue working on that?\r\n\r\nThis PR was on hold because it requires a major version release. Are we planning to proceed with the major release?', 'created_at': datetime.datetime(2024, 11, 9, 3, 37, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468304670, 'issue_id': 2479953578, 'author': 'potiuk', 'body': '@dirrao -> I think you need to synchronize with @moiseenkov @VladaZakharova @MaksYermak as the plan is to remove all deprecations (likely in Google Provider). I will remove my ""request changes"" but i think we need some kind of ""ok now we remove all deprecations before the next release of providers"" cc: @eladkal', 'created_at': datetime.datetime(2024, 11, 11, 14, 25, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469739709, 'issue_id': 2479953578, 'author': 'moiseenkov', 'body': '> @dirrao -> I think you need to synchronize with @moiseenkov @VladaZakharova @MaksYermak as the plan is to remove all deprecations (likely in Google Provider). I will remove my ""request changes"" but i think we need some kind of ""ok now we remove all deprecations before the next release of providers"" cc: @eladkal\r\n\r\nWe are currently working on deprecations removal and will raise a PR soon. Once it is done, I think we will be good to proceed with this PR as well.', 'created_at': datetime.datetime(2024, 11, 12, 6, 55, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478152081, 'issue_id': 2479953578, 'author': 'moiseenkov', 'body': ""Hi,\r\nThe deprecation removal PR is ready (#43953).\r\n@dirrao , please rebase your PR on top of my branch (or rebase on top of the main branch after my PR is merged). And please add info about breaking changes into the Google provider's CHANGELOG.rst."", 'created_at': datetime.datetime(2024, 11, 15, 7, 44, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480398952, 'issue_id': 2479953578, 'author': 'dirrao', 'body': '> #43953\r\n\r\nThanks for the update. I will rebase it once it is merged.', 'created_at': datetime.datetime(2024, 11, 16, 4, 47, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566766363, 'issue_id': 2479953578, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 1, 0, 17, 10, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-22 06:55:14 UTC): This is a provider change and shouldnâ€™t be tied with Airflow 3.0. It should be tied to when we want to bump the providerâ€™s major version, but that should likely not be the same time as Airflow 3.0 (bumping major in both would make user migration difficult).

potiuk on (2024-08-22 08:43:41 UTC): Yes. If we make provider breaking change, this requires adding a comment in CHANGELOG for that provider and bumping the major version in provider.yaml (see comment in provider's CHANGELOG at the top). And since this is a google provider - it should be coordinated with other breaking changes removal - this is being currently disucssed in https://github.com/apache/airflow/pull/41637 with @moiseenkov

moiseenkov on (2024-08-22 09:27:34 UTC): Yes


Agree with @potiuk . Let's wait for the #41637 resolution and then adjust the depreciation warning here accordingly with a proper sunset date, so users would have time to migrate their code. And once the sunset is reached, we can remove this parameter along with other stuff.

github-actions[bot] on (2024-11-05 00:15:04 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

shahar1 on (2024-11-07 17:55:35 UTC): Just recalling that https://github.com/apache/airflow/pull/41637 was resolved.
@dirrao do you want to continue working on that?

dirrao (Issue Creator) on (2024-11-09 03:37:06 UTC): This PR was on hold because it requires a major version release. Are we planning to proceed with the major release?

potiuk on (2024-11-11 14:25:47 UTC): @dirrao -> I think you need to synchronize with @moiseenkov @VladaZakharova @MaksYermak as the plan is to remove all deprecations (likely in Google Provider). I will remove my ""request changes"" but i think we need some kind of ""ok now we remove all deprecations before the next release of providers"" cc: @eladkal

moiseenkov on (2024-11-12 06:55:13 UTC): We are currently working on deprecations removal and will raise a PR soon. Once it is done, I think we will be good to proceed with this PR as well.

moiseenkov on (2024-11-15 07:44:45 UTC): Hi,
The deprecation removal PR is ready (#43953).
@dirrao , please rebase your PR on top of my branch (or rebase on top of the main branch after my PR is merged). And please add info about breaking changes into the Google provider's CHANGELOG.rst.

dirrao (Issue Creator) on (2024-11-16 04:47:23 UTC): Thanks for the update. I will rebase it once it is merged.

github-actions[bot] on (2025-01-01 00:17:10 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2479873883,pull_request,closed,,bugfix/livy-set-base-url,"Weâ€™re attempting to set `self.base_url` when it is not passed from outside. However, since the default value is an empty string, the condition `self.base_url is None` will never be true. This results in the log on line 161 being printed as 

 > Submit job xxx to # an empty url

which doesnâ€™t make sense. Eventually, `self.get_conf` will be called in `self.run_method` on line 163, so functionality-wise, everything works fine.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harryshi10,2024-08-22 05:30:19+00:00,[],2024-09-04 21:58:01+00:00,2024-09-04 21:52:19+00:00,https://github.com/apache/airflow/pull/41658,"[('area:providers', ''), ('provider:apache-livy', '')]","[{'comment_id': 2303817303, 'issue_id': 2479873883, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 22, 5, 30, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314941258, 'issue_id': 2479873883, 'author': 'potiuk', 'body': 'can you add a test for it please?', 'created_at': datetime.datetime(2024, 8, 28, 10, 31, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320960622, 'issue_id': 2479873883, 'author': 'harryshi10', 'body': '> can you add a test for it please?\r\n\r\non it', 'created_at': datetime.datetime(2024, 8, 30, 11, 41, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330185586, 'issue_id': 2479873883, 'author': 'harryshi10', 'body': 'UT added', 'created_at': datetime.datetime(2024, 9, 4, 21, 34, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330208208, 'issue_id': 2479873883, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 4, 21, 52, 22, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-22 05:30:22 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-08-28 10:31:24 UTC): can you add a test for it please?

harryshi10 (Issue Creator) on (2024-08-30 11:41:34 UTC): on it

harryshi10 (Issue Creator) on (2024-09-04 21:34:14 UTC): UT added

boring-cyborg[bot] on (2024-09-04 21:52:22 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2479152257,pull_request,closed,,PoC to make ProvidersManager independent of FAB for connection forms,"PoC to make ProvidersManager independent of FAB

Use a couple of mocks to load pre-existing provider connection forms w/o need to FAB and wtforms.
Convert all form elements to Param objects like trigger form which can be represented as JSON schema.

Test it with, make a `breeze shell` and run `python airflow/providers_manager.py` and see what is working already.",jscheffl,2024-08-21 21:20:55+00:00,[],2024-10-13 00:16:28+00:00,2024-10-13 00:16:27+00:00,https://github.com/apache/airflow/pull/41656,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2304124824, 'issue_id': 2479152257, 'author': 'potiuk', 'body': '@jscheffl  -> One small comment and suggestion here. If we are thinking long term - I think it would be worth while to figure out a mechanism where definition of connection widets is NOT read from Provider\'s manager. I think having connection definition is the only reason (or maybe one of the only very few reasons) why Webserver needs to have provider packages installed. Other than that, there is absolutely no reason why webserver shoudl have them. \r\n\r\nIf we can get to the situation that the webserver has no need to install providers at all we will be in a much more secure place - because webserver could have it\'s own much smaller container for example - without worrying about which providers are installed and which are not.\r\n\r\nAditionally - webserver would start way faster because it woudl not have to initialize Providers Manager at all.\r\n\r\nI think a good solution for that would be to store connection ""definition"" in the Database when providers are initialized and have Webserver read connection definition from the DB rather than use Providers\'s manager.', 'created_at': datetime.datetime(2024, 8, 22, 8, 50, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304129302, 'issue_id': 2479152257, 'author': 'potiuk', 'body': 'I think ""Base Operator Links"" is the other thing that we would have to solve and also pass through DB.', 'created_at': datetime.datetime(2024, 8, 22, 8, 52, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304151388, 'issue_id': 2479152257, 'author': 'potiuk', 'body': 'Started discussion in `#airflow-3-dev` on slack about it.', 'created_at': datetime.datetime(2024, 8, 22, 9, 3, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304185116, 'issue_id': 2479152257, 'author': 'ashb', 'body': 'Other thing the webserver needs the providers for currently is the ""Test"" button on the connection edit screens etc.', 'created_at': datetime.datetime(2024, 8, 22, 9, 20, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304786753, 'issue_id': 2479152257, 'author': 'jscheffl', 'body': '@potiuk UI Plugins are also contained in provider packages today. We would need to separate UI plugins from providers (as packages) if we want to keep provider package installs out-of-webserver.\r\n\r\nWhat we also can consider is that the plugin loading and init is limited to the stuff actually needed. And yes, provider meta information like connection form config could just be dropped to a blob in the DB of course.\r\n\r\nAs the ""Test"" feature caused a security incident in the past - would we plan to remove the ""Test"" button in Airflow 3 UI? That might be another discussion to just leave it out.', 'created_at': datetime.datetime(2024, 8, 22, 14, 15, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398253806, 'issue_id': 2479152257, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 8, 0, 14, 37, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-22 08:50:45 UTC): @jscheffl  -> One small comment and suggestion here. If we are thinking long term - I think it would be worth while to figure out a mechanism where definition of connection widets is NOT read from Provider's manager. I think having connection definition is the only reason (or maybe one of the only very few reasons) why Webserver needs to have provider packages installed. Other than that, there is absolutely no reason why webserver shoudl have them. 

If we can get to the situation that the webserver has no need to install providers at all we will be in a much more secure place - because webserver could have it's own much smaller container for example - without worrying about which providers are installed and which are not.

Aditionally - webserver would start way faster because it woudl not have to initialize Providers Manager at all.

I think a good solution for that would be to store connection ""definition"" in the Database when providers are initialized and have Webserver read connection definition from the DB rather than use Providers's manager.

potiuk on (2024-08-22 08:52:57 UTC): I think ""Base Operator Links"" is the other thing that we would have to solve and also pass through DB.

potiuk on (2024-08-22 09:03:38 UTC): Started discussion in `#airflow-3-dev` on slack about it.

ashb on (2024-08-22 09:20:12 UTC): Other thing the webserver needs the providers for currently is the ""Test"" button on the connection edit screens etc.

jscheffl (Issue Creator) on (2024-08-22 14:15:29 UTC): @potiuk UI Plugins are also contained in provider packages today. We would need to separate UI plugins from providers (as packages) if we want to keep provider package installs out-of-webserver.

What we also can consider is that the plugin loading and init is limited to the stuff actually needed. And yes, provider meta information like connection form config could just be dropped to a blob in the DB of course.

As the ""Test"" feature caused a security incident in the past - would we plan to remove the ""Test"" button in Airflow 3 UI? That might be another discussion to just leave it out.

github-actions[bot] on (2024-10-08 00:14:37 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2478930100,pull_request,closed,,Update `example_emr_eks` system test to run `eksctl` in one task,"We should not assume all tasks from the system test are run in the same container. Thus, we should run all `eksctl` commands within the same task (since `eksctl` needs to be installed before).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-21 19:43:10+00:00,[],2024-08-21 21:06:41+00:00,2024-08-21 21:06:40+00:00,https://github.com/apache/airflow/pull/41654,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2478923255,pull_request,closed,,More automation when retrieving Airlfow dependencies health status,"The command to retrieve Airflow dependencies health status aims to automate retrieval of all the information that has been so far manually derived and to put it automatically into Google Spreadsheet.

What's done so far:

* Google Spreadsheet integration
* Filtering of relevant OPSF scorecard values
* Converting OPSF scorecard details into comments for relevant cells
* Automatically deriving ""Governance"", ""Livecycle status"" and ""Unpatched vulnerabilities"" (no importance yet - that will need Github integration.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-21 19:40:08+00:00,[],2024-08-25 12:22:12+00:00,2024-08-25 12:22:10+00:00,https://github.com/apache/airflow/pull/41653,"[('area:dev-tools', '')]",[],
2478345510,pull_request,closed,,"Change confirmation text to ""Please Confirm""","Change confirmation text page to say ""Please confirm"" instead of ""Wait a minute"" and update associated UI-level tests. As a new user to airflow, the text ""Wait a minute"" implied that the user should wait for some background process, whereas the intention is for the user to review the action and confirm it. This is a trivial text change, so extensive testing was not performed, as the UI tests cover the change.

closes: #41649
",kev-the-dev,2024-08-21 15:25:43+00:00,[],2024-08-30 09:16:28+00:00,2024-08-22 14:05:34+00:00,https://github.com/apache/airflow/pull/41650,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2302371033, 'issue_id': 2478345510, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 21, 15, 25, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303041829, 'issue_id': 2478345510, 'author': 'bbovenzi', 'body': 'lgtm. @kev-the-dev once this is merged, do you mind cherry picking this for the `v-2-10-test` branch?', 'created_at': datetime.datetime(2024, 8, 21, 21, 26, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303257044, 'issue_id': 2478345510, 'author': 'kev-the-dev', 'body': 'Sure, will do!\n\n-------- Original Message --------\nOn 8/21/24 5:27 PM, Brent Bovenzi  wrote:\n\n> lgtm. ***@***.***(https://github.com/kev-the-dev) once this is merged, do you mind cherry picking this for the v-2-10-test branch?\n>\n> â€”\n> Reply to this email directly, [view it on GitHub](https://github.com/apache/airflow/pull/41650#issuecomment-2303041829), or [unsubscribe](https://github.com/notifications/unsubscribe-auth/ACIP7LH42CFVA7GFAMJ4F3TZSUA3PAVCNFSM6AAAAABM4IZPB6VHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMBTGA2DCOBSHE).\n> You are receiving this because you were mentioned.Message ID: ***@***.***>', 'created_at': datetime.datetime(2024, 8, 21, 23, 1, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304762449, 'issue_id': 2478345510, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 22, 14, 5, 37, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-21 15:25:48 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

bbovenzi on (2024-08-21 21:26:57 UTC): lgtm. @kev-the-dev once this is merged, do you mind cherry picking this for the `v-2-10-test` branch?

kev-the-dev (Issue Creator) on (2024-08-21 23:01:23 UTC): Sure, will do!

-------- Original Message --------
On 8/21/24 5:27 PM, Brent Bovenzi  wrote:

boring-cyborg[bot] on (2024-08-22 14:05:37 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2478185995,pull_request,closed,,Remove wrong import in PluginsManager for HookLineageReader.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Minor found by @ashb. Wrong import used for `hook_lineage_reader_classes` type hint.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JDarDagran,2024-08-21 14:27:34+00:00,[],2024-10-08 12:21:48+00:00,2024-10-08 12:21:48+00:00,https://github.com/apache/airflow/pull/41648,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:plugins', '')]","[{'comment_id': 2303580078, 'issue_id': 2478185995, 'author': 'uranusjr', 'body': 'Do we need to back port this to 2.10?', 'created_at': datetime.datetime(2024, 8, 22, 2, 58, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398253867, 'issue_id': 2478185995, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 8, 0, 14, 39, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-22 02:58:51 UTC): Do we need to back port this to 2.10?

github-actions[bot] on (2024-10-08 00:14:39 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2478174536,pull_request,closed,,fix(rest-api): Add order_by query param to TI listing APIs (#41283) (â€¦,"â€¦#41307)

* fix(rest-api): Add order_by query param to TI listing APIs (#41283)

This adds db-level sorting with order_by query param to the following TI listing APIs:
1. List task instances - /api/v1/dags/~/dagRuns/~/taskInstances
2. List task instances (batch) - /api/v1/dags/~/dagRuns/~/taskInstances/list

order_by defaults to sorting by start_date (ascending) for above mentioned 2 APIs. Please note that this does NOT change the default sorting param for the List mapped task instances API.

This also adds corresponding unit tests.

* Raise ValueError for unsupported order_by values

* Update docs for order_by

* Add TaskInstanceOrderBy for TI APIs

* Fix comment indentation

* Minor refines

---------

Co-authored-by: Tzu-ping Chung <uranusjr@gmail.com>
(cherry picked from commit b3d73af67ca9d8d1b52f28fba6b90d985b03b07d)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2024-08-21 14:22:29+00:00,[],2024-08-21 14:37:13+00:00,2024-08-21 14:24:24+00:00,https://github.com/apache/airflow/pull/41647,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2302182798, 'issue_id': 2478174536, 'author': 'pierrejeambrun', 'body': ""Wait, that's targeted for airflow 3.0 so there is nothing to backport I suppose. Closing. (Unless we want to consider it a bugfix cf the issue associated to it, and make that fix available for 2.11.0).\r\n\r\n@jedcunningham @bbovenzi what do you think ?"", 'created_at': datetime.datetime(2024, 8, 21, 14, 24, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302211586, 'issue_id': 2478174536, 'author': 'jedcunningham', 'body': 'ðŸ‘  Yep, not a bugfix imo.', 'created_at': datetime.datetime(2024, 8, 21, 14, 37, 11, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-08-21 14:24:22 UTC): Wait, that's targeted for airflow 3.0 so there is nothing to backport I suppose. Closing. (Unless we want to consider it a bugfix cf the issue associated to it, and make that fix available for 2.11.0).

@jedcunningham @bbovenzi what do you think ?

jedcunningham on (2024-08-21 14:37:11 UTC): ðŸ‘  Yep, not a bugfix imo.

"
2478094171,pull_request,closed,,Fix pod-template-file when kerberos enabled,"this PR solve those two problems when kerberos enabled:
- when there are webserver-config they are mount without volume
- base container should have kerberos env to find kerberos config and ccache.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-21 13:47:24+00:00,['romsharon98'],2024-08-21 15:22:31+00:00,2024-08-21 15:22:31+00:00,https://github.com/apache/airflow/pull/41645,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2477790087,pull_request,closed,,secrets backend deprecated methods removed,secrets backend deprecated methods get_conn_uri and  get_connections removed,dirrao,2024-08-21 11:27:03+00:00,[],2024-08-22 13:32:18+00:00,2024-08-22 13:32:17+00:00,https://github.com/apache/airflow/pull/41642,"[('provider:google', 'Google (including GCP) related issues'), ('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('area:secrets', ''), ('provider:hashicorp', 'Hashicorp provider related issues'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2302122060, 'issue_id': 2477790087, 'author': 'potiuk', 'body': 'static check to fix', 'created_at': datetime.datetime(2024, 8, 21, 13, 56, 29, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-21 13:56:29 UTC): static check to fix

"
2477761328,pull_request,closed,,Enable workload identity authentication for the Databricks provider,"This pull request adds support for [authenticating using Workload Identity ](https://learn.microsoft.com/nl-nl/azure/aks/workload-identity-overview?tabs=dotnet)for the Databricks provider. In the provided unit tests, this has been tested using mocking the token generation. However, the `DefaultAzureCredential().get_token(...)` part has been tested on an actual AKS cluster. This closes #41586.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #41586

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
",basvandriel,2024-08-21 11:12:22+00:00,[],2024-11-06 17:26:57+00:00,2024-11-06 17:26:27+00:00,https://github.com/apache/airflow/pull/41639,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2301795046, 'issue_id': 2477761328, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 21, 11, 12, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326020217, 'issue_id': 2477761328, 'author': 'BasPH', 'body': ""Looks okay to me, although there's quite a lot of code duplication between the `_get_aad_token_for_default_az_credential` and `_a _get_aad_token_for_default_az_credential` methods. Any way to extract common code?"", 'created_at': datetime.datetime(2024, 9, 3, 9, 17, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330817101, 'issue_id': 2477761328, 'author': 'jrderuiter', 'body': ""This duplication is essentially following the existing pattern that's already in place in the hook (if you look at the other methods, there is very often both a sync and an async implementation). \r\n\r\nTo reduce duplication we could break out the setup (lines 430-434) and the checking of the token (lines 450-456) into separate functions but I'm not sure if that would really improve readability. \r\n\r\nA more heavy-weight alternative would be to only define the async version and then define the sync version using [asyncio.run](https://docs.python.org/3/library/asyncio-runner.html#asyncio.run):\r\n\r\n```\r\ndef _get_aad_token_for_default_az_credential(self, resource: str) -> str:\r\n    return asyncio.run(self._a_get_aad_token_for_default_az_credential(resource)\r\n```\r\n\r\nHowever, this would add some overhead to the sync function call as `asyncio.run` starts an async event loop in the background:\r\n\r\n> This function runs the passed coroutine, taking care of managing the asyncio event loop, finalizing asynchronous generators, and closing the executor.\r\n\r\nIn short, to match the existing style I would prefer leaving it as is. However, I'm happy to explore these other options if needed. Also open to any suggestions from others :)"", 'created_at': datetime.datetime(2024, 9, 5, 7, 35, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330824383, 'issue_id': 2477761328, 'author': 'jrderuiter', 'body': '@basvandriel Can you give me write access to your PR fork + branch? Then I can take over this PR as discussed privately.', 'created_at': datetime.datetime(2024, 9, 5, 7, 38, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330841781, 'issue_id': 2477761328, 'author': 'basvandriel', 'body': 'Hi @jrderuiter, I was already working on this. I will finalize this today. Keep you posted!', 'created_at': datetime.datetime(2024, 9, 5, 7, 48, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330843997, 'issue_id': 2477761328, 'author': 'BasPH', 'body': '@jrderuiter In that case keeping the duplicated code is okay with me. Could you fix the static code checks?', 'created_at': datetime.datetime(2024, 9, 5, 7, 49, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331017946, 'issue_id': 2477761328, 'author': 'basvandriel', 'body': ""@jrderuiter @BasPH \r\n\r\nWhile I'm running my pre-commit checks I made some update on the duplicated code. Unfortunately, using `asyncio.run` is not an option. The code that is currently is being used uses a different SDK for the asynchronous part of the token generation.\r\n\r\nHowever, I think the readability increases by having a `Callable` argument, where a function returns an `AccessToken`. This way we only need have 2 functions calling the token retrieving functions."", 'created_at': datetime.datetime(2024, 9, 5, 9, 16, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331071602, 'issue_id': 2477761328, 'author': 'basvandriel', 'body': ""> I'm not really sure about the refactoring TBH, now it feels like we add an extra layer of complexity (the `executor` functions + `get_aad_token` functions) with minimal reduction in duplication.\r\n\r\nYou are right. If we want a similar approach, we would need 2 functions for the wrapping code and the rest for the variations of retrieving the token. I'm going to revert my commit and apply the other suggestions. Thanks!"", 'created_at': datetime.datetime(2024, 9, 5, 9, 42, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2337828740, 'issue_id': 2477761328, 'author': 'jrderuiter', 'body': 'I see some of the static checks are failing, can you have a look at this @basvandriel? Afterwards we should be fine to merge if @BasPH agrees.', 'created_at': datetime.datetime(2024, 9, 9, 11, 13, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2348641618, 'issue_id': 2477761328, 'author': 'jrderuiter', 'body': '@basvandriel Do you need any help fixing the static checks?', 'created_at': datetime.datetime(2024, 9, 13, 10, 48, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2352302103, 'issue_id': 2477761328, 'author': 'basvandriel', 'body': ""> @basvandriel Do you need any help fixing the static checks?\r\n\r\nHi @jrderuiter, I'm sorry for the late reply. I will be looking into this today."", 'created_at': datetime.datetime(2024, 9, 16, 8, 31, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2368125404, 'issue_id': 2477761328, 'author': 'BasPH', 'body': 'Hi @basvandriel almost looks okay to me. There\'s one tiny static check nit that thinks that ""aks"" is a typo: https://github.com/apache/airflow/actions/runs/10882398151/job/30464268761?pr=41639#step:8:80. Could you add ""aks"" to `docs/spelling_wordlist.txt`?\r\n\r\nThe other CICD failure (https://github.com/apache/airflow/actions/runs/10882398151/job/30464269767?pr=41639) is one I cannot explain at first sight. Will need to deepdive to understand what\'s failing there.', 'created_at': datetime.datetime(2024, 9, 23, 12, 49, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426197411, 'issue_id': 2477761328, 'author': 'BasPH', 'body': '@basvandriel @jrderuiter There\'s something fishy going on with the async test, see error in https://github.com/apache/airflow/actions/runs/11039010730/job/30937844742?pr=41639.\r\n\r\nThis fails:\r\n```python\r\n@pytest.mark.asyncio\r\n@mock.patch.dict(\r\n    os.environ,\r\n    {\r\n        ""AZURE_CLIENT_ID"": ""fake-client-id"",\r\n        ""AZURE_TENANT_ID"": ""fake-tenant-id"",\r\n        ""AZURE_FEDERATED_TOKEN_FILE"": ""/badpath"",\r\n        ""KUBERNETES_SERVICE_HOST"": ""fakeip"",\r\n    },\r\n)\r\n@mock.patch(\r\n    ""azure.identity.aio.DefaultAzureCredential.get_token"", return_value=create_aad_token_for_resource()\r\n)\r\n@mock.patch(""airflow.providers.databricks.hooks.databricks_base.aiohttp.ClientSession.get"")\r\nasync def test_one(self, requests_mock, get_token_mock: mock.MagicMock):\r\n    requests_mock.return_value.__aenter__.return_value.json.side_effect = mock.AsyncMock(\r\n        side_effect=[{""data"": 1}]\r\n    )\r\n\r\n    async with self._hook:\r\n        result = await self._hook.a_get_run_output(0)\r\n\r\n    assert result == {""data"": 1}\r\n```\r\n\r\nI found that moving the mocking of env vars inside the test works, but I\'m not sure why yet:\r\n\r\n```python\r\n@pytest.mark.asyncio\r\n@mock.patch(\r\n    ""azure.identity.aio.DefaultAzureCredential.get_token"", return_value=create_aad_token_for_resource()\r\n)\r\n@mock.patch(""airflow.providers.databricks.hooks.databricks_base.aiohttp.ClientSession.get"")\r\nasync def test_one(self, requests_mock, get_token_mock: mock.MagicMock):\r\n    with mock.patch.dict(\r\n        os.environ,\r\n        {\r\n            ""AZURE_CLIENT_ID"": ""fake-client-id"",\r\n            ""AZURE_TENANT_ID"": ""fake-tenant-id"",\r\n            ""AZURE_FEDERATED_TOKEN_FILE"": ""/badpath"",\r\n            ""KUBERNETES_SERVICE_HOST"": ""fakeip"",\r\n        },\r\n    ):\r\n        requests_mock.return_value.__aenter__.return_value.json.side_effect = mock.AsyncMock(\r\n            side_effect=[{""data"": 1}]\r\n        )\r\n\r\n        async with self._hook:\r\n            result = await self._hook.a_get_run_output(0)\r\n\r\n        assert result == {""data"": 1}\r\n```', 'created_at': datetime.datetime(2024, 10, 21, 9, 57, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460366602, 'issue_id': 2477761328, 'author': 'BasPH', 'body': 'All green now, it took a while but thanks for hanging on @basvandriel @jrderuiter!', 'created_at': datetime.datetime(2024, 11, 6, 17, 23, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460372572, 'issue_id': 2477761328, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 6, 17, 26, 55, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-21 11:12:27 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

BasPH on (2024-09-03 09:17:36 UTC): Looks okay to me, although there's quite a lot of code duplication between the `_get_aad_token_for_default_az_credential` and `_a _get_aad_token_for_default_az_credential` methods. Any way to extract common code?

jrderuiter on (2024-09-05 07:35:12 UTC): This duplication is essentially following the existing pattern that's already in place in the hook (if you look at the other methods, there is very often both a sync and an async implementation). 

To reduce duplication we could break out the setup (lines 430-434) and the checking of the token (lines 450-456) into separate functions but I'm not sure if that would really improve readability. 

A more heavy-weight alternative would be to only define the async version and then define the sync version using [asyncio.run](https://docs.python.org/3/library/asyncio-runner.html#asyncio.run):

```
def _get_aad_token_for_default_az_credential(self, resource: str) -> str:
    return asyncio.run(self._a_get_aad_token_for_default_az_credential(resource)
```

However, this would add some overhead to the sync function call as `asyncio.run` starts an async event loop in the background:


In short, to match the existing style I would prefer leaving it as is. However, I'm happy to explore these other options if needed. Also open to any suggestions from others :)

jrderuiter on (2024-09-05 07:38:55 UTC): @basvandriel Can you give me write access to your PR fork + branch? Then I can take over this PR as discussed privately.

basvandriel (Issue Creator) on (2024-09-05 07:48:30 UTC): Hi @jrderuiter, I was already working on this. I will finalize this today. Keep you posted!

BasPH on (2024-09-05 07:49:43 UTC): @jrderuiter In that case keeping the duplicated code is okay with me. Could you fix the static code checks?

basvandriel (Issue Creator) on (2024-09-05 09:16:12 UTC): @jrderuiter @BasPH 

While I'm running my pre-commit checks I made some update on the duplicated code. Unfortunately, using `asyncio.run` is not an option. The code that is currently is being used uses a different SDK for the asynchronous part of the token generation.

However, I think the readability increases by having a `Callable` argument, where a function returns an `AccessToken`. This way we only need have 2 functions calling the token retrieving functions.

basvandriel (Issue Creator) on (2024-09-05 09:42:20 UTC): You are right. If we want a similar approach, we would need 2 functions for the wrapping code and the rest for the variations of retrieving the token. I'm going to revert my commit and apply the other suggestions. Thanks!

jrderuiter on (2024-09-09 11:13:14 UTC): I see some of the static checks are failing, can you have a look at this @basvandriel? Afterwards we should be fine to merge if @BasPH agrees.

jrderuiter on (2024-09-13 10:48:15 UTC): @basvandriel Do you need any help fixing the static checks?

basvandriel (Issue Creator) on (2024-09-16 08:31:25 UTC): Hi @jrderuiter, I'm sorry for the late reply. I will be looking into this today.

BasPH on (2024-09-23 12:49:38 UTC): Hi @basvandriel almost looks okay to me. There's one tiny static check nit that thinks that ""aks"" is a typo: https://github.com/apache/airflow/actions/runs/10882398151/job/30464268761?pr=41639#step:8:80. Could you add ""aks"" to `docs/spelling_wordlist.txt`?

The other CICD failure (https://github.com/apache/airflow/actions/runs/10882398151/job/30464269767?pr=41639) is one I cannot explain at first sight. Will need to deepdive to understand what's failing there.

BasPH on (2024-10-21 09:57:18 UTC): @basvandriel @jrderuiter There's something fishy going on with the async test, see error in https://github.com/apache/airflow/actions/runs/11039010730/job/30937844742?pr=41639.

This fails:
```python
@pytest.mark.asyncio
@mock.patch.dict(
    os.environ,
    {
        ""AZURE_CLIENT_ID"": ""fake-client-id"",
        ""AZURE_TENANT_ID"": ""fake-tenant-id"",
        ""AZURE_FEDERATED_TOKEN_FILE"": ""/badpath"",
        ""KUBERNETES_SERVICE_HOST"": ""fakeip"",
    },
)
@mock.patch(
    ""azure.identity.aio.DefaultAzureCredential.get_token"", return_value=create_aad_token_for_resource()
)
@mock.patch(""airflow.providers.databricks.hooks.databricks_base.aiohttp.ClientSession.get"")
async def test_one(self, requests_mock, get_token_mock: mock.MagicMock):
    requests_mock.return_value.__aenter__.return_value.json.side_effect = mock.AsyncMock(
        side_effect=[{""data"": 1}]
    )

    async with self._hook:
        result = await self._hook.a_get_run_output(0)

    assert result == {""data"": 1}
```

I found that moving the mocking of env vars inside the test works, but I'm not sure why yet:

```python
@pytest.mark.asyncio
@mock.patch(
    ""azure.identity.aio.DefaultAzureCredential.get_token"", return_value=create_aad_token_for_resource()
)
@mock.patch(""airflow.providers.databricks.hooks.databricks_base.aiohttp.ClientSession.get"")
async def test_one(self, requests_mock, get_token_mock: mock.MagicMock):
    with mock.patch.dict(
        os.environ,
        {
            ""AZURE_CLIENT_ID"": ""fake-client-id"",
            ""AZURE_TENANT_ID"": ""fake-tenant-id"",
            ""AZURE_FEDERATED_TOKEN_FILE"": ""/badpath"",
            ""KUBERNETES_SERVICE_HOST"": ""fakeip"",
        },
    ):
        requests_mock.return_value.__aenter__.return_value.json.side_effect = mock.AsyncMock(
            side_effect=[{""data"": 1}]
        )

        async with self._hook:
            result = await self._hook.a_get_run_output(0)

        assert result == {""data"": 1}
```

BasPH on (2024-11-06 17:23:51 UTC): All green now, it took a while but thanks for hanging on @basvandriel @jrderuiter!

boring-cyborg[bot] on (2024-11-06 17:26:55 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2477723178,pull_request,closed,,Update the version of google-ads,"This PR is related to the upgrade of google-ads dependency. There is a new API version on Google Ads API and Google Ads API tends to deprecate too quickly. So we are trying to increase the dependency version to match with the latest version.

Since we mostly use the types from the underlying library it is safe to upgrade. Also the users can give specific API version to override default value and use the previous API versions.

Here is the ""Deprecation and sunset page"" of Google Ads API: https://developers.google.com/google-ads/api/docs/sunset-dates.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-08-21 10:52:37+00:00,[],2024-08-21 12:16:52+00:00,2024-08-21 12:16:52+00:00,https://github.com/apache/airflow/pull/41638,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2477688075,pull_request,closed,,Enforce deprecation message format with EOL for google provider package,"This PR introduces unification for deprecation messages formatting within Google's provider package by following:

1. Updated the pre-commit hook `check-code-deprecations` so it enforces a specific message structure containing the end of life date for the deprecated entity. According to the deprecation policy discussed [here](https://lists.apache.org/thread/d4vvr1z2bcpp1zg4rdv4p6dccrlg17g8), this deadline doesn't enforce removal of the deprecated entity from the source code, it only increases transparency and predictability for users, so they knew how much time do they have for the changes on their side.
2. Another reason for this change is preparation for the cleaning-up process as Google's provider package has collected a lot of old legacy code and we'd be happy to finally clean it up.
3. These changes work only within an `airflow/providers/google` scope. 
4. The default EOL is at least six months ahead.
5. Some classes and methods have assigned earlier deadlines because they have been deprecated for a very long time already and can be removed earlier or their API is shut down and they are not working already. ",moiseenkov,2024-08-21 10:35:16+00:00,[],2024-09-01 01:16:08+00:00,2024-09-01 01:16:08+00:00,https://github.com/apache/airflow/pull/41637,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:secrets', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2301736206, 'issue_id': 2477688075, 'author': 'potiuk', 'body': 'cc: @dstandish -> You wanted to do something like that - I think the approach proposed by the Google team (for now in google provider is really nice and we could apply it everywhere)', 'created_at': datetime.datetime(2024, 8, 21, 10, 40, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301773604, 'issue_id': 2477688075, 'author': 'ashb', 'body': ""We should use yyyy-mm-dd (or `yyyy.mm.dd`, don't mind separator) so the date is unabigious"", 'created_at': datetime.datetime(2024, 8, 21, 11, 0, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301775740, 'issue_id': 2477688075, 'author': 'ashb', 'body': 'Instead of a pre-commit check and enforcing the style of the message did you consider adding extra (required) args to the deprecated decorator:\r\n\r\n```python\r\n    @deprecated(\r\n        reason=""Please use `create_build_without_waiting_for_result`"",\r\n        removed_after=""2025-03-01"",\r\n        category=AirflowProviderDeprecationWarning,\r\n    )\r\n```\r\n\r\nThat way the message can be generated programaticaly and be consistent that way -- no need for a precommit check then?', 'created_at': datetime.datetime(2024, 8, 21, 11, 1, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301777088, 'issue_id': 2477688075, 'author': 'kacpermuda', 'body': ""Any standarization to deprecations is a good idea ðŸš€ \r\n\r\n> did you consider adding extra (required) args to the deprecated decorator\r\n\r\nSomething related and still on my todo list (for whenever i have time) is #36952 where i wanted to add a custom decorators (or other construct) for different deprecations (function, arg, arg_value etc.), where we could separate these specific parts (what is deprecated, since when, removal date, what to use instead etc.) into separate arguments so it's easier to generate docs out of it. I think it could work even better now with common.compat provider, maybe we could implement something more global for the airflow codebase ðŸ˜„"", 'created_at': datetime.datetime(2024, 8, 21, 11, 2, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301797352, 'issue_id': 2477688075, 'author': 'potiuk', 'body': '> Instead of a pre-commit check and enforcing the style of the message did you consider adding extra (required) args to the deprecated decorator\r\n\r\nPre-commit check is still needed regardless - because we want to make sure that all deprecations have it. But yes - they **could** be better structured. one problem with adding new fields - is that since providers and airflow core are separated, anything ""common"" we come up with will have to go to ""common.compat"" - especially in the light that providers should be compatible with both Airflow 2 and Airflow 3.\r\n\r\nSo generally - yes better structure at the expense of more cross-provider dependencies.', 'created_at': datetime.datetime(2024, 8, 21, 11, 13, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301824324, 'issue_id': 2477688075, 'author': 'kacpermuda', 'body': '> is that since providers and airflow core are separated, anything ""common"" we come up with will have to go to ""common.compat"" - especially in the light that providers should be compatible with both Airflow 2 and Airflow 3.\r\n\r\nIt\'s also explained in this discussion: https://github.com/apache/airflow/pull/37075#discussion_r1484366520, maybe someone will find it useful, so just leaving it here.', 'created_at': datetime.datetime(2024, 8, 21, 11, 29, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301843650, 'issue_id': 2477688075, 'author': 'potiuk', 'body': ""> It's also explained in this discussion: [#37075 (comment)](https://github.com/apache/airflow/pull/37075#discussion_r1484366520), maybe someone will find it useful, so just leaving it here.\r\n\r\nYep. We've been discussing this :)"", 'created_at': datetime.datetime(2024, 8, 21, 11, 40, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301859532, 'issue_id': 2477688075, 'author': 'moiseenkov', 'body': '> Instead of a pre-commit check and enforcing the style of the message did you consider adding extra (required) args to the deprecated decorator:\r\n> \r\n> ```python\r\n>     @deprecated(\r\n>         reason=""Please use `create_build_without_waiting_for_result`"",\r\n>         removed_after=""2025-03-01"",\r\n>         category=AirflowProviderDeprecationWarning,\r\n>     )\r\n> ```\r\n> \r\n> That way the message can be generated programaticaly and be consistent that way -- no need for a precommit check then?\r\n\r\nThis is the perfect approach, and I\'d be happy to apply it, but as it was discussed in https://github.com/apache/airflow/pull/37075#discussion_r1484366520, implementing this new decorator on the Airflow core side would make it very difficult to use in providers as they would have to bump Airflow version in their requirements.\r\n\r\nThe idea of releasing such a decorator in a separated provider package seems like a great solution! Is there any chance to implement it any time soon? I see that this work has already started #36952. @kacpermuda , @potiuk \r\n\r\nOtherwise, our team would be happy to merge the current PR (with date format fixed) now in order to bring some order to the google provider package now. And once the new provider with the structured deprecation decorator is released, we could adopt the current changes accordingly.', 'created_at': datetime.datetime(2024, 8, 21, 11, 49, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301895421, 'issue_id': 2477688075, 'author': 'potiuk', 'body': '> The idea of releasing such a decorator in a separated provider package seems like a great solution! Is there any chance to implement it any time soon? I see that this work has already started https://github.com/apache/airflow/pull/36952. @kacpermuda , @potiuk\r\n\r\nThe `common.compat` provider is already there. It\'s really a matter of:\r\n\r\n* adding the decorator there (with a note which minimum versio of compat provider has it).\r\n* bumping minor version of the compat provider\r\n* add a dependency in google provider to `common.compat>=NEW_VERSION`\r\n* any other provider that will want to use it, will have to do the same\r\n\r\nWe could also add this decorator to ""airflow"" utils with the note that it will be usable when min airflow in providers will be `>= 3.0` (but then it should be added in `airlfow-sdk` (cc: @ashb) - so we should not do it now, but possibly leave a TODO to add it there.', 'created_at': datetime.datetime(2024, 8, 21, 12, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301967318, 'issue_id': 2477688075, 'author': 'kacpermuda', 'body': ""> The common.compat provider is already there.\r\n\r\nMy main concern, though Iâ€™m not sure if itâ€™s entirely valid, is that we previously discussed having a `common.utils` provider specifically designed to make it easier to add simple functionality, without external dependencies, to all providers, so that they do not have to rely on core Airflow version. The `common.compat` provider, as I understand, is meant to serve as a â€œproxyâ€ that ensures code within providers functions without errors, with potentially fewer features, regardless of the Airflow version or other provider versions, but we should gradually remove things from there as we raise min. dependency versions f.e. for Airflow core. So it looks similar, but I'm not quite sure it's the same. Introducing this type of deprecation module into `common.compat` could make it more multi-functional, and it can be beneficial, I'm just not sure if i understand the background logic behind `common.compat`"", 'created_at': datetime.datetime(2024, 8, 21, 12, 45, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301995696, 'issue_id': 2477688075, 'author': 'potiuk', 'body': '> So it looks similar, but I\'m not quite sure it\'s the same. Introducing this type of deprecation module into common.compat could make it more multi-functional, and it can be beneficial, I\'m just not sure if i understand the background logic behind common.compat\r\n\r\nIt is the same. I imagine (see above) that the decorator WILL become part of ""airflow\'s sdk"" eventually  (whether it will be named as such or ""task.sdk"" - generally in Airflow 3  this SDK will become the ""util"" equivalent - and this `SDK` will contain everything that provider should be able to use (and in Airflow 3 providers will have no dependency on Airflow ""core"" - they will have dependency on the ""sdk"". So in this case ""compat"" is precisely compatibilty shim for the future ""common"" SDK that  airlfow providers will be able to use. \r\n\r\nThe only problem is that we do not YET have the SDK - this is being worked on as part of AIP-72 and will likely come together with restructuring of whole Airlfow repo  -  including moving providers to separate sub-projects and so on, so it makes very little sense to implement it now in airflow 3, because it will anyhow change.\r\n\r\n@ashb  - do you agree with that assessment ? \r\n\r\nAnd note for the future - since you proposed it here - we have to be aware that any kind of the common features that are supposed to be used in providers will have to eventually land in ""airflow.sdk"" that should be always future-compatible and for now they should land also in ""common.compat"" if we want to implement it in current providers, since we want the providers to work for both Airlfow 2/3.\r\n\r\nDoes it make sense what I described here? @ashb - is this your understanding as well?', 'created_at': datetime.datetime(2024, 8, 21, 12, 59, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304113523, 'issue_id': 2477688075, 'author': 'moiseenkov', 'body': '@kacpermuda , hi, \r\nConsidering the conversation here it seems that the best way for us is promoting your implementation https://github.com/apache/airflow/pull/36952 (as it is almost complete) and release it in the `common.compat` provider package.\r\nWould you have time for re-opening your PR and adding support for sunset dates?', 'created_at': datetime.datetime(2024, 8, 22, 8, 45, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304228988, 'issue_id': 2477688075, 'author': 'kacpermuda', 'body': '@moiseenkov, Iâ€™m happy to revisit #36952, but unfortunately, I canâ€™t commit to a specific timeline at the moment. If you have any available resources, feel free to pick it up in the meantime. Regardless, great job with this PR and moving us closer to more standardized deprecations! :)', 'created_at': datetime.datetime(2024, 8, 22, 9, 41, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304259027, 'issue_id': 2477688075, 'author': 'potiuk', 'body': '> @moiseenkov, Iâ€™m happy to revisit #36952, but unfortunately, I canâ€™t commit to a specific timeline at the moment. If you have any available resources, feel free to pick it up in the meantime. Regardless, great job with this PR and moving us closer to more standardized deprecations! :)\r\n\r\nI think we can also make it in stages. \r\n\r\nStage 1. Implement it in google provider (with google-specific deprecated decorator - with time and pre-commit checks.\r\nStage 2. Learn from it and move it (possibly extending this to other cases like version mentioned by @dstandish ) -> either to `common.compat` or future `airflow-sdk` if it\'s ready and depended on by providers by that time.\r\n\r\nGoogle provider is big enough to start ""some"" standardization efforts - many cases and likely > 50% of all operators and there is a history of things started there and adopted by others and made ""common"" (system tests for example)\r\n\r\nI don\'t think we should aim to have a final solution implemented from day 0 that is applicable to all providers - having google as a good start and ""experiment"" is IMHO - totally acceptable. \r\n\r\nWDYT others?', 'created_at': datetime.datetime(2024, 8, 22, 9, 56, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309869327, 'issue_id': 2477688075, 'author': 'moiseenkov', 'body': 'Hi everyone,\r\nAs we agreed, I introduced a custom `@deprecated` decorator within the Google provider package with a detailed structure and pre-commit hook that enforces a sunset date for changes within the provider. The date format is also adjusted.', 'created_at': datetime.datetime(2024, 8, 26, 10, 22, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320601810, 'issue_id': 2477688075, 'author': 'VladaZakharova', 'body': 'Hi @potiuk @eladkal @ashb !\r\nI think we can try to merge this,m WDYT? The longer we wait, the more information about those deprecations become irrelevant  haha', 'created_at': datetime.datetime(2024, 8, 30, 9, 13, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320783828, 'issue_id': 2477688075, 'author': 'potiuk', 'body': ""I am all for it @eladkal @dstandish - I think you had doubts - but I think we can do it as 'google provider specific' for now. I guess small, provider-specific solutions like that are better than inaction and waiting for responses. We can always change it later - no harm done to any other providers.\n\nWill merge if I don't hear a complain"", 'created_at': datetime.datetime(2024, 8, 30, 10, 31, 7, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-21 10:40:07 UTC): cc: @dstandish -> You wanted to do something like that - I think the approach proposed by the Google team (for now in google provider is really nice and we could apply it everywhere)

ashb on (2024-08-21 11:00:29 UTC): We should use yyyy-mm-dd (or `yyyy.mm.dd`, don't mind separator) so the date is unabigious

ashb on (2024-08-21 11:01:37 UTC): Instead of a pre-commit check and enforcing the style of the message did you consider adding extra (required) args to the deprecated decorator:

```python
    @deprecated(
        reason=""Please use `create_build_without_waiting_for_result`"",
        removed_after=""2025-03-01"",
        category=AirflowProviderDeprecationWarning,
    )
```

That way the message can be generated programaticaly and be consistent that way -- no need for a precommit check then?

kacpermuda on (2024-08-21 11:02:21 UTC): Any standarization to deprecations is a good idea ðŸš€ 


Something related and still on my todo list (for whenever i have time) is #36952 where i wanted to add a custom decorators (or other construct) for different deprecations (function, arg, arg_value etc.), where we could separate these specific parts (what is deprecated, since when, removal date, what to use instead etc.) into separate arguments so it's easier to generate docs out of it. I think it could work even better now with common.compat provider, maybe we could implement something more global for the airflow codebase ðŸ˜„

potiuk on (2024-08-21 11:13:45 UTC): Pre-commit check is still needed regardless - because we want to make sure that all deprecations have it. But yes - they **could** be better structured. one problem with adding new fields - is that since providers and airflow core are separated, anything ""common"" we come up with will have to go to ""common.compat"" - especially in the light that providers should be compatible with both Airflow 2 and Airflow 3.

So generally - yes better structure at the expense of more cross-provider dependencies.

kacpermuda on (2024-08-21 11:29:27 UTC): It's also explained in this discussion: https://github.com/apache/airflow/pull/37075#discussion_r1484366520, maybe someone will find it useful, so just leaving it here.

potiuk on (2024-08-21 11:40:16 UTC): Yep. We've been discussing this :)

moiseenkov (Issue Creator) on (2024-08-21 11:49:22 UTC): This is the perfect approach, and I'd be happy to apply it, but as it was discussed in https://github.com/apache/airflow/pull/37075#discussion_r1484366520, implementing this new decorator on the Airflow core side would make it very difficult to use in providers as they would have to bump Airflow version in their requirements.

The idea of releasing such a decorator in a separated provider package seems like a great solution! Is there any chance to implement it any time soon? I see that this work has already started #36952. @kacpermuda , @potiuk 

Otherwise, our team would be happy to merge the current PR (with date format fixed) now in order to bring some order to the google provider package now. And once the new provider with the structured deprecation decorator is released, we could adopt the current changes accordingly.

potiuk on (2024-08-21 12:09:00 UTC): The `common.compat` provider is already there. It's really a matter of:

* adding the decorator there (with a note which minimum versio of compat provider has it).
* bumping minor version of the compat provider
* add a dependency in google provider to `common.compat>=NEW_VERSION`
* any other provider that will want to use it, will have to do the same

We could also add this decorator to ""airflow"" utils with the note that it will be usable when min airflow in providers will be `>= 3.0` (but then it should be added in `airlfow-sdk` (cc: @ashb) - so we should not do it now, but possibly leave a TODO to add it there.

kacpermuda on (2024-08-21 12:45:21 UTC): My main concern, though Iâ€™m not sure if itâ€™s entirely valid, is that we previously discussed having a `common.utils` provider specifically designed to make it easier to add simple functionality, without external dependencies, to all providers, so that they do not have to rely on core Airflow version. The `common.compat` provider, as I understand, is meant to serve as a â€œproxyâ€ that ensures code within providers functions without errors, with potentially fewer features, regardless of the Airflow version or other provider versions, but we should gradually remove things from there as we raise min. dependency versions f.e. for Airflow core. So it looks similar, but I'm not quite sure it's the same. Introducing this type of deprecation module into `common.compat` could make it more multi-functional, and it can be beneficial, I'm just not sure if i understand the background logic behind `common.compat`

potiuk on (2024-08-21 12:59:04 UTC): It is the same. I imagine (see above) that the decorator WILL become part of ""airflow's sdk"" eventually  (whether it will be named as such or ""task.sdk"" - generally in Airflow 3  this SDK will become the ""util"" equivalent - and this `SDK` will contain everything that provider should be able to use (and in Airflow 3 providers will have no dependency on Airflow ""core"" - they will have dependency on the ""sdk"". So in this case ""compat"" is precisely compatibilty shim for the future ""common"" SDK that  airlfow providers will be able to use. 

The only problem is that we do not YET have the SDK - this is being worked on as part of AIP-72 and will likely come together with restructuring of whole Airlfow repo  -  including moving providers to separate sub-projects and so on, so it makes very little sense to implement it now in airflow 3, because it will anyhow change.

@ashb  - do you agree with that assessment ? 

And note for the future - since you proposed it here - we have to be aware that any kind of the common features that are supposed to be used in providers will have to eventually land in ""airflow.sdk"" that should be always future-compatible and for now they should land also in ""common.compat"" if we want to implement it in current providers, since we want the providers to work for both Airlfow 2/3.

Does it make sense what I described here? @ashb - is this your understanding as well?

moiseenkov (Issue Creator) on (2024-08-22 08:45:08 UTC): @kacpermuda , hi, 
Considering the conversation here it seems that the best way for us is promoting your implementation https://github.com/apache/airflow/pull/36952 (as it is almost complete) and release it in the `common.compat` provider package.
Would you have time for re-opening your PR and adding support for sunset dates?

kacpermuda on (2024-08-22 09:41:47 UTC): @moiseenkov, Iâ€™m happy to revisit #36952, but unfortunately, I canâ€™t commit to a specific timeline at the moment. If you have any available resources, feel free to pick it up in the meantime. Regardless, great job with this PR and moving us closer to more standardized deprecations! :)

potiuk on (2024-08-22 09:56:55 UTC): I think we can also make it in stages. 

Stage 1. Implement it in google provider (with google-specific deprecated decorator - with time and pre-commit checks.
Stage 2. Learn from it and move it (possibly extending this to other cases like version mentioned by @dstandish ) -> either to `common.compat` or future `airflow-sdk` if it's ready and depended on by providers by that time.

Google provider is big enough to start ""some"" standardization efforts - many cases and likely > 50% of all operators and there is a history of things started there and adopted by others and made ""common"" (system tests for example)

I don't think we should aim to have a final solution implemented from day 0 that is applicable to all providers - having google as a good start and ""experiment"" is IMHO - totally acceptable. 

WDYT others?

moiseenkov (Issue Creator) on (2024-08-26 10:22:06 UTC): Hi everyone,
As we agreed, I introduced a custom `@deprecated` decorator within the Google provider package with a detailed structure and pre-commit hook that enforces a sunset date for changes within the provider. The date format is also adjusted.

VladaZakharova on (2024-08-30 09:13:36 UTC): Hi @potiuk @eladkal @ashb !
I think we can try to merge this,m WDYT? The longer we wait, the more information about those deprecations become irrelevant  haha

potiuk on (2024-08-30 10:31:07 UTC): I am all for it @eladkal @dstandish - I think you had doubts - but I think we can do it as 'google provider specific' for now. I guess small, provider-specific solutions like that are better than inaction and waiting for responses. We can always change it later - no harm done to any other providers.

Will merge if I don't hear a complain

"
2477523672,pull_request,closed,,task command deprecated option ignore-depends-on-past removal,task command deprecated option ignore-depends-on-past removal,dirrao,2024-08-21 09:18:04+00:00,[],2024-08-21 19:45:32+00:00,2024-08-21 13:54:09+00:00,https://github.com/apache/airflow/pull/41635,"[('area:CLI', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2477446842,pull_request,closed,,fix: custom query should have precedence over default query in RedshiftToS3Operator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR contains a small fix, in my opinion. When unloading data to S3, one can either pass custom select_query or provide schema and table so that default query is created (SELECT * FROM {self.schema}.{self.table}). After validation to some parameters has been added in #37861, when custom query is provided together with schema and table it's being overwritten by default query. I think that custom select_query should always have precedence, when provided.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-21 08:43:17+00:00,[],2024-08-21 14:25:06+00:00,2024-08-21 14:18:06+00:00,https://github.com/apache/airflow/pull/41634,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2477445390,pull_request,closed,,filename template arg in providers file task handlers backward compitability support,"filename template arg in providers file task handlers backward compitability support
related: #41552 ",dirrao,2024-08-21 08:42:33+00:00,['dirrao'],2024-08-21 11:16:53+00:00,2024-08-21 09:37:13+00:00,https://github.com/apache/airflow/pull/41633,"[('provider:google', 'Google (including GCP) related issues'), ('provider:microsoft-azure', 'Azure-related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:logging', ''), ('provider:elasticsearch', ''), ('provider:alibaba', '')]","[{'comment_id': 2301802619, 'issue_id': 2477445390, 'author': 'eladkal', 'body': 'Thanks for this one @dirrao', 'created_at': datetime.datetime(2024, 8, 21, 11, 16, 52, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-21 11:16:52 UTC): Thanks for this one @dirrao

"
2477397821,pull_request,closed,,feat: add OpenLineage support for RedshiftToS3Operator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Similar to #41575 , I'm adding OpenLineage support for operator in reverse direction - RedshiftToS3Operator.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-21 08:19:45+00:00,[],2024-10-22 18:21:12+00:00,2024-10-22 17:13:42+00:00,https://github.com/apache/airflow/pull/41632,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2301556786, 'issue_id': 2477397821, 'author': 'kacpermuda', 'body': 'This should wait for #41634.', 'created_at': datetime.datetime(2024, 8, 21, 9, 11, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302170783, 'issue_id': 2477397821, 'author': 'vincbeck', 'body': '#41634 is merged, feel free to rebase', 'created_at': datetime.datetime(2024, 8, 21, 14, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302188068, 'issue_id': 2477397821, 'author': 'kacpermuda', 'body': ""Thanks ! I've found out that I still need to add some work here, probably parse the select_query when used to retrieve all the input tables from redshift. Will keep it in draft for now until it's ready :)"", 'created_at': datetime.datetime(2024, 8, 21, 14, 26, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409032981, 'issue_id': 2477397821, 'author': 'potiuk', 'body': 'Is that related with https://github.com/apache/airflow/pull/42963 @kacpermuda ?', 'created_at': datetime.datetime(2024, 10, 13, 16, 4, 45, tzinfo=datetime.timezone.utc)}]","kacpermuda (Issue Creator) on (2024-08-21 09:11:21 UTC): This should wait for #41634.

vincbeck on (2024-08-21 14:19:00 UTC): #41634 is merged, feel free to rebase

kacpermuda (Issue Creator) on (2024-08-21 14:26:44 UTC): Thanks ! I've found out that I still need to add some work here, probably parse the select_query when used to retrieve all the input tables from redshift. Will keep it in draft for now until it's ready :)

potiuk on (2024-10-13 16:04:45 UTC): Is that related with https://github.com/apache/airflow/pull/42963 @kacpermuda ?

"
2477306395,pull_request,closed,,fix: remove part of openlineage extraction from S3ToRedshiftOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Recently the OpenLineage support for S3ToRedshiftOperator has been added. Upon closer inspection together with @Artuz37 we found out that some edge cases do not allow us to deduce the schema and column level lineage on s3 file, and the wildcard char in S3 does not work like some may expect, so we adjusted the OpenLineage extraction to provide only reliable lineage. Tests were adjusted to reflect that changes.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-21 07:39:17+00:00,[],2024-08-21 12:19:23+00:00,2024-08-21 12:18:44+00:00,https://github.com/apache/airflow/pull/41631,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2477129776,pull_request,closed,,Mark tabular provider as removed,"Next release of tabular provider will be the last as users should migrate to apache-iceberg provider, once release the provider will be removed from source code
",eladkal,2024-08-21 05:58:31+00:00,[],2024-08-22 15:02:01+00:00,2024-08-22 15:01:58+00:00,https://github.com/apache/airflow/pull/41629,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:tabular', '')]","[{'comment_id': 2304900394, 'issue_id': 2477129776, 'author': 'eladkal', 'body': 'failures are not related to the PR. merging', 'created_at': datetime.datetime(2024, 8, 22, 15, 1, 52, tzinfo=datetime.timezone.utc)}]","eladkal (Issue Creator) on (2024-08-22 15:01:52 UTC): failures are not related to the PR. merging

"
2477030451,pull_request,closed,,Add kubernetes_resources to differentiate from Celery worker resources,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #28880
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This adds a kubernetes_resources setting to the pod template so that those using the CeleryKubernetesExecutor can specify different resource settings for the Celery workers and the Kubernetes workers. In practice the Celery workers will be few in number and probably need more CPU and memory since they will handle multiple tasks, while the Kubernetes workers will be many in number and need much less CPU and memory. However, with the current one-size-fits-both approach, Kubernetes worker pods have to wait to get scheduled because of high initial resource requests.

closes: #28880

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",SKisContent,2024-08-21 04:33:05+00:00,[],2024-10-30 00:15:34+00:00,2024-10-30 00:15:34+00:00,https://github.com/apache/airflow/pull/41628,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2301191858, 'issue_id': 2477030451, 'author': 'nevcohen', 'body': 'Now that there is a hybrid executor, we might want an entirely separate set of values \u200b\u200bfor the `pod-template`? Or it will just be duplication of values?', 'created_at': datetime.datetime(2024, 8, 21, 5, 57, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301208182, 'issue_id': 2477030451, 'author': 'SKisContent', 'body': '@nevcohen I may not be understanding your question. The proposed change allows for a separate set of resource specifications for the Kubernetes worker pod. In my case, my values.yaml file under the workers section contains this:\r\n```\r\n  resources:\r\n    limits:\r\n      memory: 8500Mi\r\n    requests:\r\n      cpu: 2000m\r\n      memory: 4500Mi\r\n\r\n  # Additional resource requests for the KubernetesExecutor pods\r\n  kubernetes_resources:\r\n   limits:\r\n    memory: 512Mi\r\n   requests:\r\n    cpu: 200m\r\n    memory: 128Mi\r\n```\r\n\r\nThus the Celery worker pods are scheduled on nodes that have at least 2 vCPUs available, and the Kubernetes worker pods get scheduled on nodes that have 0.2 vCPUs.', 'created_at': datetime.datetime(2024, 8, 21, 6, 11, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301245615, 'issue_id': 2477030451, 'author': 'nevcohen', 'body': ""I mean why not add `values.podTemplate`? Guess in the future there will be more differences that won't be the same in the workers of the celery executor and in the pods of the k8s executor.\n\nI'm just asking, maybe I'm wrong.."", 'created_at': datetime.datetime(2024, 8, 21, 6, 35, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306073357, 'issue_id': 2477030451, 'author': 'SKisContent', 'body': ""@nevcohen  Are you asking why not use the existing values.podTemplate section? Writing out a whole template seems overkill, requires the user to spend a lot more time on the task, and if in the future the default template changes, the user would have to be aware of that and update the inline template.\r\n\r\nThe solution in this PR seems like a quick fix for a problem that several people are facing (see related issue), I'm not aware of other parts of the manifest that people want to change."", 'created_at': datetime.datetime(2024, 8, 23, 2, 34, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306121185, 'issue_id': 2477030451, 'author': 'nevcohen', 'body': 'OK, I understand, agree with you for now.\n\nIn the future, when more people use CeleryKubernetesExecutor we will need something like this:\n\n```yaml\nworker:\n    ...\n    resurce:\n        ...\n    ...\npodTemplate:\n    ...\n    resurce:\n        ...\n    ...\n```\nAnd the pod-template will look like this:\n```yaml\n    ...\n      resources: {{- toYaml (or .Values.podTemplate.resources .Values.workers.resources) | nindent 8 }}\n    ...\n```\n\nAnd continue like this for most of the other values of the worker that should also be in the pod-template.', 'created_at': datetime.datetime(2024, 8, 23, 3, 41, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329185652, 'issue_id': 2477030451, 'author': 'SKisContent', 'body': 'Hi, @dstandish  @hussein-awala @jedcunningham\r\nWould it be possible to get a yea/nay on this PR so that my org can make a decision on how to go forward?', 'created_at': datetime.datetime(2024, 9, 4, 14, 13, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2427963831, 'issue_id': 2477030451, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 22, 0, 15, 19, tzinfo=datetime.timezone.utc)}]","nevcohen on (2024-08-21 05:57:39 UTC): Now that there is a hybrid executor, we might want an entirely separate set of values â€‹â€‹for the `pod-template`? Or it will just be duplication of values?

SKisContent (Issue Creator) on (2024-08-21 06:11:02 UTC): @nevcohen I may not be understanding your question. The proposed change allows for a separate set of resource specifications for the Kubernetes worker pod. In my case, my values.yaml file under the workers section contains this:
```
  resources:
    limits:
      memory: 8500Mi
    requests:
      cpu: 2000m
      memory: 4500Mi

  # Additional resource requests for the KubernetesExecutor pods
  kubernetes_resources:
   limits:
    memory: 512Mi
   requests:
    cpu: 200m
    memory: 128Mi
```

Thus the Celery worker pods are scheduled on nodes that have at least 2 vCPUs available, and the Kubernetes worker pods get scheduled on nodes that have 0.2 vCPUs.

nevcohen on (2024-08-21 06:35:55 UTC): I mean why not add `values.podTemplate`? Guess in the future there will be more differences that won't be the same in the workers of the celery executor and in the pods of the k8s executor.

I'm just asking, maybe I'm wrong..

SKisContent (Issue Creator) on (2024-08-23 02:34:23 UTC): @nevcohen  Are you asking why not use the existing values.podTemplate section? Writing out a whole template seems overkill, requires the user to spend a lot more time on the task, and if in the future the default template changes, the user would have to be aware of that and update the inline template.

The solution in this PR seems like a quick fix for a problem that several people are facing (see related issue), I'm not aware of other parts of the manifest that people want to change.

nevcohen on (2024-08-23 03:41:28 UTC): OK, I understand, agree with you for now.

In the future, when more people use CeleryKubernetesExecutor we will need something like this:

```yaml
worker:
    ...
    resurce:
        ...
    ...
podTemplate:
    ...
    resurce:
        ...
    ...
```
And the pod-template will look like this:
```yaml
    ...
      resources: {{- toYaml (or .Values.podTemplate.resources .Values.workers.resources) | nindent 8 }}
    ...
```

And continue like this for most of the other values of the worker that should also be in the pod-template.

SKisContent (Issue Creator) on (2024-09-04 14:13:46 UTC): Hi, @dstandish  @hussein-awala @jedcunningham
Would it be possible to get a yea/nay on this PR so that my org can make a decision on how to go forward?

github-actions[bot] on (2024-10-22 00:15:19 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2476543510,pull_request,closed,,Implement `on_killed` support for tasks during DAG run timeout,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

This PR addresses issue #41036 by adding support for the `on_killed` callback on tasks that are still running when a DAG run reaches its timeout.

Key changes:

1. Added a new configuration option `call_on_kill_on_dagrun_timeout` to control whether tasks should be killed when a DAG run times out (default: False).
2. Updated logic in `_schedule_dag_run` to call task `on_kill` if  `call_on_kill_on_dagrun_timeout` is enabled.

closes: https://github.com/apache/airflow/issues/41036

Testing:
- Added unit test for the new timeout handling logic
- Verified that the new configuration option works as expected
",MRLab12,2024-08-20 21:08:43+00:00,[],2024-09-04 17:22:35+00:00,2024-09-04 17:22:35+00:00,https://github.com/apache/airflow/pull/41627,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2299777200, 'issue_id': 2476543510, 'author': 'MRLab12', 'body': ""I'm having some issues with the test I added. Looking at other tests in `test_scheduler_job` I see that `session.refresh(dr)` is used before asserting the dag run state. In my test it causes a missing state error. Has anyone encountered this before?\r\n\r\nAlso. I want to check that the `on_kill` method of `BashOperator` is called, but haven't gotten the Mock to work and it is currently failing. Looking into it.\r\n\r\nI wanted to get this draft PR up to check that I did the correct changes. Hopefully I understood the issue correctly."", 'created_at': datetime.datetime(2024, 8, 20, 21, 13, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316105127, 'issue_id': 2476543510, 'author': 'MRLab12', 'body': 'Apologies for the merge mess!', 'created_at': datetime.datetime(2024, 8, 28, 19, 32, 46, tzinfo=datetime.timezone.utc)}]","MRLab12 (Issue Creator) on (2024-08-20 21:13:34 UTC): I'm having some issues with the test I added. Looking at other tests in `test_scheduler_job` I see that `session.refresh(dr)` is used before asserting the dag run state. In my test it causes a missing state error. Has anyone encountered this before?

Also. I want to check that the `on_kill` method of `BashOperator` is called, but haven't gotten the Mock to work and it is currently failing. Looking into it.

I wanted to get this draft PR up to check that I did the correct changes. Hopefully I understood the issue correctly.

MRLab12 (Issue Creator) on (2024-08-28 19:32:46 UTC): Apologies for the merge mess!

"
2476486158,pull_request,closed,,Make latest botocore tests green,"The latest botocore tests are conflicting with a few requirements and until apache-beam upcoming version is released we need to do some manual exclusions. Those exclusions should make latest botocore test green again.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-20 20:26:56+00:00,[],2024-08-30 09:20:45+00:00,2024-08-21 09:17:55+00:00,https://github.com/apache/airflow/pull/41626,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('upgrade to newer dependencies', 'If set, upgrade to newer dependencies is forced')]","[{'comment_id': 2301454608, 'issue_id': 2476486158, 'author': 'potiuk', 'body': '> is this for opensearch? or opensearch is part of apache-beam\r\n\r\nThis is because currently the tests for ""latest"" botocore have conflicting dependencies and we are workarounding it - by temporarily disabling dependencies that have those conflicts.\r\n\r\nIn this case the problem is `apache.beam` that (currently released version)  has reqeusts < 3 but != 2.32.* (due to some problem with their test harness - apparently requests did not work with the docker test harness they used). The problem with that is that growing number of our dependencies (for example opensearch) has `requests >= 2.32` and when we attempt to upgrade botocore - through a ripple-effect of dependencies pulling other dependencies, this leads to unsolvable conflicts (because latest botocore will not work with earlier versions of those dependencies that can work with requests 2.31.*:\r\n\r\n```  \r\n  Uninstalled 3 packages in 320ms\r\n   - aiobotocore==2.13.2\r\n   - s3fs==2024.6.1\r\n   - yandexcloud==0.313.0\r\n  + uv pip install --python /usr/local/bin/python --upgrade boto3 botocore \'oss2>=2.14.0\' \'cryptography<43.0.0\' \'requests!=2.32.*,<3.0.0,>=2.24.0\'\r\n  Resolved 19 packages in 32.61s\r\n  Prepared 3 packages in 325ms\r\n  Uninstalled 3 packages in 913ms\r\n  Installed 3 packages in 140ms\r\n   - boto3==1.34.131\r\n   + boto3==1.35.2\r\n   - botocore==1.34.131\r\n   + botocore==1.35.2\r\n   - requests==2.32.3\r\n   + requests==2.31.0\r\n  + set +x\r\n\r\n  opensearch-py 2.7.0 has requirement requests<3.0.0,>=2.32.0, but you have requests 2.31.0.\r\n```\r\n\r\n\r\nThe apache-beam problem has been solved and merged as I opened https://github.com/apache/beam/issues/32080 - 2 weeks ago so that they remove the limitation - and they merged it literally yesterday - https://github.com/apache/beam/pull/32236 \r\n\r\nSo by removing opensearch from latest botocore tests, we termporarily make it works now - but once apache-beam 2.59.0 is released, we should be able to bring opensearch back to those tests.', 'created_at': datetime.datetime(2024, 8, 21, 8, 23, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301457788, 'issue_id': 2476486158, 'author': 'Lee-W', 'body': 'got it! It makes sense now. Thanks for the details!', 'created_at': datetime.datetime(2024, 8, 21, 8, 25, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301460936, 'issue_id': 2476486158, 'author': 'potiuk', 'body': '>  got it! It makes sense now. Thanks for the details!\r\n\r\nYes. Dependencies are hard. Airlfow dependencies doubly so.', 'created_at': datetime.datetime(2024, 8, 21, 8, 26, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301466130, 'issue_id': 2476486158, 'author': 'potiuk', 'body': 'uv.lock also commited - by mistake now (removed it)', 'created_at': datetime.datetime(2024, 8, 21, 8, 29, 28, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-21 08:23:40 UTC): This is because currently the tests for ""latest"" botocore have conflicting dependencies and we are workarounding it - by temporarily disabling dependencies that have those conflicts.

In this case the problem is `apache.beam` that (currently released version)  has reqeusts < 3 but != 2.32.* (due to some problem with their test harness - apparently requests did not work with the docker test harness they used). The problem with that is that growing number of our dependencies (for example opensearch) has `requests >= 2.32` and when we attempt to upgrade botocore - through a ripple-effect of dependencies pulling other dependencies, this leads to unsolvable conflicts (because latest botocore will not work with earlier versions of those dependencies that can work with requests 2.31.*:

```  
  Uninstalled 3 packages in 320ms
   - aiobotocore==2.13.2
   - s3fs==2024.6.1
   - yandexcloud==0.313.0
  + uv pip install --python /usr/local/bin/python --upgrade boto3 botocore 'oss2>=2.14.0' 'cryptography<43.0.0' 'requests!=2.32.*,<3.0.0,>=2.24.0'
  Resolved 19 packages in 32.61s
  Prepared 3 packages in 325ms
  Uninstalled 3 packages in 913ms
  Installed 3 packages in 140ms
   - boto3==1.34.131
   + boto3==1.35.2
   - botocore==1.34.131
   + botocore==1.35.2
   - requests==2.32.3
   + requests==2.31.0
  + set +x

  opensearch-py 2.7.0 has requirement requests<3.0.0,>=2.32.0, but you have requests 2.31.0.
```


The apache-beam problem has been solved and merged as I opened https://github.com/apache/beam/issues/32080 - 2 weeks ago so that they remove the limitation - and they merged it literally yesterday - https://github.com/apache/beam/pull/32236 

So by removing opensearch from latest botocore tests, we termporarily make it works now - but once apache-beam 2.59.0 is released, we should be able to bring opensearch back to those tests.

Lee-W on (2024-08-21 08:25:19 UTC): got it! It makes sense now. Thanks for the details!

potiuk (Issue Creator) on (2024-08-21 08:26:54 UTC): Yes. Dependencies are hard. Airlfow dependencies doubly so.

potiuk (Issue Creator) on (2024-08-21 08:29:28 UTC): uv.lock also commited - by mistake now (removed it)

"
2476451164,pull_request,closed,,Handle executor events in `dag.test()`,"If the task did not reach the task runner environment and fails, no update is made in the DB. The executor is sending ""events"" that are handled by the scheduler. In `dag.test()`, there is no scheduler, therefore we need to handle them there as well.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-20 20:04:27+00:00,[],2024-08-22 13:33:30+00:00,2024-08-22 13:33:28+00:00,https://github.com/apache/airflow/pull/41625,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2302256161, 'issue_id': 2476451164, 'author': 'vincbeck', 'body': ""> Any way to add some tests so that this doesn't regress again? Does the `dag.test` code itself even have unit tests?\r\n\r\nIt does but we are not testing `dag.test` when `use_executor` is `True`. The reason why it is not tested is it is quite hard to run an executor in pytest. Even `LocalExecutor` fails. And mocking the executor would result in not testing the feature. I think this should be belong to system test where an actual executor is run."", 'created_at': datetime.datetime(2024, 8, 21, 14, 54, 11, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-08-21 14:54:11 UTC): It does but we are not testing `dag.test` when `use_executor` is `True`. The reason why it is not tested is it is quite hard to run an executor in pytest. Even `LocalExecutor` fails. And mocking the executor would result in not testing the feature. I think this should be belong to system test where an actual executor is run.

"
2476339299,pull_request,closed,,Enable running Pull Requests against v2-10-stable branch,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-20 19:02:36+00:00,[],2024-08-20 21:51:38+00:00,2024-08-20 21:51:37+00:00,https://github.com/apache/airflow/pull/41624,"[('area:dev-tools', '')]","[{'comment_id': 2299562796, 'issue_id': 2476339299, 'author': 'potiuk', 'body': 'cc: @eladkal @utkarsharma2 -> you will also have to merge and backport-that one to #41610 in order to make the CI PR workflow to run', 'created_at': datetime.datetime(2024, 8, 20, 19, 3, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299565442, 'issue_id': 2476339299, 'author': 'potiuk', 'body': 'We have not been doing it before because we were directly cherry-picking and only ""push"" events happened for v2-10-test, not PRs - by enabling branch protection, and only allowing PRs to v2* branches, we need to enable this as well', 'created_at': datetime.datetime(2024, 8, 20, 19, 5, 25, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-20 19:03:58 UTC): cc: @eladkal @utkarsharma2 -> you will also have to merge and backport-that one to #41610 in order to make the CI PR workflow to run

potiuk (Issue Creator) on (2024-08-20 19:05:25 UTC): We have not been doing it before because we were directly cherry-picking and only ""push"" events happened for v2-10-test, not PRs - by enabling branch protection, and only allowing PRs to v2* branches, we need to enable this as well

"
2476304184,pull_request,closed,,Apply GitHub workflow changes to stable branch,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-20 18:45:20+00:00,[],2024-08-20 19:22:29+00:00,2024-08-20 19:22:27+00:00,https://github.com/apache/airflow/pull/41623,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2299547105, 'issue_id': 2476304184, 'author': 'potiuk', 'body': '@eladkal @utkarsharma2 -> please merge it regardless if it fails (it should fail with PROD images too) and then you will be able to  rerun the failing ""sync PR: #41610', 'created_at': datetime.datetime(2024, 8, 20, 18, 56, 5, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-20 18:56:05 UTC): @eladkal @utkarsharma2 -> please merge it regardless if it fails (it should fail with PROD images too) and then you will be able to  rerun the failing ""sync PR: #41610

"
2476074581,pull_request,closed,,"remove the removed --use-migration-files argument of ""airflow db reset"" command in run_generate_migration.sh","## Why
The ""--use-migration-files"" is no longer a valid argument of ""airflow db reset""

## What
remove the argument in ""scripts/in_container/run_generate_migration.sh"" which breaks `breeze generate-migration-file`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-20 16:31:17+00:00,[],2024-08-21 03:07:33+00:00,2024-08-21 03:07:31+00:00,https://github.com/apache/airflow/pull/41621,"[('area:dev-tools', '')]",[],
2476016997,pull_request,closed,,[redis]adding additional values for existing persistence claim,"For redis persistence  section, adding a value `existingClaim`, similar to dags and logs, if existingClaim value exisits, using existing claim name instead of using volumeClaimTemplates. 

* How to test:
update existingClaim value:
```
    # the name of an existing PVC to use
    existingClaim: pvc-airflow-test-redis
```
run `helm template --name-template=airflow . > airflow.yaml`

```
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: airflow-redis
.
.
.
          volumeMounts:
            - name: redis-db
              mountPath: /data
.
.
.
      volumes:
        - name: redis-db
          persistentVolumeClaim:
            claimName: pvc-airflow-test-redis
```

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kongdewen,2024-08-20 16:04:05+00:00,[],2024-08-27 09:18:56+00:00,2024-08-27 09:18:53+00:00,https://github.com/apache/airflow/pull/41619,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2299214428, 'issue_id': 2476016997, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 20, 16, 4, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302748978, 'issue_id': 2476016997, 'author': 'romsharon98', 'body': 'can you add tests for this?', 'created_at': datetime.datetime(2024, 8, 21, 18, 53, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311996880, 'issue_id': 2476016997, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 27, 9, 18, 55, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-20 16:04:09 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

romsharon98 on (2024-08-21 18:53:17 UTC): can you add tests for this?

boring-cyborg[bot] on (2024-08-27 09:18:55 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2476008398,pull_request,closed,,Add fixes by breeze/precommit-lint static checks (#41604),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #41604.

This adds the fixes by breeze/precommit-lint static checks.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",omkar-foss,2024-08-20 16:00:15+00:00,[],2024-08-21 05:02:19+00:00,2024-08-20 19:40:03+00:00,https://github.com/apache/airflow/pull/41618,"[('area:providers', ''), ('provider:fab', '')]",[],
2475924602,pull_request,closed,,chore(docs): add note about Helm Chart,"The Helm Chart does not support both git-sync and persistence to be configured at the same time.

Fixes #27476

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",aairey,2024-08-20 15:20:59+00:00,[],2024-12-01 00:19:52+00:00,2024-12-01 00:19:52+00:00,https://github.com/apache/airflow/pull/41617,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:helm-chart', 'Airflow Helm Chart'), ('kind:documentation', '')]","[{'comment_id': 2299123687, 'issue_id': 2475924602, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 20, 15, 21, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398253938, 'issue_id': 2475924602, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 8, 0, 14, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399861619, 'issue_id': 2475924602, 'author': 'aairey', 'body': '> Keeping the note aligned with the below reasoning\n\nSorry it is a bit unclear to me what is expected now.\nCould you suggest your changes inline?', 'created_at': datetime.datetime(2024, 10, 8, 13, 32, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495713899, 'issue_id': 2475924602, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 24, 0, 17, 32, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-20 15:21:03 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2024-10-08 00:14:41 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

aairey (Issue Creator) on (2024-10-08 13:32:18 UTC): Sorry it is a bit unclear to me what is expected now.
Could you suggest your changes inline?

github-actions[bot] on (2024-11-24 00:17:32 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2475783011,pull_request,closed,,Make kerberos an optional and devel dependency for impala and fab,"The improved compatibility tests detected that FAB provider tests have implicit dependency on kerberos - similar as impala. This change make kerberos an optional dependency of FAB as well as it as development dependency for both impala and FAB.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-20 14:18:07+00:00,[],2024-08-20 17:02:25+00:00,2024-08-20 17:02:24+00:00,https://github.com/apache/airflow/pull/41616,"[('area:providers', ''), ('provider:apache-impala', ''), ('provider:fab', '')]","[{'comment_id': 2298981242, 'issue_id': 2475783011, 'author': 'potiuk', 'body': 'Should fix failing compatibility check for Airflow 2.9 (similar case as missing methodtools)', 'created_at': datetime.datetime(2024, 8, 20, 14, 18, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298982867, 'issue_id': 2475783011, 'author': 'potiuk', 'body': 'https://github.com/apache/airflow/actions/runs/10472575491/job/29002919190#step:11:4167 is failing compatibility test in main.', 'created_at': datetime.datetime(2024, 8, 20, 14, 19, 42, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-20 14:18:59 UTC): Should fix failing compatibility check for Airflow 2.9 (similar case as missing methodtools)

potiuk (Issue Creator) on (2024-08-20 14:19:42 UTC): https://github.com/apache/airflow/actions/runs/10472575491/job/29002919190#step:11:4167 is failing compatibility test in main.

"
2475697242,pull_request,closed,,Set better logging level for path wrapper,This PR improves the log level of the `ObjectStoragePath` wrapper (`TrackingFileWrapper`). Currently it logs regular operations as errors which does not make sense to us. We can also remove the entire log line if desired.,JSCU-CNI,2024-08-20 13:44:46+00:00,[],2024-08-30 09:15:52+00:00,2024-08-22 09:19:39+00:00,https://github.com/apache/airflow/pull/41615,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2304073928, 'issue_id': 2475697242, 'author': 'potiuk', 'body': 'Should we backport it to 2.10.1 ?', 'created_at': datetime.datetime(2024, 8, 22, 8, 24, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304183872, 'issue_id': 2475697242, 'author': 'mobuchowski', 'body': '@potiuk yes ðŸ˜¢', 'created_at': datetime.datetime(2024, 8, 22, 9, 19, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304235861, 'issue_id': 2475697242, 'author': 'potiuk', 'body': 'So you will backport it @mobuchowski ?', 'created_at': datetime.datetime(2024, 8, 22, 9, 45, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-22 08:24:50 UTC): Should we backport it to 2.10.1 ?

mobuchowski on (2024-08-22 09:19:36 UTC): @potiuk yes ðŸ˜¢

potiuk on (2024-08-22 09:45:13 UTC): So you will backport it @mobuchowski ?

"
2475603861,pull_request,closed,,Cherry pick watchtower limiting,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-20 13:06:20+00:00,[],2024-08-30 11:43:59+00:00,2024-08-20 13:07:46+00:00,https://github.com/apache/airflow/pull/41614,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2298818360, 'issue_id': 2475603861, 'author': 'potiuk', 'body': 'Backport to v2-10-test', 'created_at': datetime.datetime(2024, 8, 20, 13, 7, 6, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-20 13:07:06 UTC): Backport to v2-10-test

"
2475576025,pull_request,closed,,Limit watchtower as depenendcy as 3.3.0 breaks main.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-20 12:53:19+00:00,[],2024-08-30 09:15:28+00:00,2024-08-20 13:05:01+00:00,https://github.com/apache/airflow/pull/41612,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2475512165,pull_request,closed,,Feature/upstream by state,"related: https://github.com/apache/airflow/pull/41506
change the target branch from airflow3 to 2.10 according to [this comment ](https://github.com/apache/airflow/pull/41506#issuecomment-2295402432) on the related PR.

this PR add an ability to get all upstream tasks by state.
the current state is that user can get only upstream tasks without any state.

this can solve issues like this https://stackoverflow.com/questions/73740427/airflow-how-to-get-list-of-upstream-failed-tasks



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-20 12:22:37+00:00,[],2024-08-26 15:58:03+00:00,2024-08-26 15:58:03+00:00,https://github.com/apache/airflow/pull/41611,[],"[{'comment_id': 2305965821, 'issue_id': 2475512165, 'author': 'jedcunningham', 'body': ""I'm not sure we should be adding this to 2.x at this point - this is not a bugfix or something appropriate for a bridge release imo. Even if we did, this should go to `v2-10-test`, not stable."", 'created_at': datetime.datetime(2024, 8, 23, 0, 33, 14, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2024-08-23 00:33:14 UTC): I'm not sure we should be adding this to 2.x at this point - this is not a bugfix or something appropriate for a bridge release imo. Even if we did, this should go to `v2-10-test`, not stable.

"
2475488105,pull_request,closed,,Sync v2-10-stable with v2-10-test to release python client v2.10.0,,utkarsharma2,2024-08-20 12:11:13+00:00,[],2024-08-22 09:00:12+00:00,2024-08-22 09:00:09+00:00,https://github.com/apache/airflow/pull/41610,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:helm-chart', 'Airflow Helm Chart'), ('area:production-image', 'Production image improvements and fixes'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2298807998, 'issue_id': 2475488105, 'author': 'pierrejeambrun', 'body': ""I am not sure here, can't we use the `2.10.0` tag  that was just released to base our python client release off of it ?\r\n\r\nSo the client and the airflow API are in sync ?\r\n\r\nHere this sync PR potentially add extra commits that fix / update the API while those are not part of the 2.10.0 airflow release.\r\n\r\nMaybe I misunderstood something."", 'created_at': datetime.datetime(2024, 8, 20, 13, 2, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298839633, 'issue_id': 2475488105, 'author': 'potiuk', 'body': '@pierrejeambrun  Agree, ti\'s a bit broken now - It\'s a consequence of the change we agreed that we back-port them to v2-10-test -as we merge PRs to main - previously we only marked them as ""to-be-cherry-picked"" - but now the situation changed. Previously only **some** changes would have to be cherry-picked for the client release (changing version / changelog of the client mainly https://github.com/astronomer/airflow/commit/3ea764f802fddf16f4a12f39212f067e1abcbbf5  - and potentially some dependencies https://github.com/astronomer/airflow/commit/e76dba61b92eadcee9e3193640ab8db6a9466528 also the watchtower limit few moment ago that broke stable) and it happened before any other cherry-picks were done and merged to stable. \r\n\r\nMaybe the idea of backporting needs soem refinement in the process - like release python client as part of releasing Airflow.', 'created_at': datetime.datetime(2024, 8, 20, 13, 17, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298849147, 'issue_id': 2475488105, 'author': 'utkarsharma2', 'body': ""> I am not sure here, can't we just use the `2.10.0` tag that was just released to base our python client release off of it ?\r\n> \r\n> So the client and the airflow API are in sync ?\r\n> \r\n> Here this sync PR potentially add extra commits that fix / update the API while those are not part of the 2.10.0 airflow release.\r\n> \r\n> Maybe I misunderstood something.\r\n\r\nWe can do that as well. I'm trying to follow the [release process](https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PYTHON_CLIENT.md) as much as possible. Also, I don't see it as much of an issue here, since there aren't any changes that could affect the Python client release, other than what we intend(clients/python/CHANGELOG.md  and clients/python/version.txt) to add. I might have missed some, please point out any commits you are concerned about?"", 'created_at': datetime.datetime(2024, 8, 20, 13, 21, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298879800, 'issue_id': 2475488105, 'author': 'pierrejeambrun', 'body': ""> might have missed some, please point out any commits you are concerned about?\r\n\r\nI didn't take a look in the details at the commits that are being sync to stable. That was just a general observation that this way of doing it 'could' potentially cause trouble.\r\n\r\nI'm wondering how we would actually handle the case where one of those backport commit do modify the openapi spec (for instance fix a parameter type) between the time when airflow core is released, and we have not yet released the related client version."", 'created_at': datetime.datetime(2024, 8, 20, 13, 35, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298940374, 'issue_id': 2475488105, 'author': 'potiuk', 'body': ""> I'm wondering how we would actually handle the case where one of those backport commit do modify the openapi spec (for instance fix a parameter type) between the time when airflow core is released, and we have not yet released the related client version.\r\n\r\nI tihnk the issue can be solved by timing of releases. If we generate and client changelog / make decision whether we release API and decision on the version of the client at the sama time when we release Airflow, this would be a non-issue. \r\nIn this case several days passed since and circumstances and environment changed (new dependencies released that required some actions, PRs were merged to v2-10-test)\r\n\r\n@ephraimbuddy @utkarsharma2 @jedcunningham -> WDYT."", 'created_at': datetime.datetime(2024, 8, 20, 14, 1, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299021591, 'issue_id': 2475488105, 'author': 'utkarsharma2', 'body': ""> > I'm wondering how we would actually handle the case where one of those backport commit do modify the openapi spec (for instance fix a parameter type) between the time when airflow core is released, and we have not yet released the related client version.\r\n> \r\n> I tihnk the issue can be solved by timing of releases. If we generate and client changelog / make decision whether we release API and decision on the version of the client at the sama time when we release Airflow, this would be a non-issue. In this case several days passed since and circumstances and environment changed (new dependencies released that required some actions, PRs were merged to v2-10-test)\r\n> \r\n> @ephraimbuddy @utkarsharma2 @jedcunningham -> WDYT.\r\n\r\nYes, we can decide and move forward with the client release quickly. However, there's a caveat based on my limited experience with Airflow releases: they can become quite hectic. Handling two releases back-to-back could be taxing for the release manager. I would prefer if we could decouple the release processes.\r\n\r\nThe way I see it, we need to update the changelog and make the necessary version changes in both the 2-10-stable and 2-10-test branches. This can be done by submitting separate PRs for each branch, allowing us to continue the release from the 2-10-stable without any unexpected changes and not being concerned about what's added in the 2-10-test. \r\n\r\nMy understanding might have some gaps, just thinking out loud here. :)"", 'created_at': datetime.datetime(2024, 8, 20, 14, 36, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299038691, 'issue_id': 2475488105, 'author': 'pierrejeambrun', 'body': ""I can confirm that sometimes the release process can become a bit painful and having to chain that with other release process can represent a significant effort. That would be more confortable for the release manager if we can figure something out that is a bit more flexible on the schedule as suggested by @utkarsharma2.\r\n\r\n> The way I see it, we need to update the changelog and make the necessary version changes in both the 2-10-stable and 2-10-test branches. This can be done by submitting separate PRs for each branch, allowing us to continue the release from the 2-10-stable without any unexpected changes and not being concerned about what's added in the 2-10-test.\r\n\r\nI like that, and it makes sense that the client is based off a released 'stable' branch."", 'created_at': datetime.datetime(2024, 8, 20, 14, 44, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299338550, 'issue_id': 2475488105, 'author': 'potiuk', 'body': ""> This can be done by submitting separate PRs for each branch, allowing us to continue the release from the 2-10-stable without any unexpected changes and not being concerned about what's added in the 2-10-test.\r\n\r\nYes. That would be another good approach."", 'created_at': datetime.datetime(2024, 8, 20, 17, 4, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299550529, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'BTW, This one will not work still - we also need to enable PRs for v2-10-stable which are not enabled.', 'created_at': datetime.datetime(2024, 8, 20, 18, 57, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301423162, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Hey @utkarsharma2 -> I believe we are getting very close :). There is this one flaky test with mapping and I **think** it shoudl be fixed by cherry-picking https://github.com/apache/airflow/pull/41414 - this is the only ""test"" change for database isolation mode that did not make it to v2-10-test branch as far as I can see (cc: @jscheffl - can you maybe take a look as well to double check?)', 'created_at': datetime.datetime(2024, 8, 21, 8, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301426538, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Correction:\r\n\r\nhttps://github.com/apache/airflow/pull/41344 and https://github.com/apache/airflow/pull/41414', 'created_at': datetime.datetime(2024, 8, 21, 8, 11, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301430074, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Also this one: https://github.com/apache/airflow/pull/41626  should fix ""latest boto"" tests when merged.', 'created_at': datetime.datetime(2024, 8, 21, 8, 12, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301484443, 'issue_id': 2475488105, 'author': 'jscheffl', 'body': '> Hey @utkarsharma2 -> I believe we are getting very close :). There is this one flaky test with mapping and I **think** it shoudl be fixed by cherry-picking #41414 - this is the only ""test"" change for database isolation mode that did not make it to v2-10-test branch as far as I can see (cc: @jscheffl - can you maybe take a look as well to double check?)\r\n\r\nFor the PRs I mentioned I am not sure - they are okay to get to v2-10-test (shall I make PRs for this, lost track about the vast amount of patches we made for isolation mode) but in the last build I only see two problems left caused by boto?', 'created_at': datetime.datetime(2024, 8, 21, 8, 37, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301529131, 'issue_id': 2475488105, 'author': 'utkarsharma2', 'body': '> Hey @utkarsharma2 -> I believe we are getting very close :). There is this one flaky test with mapping and I **think** it shoudl be fixed by cherry-picking #41414 - this is the only ""test"" change for database isolation mode that did not make it to v2-10-test branch as far as I can see (cc: @jscheffl - can you maybe take a look as well to double check?)\r\n\r\nYes, we are! Thanks for looking into this @potiuk :)\r\n\r\n\r\n> Correction:\r\n> https://github.com/apache/airflow/pull/41344 and https://github.com/apache/airflow/pull/41414\r\n\r\nhttps://github.com/apache/airflow/pull/41344 is already part of the branch. I have cherry-picked https://github.com/apache/airflow/pull/41414\r\n\r\nI\'m waiting for us to merge https://github.com/apache/airflow/pull/41626 to the main so I can cherry-pick this as well.', 'created_at': datetime.datetime(2024, 8, 21, 8, 58, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301571189, 'issue_id': 2475488105, 'author': 'potiuk', 'body': ""> I'm waiting for us to merge https://github.com/apache/airflow/pull/41626 to the main so I can cherry-pick this as well.\r\n\r\nMerged"", 'created_at': datetime.datetime(2024, 8, 21, 9, 18, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301650750, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Hmm. We still have the flaky D tests/models/test_taskinstance.py::TestTaskInstance::test_check_task_dependencies_for_mapped - and I do recall having it (and fixing) in main...  Let me try to dig deeper and find what we are missing here.', 'created_at': datetime.datetime(2024, 8, 21, 9, 58, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301651618, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'cc: @jscheffl -> maybe that one rings a bell for you ?', 'created_at': datetime.datetime(2024, 8, 21, 9, 59, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301672365, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Anh I know. @utkarsharma2 - this should be fixed by cherry-picking #41389', 'created_at': datetime.datetime(2024, 8, 21, 10, 9, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301677351, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'And #41471 should also make ""Database Isolation tests"" stable.', 'created_at': datetime.datetime(2024, 8, 21, 10, 12, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301679219, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Yeah I think the last two @utkarsharma2 #41389 and #41471 should bring the stability back (those are test-only changes).', 'created_at': datetime.datetime(2024, 8, 21, 10, 13, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301682728, 'issue_id': 2475488105, 'author': 'utkarsharma2', 'body': '> Yeah I think the last two @utkarsharma2 #41389 and #41471 should bring the stability back (those are test-only changes).\r\n\r\nThanks @potiuk I have cherry-picked them.', 'created_at': datetime.datetime(2024, 8, 21, 10, 14, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301816496, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'OK. I think the remaining ones are the ""regular"" flakes - that we have no good solution for now - so just re-running them after tests complete should help', 'created_at': datetime.datetime(2024, 8, 21, 11, 24, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301878250, 'issue_id': 2475488105, 'author': 'jscheffl', 'body': '> OK. I think the remaining ones are the ""regular"" flakes - that we have no good solution for now - so just re-running them after tests complete should help\r\n\r\nI double-checked the list of PRs we had for making DB isolation tests working, don\'t know if implicitly contained but https://github.com/apache/airflow/pull/41450 was also merged on main and seems to be missing in v2-10-test.', 'created_at': datetime.datetime(2024, 8, 21, 11, 59, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303037028, 'issue_id': 2475488105, 'author': 'potiuk', 'body': 'Green ! :)', 'created_at': datetime.datetime(2024, 8, 21, 21, 23, 23, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-08-20 13:02:02 UTC): I am not sure here, can't we use the `2.10.0` tag  that was just released to base our python client release off of it ?

So the client and the airflow API are in sync ?

Here this sync PR potentially add extra commits that fix / update the API while those are not part of the 2.10.0 airflow release.

Maybe I misunderstood something.

potiuk on (2024-08-20 13:17:02 UTC): @pierrejeambrun  Agree, ti's a bit broken now - It's a consequence of the change we agreed that we back-port them to v2-10-test -as we merge PRs to main - previously we only marked them as ""to-be-cherry-picked"" - but now the situation changed. Previously only **some** changes would have to be cherry-picked for the client release (changing version / changelog of the client mainly https://github.com/astronomer/airflow/commit/3ea764f802fddf16f4a12f39212f067e1abcbbf5  - and potentially some dependencies https://github.com/astronomer/airflow/commit/e76dba61b92eadcee9e3193640ab8db6a9466528 also the watchtower limit few moment ago that broke stable) and it happened before any other cherry-picks were done and merged to stable. 

Maybe the idea of backporting needs soem refinement in the process - like release python client as part of releasing Airflow.

utkarsharma2 (Issue Creator) on (2024-08-20 13:21:24 UTC): We can do that as well. I'm trying to follow the [release process](https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PYTHON_CLIENT.md) as much as possible. Also, I don't see it as much of an issue here, since there aren't any changes that could affect the Python client release, other than what we intend(clients/python/CHANGELOG.md  and clients/python/version.txt) to add. I might have missed some, please point out any commits you are concerned about?

pierrejeambrun on (2024-08-20 13:35:08 UTC): I didn't take a look in the details at the commits that are being sync to stable. That was just a general observation that this way of doing it 'could' potentially cause trouble.

I'm wondering how we would actually handle the case where one of those backport commit do modify the openapi spec (for instance fix a parameter type) between the time when airflow core is released, and we have not yet released the related client version.

potiuk on (2024-08-20 14:01:35 UTC): I tihnk the issue can be solved by timing of releases. If we generate and client changelog / make decision whether we release API and decision on the version of the client at the sama time when we release Airflow, this would be a non-issue. 
In this case several days passed since and circumstances and environment changed (new dependencies released that required some actions, PRs were merged to v2-10-test)

@ephraimbuddy @utkarsharma2 @jedcunningham -> WDYT.

utkarsharma2 (Issue Creator) on (2024-08-20 14:36:25 UTC): Yes, we can decide and move forward with the client release quickly. However, there's a caveat based on my limited experience with Airflow releases: they can become quite hectic. Handling two releases back-to-back could be taxing for the release manager. I would prefer if we could decouple the release processes.

The way I see it, we need to update the changelog and make the necessary version changes in both the 2-10-stable and 2-10-test branches. This can be done by submitting separate PRs for each branch, allowing us to continue the release from the 2-10-stable without any unexpected changes and not being concerned about what's added in the 2-10-test. 

My understanding might have some gaps, just thinking out loud here. :)

pierrejeambrun on (2024-08-20 14:44:13 UTC): I can confirm that sometimes the release process can become a bit painful and having to chain that with other release process can represent a significant effort. That would be more confortable for the release manager if we can figure something out that is a bit more flexible on the schedule as suggested by @utkarsharma2.


I like that, and it makes sense that the client is based off a released 'stable' branch.

potiuk on (2024-08-20 17:04:53 UTC): Yes. That would be another good approach.

potiuk on (2024-08-20 18:57:34 UTC): BTW, This one will not work still - we also need to enable PRs for v2-10-stable which are not enabled.

potiuk on (2024-08-21 08:09:38 UTC): Hey @utkarsharma2 -> I believe we are getting very close :). There is this one flaky test with mapping and I **think** it shoudl be fixed by cherry-picking https://github.com/apache/airflow/pull/41414 - this is the only ""test"" change for database isolation mode that did not make it to v2-10-test branch as far as I can see (cc: @jscheffl - can you maybe take a look as well to double check?)

potiuk on (2024-08-21 08:11:03 UTC): Correction:

https://github.com/apache/airflow/pull/41344 and https://github.com/apache/airflow/pull/41414

potiuk on (2024-08-21 08:12:28 UTC): Also this one: https://github.com/apache/airflow/pull/41626  should fix ""latest boto"" tests when merged.

jscheffl on (2024-08-21 08:37:17 UTC): For the PRs I mentioned I am not sure - they are okay to get to v2-10-test (shall I make PRs for this, lost track about the vast amount of patches we made for isolation mode) but in the last build I only see two problems left caused by boto?

utkarsharma2 (Issue Creator) on (2024-08-21 08:58:14 UTC): Yes, we are! Thanks for looking into this @potiuk :)



https://github.com/apache/airflow/pull/41344 is already part of the branch. I have cherry-picked https://github.com/apache/airflow/pull/41414

I'm waiting for us to merge https://github.com/apache/airflow/pull/41626 to the main so I can cherry-pick this as well.

potiuk on (2024-08-21 09:18:22 UTC): Merged

potiuk on (2024-08-21 09:58:58 UTC): Hmm. We still have the flaky D tests/models/test_taskinstance.py::TestTaskInstance::test_check_task_dependencies_for_mapped - and I do recall having it (and fixing) in main...  Let me try to dig deeper and find what we are missing here.

potiuk on (2024-08-21 09:59:25 UTC): cc: @jscheffl -> maybe that one rings a bell for you ?

potiuk on (2024-08-21 10:09:39 UTC): Anh I know. @utkarsharma2 - this should be fixed by cherry-picking #41389

potiuk on (2024-08-21 10:12:05 UTC): And #41471 should also make ""Database Isolation tests"" stable.

potiuk on (2024-08-21 10:13:04 UTC): Yeah I think the last two @utkarsharma2 #41389 and #41471 should bring the stability back (those are test-only changes).

utkarsharma2 (Issue Creator) on (2024-08-21 10:14:54 UTC): Thanks @potiuk I have cherry-picked them.

potiuk on (2024-08-21 11:24:54 UTC): OK. I think the remaining ones are the ""regular"" flakes - that we have no good solution for now - so just re-running them after tests complete should help

jscheffl on (2024-08-21 11:59:44 UTC): I double-checked the list of PRs we had for making DB isolation tests working, don't know if implicitly contained but https://github.com/apache/airflow/pull/41450 was also merged on main and seems to be missing in v2-10-test.

potiuk on (2024-08-21 21:23:23 UTC): Green ! :)

"
2475405198,pull_request,closed,,custom dependency detector removal,custom dependency detector removal,dirrao,2024-08-20 11:27:55+00:00,[],2024-08-21 19:45:32+00:00,2024-08-20 14:20:50+00:00,https://github.com/apache/airflow/pull/41609,"[('area:serialization', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2475273052,pull_request,closed,,[Backport] Fix InletEventsAccessors type stub (#41572),Cherry picking 2545918b2272202f5427a2dcf98e700709705b32 (#41572),uranusjr,2024-08-20 10:20:27+00:00,[],2024-08-30 11:44:17+00:00,2024-08-20 10:54:17+00:00,https://github.com/apache/airflow/pull/41607,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2474929844,pull_request,closed,,"Fix UI rendering when XCom is INT, FLOAT, BOOL or NULL (#41516)","Backport of https://github.com/apache/airflow/pull/41516 to be in 2.10.1.

Cherry-pick of https://github.com/apache/airflow/commit/563bc494ab5c610c46a60b2fe6beed742e3d588e",jscheffl,2024-08-20 07:35:08+00:00,[],2024-08-30 11:44:35+00:00,2024-08-20 08:45:08+00:00,https://github.com/apache/airflow/pull/41605,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2474393351,pull_request,closed,,Update start-airflow executor defaulting for Celery integ,"When using the Celery integration, we should default to the CeleryExecutor instead of the LocalExecutor. Otherwise even the most basic commands (like starting the celery workers) will fail to run within the tmux terminals (see example below):

![Screenshot from 2024-08-19 14-38-26](https://github.com/user-attachments/assets/31ea910a-4b89-4a2f-82f0-b2b3914d8f7b)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-08-19 22:54:41+00:00,[],2024-08-20 12:04:37+00:00,2024-08-20 12:04:37+00:00,https://github.com/apache/airflow/pull/41603,"[('area:dev-tools', '')]",[],
2474376363,pull_request,closed,,Add slots_occupied to old hybrid executors,"Each time the base executor changes, often those need to be copied into the old (soon to be deprecated) hybrid executors. This was missed for the new slots_occupied property.

fixes #41525

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-08-19 22:43:33+00:00,[],2024-08-20 12:14:00+00:00,2024-08-20 06:11:59+00:00,https://github.com/apache/airflow/pull/41602,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', '')]","[{'comment_id': 2297642056, 'issue_id': 2474376363, 'author': 'o-nikolas', 'body': 'CC @LipuFei @potiuk', 'created_at': datetime.datetime(2024, 8, 19, 22, 47, 47, tzinfo=datetime.timezone.utc)}]","o-nikolas (Issue Creator) on (2024-08-19 22:47:47 UTC): CC @LipuFei @potiuk

"
2474258121,pull_request,closed,, Add callback to process Azure Service Bus message contents,"This PR adds a callback to process messages from an Azure Service Bus. 

Right now, on main, the Azure Service Bus message receiver simply logs the messages received and returns. This PR preserves that default, but adds the ability to pass in a callback function with the signature ServiceBusMessage -> None which is applied to each message received.

This change is made to both the general receiver and the subscription receiver.

I'd like someone from the Airflow community to weigh in on if this is a good solution. To me, it seemed like the least intrusive way to add a hook to obtain the message contents. However, I'm not sure if it plays well with the Airflow Operator standards as I've barely been using Airflow for a month.

Please let me know if you see any errors, omissions, or if I'm headed in the wrong direction.

Thank you,
Tim",perry2of5,2024-08-19 21:42:38+00:00,[],2024-10-24 18:49:16+00:00,2024-09-04 22:34:02+00:00,https://github.com/apache/airflow/pull/41601,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2299839998, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'This addresses https://github.com/apache/airflow/discussions/26446', 'created_at': datetime.datetime(2024, 8, 20, 22, 3, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307866016, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'Any chance @Lee-W or @Taragolis can review?', 'created_at': datetime.datetime(2024, 8, 23, 22, 4, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314777532, 'issue_id': 2474258121, 'author': 'Lee-W', 'body': 'It looks good at the first glance but would like to know what would be the main usage of this functionality', 'created_at': datetime.datetime(2024, 8, 28, 9, 14, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315811790, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': ""For my particular use case, I want to grab a file-location URL out of the message body and pass it to the next task in the DAG. In general, it provides a way to receive data from the message and react to it. This data may be success or failure information, file locations, etc. Other people have looked for this functionality too: https://github.com/apache/airflow/discussions/26446\r\n\r\nIn the AWS provider, the SQS sensor provides a similar result by putting the message into XCOM under the key messages. https://github.com/apache/airflow/blob/main/airflow/providers/amazon/aws/sensors/sqs.py#L46 I don't know that I always want the entire message shoved into XCOM though. Often, I might want to branch or just store part of the data and so I provide a callback function so the user of the operator can choose what they want to happen with the data in the message body."", 'created_at': datetime.datetime(2024, 8, 28, 16, 37, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320763837, 'issue_id': 2474258121, 'author': 'Lee-W', 'body': ""> For my particular use case, I want to grab a file-location URL out of the message body and pass it to the next task in the DAG. In general, it provides a way to receive data from the message and react to it. This data may be success or failure information, file locations, etc. Other people have looked for this functionality too: #26446\r\n> \r\n> In the AWS provider, the SQS sensor provides a similar result by putting the message into XCOM under the key messages. https://github.com/apache/airflow/blob/main/airflow/providers/amazon/aws/sensors/sqs.py#L46 I don't know that I always want the entire message shoved into XCOM though. Often, I might want to branch or just store part of the data and so I provide a callback function so the user of the operator can choose what they want to happen with the data in the message body.\r\n\r\nSounds good ðŸ‘"", 'created_at': datetime.datetime(2024, 8, 30, 10, 19, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2329917131, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'This is ready to be reviewed again.', 'created_at': datetime.datetime(2024, 9, 4, 20, 32, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330269872, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'Thank you @potiuk and @Lee-W.', 'created_at': datetime.datetime(2024, 9, 4, 22, 36, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411644710, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'I might have messed this one up from a usability point of view. I was assuming that if the context (to access XComs) was needed in the callback it could be captured in a lambda and passed down. However, I\'m having trouble accomplishing that and it look like the old technique of calling an operator from within an ""outer"" task function is now _highly_ discouraged. \r\n\r\nThe obvious solution""is to add a context parameter to the callback function. However, this would change the method signature and potentially break code somewhere ""in the wild"". I highly doubt anyone is using this yet, but that seems like the wrong thing to do.\r\n\r\nAnother solution would be to have to possible signatures of the callback: one with the context parameter and one without. Then inspect the callback function and only pass the context if the callback takes two arguments.  That seems messy. Any thoughts on this?', 'created_at': datetime.datetime(2024, 10, 14, 15, 47, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411751647, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'I suppose for 1-argument callbacks we could catch the type error, print a warning to update the function, and then call it with just the message. Is generating the TypeError expensive?', 'created_at': datetime.datetime(2024, 10, 14, 16, 38, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412632998, 'issue_id': 2474258121, 'author': 'Lee-W', 'body': '> The obvious solution""is to add a context parameter to the callback function. However, this would change the method signature and potentially break code somewhere ""in the wild"". I highly doubt anyone is using this yet, but that seems like the wrong thing to do.\r\n\r\nmaybe bump a major version for this?\r\n\r\n> Another solution would be to have to possible signatures of the callback: one with the context parameter and one without. Then inspect the callback function and only pass the context if the callback takes two arguments. That seems messy. Any thoughts on this?\r\n\r\nI personally don\'t like it ðŸ¤”  sounds hacky to me\r\n\r\n> I suppose for 1-argument callbacks we could catch the type error, print a warning to update the function, and then call it with just the message. Is generating the TypeError expensive?\r\n\r\nI guess it just as expensive as a regular exception?', 'created_at': datetime.datetime(2024, 10, 15, 1, 27, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414315471, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': ""Everything except releasing a major version sounds too hacky to me as well....  I'll open a ticket for this."", 'created_at': datetime.datetime(2024, 10, 15, 15, 28, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2436114073, 'issue_id': 2474258121, 'author': 'perry2of5', 'body': 'opened 43361', 'created_at': datetime.datetime(2024, 10, 24, 18, 49, 14, tzinfo=datetime.timezone.utc)}]","perry2of5 (Issue Creator) on (2024-08-20 22:03:31 UTC): This addresses https://github.com/apache/airflow/discussions/26446

perry2of5 (Issue Creator) on (2024-08-23 22:04:14 UTC): Any chance @Lee-W or @Taragolis can review?

Lee-W on (2024-08-28 09:14:40 UTC): It looks good at the first glance but would like to know what would be the main usage of this functionality

perry2of5 (Issue Creator) on (2024-08-28 16:37:08 UTC): For my particular use case, I want to grab a file-location URL out of the message body and pass it to the next task in the DAG. In general, it provides a way to receive data from the message and react to it. This data may be success or failure information, file locations, etc. Other people have looked for this functionality too: https://github.com/apache/airflow/discussions/26446

In the AWS provider, the SQS sensor provides a similar result by putting the message into XCOM under the key messages. https://github.com/apache/airflow/blob/main/airflow/providers/amazon/aws/sensors/sqs.py#L46 I don't know that I always want the entire message shoved into XCOM though. Often, I might want to branch or just store part of the data and so I provide a callback function so the user of the operator can choose what they want to happen with the data in the message body.

Lee-W on (2024-08-30 10:19:19 UTC): Sounds good ðŸ‘

perry2of5 (Issue Creator) on (2024-09-04 20:32:04 UTC): This is ready to be reviewed again.

perry2of5 (Issue Creator) on (2024-09-04 22:36:52 UTC): Thank you @potiuk and @Lee-W.

perry2of5 (Issue Creator) on (2024-10-14 15:47:45 UTC): I might have messed this one up from a usability point of view. I was assuming that if the context (to access XComs) was needed in the callback it could be captured in a lambda and passed down. However, I'm having trouble accomplishing that and it look like the old technique of calling an operator from within an ""outer"" task function is now _highly_ discouraged. 

The obvious solution""is to add a context parameter to the callback function. However, this would change the method signature and potentially break code somewhere ""in the wild"". I highly doubt anyone is using this yet, but that seems like the wrong thing to do.

Another solution would be to have to possible signatures of the callback: one with the context parameter and one without. Then inspect the callback function and only pass the context if the callback takes two arguments.  That seems messy. Any thoughts on this?

perry2of5 (Issue Creator) on (2024-10-14 16:38:32 UTC): I suppose for 1-argument callbacks we could catch the type error, print a warning to update the function, and then call it with just the message. Is generating the TypeError expensive?

Lee-W on (2024-10-15 01:27:30 UTC): maybe bump a major version for this?


I personally don't like it ðŸ¤”  sounds hacky to me


I guess it just as expensive as a regular exception?

perry2of5 (Issue Creator) on (2024-10-15 15:28:32 UTC): Everything except releasing a major version sounds too hacky to me as well....  I'll open a ticket for this.

perry2of5 (Issue Creator) on (2024-10-24 18:49:14 UTC): opened 43361

"
2474054793,pull_request,closed,,Update min version req of gcloud-aio-bigquery,"In the following PR - https://github.com/apache/airflow/pull/38912 we are passing location to gcloud-aio-bigquery [Job init()](https://github.com/talkiq/gcloud-aio/blob/304a0618432101c5fd425f542f853ac83080d740/bigquery/gcloud/aio/bigquery/job.py#L21) method, which was only introduced in the [7.1.0](https://github.com/talkiq/gcloud-aio/blob/0df92baa22d0a4c44d1729f4af482bea1b63e5ff/bigquery/gcloud/aio/bigquery/job.py#L27) version of gcloud-aio-bigquery lib. Since the current min requirement in provider version 10.21.0 is >= 6.1.2. Due to this if we have a lower version then <7.1.0 of gcloud-aio-bigquery, the jobs are not canceled when we cancel the corresponding task in Airflow UI.

This PR aims at adding the pin for the right version (>=7.1.0) of gcloud-aio-bigquery dependency of apache-airflow-providers-google",utkarsharma2,2024-08-19 19:32:25+00:00,[],2024-11-12 00:14:49+00:00,2024-11-12 00:14:49+00:00,https://github.com/apache/airflow/pull/41599,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:dev-tools', '')]","[{'comment_id': 2298733465, 'issue_id': 2474054793, 'author': 'utkarsharma2', 'body': ""> I don't think we need the content in dev/breeze/doc/images in this PR?\r\n\r\nHmm looks odd, but they were generated by pre-commits hooks, let me double check it."", 'created_at': datetime.datetime(2024, 8, 20, 12, 25, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2363391843, 'issue_id': 2474054793, 'author': 'eladkal', 'body': '> which was only introduced in the [7.1.0](https://github.com/talkiq/gcloud-aio/blob/0df92baa22d0a4c44d1729f4af482bea1b63e5ff/bigquery/gcloud/aio/bigquery/job.py#L27) version of gcloud-aio-bigquery lib. Since the current min requirement in provider version 10.21.0 is >= 6.1.2. Due to this if we have a lower version then <7.1.0 of gcloud-aio-bigquery, the jobs are not canceled when we cancel the corresponding task in Airflow UI.\r\n\r\nThat is fine though. If we bump to min version for every new feature it means that we always set only latest version of any library we bring. The solution to the problem you are describing is wrapping the specific feature with checking of min needed version of the upstream library.', 'created_at': datetime.datetime(2024, 9, 20, 10, 26, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455963012, 'issue_id': 2474054793, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 5, 0, 15, 6, tzinfo=datetime.timezone.utc)}]","utkarsharma2 (Issue Creator) on (2024-08-20 12:25:35 UTC): Hmm looks odd, but they were generated by pre-commits hooks, let me double check it.

eladkal on (2024-09-20 10:26:44 UTC): That is fine though. If we bump to min version for every new feature it means that we always set only latest version of any library we bring. The solution to the problem you are describing is wrapping the specific feature with checking of min needed version of the upstream library.

github-actions[bot] on (2024-11-05 00:15:06 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2473765093,pull_request,closed,,Update the usage of credentials in the sagemaker test,"The script run in the sagemaker job imports boto, but doesn't actually use it. This change drops boto and removes a lot of the need for credentials management. This simplifies the system test.

I've run the test manually and it passes.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-08-19 16:39:16+00:00,[],2024-08-19 18:35:26+00:00,2024-08-19 18:35:25+00:00,https://github.com/apache/airflow/pull/41595,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2473635703,pull_request,closed,,Add documentation for state mismatch between db and executor,This was discussed at length in [this comment](https://github.com/apache/airflow/pull/40468#discussion_r1670868964) to #40468 ,RNHTTR,2024-08-19 15:27:15+00:00,[],2024-10-22 00:15:20+00:00,2024-10-22 00:15:20+00:00,https://github.com/apache/airflow/pull/41593,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2412570430, 'issue_id': 2473635703, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 15, 0, 15, 10, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-15 00:15:10 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2473629402,pull_request,closed,,fix: task flow dynamic mapping with default_args,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #33600


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-19 15:24:13+00:00,[],2024-10-02 04:01:42+00:00,2024-10-02 01:13:38+00:00,https://github.com/apache/airflow/pull/41592,[],"[{'comment_id': 2351540980, 'issue_id': 2473629402, 'author': 'phi-friday', 'body': 'After a recent rebase, I\'m getting the following error, and I\'m not sure why.\r\n\r\n```shell\r\n_________ TestOtelMetrics.test_timer_start_and_stop_manually_send_true _________\r\n[gw2] linux -- Python 3.8.20 /usr/local/bin/python\r\n\r\nself = <tests.core.test_otel_logger.TestOtelMetrics object at 0x7f0c14b7e370>\r\nmock_time = <MagicMock name=\'perf_counter\' id=\'139690224843072\'>\r\nname = \'test_stats_run\'\r\n\r\n    @mock.patch.object(time, ""perf_counter"", side_effect=[0.0, 3.14])\r\n    def test_timer_start_and_stop_manually_send_true(self, mock_time, name):\r\n        timer = self.stats.timer(name)\r\n        timer.start()\r\n        # Perform some task\r\n        timer.stop(send=True)\r\n    \r\n        assert isinstance(timer.duration, float)\r\n>       assert timer.duration == 3.14\r\nE       assert 3140.0 == 3.14\r\nE        +  where 3140.0 = <airflow.metrics.otel_logger._OtelTimer object at 0x7f0c2a6999a0>.duration\r\n\r\ntests/core/test_otel_logger.py:327: AssertionError\r\n```', 'created_at': datetime.datetime(2024, 9, 15, 11, 10, 18, tzinfo=datetime.timezone.utc)}]","phi-friday (Issue Creator) on (2024-09-15 11:10:18 UTC): After a recent rebase, I'm getting the following error, and I'm not sure why.

```shell
_________ TestOtelMetrics.test_timer_start_and_stop_manually_send_true _________
[gw2] linux -- Python 3.8.20 /usr/local/bin/python

self = <tests.core.test_otel_logger.TestOtelMetrics object at 0x7f0c14b7e370>
mock_time = <MagicMock name='perf_counter' id='139690224843072'>
name = 'test_stats_run'

    @mock.patch.object(time, ""perf_counter"", side_effect=[0.0, 3.14])
    def test_timer_start_and_stop_manually_send_true(self, mock_time, name):
        timer = self.stats.timer(name)
        timer.start()
        # Perform some task
        timer.stop(send=True)
    
        assert isinstance(timer.duration, float)
E       assert 3140.0 == 3.14
E        +  where 3140.0 = <airflow.metrics.otel_logger._OtelTimer object at 0x7f0c2a6999a0>.duration

tests/core/test_otel_logger.py:327: AssertionError
```

"
2473613157,pull_request,closed,,fix log for notifier(instance) without __name__,"fix [#41563](https://github.com/apache/airflow/issues/41563)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",obarisk,2024-08-19 15:16:25+00:00,[],2024-08-30 09:30:47+00:00,2024-08-23 03:00:58+00:00,https://github.com/apache/airflow/pull/41591,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2296828835, 'issue_id': 2473613157, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 19, 15, 16, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301378820, 'issue_id': 2473613157, 'author': 'uranusjr', 'body': 'Please consider setting up pre-commit to run linters locally before pushing. The code format needs some work.\r\n\r\nSearch in `contributing-docs` to find relevant information on how to setup and run pre-commit.', 'created_at': datetime.datetime(2024, 8, 21, 7, 50, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304099615, 'issue_id': 2473613157, 'author': 'potiuk', 'body': 'Once the tests are fixed and we merge it - can you please back-port it to as `v2-10-test` PR @obarisk  ?', 'created_at': datetime.datetime(2024, 8, 22, 8, 38, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306092675, 'issue_id': 2473613157, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 23, 3, 1, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-19 15:16:29 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

uranusjr on (2024-08-21 07:50:12 UTC): Please consider setting up pre-commit to run linters locally before pushing. The code format needs some work.

Search in `contributing-docs` to find relevant information on how to setup and run pre-commit.

potiuk on (2024-08-22 08:38:03 UTC): Once the tests are fixed and we merge it - can you please back-port it to as `v2-10-test` PR @obarisk  ?

boring-cyborg[bot] on (2024-08-23 03:01:00 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2473348983,pull_request,closed,,kubernetes remove 1.27 support,"EKS 1.27 end 24 Jul 2024

AKS 1.27 end 31 Jul 2024",raphaelauv,2024-08-19 13:19:15+00:00,[],2024-08-19 15:16:49+00:00,2024-08-19 15:01:14+00:00,https://github.com/apache/airflow/pull/41590,"[('area:dev-tools', '')]",[],
2473346078,pull_request,closed,,Lower log level when no pod template file is supplied,"I suggest lowering the log message when no pod template file is provided from warning to info level. This is accepted behaviour, many users specify pod settings on task-level. However, logging a warning suggests otherwise, which is confusing.

WARNING log message example:
```
[2024-08-19, 11:09:46 UTC] {pod_generator.py:525} WARNING - Model file /usr/local/airflow/pod_template_file.yaml does not exist
```",BasPH,2024-08-19 13:18:03+00:00,[],2024-08-19 13:20:59+00:00,2024-08-19 13:18:54+00:00,https://github.com/apache/airflow/pull/41589,[],[],
2473140281,pull_request,closed,,Upgrade build and chart dependencies (#41570),"(cherry picked from commit c88192c466cb91842310f82a61eaa48b39439bef)

",utkarsharma2,2024-08-19 11:34:28+00:00,[],2024-08-30 11:46:29+00:00,2024-08-19 13:00:42+00:00,https://github.com/apache/airflow/pull/41588,"[('area:dev-tools', ''), ('area:helm-chart', 'Airflow Helm Chart'), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2473120972,pull_request,closed,,fix: openlineage replace dagTree with downstream_task_ids,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
related: #41505 

Even after fix in #41494 has been implemented, we were still able to cause the scheduler OOM error when creating a dag_tree with the example dag below:
<details>
<summary>dag crashing the dagTree</summary>

```
with DAG(""dag"", schedule=None):
    start = EmptyOperator(task_id=""start"")

    a = [
        start
        >> EmptyOperator(task_id=f""a_1_{i}"")
        >> EmptyOperator(task_id=f""a_2_{i}"")
        >> EmptyOperator(task_id=f""a_3_{i}"")
        for i in range(200)
    ]

    middle = EmptyOperator(task_id=""middle"")

    b = [
        middle
        >> EmptyOperator(task_id=f""b_1_{i}"")
        >> EmptyOperator(task_id=f""b_2_{i}"")
        >> EmptyOperator(task_id=f""b_3_{i}"")
        for i in range(200)
    ]

    middle2 = EmptyOperator(task_id=""middle2"")

    c = [
        middle2
        >> EmptyOperator(task_id=f""c_1_{i}"")
        >> EmptyOperator(task_id=f""c_2_{i}"")
        >> EmptyOperator(task_id=f""c_3_{i}"")
        for i in range(200)
    ]

    end = EmptyOperator(task_id=""end"")

    start >> a >> middle >> b >> middle2 >> c >> end
```
</details>

To prevent OpenLineage from breaking the scheduler with additional computation, we should only rely on the information that Airflow uses itself - downstream task ids.

This PR removes the dagTree information from OL AirflowJobFacet and adds downstream task ids to the list of tasks included in the same facet. This dramatically reduces the size of the facet and allows the consumer that rely on this information to sill re-create it. 

<details>
<summary>example snippet to re-create</summary>

```
tasks = {
    'task': {'downstream_tasks': []},
    'task1': {'downstream_tasks': [""task""]},
    'task2': {'downstream_tasks': [""task1""]},
}

def add_to_tree(task_id, tree):
    if task_id not in tree:
        tree[task_id] = {}

    for downstream_task in tasks[task_id].get('downstream_tasks', []):
        add_to_tree(downstream_task, tree[task_id])

def is_root_task(task_id):
    # A task is considered a root task if no other task lists it as a downstream task
    for task_info in tasks.values():
        if task_id in task_info.get('downstream_tasks', []):
            return False
    return True

dag_tree = {}
for task_id in tasks:
    if is_root_task(task_id):
        add_to_tree(task_id, dag_tree)

print(dag_tree)
# {'task2': {'task1': {'task': {}}}}
```
</details>


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-19 11:23:36+00:00,[],2024-08-23 11:11:50+00:00,2024-08-21 08:03:08+00:00,https://github.com/apache/airflow/pull/41587,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2306845831, 'issue_id': 2473120972, 'author': 'tatiana', 'body': 'apache-airflow-provider-openlineage 1.11.0 contains the first change: https://github.com/apache/airflow/issues/41577\r\nbut the following change will be released only in 1.12', 'created_at': datetime.datetime(2024, 8, 23, 11, 0, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306847011, 'issue_id': 2473120972, 'author': 'tatiana', 'body': '@mobuchowski to update once we have the next release', 'created_at': datetime.datetime(2024, 8, 23, 11, 0, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306865722, 'issue_id': 2473120972, 'author': 'kacpermuda', 'body': '@tatiana The 1.11.0 has not been released yet, it has been excluded from this wave exactly because of this fix ([my message](https://github.com/apache/airflow/issues/41577#issuecomment-2296804228)). We should expect 1.11.0rc2 soon and both fixes will be included in 1.11.0.', 'created_at': datetime.datetime(2024, 8, 23, 11, 11, 49, tzinfo=datetime.timezone.utc)}]","tatiana on (2024-08-23 11:00:31 UTC): apache-airflow-provider-openlineage 1.11.0 contains the first change: https://github.com/apache/airflow/issues/41577
but the following change will be released only in 1.12

tatiana on (2024-08-23 11:00:49 UTC): @mobuchowski to update once we have the next release

kacpermuda (Issue Creator) on (2024-08-23 11:11:49 UTC): @tatiana The 1.11.0 has not been released yet, it has been excluded from this wave exactly because of this fix ([my message](https://github.com/apache/airflow/issues/41577#issuecomment-2296804228)). We should expect 1.11.0rc2 soon and both fixes will be included in 1.11.0.

"
2473116599,pull_request,closed,,Sync v2-10-stable with v2-10-test to release python client v2.10.0,,utkarsharma2,2024-08-19 11:21:01+00:00,[],2024-08-20 12:13:33+00:00,2024-08-20 12:13:32+00:00,https://github.com/apache/airflow/pull/41585,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2298709991, 'issue_id': 2473116599, 'author': 'utkarsharma2', 'body': 'Closing it in favor of PR - https://github.com/apache/airflow/pull/41610. Since there are constant changes added to the v2-10-test branch and the CI is taking forever to get green which prevents us from releasing the python client.', 'created_at': datetime.datetime(2024, 8, 20, 12, 13, 32, tzinfo=datetime.timezone.utc)}]","utkarsharma2 (Issue Creator) on (2024-08-20 12:13:32 UTC): Closing it in favor of PR - https://github.com/apache/airflow/pull/41610. Since there are constant changes added to the v2-10-test branch and the CI is taking forever to get green which prevents us from releasing the python client.

"
2473056159,pull_request,closed,,Add changelog for airflow python client 2.10.0 (#41583),"* Add changelog for airflow python client 2.10.0

* Update client version

(cherry picked from commit 317a28ed435960e7184e357a2f128806c34612fa)
",utkarsharma2,2024-08-19 10:49:13+00:00,[],2024-08-30 11:46:56+00:00,2024-08-19 11:00:03+00:00,https://github.com/apache/airflow/pull/41584,"[('area:API', ""Airflow's REST/HTTP API""), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2472998267,pull_request,closed,,Add changelog for airflow python client 2.10.0,,utkarsharma2,2024-08-19 10:19:17+00:00,[],2024-08-30 09:26:09+00:00,2024-08-19 10:34:17+00:00,https://github.com/apache/airflow/pull/41583,"[('area:API', ""Airflow's REST/HTTP API""), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2472940106,pull_request,closed,,Skip AWS auth test when python3-saml not installed,"Python3-saml is an optional dependency of Amazon provider and in case of Airflow 2.9 tests python3-saml is not installed yet, so we should skip the tests in case it is not.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-19 09:51:43+00:00,[],2024-08-19 12:05:00+00:00,2024-08-19 12:04:58+00:00,https://github.com/apache/airflow/pull/41582,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2472916174,pull_request,closed,,Kubernetes 1.31 support,,raphaelauv,2024-08-19 09:40:05+00:00,[],2024-08-19 12:41:23+00:00,2024-08-19 12:15:52+00:00,https://github.com/apache/airflow/pull/41581,"[('area:dev-tools', '')]","[{'comment_id': 2296433637, 'issue_id': 2472916174, 'author': 'potiuk', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 8, 19, 12, 15, 57, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-19 12:15:57 UTC): Thanks!

"
2472770040,pull_request,closed,,decorators deprecated apply_defaults removal,decorators deprecated apply_defaults removal,dirrao,2024-08-19 08:28:07+00:00,['dirrao'],2024-08-21 19:45:32+00:00,2024-08-19 09:32:05+00:00,https://github.com/apache/airflow/pull/41579,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2472732728,pull_request,closed,,Add DataflowStartYamlJobOperator,Add DataflowStartYamlJobOperator as a replacement option for DataflowStartSqlJobOperator.,moiseenkov,2024-08-19 08:10:16+00:00,[],2024-09-02 20:23:21+00:00,2024-09-02 14:27:01+00:00,https://github.com/apache/airflow/pull/41576,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', ''), ('kind:documentation', '')]","[{'comment_id': 2324601110, 'issue_id': 2472732728, 'author': 'moiseenkov', 'body': '> Looks good overall!\r\n> I got a small comment regarding reusability.\r\n\r\n@shahar1 , \r\nThanks for the review. Please take a look at the fixes.', 'created_at': datetime.datetime(2024, 9, 2, 12, 9, 15, tzinfo=datetime.timezone.utc)}]","moiseenkov (Issue Creator) on (2024-09-02 12:09:15 UTC): @shahar1 , 
Thanks for the review. Please take a look at the fixes.

"
2472714612,pull_request,closed,,Openlineage s3 to redshift operator integration,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
**Recreated approved PR https://github.com/apache/airflow/pull/41422, because I made a mess rebasing**
Added get_openlineage_facets_on_complete method to S3ToRedshiftOperator.
It extracts target table schema by querying redshift and creates identity column level lineage.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Artuz37,2024-08-19 08:01:22+00:00,[],2024-08-19 14:11:59+00:00,2024-08-19 14:11:54+00:00,https://github.com/apache/airflow/pull/41575,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2296680686, 'issue_id': 2472714612, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 19, 14, 11, 58, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-19 14:11:58 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2472696411,pull_request,closed,,Allow usage of Jinja templating inside task param,"Added rendering of parameters in the task context

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
closes: #31801 
",eter4eter,2024-08-19 07:52:43+00:00,['uranusjr'],2024-10-10 00:14:58+00:00,2024-10-10 00:14:58+00:00,https://github.com/apache/airflow/pull/41574,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('AIP-80', 'Explicit Template Fields')]","[{'comment_id': 2295898117, 'issue_id': 2472696411, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 19, 7, 52, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298157572, 'issue_id': 2472696411, 'author': 'uranusjr', 'body': 'I will do this as a part of AIP-80. Instead of supporting Jinja template strings directly, Param will be able to resolve Template classes.\r\n\r\nhttps://cwiki.apache.org/confluence/x/2grOEg\r\n\r\nDeferring this for now until AIP-80 is implemented. We wonâ€™t have a feature release before that anyway.', 'created_at': datetime.datetime(2024, 8, 20, 7, 26, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394810053, 'issue_id': 2472696411, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 5, 0, 14, 54, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-19 07:52:47 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

uranusjr (Assginee) on (2024-08-20 07:26:38 UTC): I will do this as a part of AIP-80. Instead of supporting Jinja template strings directly, Param will be able to resolve Template classes.

https://cwiki.apache.org/confluence/x/2grOEg

Deferring this for now until AIP-80 is implemented. We wonâ€™t have a feature release before that anyway.

github-actions[bot] on (2024-10-05 00:14:54 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2472498917,pull_request,closed,,Small refactoring of Dataplex system tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-08-19 05:37:40+00:00,[],2024-08-19 09:28:53+00:00,2024-08-19 09:28:53+00:00,https://github.com/apache/airflow/pull/41573,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2472370625,pull_request,closed,,fix: InletEventsAccessors stubs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

`InletEventsAccessors` allowed `DatasetAlias`.
But `context.pyi` does not allowed it.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-19 03:22:42+00:00,[],2024-08-30 09:15:11+00:00,2024-08-20 10:17:49+00:00,https://github.com/apache/airflow/pull/41572,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2472187190,pull_request,closed,,Upgrade build and chart dependencies,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-18 23:06:30+00:00,[],2024-08-30 09:05:48+00:00,2024-08-19 09:05:26+00:00,https://github.com/apache/airflow/pull/41570,"[('area:dev-tools', ''), ('area:helm-chart', 'Airflow Helm Chart'), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2472168420,pull_request,closed,,Remove debian bullseye support (#41568),"(cherry picked from commit 5c323a9c562c6e886dbba460fc733a6f8590bf8b)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-18 22:07:43+00:00,[],2024-09-02 04:12:39+00:00,2024-08-19 13:32:48+00:00,https://github.com/apache/airflow/pull/41569,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2295414202, 'issue_id': 2472168420, 'author': 'potiuk', 'body': 'Backport to v2-10-test', 'created_at': datetime.datetime(2024, 8, 18, 22, 12, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295414256, 'issue_id': 2472168420, 'author': 'potiuk', 'body': ""(it's long overdue - should be removed in 2.9.0)"", 'created_at': datetime.datetime(2024, 8, 18, 22, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296545316, 'issue_id': 2472168420, 'author': 'potiuk', 'body': 'Would love also get that one back-ported (for docs in v2.10.1 mostly', 'created_at': datetime.datetime(2024, 8, 19, 13, 11, 7, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-18 22:12:48 UTC): Backport to v2-10-test

potiuk (Issue Creator) on (2024-08-18 22:13:00 UTC): (it's long overdue - should be removed in 2.9.0)

potiuk (Issue Creator) on (2024-08-19 13:11:07 UTC): Would love also get that one back-ported (for docs in v2.10.1 mostly

"
2472141872,pull_request,closed,,Remove debian bullseye support,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-18 21:02:21+00:00,[],2024-09-02 04:13:00+00:00,2024-08-18 21:50:47+00:00,https://github.com/apache/airflow/pull/41568,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('type:doc-only', 'Changelog: Doc Only')]",[],
2472120593,pull_request,closed,,Make all test pass in Database Isolation mode,"This adds dedicated ""DatabaseIsolation"" test to airflow v2-10-test branch..

The DatabaseIsolation test will run all ""db-tests"" with enabled DB isolation mode and running `internal-api` component - groups of tests marked with ""skip-if-database-isolation"" will be skipped.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-18 19:54:56+00:00,[],2024-08-30 09:26:25+00:00,2024-08-19 12:03:14+00:00,https://github.com/apache/airflow/pull/41567,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2295419331, 'issue_id': 2472120593, 'author': 'potiuk', 'body': ""CC: @jscheffl -> the only problem with that one is that provider's tests are not run in v2-10-test branch (by definition). \r\n\r\nWhich I **think** is not a problem - we already gone through the exercise of fixing all db isolation test failures in providers, and it's unlilkely this will deteriorate over time. WDYT?"", 'created_at': datetime.datetime(2024, 8, 18, 22, 34, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296409926, 'issue_id': 2472120593, 'author': 'potiuk', 'body': 'cc: @utkarsharma2 - I am merging this one as with some of the test changes (only tests) I believe it brings stability to the running tests and you need it for Python client relase.', 'created_at': datetime.datetime(2024, 8, 19, 12, 3, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296960236, 'issue_id': 2472120593, 'author': 'jscheffl', 'body': ""> CC: @jscheffl -> the only problem with that one is that provider's tests are not run in v2-10-test branch (by definition).\r\n> \r\n> Which I **think** is not a problem - we already gone through the exercise of fixing all db isolation test failures in providers, and it's unlilkely this will deteriorate over time. WDYT?\r\n\r\nI'd assume there is a small (but realistic) residual risk that a new provider change/feature will not be working in DB isolation mode. For this you would need to und a backpat compatability check in isolation mode on-top of the existing (to be created?) back-compatability check with Airflow 2.10 line.\r\n\r\nI think for such cases the specific provider needs to be patched. As long as the core is stable, I am happy."", 'created_at': datetime.datetime(2024, 8, 19, 16, 21, 52, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-18 22:34:34 UTC): CC: @jscheffl -> the only problem with that one is that provider's tests are not run in v2-10-test branch (by definition). 

Which I **think** is not a problem - we already gone through the exercise of fixing all db isolation test failures in providers, and it's unlilkely this will deteriorate over time. WDYT?

potiuk (Issue Creator) on (2024-08-19 12:03:11 UTC): cc: @utkarsharma2 - I am merging this one as with some of the test changes (only tests) I believe it brings stability to the running tests and you need it for Python client relase.

jscheffl on (2024-08-19 16:21:52 UTC): I'd assume there is a small (but realistic) residual risk that a new provider change/feature will not be working in DB isolation mode. For this you would need to und a backpat compatability check in isolation mode on-top of the existing (to be created?) back-compatability check with Airflow 2.10 line.

I think for such cases the specific provider needs to be patched. As long as the core is stable, I am happy.

"
2472096322,pull_request,closed,,Fix changelog template for new providers w/o relevant commits,"During the implementation of AIP-69 I realized that the CI fails during the check of preparation of changelog. Reason is that the `classified_changes` prepared is None and the Jinja templating fails. See `dev/breeze/src/airflow_breeze/prepare_providers/provider_documentation.py:960`.

This PR fixes/adjusts the jinja template if no commits can be found.",jscheffl,2024-08-18 18:41:17+00:00,[],2024-08-18 19:17:23+00:00,2024-08-18 19:17:23+00:00,https://github.com/apache/airflow/pull/41566,"[('area:dev-tools', '')]",[],
2472094171,pull_request,closed,,Support pre-versions in version handling in Breeze,"During the implementation of AIP-69 for which we agreed to make a pre-release as provider only I noticed that breeze fails in non-numeric versions, e.g. I used `0.1.0pre0` as the code attempts to remove leading zeroes.

This bugfix just removed leading zeroes but leaves other parts of the version number unchanged.",jscheffl,2024-08-18 18:34:36+00:00,[],2024-08-18 20:08:37+00:00,2024-08-18 20:08:37+00:00,https://github.com/apache/airflow/pull/41565,"[('area:dev-tools', '')]",[],
2472028801,pull_request,closed,,Airflow Standard Provider,"Extract all time operators and sensors from airflow core and remove them to `standard` provider
Mailing list thread: https://lists.apache.org/thread/2dmlqkcmyomm4q7rrovygs6bw655zx07

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-18 15:36:47+00:00,['romsharon98'],2024-10-31 12:29:55+00:00,2024-09-18 13:12:16+00:00,https://github.com/apache/airflow/pull/41564,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:standard', '')]","[{'comment_id': 2308790425, 'issue_id': 2472028801, 'author': 'potiuk', 'body': 'One more thing - at least for now, ""standard"" should be added to list of preinstalled providers in `hatch_build.py` \r\n\r\n```\r\nPRE_INSTALLED_PROVIDERS = [\r\n    ""common.compat"",\r\n    ""common.io"",\r\n    ""common.sql"",\r\n    ""fab>=1.0.2"",\r\n    ""ftp"",\r\n    ""http"",\r\n    ""imap"",\r\n    ""smtp"",\r\n    ""sqlite"",\r\n]\r\n```', 'created_at': datetime.datetime(2024, 8, 25, 11, 28, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308790670, 'issue_id': 2472028801, 'author': 'potiuk', 'body': 'We might change where it is added in Airflow 3, but for now it should be added here.', 'created_at': datetime.datetime(2024, 8, 25, 11, 29, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308792633, 'issue_id': 2472028801, 'author': 'potiuk', 'body': ""1. we need to deprecate the existed operators in core\r\n\r\n> Yes, but I think this should be done as separate PR to v2-10-test. I think we do not want to back-port that one to v2-10-test - and we should simply do it there (after we release `standard` as provider). I am not sure we want to back-port the whole PR here to v2-10-test (providers are not build nor tested there anyway).\r\n\r\n2. we are missing all the operators (currently it's only for time operators)\r\n\r\n> I think those should be separate, smaller PRs ?\r\n\r\n3. I am not sure what about the hooks folder?\r\n\r\n> I think it's the same ^^ - some should be moved but separately."", 'created_at': datetime.datetime(2024, 8, 25, 11, 34, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308793428, 'issue_id': 2472028801, 'author': 'gopidesupavan', 'body': 'Thanks @romsharon98 , will be adding rest of the operators and sensors to this.', 'created_at': datetime.datetime(2024, 8, 25, 11, 36, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308793842, 'issue_id': 2472028801, 'author': 'gopidesupavan', 'body': ""> we are missing few things...\r\n> \r\n> 1. we need to deprecate the existed operators in core\r\n> 2. we are missing all the operators and sensors we have in core (currently it's only for time operators)\r\n> 3. I am not sure what about the `hooks` folder?\r\n\r\n@eladkal me and romsharon discussed , i will be adding rest of the operators and sensors."", 'created_at': datetime.datetime(2024, 8, 25, 11, 37, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308794930, 'issue_id': 2472028801, 'author': 'potiuk', 'body': 'Ah .. so no ... We should not add it to preinstalled just **yet** - until we release it (sorry @romsharon98 -> see the failure on openapi client).', 'created_at': datetime.datetime(2024, 8, 25, 11, 40, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308795806, 'issue_id': 2472028801, 'author': 'eladkal', 'body': '> Yes, but I think this should be done as separate PR to v2-10-test. I think we do not want to back-port that one to v2-10-test - and we should simply do it there (after we release standard as provider). I am not sure we want to back-port the whole PR here to v2-10-test (providers are not build nor tested there anyway).\r\n\r\nThen I propose this PR to remove the files from main that we migrated to the provider.\r\nThe PR to v2-10-test would be just to replace the classes with deprecation notes after we release the provider.', 'created_at': datetime.datetime(2024, 8, 25, 11, 43, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308797132, 'issue_id': 2472028801, 'author': 'potiuk', 'body': '> Then I propose this PR to remove the files from main that we migrated to the provider. \r\n\r\nThis is what the PR does.\r\n\r\n<img width=""767"" alt=""Screenshot 2024-08-25 at 13 46 45"" src=""https://github.com/user-attachments/assets/a2090679-334f-4f79-8d87-a775d17bde13"">', 'created_at': datetime.datetime(2024, 8, 25, 11, 47, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308798626, 'issue_id': 2472028801, 'author': 'eladkal', 'body': ""Ah! I didn't see changes to `airflow/core` folder so I assumed it was missed.\r\nNot very friendly UX design from GitHub"", 'created_at': datetime.datetime(2024, 8, 25, 11, 50, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308799044, 'issue_id': 2472028801, 'author': 'gopidesupavan', 'body': '> > Yes, but I think this should be done as separate PR to v2-10-test. I think we do not want to back-port that one to v2-10-test - and we should simply do it there (after we release standard as provider). I am not sure we want to back-port the whole PR here to v2-10-test (providers are not build nor tested there anyway).\r\n> \r\n> Then I propose this PR to remove the files from main that we migrated to the provider. The PR to v2-10-test would be just to replace the classes with deprecation notes after we release the provider.\r\n\r\nPlease correct me if i understood this, on v2-10-test deprecation updates required for all the changes we are doing on main?', 'created_at': datetime.datetime(2024, 8, 25, 11, 50, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308800207, 'issue_id': 2472028801, 'author': 'potiuk', 'body': '> Please correct me if i understood this, on v2-10-test deprecation updates required for all the changes we are doing on main?\r\n\r\nNo - only those that are supposed to affect DAG authors.', 'created_at': datetime.datetime(2024, 8, 25, 11, 54, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308803425, 'issue_id': 2472028801, 'author': 'potiuk', 'body': 'BTW. We **will** have to make the old ""standard"" providers still work in Airflow 3 I **think** so we will have to make the old operator imports work (likely with the mechanism mentioned by @ashb - `sys.meta_path`) - otherwise it will `require` many dags to change. I think we should apply the same mechanism as we will do for importing BaseOperator etc. in Airflow 3 (and still raise deprecation warning).\r\n\r\n@ashb ? Do you agree ?', 'created_at': datetime.datetime(2024, 8, 25, 12, 2, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308913875, 'issue_id': 2472028801, 'author': 'potiuk', 'body': 'Interesting. The errors we see are very useful :).\r\n\r\n1) examples are part of the documentation of ""main"" airflow"" - and I am afraid they will have to remain as examples in ""airflow"" not moved to provider, especially because point 2)...\r\n\r\n2) the examples should be embedded and shown in airflow when ""examples"" are enabled - I think we should not (at least not now) to develop a mechanism to read examples for Airflow from providers.\r\n\r\n3) The tests should also mock the moved packages.\r\n\r\n```\r\n<module \'airflow.sensors.time_delta\' from \'/usr/local/lib/python3.8/site-packages/airflow/sensors/time_delta.py\'> does not have the attribute \'sleep\'\r\nFAILED tests/providers/standard/time/sensors/test_time_delta.py::TestTimeDeltaSensorAsync::test_wait_sensor[True] - AttributeError: <module \'airflow.sensors.time_delta\' from \'/u\r\n```', 'created_at': datetime.datetime(2024, 8, 25, 16, 24, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308975222, 'issue_id': 2472028801, 'author': 'romsharon98', 'body': '> Interesting. The errors we see are very useful :).\r\n> \r\n> 1. examples are part of the documentation of ""main"" airflow"" - and I am afraid they will have to remain as examples in ""airflow"" not moved to provider, especially because point 2)...\r\n> 2. the examples should be embedded and shown in airflow when ""examples"" are enabled - I think we should not (at least not now) to develop a mechanism to read examples for Airflow from providers.\r\n> 3. The tests should also mock the moved packages.\r\n> \r\n> ```\r\n> <module \'airflow.sensors.time_delta\' from \'/usr/local/lib/python3.8/site-packages/airflow/sensors/time_delta.py\'> does not have the attribute \'sleep\'\r\n> FAILED tests/providers/standard/time/sensors/test_time_delta.py::TestTimeDeltaSensorAsync::test_wait_sensor[True] - AttributeError: <module \'airflow.sensors.time_delta\' from \'/u\r\n> ```\r\n\r\nrevert the example dags to be under `main` airflow.\r\nshould I add a link in index.yaml for those example dags? \r\n\r\nalso not sure but should I change somewhere in the code to tell that this provider is mandatory and will auto installed?', 'created_at': datetime.datetime(2024, 8, 25, 20, 2, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308975730, 'issue_id': 2472028801, 'author': 'potiuk', 'body': ""> also not sure but should I change somewhere in the code to tell that this provider is mandatory and will auto installed?\r\n\r\nThat's the preinstalled_providers - but it will only work after it's been released and it will likely change with Airflow 3 so for now - no need."", 'created_at': datetime.datetime(2024, 8, 25, 20, 4, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308984153, 'issue_id': 2472028801, 'author': 'gopidesupavan', 'body': 'so for time related things its placed under time/ , for other operators and sensors am placing like this . \r\n\r\nstandard/core/operators/\r\nstandard/core/sensors/\r\n\r\nis this fine? or any other suggestion.', 'created_at': datetime.datetime(2024, 8, 25, 20, 31, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309566421, 'issue_id': 2472028801, 'author': 'eladkal', 'body': 'Lets wait with merge till we understand the impact of https://github.com/apache/airflow/pull/41727#discussion_r1730836865', 'created_at': datetime.datetime(2024, 8, 26, 7, 48, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309602342, 'issue_id': 2472028801, 'author': 'eladkal', 'body': '> Lets wait with merge till we understand the impact of [#41727 (comment)](https://github.com/apache/airflow/pull/41727#discussion_r1730836865)\r\n\r\nrelevant code was reverted. We are good to go here.', 'created_at': datetime.datetime(2024, 8, 26, 8, 6, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2335097142, 'issue_id': 2472028801, 'author': 'romsharon98', 'body': 'I think that after the [consensus](https://lists.apache.org/thread/1ltpczo121tgk2pzx31bgsk0zj4s5o6x) we can remove the request change @eladkal.', 'created_at': datetime.datetime(2024, 9, 7, 7, 3, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2335161119, 'issue_id': 2472028801, 'author': 'potiuk', 'body': 'LGTM in general.  Tests are failing and need to be fixed, and I added few comments that should be resolved before merging that one. Also I think we should figure out (but that might be next) how to get example_dags to display them in Airflow 3 from provider (likely change/extend from where they are loaded) - but this should be a separate PR, likely when we have few more examples moved.', 'created_at': datetime.datetime(2024, 9, 7, 11, 42, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2351515949, 'issue_id': 2472028801, 'author': 'gopidesupavan', 'body': '@romsharon98 just checking is the changes required in here https://github.com/apache/airflow/blob/main/docs/apache-airflow/operators-and-hooks-ref.rst?plain=1#L91 ?', 'created_at': datetime.datetime(2024, 9, 15, 10, 18, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2352241084, 'issue_id': 2472028801, 'author': 'romsharon98', 'body': '> @romsharon98 just checking is the changes required in here https://github.com/apache/airflow/blob/main/docs/apache-airflow/operators-and-hooks-ref.rst?plain=1#L91 ?\r\n\r\ngood catch! I will modify it ðŸ˜„', 'created_at': datetime.datetime(2024, 9, 16, 7, 57, 45, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-25 11:28:30 UTC): One more thing - at least for now, ""standard"" should be added to list of preinstalled providers in `hatch_build.py` 

```
PRE_INSTALLED_PROVIDERS = [
    ""common.compat"",
    ""common.io"",
    ""common.sql"",
    ""fab>=1.0.2"",
    ""ftp"",
    ""http"",
    ""imap"",
    ""smtp"",
    ""sqlite"",
]
```

potiuk on (2024-08-25 11:29:08 UTC): We might change where it is added in Airflow 3, but for now it should be added here.

potiuk on (2024-08-25 11:34:12 UTC): 1. we need to deprecate the existed operators in core


2. we are missing all the operators (currently it's only for time operators)


3. I am not sure what about the hooks folder?

gopidesupavan on (2024-08-25 11:36:31 UTC): Thanks @romsharon98 , will be adding rest of the operators and sensors to this.

gopidesupavan on (2024-08-25 11:37:50 UTC): @eladkal me and romsharon discussed , i will be adding rest of the operators and sensors.

potiuk on (2024-08-25 11:40:56 UTC): Ah .. so no ... We should not add it to preinstalled just **yet** - until we release it (sorry @romsharon98 -> see the failure on openapi client).

eladkal on (2024-08-25 11:43:26 UTC): Then I propose this PR to remove the files from main that we migrated to the provider.
The PR to v2-10-test would be just to replace the classes with deprecation notes after we release the provider.

potiuk on (2024-08-25 11:47:04 UTC): This is what the PR does.

<img width=""767"" alt=""Screenshot 2024-08-25 at 13 46 45"" src=""https://github.com/user-attachments/assets/a2090679-334f-4f79-8d87-a775d17bde13"">

eladkal on (2024-08-25 11:50:03 UTC): Ah! I didn't see changes to `airflow/core` folder so I assumed it was missed.
Not very friendly UX design from GitHub

gopidesupavan on (2024-08-25 11:50:56 UTC): Please correct me if i understood this, on v2-10-test deprecation updates required for all the changes we are doing on main?

potiuk on (2024-08-25 11:54:21 UTC): No - only those that are supposed to affect DAG authors.

potiuk on (2024-08-25 12:02:01 UTC): BTW. We **will** have to make the old ""standard"" providers still work in Airflow 3 I **think** so we will have to make the old operator imports work (likely with the mechanism mentioned by @ashb - `sys.meta_path`) - otherwise it will `require` many dags to change. I think we should apply the same mechanism as we will do for importing BaseOperator etc. in Airflow 3 (and still raise deprecation warning).

@ashb ? Do you agree ?

potiuk on (2024-08-25 16:24:22 UTC): Interesting. The errors we see are very useful :).

1) examples are part of the documentation of ""main"" airflow"" - and I am afraid they will have to remain as examples in ""airflow"" not moved to provider, especially because point 2)...

2) the examples should be embedded and shown in airflow when ""examples"" are enabled - I think we should not (at least not now) to develop a mechanism to read examples for Airflow from providers.

3) The tests should also mock the moved packages.

```
<module 'airflow.sensors.time_delta' from '/usr/local/lib/python3.8/site-packages/airflow/sensors/time_delta.py'> does not have the attribute 'sleep'
FAILED tests/providers/standard/time/sensors/test_time_delta.py::TestTimeDeltaSensorAsync::test_wait_sensor[True] - AttributeError: <module 'airflow.sensors.time_delta' from '/u
```

romsharon98 (Issue Creator) on (2024-08-25 20:02:43 UTC): revert the example dags to be under `main` airflow.
should I add a link in index.yaml for those example dags? 

also not sure but should I change somewhere in the code to tell that this provider is mandatory and will auto installed?

potiuk on (2024-08-25 20:04:37 UTC): That's the preinstalled_providers - but it will only work after it's been released and it will likely change with Airflow 3 so for now - no need.

gopidesupavan on (2024-08-25 20:31:59 UTC): so for time related things its placed under time/ , for other operators and sensors am placing like this . 

standard/core/operators/
standard/core/sensors/

is this fine? or any other suggestion.

eladkal on (2024-08-26 07:48:13 UTC): Lets wait with merge till we understand the impact of https://github.com/apache/airflow/pull/41727#discussion_r1730836865

eladkal on (2024-08-26 08:06:47 UTC): relevant code was reverted. We are good to go here.

romsharon98 (Issue Creator) on (2024-09-07 07:03:08 UTC): I think that after the [consensus](https://lists.apache.org/thread/1ltpczo121tgk2pzx31bgsk0zj4s5o6x) we can remove the request change @eladkal.

potiuk on (2024-09-07 11:42:05 UTC): LGTM in general.  Tests are failing and need to be fixed, and I added few comments that should be resolved before merging that one. Also I think we should figure out (but that might be next) how to get example_dags to display them in Airflow 3 from provider (likely change/extend from where they are loaded) - but this should be a separate PR, likely when we have few more examples moved.

gopidesupavan on (2024-09-15 10:18:38 UTC): @romsharon98 just checking is the changes required in here https://github.com/apache/airflow/blob/main/docs/apache-airflow/operators-and-hooks-ref.rst?plain=1#L91 ?

romsharon98 (Issue Creator) on (2024-09-16 07:57:45 UTC): good catch! I will modify it ðŸ˜„

"
2471947266,pull_request,closed,,Fix `EmrCreateJobFlowOperator` using deferrable mode with `wait_for_completion`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements. See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership. The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License. You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied. See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

### Summary of Changes
This PR addresses issue #40966 by modifying the logic in the `EmrCreateJobFlowOperator` to ensure that the `deferrable` argument only activates the deferral trigger when `wait_for_completion` is also set to `True`. Previously, the deferral trigger would be added regardless of the `wait_for_completion` setting, leading to unintended behavior.

### Changes Made:
- Updated the condition for deferring to check both `deferrable` and `wait_for_completion`.
- Adjusted the condition for synchronous waiting to occur only when `wait_for_completion=True` and `deferrable=False`.


Please review the changes, and let me know if further adjustments are needed.

Closes: https://github.com/apache/airflow/issues/40966
",laksh-krishna-sharma,2024-08-18 12:33:08+00:00,[],2024-09-23 14:17:55+00:00,2024-09-22 23:27:22+00:00,https://github.com/apache/airflow/pull/41561,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2295245962, 'issue_id': 2471947266, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 18, 12, 33, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295401096, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': 'Thank you for letting me know, @shahar1. I will make the changes and add comments again . I\'ll update you once the problem is resolved.""', 'created_at': datetime.datetime(2024, 8, 18, 21, 33, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295406553, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': '@shahar1 sir please review the update.', 'created_at': datetime.datetime(2024, 8, 18, 21, 47, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296689428, 'issue_id': 2471947266, 'author': 'vincbeck', 'body': 'Can you please add unit tests?', 'created_at': datetime.datetime(2024, 8, 19, 14, 15, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307487355, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': '@shahar1 sir could you please advise on the appropriate folder for placing unit test cases?', 'created_at': datetime.datetime(2024, 8, 23, 17, 9, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307693418, 'issue_id': 2471947266, 'author': 'shahar1', 'body': '> @shahar1 sir could you please advise on the appropriate folder for placing unit test cases?\n\n`tests/providers/amazon/aws/operators/`, and there check all the files that start with `emr_`.', 'created_at': datetime.datetime(2024, 8, 23, 19, 30, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310338991, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': ""@shahar1 sir and @vincbeck sir I've added unit test cases and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement."", 'created_at': datetime.datetime(2024, 8, 26, 14, 20, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310376123, 'issue_id': 2471947266, 'author': 'vincbeck', 'body': ""> @shahar1 sir and @vincbeck sir I've added unit test cases and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement.\r\n\r\nThanks for doing it! The tests are pretty good!"", 'created_at': datetime.datetime(2024, 8, 26, 14, 37, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310503961, 'issue_id': 2471947266, 'author': 'shahar1', 'body': 'Looks great!', 'created_at': datetime.datetime(2024, 8, 26, 15, 37, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310530102, 'issue_id': 2471947266, 'author': 'vincbeck', 'body': 'Some tests are failing, could you check that please?', 'created_at': datetime.datetime(2024, 8, 26, 15, 50, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310530254, 'issue_id': 2471947266, 'author': 'vincbeck', 'body': 'https://github.com/apache/airflow/actions/runs/10561464118/job/29259176171?pr=41561', 'created_at': datetime.datetime(2024, 8, 26, 15, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310876845, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': ""Thank you for your review @vincbeck and @shahar1. I will investigate the issue and address the failing tests as soon as possible. I'll update once the problem is resolved."", 'created_at': datetime.datetime(2024, 8, 26, 19, 4, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2359480319, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': ""@shahar1 sir and @vincbeck sir I've added unit test cases and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement but i am stuck in resolving these errors please sir can you guide me to resolve these issue"", 'created_at': datetime.datetime(2024, 9, 18, 22, 1, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2361433287, 'issue_id': 2471947266, 'author': 'shahar1', 'body': ""> @shahar1 sir and @vincbeck sir I've added unit test cases and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement but i am stuck in resolving these errors please sir can you guide me to resolve these issue\r\n\r\nHello, here's some guidance:\r\n1. In `test_create_job_flow_deferrable` you need to set `self.operator.wait_for_completion = True` (otherwise it won't pass the first if).\r\n1. In `test_deferrable_and_wait_for_completion`, when you call the `assert` statement you create a new instance of `EmrCreateJobFlowTrigger` - which will always be different than the instance that is created by the original function.\r\nI'd suggest to mock `EmrCreateJobFlowTrigger` (let's call it `mock_trigger`) and then you could assert on `trigger=mock_trigger.return_value`. \r\nYou could also create a separate assertion for the attributes of `mock_trigger` to ensure that all the parameters are as expected.\r\n\r\nAlso, please notice that you need to resolve conflicts by merging/rebasing from `main`.\r\nPlease let me know if you encounter any issues."", 'created_at': datetime.datetime(2024, 9, 19, 16, 7, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2362391785, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': 'Thank you for your help, @shahar1 sir. Iâ€™ve resolved the issue, and all checks have now passed on GitHub. I really appreciate your guidance!', 'created_at': datetime.datetime(2024, 9, 19, 23, 54, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2363965032, 'issue_id': 2471947266, 'author': 'vincbeck', 'body': 'There is a conflict now :)', 'created_at': datetime.datetime(2024, 9, 20, 15, 14, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2364748096, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': 'Sir, I resolved the branch conflict. Please review the updates.', 'created_at': datetime.datetime(2024, 9, 20, 23, 28, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2364791765, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': ""@shahar1 sir and @vincbeck sir I've tried to resolve conflict and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement but i am stuck in resolving these errors please sir can you guide me to resolve these issue"", 'created_at': datetime.datetime(2024, 9, 21, 0, 56, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2365040705, 'issue_id': 2471947266, 'author': 'shahar1', 'body': '> @shahar1 sir and @vincbeck sir I\'ve tried to resolve conflict and done my best to cover the expected behaviors. As I\'m a beginner, I\'d greatly appreciate your feedback and any suggestions for improvement but i am stuck in resolving these errors please sir can you guide me to resolve these issue\r\n\r\nTake a look at this part:\r\n```python\r\n        mock_defer.assert_called_once_with(\r\n            trigger=EmrCreateJobFlowTrigger( # <- New instance\r\n                job_flow_id=JOB_FLOW_ID,\r\n                aws_conn_id=self.operator.aws_conn_id,\r\n                waiter_delay=self.operator.waiter_delay,\r\n                waiter_max_attempts=self.operator.waiter_max_attempts,\r\n            ),\r\n            method_name=""execute_complete"",\r\n            timeout=timedelta(seconds=self.operator.waiter_max_attempts * self.operator.waiter_delay + 60),\r\n        )\r\n```\r\n\r\nAs I previously wrote, here you create a new instance of `EmrCreateJobFlowTrigger` - which means that it will always be different than the instance created within the [trigger](https://github.com/apache/airflow/blob/3cea4fdc9e5ff55c0fb87d3f57e0be3fba520f28/airflow/providers/amazon/aws/operators/emr.py#L833) attribute of `defer()`. Try to find a way to patch the creation of this instance, so they\'ll become the same entity. Then, it will be easier for you to compare them.', 'created_at': datetime.datetime(2024, 9, 21, 7, 20, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2365269548, 'issue_id': 2471947266, 'author': 'laksh-krishna-sharma', 'body': 'Thank you, @bitomukesh , for helping resolve the error! I really appreciate your assistance!""', 'created_at': datetime.datetime(2024, 9, 21, 17, 57, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2368418334, 'issue_id': 2471947266, 'author': 'vincbeck', 'body': 'Why closing it @laksh-krishna-sharma?', 'created_at': datetime.datetime(2024, 9, 23, 14, 17, 53, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-18 12:33:12 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

laksh-krishna-sharma (Issue Creator) on (2024-08-18 21:33:21 UTC): Thank you for letting me know, @shahar1. I will make the changes and add comments again . I'll update you once the problem is resolved.""

laksh-krishna-sharma (Issue Creator) on (2024-08-18 21:47:09 UTC): @shahar1 sir please review the update.

vincbeck on (2024-08-19 14:15:53 UTC): Can you please add unit tests?

laksh-krishna-sharma (Issue Creator) on (2024-08-23 17:09:54 UTC): @shahar1 sir could you please advise on the appropriate folder for placing unit test cases?

shahar1 on (2024-08-23 19:30:30 UTC): `tests/providers/amazon/aws/operators/`, and there check all the files that start with `emr_`.

laksh-krishna-sharma (Issue Creator) on (2024-08-26 14:20:49 UTC): @shahar1 sir and @vincbeck sir I've added unit test cases and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement.

vincbeck on (2024-08-26 14:37:03 UTC): Thanks for doing it! The tests are pretty good!

shahar1 on (2024-08-26 15:37:02 UTC): Looks great!

vincbeck on (2024-08-26 15:50:55 UTC): Some tests are failing, could you check that please?

vincbeck on (2024-08-26 15:51:00 UTC): https://github.com/apache/airflow/actions/runs/10561464118/job/29259176171?pr=41561

laksh-krishna-sharma (Issue Creator) on (2024-08-26 19:04:11 UTC): Thank you for your review @vincbeck and @shahar1. I will investigate the issue and address the failing tests as soon as possible. I'll update once the problem is resolved.

laksh-krishna-sharma (Issue Creator) on (2024-09-18 22:01:14 UTC): @shahar1 sir and @vincbeck sir I've added unit test cases and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement but i am stuck in resolving these errors please sir can you guide me to resolve these issue

shahar1 on (2024-09-19 16:07:04 UTC): Hello, here's some guidance:
1. In `test_create_job_flow_deferrable` you need to set `self.operator.wait_for_completion = True` (otherwise it won't pass the first if).
1. In `test_deferrable_and_wait_for_completion`, when you call the `assert` statement you create a new instance of `EmrCreateJobFlowTrigger` - which will always be different than the instance that is created by the original function.
I'd suggest to mock `EmrCreateJobFlowTrigger` (let's call it `mock_trigger`) and then you could assert on `trigger=mock_trigger.return_value`. 
You could also create a separate assertion for the attributes of `mock_trigger` to ensure that all the parameters are as expected.

Also, please notice that you need to resolve conflicts by merging/rebasing from `main`.
Please let me know if you encounter any issues.

laksh-krishna-sharma (Issue Creator) on (2024-09-19 23:54:14 UTC): Thank you for your help, @shahar1 sir. Iâ€™ve resolved the issue, and all checks have now passed on GitHub. I really appreciate your guidance!

vincbeck on (2024-09-20 15:14:25 UTC): There is a conflict now :)

laksh-krishna-sharma (Issue Creator) on (2024-09-20 23:28:22 UTC): Sir, I resolved the branch conflict. Please review the updates.

laksh-krishna-sharma (Issue Creator) on (2024-09-21 00:56:55 UTC): @shahar1 sir and @vincbeck sir I've tried to resolve conflict and done my best to cover the expected behaviors. As I'm a beginner, I'd greatly appreciate your feedback and any suggestions for improvement but i am stuck in resolving these errors please sir can you guide me to resolve these issue

shahar1 on (2024-09-21 07:20:17 UTC): Take a look at this part:
```python
        mock_defer.assert_called_once_with(
            trigger=EmrCreateJobFlowTrigger( # <- New instance
                job_flow_id=JOB_FLOW_ID,
                aws_conn_id=self.operator.aws_conn_id,
                waiter_delay=self.operator.waiter_delay,
                waiter_max_attempts=self.operator.waiter_max_attempts,
            ),
            method_name=""execute_complete"",
            timeout=timedelta(seconds=self.operator.waiter_max_attempts * self.operator.waiter_delay + 60),
        )
```

As I previously wrote, here you create a new instance of `EmrCreateJobFlowTrigger` - which means that it will always be different than the instance created within the [trigger](https://github.com/apache/airflow/blob/3cea4fdc9e5ff55c0fb87d3f57e0be3fba520f28/airflow/providers/amazon/aws/operators/emr.py#L833) attribute of `defer()`. Try to find a way to patch the creation of this instance, so they'll become the same entity. Then, it will be easier for you to compare them.

laksh-krishna-sharma (Issue Creator) on (2024-09-21 17:57:39 UTC): Thank you, @bitomukesh , for helping resolve the error! I really appreciate your assistance!""

vincbeck on (2024-09-23 14:17:53 UTC): Why closing it @laksh-krishna-sharma?

"
2471918484,pull_request,open,,Adding config max_active_tasks_include_deferred,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

Adding max_active_tasks_include_deferred.

max_active_tasks should take in account the deferred task when max_active_tasks_include_deferred=true

closes: #40528
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #40528
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-08-18 11:18:26+00:00,[],2025-01-11 00:15:28+00:00,,https://github.com/apache/airflow/pull/41560,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2299708676, 'issue_id': 2471918484, 'author': 'gopidesupavan', 'body': 'Hi , can you please help me , which airflow_version should i set in the migration file?', 'created_at': datetime.datetime(2024, 8, 20, 20, 29, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299778718, 'issue_id': 2471918484, 'author': 'gopidesupavan', 'body': 'I am not sure exact version :), so have updated to 3.0.0 version, but please let me know if this version needs to be changed.', 'created_at': datetime.datetime(2024, 8, 20, 21, 14, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303615075, 'issue_id': 2471918484, 'author': 'uranusjr', 'body': 'This should be 3.0; we are not adding new features to 2.x at this point (unless they help the 2-3 migration; this one does not).', 'created_at': datetime.datetime(2024, 8, 22, 3, 44, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2305510621, 'issue_id': 2471918484, 'author': 'gopidesupavan', 'body': '> This should be 3.0; we are not adding new features to 2.x at this point (unless they help the 2-3 migration; this one does not).\r\n\r\nSure thank you @uranusjr :).', 'created_at': datetime.datetime(2024, 8, 22, 19, 47, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445419179, 'issue_id': 2471918484, 'author': 'kmehkeri', 'body': 'Could this new parameter affect in the same way all params that control concurrency?\r\n* max_active_tasks\r\n* max_active_tasks_per_dag\r\n* concurrency\r\n* max_active_tis_per_dag\r\n* max_active_tis_per_dagrun', 'created_at': datetime.datetime(2024, 10, 29, 22, 8, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498628333, 'issue_id': 2471918484, 'author': 'ewelinastr', 'body': '> Could this new parameter affect in the same way all params that control concurrency?\r\n> \r\n> * max_active_tasks\r\n> * max_active_tasks_per_dag\r\n> * concurrency\r\n> * max_active_tis_per_dag\r\n> * max_active_tis_per_dagrun\r\n\r\nYep better option would be to have one config include_deferred=true for all of this above', 'created_at': datetime.datetime(2024, 11, 25, 17, 30, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500368338, 'issue_id': 2471918484, 'author': 'gopidesupavan', 'body': '> Could this new parameter affect in the same way all params that control concurrency?\r\n> \r\n> * max_active_tasks\r\n> * max_active_tasks_per_dag\r\n> * concurrency\r\n> * max_active_tis_per_dag\r\n> * max_active_tis_per_dagrun\r\n\r\nnot all parameters it to applicable, this is at dag level.', 'created_at': datetime.datetime(2024, 11, 26, 11, 21, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501701162, 'issue_id': 2471918484, 'author': 'gopidesupavan', 'body': ""> > Could this new parameter affect in the same way all params that control concurrency?\r\n> > \r\n> > * max_active_tasks\r\n> > * max_active_tasks_per_dag\r\n> > * concurrency\r\n> > * max_active_tis_per_dag\r\n> > * max_active_tis_per_dagrun\r\n> \r\n> Yep better option would be to have one config include_deferred=true for all of this above\r\n\r\nI'm uncertain whether adding this configuration to all the existing configurations might introduce additional complexity or potential side effects; I'll need to investigate further.\r\n\r\nIf anyone has any opinions or insights on this, please feel free to share."", 'created_at': datetime.datetime(2024, 11, 26, 18, 55, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2584944565, 'issue_id': 2471918484, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 11, 0, 15, 27, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-08-20 20:29:01 UTC): Hi , can you please help me , which airflow_version should i set in the migration file?

gopidesupavan (Issue Creator) on (2024-08-20 21:14:42 UTC): I am not sure exact version :), so have updated to 3.0.0 version, but please let me know if this version needs to be changed.

uranusjr on (2024-08-22 03:44:02 UTC): This should be 3.0; we are not adding new features to 2.x at this point (unless they help the 2-3 migration; this one does not).

gopidesupavan (Issue Creator) on (2024-08-22 19:47:13 UTC): Sure thank you @uranusjr :).

kmehkeri on (2024-10-29 22:08:31 UTC): Could this new parameter affect in the same way all params that control concurrency?
* max_active_tasks
* max_active_tasks_per_dag
* concurrency
* max_active_tis_per_dag
* max_active_tis_per_dagrun

ewelinastr on (2024-11-25 17:30:32 UTC): Yep better option would be to have one config include_deferred=true for all of this above

gopidesupavan (Issue Creator) on (2024-11-26 11:21:05 UTC): not all parameters it to applicable, this is at dag level.

gopidesupavan (Issue Creator) on (2024-11-26 18:55:35 UTC): I'm uncertain whether adding this configuration to all the existing configurations might introduce additional complexity or potential side effects; I'll need to investigate further.

If anyone has any opinions or insights on this, please feel free to share.

github-actions[bot] on (2025-01-11 00:15:27 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2471869054,pull_request,closed,,Prepare docs for Aug 2nd wave of providers,,eladkal,2024-08-18 09:04:43+00:00,[],2024-08-19 06:11:55+00:00,2024-08-19 06:11:52+00:00,https://github.com/apache/airflow/pull/41559,"[('area:providers', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-beam', ''), ('provider:apache-drill', ''), ('provider:apache-cassandra', ''), ('provider:apache-flink', ''), ('provider:apache-hdfs', '')]","[{'comment_id': 2295743160, 'issue_id': 2471869054, 'author': 'eladkal', 'body': 'merging, no need to refresh the changelog generation as no new commits for providers', 'created_at': datetime.datetime(2024, 8, 19, 6, 11, 47, tzinfo=datetime.timezone.utc)}]","eladkal (Issue Creator) on (2024-08-19 06:11:47 UTC): merging, no need to refresh the changelog generation as no new commits for providers

"
2471743087,pull_request,closed,,Make CronTriggerTimetable startup behavior intuitive,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The first run behavior for cron based DAGs (and most DAGs really) is quite unintuitive. It is very common for users to want to run a DAG for the first time either immediately, with a logical date of the past run that would have occurred most recently, or to wait until the next run time and then begin. The former is only possible if you set catchup to False and the latter is not possible without knowing ahead of time when that next run would be and hardcoding the start time for the DAG (which is not feasible when doing dev/text/prod environment promotion of the same DAG file). 

It is also very common to set the start_date to a dynamic function that calculates a date in the recent past, such as days_ago(1), which can bite you if you're used to doing that (or have coded it into a DAG factory pattern) and then you set up your first monthly DAG. The existing timetables behavior is to silently miss the run, which makes it even worse.

This PR adds the ability to set start_date to `None` and get the intuitive behavior of running the last run if that run would have happened in the very recent past (10% of the distance between DAG runs) or to wait for the next run otherwise. It also allows using the `run_immediately` parameter to specify always running the last run, always waiting for the next run, or passing a timedelta to exactly control what ""recent past"" means for this particular DAG. Setting start_date to `None` is a much more accurate and clear indication of author intent that `days_ago(x)`.

I hope that if this is widely adopted, we can stop seeing users miss DAG runs or using dynamic start dates.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",collinmcnulty,2024-08-18 01:56:12+00:00,[],2024-10-25 20:39:35+00:00,2024-10-25 20:39:35+00:00,https://github.com/apache/airflow/pull/41558,"[('area:core', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]","[{'comment_id': 2295063424, 'issue_id': 2471743087, 'author': 'collinmcnulty', 'body': 'The ""best practice"" for having the first run begin at the most recent run is to set the start_date far in the past and catchup=False, but I think having a meaningless date passed to start_date is not a good thing for Airflow to need and doesn\'t match author intent.', 'created_at': datetime.datetime(2024, 8, 18, 2, 1, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296563885, 'issue_id': 2471743087, 'author': 'collinmcnulty', 'body': ""I found a logical bug. Setting to False creates a race condition to actually schedule the first run. We'll need some minimum buffer time where the next run time does not update even when `run_immediately=False`"", 'created_at': datetime.datetime(2024, 8, 19, 13, 20, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307398798, 'issue_id': 2471743087, 'author': 'collinmcnulty', 'body': ""@uranusjr We spoke about what CronDataInterval's behavior is when start_date is None, but I found that the DAG object actually restricts you from setting start date to None. This, I believe, is no longer necessary, and actually the CronDataIntervalTimetable's behavior as written seems sensible, it's just not accessible. I added a commit to remove that restriction on start_date"", 'created_at': datetime.datetime(2024, 8, 23, 16, 15, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320402750, 'issue_id': 2471743087, 'author': 'uranusjr', 'body': 'Needs to resolve conflicts but otherwise looks good to me.', 'created_at': datetime.datetime(2024, 8, 30, 7, 56, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412570456, 'issue_id': 2471743087, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 15, 0, 15, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426555967, 'issue_id': 2471743087, 'author': 'collinmcnulty', 'body': ""@uranusjr I don't think this test failure is related to the change. I merged in the changes from main and think this new version should be ready to merge."", 'created_at': datetime.datetime(2024, 10, 21, 12, 38, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435882044, 'issue_id': 2471743087, 'author': 'potiuk', 'body': 'You need to rebase - there are conflicts. That should also address the issue with unrelated test failing @collinmcnulty', 'created_at': datetime.datetime(2024, 10, 24, 17, 13, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435915770, 'issue_id': 2471743087, 'author': 'potiuk', 'body': 'Smth is wrong. There are a LOT of changes', 'created_at': datetime.datetime(2024, 10, 24, 17, 29, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435960140, 'issue_id': 2471743087, 'author': 'collinmcnulty', 'body': 'I believe I fixed it. Someone else had made the changes to the dag model to allow None in the meantime while this PR was languishing, so now its only about CronTriggerTimetable itself.', 'created_at': datetime.datetime(2024, 10, 24, 17, 43, 45, tzinfo=datetime.timezone.utc)}]","collinmcnulty (Issue Creator) on (2024-08-18 02:01:20 UTC): The ""best practice"" for having the first run begin at the most recent run is to set the start_date far in the past and catchup=False, but I think having a meaningless date passed to start_date is not a good thing for Airflow to need and doesn't match author intent.

collinmcnulty (Issue Creator) on (2024-08-19 13:20:12 UTC): I found a logical bug. Setting to False creates a race condition to actually schedule the first run. We'll need some minimum buffer time where the next run time does not update even when `run_immediately=False`

collinmcnulty (Issue Creator) on (2024-08-23 16:15:01 UTC): @uranusjr We spoke about what CronDataInterval's behavior is when start_date is None, but I found that the DAG object actually restricts you from setting start date to None. This, I believe, is no longer necessary, and actually the CronDataIntervalTimetable's behavior as written seems sensible, it's just not accessible. I added a commit to remove that restriction on start_date

uranusjr on (2024-08-30 07:56:59 UTC): Needs to resolve conflicts but otherwise looks good to me.

github-actions[bot] on (2024-10-15 00:15:11 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

collinmcnulty (Issue Creator) on (2024-10-21 12:38:50 UTC): @uranusjr I don't think this test failure is related to the change. I merged in the changes from main and think this new version should be ready to merge.

potiuk on (2024-10-24 17:13:03 UTC): You need to rebase - there are conflicts. That should also address the issue with unrelated test failing @collinmcnulty

potiuk on (2024-10-24 17:29:53 UTC): Smth is wrong. There are a LOT of changes

collinmcnulty (Issue Creator) on (2024-10-24 17:43:45 UTC): I believe I fixed it. Someone else had made the changes to the dag model to allow None in the meantime while this PR was languishing, so now its only about CronTriggerTimetable itself.

"
2471627584,pull_request,closed,,Wait sensor async,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

There is an example of a deferrable sensor that waits for one hour [in the documentation](https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/deferring.html#writing-deferrable-operators), but there has not yet been an implementation of such a sensor in Airflow. This seems like a such a basic use case that it would make sense to include. There is the TimeDeltaSensor, but this sensor is based on the data interval of the DAG run, not the start time of the task.

I have observed some Airflow users using BashOperators that sleep for a specified time for want of this sensor, which would be strictly better, especially when run as deferrable.

<!-- Please keep an empty line above the dashes. -->
---



**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",collinmcnulty,2024-08-17 18:41:16+00:00,[],2024-08-20 19:50:55+00:00,2024-08-20 19:50:55+00:00,https://github.com/apache/airflow/pull/41557,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2471627028,pull_request,closed,,New provider for Magento open  source,"This pull request introduces a new Magento provider for Apache Airflow. This provider includes basic operators and hooks to facilitate interaction with Magento's API, allowing users to efficiently fetch and process Magento orders and other related data.

Features Implemented:

GetOrdersOperator:

Fetches sales orders from Magento based on the specified status.
Integrates with Magento's REST API to retrieve order details.

Key Components:

MagentoHook: A hook to connect and interact with Magento's API using OAuth authentication.
GetOrdersOperator: Custom operator to retrieve sales orders from Magento.

Configuration:

Magento Connection: Configure the Magento connection (magento_default) in Airflow to provide OAuth API credentials.
",sivajik34,2024-08-17 18:39:18+00:00,[],2024-10-12 00:14:37+00:00,2024-10-12 00:14:37+00:00,https://github.com/apache/airflow/pull/41556,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', '')]","[{'comment_id': 2294938821, 'issue_id': 2471627028, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 17, 18, 39, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295379965, 'issue_id': 2471627028, 'author': 'potiuk', 'body': ""And to add to what @hussein-awala wrote - it's not very likely we will accept magento as managed by the community - we need to be able to support providers in the community and I guess magento is something rather niche that is likely better to host and release as your own provider @sivajik34 - there is no particular reason we should accept every single e-commerce provider as something that Airflow community will manage - it's much better to be managed by somoene who uses and cares about magento (i.e. you or magento community in general).\r\n\r\nJust to set expectations - taking over support for such providers be the community is a liability not an asset and we are not going to take it over unless\r\n\r\na) community is convinced it is very popular and its' good to be managed in the Airflow communiyt\r\nb) community is convinced that there is a reputable entitty that wil make sure all integration is working there \r\n\r\nSee system test dashboards https://airflow.apache.org/ecosystem/#airflow-provider-system-test-dashboards"", 'created_at': datetime.datetime(2024, 8, 18, 20, 24, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295543149, 'issue_id': 2471627028, 'author': 'kodurusivakumar34', 'body': '@potiuk\n\nThank you for your feedback on the pull request for the Magento provider. I understand the concerns raised and would like to address them with two proposed solutions:\n\n**Option 1: Separate Repository for Third-Party Providers**\n\nI propose creating a dedicated repository for third-party providers that are less central to the core Airflow functionality. This repository would serve as a central location where users can find and review all available third-party providers. It would also simplify the process for contributors to add new providers and for users to discover them. \n\n**Pros:**\n- Keeps the main Airflow repository focused on core providers.\n- Provides a single location for all third-party providers.\n- Simplifies contribution and discovery of third-party providers.\n\n**Cons:**\n- Users would need to check a separate repository for third-party providers.\n- Requires additional effort to maintain and coordinate updates across repositories.\n\n**Option 2: Separate Folder with Flag in `provider.yaml`**\n\nAlternatively, we could maintain third-party providers within a designated folder in the main repository and use a flag in the `provider.yaml` file to distinguish between core and third-party providers. This approach would keep everything within the main repository while clearly indicating the status and type of each provider.\n\n**Pros:**\n- Keeps all providers within a single repository for easier access.\n- Allows clear differentiation between core and third-party providers.\n- Immediate awareness of third-party providers through the `provider.yaml` flag.\n\n**Cons:**\n- Potential for increased clutter within the main repository.\n- Requires additional management for the flag system in `provider.yaml`.\n\nI am open to discussing these options further or considering any other recommendations the community may have. My goal is to contribute to Airflow in a way that aligns with best practices and meets the needs of the community.\n\nThank you for your consideration.', 'created_at': datetime.datetime(2024, 8, 19, 2, 18, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296094645, 'issue_id': 2471627028, 'author': 'raphaelauv', 'body': '@sivajik34 what is magento ?\r\n\r\nis this project https://github.com/magento/magento2 ?', 'created_at': datetime.datetime(2024, 8, 19, 9, 24, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296101355, 'issue_id': 2471627028, 'author': 'kodurusivakumar34', 'body': '@raphaelauv Yes. It is an ecommerce framework.\n\nAdobe commerce is an enterprise product.\nMagento is Open source product.\nMagento open source+ extra features= Adobe commerce.\nhttps://business.adobe.com/products/magento/magento-commerce.html', 'created_at': datetime.datetime(2024, 8, 19, 9, 27, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296204906, 'issue_id': 2471627028, 'author': 'potiuk', 'body': '@kodurusivakumar34 -> Those options are not really feasible. Apache Airflow is a project belonging to the Apache Software Foundation and whatever we keep and release - formally - as an ""Apache Software Foundation software"" has to be released formaly and legally using the ASF processess and governance. \r\n\r\nThat includes responsibilty for managing the releases, security fixes, and more - PMC members have to approve and review every such release and we cannot endores or promote 3rd-party managed software to be released without the overhead incurred: review process, PMC and committers approval, licence compliance, security process and policies clear maintenance rules etc. etc.\r\n\r\nAnything that is released or hosted in ""apache"" repositories, has to have the ASF ""stamp of approval"" so to speak.\r\n\r\nYou can start reading here if you are interested https://www.apache.org/legal/release-policy.html  - but there are more links to follow when you read it. This is legal, compliance and governance issue, not a technical issue which prevents the ASF to be legally responsible for 3rd-party software that it does not have any control over, once the software gets contributed to the ASF it becomes ""The ASF"" software - with all the requirements and expectations that come with it.\r\n\r\nBut there is nothing to prevent any other entities to build such a repository of 3rd-party providers or index them. For example there is https://registry.astronomer.io/ where you can browse various airflow providers. And you - or anyone else - can release magento provider on their own and submit it to such registries.', 'created_at': datetime.datetime(2024, 8, 19, 10, 12, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296212411, 'issue_id': 2471627028, 'author': 'potiuk', 'body': 'BTW. This is where https://airflow.apache.org/ecosystem/ page exist. If you look at the top:\r\n\r\n> These resources and services are not maintained, nor endorsed by the Apache AirflowÂ® Community and Apache Airflow project (maintained by the Committers and the Airflow PMC). Use them at your sole discretion. The community does not verify the licences nor validity of those tools, so itâ€™s your responsibility to verify them.\r\n\r\n> If you would you like to be included on this page, please reach out to the [Apache Airflow dev or user mailing list](https://airflow.apache.org/community/) and let us know or simply open a Pull Request to that page.\r\n\r\nWe simply cannot - according to the ASF rules - mix ""community"" and ""3rd-party"" software - and such ""ecosystem"" page with clear indication that this is 3rd-party is the way we ""clearly separate"" these.', 'created_at': datetime.datetime(2024, 8, 19, 10, 15, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296220641, 'issue_id': 2471627028, 'author': 'potiuk', 'body': 'BTW. I see you already have https://github.com/sivajik34/magento-airflow I see you already host your provider. So the easiest way to make it discoverable is to add link to it to the ""ecosystem"" page.', 'created_at': datetime.datetime(2024, 8, 19, 10, 19, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302037816, 'issue_id': 2471627028, 'author': 'sivajik34', 'body': 'Thank you for your feedback. I  will maintain as separate repo.\r\nhttps://pypi.org/project/apache-airflow-provider-magento\r\nhttps://github.com/sivajik34/magento-airflow/tree/main', 'created_at': datetime.datetime(2024, 8, 21, 13, 17, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302048573, 'issue_id': 2471627028, 'author': 'potiuk', 'body': '> Thank you for your feedback. I will maintain as separate repo. https://pypi.org/project/apache-airflow-provider-magento https://github.com/sivajik34/magento-airflow/tree/main\r\n\r\nOne thing though. We do not want to enforce it - and cannot prevent people from creating such name, but generally I think you should not use ""apache-airlfow-providers-magento"" as provider name - it suggests it is an ""apache"" provider where it is not, so I would kindly ask you to change the PyPI name and handle the ownership of that name in PyPI to the ""Apache Airlfow"" pypi organization. You can add me as an owner (`@potiuk`) and I can transfer it there.', 'created_at': datetime.datetime(2024, 8, 21, 13, 22, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302054194, 'issue_id': 2471627028, 'author': 'potiuk', 'body': ""That's not very strong request just request to make a clear distinction - again - we probably won't foirce any action there - even if we could (Apache Airflow is now registered trademark in the US), it's more of a kind request - since it is up 25 minutes, it's likely way easier to change it now rather than some time in the future."", 'created_at': datetime.datetime(2024, 8, 21, 13, 24, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302067572, 'issue_id': 2471627028, 'author': 'sivajik34', 'body': ""Sure .Yesterday I published, I will try to change the name. Thank you\r\n\r\nOn Wed, 21 Aug 2024, 6:55 pm Jarek Potiuk, ***@***.***> wrote:\r\n\r\n> That's not very strong request just request to make a clear distinction -\r\n> again - we probably won't foirce any action there - even if we could\r\n> (Apache Airflow is now registered trademark in the US), it's more of a kind\r\n> request - since it is up 25 minutes, it's likely way easier to change it\r\n> now rather than some time in the future.\r\n>\r\n> â€”\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/apache/airflow/pull/41556#issuecomment-2302054194>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AB2IPHXAHBTYXAFPUBVWOKTZSSILDAVCNFSM6AAAAABMVUF3JOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMBSGA2TIMJZGQ>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>"", 'created_at': datetime.datetime(2024, 8, 21, 13, 30, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2302082548, 'issue_id': 2471627028, 'author': 'potiuk', 'body': '> Sure .Yesterday I published, I will try to change the name. Thank you\r\n\r\nThanks for being responsive - really appreciate!', 'created_at': datetime.datetime(2024, 8, 21, 13, 36, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395235518, 'issue_id': 2471627028, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 6, 0, 16, 31, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-17 18:39:22 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-08-18 20:24:40 UTC): And to add to what @hussein-awala wrote - it's not very likely we will accept magento as managed by the community - we need to be able to support providers in the community and I guess magento is something rather niche that is likely better to host and release as your own provider @sivajik34 - there is no particular reason we should accept every single e-commerce provider as something that Airflow community will manage - it's much better to be managed by somoene who uses and cares about magento (i.e. you or magento community in general).

Just to set expectations - taking over support for such providers be the community is a liability not an asset and we are not going to take it over unless

a) community is convinced it is very popular and its' good to be managed in the Airflow communiyt
b) community is convinced that there is a reputable entitty that wil make sure all integration is working there 

See system test dashboards https://airflow.apache.org/ecosystem/#airflow-provider-system-test-dashboards

kodurusivakumar34 on (2024-08-19 02:18:43 UTC): @potiuk

Thank you for your feedback on the pull request for the Magento provider. I understand the concerns raised and would like to address them with two proposed solutions:

**Option 1: Separate Repository for Third-Party Providers**

I propose creating a dedicated repository for third-party providers that are less central to the core Airflow functionality. This repository would serve as a central location where users can find and review all available third-party providers. It would also simplify the process for contributors to add new providers and for users to discover them. 

**Pros:**
- Keeps the main Airflow repository focused on core providers.
- Provides a single location for all third-party providers.
- Simplifies contribution and discovery of third-party providers.

**Cons:**
- Users would need to check a separate repository for third-party providers.
- Requires additional effort to maintain and coordinate updates across repositories.

**Option 2: Separate Folder with Flag in `provider.yaml`**

Alternatively, we could maintain third-party providers within a designated folder in the main repository and use a flag in the `provider.yaml` file to distinguish between core and third-party providers. This approach would keep everything within the main repository while clearly indicating the status and type of each provider.

**Pros:**
- Keeps all providers within a single repository for easier access.
- Allows clear differentiation between core and third-party providers.
- Immediate awareness of third-party providers through the `provider.yaml` flag.

**Cons:**
- Potential for increased clutter within the main repository.
- Requires additional management for the flag system in `provider.yaml`.

I am open to discussing these options further or considering any other recommendations the community may have. My goal is to contribute to Airflow in a way that aligns with best practices and meets the needs of the community.

Thank you for your consideration.

raphaelauv on (2024-08-19 09:24:37 UTC): @sivajik34 what is magento ?

is this project https://github.com/magento/magento2 ?

kodurusivakumar34 on (2024-08-19 09:27:51 UTC): @raphaelauv Yes. It is an ecommerce framework.

Adobe commerce is an enterprise product.
Magento is Open source product.
Magento open source+ extra features= Adobe commerce.
https://business.adobe.com/products/magento/magento-commerce.html

potiuk on (2024-08-19 10:12:16 UTC): @kodurusivakumar34 -> Those options are not really feasible. Apache Airflow is a project belonging to the Apache Software Foundation and whatever we keep and release - formally - as an ""Apache Software Foundation software"" has to be released formaly and legally using the ASF processess and governance. 

That includes responsibilty for managing the releases, security fixes, and more - PMC members have to approve and review every such release and we cannot endores or promote 3rd-party managed software to be released without the overhead incurred: review process, PMC and committers approval, licence compliance, security process and policies clear maintenance rules etc. etc.

Anything that is released or hosted in ""apache"" repositories, has to have the ASF ""stamp of approval"" so to speak.

You can start reading here if you are interested https://www.apache.org/legal/release-policy.html  - but there are more links to follow when you read it. This is legal, compliance and governance issue, not a technical issue which prevents the ASF to be legally responsible for 3rd-party software that it does not have any control over, once the software gets contributed to the ASF it becomes ""The ASF"" software - with all the requirements and expectations that come with it.

But there is nothing to prevent any other entities to build such a repository of 3rd-party providers or index them. For example there is https://registry.astronomer.io/ where you can browse various airflow providers. And you - or anyone else - can release magento provider on their own and submit it to such registries.

potiuk on (2024-08-19 10:15:36 UTC): BTW. This is where https://airflow.apache.org/ecosystem/ page exist. If you look at the top:



We simply cannot - according to the ASF rules - mix ""community"" and ""3rd-party"" software - and such ""ecosystem"" page with clear indication that this is 3rd-party is the way we ""clearly separate"" these.

potiuk on (2024-08-19 10:19:21 UTC): BTW. I see you already have https://github.com/sivajik34/magento-airflow I see you already host your provider. So the easiest way to make it discoverable is to add link to it to the ""ecosystem"" page.

sivajik34 (Issue Creator) on (2024-08-21 13:17:09 UTC): Thank you for your feedback. I  will maintain as separate repo.
https://pypi.org/project/apache-airflow-provider-magento
https://github.com/sivajik34/magento-airflow/tree/main

potiuk on (2024-08-21 13:22:08 UTC): One thing though. We do not want to enforce it - and cannot prevent people from creating such name, but generally I think you should not use ""apache-airlfow-providers-magento"" as provider name - it suggests it is an ""apache"" provider where it is not, so I would kindly ask you to change the PyPI name and handle the ownership of that name in PyPI to the ""Apache Airlfow"" pypi organization. You can add me as an owner (`@potiuk`) and I can transfer it there.

potiuk on (2024-08-21 13:24:43 UTC): That's not very strong request just request to make a clear distinction - again - we probably won't foirce any action there - even if we could (Apache Airflow is now registered trademark in the US), it's more of a kind request - since it is up 25 minutes, it's likely way easier to change it now rather than some time in the future.

sivajik34 (Issue Creator) on (2024-08-21 13:30:38 UTC): Sure .Yesterday I published, I will try to change the name. Thank you

On Wed, 21 Aug 2024, 6:55 pm Jarek Potiuk, ***@***.***> wrote:

potiuk on (2024-08-21 13:36:47 UTC): Thanks for being responsive - really appreciate!

github-actions[bot] on (2024-10-06 00:16:31 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2471626261,pull_request,closed,,Switch cloudant provider from cloudant library to ibmcloudant library,"closes: #21004, cloudant is no longer developed and ibmcloudant is the active replacement

This is a breaking change to the provider in the following ways:

- `get_conn` now returns a `CloudantV1` object with different function names than the previous `Cloudant` object; the mappings from the old library functions to the new are outlined here: https://github.com/cloudant/python-cloudant/blob/master/MIGRATION.md#reference-table
- `get_conn` now directly returns a usable object instead of a context manager; `with`-block syntax is no longer needed
- The connection is now checked for a mandatory `host` value that functions as the Cloudant account name (previously the host field was optional, but could cause a runtime failure)
",topherinternational,2024-08-17 18:36:40+00:00,[],2024-09-06 11:15:37+00:00,2024-09-06 11:02:20+00:00,https://github.com/apache/airflow/pull/41555,"[('area:providers', ''), ('provider:cloudant', ''), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2294991433, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': ""Rats, looks like the joke is on me and this PR is blocked on another third-party...`ibmcloudant` has a dependency conflict with the Snowflake Python library that nerfs the Airflow build for Python 3.8 and 3.9. \r\n\r\nThere's an [issue](https://github.com/snowflakedb/snowflake-connector-python/issues/2016) for this in the Snowflake repo ([two issues actually](https://github.com/snowflakedb/snowflake-connector-python/issues/1997)) with an [open PR](https://github.com/snowflakedb/snowflake-connector-python/pull/1998), so hopefully it will be fixed soon and this Cloudant PR will unblock.\r\n\r\nIronic as this issue stalled for a while waiting for Flask-AppBuilder to fix a dependency pin.\r\n\r\nDetails:\r\n\r\n`ibmcloudant` brings in `ibm-cloud-sdk-core` which [requires `urllib3` 2.x](https://github.com/IBM/python-sdk-core/blob/main/pyproject.toml#L30), which is fine for core Airflow, but the snowflake provider brings in `snowflake-connector-python`, which (for Python 3.8. and 3.9 only) requires urllib3 1.x."", 'created_at': datetime.datetime(2024, 8, 17, 21, 31, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295383399, 'issue_id': 2471626261, 'author': 'potiuk', 'body': '> Rats, looks like the joke is on me and this PR is blocked on another third-party...`ibmcloudant` has a dependency conflict with the Snowflake Python library that nerfs the Airflow build for Python 3.8 and 3.9.\r\n> \r\n> There\'s an [issue](https://github.com/snowflakedb/snowflake-connector-python/issues/2016) for this in the Snowflake repo ([two issues actually](https://github.com/snowflakedb/snowflake-connector-python/issues/1997)) with an [open PR](https://github.com/snowflakedb/snowflake-connector-python/pull/1998), so hopefully it will be fixed soon and this Cloudant PR will unblock.\r\n> \r\n> Ironic as this issue stalled for a while waiting for Flask-AppBuilder to fix a dependency pin.\r\n> \r\n> Details:\r\n> \r\n> `ibmcloudant` brings in `ibm-cloud-sdk-core` which [requires `urllib3` 2.x](https://github.com/IBM/python-sdk-core/blob/main/pyproject.toml#L30), which is fine for core Airflow, but the snowflake provider brings in `snowflake-connector-python`, which (for Python 3.8. and 3.9 only) requires urllib3 1.x.\r\n\r\nYou could potentially also add ""3.8"" and ""3.9"" to ""excluded-python-versions"" in the new version of cloudant provider (in provider.yaml) with the link to the snowflake issue - and remove the exclusions once this problem is fixed.', 'created_at': datetime.datetime(2024, 8, 18, 20, 38, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295383824, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'See https://github.com/apache/airflow/pull/41548 - where we just removed such exclusion for Papermill for Python 3.12', 'created_at': datetime.datetime(2024, 8, 18, 20, 40, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295384199, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'I\'ve added ""all-versions"" tag to the PR of yours - to make sure it\'s tested on all versions - so once you exclude python versions you should be able to see both CI images and tests to run for cloudant only on 3.10 -> 3.12 images and be skipped for 3.8 and 3.9', 'created_at': datetime.datetime(2024, 8, 18, 20, 42, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295512197, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': 'Great explanation, thank you @potiuk', 'created_at': datetime.datetime(2024, 8, 19, 1, 40, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295750150, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': ""Ok @potiuk I've added the exclusion and an explanatory comment, so I think this is complete. Please review at your convenience, thanks."", 'created_at': datetime.datetime(2024, 8, 19, 6, 17, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296264555, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'You should also add a note at the top of changelog (see comment at the top of changelog) and bump the version to the new major release in the provider.yaml.', 'created_at': datetime.datetime(2024, 8, 19, 10, 41, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306136496, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': 'edit: moved this comment to an issue #41718\r\n\r\n@potiuk @eladkal we have 3 persistent failures in the provider checks; tldr, I think there\'s a bug-ish in the provider checks commands in breeze where all providers are assumed to be supported on Python 3.8. \r\n\r\nThe command `breeze release-management verify-provider-packages --use-packages-from-dist --package-format wheel --use-airflow-version wheel --airflow-constraints-reference default --providers-constraints-location /files/constraints-3.8/constraints-source-providers-3.8.txt` installs all of the provider wheels built in the earlier `breeze release-management prepare-provider-packages ...` step. \r\n\r\nThis process all runs on 3.8 and so implicitly assumes that all of the providers are legit for 3.8; neither step looks like it checks `excluded-python-versions`. So the install fails due to the ibmcloudant and snowflake dependency conflict (the very reason we excluded 3.8 in the first place). \r\n\r\nThese commands happen in `Provider packages wheel build and verify`, `Compat 2.8.4:P3.8 provider check` and `Compat 2.9.1:P3.8 provider check`.\r\n\r\nAddressing this is obviously your call, but maybe some options are?:\r\n1. Make `prepare-provider-packages` check excluded versions before building a particular provider wheel\r\n2. Add ""Remove incompatible <version> provider packages"" task to `Provider packages wheel build and verify`, and have the task reference the provider dependencies json and the excluded python versions.\r\n3. Run the provider checks on every supported python version (after doing 1 or 2)\r\n\r\nI checked the repo and none of the released providers exclude Python 3.8, I figure maybe this problem hasn\'t come up yet.', 'created_at': datetime.datetime(2024, 8, 23, 4, 1, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306141955, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': 'We also have spurious failures where one of the tests in ""Lowest direct dependency resolution tests"" and one in ""Kubernetes tests"" will fail, but it looks like a different one each time. Suspiciously the failures take about twice as long as any of the successes (2hrs vs ~55mins) so maybe a resource starvation or a hang in a testing resource.', 'created_at': datetime.datetime(2024, 8, 23, 4, 4, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308775821, 'issue_id': 2471626261, 'author': 'potiuk', 'body': '> We also have spurious failures where one of the tests in ""Lowest direct dependency resolution tests"" and one in ""Kubernetes tests"" will fail, but it looks like a different one each time. Suspiciously the failures take about twice as long as any of the successes (2hrs vs ~55mins) so maybe a resource starvation or a hang in a testing resource.\r\n\r\nYes. Some flakes.', 'created_at': datetime.datetime(2024, 8, 25, 10, 45, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308779326, 'issue_id': 2471626261, 'author': 'potiuk', 'body': '> I checked the repo and none of the released providers exclude Python 3.8, I figure maybe this problem hasn\'t come up yet.\r\n\r\nYes. As I wrote in the #41718 - likely matrix for all providers and python versions is far too big an overhead for this one - this is the first time we have a provider that does not work for 3.8. So likely removing the providers that are not 3.8 compatible is the way to go - feel free to do so. We already have a code that removes non-compatible providers in compatibility checks - you can add ibmcloudant there (with comment referring to the conflict and issue with snowflake). Similarly you can even hard-code a step after builiding the providers in verify providers (again - with comment and link to the snowflake issue and note that it should be removed after the issue is solved.\r\n\r\nHere is the compatibility check config and you can add ibmcloudant there for all versions simply. Also we could - theoretically also add 3.10 there and NOT remove cloudant, but taking into account temporary (hopefully) state for the removal, I don\'t think we need.\r\n\r\n```\r\nBASE_PROVIDERS_COMPATIBILITY_CHECKS: list[dict[str, str | list[str]]] = [\r\n    {\r\n        ""python-version"": ""3.8"",\r\n        ""airflow-version"": ""2.8.4"",\r\n        ""remove-providers"": ""fab"",\r\n        ""run-tests"": ""true"",\r\n    },\r\n    {\r\n        ""python-version"": ""3.8"",\r\n        ""airflow-version"": ""2.9.3"",\r\n        ""remove-providers"": """",\r\n        ""run-tests"": ""true"",\r\n    },\r\n    {\r\n        ""python-version"": ""3.8"",\r\n        ""airflow-version"": ""2.10.0"",\r\n        ""remove-providers"": """",\r\n        ""run-tests"": ""true"",\r\n    },\r\n]\r\n```', 'created_at': datetime.datetime(2024, 8, 25, 10, 54, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320776697, 'issue_id': 2471626261, 'author': 'potiuk', 'body': ""There is one more issue - when package is excluded fromcertai version , the 'lowest deendencies' test goes   wild - it tests all other packages then. This should be fixed as part of CI infra fix"", 'created_at': datetime.datetime(2024, 8, 30, 10, 27, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323075534, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'I added a fixup that is supposed to skip cloundant tests for 3.8, 3.9, 3.12 @topherinternational', 'created_at': datetime.datetime(2024, 8, 31, 23, 57, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323262923, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'Almost there. For some strange reason apache.beam ""downgrade"" does not work quite consistently and hangs for Python 3.12.\r\n\r\n Need to take a look', 'created_at': datetime.datetime(2024, 9, 1, 9, 54, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323323766, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'I guess we will also have to exclude Python 3.12 version - until apache.beam fixes the conflicts.', 'created_at': datetime.datetime(2024, 9, 1, 12, 41, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323435403, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': ""> There is one more issue - when package is excluded fromcertai version , the 'lowest deendencies' test goes   wild - it tests all other packages then. This should be fixed as part of CI infra fix\n\nI found the bug in breeze that causes this, I am coding it up into a separate PR."", 'created_at': datetime.datetime(2024, 9, 1, 17, 33, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2328372934, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'Hmm. The problem is this for apache.beam\r\n\r\n```\r\n--verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes\r\n--junitxml=/files/test_result-providers_apache_beam-postgres.xml\r\n--timeouts-order moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 \r\n--disable-warnings -rfEX --ignore=tests/system --ignore=tests/integration\r\n--warning-output-path=/files/warnings-providers_apache_beam-postgres.txt\r\n--ignore=helm_tests --with-db-init --ignore=tests/providers/apache/beam\r\n--ignore=tests/system/providers/apache/beam\r\n--ignore=tests/integration/providers/apache/beam --no-cov\r\n```\r\n\r\nIt runs `all other` tests as beam is also excluded for Python 3.12', 'created_at': datetime.datetime(2024, 9, 4, 9, 31, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2328558624, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'This one should fix it https://github.com/apache/airflow/pull/41991', 'created_at': datetime.datetime(2024, 9, 4, 10, 49, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2328766532, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': '> Hmm. The problem is this for apache.beam\n> \n> \n> \n> ```\n> \n> --verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes\n> \n> --junitxml=/files/test_result-providers_apache_beam-postgres.xml\n> \n> --timeouts-order moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 \n> \n> --disable-warnings -rfEX --ignore=tests/system --ignore=tests/integration\n> \n> --warning-output-path=/files/warnings-providers_apache_beam-postgres.txt\n> \n> --ignore=helm_tests --with-db-init --ignore=tests/providers/apache/beam\n> \n> --ignore=tests/system/providers/apache/beam\n> \n> --ignore=tests/integration/providers/apache/beam --no-cov\n> \n> ```\n> \n> \n> \n> It runs `all other` tests as beam is also excluded for Python 3.12\n\nHmm, that looks like the same problem I brought up in #41967, Breeze removes the test dir argument for the excluded provider, and so the command winds up running all of the tests.', 'created_at': datetime.datetime(2024, 9, 4, 11, 56, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330183058, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'I rebased to see if the fix #41991 is merged', 'created_at': datetime.datetime(2024, 9, 4, 21, 32, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331258325, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': 'Opened #42027 which I think fixes the current test failures.', 'created_at': datetime.datetime(2024, 9, 5, 11, 15, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331295625, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž', 'created_at': datetime.datetime(2024, 9, 5, 11, 37, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331401946, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': 'Another cross-fix: #42030', 'created_at': datetime.datetime(2024, 9, 5, 12, 26, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331483524, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž', 'created_at': datetime.datetime(2024, 9, 5, 12, 37, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331673474, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': ""I removed those skip functions from the Dockerfile and entrypoint files since I think that's covered now by #41991."", 'created_at': datetime.datetime(2024, 9, 5, 13, 22, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331727868, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž', 'created_at': datetime.datetime(2024, 9, 5, 13, 45, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2333811313, 'issue_id': 2471626261, 'author': 'potiuk', 'body': 'Woooooohoooo!', 'created_at': datetime.datetime(2024, 9, 6, 11, 2, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2333824217, 'issue_id': 2471626261, 'author': 'topherinternational', 'body': '> Woooooohoooo!\r\n\r\nThis has been...educational ðŸ˜‰', 'created_at': datetime.datetime(2024, 9, 6, 11, 10, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2333832009, 'issue_id': 2471626261, 'author': 'potiuk', 'body': '> This has been...educational \r\n\r\nOh, I am sure it was :)', 'created_at': datetime.datetime(2024, 9, 6, 11, 15, 35, tzinfo=datetime.timezone.utc)}]","topherinternational (Issue Creator) on (2024-08-17 21:31:53 UTC): Rats, looks like the joke is on me and this PR is blocked on another third-party...`ibmcloudant` has a dependency conflict with the Snowflake Python library that nerfs the Airflow build for Python 3.8 and 3.9. 

There's an [issue](https://github.com/snowflakedb/snowflake-connector-python/issues/2016) for this in the Snowflake repo ([two issues actually](https://github.com/snowflakedb/snowflake-connector-python/issues/1997)) with an [open PR](https://github.com/snowflakedb/snowflake-connector-python/pull/1998), so hopefully it will be fixed soon and this Cloudant PR will unblock.

Ironic as this issue stalled for a while waiting for Flask-AppBuilder to fix a dependency pin.

Details:

`ibmcloudant` brings in `ibm-cloud-sdk-core` which [requires `urllib3` 2.x](https://github.com/IBM/python-sdk-core/blob/main/pyproject.toml#L30), which is fine for core Airflow, but the snowflake provider brings in `snowflake-connector-python`, which (for Python 3.8. and 3.9 only) requires urllib3 1.x.

potiuk on (2024-08-18 20:38:46 UTC): You could potentially also add ""3.8"" and ""3.9"" to ""excluded-python-versions"" in the new version of cloudant provider (in provider.yaml) with the link to the snowflake issue - and remove the exclusions once this problem is fixed.

potiuk on (2024-08-18 20:40:38 UTC): See https://github.com/apache/airflow/pull/41548 - where we just removed such exclusion for Papermill for Python 3.12

potiuk on (2024-08-18 20:42:16 UTC): I've added ""all-versions"" tag to the PR of yours - to make sure it's tested on all versions - so once you exclude python versions you should be able to see both CI images and tests to run for cloudant only on 3.10 -> 3.12 images and be skipped for 3.8 and 3.9

topherinternational (Issue Creator) on (2024-08-19 01:40:54 UTC): Great explanation, thank you @potiuk

topherinternational (Issue Creator) on (2024-08-19 06:17:23 UTC): Ok @potiuk I've added the exclusion and an explanatory comment, so I think this is complete. Please review at your convenience, thanks.

potiuk on (2024-08-19 10:41:55 UTC): You should also add a note at the top of changelog (see comment at the top of changelog) and bump the version to the new major release in the provider.yaml.

topherinternational (Issue Creator) on (2024-08-23 04:01:01 UTC): edit: moved this comment to an issue #41718

@potiuk @eladkal we have 3 persistent failures in the provider checks; tldr, I think there's a bug-ish in the provider checks commands in breeze where all providers are assumed to be supported on Python 3.8. 

The command `breeze release-management verify-provider-packages --use-packages-from-dist --package-format wheel --use-airflow-version wheel --airflow-constraints-reference default --providers-constraints-location /files/constraints-3.8/constraints-source-providers-3.8.txt` installs all of the provider wheels built in the earlier `breeze release-management prepare-provider-packages ...` step. 

This process all runs on 3.8 and so implicitly assumes that all of the providers are legit for 3.8; neither step looks like it checks `excluded-python-versions`. So the install fails due to the ibmcloudant and snowflake dependency conflict (the very reason we excluded 3.8 in the first place). 

These commands happen in `Provider packages wheel build and verify`, `Compat 2.8.4:P3.8 provider check` and `Compat 2.9.1:P3.8 provider check`.

Addressing this is obviously your call, but maybe some options are?:
1. Make `prepare-provider-packages` check excluded versions before building a particular provider wheel
2. Add ""Remove incompatible <version> provider packages"" task to `Provider packages wheel build and verify`, and have the task reference the provider dependencies json and the excluded python versions.
3. Run the provider checks on every supported python version (after doing 1 or 2)

I checked the repo and none of the released providers exclude Python 3.8, I figure maybe this problem hasn't come up yet.

topherinternational (Issue Creator) on (2024-08-23 04:04:33 UTC): We also have spurious failures where one of the tests in ""Lowest direct dependency resolution tests"" and one in ""Kubernetes tests"" will fail, but it looks like a different one each time. Suspiciously the failures take about twice as long as any of the successes (2hrs vs ~55mins) so maybe a resource starvation or a hang in a testing resource.

potiuk on (2024-08-25 10:45:32 UTC): Yes. Some flakes.

potiuk on (2024-08-25 10:54:35 UTC): Yes. As I wrote in the #41718 - likely matrix for all providers and python versions is far too big an overhead for this one - this is the first time we have a provider that does not work for 3.8. So likely removing the providers that are not 3.8 compatible is the way to go - feel free to do so. We already have a code that removes non-compatible providers in compatibility checks - you can add ibmcloudant there (with comment referring to the conflict and issue with snowflake). Similarly you can even hard-code a step after builiding the providers in verify providers (again - with comment and link to the snowflake issue and note that it should be removed after the issue is solved.

Here is the compatibility check config and you can add ibmcloudant there for all versions simply. Also we could - theoretically also add 3.10 there and NOT remove cloudant, but taking into account temporary (hopefully) state for the removal, I don't think we need.

```
BASE_PROVIDERS_COMPATIBILITY_CHECKS: list[dict[str, str | list[str]]] = [
    {
        ""python-version"": ""3.8"",
        ""airflow-version"": ""2.8.4"",
        ""remove-providers"": ""fab"",
        ""run-tests"": ""true"",
    },
    {
        ""python-version"": ""3.8"",
        ""airflow-version"": ""2.9.3"",
        ""remove-providers"": """",
        ""run-tests"": ""true"",
    },
    {
        ""python-version"": ""3.8"",
        ""airflow-version"": ""2.10.0"",
        ""remove-providers"": """",
        ""run-tests"": ""true"",
    },
]
```

potiuk on (2024-08-30 10:27:12 UTC): There is one more issue - when package is excluded fromcertai version , the 'lowest deendencies' test goes   wild - it tests all other packages then. This should be fixed as part of CI infra fix

potiuk on (2024-08-31 23:57:36 UTC): I added a fixup that is supposed to skip cloundant tests for 3.8, 3.9, 3.12 @topherinternational

potiuk on (2024-09-01 09:54:52 UTC): Almost there. For some strange reason apache.beam ""downgrade"" does not work quite consistently and hangs for Python 3.12.

 Need to take a look

potiuk on (2024-09-01 12:41:08 UTC): I guess we will also have to exclude Python 3.12 version - until apache.beam fixes the conflicts.

topherinternational (Issue Creator) on (2024-09-01 17:33:02 UTC): I found the bug in breeze that causes this, I am coding it up into a separate PR.

potiuk on (2024-09-04 09:31:28 UTC): Hmm. The problem is this for apache.beam

```
--verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes
--junitxml=/files/test_result-providers_apache_beam-postgres.xml
--timeouts-order moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 
--disable-warnings -rfEX --ignore=tests/system --ignore=tests/integration
--warning-output-path=/files/warnings-providers_apache_beam-postgres.txt
--ignore=helm_tests --with-db-init --ignore=tests/providers/apache/beam
--ignore=tests/system/providers/apache/beam
--ignore=tests/integration/providers/apache/beam --no-cov
```

It runs `all other` tests as beam is also excluded for Python 3.12

potiuk on (2024-09-04 10:49:49 UTC): This one should fix it https://github.com/apache/airflow/pull/41991

topherinternational (Issue Creator) on (2024-09-04 11:56:54 UTC): Hmm, that looks like the same problem I brought up in #41967, Breeze removes the test dir argument for the excluded provider, and so the command winds up running all of the tests.

potiuk on (2024-09-04 21:32:09 UTC): I rebased to see if the fix #41991 is merged

topherinternational (Issue Creator) on (2024-09-05 11:15:53 UTC): Opened #42027 which I think fixes the current test failures.

potiuk on (2024-09-05 11:37:14 UTC): ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž

topherinternational (Issue Creator) on (2024-09-05 12:26:04 UTC): Another cross-fix: #42030

potiuk on (2024-09-05 12:37:30 UTC): ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž

topherinternational (Issue Creator) on (2024-09-05 13:22:36 UTC): I removed those skip functions from the Dockerfile and entrypoint files since I think that's covered now by #41991.

potiuk on (2024-09-05 13:45:52 UTC): ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤žðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž ðŸ¤ž

potiuk on (2024-09-06 11:02:27 UTC): Woooooohoooo!

topherinternational (Issue Creator) on (2024-09-06 11:10:41 UTC): This has been...educational ðŸ˜‰

potiuk on (2024-09-06 11:15:35 UTC): Oh, I am sure it was :)

"
2471566385,pull_request,closed,,feat(providers/openai): support batch api in hook/operator/trigger,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:



How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #41336 
- [x] Hook that supports batch api related operation
- [x] Operator/Trigger for Batch API
- [x] Unit tests for new added behaviors to hook
- [x] Unit tests for new added behaviors to operator
- [x] Unit tests for new added behaviors to trigger
- [x] Update how-to guide
- [x] Update provider.yaml

![image](https://github.com/user-attachments/assets/e637be04-39ce-425d-b5f0-774d609e1d29)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",josix,2024-08-17 15:28:19+00:00,[],2025-01-08 19:42:25+00:00,2024-08-22 10:34:35+00:00,https://github.com/apache/airflow/pull/41554,"[('area:providers', ''), ('provider:openai', '')]",[],
2471478716,pull_request,closed,,log handler deprecated filename_template argument removal,"Passing filename_template to a log handler is deprecated and has no effect. So, removing deprecated filename_template argument in log handler.",dirrao,2024-08-17 11:04:00+00:00,['dirrao'],2024-08-21 19:45:31+00:00,2024-08-20 07:24:16+00:00,https://github.com/apache/airflow/pull/41552,"[('provider:google', 'Google (including GCP) related issues'), ('provider:microsoft-azure', 'Azure-related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:logging', ''), ('provider:elasticsearch', ''), ('provider:alibaba', ''), ('provider:apache-hdfs', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2298322449, 'issue_id': 2471478716, 'author': 'eladkal', 'body': 'This PR involves both core and provider changes.\r\nPlease clarify what it means for new versions of providers (that will include this PR) but installed with Airflow 2.\r\nSomething is odd here.\r\n\r\nThe parameter in question is public API which is why we deprecate it first. Now main is Airflow 3 so we can remove it but providers must still be compatible with Airflow 2... so how can we remove it from providers safely now?', 'created_at': datetime.datetime(2024, 8, 20, 8, 50, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298754575, 'issue_id': 2471478716, 'author': 'dirrao', 'body': '> This PR involves both core and provider changes. Please clarify what it means for new versions of providers (that will include this PR) but installed with Airflow 2. Something is odd here.\r\n> \r\n Right now, this field is not being used and has no effect. The filename_template is optional argument with default value None.\r\n We can still able to install and use latest providers on airflow 2 without any issue. \r\n\r\n> The parameter in question is public API which is why we deprecate it first. Now main is Airflow 3 so we can remove it but providers must still be compatible with Airflow 2... so how can we remove it from providers safely now?\r\n\r\nAs I said in the above statement, the providers can still work with airflow 2.', 'created_at': datetime.datetime(2024, 8, 20, 12, 36, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298866225, 'issue_id': 2471478716, 'author': 'potiuk', 'body': '@eladkal is right - if someone  installs the new provider witn an old configuration in Airlfow 2 with filename_template, it will just fail with ""attemptign to iniitalize handlew with ""filename_template"" argument passed but  it\'s missing"" (or smth like that).', 'created_at': datetime.datetime(2024, 8, 20, 13, 29, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298895036, 'issue_id': 2471478716, 'author': 'dirrao', 'body': 'I see the keyword arguments for the all the \r\n\r\n> @eladkal is right - if someone installs the new provider witn an old configuration in Airlfow 2 with filename_template, it will just fail with ""attemptign to iniitalize handlew with ""filename_template"" argument passed but it\'s missing"" (or smth like that).\r\n\r\nYah. You are right. Most of them are supporting keyword arguments except one/two  (like. es handler).', 'created_at': datetime.datetime(2024, 8, 20, 13, 41, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299399556, 'issue_id': 2471478716, 'author': 'dirrao', 'body': '@eladkal / @potiuk \r\nLet me know if you want me to revert it for providers alone.', 'created_at': datetime.datetime(2024, 8, 20, 17, 38, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299671625, 'issue_id': 2471478716, 'author': 'potiuk', 'body': 'Just reverting will not be enough, but I think if the base Handler will accept extra arguments (and ignores them) we should be home', 'created_at': datetime.datetime(2024, 8, 20, 20, 5, 29, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-20 08:50:22 UTC): This PR involves both core and provider changes.
Please clarify what it means for new versions of providers (that will include this PR) but installed with Airflow 2.
Something is odd here.

The parameter in question is public API which is why we deprecate it first. Now main is Airflow 3 so we can remove it but providers must still be compatible with Airflow 2... so how can we remove it from providers safely now?

dirrao (Issue Creator) on (2024-08-20 12:36:27 UTC): Right now, this field is not being used and has no effect. The filename_template is optional argument with default value None.
 We can still able to install and use latest providers on airflow 2 without any issue. 


As I said in the above statement, the providers can still work with airflow 2.

potiuk on (2024-08-20 13:29:01 UTC): @eladkal is right - if someone  installs the new provider witn an old configuration in Airlfow 2 with filename_template, it will just fail with ""attemptign to iniitalize handlew with ""filename_template"" argument passed but  it's missing"" (or smth like that).

dirrao (Issue Creator) on (2024-08-20 13:41:52 UTC): I see the keyword arguments for the all the 


Yah. You are right. Most of them are supporting keyword arguments except one/two  (like. es handler).

dirrao (Issue Creator) on (2024-08-20 17:38:49 UTC): @eladkal / @potiuk 
Let me know if you want me to revert it for providers alone.

potiuk on (2024-08-20 20:05:29 UTC): Just reverting will not be enough, but I think if the base Handler will accept extra arguments (and ignores them) we should be home

"
2471469516,pull_request,closed,,base executor unused validate_command function removal,base executor deprecated unused validate_command function removal,dirrao,2024-08-17 10:33:28+00:00,[],2024-08-18 21:37:42+00:00,2024-08-18 21:37:42+00:00,https://github.com/apache/airflow/pull/41551,"[('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]",[],
2471337378,pull_request,closed,,"airflow deprecated settings session_lifetime_days, force_log_out_after and policy removal","airflow deprecated settings session_lifetime_days, force_log_out_after and policy removal",dirrao,2024-08-17 04:52:59+00:00,['dirrao'],2024-08-21 19:45:31+00:00,2024-08-18 21:26:17+00:00,https://github.com/apache/airflow/pull/41550,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2471311948,pull_request,closed,,Fix: Keep compatibility with old FAB versions,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
closes: https://github.com/apache/airflow/issues/41540

FAB versions before 1.3.0 still use the old access control format that allows only DAGs resource. This PR fixes the format when airflow is running with FAB versions < 1.3.0.

Tests:
- FAB 1.2.2
  - Old access_control format: `access_control={'Viewer': [""can_read"",""can_delete""]}`
```
# airflow sync-perm --include-dags 
Updating actions and resources for all existing roles                                                                
Updating permission on all DAG views                                                                                 
[2024-08-19T16:57:58.390+0000] {dagbag.py:567} INFO - Filling up the DagBag from database                            
[2024-08-19T16:57:58.397+0000] {override.py:1105} WARNING - ACCESS CONTROL: {'Viewer': {'can_read', 'can_delete'}}   
[2024-08-19T16:57:58.410+0000] {override.py:1882} INFO - Added Permission can read on DAG:tutorial2 to role Viewer   
[2024-08-19T16:57:58.414+0000] {override.py:1882} INFO - Added Permission can delete on DAG:tutorial2 to role Viewer 
```
  - New access_control format: `access_control={'Viewer': {""DAGs"": [""can_read"",""can_delete""]}}`
![image](https://github.com/user-attachments/assets/c2d38d17-78b2-44be-803c-068ef760110d)


- FAB 1.3.0:
  - Mixed formats:

```
access_control={
        'Viewer': [""can_read"",""can_delete""]
    }
    
access_control={
        'Viewer': {""DAGs"": [""can_read"",""can_delete""],
                   ""DAG Runs"": [""can_create""],}
    },

# airflow sync-perm --include-dags                                                                                                                       
Updating actions and resources for all existing roles                                                                                                    
Updating permission on all DAG views                                                                                                                     
[2024-08-19T17:15:21.591+0000] {dagbag.py:567} INFO - Filling up the DagBag from database                                                                
[2024-08-19T17:15:21.601+0000] {override.py:1158} WARNING - ACCESS CONTROL: {'Viewer': {'DAGs': {'can_read', 'can_delete'}}}                             
[2024-08-19T17:15:21.613+0000] {override.py:1158} WARNING - ACCESS CONTROL: {'Viewer': {'DAGs': {'can_read', 'can_delete'}, 'DAG Runs': ['can_create']}} 
```


<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: https://github.com/apache/airflow/issues/41540
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",joaopamaral,2024-08-17 03:36:25+00:00,[],2024-08-30 09:20:26+00:00,2024-08-20 19:42:05+00:00,https://github.com/apache/airflow/pull/41549,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2297291567, 'issue_id': 2471311948, 'author': 'joaopamaral', 'body': 'There is another breaking change [Remove deprecated SubDags](https://github.com/apache/airflow/pull/41390) that is causing a failure during the sync permissions in old FAB versions: https://github.com/apache/airflow/blame/587015ddc84dfd306e4c2487c3aeb65ae280eab5/airflow/providers/fab/auth_manager/security_manager/override.py#L1076\r\n\r\nWhen I try to run the `airflow sync-perm --include-dags ` with airflow main branch and an old FAB I get the error which is not related to the access control changes:\r\n```\r\n# airflow sync-perm --include-dags                                                                                                                                            â”‚  ____________       _____________\r\n/usr/local/lib/python3.8/site-packages/flask_limiter/extension.py:333 UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for â”‚ ____    |__( )_________  __/__  /________      __\r\nproduction use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.                                                            â”‚____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\r\nUpdating actions and resources for all existing roles                                                                                                                                                       â”‚___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\r\nUpdating permission on all DAG views                                                                                                                                                                        â”‚ _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\r\n[2024-08-19T19:26:23.125+0000] {dagbag.py:567} INFO - Filling up the DagBag from database                                                                                                                   â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Starting gunicorn 23.0.0\r\nTraceback (most recent call last):                                                                                                                                                                          â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Listening at: http://[::]:8794 (140)\r\n  File ""/usr/local/bin/airflow"", line 8, in <module>                                                                                                                                                        â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Using worker: sync\r\n    sys.exit(main())                                                                                                                                                                                        â”‚[2024-08-19 19:24:20 +0000] [141] [INFO] Booting worker with pid: 141\r\n  File ""/opt/airflow/airflow/__main__.py"", line 62, in main                                                                                                                                                 â”‚[2024-08-19 19:24:20 +0000] [142] [INFO] Booting worker with pid: 142\r\n    args.func(args)                                                                                                                                                                                         â”‚[2024-08-19T19:24:20.894+0000] {triggerer_job_runner.py:181} INFO - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>\r\n  File ""/opt/airflow/airflow/cli/cli_config.py"", line 49, in command                                                                                                                                        â”‚[2024-08-19T19:24:20.894+0000] {triggerer_job_runner.py:237} INFO - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>]\r\n    return func(*args, **kwargs)                                                                                                                                                                            â”‚[2024-08-19T19:24:20.900+0000] {triggerer_job_runner.py:338} INFO - Starting the triggerer\r\n  File ""/opt/airflow/airflow/utils/cli.py"", line 115, in wrapper                                                                                                                                            â”‚[2024-08-19T19:25:21.099+0000] {triggerer_job_runner.py:510} INFO - 0 triggers currently running\r\n    return f(*args, **kwargs)                                                                                                                                                                               â”‚[2024-08-19T19:26:21.264+0000] {triggerer_job_runner.py:510} INFO - 0 triggers currently running\r\n  File ""/opt/airflow/airflow/utils/providers_configuration_loader.py"", line 55, in wrapped_function                                                                                                         â”‚\r\n    return func(*args, **kwargs)                                                                                                                                                                            â”‚\r\n  File ""/opt/airflow/airflow/providers/fab/auth_manager/cli_commands/sync_perm_command.py"", line 39, in sync_perm                                                                                           â”‚\r\n    appbuilder.sm.create_dag_specific_permissions()                                                                                                                                                         â”‚\r\n  File ""/opt/airflow/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1067, in create_dag_specific_permissions                                                                        â”‚\r\n    root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id                                                                                                                                   â”‚\r\nAttributeError: \'SerializedDAG\' object has no attribute \'parent_dag\'\r\n```\r\n\r\nTo run the final tests with this PR change I need to apply the [this line change](https://github.com/apache/airflow/blame/587015ddc84dfd306e4c2487c3aeb65ae280eab5/airflow/providers/fab/auth_manager/security_manager/override.py#L1076). \r\n\r\n@kaxil, do you know if it\'s related to this [PR](https://github.com/apache/airflow/pull/41390), is it expected to keep the compatibility with old FAB versions?', 'created_at': datetime.datetime(2024, 8, 19, 19, 30, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297729922, 'issue_id': 2471311948, 'author': 'kaxil', 'body': '> There is another breaking change [Remove deprecated SubDags](https://github.com/apache/airflow/pull/41390) that is causing a failure during the sync permissions in old FAB versions: https://github.com/apache/airflow/blame/587015ddc84dfd306e4c2487c3aeb65ae280eab5/airflow/providers/fab/auth_manager/security_manager/override.py#L1076\r\n> \r\n> When I try to run the `airflow sync-perm --include-dags ` with airflow 2.10 and an old FAB I get the error which is not related to the access control changes:\r\n> \r\n> ```\r\n> # airflow sync-perm --include-dags                                                                                                                                            â”‚  ____________       _____________\r\n> /usr/local/lib/python3.8/site-packages/flask_limiter/extension.py:333 UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for â”‚ ____    |__( )_________  __/__  /________      __\r\n> production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.                                                            â”‚____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\r\n> Updating actions and resources for all existing roles                                                                                                                                                       â”‚___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\r\n> Updating permission on all DAG views                                                                                                                                                                        â”‚ _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\r\n> [2024-08-19T19:26:23.125+0000] {dagbag.py:567} INFO - Filling up the DagBag from database                                                                                                                   â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Starting gunicorn 23.0.0\r\n> Traceback (most recent call last):                                                                                                                                                                          â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Listening at: http://[::]:8794 (140)\r\n>   File ""/usr/local/bin/airflow"", line 8, in <module>                                                                                                                                                        â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Using worker: sync\r\n>     sys.exit(main())                                                                                                                                                                                        â”‚[2024-08-19 19:24:20 +0000] [141] [INFO] Booting worker with pid: 141\r\n>   File ""/opt/airflow/airflow/__main__.py"", line 62, in main                                                                                                                                                 â”‚[2024-08-19 19:24:20 +0000] [142] [INFO] Booting worker with pid: 142\r\n>     args.func(args)                                                                                                                                                                                         â”‚[2024-08-19T19:24:20.894+0000] {triggerer_job_runner.py:181} INFO - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>\r\n>   File ""/opt/airflow/airflow/cli/cli_config.py"", line 49, in command                                                                                                                                        â”‚[2024-08-19T19:24:20.894+0000] {triggerer_job_runner.py:237} INFO - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>]\r\n>     return func(*args, **kwargs)                                                                                                                                                                            â”‚[2024-08-19T19:24:20.900+0000] {triggerer_job_runner.py:338} INFO - Starting the triggerer\r\n>   File ""/opt/airflow/airflow/utils/cli.py"", line 115, in wrapper                                                                                                                                            â”‚[2024-08-19T19:25:21.099+0000] {triggerer_job_runner.py:510} INFO - 0 triggers currently running\r\n>     return f(*args, **kwargs)                                                                                                                                                                               â”‚[2024-08-19T19:26:21.264+0000] {triggerer_job_runner.py:510} INFO - 0 triggers currently running\r\n>   File ""/opt/airflow/airflow/utils/providers_configuration_loader.py"", line 55, in wrapped_function                                                                                                         â”‚\r\n>     return func(*args, **kwargs)                                                                                                                                                                            â”‚\r\n>   File ""/opt/airflow/airflow/providers/fab/auth_manager/cli_commands/sync_perm_command.py"", line 39, in sync_perm                                                                                           â”‚\r\n>     appbuilder.sm.create_dag_specific_permissions()                                                                                                                                                         â”‚\r\n>   File ""/opt/airflow/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1067, in create_dag_specific_permissions                                                                        â”‚\r\n>     root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id                                                                                                                                   â”‚\r\n> AttributeError: \'SerializedDAG\' object has no attribute \'parent_dag\'\r\n> ```\r\n> \r\n> To run the final tests with this PR change I need to apply the [this line change](https://github.com/apache/airflow/blame/587015ddc84dfd306e4c2487c3aeb65ae280eab5/airflow/providers/fab/auth_manager/security_manager/override.py#L1076).\r\n> \r\n> @kaxil, do you know if it\'s related to this [PR](https://github.com/apache/airflow/pull/41390), is it expected to keep the compatibility with old FAB versions?\r\n\r\nOlder FAB version won\'t work with Airflow 3. You will need to use the changes from [the PR ](https://github.com/apache/airflow/pull/41390) or use  `apache-airflow-providers-fab==1.3.0rc1`', 'created_at': datetime.datetime(2024, 8, 20, 0, 11, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297798069, 'issue_id': 2471311948, 'author': 'joaopamaral', 'body': ""> Older FAB version won't work with Airflow 3. You will need to use the changes from https://github.com/apache/airflow/pull/41390or use apache-airflow-providers-fab==1.3.0rc1\r\n\r\nThanks for explaining that @kaxil! I've tested with tag 2.10.0 and it's working."", 'created_at': datetime.datetime(2024, 8, 20, 1, 35, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299675922, 'issue_id': 2471311948, 'author': 'potiuk', 'body': 'According to the new rules- we should also back-port it to v2-10-test by PR', 'created_at': datetime.datetime(2024, 8, 20, 20, 8, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299677966, 'issue_id': 2471311948, 'author': 'potiuk', 'body': '(we means merging committer shoudl decide if they want to do it themselves or ask the author to do so).', 'created_at': datetime.datetime(2024, 8, 20, 20, 9, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299683546, 'issue_id': 2471311948, 'author': 'vincbeck', 'body': ""Good call, actually (and I should have thought about it before merging it), do we need it in main at all? Should it be only in 2.10 branch? Because as Kaxil mentioned:\r\n\r\n> Older FAB version won't work with Airflow 3. You will need to use the changes from https://github.com/apache/airflow/pull/41390or use apache-airflow-providers-fab==1.3.0rc1\r\n\r\nTherefore, this compatibility code should only be for Airflow 2.x?"", 'created_at': datetime.datetime(2024, 8, 20, 20, 12, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299717276, 'issue_id': 2471311948, 'author': 'potiuk', 'body': 'Possibly - but we have not seen this kind of need before - we assumed we backport everything from main  and we do not have ""2.10 only"" fixes - but yes, this one looks like a legitimate case (@ephraimbuddy @utkarsharma2 @kaxil ?)', 'created_at': datetime.datetime(2024, 8, 20, 20, 34, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310366989, 'issue_id': 2471311948, 'author': 'vincbeck', 'body': '@ephraimbuddy @utkarsharma2 @kaxil?', 'created_at': datetime.datetime(2024, 8, 26, 14, 32, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312596199, 'issue_id': 2471311948, 'author': 'potiuk', 'body': 'Regardless from decision #41792  is the backport as it needs to go there.', 'created_at': datetime.datetime(2024, 8, 27, 13, 40, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312751486, 'issue_id': 2471311948, 'author': 'potiuk', 'body': '@joaopamaral  -> I just cherry-picked the change to v2-10-test, but tests are failing, would you mind back-porting it and fixing the tests - see #41792', 'created_at': datetime.datetime(2024, 8, 27, 14, 36, 58, tzinfo=datetime.timezone.utc)}]","joaopamaral (Issue Creator) on (2024-08-19 19:30:03 UTC): There is another breaking change [Remove deprecated SubDags](https://github.com/apache/airflow/pull/41390) that is causing a failure during the sync permissions in old FAB versions: https://github.com/apache/airflow/blame/587015ddc84dfd306e4c2487c3aeb65ae280eab5/airflow/providers/fab/auth_manager/security_manager/override.py#L1076

When I try to run the `airflow sync-perm --include-dags ` with airflow main branch and an old FAB I get the error which is not related to the access control changes:
```
# airflow sync-perm --include-dags                                                                                                                                            â”‚  ____________       _____________
/usr/local/lib/python3.8/site-packages/flask_limiter/extension.py:333 UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for â”‚ ____    |__( )_________  __/__  /________      __
production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.                                                            â”‚____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
Updating actions and resources for all existing roles                                                                                                                                                       â”‚___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
Updating permission on all DAG views                                                                                                                                                                        â”‚ _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2024-08-19T19:26:23.125+0000] {dagbag.py:567} INFO - Filling up the DagBag from database                                                                                                                   â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Starting gunicorn 23.0.0
Traceback (most recent call last):                                                                                                                                                                          â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Listening at: http://[::]:8794 (140)
  File ""/usr/local/bin/airflow"", line 8, in <module>                                                                                                                                                        â”‚[2024-08-19 19:24:20 +0000] [140] [INFO] Using worker: sync
    sys.exit(main())                                                                                                                                                                                        â”‚[2024-08-19 19:24:20 +0000] [141] [INFO] Booting worker with pid: 141
  File ""/opt/airflow/airflow/__main__.py"", line 62, in main                                                                                                                                                 â”‚[2024-08-19 19:24:20 +0000] [142] [INFO] Booting worker with pid: 142
    args.func(args)                                                                                                                                                                                         â”‚[2024-08-19T19:24:20.894+0000] {triggerer_job_runner.py:181} INFO - Setting up TriggererHandlerWrapper with handler <FileTaskHandler (NOTSET)>
  File ""/opt/airflow/airflow/cli/cli_config.py"", line 49, in command                                                                                                                                        â”‚[2024-08-19T19:24:20.894+0000] {triggerer_job_runner.py:237} INFO - Setting up logging queue listener with handlers [<RedirectStdHandler <stdout> (NOTSET)>, <TriggererHandlerWrapper (NOTSET)>]
    return func(*args, **kwargs)                                                                                                                                                                            â”‚[2024-08-19T19:24:20.900+0000] {triggerer_job_runner.py:338} INFO - Starting the triggerer
  File ""/opt/airflow/airflow/utils/cli.py"", line 115, in wrapper                                                                                                                                            â”‚[2024-08-19T19:25:21.099+0000] {triggerer_job_runner.py:510} INFO - 0 triggers currently running
    return f(*args, **kwargs)                                                                                                                                                                               â”‚[2024-08-19T19:26:21.264+0000] {triggerer_job_runner.py:510} INFO - 0 triggers currently running
  File ""/opt/airflow/airflow/utils/providers_configuration_loader.py"", line 55, in wrapped_function                                                                                                         â”‚
    return func(*args, **kwargs)                                                                                                                                                                            â”‚
  File ""/opt/airflow/airflow/providers/fab/auth_manager/cli_commands/sync_perm_command.py"", line 39, in sync_perm                                                                                           â”‚
    appbuilder.sm.create_dag_specific_permissions()                                                                                                                                                         â”‚
  File ""/opt/airflow/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1067, in create_dag_specific_permissions                                                                        â”‚
    root_dag_id = dag.parent_dag.dag_id if dag.parent_dag else dag.dag_id                                                                                                                                   â”‚
AttributeError: 'SerializedDAG' object has no attribute 'parent_dag'
```

To run the final tests with this PR change I need to apply the [this line change](https://github.com/apache/airflow/blame/587015ddc84dfd306e4c2487c3aeb65ae280eab5/airflow/providers/fab/auth_manager/security_manager/override.py#L1076). 

@kaxil, do you know if it's related to this [PR](https://github.com/apache/airflow/pull/41390), is it expected to keep the compatibility with old FAB versions?

kaxil on (2024-08-20 00:11:28 UTC): Older FAB version won't work with Airflow 3. You will need to use the changes from [the PR ](https://github.com/apache/airflow/pull/41390) or use  `apache-airflow-providers-fab==1.3.0rc1`

joaopamaral (Issue Creator) on (2024-08-20 01:35:01 UTC): Thanks for explaining that @kaxil! I've tested with tag 2.10.0 and it's working.

potiuk on (2024-08-20 20:08:08 UTC): According to the new rules- we should also back-port it to v2-10-test by PR

potiuk on (2024-08-20 20:09:19 UTC): (we means merging committer shoudl decide if they want to do it themselves or ask the author to do so).

vincbeck on (2024-08-20 20:12:51 UTC): Good call, actually (and I should have thought about it before merging it), do we need it in main at all? Should it be only in 2.10 branch? Because as Kaxil mentioned:


Therefore, this compatibility code should only be for Airflow 2.x?

potiuk on (2024-08-20 20:34:37 UTC): Possibly - but we have not seen this kind of need before - we assumed we backport everything from main  and we do not have ""2.10 only"" fixes - but yes, this one looks like a legitimate case (@ephraimbuddy @utkarsharma2 @kaxil ?)

vincbeck on (2024-08-26 14:32:52 UTC): @ephraimbuddy @utkarsharma2 @kaxil?

potiuk on (2024-08-27 13:40:06 UTC): Regardless from decision #41792  is the backport as it needs to go there.

potiuk on (2024-08-27 14:36:58 UTC): @joaopamaral  -> I just cherry-picked the change to v2-10-test, but tests are failing, would you mind back-porting it and fixing the tests - see #41792

"
2471295253,pull_request,closed,,restore python 3.12 support for papermill,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The papermill provider was previously excluded from releasing a version compatible with Python 3.12 due to version compatibility issues with the aiohttp dependency. However, papermill version 2.6.0, which includes a fix for this issue, has now been released. By raising the minimum version to 2.6.0, we can ensure compatibility with Python 3.12.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",morokosi,2024-08-17 02:50:37+00:00,[],2024-08-17 09:27:56+00:00,2024-08-17 08:19:05+00:00,https://github.com/apache/airflow/pull/41548,"[('area:providers', ''), ('provider:papermill', '')]","[{'comment_id': 2294591349, 'issue_id': 2471295253, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 17, 2, 50, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2294791020, 'issue_id': 2471295253, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 17, 8, 19, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2294791049, 'issue_id': 2471295253, 'author': 'potiuk', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 8, 17, 8, 19, 15, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-17 02:50:41 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-08-17 08:19:07 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-08-17 08:19:15 UTC): Thanks!

"
2470812706,pull_request,closed,,Skip task in example_dynamodb_to_s3.py,"`backup_db_to_point_in_time_incremental_export` requires at least a 15-minute window of available data, causing the system tests to fail.  Moving it into a branching task group will let us keep the code snippet in the docs without actually running the task in the test.

Workaround for the issue presented in https://github.com/apache/airflow/pull/41304.  If someone wants to take on an actual fix, tag me and I'll review it, but for now I want to get the test running again.  Branching operators are a bit confusing, see how we did it in the Bedrock system test ([here](https://github.com/apache/airflow/blob/main/tests/system/providers/amazon/aws/example_bedrock.py#L80)) if you want to see some existing working examples.

TLDR of the issue:

```
error: ""from"" time can't be equal to ""to"" time
tried: so I set ""from"" to export_time - 1_minute
error: ""from"" can't be less than table creation time
tried: revert the above and set ""to"" to be latest_export_time + 1_minute
error: Difference between ""from"" time and ""to"" is less than 15 minutes
tried: revert the above and set ""to"" to be latest_export_time + 16_minutes
error: ""to"" time cannot be greater than the current time
tried: revert the above and set ""to"" time to utcnow()
error: this gets set at parse time and ""to"" time is now in the past
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-08-16 19:10:26+00:00,[],2024-08-16 20:29:42+00:00,2024-08-16 20:29:42+00:00,https://github.com/apache/airflow/pull/41546,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2470810681,pull_request,closed,,Add specific Slack operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adding `Slack***Operator` to perform specific, common, API actions

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",fritz-astronomer,2024-08-16 19:08:44+00:00,[],2024-09-27 16:11:01+00:00,2024-09-27 16:11:01+00:00,https://github.com/apache/airflow/pull/41545,"[('area:providers', ''), ('provider:slack', '')]",[],
2470733605,pull_request,closed,,Fix Non-DB test calculation for main builds (#41499),"Pytest has a weird behaviour that it will not collect tests from parent folder when subfolder of it is specified after the parent folder. This caused some non-db tests from providers folder have been skipped during main build.

The issue in Pytest 8.2 (used to work before) is tracked at https://github.com/pytest-dev/pytest/issues/12605

(cherry picked from commit d48982692c54d024d7c05e1efb7cd2adeb7d896c)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-16 18:10:53+00:00,[],2024-08-30 11:47:11+00:00,2024-08-16 19:24:46+00:00,https://github.com/apache/airflow/pull/41543,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2293944034, 'issue_id': 2470733605, 'author': 'potiuk', 'body': 'BAckporting pytest8 workaroud to v2-10-test', 'created_at': datetime.datetime(2024, 8, 16, 18, 11, 25, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-16 18:11:25 UTC): BAckporting pytest8 workaroud to v2-10-test

"
2470688766,pull_request,closed,,Fix failing pydantic v1 tests (#41534),"We need to exclude some versions of Pydantic v1 because it conflicts with aws provider.

(cherry picked from commit a033c5f15a033c751419506ea77ffdbacdd37705)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-16 17:37:26+00:00,[],2024-08-30 11:47:28+00:00,2024-08-16 18:08:56+00:00,https://github.com/apache/airflow/pull/41541,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2470532460,pull_request,closed,,smtp email user and password deprecated config removal,smtp email user and password deprecated config removal,dirrao,2024-08-16 15:54:12+00:00,['dirrao'],2024-08-21 19:45:30+00:00,2024-08-18 21:27:05+00:00,https://github.com/apache/airflow/pull/41539,"[('kind:documentation', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2470390336,pull_request,closed,,add execute_sql API to fix ElasticSearchSQLHook,"Fixes #41486 

The current `ElasticsearchSQLHook` is not working since it is still using `elasticsearch-dbapi` which has already been deprecated last year. This PR fixes the issue by adding a `execute_sql` API, which simply forwards the SQL query to the underlying official elasticsearch client.

Docs are also updated to show a working example of `ElasticsearchSQLHook`. A Screencap of the log output: 

![image](https://github.com/user-attachments/assets/038d26c1-9ad2-4c0c-90f4-1d2a1286990c)
",Owen-CH-Leung,2024-08-16 14:29:27+00:00,[],2024-08-25 13:08:25+00:00,2024-08-17 04:15:40+00:00,https://github.com/apache/airflow/pull/41537,"[('area:providers', ''), ('area:system-tests', ''), ('provider:elasticsearch', '')]","[{'comment_id': 2293694267, 'issue_id': 2470390336, 'author': 'eladkal', 'body': 'Static checks are failing :(', 'created_at': datetime.datetime(2024, 8, 16, 15, 13, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293756831, 'issue_id': 2470390336, 'author': 'Owen-CH-Leung', 'body': 'I think the 3 failing tests are `Tests / Basic tests / Test Airflow release commands` , `Tests / Provider checks / Provider packages sdist build and install` , `Tests / Integration Tests / Integration Tests: mssql ` , which are not related to static check ?\r\n\r\n`Tests / Static checks, mypy, docs / Static checks` is green', 'created_at': datetime.datetime(2024, 8, 16, 15, 54, 22, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-16 15:13:49 UTC): Static checks are failing :(

Owen-CH-Leung (Issue Creator) on (2024-08-16 15:54:22 UTC): I think the 3 failing tests are `Tests / Basic tests / Test Airflow release commands` , `Tests / Provider checks / Provider packages sdist build and install` , `Tests / Integration Tests / Integration Tests: mssql ` , which are not related to static check ?

`Tests / Static checks, mypy, docs / Static checks` is green

"
2470269327,pull_request,closed,,Removed deprecated parameters from AzureKeyVaultBackend,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
Removed deprecated parameters from AzureKeyVaultBackend
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-08-16 13:22:13+00:00,[],2024-10-30 00:15:35+00:00,2024-10-30 00:15:35+00:00,https://github.com/apache/airflow/pull/41536,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('area:secrets', '')]","[{'comment_id': 2430545072, 'issue_id': 2470269327, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 23, 0, 15, 15, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-23 00:15:15 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2470262790,pull_request,closed,,Incorrect try number subtraction producing invalid span id for OTEL aâ€¦,"â€¦irflow (issue #41501) (#41502)

* Fix for issue #39336

* removed unnecessary import

(cherry picked from commit dd3c3a7a43102c967d76cdcfe1f2f8ebeef4e212)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-16 13:18:16+00:00,[],2024-08-30 11:47:50+00:00,2024-08-16 16:10:51+00:00,https://github.com/apache/airflow/pull/41535,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2293648020, 'issue_id': 2470262790, 'author': 'potiuk', 'body': 'cc: @utkarsharma2 @kaxil @ephraimbuddy -> should we mark both PRs with ""Milestone 2.10.1"" - the one in main and the backport one? WDYT?', 'created_at': datetime.datetime(2024, 8, 16, 14, 46, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293763606, 'issue_id': 2470262790, 'author': 'ephraimbuddy', 'body': '> cc: @utkarsharma2 @kaxil @ephraimbuddy -> should we mark both PRs with ""Milestone 2.10.1"" - the one in main and the backport one? WDYT?\r\n\r\nI think only the backport is enough', 'created_at': datetime.datetime(2024, 8, 16, 15, 59, 9, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-16 14:46:44 UTC): cc: @utkarsharma2 @kaxil @ephraimbuddy -> should we mark both PRs with ""Milestone 2.10.1"" - the one in main and the backport one? WDYT?

ephraimbuddy on (2024-08-16 15:59:09 UTC): I think only the backport is enough

"
2470190264,pull_request,closed,,Fix failing pydantic v1 tests,"We need to exclude some versions of Pydantic v1 because it conflicts with aws provider.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-16 12:34:25+00:00,[],2024-08-30 09:03:05+00:00,2024-08-16 13:14:53+00:00,https://github.com/apache/airflow/pull/41534,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2470180169,pull_request,closed,,Removed deprecated param from local_filesystem,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
Removed deprecated param from local_filesystem
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-08-16 12:28:15+00:00,[],2024-08-16 13:02:04+00:00,2024-08-16 13:02:04+00:00,https://github.com/apache/airflow/pull/41533,"[('area:secrets', '')]",[],
2470130976,pull_request,closed,,Add retrieve output docker swarm operator,"Closes: https://github.com/apache/airflow/issues/41445

Updates the `DockerSwarmOperator` to include the same `retrieve_output` functionality as the `DockerOperator`: get access of the content of a file as XCom at the end of a task, before the container is destroyed. To take account of possible container replication at deployment time, a `Task` and `Container` retrieval step has been added, in addition to the specific `retrieve_output` functionality.

The modifications were tested with the Dag provided below:

```py
from airflow import DAG
from airflow.utils.dates import days_ago
from datetime import timedelta

from docker import types
from airflow.providers.docker.operators.docker import DockerOperator
from airflow.providers.docker.operators.docker_swarm import DockerSwarmOperator

params = {
    'dag_id': 'test_xcom_docker_docker_swarm',
    'catchup': False,
    'max_active_runs': 1,
    'default_args': {
        'owner': 'airflow',
        'start_date': days_ago(1),
        'retries': 1,
        'retry_delay': timedelta(minutes=5)
    }
}

with DAG(**params) as dag:
    write_xcom_docker = DockerOperator(
        task_id='write_xcom_docker',
        image='python:latest',
        api_version='auto',
        command=""""""python -c '

import os
import pickle

capitals = {
  ""Canada"": ""Ottawa"", 
  ""England"": ""London"",
  ""France"": ""Paris"",
  ""Germany"": ""Berlin"", 
}

file_path = ""/tmp/variable.pickle""
with open(file_path, ""wb+"") as file:
    pickle.dump(capitals, file)

    '
    """""",
        retrieve_output=True,
        retrieve_output_path='/tmp/variable.pickle')

    write_xcom_docker_swarm = DockerSwarmOperator(
        task_id='write_xcom_docker_swarm',
        image='python:latest',
        api_version='auto',
        command=""""""python -c '

import os
import pickle

capitals = {
  ""Canada"": ""Ottawa"", 
  ""England"": ""London"",
  ""France"": ""Paris"",
  ""Germany"": ""Berlin"", 
}

file_path = ""/tmp/variable.pickle""
with open(file_path, ""wb+"") as file:
    pickle.dump(capitals, file)

    '
    """""",
        retrieve_output=True,
        retrieve_output_path='/tmp/variable.pickle')

    write_xcom_docker_swarm_replicas = DockerSwarmOperator(
        task_id='write_xcom_docker_swarm_replicas',
        image='python:latest',
        api_version='auto',
        command=""""""python -c '

import os
import pickle

capitals = {
  ""Canada"": ""Ottawa"", 
  ""England"": ""London"",
  ""France"": ""Paris"",
  ""Germany"": ""Berlin"", 
}

file_path = ""/tmp/variable.pickle""
with open(file_path, ""wb+"") as file:
    pickle.dump(capitals, file)

    '
    """""",
        retrieve_output=True,
        retrieve_output_path='/tmp/variable.pickle',
        mode=types.ServiceMode(mode=""replicated"", replicas=2))

write_xcom_docker >> write_xcom_docker_swarm >> write_xcom_docker_swarm_replicas
```

Here the results:
- `DockerOperator`:
![image](https://github.com/user-attachments/assets/5bb550a3-62ba-4a53-a119-f17bf0211612)
- `DockerSwarmOperator` without replication: 
![image](https://github.com/user-attachments/assets/b4c89d4d-0fdf-4388-ba81-4ae5191e9e60)
- `DockerSwarmOperator` with `replicas=2`: 
![image](https://github.com/user-attachments/assets/9b4c85ba-15a6-478c-ad3b-63b0831f2a6b)
As `replicas=2` in the Service configuration inside the DAG, 2 files were loaded inside the `return_value` XCOM.

If needed, I can create a specific PR for the `v2-10-test` branch !

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rgriffier,2024-08-16 11:58:55+00:00,[],2024-10-15 19:18:19+00:00,2024-08-22 08:35:22+00:00,https://github.com/apache/airflow/pull/41531,"[('area:providers', ''), ('provider:docker', '')]","[{'comment_id': 2293376751, 'issue_id': 2470130976, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 16, 11, 58, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304094404, 'issue_id': 2470130976, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 22, 8, 35, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304588105, 'issue_id': 2470130976, 'author': 'rgriffier', 'body': '@potiuk Thank you for validating the PR. Do I need to make a specific one for `2.10` so that the feature is available in the next release 2.XX?', 'created_at': datetime.datetime(2024, 8, 22, 12, 48, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304593186, 'issue_id': 2470130976, 'author': 'potiuk', 'body': 'This is provider-only change - it will be released in the next docker provider\r\n\r\nNote! Current state of airflow development is that technically there will be no new 2.* releases any more (just 2.11 as a bridge release for Airflow 3) - but users will be able to upgrade providers for 2 for quite some time and we will keep on releasing them.', 'created_at': datetime.datetime(2024, 8, 22, 12, 50, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408945693, 'issue_id': 2470130976, 'author': 'spoutin', 'body': 'unless I\'m missing something, the docker sdk function to `get_archive` is only available on the the workers that hosted the docker container since it uses the container ID.  If you have a multi node setup how are you able to retrieve the logs if the airflow worker that executed the docker container is not on the same docker swarm worker node?\r\n\r\ni also noticed that you\'re calling the `inspect_container`, this has the same limitation; you can only inspect containers that are on the same worker.\r\n\r\nThe docker ""tasks"" APIs are what we should be using to access Docker Services tasks not the ""container"" APIs.\r\n\r\nWhat\'s confusing me is that this was tested but I\'m not sure how.  Unless I\'m confused about the Docker Swarm APIs or there is some form of a Docker API gateway / proxy that is routing the docker APIs to the correct workers I\'m not sure how this is working.', 'created_at': datetime.datetime(2024, 10, 13, 11, 45, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409653361, 'issue_id': 2470130976, 'author': 'potiuk', 'body': 'Any comments for the above @rgriffier ?', 'created_at': datetime.datetime(2024, 10, 14, 1, 43, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414695704, 'issue_id': 2470130976, 'author': 'rgriffier', 'body': ""I'll have to check, I did test the code in Swarm mode but I'm not sure whether I was testing with a container deployed on a node other than the manager node... I'll have a look at it this weekend, I'll tell you again (but I'm fairly convinced by @spoutin's arguments, I'm afraid I tested in a configuration far from the reality of use)..."", 'created_at': datetime.datetime(2024, 10, 15, 18, 11, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414821992, 'issue_id': 2470130976, 'author': 'rgriffier', 'body': ""I've just checked and it doesn't work if the container being deployed is not on the same host as the manager.\r\nMy bad, I wasn't on my usual infrastructure and I didn't notice that I only had one node. @spoutin comment was right on the mark. I've seen in your PR that you're proposing to delete what I'd added, which is actually a good idea. I thinks it's impossible to do what I wanted with the Docker API at the moment: Swarm mode does not allow containers deployed on worker nodes to be queried from the manager. Sorry for the bad testing."", 'created_at': datetime.datetime(2024, 10, 15, 19, 18, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-16 11:58:59 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-08-22 08:35:24 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

rgriffier (Issue Creator) on (2024-08-22 12:48:02 UTC): @potiuk Thank you for validating the PR. Do I need to make a specific one for `2.10` so that the feature is available in the next release 2.XX?

potiuk on (2024-08-22 12:50:33 UTC): This is provider-only change - it will be released in the next docker provider

Note! Current state of airflow development is that technically there will be no new 2.* releases any more (just 2.11 as a bridge release for Airflow 3) - but users will be able to upgrade providers for 2 for quite some time and we will keep on releasing them.

spoutin on (2024-10-13 11:45:18 UTC): unless I'm missing something, the docker sdk function to `get_archive` is only available on the the workers that hosted the docker container since it uses the container ID.  If you have a multi node setup how are you able to retrieve the logs if the airflow worker that executed the docker container is not on the same docker swarm worker node?

i also noticed that you're calling the `inspect_container`, this has the same limitation; you can only inspect containers that are on the same worker.

The docker ""tasks"" APIs are what we should be using to access Docker Services tasks not the ""container"" APIs.

What's confusing me is that this was tested but I'm not sure how.  Unless I'm confused about the Docker Swarm APIs or there is some form of a Docker API gateway / proxy that is routing the docker APIs to the correct workers I'm not sure how this is working.

potiuk on (2024-10-14 01:43:04 UTC): Any comments for the above @rgriffier ?

rgriffier (Issue Creator) on (2024-10-15 18:11:55 UTC): I'll have to check, I did test the code in Swarm mode but I'm not sure whether I was testing with a container deployed on a node other than the manager node... I'll have a look at it this weekend, I'll tell you again (but I'm fairly convinced by @spoutin's arguments, I'm afraid I tested in a configuration far from the reality of use)...

rgriffier (Issue Creator) on (2024-10-15 19:18:18 UTC): I've just checked and it doesn't work if the container being deployed is not on the same host as the manager.
My bad, I wasn't on my usual infrastructure and I didn't notice that I only had one node. @spoutin comment was right on the mark. I've seen in your PR that you're proposing to delete what I'd added, which is actually a good idea. I thinks it's impossible to do what I wanted with the Docker API at the moment: Swarm mode does not allow containers deployed on worker nodes to be queried from the manager. Sorry for the bad testing.

"
2470123293,pull_request,closed,,Update version_added field for config that are released in 2.10,,utkarsharma2,2024-08-16 11:54:11+00:00,[],2024-08-16 12:56:58+00:00,2024-08-16 12:56:58+00:00,https://github.com/apache/airflow/pull/41530,[],[],
2470079162,pull_request,closed,,Chart: Default airflow version to 2.10.0,,utkarsharma2,2024-08-16 11:27:05+00:00,[],2025-02-05 15:51:59+00:00,2024-08-17 18:39:31+00:00,https://github.com/apache/airflow/pull/41529,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2470052604,pull_request,closed,,Airflow 2.10.0 has been released,,utkarsharma2,2024-08-16 11:12:06+00:00,[],2024-08-21 07:50:08+00:00,2024-08-21 07:50:06+00:00,https://github.com/apache/airflow/pull/41528,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2470049747,pull_request,closed,,Refactor DataprocCreateBatchOperator and Dataproc system tests,"Refactored `DataprocCreateBatchOperator`:
- significantly refactored the `execute()` method for decreasing its accumulated complexity and code duplication.
- made the `batch_id` parameter optional as it is supported by API
- made the `region` parameter required because (1) it is required by the API, and (2) it was already required de-facto because the operator used to raise and exception manually: `raise AirflowException(""Region should be set here"")`
- added a specific error message to the operator logs (in both deferrable=True|False modes), so it would be more convenient for users to debug their batch jobs using the operator logs directly.

Also additionally slight refactored Dataproc system tests:
- reduced parallelism
- added retry to cluster creation tasks in a hope to suppress [the error](https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-vm-creation)

This PR also rolls back changes in pre-commit hook made for Dataflow system tests. From now those changes rea not needed.",moiseenkov,2024-08-16 11:10:30+00:00,[],2024-08-16 17:12:14+00:00,2024-08-16 17:12:14+00:00,https://github.com/apache/airflow/pull/41527,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:system-tests', '')]",[],
2469828518,pull_request,closed,,Chart: Allow hybrid executors,"Airflow 2.10.0 has the new feature to use multiple executors. The value schema check in the current Helm chart doesn't allow this because it has a strict list of allowed values. I removed this enum check list to enable custom and combinations of executors.

Another change is the `executor` label in the scheduler Deployment. I removed this label because it has no functional use. Reasons are:

1. Characters such as `:` are not allowed in label values. This prevents me from using short names such as `airflow.providers.amazon.aws.executors.ecs.AwsEcsExecutor:AwsEcsExecutor`
2. The label value can have max 63 characters. Even if (1) is okay, we still need to do some string truncating.

~Another change is the `executor` label in the scheduler Deployment. Because Kubernetes allows max 63 characters for label values, and hybrid executor values can easily exceed this limit, therefore I added a `trunc -63` to prevent this. This value has no functional use AFAIK, so doing a truncate here will not cause any functional problems.~


",LipuFei,2024-08-16 08:57:14+00:00,[],2024-10-13 00:16:29+00:00,2024-10-13 00:16:28+00:00,https://github.com/apache/airflow/pull/41524,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2306476685, 'issue_id': 2469828518, 'author': 'LipuFei', 'body': ""> We have a ton of conditionals like [if CeleryExecutor](https://github.com/apache/airflow/blob/09ce3a5100c266369350c85e9f9a0f72ecca9e98/chart/templates/workers/worker-deployment.yaml#L26) so we can provision the right stuff for the release, but you've not accounted for any of that with this change. Try it with `CeleryExecutor,KubernetesExecutor`, for example, to see the problems this brings.\r\n> \r\n> I think @hussein-awala idea of an array of executors makes sense, but I agree the shortname/enum thing is definitely a problem. We will need to come up with something here.\r\n\r\nI agree. After some digging, I indeed see a lot of references to `.Values.executor` everywhere, not to mention the `executor` references to `.Values.config.core.executor` and they need to be the same...\r\n\r\nI will work on this slowly, excluding the short name support. It's a lot more complex than I initially expected."", 'created_at': datetime.datetime(2024, 8, 23, 7, 34, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398254038, 'issue_id': 2469828518, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 8, 0, 14, 43, tzinfo=datetime.timezone.utc)}]","LipuFei (Issue Creator) on (2024-08-23 07:34:32 UTC): I agree. After some digging, I indeed see a lot of references to `.Values.executor` everywhere, not to mention the `executor` references to `.Values.config.core.executor` and they need to be the same...

I will work on this slowly, excluding the short name support. It's a lot more complex than I initially expected.

github-actions[bot] on (2024-10-08 00:14:43 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2469338635,pull_request,closed,,helm chart default airflow version update to 2.10.0,helm chart default airflow version update to 2.10.0,dirrao,2024-08-16 03:02:04+00:00,[],2024-08-16 11:49:01+00:00,2024-08-16 11:49:01+00:00,https://github.com/apache/airflow/pull/41521,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2293362809, 'issue_id': 2469338635, 'author': 'hussein-awala', 'body': 'This is one of the release manager tasks, it will be closed by #41529', 'created_at': datetime.datetime(2024, 8, 16, 11, 49, 1, tzinfo=datetime.timezone.utc)}]","hussein-awala on (2024-08-16 11:49:01 UTC): This is one of the release manager tasks, it will be closed by #41529

"
2469328456,pull_request,closed,,Util helper deprecated functions  removal,Util helper deprecated functions  removal,dirrao,2024-08-16 02:50:53+00:00,[],2024-08-21 19:45:30+00:00,2024-08-16 13:50:23+00:00,https://github.com/apache/airflow/pull/41520,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2469129434,pull_request,closed,,Partial fix for example_dynamodb_to_s3.py,"Partial fix for https://github.com/apache/airflow/pull/41304 but  `backup_db_to_point_in_time_incremental_export` still fails with ""Incremental export period from time should not be greater or equal to incremental export period to time""

We need to either figure that out (see troubleshooting steps in the other PR) or disable that task from running in the test.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-08-15 23:10:01+00:00,[],2024-08-16 11:17:34+00:00,2024-08-16 11:17:33+00:00,https://github.com/apache/airflow/pull/41517,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2469058726,pull_request,closed,,"Fix UI rendering issues if XCom values are INT, FLOAT, BOOL or NULL in web UI","closes: #41514 

Before:
![image](https://github.com/user-attachments/assets/a0863f7c-4bf4-4f11-89a1-b118e6ef96c3)

After:
![image](https://github.com/user-attachments/assets/c2f06a69-19dc-49df-955f-f223e5618374)
",jscheffl,2024-08-15 22:06:36+00:00,[],2024-08-30 09:14:45+00:00,2024-08-20 03:56:03+00:00,https://github.com/apache/airflow/pull/41516,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2468983324,pull_request,closed,,Fix `AwsTaskLogFetcher` missing logs,"Resolves #40875.

As mentioned in #40875, in some cases `EcsRunTaskOperator` have missing logs in the log group specified through `awslogs_group`. When `awslogs_group` is provided, the operator pull logs from `awslogs_group` (where the ECS task logs are) and log them so that the user can see them in the UI. The issue is, somehow (and I really cannot explain why), when multiple logs from `awslogs_group` have the same timestamp, only one of them (the first one) is logged. An example to better understand:

```
log_events = self._get_log_events(continuation_token)
for log_event in log_events:
    self.logger.info(self.event_to_str(log_event))
```

If `log_events` has 2 events with the same timestamp, `self.logger.info(self.event_to_str(log_event))` will run twice but will log once.

Adding a delay between the logging operators ""fix"" the issue.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-15 21:17:10+00:00,[],2024-09-20 21:27:10+00:00,2024-08-17 06:08:36+00:00,https://github.com/apache/airflow/pull/41515,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2468815901,pull_request,closed,,fix: unwrap Param objects when used as DagParam defaults,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Using a Param as a default in a DagParam _almost_ works; the ""Trigger DAG"" UI form is correctly generated taking into account the ""metadata"" in the Param (like `description`), and when triggering the DAG manually everything works as expected.

However when the DAG is triggered on a schedule (so that the default values are used) the DagParam resolves to the Param object at runtime (rather than the default _inside_ the Param object) which obviously breaks the DAG.

This is especially a problem when using the `@dag` decorator to define DagParams implicitly through the decorated functions default parameters. Without this fix, the utility of the `@dag` decorator is significantly diminished because only ""plain"" defaults (without any attached metadata to drive UI generation) can be used in the decorated function.",nickmyatt,2024-08-15 19:52:38+00:00,[],2024-10-13 00:16:29+00:00,2024-10-13 00:16:29+00:00,https://github.com/apache/airflow/pull/41513,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2292082065, 'issue_id': 2468815901, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 15, 19, 52, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295364126, 'issue_id': 2468815901, 'author': 'jscheffl', 'body': ""@nickmyatt I do not get the full point behind the adjustment. Description and change do not match or I just don't get it. Can you please post an example problematic DAG that I understand the problem root or usage?"", 'created_at': datetime.datetime(2024, 8, 18, 19, 24, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296180739, 'issue_id': 2468815901, 'author': 'nickmyatt', 'body': 'Hi @jscheffl, sorry I dashed this fix off in a bit of a rush... Consider this DAG:\r\n\r\n```python\r\n@task\r\ndef log_array_param(array: Iterable[str]):\r\n    for elem in array:\r\n        print(elem)\r\n\r\n@dag(schedule=""* * * * * "", start_date=datetime.datetime.fromisoformat(""2024-01-01""))\r\ndef test_dag(\r\n    example_array_param=Param([""foo"", ""bar""], description=""An example of an array parameter""),\r\n):\r\n\r\n    log_array_param(example_array_param)\r\n\r\ntest_dag()\r\n```\r\n\r\nIf I run this from Airflow UI, I see something like this:\r\n\r\n![image](https://github.com/user-attachments/assets/90c5c00e-c721-43fa-905f-f94527b1c5a3)\r\n\r\nand clicking ""Trigger"" works as expected (note that `foo` and `bar` get logged on separate lines, so at runtime the task is getting passed `[""foo"", ""bar""]`)\r\n\r\n![image](https://github.com/user-attachments/assets/044c9d45-00b3-4beb-9c0e-c617dcf5b92a)\r\n\r\nHowever if the DAG gets run on a schedule, the task fails with the following exception:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/dag.py"", line 3053, in test\r\n    _run_task(\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/dag.py"", line 4358, in _run_task\r\n    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/utils/session.py"", line 94, in wrapper\r\n    return func(*args, **kwargs)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 2995, in _run_raw_task\r\n    return _run_raw_task(\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 273, in _run_raw_task\r\n    TaskInstance._execute_task_with_callbacks(\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 3149, in _execute_task_with_callbacks\r\n    result = self._execute_task(context, task_orig)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 3173, in _execute_task\r\n    return _execute_task(self, context, task_orig)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 767, in _execute_task\r\n    result = _execute_callable(context=context, **execute_callable_kwargs)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 733, in _execute_callable\r\n    return ExecutionCallableRunner(\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/utils/operator_helpers.py"", line 252, in run\r\n    return self.func(*args, **kwargs)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/baseoperator.py"", line 406, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/decorators/base.py"", line 266, in execute\r\n    return_value = super().execute(context)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/baseoperator.py"", line 406, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/operators/python.py"", line 238, in execute\r\n    return_value = self.execute_callable()\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/operators/python.py"", line 256, in execute_callable\r\n    return runner.run(*self.op_args, **self.op_kwargs)\r\n  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/utils/operator_helpers.py"", line 252, in run\r\n    return self.func(*args, **kwargs)\r\n  File ""/home/nickmyatt/airflow/dags/test_dag.py"", line 24, in log_array_param\r\n    for elem in array:\r\nTypeError: \'Param\' object is not iterable\r\n```\r\n\r\nwhich is because, at runtime, the task is getting passed `Param([""foo"", ""bar""], ....)` rather than `[""foo"", ""bar""]`.\r\n\r\nThis patch _unwraps_ that `Param`, so that the tasks always sees `[""foo"", ""bar""]`, regardless of whether manually triggered or run on schedule.', 'created_at': datetime.datetime(2024, 8, 19, 10, 5, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297019244, 'issue_id': 2468815901, 'author': 'jscheffl', 'body': 'Thanks for the context. This enlightens me. I was never using DAG level kwargs as you had in your example. I also could not find any reference about such usage in the TaskFlow docs (https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/taskflow.html) nor in the Params docs (https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/params.html).\r\n\r\nI am not a deeper level expert - so probably we need to have some guidance from @ashb / @uranusjr / @potiuk - Is the reported flaw a ""loop hole"" or really a bug? Is it an intended use to have DAG level decorator params defined with any arbitrary name or shall it be in the decorator as `params`?\r\n\r\nIf it is in-line with concepts we might need to add some more examples and also tests to it to ensure it is stable (would not like to accept only the 3 LoC in the PR solely w/o docs and tests). And it would be a new feature or just a stabilization and detailing of a non well documented concept?\r\n\r\nIf it is not intended use do we need to add some validators to prevent such use or at least generate warnings?\r\n\r\n(Personally I like the syntax as it is in the example but I assume it would need more documentation, tests and examples)', 'created_at': datetime.datetime(2024, 8, 19, 16, 55, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297213033, 'issue_id': 2468815901, 'author': 'nickmyatt', 'body': ""Here's an example of the use of the `@dag` decorator with kwargs: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#the-dag-decorator\r\n\r\nThat page says\r\n\r\n> As well as being a new way of making DAGs cleanly, the decorator also sets up any parameters you have in your function as DAG parameters, letting you [set those parameters when triggering the DAG](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dag-run.html#dagrun-parameters). You can then access the parameters from Python code, or from {{ context.params }} inside a [Jinja template](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/operators.html#concepts-jinja-templating).\r\n\r\nSo, it looks like the _intention_ is for these kwargs to be treated in the same way as the `params` argument to the `DAG` constructor, which _does_ accept `Param`s for richer trigger form definitions, as described here https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/params.html#use-params-to-provide-a-trigger-ui-form\r\n\r\nIt would seem strange that `@dag` is _deliberately_ less powerful than `DAG` in this regard."", 'created_at': datetime.datetime(2024, 8, 19, 18, 45, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297230720, 'issue_id': 2468815901, 'author': 'jscheffl', 'body': '> Here\'s an example of the use of the `@dag` decorator with kwargs: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#the-dag-decorator\r\n> \r\n> That page says\r\n> \r\n> > As well as being a new way of making DAGs cleanly, the decorator also sets up any parameters you have in your function as DAG parameters, letting you [set those parameters when triggering the DAG](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dag-run.html#dagrun-parameters). You can then access the parameters from Python code, or from {{ context.params }} inside a [Jinja template](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/operators.html#concepts-jinja-templating).\r\n> \r\n> So, it looks like the _intention_ is for these kwargs to be treated in the same way as the `params` argument to the `DAG` constructor, which _does_ accept `Param`s for richer trigger form definitions, as described here https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/params.html#use-params-to-provide-a-trigger-ui-form\r\n> \r\n> It would seem strange that `@dag` is _deliberately_ less powerful than `DAG` in this regard.\r\n\r\nYes. But what the docs say: use a Jinja2 template as templated params.So to be preceise I would interpret it as:\r\n```\r\n@dag(\r\n    schedule=""* * * * * "",\r\n    start_date=datetime.datetime.fromisoformat(""2024-01-01""),\r\n    params={\r\n        ""example_array_param"": Param([""foo"", ""bar""], description=""An example of an array parameter""),\r\n    },\r\n)\r\ndef test_dag(\r\n    example_array_param=""{{ params.example_array_param }}"",\r\n):\r\n    (...)\r\n```\r\n...but I agree that yours look much cleaner and Pythonic. (As well I have not checked the opposite if the Jinja templating works in this case)\r\n\r\nAs said it is not solely about fixing this alone but also to add proper tests and documentation. You don\'t want to have your feature breaking down because nobody knows about it and it is lost in a refactoring. And if it is cool would be great more people know about it.', 'created_at': datetime.datetime(2024, 8, 19, 18, 55, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297990613, 'issue_id': 2468815901, 'author': 'nickmyatt', 'body': 'I see that there is indeed no specific mention of combining `@dag` and `Param` in the docs, but I got the idea to try it by looking at documentation examples of `@dag` and `DAG(params=...)`, and was then surprised to find that the ""obvious"" combination of those examples doesn\'t work as I would have expected :)\r\n\r\nCurrently I am using a workaround that looks like\r\n\r\n```python\r\n@task\r\ndef unwrap_param(param):\r\n    if isinstance(param, Param):\r\n        return param.value\r\n    return param\r\n\r\n@dag(schedule=""* * * * * "", start_date=datetime.datetime.fromisoformat(""2024-01-01""))\r\ndef test_dag(\r\n    example_array_param=Param([""foo"", ""bar""], description=""An example of an array parameter""),\r\n):\r\n    example_array_param = unwrap_param(example_array_param)\r\n    log_array_param(example_array_param)\r\n```\r\n\r\nwhich does the same thing as the patch, but requires an extra `unwrap_param` task in every DAG to do the ""unwrapping"".\r\n\r\nI tried your suggestion, and the task prints out\r\n\r\n```\r\n{\r\n{\r\n \r\np\r\na\r\nr\r\na\r\nm\r\ns\r\n.\r\ne\r\nx\r\na\r\nm\r\np\r\nl\r\n# and so on ....\r\n```\r\n\r\nLooking at the implementation of `@dag`, I would guess that this is because `dag_obj.param` https://github.com/apache/airflow/blob/main/airflow/models/dag.py#L3887 instantiates a `DagParam`, which clobbers any existing param with that name https://github.com/apache/airflow/blob/563bc494ab5c610c46a60b2fe6beed742e3d588e/airflow/models/param.py#L325. Thus\r\n\r\n```\r\n    params={\r\n        ""example_array_param"": Param([""foo"", ""bar""], description=""An example of an array parameter""),\r\n    },\r\n```\r\n\r\nhas no effect. Moreover I\'m not sure how Jinja templates actually interact with TaskFlow-style parameter passing? I suspect they just don\'t get resolved. In general I\'m keen to avoid string templating (which is why I am using `@dag`), because\r\n\r\n- it doesn\'t work with static analysis\r\n- it requires `render_template_as_native_obj` to be useful, which looks like it needs to be turned on for the entire DAG, and so potentially changes the behaviour of any existing templates.\r\n\r\n---\r\n\r\nAll that said, what would be needed to consider this patch further? I can add a test if you could point me in the right direction, but I don\'t really have time to prepare documentation on a speculative basis, i.e. if there is a chance this PR could still be declined.', 'created_at': datetime.datetime(2024, 8, 20, 5, 22, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304857683, 'issue_id': 2468815901, 'author': 'nolan1999', 'body': 'I was about about to open an issue because i encountered the exact same problem.\r\n\r\nI think that either supporting `Param` in the `kwargs` or explicitly preventing it would be useful, here is what happened to me:\r\n- I want to manually trigger an existing DAG from the UI, but notice that the parameters are read as strings instead of python objects (in that case, lists).\r\n- I look at the documentation and see that with `Param` i can add JSON schema validation and get the casting to python types from the UI. The documentation only shows examples using `with DAG...`, but the documentation for the `@dag` decorator proposes it as an alternative so i (my mistake) assume feature parity.\r\n- I try using `Param` in the `@dag`-decorated function, test on the UI, everything works as expected (including the default).\r\n- I merge the changes and the first scheduled run fails.\r\n\r\nIt would be great if this PR could be worked on/merged. The current solution (using `params` instead of `kwargs`) looks like a workaround in my case since the rest of the DAGs in the codebase use the `kwargs` instead of the `params` to define DAG parameters.', 'created_at': datetime.datetime(2024, 8, 22, 14, 45, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398254105, 'issue_id': 2468815901, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 8, 0, 14, 45, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-15 19:52:42 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jscheffl on (2024-08-18 19:24:30 UTC): @nickmyatt I do not get the full point behind the adjustment. Description and change do not match or I just don't get it. Can you please post an example problematic DAG that I understand the problem root or usage?

nickmyatt (Issue Creator) on (2024-08-19 10:05:21 UTC): Hi @jscheffl, sorry I dashed this fix off in a bit of a rush... Consider this DAG:

```python
@task
def log_array_param(array: Iterable[str]):
    for elem in array:
        print(elem)

@dag(schedule=""* * * * * "", start_date=datetime.datetime.fromisoformat(""2024-01-01""))
def test_dag(
    example_array_param=Param([""foo"", ""bar""], description=""An example of an array parameter""),
):

    log_array_param(example_array_param)

test_dag()
```

If I run this from Airflow UI, I see something like this:

![image](https://github.com/user-attachments/assets/90c5c00e-c721-43fa-905f-f94527b1c5a3)

and clicking ""Trigger"" works as expected (note that `foo` and `bar` get logged on separate lines, so at runtime the task is getting passed `[""foo"", ""bar""]`)

![image](https://github.com/user-attachments/assets/044c9d45-00b3-4beb-9c0e-c617dcf5b92a)

However if the DAG gets run on a schedule, the task fails with the following exception:

```
Traceback (most recent call last):
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/dag.py"", line 3053, in test
    _run_task(
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/dag.py"", line 4358, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/utils/session.py"", line 94, in wrapper
    return func(*args, **kwargs)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 2995, in _run_raw_task
    return _run_raw_task(
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 3149, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 3173, in _execute_task
    return _execute_task(self, context, task_orig)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/baseoperator.py"", line 406, in wrapper
    return func(self, *args, **kwargs)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/decorators/base.py"", line 266, in execute
    return_value = super().execute(context)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/models/baseoperator.py"", line 406, in wrapper
    return func(self, *args, **kwargs)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/operators/python.py"", line 238, in execute
    return_value = self.execute_callable()
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/operators/python.py"", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File ""/home/nickmyatt/.pyenv/versions/3.10.4/lib/python3.10/site-packages/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
  File ""/home/nickmyatt/airflow/dags/test_dag.py"", line 24, in log_array_param
    for elem in array:
TypeError: 'Param' object is not iterable
```

which is because, at runtime, the task is getting passed `Param([""foo"", ""bar""], ....)` rather than `[""foo"", ""bar""]`.

This patch _unwraps_ that `Param`, so that the tasks always sees `[""foo"", ""bar""]`, regardless of whether manually triggered or run on schedule.

jscheffl on (2024-08-19 16:55:42 UTC): Thanks for the context. This enlightens me. I was never using DAG level kwargs as you had in your example. I also could not find any reference about such usage in the TaskFlow docs (https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/taskflow.html) nor in the Params docs (https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/params.html).

I am not a deeper level expert - so probably we need to have some guidance from @ashb / @uranusjr / @potiuk - Is the reported flaw a ""loop hole"" or really a bug? Is it an intended use to have DAG level decorator params defined with any arbitrary name or shall it be in the decorator as `params`?

If it is in-line with concepts we might need to add some more examples and also tests to it to ensure it is stable (would not like to accept only the 3 LoC in the PR solely w/o docs and tests). And it would be a new feature or just a stabilization and detailing of a non well documented concept?

If it is not intended use do we need to add some validators to prevent such use or at least generate warnings?

(Personally I like the syntax as it is in the example but I assume it would need more documentation, tests and examples)

nickmyatt (Issue Creator) on (2024-08-19 18:45:29 UTC): Here's an example of the use of the `@dag` decorator with kwargs: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#the-dag-decorator

That page says


So, it looks like the _intention_ is for these kwargs to be treated in the same way as the `params` argument to the `DAG` constructor, which _does_ accept `Param`s for richer trigger form definitions, as described here https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/params.html#use-params-to-provide-a-trigger-ui-form

It would seem strange that `@dag` is _deliberately_ less powerful than `DAG` in this regard.

jscheffl on (2024-08-19 18:55:11 UTC): Yes. But what the docs say: use a Jinja2 template as templated params.So to be preceise I would interpret it as:
```
@dag(
    schedule=""* * * * * "",
    start_date=datetime.datetime.fromisoformat(""2024-01-01""),
    params={
        ""example_array_param"": Param([""foo"", ""bar""], description=""An example of an array parameter""),
    },
)
def test_dag(
    example_array_param=""{{ params.example_array_param }}"",
):
    (...)
```
...but I agree that yours look much cleaner and Pythonic. (As well I have not checked the opposite if the Jinja templating works in this case)

As said it is not solely about fixing this alone but also to add proper tests and documentation. You don't want to have your feature breaking down because nobody knows about it and it is lost in a refactoring. And if it is cool would be great more people know about it.

nickmyatt (Issue Creator) on (2024-08-20 05:22:36 UTC): I see that there is indeed no specific mention of combining `@dag` and `Param` in the docs, but I got the idea to try it by looking at documentation examples of `@dag` and `DAG(params=...)`, and was then surprised to find that the ""obvious"" combination of those examples doesn't work as I would have expected :)

Currently I am using a workaround that looks like

```python
@task
def unwrap_param(param):
    if isinstance(param, Param):
        return param.value
    return param

@dag(schedule=""* * * * * "", start_date=datetime.datetime.fromisoformat(""2024-01-01""))
def test_dag(
    example_array_param=Param([""foo"", ""bar""], description=""An example of an array parameter""),
):
    example_array_param = unwrap_param(example_array_param)
    log_array_param(example_array_param)
```

which does the same thing as the patch, but requires an extra `unwrap_param` task in every DAG to do the ""unwrapping"".

I tried your suggestion, and the task prints out

```
{
{
 
p
a
r
a
m
s
.
e
x
a
m
p
l
# and so on ....
```

Looking at the implementation of `@dag`, I would guess that this is because `dag_obj.param` https://github.com/apache/airflow/blob/main/airflow/models/dag.py#L3887 instantiates a `DagParam`, which clobbers any existing param with that name https://github.com/apache/airflow/blob/563bc494ab5c610c46a60b2fe6beed742e3d588e/airflow/models/param.py#L325. Thus

```
    params={
        ""example_array_param"": Param([""foo"", ""bar""], description=""An example of an array parameter""),
    },
```

has no effect. Moreover I'm not sure how Jinja templates actually interact with TaskFlow-style parameter passing? I suspect they just don't get resolved. In general I'm keen to avoid string templating (which is why I am using `@dag`), because

- it doesn't work with static analysis
- it requires `render_template_as_native_obj` to be useful, which looks like it needs to be turned on for the entire DAG, and so potentially changes the behaviour of any existing templates.

---

All that said, what would be needed to consider this patch further? I can add a test if you could point me in the right direction, but I don't really have time to prepare documentation on a speculative basis, i.e. if there is a chance this PR could still be declined.

nolan1999 on (2024-08-22 14:45:28 UTC): I was about about to open an issue because i encountered the exact same problem.

I think that either supporting `Param` in the `kwargs` or explicitly preventing it would be useful, here is what happened to me:
- I want to manually trigger an existing DAG from the UI, but notice that the parameters are read as strings instead of python objects (in that case, lists).
- I look at the documentation and see that with `Param` i can add JSON schema validation and get the casting to python types from the UI. The documentation only shows examples using `with DAG...`, but the documentation for the `@dag` decorator proposes it as an alternative so i (my mistake) assume feature parity.
- I try using `Param` in the `@dag`-decorated function, test on the UI, everything works as expected (including the default).
- I merge the changes and the first scheduled run fails.

It would be great if this PR could be worked on/merged. The current solution (using `params` instead of `kwargs`) looks like a workaround in my case since the rest of the DAGs in the codebase use the `kwargs` instead of the `params` to define DAG parameters.

github-actions[bot] on (2024-10-08 00:14:45 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2468578339,pull_request,closed,,Add support for executing multiple sequential sql statements in AthenaOperator [defer support],"This PR introduces support for multiple queries in the `AthenaOperator` in the AWS provider for Apache Airflow
   - The `query` parameter now accepts a list of SQL strings in addition to a single string. This allows the execution of multiple queries in sequence within a single task.
   - A new optional parameter `split_statements` has been added.
   - The query execution logic has been refactored into a loop that processes each query individually, ensuring that all queries are executed or appropriately deferred.
   - The `execute_next_query` method has been introduced to handle the deferred execution of queries. This method replaces the `execute_complete` method.

**Note: I havenâ€™t worked on tests or docs yet, Iâ€™ll proceed with those once weâ€™re happy with the implementation.**",flolas,2024-08-15 17:33:43+00:00,[],2024-11-25 00:16:39+00:00,2024-11-25 00:16:39+00:00,https://github.com/apache/airflow/pull/41511,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2292607378, 'issue_id': 2468578339, 'author': 'eladkal', 'body': ""Can you clarify what's changed since https://github.com/apache/airflow/issues/34583#issuecomment-1762259858 ?"", 'created_at': datetime.datetime(2024, 8, 16, 2, 14, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293269207, 'issue_id': 2468578339, 'author': 'flolas', 'body': ""> Can you clarify what's changed since [#34583 (comment)](https://github.com/apache/airflow/issues/34583#issuecomment-1762259858)?\r\n\r\nOkay, you got me, lol! I think I made my point in [this comment](https://github.com/apache/airflow/issues/34583#issuecomment-1732598175).\r\n\r\nWhy did I opt for AthenaHook here? Unfortunately, DB API 2.0 does not specify a standard for async/awaitable query execution. I was considering #30451, but I found out that every library implements different async strategies, which would be really hard to maintain in Airflow (also see https://github.com/apache/airflow/issues/30451#issuecomment-1496043958).\r\n\r\nI think the decision between Athena SQL Hook and Athena Hook, and why we need to support both, is covered in the [docs](https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/operators/athena/index.html):\r\n```\r\nAmazon Athena (API): Choose this option if you need to execute a single statement without bringing back the results in Airflow.\r\n\r\nAmazon Athena SQL (DB API Connection): Opt for this if you need to execute multiple queries in the same operator, and itâ€™s essential to retrieve and process query results directly in Airflow, such as for sensing values or further data manipulation.\r\n```\r\n\r\nPerhaps another option is to support using both connections (Athena SQL Hook and Athena Hook) for AthenaOperator, but using PyAthena (Athena SQL Hook) for async executions does not help at all having the current implementation of the `AthenaTrigger`.\r\n\r\nNote: I havenâ€™t worked on tests or docs yet, Iâ€™ll proceed with those once weâ€™re happy with the implementation."", 'created_at': datetime.datetime(2024, 8, 16, 10, 39, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293878954, 'issue_id': 2468578339, 'author': 'eladkal', 'body': ""> Note: I havenâ€™t worked on tests or docs yet, Iâ€™ll proceed with those once weâ€™re happy with the implementation.\r\n\r\nIf now you believe we need both then what I am looking for is how to make it easier for users to understand when to use each one. I guess functionality is not overlapping otherwise we wouldn't need a 2nd one"", 'created_at': datetime.datetime(2024, 8, 16, 17, 21, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384537322, 'issue_id': 2468578339, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 1, 0, 17, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392661629, 'issue_id': 2468578339, 'author': 'eladkal', 'body': ""@flolas what is the status of this PR?\r\nAs mentioned before if you believe it's needed functionality and there is a valid use case for this one I am happy to proceed. I think it might be just an issue of doc clarification/compare between the different options of how users can intercat with Athena and when it's best to use which option."", 'created_at': datetime.datetime(2024, 10, 4, 2, 20, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482375433, 'issue_id': 2468578339, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 18, 9, 17, 14, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-16 02:14:21 UTC): Can you clarify what's changed since https://github.com/apache/airflow/issues/34583#issuecomment-1762259858 ?

flolas (Issue Creator) on (2024-08-16 10:39:01 UTC): Okay, you got me, lol! I think I made my point in [this comment](https://github.com/apache/airflow/issues/34583#issuecomment-1732598175).

Why did I opt for AthenaHook here? Unfortunately, DB API 2.0 does not specify a standard for async/awaitable query execution. I was considering #30451, but I found out that every library implements different async strategies, which would be really hard to maintain in Airflow (also see https://github.com/apache/airflow/issues/30451#issuecomment-1496043958).

I think the decision between Athena SQL Hook and Athena Hook, and why we need to support both, is covered in the [docs](https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/operators/athena/index.html):
```
Amazon Athena (API): Choose this option if you need to execute a single statement without bringing back the results in Airflow.

Amazon Athena SQL (DB API Connection): Opt for this if you need to execute multiple queries in the same operator, and itâ€™s essential to retrieve and process query results directly in Airflow, such as for sensing values or further data manipulation.
```

Perhaps another option is to support using both connections (Athena SQL Hook and Athena Hook) for AthenaOperator, but using PyAthena (Athena SQL Hook) for async executions does not help at all having the current implementation of the `AthenaTrigger`.

Note: I havenâ€™t worked on tests or docs yet, Iâ€™ll proceed with those once weâ€™re happy with the implementation.

eladkal on (2024-08-16 17:21:27 UTC): If now you believe we need both then what I am looking for is how to make it easier for users to understand when to use each one. I guess functionality is not overlapping otherwise we wouldn't need a 2nd one

github-actions[bot] on (2024-10-01 00:17:07 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

eladkal on (2024-10-04 02:20:47 UTC): @flolas what is the status of this PR?
As mentioned before if you believe it's needed functionality and there is a valid use case for this one I am happy to proceed. I think it might be just an issue of doc clarification/compare between the different options of how users can intercat with Athena and when it's best to use which option.

github-actions[bot] on (2024-11-18 09:17:14 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2468553387,pull_request,closed,,Fix variable interpolation in Airflow core release guide,,jedcunningham,2024-08-15 17:22:47+00:00,[],2024-08-15 19:37:05+00:00,2024-08-15 19:37:03+00:00,https://github.com/apache/airflow/pull/41510,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2468455300,pull_request,closed,,fix: docker decorator pyi signature,"A small fix for the docker decorator signature

Signature should be `list[Mount] | None` instead of `list[str] | None`

resolve #41508 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",benbenbang,2024-08-15 16:38:58+00:00,[],2024-08-17 11:43:14+00:00,2024-08-15 22:38:35+00:00,https://github.com/apache/airflow/pull/41509,"[('provider:docker', '')]",[],
2468447740,pull_request,closed,,Fixing user_confirmation for quit action for prepare-provider-documentation,"
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The quit action was a no-op for the `prepare-provider-documentation` command. It looked like so:
```
=================================================================================================  ===========  =======================================================================
Commit                                                                                             Committed    Subject
=================================================================================================  ===========  =======================================================================
`fcbff15bda <https://github.com/apache/airflow/commit/fcbff15bda151f70db0ca13fdde015bace5527c4>`_  2024-08-12   ``Bump minimum Airflow version in providers to Airflow 2.8.0 (#41396)``
=================================================================================================  ===========  =======================================================================

Does the provider: apache.beam have any changes apart from 'doc-only'?
Press y/N/q: q

Define the type of change for `Bump minimum Airflow version in providers to Airflow 2.8.0 (https://github.com/apache/airflow/pull/41396)` by referring to the above table
Type of change (b)ugfix, (f)eature, (x)breaking change, (m)misc, (s)kip, (q)uit ? ^C

Summary of prepared documentation:


No packages prepared!

```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-08-15 16:34:58+00:00,[],2024-08-16 12:00:10+00:00,2024-08-16 12:00:10+00:00,https://github.com/apache/airflow/pull/41507,"[('area:dev-tools', '')]",[],
2468413116,pull_request,closed,,Feature/ Get upstream task ids by state,"this PR add an ability to get all upstream tasks by state.
the current state is that user can get only upstream tasks without any state.

this can solve issues like this https://stackoverflow.com/questions/73740427/airflow-how-to-get-list-of-upstream-failed-tasks
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-15 16:20:47+00:00,[],2024-08-20 12:23:56+00:00,2024-08-20 12:05:09+00:00,https://github.com/apache/airflow/pull/41506,"[('type:new-feature', 'Changelog: New Features')]","[{'comment_id': 2295402432, 'issue_id': 2468413116, 'author': 'potiuk', 'body': 'I am not sure if we want to add this -> generally speaking, I **think** we want to get rid of the TaskInstance as model being available and used in Airflow 3 and use Airflow-sdk (with AIP-72) -  but that is pending POC from @ashb  so I am not sure if we will still be using TaskInstance for this kind of retrieval (especially that `Session` is passed in the method).', 'created_at': datetime.datetime(2024, 8, 18, 21, 36, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298730161, 'issue_id': 2468413116, 'author': 'romsharon98', 'body': '> this PR add an ability to get all upstream tasks by state. the current state is that user can get only upstream tasks without any state.\r\n> \r\n> this can solve issues like this https://stackoverflow.com/questions/73740427/airflow-how-to-get-list-of-upstream-failed-tasks\r\n\r\nI open a new PR with target branch v2-10-stabel.', 'created_at': datetime.datetime(2024, 8, 20, 12, 23, 54, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-18 21:36:58 UTC): I am not sure if we want to add this -> generally speaking, I **think** we want to get rid of the TaskInstance as model being available and used in Airflow 3 and use Airflow-sdk (with AIP-72) -  but that is pending POC from @ashb  so I am not sure if we will still be using TaskInstance for this kind of retrieval (especially that `Session` is passed in the method).

romsharon98 (Issue Creator) on (2024-08-20 12:23:54 UTC): I open a new PR with target branch v2-10-stabel.

"
2468175993,pull_request,closed,,Field Deletion Warning when editing Connections (#41144),"Cherry pick for 2.10.x

#41144


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-15 14:28:44+00:00,[],2024-08-30 11:54:22+00:00,2024-08-19 14:38:16+00:00,https://github.com/apache/airflow/pull/41504,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2468168140,pull_request,closed,,Fix try selector refresh (#41483),"Cherry pick a fix to the task history selector for 2.10.x #41483


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-15 14:26:48+00:00,[],2024-08-30 11:46:10+00:00,2024-08-19 13:01:49+00:00,https://github.com/apache/airflow/pull/41503,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2468141123,pull_request,closed,,Incorrect try number subtraction producing invalid span id for OTEL airflow (issue #41501),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR fixes the issue of try_number being incorrectly decremented in certain occasions when instrumenting and emitting span and span attributes for the task instance. try_number needed to be decremented or incremented in Airflow, depending on conditions and logic, but has been resolved in the PR: https://github.com/apache/airflow/pull/39336, and will be available in Airflow 2.10.0. Due to this fix, it is necessary for the parts where try_number was being decremented to not continue to do so for the OTEL span instrumentation.

closes #41501 
",howardyoo,2024-08-15 14:17:57+00:00,[],2024-08-30 09:02:35+00:00,2024-08-16 13:16:35+00:00,https://github.com/apache/airflow/pull/41502,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2293219573, 'issue_id': 2468141123, 'author': 'uranusjr', 'body': 'I wonder if this is related to the recent(-ish) try semantic changes? cc @jedcunningham', 'created_at': datetime.datetime(2024, 8, 16, 10, 3, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293488951, 'issue_id': 2468141123, 'author': 'howardyoo', 'body': '> The change looks good, could you update the PR title to something that describes it?\r\n\r\nSure, no problem! Updated the PR title.', 'created_at': datetime.datetime(2024, 8, 16, 13, 14, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293492313, 'issue_id': 2468141123, 'author': 'potiuk', 'body': ""> I wonder if this is related to the recent(-ish) try semantic changes?\r\n\r\nYep. It's in the description - result of #39336"", 'created_at': datetime.datetime(2024, 8, 16, 13, 16, 16, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-16 10:03:49 UTC): I wonder if this is related to the recent(-ish) try semantic changes? cc @jedcunningham

howardyoo (Issue Creator) on (2024-08-16 13:14:12 UTC): Sure, no problem! Updated the PR title.

potiuk on (2024-08-16 13:16:16 UTC): Yep. It's in the description - result of #39336

"
2467949404,pull_request,closed,,Mark TestSparkKubernetes test as db test,"This test missed the mark and it has not been detected because of a bugggy pytest behaviour https://github.com/pytest-dev/pytest/issues/12605 that we had to workaround in #41499

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-15 12:23:26+00:00,[],2024-08-15 14:02:40+00:00,2024-08-15 14:02:40+00:00,https://github.com/apache/airflow/pull/41500,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2467938356,pull_request,closed,,Fix Non-DB test calculation for main builds,"Pytest has a weird behaviour that it will not collect tests from parent folder when subfolder of it is specified after the parent folder. This caused some non-db tests from providers folder have been skipped during main build.

The issue in Pytest 8.2 (used to work before) is tracked at
https://github.com/pytest-dev/pytest/issues/12605

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-15 12:15:16+00:00,[],2024-08-30 09:03:40+00:00,2024-08-15 14:50:12+00:00,https://github.com/apache/airflow/pull/41499,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2291204282, 'issue_id': 2467938356, 'author': 'potiuk', 'body': 'Ok. Now we correctly fail Non-DB tests for spark kubernetes in ""main"" build - this will be fixed after #41500 is merged.', 'created_at': datetime.datetime(2024, 8, 15, 12, 46, 58, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-15 12:46:58 UTC): Ok. Now we correctly fail Non-DB tests for spark kubernetes in ""main"" build - this will be fixed after #41500 is merged.

"
2467843508,pull_request,closed,,Airflow 3: airflow date utils date_range and days_ago deprecations removal,Airflow 3: airflow date utils date_range and days_ago deprecations removal,dirrao,2024-08-15 10:58:03+00:00,['dirrao'],2024-08-21 19:45:29+00:00,2024-08-16 13:51:42+00:00,https://github.com/apache/airflow/pull/41496,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2291323567, 'issue_id': 2467843508, 'author': 'dirrao', 'body': '> it needs newsfragment to notify about the breaking change\r\n\r\nI have added the news fragment for this change.', 'created_at': datetime.datetime(2024, 8, 15, 14, 1, 24, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-15 14:01:24 UTC): I have added the news fragment for this change.

"
2467838357,pull_request,closed,,fix: get task dependencies without serializing task tree to string,"Currently `_get_parsed_dag_tree` uses `get_tree_view` which in degenerated case (like, in test `test_get_dag_tree_large_dag` can generate string tree representation taking multiple gigabytes of memory.

However, for what it's trying to accomplish, pretty much any temporary allocations are not necessary. This fix constructs task dependency tree without intermediate representation.

Previous memory consumption:

```
root@a24bae3584cb:/opt/airflow# pytest --memray tests/providers/openlineage/utils/test_utils.py::test_get_dag_tree_large_dag
=========================================================================================================================================================================== test session starts ============================================================================================================================================================================
platform linux -- Python 3.12.5, pytest-8.3.2, pluggy-1.5.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /opt/airflow
configfile: pyproject.toml
plugins: memray-1.7.0, timeouts-1.2.1, icdiff-0.9, mock-3.14.0, rerunfailures-14.0, requests-mock-1.12.1, xdist-3.6.1, asyncio-0.23.8, anyio-4.4.0, instafail-0.5.0, cov-5.0.0, time-machine-2.15.0, custom-exit-code-0.3.0
asyncio: mode=Mode.STRICT
setup timeout: 0.0s, execution timeout: 0.0s, teardown timeout: 0.0s
collected 1 item

tests/providers/openlineage/utils/test_utils.py::test_get_dag_tree_large_dag PASSED                                                                                                                                                                                                                                                                                  [100%]


============================================================================================================================================================================== MEMRAY REPORT ===============================================================================================================================================================================
Allocation results for tests/providers/openlineage/utils/test_utils.py::test_get_dag_tree_large_dag at the high watermark

	 ðŸ“¦ Total memory allocated: 5.4GiB
	 ðŸ“ Total allocations: 23
	 ðŸ“Š Histogram of allocation sizes: |â–â–â–ˆ  |
	 ðŸ¥‡ Biggest allocating functions:
		- _safe_get_dag_tree_view:/opt/airflow/airflow/providers/openlineage/utils/utils.py:446 -> 2.7GiB
		- get_tree_view:/opt/airflow/airflow/models/dag.py:2445 -> 2.7GiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB


=================================================================================================================================================================== Warning summary. Total: 3, Unique: 3 ===================================================================================================================================================================
airflow: total 1, unique 1
  collect: total 1, unique 1
other: total 2, unique 2
  collect: total 2, unique 2
Warnings saved into /opt/airflow/tests/warnings.txt file.
============================================================================================================================================================================ 1 passed in 8.60s =============================================================================================================================================================================
```

current memory consumption:

```
root@2788b43cb914:/opt/airflow# pytest --memray tests/providers/openlineage/utils/test_utils.py::test_get_dag_tree_large_dag
=========================================================================================================================================================================== test session starts ============================================================================================================================================================================
platform linux -- Python 3.12.5, pytest-8.3.2, pluggy-1.5.0 -- /usr/local/bin/python
cachedir: .pytest_cache
rootdir: /opt/airflow
configfile: pyproject.toml
plugins: memray-1.7.0, timeouts-1.2.1, icdiff-0.9, mock-3.14.0, rerunfailures-14.0, requests-mock-1.12.1, xdist-3.6.1, asyncio-0.23.8, anyio-4.4.0, instafail-0.5.0, cov-5.0.0, time-machine-2.15.0, custom-exit-code-0.3.0
asyncio: mode=Mode.STRICT
setup timeout: 0.0s, execution timeout: 0.0s, teardown timeout: 0.0s
collected 1 item

tests/providers/openlineage/utils/test_utils.py::test_get_dag_tree_large_dag PASSED                                                                                                                                                                                                                                                                                  [100%]


============================================================================================================================================================================== MEMRAY REPORT ===============================================================================================================================================================================
Allocation results for tests/providers/openlineage/utils/test_utils.py::test_get_dag_tree_large_dag at the high watermark

	 ðŸ“¦ Total memory allocated: 16.0MiB
	 ðŸ“ Total allocations: 30
	 ðŸ“Š Histogram of allocation sizes: |â–â–ˆ â–ƒâ–‡|
	 ðŸ¥‡ Biggest allocating functions:
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB
		- __setattr__:/opt/airflow/airflow/models/baseoperator.py:1191 -> 1.3MiB


=================================================================================================================================================================== Warning summary. Total: 3, Unique: 3 ===================================================================================================================================================================
airflow: total 1, unique 1
  collect: total 1, unique 1
other: total 2, unique 2
  collect: total 2, unique 2
Warnings saved into /opt/airflow/tests/warnings.txt file.
============================================================================================================================================================================ 1 passed in 2.49s =============================================================================================================================================================================
```",mobuchowski,2024-08-15 10:53:53+00:00,[],2024-08-15 14:45:31+00:00,2024-08-15 13:32:31+00:00,https://github.com/apache/airflow/pull/41494,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2291334258, 'issue_id': 2467838357, 'author': 'jlaneve', 'body': ""Nice! Do you know if there's an issue open to track the underlying function? This fixed it for OL but not for other consumers of that function"", 'created_at': datetime.datetime(2024, 8, 15, 14, 7, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291424996, 'issue_id': 2467838357, 'author': 'mobuchowski', 'body': '@jlaneve just created it. https://github.com/apache/airflow/issues/41505', 'created_at': datetime.datetime(2024, 8, 15, 14, 45, 30, tzinfo=datetime.timezone.utc)}]","jlaneve on (2024-08-15 14:07:27 UTC): Nice! Do you know if there's an issue open to track the underlying function? This fixed it for OL but not for other consumers of that function

mobuchowski (Issue Creator) on (2024-08-15 14:45:30 UTC): @jlaneve just created it. https://github.com/apache/airflow/issues/41505

"
2467475295,pull_request,closed,,Airflow 3: python operators deprecations removal,Airflow 3: python operators deprecations removal,dirrao,2024-08-15 06:06:27+00:00,['dirrao'],2024-12-03 00:17:40+00:00,2024-12-03 00:17:40+00:00,https://github.com/apache/airflow/pull/41493,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2291036803, 'issue_id': 2467475295, 'author': 'dirrao', 'body': '> We need to wait with breaking changes to core operators/sensors\r\n> \r\n> See https://lists.apache.org/thread/2dmlqkcmyomm4q7rrovygs6bw655zx07\r\n\r\nAre we planning to introduce new provider in Airflow 3?', 'created_at': datetime.datetime(2024, 8, 15, 10, 27, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309009112, 'issue_id': 2467475295, 'author': 'jscheffl', 'body': '> > We need to wait with breaking changes to core operators/sensors\r\n> > See https://lists.apache.org/thread/2dmlqkcmyomm4q7rrovygs6bw655zx07\r\n> \r\n> Are we planning to introduce new provider in Airflow 3?\r\n\r\nBut... @eladkal we shoudl ""clean-up"" before carrying the legacy to new operators.. or? In my eyes we shoudl not carry-over deprecations.', 'created_at': datetime.datetime(2024, 8, 25, 21, 57, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309009475, 'issue_id': 2467475295, 'author': 'jscheffl', 'body': 'Newsfragment is missing though :-D Please add...', 'created_at': datetime.datetime(2024, 8, 25, 21, 58, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309204887, 'issue_id': 2467475295, 'author': 'dirrao', 'body': '> Newsfragment is missing though :-D Please add...\r\n\r\nAdded the news fragment for this change.', 'created_at': datetime.datetime(2024, 8, 26, 2, 58, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309272491, 'issue_id': 2467475295, 'author': 'eladkal', 'body': '~If we move the operator to providers there is no need for newsfragment. The breaking change will be in providers not in core.~', 'created_at': datetime.datetime(2024, 8, 26, 4, 14, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313564538, 'issue_id': 2467475295, 'author': 'jscheffl', 'body': 'I see two other deprecations in python.py - can you also remove these in the scope of the PR?', 'created_at': datetime.datetime(2024, 8, 27, 21, 12, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315750660, 'issue_id': 2467475295, 'author': 'dirrao', 'body': '> Newsfragment is missing though :-D Please add...\r\n\r\nI have added the news fragment.', 'created_at': datetime.datetime(2024, 8, 28, 16, 4, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315779572, 'issue_id': 2467475295, 'author': 'dirrao', 'body': '> I see two other deprecations in python.py - can you also remove these in the scope of the PR?\r\n\r\nSerialization code refactoring changes added recently (may be 2.10). Does it make sense to remove them immediately?', 'created_at': datetime.datetime(2024, 8, 28, 16, 19, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2316272832, 'issue_id': 2467475295, 'author': 'jscheffl', 'body': ""> > I see two other deprecations in python.py - can you also remove these in the scope of the PR?\r\n> \r\n> Serialization code refactoring changes added recently (may be 2.10). Does it make sense to remove them immediately?\r\n\r\nDeprecated is deprecated I'd say. It is by warning announced to be gone. Even if it is just announced in 2.10, this means 6+ months of notice before release. As well if we not remove in 3.0, then we would need to carry until 4.0"", 'created_at': datetime.datetime(2024, 8, 28, 21, 21, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320753115, 'issue_id': 2467475295, 'author': 'dirrao', 'body': ""> > > I see two other deprecations in python.py - can you also remove these in the scope of the PR?\r\n> > \r\n> > \r\n> > Serialization code refactoring changes added recently (may be 2.10). Does it make sense to remove them immediately?\r\n> \r\n> Deprecated is deprecated I'd say. It is by warning announced to be gone. Even if it is just announced in 2.10, this means 6+ months of notice before release. As well if we not remove in 3.0, then we would need to carry until 4.0\r\n\r\nYes. However, I want to reconfirm once before making the changes. \r\n@eladkal  / @potiuk WDYT?"", 'created_at': datetime.datetime(2024, 8, 30, 10, 13, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323101716, 'issue_id': 2467475295, 'author': 'potiuk', 'body': 'I think we need to wait for next dev call where we discuss ""standard"" provider\'s scope', 'created_at': datetime.datetime(2024, 9, 1, 1, 18, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402413754, 'issue_id': 2467475295, 'author': 'dirrao', 'body': '> I think we need to wait for next dev call where we discuss ""standard"" provider\'s scope\r\n\r\nAny update on this?', 'created_at': datetime.datetime(2024, 10, 9, 13, 52, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405446933, 'issue_id': 2467475295, 'author': 'dirrao', 'body': '@potiuk / @eladkal \r\nare we good to merge this PR?', 'created_at': datetime.datetime(2024, 10, 10, 15, 31, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409036726, 'issue_id': 2467475295, 'author': 'potiuk', 'body': '> @potiuk / @eladkal are we good to merge this PR?\r\n\r\nNo - not really - there is another change in progress - https://github.com/apache/airflow/pull/42081 that moves Python operators to ""standard"" providers, and I think what you did here should be done as part of it, rather than separate PR from you - so I think the best course of action is to close that one and get you @dirrao to review and make comment in the #42081 so that we make sure deprecations are removed in the standard provider.\r\n\r\nThis should be generally done in the same way for all operators that are part of the ""core"" - we should move all of them to "" ""standard"" and remove the deprecation ""along the way"". \r\n\r\ncc: @gopidesupavan.', 'created_at': datetime.datetime(2024, 10, 13, 16, 15, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505033180, 'issue_id': 2467475295, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 28, 0, 16, 25, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-15 10:27:52 UTC): Are we planning to introduce new provider in Airflow 3?

jscheffl on (2024-08-25 21:57:31 UTC): But... @eladkal we shoudl ""clean-up"" before carrying the legacy to new operators.. or? In my eyes we shoudl not carry-over deprecations.

jscheffl on (2024-08-25 21:58:52 UTC): Newsfragment is missing though :-D Please add...

dirrao (Issue Creator) on (2024-08-26 02:58:48 UTC): Added the news fragment for this change.

eladkal on (2024-08-26 04:14:09 UTC): ~If we move the operator to providers there is no need for newsfragment. The breaking change will be in providers not in core.~

jscheffl on (2024-08-27 21:12:14 UTC): I see two other deprecations in python.py - can you also remove these in the scope of the PR?

dirrao (Issue Creator) on (2024-08-28 16:04:37 UTC): I have added the news fragment.

dirrao (Issue Creator) on (2024-08-28 16:19:33 UTC): Serialization code refactoring changes added recently (may be 2.10). Does it make sense to remove them immediately?

jscheffl on (2024-08-28 21:21:10 UTC): Deprecated is deprecated I'd say. It is by warning announced to be gone. Even if it is just announced in 2.10, this means 6+ months of notice before release. As well if we not remove in 3.0, then we would need to carry until 4.0

dirrao (Issue Creator) on (2024-08-30 10:13:05 UTC): Yes. However, I want to reconfirm once before making the changes. 
@eladkal  / @potiuk WDYT?

potiuk on (2024-09-01 01:18:14 UTC): I think we need to wait for next dev call where we discuss ""standard"" provider's scope

dirrao (Issue Creator) on (2024-10-09 13:52:35 UTC): Any update on this?

dirrao (Issue Creator) on (2024-10-10 15:31:54 UTC): @potiuk / @eladkal 
are we good to merge this PR?

potiuk on (2024-10-13 16:15:43 UTC): No - not really - there is another change in progress - https://github.com/apache/airflow/pull/42081 that moves Python operators to ""standard"" providers, and I think what you did here should be done as part of it, rather than separate PR from you - so I think the best course of action is to close that one and get you @dirrao to review and make comment in the #42081 so that we make sure deprecations are removed in the standard provider.

This should be generally done in the same way for all operators that are part of the ""core"" - we should move all of them to "" ""standard"" and remove the deprecation ""along the way"". 

cc: @gopidesupavan.

github-actions[bot] on (2024-11-28 00:16:25 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2467333415,pull_request,closed,,Resolve deprecation warnings in Google Kubernetes Engine system tests (#39485),"Reworks the GKE example DAGs to remove deprecation warnings, also fixes a misprint in the deprecation warning message.

related: #39485

@VladaZakharova requested to be tagged for Google provider changes

@Taragolis as issue owner
",topherinternational,2024-08-15 03:47:39+00:00,[],2024-12-26 00:15:17+00:00,2024-12-26 00:15:17+00:00,https://github.com/apache/airflow/pull/41492,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2364261740, 'issue_id': 2467333415, 'author': 'eladkal', 'body': '@topherinternational @VladaZakharova what is the status of this PR?', 'created_at': datetime.datetime(2024, 9, 20, 18, 6, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455963054, 'issue_id': 2467333415, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 5, 0, 15, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2456841476, 'issue_id': 2467333415, 'author': 'VladaZakharova', 'body': ""> @topherinternational @VladaZakharova what is the status of this PR?\r\n\r\nHi! Waiting for @topherinternational to answer Max's question, since we think the system test will not work correctly with such configuration"", 'created_at': datetime.datetime(2024, 11, 5, 10, 47, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557905304, 'issue_id': 2467333415, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 21, 0, 14, 56, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-09-20 18:06:36 UTC): @topherinternational @VladaZakharova what is the status of this PR?

github-actions[bot] on (2024-11-05 00:15:09 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

VladaZakharova on (2024-11-05 10:47:47 UTC): Hi! Waiting for @topherinternational to answer Max's question, since we think the system test will not work correctly with such configuration

github-actions[bot] on (2024-12-21 00:14:56 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2467122771,pull_request,closed,,Fix news fragment check conditional,"We only want to fail the script if the 'towncrier check' call fails. The previous code always runs the '&& false' part (because the printf call always succeeds) and failed the job.
",uranusjr,2024-08-15 01:28:55+00:00,[],2024-08-15 03:29:16+00:00,2024-08-15 03:29:15+00:00,https://github.com/apache/airflow/pull/41491,"[('area:dev-tools', '')]",[],
2466908822,pull_request,closed,,Fix Kinesis Analytics system test,"With the default `force=False` the test fails on our CI because the data retention policy is blocking the deletion.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-08-14 21:58:08+00:00,[],2024-08-15 16:46:41+00:00,2024-08-15 12:47:48+00:00,https://github.com/apache/airflow/pull/41489,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]","[{'comment_id': 2290031797, 'issue_id': 2466908822, 'author': 'ferruzzi', 'body': ""There are some test failures but they don't appear to be related."", 'created_at': datetime.datetime(2024, 8, 14, 22, 32, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291205035, 'issue_id': 2466908822, 'author': 'potiuk', 'body': 'As strange as it seems I identified this failing tests as something that was not detected in main build because of pytest 8.* bug https://github.com/pytest-dev/pytest/issues/12605 \r\n\r\nI fixed it in #41500  and also workarounded the pytest bug in #41499', 'created_at': datetime.datetime(2024, 8, 15, 12, 47, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291701233, 'issue_id': 2466908822, 'author': 'ferruzzi', 'body': ""Strange, nice catch Jarek.  Github went down shortly after I saw the failing test here so I was thinking it was just a precursor for that and didn't look too deep yet."", 'created_at': datetime.datetime(2024, 8, 15, 16, 46, 40, tzinfo=datetime.timezone.utc)}]","ferruzzi (Issue Creator) on (2024-08-14 22:32:22 UTC): There are some test failures but they don't appear to be related.

potiuk on (2024-08-15 12:47:29 UTC): As strange as it seems I identified this failing tests as something that was not detected in main build because of pytest 8.* bug https://github.com/pytest-dev/pytest/issues/12605 

I fixed it in #41500  and also workarounded the pytest bug in #41499

ferruzzi (Issue Creator) on (2024-08-15 16:46:40 UTC): Strange, nice catch Jarek.  Github went down shortly after I saw the failing test here so I was thinking it was just a precursor for that and didn't look too deep yet.

"
2466576541,pull_request,closed,,Cleanup installed packages when running provider compatibility tests,"When running tests for providers with old Airflow versions, we have to make sure to uninstall all packages before installing old Airflow versions - because some of the packages can be installed by new Airflow version and they are missing in the old Airflow version.

This has already happened in #41402 with methodtools.

This PR adds `--clean-airflow-installation` flag to relevant breeze commands that install other airflow version. This is quite a bit slower as it requires to uninstall and reinstall packages so we do not set it by default.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 18:44:45+00:00,[],2024-08-18 22:12:30+00:00,2024-08-18 22:12:29+00:00,https://github.com/apache/airflow/pull/41488,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]","[{'comment_id': 2295414045, 'issue_id': 2466576541, 'author': 'potiuk', 'body': 'I had to add a bit more stuff to make the ""unwanted"" packages removal - and the ""--clean"" installation takes quite a bit more time, so I only enabled it in canary runs.', 'created_at': datetime.datetime(2024, 8, 18, 22, 12, 9, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-18 22:12:09 UTC): I had to add a bit more stuff to make the ""unwanted"" packages removal - and the ""--clean"" installation takes quite a bit more time, so I only enabled it in canary runs.

"
2466343029,pull_request,closed,,Add WebEncoder for trigger page rendering to avoid render failure,"Chery pick https://github.com/apache/airflow/pull/41350 for 2.10.x


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-14 16:54:41+00:00,[],2024-08-30 11:48:10+00:00,2024-08-15 14:23:05+00:00,https://github.com/apache/airflow/pull/41485,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2466307503,pull_request,closed,,Make PROD image building works in non-main PRs (#41480),"The PROD image building fails currently in non-main because it attempts to build source provider packages rather than use them from PyPi when PR is run against ""v-test"" branch.

This PR fixes it:

* PROD images in non-main-targetted build will pull providers from PyPI rather than build them
* they use PyPI constraints to install the providers
* they use UV - which should speed up building of the images

(cherry picked from commit 4d5f1c42a7873329b1b6b8b9b39db2c3033b46df)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 16:36:22+00:00,[],2024-08-30 11:48:48+00:00,2024-08-14 17:12:50+00:00,https://github.com/apache/airflow/pull/41484,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2289270284, 'issue_id': 2466307503, 'author': 'potiuk', 'body': 'Backporting the ""PROD building"" fix.', 'created_at': datetime.datetime(2024, 8, 14, 16, 37, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289318740, 'issue_id': 2466307503, 'author': 'potiuk', 'body': 'Again - we will have to merge it with ""leap of faith""', 'created_at': datetime.datetime(2024, 8, 14, 16, 57, 39, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-14 16:37:10 UTC): Backporting the ""PROD building"" fix.

potiuk (Issue Creator) on (2024-08-14 16:57:39 UTC): Again - we will have to merge it with ""leap of faith""

"
2466226833,pull_request,closed,,Fix try selector refresh,"Fixes: https://github.com/apache/airflow/issues/41462

We had two separate sources of truth on how many try numbers to show. It got messy during autorefresh. I think the TI History endpoint is good enough to rely on and use as a single source of truth.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-14 15:52:25+00:00,[],2024-08-30 09:06:22+00:00,2024-08-15 03:46:01+00:00,https://github.com/apache/airflow/pull/41483,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2289916426, 'issue_id': 2466226833, 'author': 'jscheffl', 'body': ""...and if somebody calls for 2.10.0.rc2 then we have a chance to cherry-pick this into as well... let's see"", 'created_at': datetime.datetime(2024, 8, 14, 21, 14, 18, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-14 21:14:18 UTC): ...and if somebody calls for 2.10.0.rc2 then we have a chance to cherry-pick this into as well... let's see

"
2466181864,pull_request,closed,,feat: openlineage listener captures hook-level lineage,Enable OpenLineage provider to get data collected using [AIP-62 mechanism](https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-62+Getting+Lineage+from+Hook+Instrumentation),mobuchowski,2024-08-14 15:28:53+00:00,[],2024-08-23 10:32:05+00:00,2024-08-23 10:32:05+00:00,https://github.com/apache/airflow/pull/41482,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2465941537,pull_request,closed,,Prevent provider lowest-dependency tests to run in non-main branch (#â€¦,"â€¦41478)

When running tests in v2-10-test branch, lowest depenency tests are run for providers - because when calculating separate tests, the ""skip_provider_tests"" has not been used to filter them out.

This PR fixes it.

(cherry picked from commit 75da5074969ec874040ea094d5afe00b7f02be76)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 14:03:42+00:00,[],2024-08-30 09:01:45+00:00,2024-08-14 15:01:30+00:00,https://github.com/apache/airflow/pull/41481,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2288966555, 'issue_id': 2465941537, 'author': 'potiuk', 'body': 'Since we cannot cherry-pick changes @ephraimbuddy @kaxil @utkarsharma2  @eladkal - -> this one will have to be merged in red status - please approve it based on a ""leap of faith"" .\r\n\r\nThe PROD image build will be only fixed after we merge and have another cherry-pick PR for #41480 (which also will have to be merged with failing PROD build - it will only get fixed after we merge it to v2-10-test.', 'created_at': datetime.datetime(2024, 8, 14, 14, 36, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288969630, 'issue_id': 2465941537, 'author': 'potiuk', 'body': 'BTW. this one works - because lowest dependency test only runs ""airflow"" core tests not provider tests:\r\n\r\n<img width=""1413"" alt=""Screenshot 2024-08-14 at 16 34 22"" src=""https://github.com/user-attachments/assets/c5df8cef-cef3-449d-8403-3fc99da7132e"">', 'created_at': datetime.datetime(2024, 8, 14, 14, 37, 25, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-14 14:36:35 UTC): Since we cannot cherry-pick changes @ephraimbuddy @kaxil @utkarsharma2  @eladkal - -> this one will have to be merged in red status - please approve it based on a ""leap of faith"" .

The PROD image build will be only fixed after we merge and have another cherry-pick PR for #41480 (which also will have to be merged with failing PROD build - it will only get fixed after we merge it to v2-10-test.

potiuk (Issue Creator) on (2024-08-14 14:37:25 UTC): BTW. this one works - because lowest dependency test only runs ""airflow"" core tests not provider tests:

<img width=""1413"" alt=""Screenshot 2024-08-14 at 16 34 22"" src=""https://github.com/user-attachments/assets/c5df8cef-cef3-449d-8403-3fc99da7132e"">

"
2465921230,pull_request,closed,,Make PROD image building works in non-main PRs,"The PROD image building fails currently in non-main because it attempts to build source provider packages rather than use them from PyPi when PR is run against ""v-test"" branch.

This PR fixes it:

* PROD images in non-main-targetted build will pull providers from PyPI rather than build them
* they use PyPI constraints to install the providers
* they use UV - which should speed up building of the images

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 13:57:43+00:00,[],2024-08-30 11:48:35+00:00,2024-08-14 14:59:46+00:00,https://github.com/apache/airflow/pull/41480,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2288973082, 'issue_id': 2465921230, 'author': 'potiuk', 'body': 'We need to get that one fixes and back-ported to v2-10-test in order to avoid PRs to v2-10-test fail with PROD image build failure', 'created_at': datetime.datetime(2024, 8, 14, 14, 38, 18, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-14 14:38:18 UTC): We need to get that one fixes and back-ported to v2-10-test in order to avoid PRs to v2-10-test fail with PROD image build failure

"
2465883357,pull_request,closed,,Airflow SFTPToGCSOperator sftp file exist check,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



Adds a **fail_on_sftp_file_not_exist** parameter to the `SFTPToGCSOperator`, allowing users to configure whether the task should fail or continue when the specified file is not found on the SFTP server.

---

### Description

This PR introduces a new parameter, `fail_on_sftp_file_not_exist`, to the `SFTPToGCSOperator`. This parameter allows users to specify whether the operator should fail the task if the specified file is not found on the SFTP server.

Previously, the operator would raise an exception and fail the task if the file was not found on the SFTP server. With the introduction of the `fail_on_sftp_file_not_exist` parameter, users now have the flexibility to configure the operator's behavior in such scenarios. By setting this parameter to `False`, the operator will log a warning message instead of failing the task, allowing the DAG to continue running.

This enhancement aligns with similar improvements requested for other operators, such as the `SFTPToS3Operator`.

### Changes

- Added the `fail_on_sftp_file_not_exist` parameter to the `SFTPToGCSOperator`.
- Updated the `_copy_single_object` method to conditionally handle missing files based on the value of `fail_on_sftp_file_not_exist`.
- Provided relevant test cases to ensure the new parameter functions as expected.

",kandharvishnu,2024-08-14 13:43:36+00:00,[],2024-11-04 09:36:46+00:00,2024-11-04 09:36:46+00:00,https://github.com/apache/airflow/pull/41479,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2392546506, 'issue_id': 2465883357, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 4, 0, 14, 57, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-10-04 00:14:57 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2465882017,pull_request,closed,,Prevent provider lowest-dependency tests to run in non-main branch,"When running tests in v2-10-test branch, lowest depenency tests are run for providers - because when calculating separate tests, the ""skip_provider_tests"" has not been used to filter them out.

This PR fixes it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 13:43:03+00:00,[],2024-08-30 09:24:21+00:00,2024-08-14 14:02:30+00:00,https://github.com/apache/airflow/pull/41478,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2288799514, 'issue_id': 2465882017, 'author': 'potiuk', 'body': 'That should significantly speed up v2-10-test runs.', 'created_at': datetime.datetime(2024, 8, 14, 13, 43, 46, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-14 13:43:46 UTC): That should significantly speed up v2-10-test runs.

"
2465782552,pull_request,closed,,Enable pull requests to be run from v*test branches (#41474),"Since we switch from direct push of cherry-picking to open PRs against v*test branch, we should enable PRs to run for the target branch.

(cherry picked from commit a9363e6a30d73a647ed7d45c92d46d1f6f98513f)


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 13:04:46+00:00,[],2024-08-30 11:49:54+00:00,2024-08-14 13:06:46+00:00,https://github.com/apache/airflow/pull/41476,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2465773155,pull_request,closed,,Update test_sftp_to_gcs.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kandharvishnu,2024-08-14 13:00:33+00:00,[],2024-08-14 13:27:40+00:00,2024-08-14 13:27:40+00:00,https://github.com/apache/airflow/pull/41475,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2465720105,pull_request,closed,,Enable pull requests to be run for v*test branches,"Since we switch from direct push of cherry-picking to open PRs against v*test branch, we should enable PRs to run for the target branch.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 12:36:55+00:00,[],2024-08-30 09:01:24+00:00,2024-08-14 12:52:23+00:00,https://github.com/apache/airflow/pull/41474,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2465683675,pull_request,closed,,Airflow SFTPToGCSOperator sftp file exist check,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



Adds a **fail_on_sftp_file_not_exist** parameter to the `SFTPToGCSOperator`, allowing users to configure whether the task should fail or continue when the specified file is not found on the SFTP server.

---

### Description

This PR introduces a new parameter, `fail_on_sftp_file_not_exist`, to the `SFTPToGCSOperator`. This parameter allows users to specify whether the operator should fail the task if the specified file is not found on the SFTP server.

Previously, the operator would raise an exception and fail the task if the file was not found on the SFTP server. With the introduction of the `fail_on_sftp_file_not_exist` parameter, users now have the flexibility to configure the operator's behavior in such scenarios. By setting this parameter to `False`, the operator will log a warning message instead of failing the task, allowing the DAG to continue running.

This enhancement aligns with similar improvements requested for other operators, such as the `SFTPToS3Operator`.

### Changes

- Added the `fail_on_sftp_file_not_exist` parameter to the `SFTPToGCSOperator`.
- Updated the `_copy_single_object` method to conditionally handle missing files based on the value of `fail_on_sftp_file_not_exist`.
- Provided relevant test cases to ensure the new parameter functions as expected.

",kandharvishnu,2024-08-14 12:19:13+00:00,[],2024-08-14 12:26:00+00:00,2024-08-14 12:25:59+00:00,https://github.com/apache/airflow/pull/41473,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2465538058,pull_request,closed,,Fix database isolation case for task mapping taskinstance tests,"Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-14 11:06:34+00:00,[],2024-09-17 11:06:49+00:00,2024-08-14 14:24:37+00:00,https://github.com/apache/airflow/pull/41471,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2288462638, 'issue_id': 2465538058, 'author': 'potiuk', 'body': 'Should fix the failing 32 task_instance tests.', 'created_at': datetime.datetime(2024, 8, 14, 11, 7, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288491115, 'issue_id': 2465538058, 'author': 'potiuk', 'body': ""> I think it looks fine, but I don't fully understand it. So will wait for someone else's review...\r\n\r\nThe problem was that task retrieved via get_task_instance wes None (but this is only needed for this test)"", 'created_at': datetime.datetime(2024, 8, 14, 11, 24, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288738039, 'issue_id': 2465538058, 'author': 'potiuk', 'body': 'Actually it turns out that the tests should be skipped altogether as they are monkeypatching calculate method locally.', 'created_at': datetime.datetime(2024, 8, 14, 13, 24, 53, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-14 11:07:13 UTC): Should fix the failing 32 task_instance tests.

potiuk (Issue Creator) on (2024-08-14 11:24:34 UTC): The problem was that task retrieved via get_task_instance wes None (but this is only needed for this test)

potiuk (Issue Creator) on (2024-08-14 13:24:53 UTC): Actually it turns out that the tests should be skipped altogether as they are monkeypatching calculate method locally.

"
2465512447,pull_request,closed,,[Backport] Deprecate implicit default DAG schedule,This backports #41321 to 2.10.,uranusjr,2024-08-14 10:52:49+00:00,[],2024-08-30 11:44:56+00:00,2024-08-20 03:58:17+00:00,https://github.com/apache/airflow/pull/41469,"[('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2288693526, 'issue_id': 2465512447, 'author': 'potiuk', 'body': 'I think you need to rebase it now @uranusjr to trigger tests after #41476 has been cherry-picked to v2-10-test', 'created_at': datetime.datetime(2024, 8, 14, 13, 7, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288844867, 'issue_id': 2465512447, 'author': 'potiuk', 'body': 'Yeah. Some small fixes are still needed as expected #41478 and  #41480 - likely some cache speedup will be needed as well', 'created_at': datetime.datetime(2024, 8, 14, 14, 0, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289363211, 'issue_id': 2465512447, 'author': 'potiuk', 'body': 'Ok. Try to rebase and see if it will work now @uranusjr', 'created_at': datetime.datetime(2024, 8, 14, 17, 13, 14, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-14 13:07:32 UTC): I think you need to rebase it now @uranusjr to trigger tests after #41476 has been cherry-picked to v2-10-test

potiuk on (2024-08-14 14:00:56 UTC): Yeah. Some small fixes are still needed as expected #41478 and  #41480 - likely some cache speedup will be needed as well

potiuk on (2024-08-14 17:13:14 UTC): Ok. Try to rebase and see if it will work now @uranusjr

"
2465368924,pull_request,closed,,Allow 3.x Docker images,"This is starting to fail since weâ€™ve bumped the Airflow versionâ€¦

I _think_ we canâ€™t get rid of the `2.` case just yet? Not sure about that.",uranusjr,2024-08-14 09:41:28+00:00,[],2024-08-14 09:47:35+00:00,2024-08-14 09:46:56+00:00,https://github.com/apache/airflow/pull/41466,"[('area:production-image', 'Production image improvements and fixes')]",[],
2465269040,pull_request,closed,,Add missing field to KubernetesHook,"Add missing setting of field _is_in_cluster=False in KubernetesHook if loading config file.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-08-14 08:53:22+00:00,[],2024-08-20 20:50:41+00:00,2024-08-20 20:50:41+00:00,https://github.com/apache/airflow/pull/41464,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2288422256, 'issue_id': 2465269040, 'author': 'potiuk', 'body': 'Can we add test to avoid regression ?', 'created_at': datetime.datetime(2024, 8, 14, 10, 43, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293041520, 'issue_id': 2465269040, 'author': 'VladaZakharova', 'body': 'Hi @potiuk @amoghrajesh !\r\nThis line was accidentally deleted in one of the previous PRs and I am trying to return it back :)', 'created_at': datetime.datetime(2024, 8, 16, 8, 11, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293072454, 'issue_id': 2465269040, 'author': 'amoghrajesh', 'body': 'I see, i wonder how no test caught it. Is there a way to add some test that catches such regressions?', 'created_at': datetime.datetime(2024, 8, 16, 8, 29, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293235788, 'issue_id': 2465269040, 'author': 'VladaZakharova', 'body': '> I see, i wonder how no test caught it. Is there a way to add some test that catches such regressions?\r\n\r\nsure, I will try ðŸ¥²', 'created_at': datetime.datetime(2024, 8, 16, 10, 14, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-14 10:43:46 UTC): Can we add test to avoid regression ?

VladaZakharova (Issue Creator) on (2024-08-16 08:11:53 UTC): Hi @potiuk @amoghrajesh !
This line was accidentally deleted in one of the previous PRs and I am trying to return it back :)

amoghrajesh on (2024-08-16 08:29:11 UTC): I see, i wonder how no test caught it. Is there a way to add some test that catches such regressions?

VladaZakharova (Issue Creator) on (2024-08-16 10:14:13 UTC): sure, I will try ðŸ¥²

"
2465250513,pull_request,open,,introduce `fail_policy`,"following first try based on 2.10.0b1 :https://github.com/apache/airflow/pull/41047

- introduce fail_policy parameter
- remove soft_fail and silent_fail parameters

- introduce the SKIP_ON_ANY_ERROR
- replace soft_fail by SKIP_ON_TIMEOUT
- replace silent_fail by IGNORE_ERROR

why ? 

cause currently `soft_fail` `never_fail` and `silent_fail` are confusing",raphaelauv,2024-08-14 08:44:17+00:00,[],2025-02-08 15:58:57+00:00,,https://github.com/apache/airflow/pull/41463,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:http', ''), ('provider:ftp', ''), ('provider:sftp', ''), ('provider:common-compat', '')]","[{'comment_id': 2308893314, 'issue_id': 2465250513, 'author': 'potiuk', 'body': 'Hey @raphaelauv -> maybe that is a misunderstanding. We can\'t really ""remove"" soft fail and replace it in the providers ""now\' - they will still have to support 2.8 - 2.10, so we cannot **really* remove soft_fail (and tests with it). This was not really possible in 2.10 and is not really going to be possible now. \r\n\r\nWhat I really see as the moment we implement it is when we have the new ""task-sdk"" in Airflow 3 - this is where it will be providing ""Base Sensor"" , ""Base Operator"" - and there we will be able to do similar things as with ""common.compat"" - where we will be able to add new functionality (""Fail Policy"")  without having to be tied with specific Airflow 3 version.\r\n\r\nI think the way implemented now it\'s not really usable - it won\'t work for Airfllow 2, and Airflow 3 will have the ""sdk"" implemented differently, so I am not sure it\'s worth spending time on it now. There is no ""easy"" way of implementing it without breaking current ""2.8, 2.9, 2.10"" behaviour.', 'created_at': datetime.datetime(2024, 8, 25, 15, 19, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308894693, 'issue_id': 2465250513, 'author': 'raphaelauv', 'body': 'hi, I did a compatible 2.8 2.9 2.10 implementation https://github.com/apache/airflow/pull/41047 but you said that it was not a feature welcome on 2.10 branch,\r\n\r\nso there go this PR that is waiting for airflow 3 and if there is a new ""sdk"" I will make it compatible.', 'created_at': datetime.datetime(2024, 8, 25, 15, 24, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308905483, 'issue_id': 2465250513, 'author': 'potiuk', 'body': '> hi, I did a compatible 2.8 2.9 2.10 implementation https://github.com/apache/airflow/pull/41047 but you said that it was not a feature welcome on 2.10 branch.\r\n\r\nI think there was no (easy) way to make it really 2.8-2.10 compatible. It was still changing behaviour for 2.10 - as I understood it and it was main reason why I hesitated with merging it - because we did not want to suddenly change behaviour of those sensors whe users will move between 2.8 and 2.10.\r\n\r\nThe problem with the change is it is implemented now is that you can\'t import  ""AirflowPokeFailException"" And ""FailPolicy"" from ""airflow 2"" in providers - because it is just missing in Airflow 2.8 - 2.10 and providers simply will not work for 2.8. 2.9. 2.10. And since we do not have Airlfow 3 for quite some time (6 months) - it means they won\'t work at all. And having it in 2.10 would not help to much (because the providers will still have to work for 2.8-2.9 where it is missing).\r\n\r\nBut the future implementation of it might be (or at least that\'s how I see it). Example SFTP provider:\r\n\r\n* airflow.providers.sftp depends on airflow.sdlk (which is independent from Airflow Version - and can be installed also in Airflow 2.8 - 2.10 (or whatever versions will be supported then)\r\n\r\n* the PokeFailException , Fail Policy and - most importantly - BaseSensorOperator will also come from the ""task-sdk"", not from ""airflow"".\r\n\r\n* the ""BaseSensorOperator"" from ""task-sdk"" - at least as long as Airflow 2 is supported - should support both - soft fail (with deprecation) and Fail Policy - and deprecation on soft_fail will suggest to switch to Airflow 3\'s Fail Policy and we might be able to drop it some day - and the thing there is that for those future providers, the user will be able to see the deprecation to Fail Policy even when running on Airflow 2.\r\n\r\nI am not sure if it makes it clearer - but with ""task.sdk"" and code for airflow BaseOperators / Sensor operators etc. coming from there, rather than from ""airflow"" we will be able to handle it quite a bit better. Or so I hope.', 'created_at': datetime.datetime(2024, 8, 25, 15, 58, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308907278, 'issue_id': 2465250513, 'author': 'raphaelauv', 'body': '```\r\n It was still changing behaviour for 2.10 .. because we did not want to suddenly change behaviour of those sensors\r\n```\r\nyes previous PR was fixing a bug introduce in airflow 2.7.1 that suddenly changed the behaviour of sensors\r\n\r\n```\r\nThe problem with the change is it is implemented now is that you can\'t import ""AirflowPokeFailException"" And ""FailPolicy"" from ""airflow 2"" in providers - because it is just missing in Airflow 2.8 - 2.10 and providers simply will not work for 2.8. 2.9. 2.10. And since we do not have Airlfow 3 for quite some time (6 months) - it means they won\'t work at all. And having it in 2.10 would not help to much (because the providers will still have to work for 2.8-2.9 where it is missing).\r\n```\r\n\r\nmy previous PR was compatible with 2.9 and 2.10, all tests were green  -> \r\n![image](https://github.com/user-attachments/assets/6848836c-20f4-4c42-a2e2-dd54a0887b7b)\r\n\r\n---\r\n ```\r\n...  but with ""task.sdk"" ...\r\n ```\r\n\r\nthanks for the info I will have a look to the AIP\r\nhttps://cwiki.apache.org/confluence/display/AIRFLOW/AIP-72+Task+Execution+Interface+aka+Task+SDK', 'created_at': datetime.datetime(2024, 8, 25, 16, 4, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308917159, 'issue_id': 2465250513, 'author': 'potiuk', 'body': '> yes previous PR was fixing a bug introduce in airflow 2.7.1 that suddenly changed the behaviour of sensors\r\n\r\n I think this is really a question of qualification of that change as a bug - when it works the way it worked, for such long (2.7.1 - 2.9.3) you cannot ""really"" see it as a bug any more - someone could have started relying on it. And there is no good solution to that issue - whetever you do, you break something, so better to keep the old behaviour, deprecate it eventually and **add** new way of doing things better.  Which I think Airflow 3 is better for rather than 2.10 becasue this ""new"" thing would only work for 2.10 which is the last releae of Airflow 2.\r\n\r\nUnfortunately I have not seen anyone else commenting on it and deciding, there was a rush to  release Airflow 2.10, so I did not want to make a decision myself.\r\n\r\nSorry for that. I was just cautious.', 'created_at': datetime.datetime(2024, 8, 25, 16, 33, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309625355, 'issue_id': 2465250513, 'author': 'raphaelauv', 'body': '` I have not seen anyone else commenting on it `\r\n\r\nyes it\'s true that this ""problem/bug/feature"" does not attract attention, I\'m always surprise how alone I feel when I found a bug on delivery semantics that can lead to data loss, and also how anecdotal and transparent it is for the user to change/break/fix these behaviors.\r\n\r\nThanks again for your review @potiuk , always a pleasure :+1:', 'created_at': datetime.datetime(2024, 8, 26, 8, 18, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406264399, 'issue_id': 2465250513, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 11, 0, 15, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411678880, 'issue_id': 2465250513, 'author': 'raphaelauv', 'body': 'no stale', 'created_at': datetime.datetime(2024, 10, 14, 16, 4, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2545116981, 'issue_id': 2465250513, 'author': 'eladkal', 'body': ""You can apply the breaking change to Airflow 3 and in providers work it so it will be backward compatible till min version of providers is Airflow 3. It's more code lines but it's the safe path to introduce this feature."", 'created_at': datetime.datetime(2024, 12, 16, 9, 55, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564371944, 'issue_id': 2465250513, 'author': 'raphaelauv', 'body': 'okay, I will re-add compatibility with 2.X , thanks for the review', 'created_at': datetime.datetime(2024, 12, 28, 16, 16, 35, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-25 15:19:34 UTC): Hey @raphaelauv -> maybe that is a misunderstanding. We can't really ""remove"" soft fail and replace it in the providers ""now' - they will still have to support 2.8 - 2.10, so we cannot **really* remove soft_fail (and tests with it). This was not really possible in 2.10 and is not really going to be possible now. 

What I really see as the moment we implement it is when we have the new ""task-sdk"" in Airflow 3 - this is where it will be providing ""Base Sensor"" , ""Base Operator"" - and there we will be able to do similar things as with ""common.compat"" - where we will be able to add new functionality (""Fail Policy"")  without having to be tied with specific Airflow 3 version.

I think the way implemented now it's not really usable - it won't work for Airfllow 2, and Airflow 3 will have the ""sdk"" implemented differently, so I am not sure it's worth spending time on it now. There is no ""easy"" way of implementing it without breaking current ""2.8, 2.9, 2.10"" behaviour.

raphaelauv (Issue Creator) on (2024-08-25 15:24:15 UTC): hi, I did a compatible 2.8 2.9 2.10 implementation https://github.com/apache/airflow/pull/41047 but you said that it was not a feature welcome on 2.10 branch,

so there go this PR that is waiting for airflow 3 and if there is a new ""sdk"" I will make it compatible.

potiuk on (2024-08-25 15:58:09 UTC): I think there was no (easy) way to make it really 2.8-2.10 compatible. It was still changing behaviour for 2.10 - as I understood it and it was main reason why I hesitated with merging it - because we did not want to suddenly change behaviour of those sensors whe users will move between 2.8 and 2.10.

The problem with the change is it is implemented now is that you can't import  ""AirflowPokeFailException"" And ""FailPolicy"" from ""airflow 2"" in providers - because it is just missing in Airflow 2.8 - 2.10 and providers simply will not work for 2.8. 2.9. 2.10. And since we do not have Airlfow 3 for quite some time (6 months) - it means they won't work at all. And having it in 2.10 would not help to much (because the providers will still have to work for 2.8-2.9 where it is missing).

But the future implementation of it might be (or at least that's how I see it). Example SFTP provider:

* airflow.providers.sftp depends on airflow.sdlk (which is independent from Airflow Version - and can be installed also in Airflow 2.8 - 2.10 (or whatever versions will be supported then)

* the PokeFailException , Fail Policy and - most importantly - BaseSensorOperator will also come from the ""task-sdk"", not from ""airflow"".

* the ""BaseSensorOperator"" from ""task-sdk"" - at least as long as Airflow 2 is supported - should support both - soft fail (with deprecation) and Fail Policy - and deprecation on soft_fail will suggest to switch to Airflow 3's Fail Policy and we might be able to drop it some day - and the thing there is that for those future providers, the user will be able to see the deprecation to Fail Policy even when running on Airflow 2.

I am not sure if it makes it clearer - but with ""task.sdk"" and code for airflow BaseOperators / Sensor operators etc. coming from there, rather than from ""airflow"" we will be able to handle it quite a bit better. Or so I hope.

raphaelauv (Issue Creator) on (2024-08-25 16:04:08 UTC): ```
 It was still changing behaviour for 2.10 .. because we did not want to suddenly change behaviour of those sensors
```
yes previous PR was fixing a bug introduce in airflow 2.7.1 that suddenly changed the behaviour of sensors

```
The problem with the change is it is implemented now is that you can't import ""AirflowPokeFailException"" And ""FailPolicy"" from ""airflow 2"" in providers - because it is just missing in Airflow 2.8 - 2.10 and providers simply will not work for 2.8. 2.9. 2.10. And since we do not have Airlfow 3 for quite some time (6 months) - it means they won't work at all. And having it in 2.10 would not help to much (because the providers will still have to work for 2.8-2.9 where it is missing).
```

my previous PR was compatible with 2.9 and 2.10, all tests were green  -> 
![image](https://github.com/user-attachments/assets/6848836c-20f4-4c42-a2e2-dd54a0887b7b)

---
 ```
...  but with ""task.sdk"" ...
 ```

thanks for the info I will have a look to the AIP
https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-72+Task+Execution+Interface+aka+Task+SDK

potiuk on (2024-08-25 16:33:44 UTC): I think this is really a question of qualification of that change as a bug - when it works the way it worked, for such long (2.7.1 - 2.9.3) you cannot ""really"" see it as a bug any more - someone could have started relying on it. And there is no good solution to that issue - whetever you do, you break something, so better to keep the old behaviour, deprecate it eventually and **add** new way of doing things better.  Which I think Airflow 3 is better for rather than 2.10 becasue this ""new"" thing would only work for 2.10 which is the last releae of Airflow 2.

Unfortunately I have not seen anyone else commenting on it and deciding, there was a rush to  release Airflow 2.10, so I did not want to make a decision myself.

Sorry for that. I was just cautious.

raphaelauv (Issue Creator) on (2024-08-26 08:18:31 UTC): ` I have not seen anyone else commenting on it `

yes it's true that this ""problem/bug/feature"" does not attract attention, I'm always surprise how alone I feel when I found a bug on delivery semantics that can lead to data loss, and also how anecdotal and transparent it is for the user to change/break/fix these behaviors.

Thanks again for your review @potiuk , always a pleasure :+1:

github-actions[bot] on (2024-10-11 00:15:01 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

raphaelauv (Issue Creator) on (2024-10-14 16:04:43 UTC): no stale

eladkal on (2024-12-16 09:55:17 UTC): You can apply the breaking change to Airflow 3 and in providers work it so it will be backward compatible till min version of providers is Airflow 3. It's more code lines but it's the safe path to introduce this feature.

raphaelauv (Issue Creator) on (2024-12-28 16:16:35 UTC): okay, I will re-add compatibility with 2.X , thanks for the review

"
2465139643,pull_request,closed,,fix: rm deprecated import in `common.sql`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #41460 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-14 07:48:50+00:00,[],2024-08-14 08:44:56+00:00,2024-08-14 08:42:50+00:00,https://github.com/apache/airflow/pull/41461,"[('area:providers', ''), ('provider:common-sql', '')]","[{'comment_id': 2288187770, 'issue_id': 2465139643, 'author': 'potiuk', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 8, 14, 8, 42, 58, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-14 08:42:58 UTC): Thanks!

"
2465083121,pull_request,closed,,Add 2.10.0rc1 to issue template,,ephraimbuddy,2024-08-14 07:17:21+00:00,[],2024-08-14 07:54:37+00:00,2024-08-14 07:54:35+00:00,https://github.com/apache/airflow/pull/41459,"[('area:dev-tools', '')]",[],
2465067288,pull_request,closed,,Describe behaviour of patch_already_checked docstring correctly,"Fix a small discrepancy in the docstring of `patch_already_checked`, which doesn't match the actual behavior.",BasPH,2024-08-14 07:08:09+00:00,[],2024-08-14 10:15:56+00:00,2024-08-14 10:15:56+00:00,https://github.com/apache/airflow/pull/41458,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2465008952,pull_request,closed,,Add Airflow 3 development readme,Lets have a doc that list the protocols we accepted for development of Airflow 3,eladkal,2024-08-14 06:29:53+00:00,[],2024-09-11 18:19:35+00:00,2024-09-11 18:19:24+00:00,https://github.com/apache/airflow/pull/41457,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2288620794, 'issue_id': 2465008952, 'author': 'uranusjr', 'body': 'Also, since I just opened a backport PR (https://github.com/apache/airflow/pull/41469)\r\n\r\nIs it expected to not have CI run? Should at least some test jobs run?', 'created_at': datetime.datetime(2024, 8, 14, 12, 32, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288631300, 'issue_id': 2465008952, 'author': 'potiuk', 'body': ""> Also, since I just opened a backport PR (#41469)\r\n> \r\n> Is it expected to not have CI run? Should at least some test jobs run?\r\n\r\nhttps://github.com/apache/airflow/pull/41474 -> PRs workflows were only enabled for main. It might need some more fixes, but let's merge it to main and close/reopen your PR to see if it will succeed."", 'created_at': datetime.datetime(2024, 8, 14, 12, 38, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296420477, 'issue_id': 2465008952, 'author': 'kaxil', 'body': 'Pre-commit (`doctoc`) is failing\r\n\r\n```\r\n+- [Milestones for PR](#milestones-for-pr)\r\n+  - [Set 2.10.x milestone](#set-210x-milestone)\r\n+  - [Set 2.11 milestone](#set-211-milestone)\r\n+  - [Set 3 milestone](#set-3-milestone)\r\n \r\n```', 'created_at': datetime.datetime(2024, 8, 19, 12, 8, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296950775, 'issue_id': 2465008952, 'author': 'jscheffl', 'body': '> Pre-commit (`doctoc`) is failing\r\n> \r\n> ```\r\n> +- [Milestones for PR](#milestones-for-pr)\r\n> +  - [Set 2.10.x milestone](#set-210x-milestone)\r\n> +  - [Set 2.11 milestone](#set-211-milestone)\r\n> +  - [Set 3 milestone](#set-3-milestone)\r\n>  \r\n> ```\r\n\r\nIf we need to find more things that we need to take care as committer/PMS, we might really re-structure not from the role of contributor/committer but but it in the reversed order to describe per use case and have a checklist per PR what we should do? Will there be more things coming?', 'created_at': datetime.datetime(2024, 8, 19, 16, 16, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296975929, 'issue_id': 2465008952, 'author': 'eladkal', 'body': ""> If we need to find more things that we need to take care as committer/PMS, we might really re-structure not from the role of contributor/committer but but it in the reversed order to describe per use case and have a checklist per PR what we should do? Will there be more things coming?\r\n\r\nWe can always change the doc structure (even now if you have a suggestion to make it more friendly)\r\nI assume we will add/remove stuff as we move forward. For example after 2.11 the 2.10 branch related stuff won't be needed."", 'created_at': datetime.datetime(2024, 8, 19, 16, 30, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2344373299, 'issue_id': 2465008952, 'author': 'eladkal', 'body': 'Merging. We can iterate/change the doc as needed', 'created_at': datetime.datetime(2024, 9, 11, 18, 19, 18, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-14 12:32:35 UTC): Also, since I just opened a backport PR (https://github.com/apache/airflow/pull/41469)

Is it expected to not have CI run? Should at least some test jobs run?

potiuk on (2024-08-14 12:38:08 UTC): https://github.com/apache/airflow/pull/41474 -> PRs workflows were only enabled for main. It might need some more fixes, but let's merge it to main and close/reopen your PR to see if it will succeed.

kaxil on (2024-08-19 12:08:59 UTC): Pre-commit (`doctoc`) is failing

```
+- [Milestones for PR](#milestones-for-pr)
+  - [Set 2.10.x milestone](#set-210x-milestone)
+  - [Set 2.11 milestone](#set-211-milestone)
+  - [Set 3 milestone](#set-3-milestone)
 
```

jscheffl on (2024-08-19 16:16:35 UTC): If we need to find more things that we need to take care as committer/PMS, we might really re-structure not from the role of contributor/committer but but it in the reversed order to describe per use case and have a checklist per PR what we should do? Will there be more things coming?

eladkal (Issue Creator) on (2024-08-19 16:30:36 UTC): We can always change the doc structure (even now if you have a suggestion to make it more friendly)
I assume we will add/remove stuff as we move forward. For example after 2.11 the 2.10 branch related stuff won't be needed.

eladkal (Issue Creator) on (2024-09-11 18:19:18 UTC): Merging. We can iterate/change the doc as needed

"
2464916885,pull_request,closed,,Update Airflow version to `3.0.0.dev0`,Main is now Airflow 3!,jedcunningham,2024-08-14 05:13:01+00:00,[],2024-08-14 09:46:06+00:00,2024-08-14 08:37:26+00:00,https://github.com/apache/airflow/pull/41456,"[('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2464703271,pull_request,closed,,Unify DAG schedule args and change default to None,"The arguments 'schedule_interval' and 'timetable' are removed from both the DAG class and the `@dag` decorator.
    
The default value of the 'schedule' argument (on both entities) is changed to None (i.e. a DAG will not have a schedule by default).
    
The 'timetable' attribute still exists on DAG, and is now the only value that reflects the DAG's schedule. The 'schedule_interval' attribute is removed from DAG.
    
The 'schedule_interval' on DagModel used to store a string representation of DAG's attribute of the same name, is now replaced by timetable_summary, which should (mostly?) work the same as before. We can fix minor UI differences as we go. Some use cases that rely on that field are also changed to use other fields instead (dataset_expression, for example, can be used to check whether a DAG is dataset-triggered).
    
The API field 'schedule_interval' has also been removed since that field no longer exists in the database. This has some side effects. The field previously contains some type information for delta values, but now becomes a simple string. It is unclear if anyone really needs the information, but we can always bring it back if needed.

Close #24842",uranusjr,2024-08-14 01:30:28+00:00,[],2024-08-26 09:06:57+00:00,2024-08-26 09:06:55+00:00,https://github.com/apache/airflow/pull/41453,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('provider:fab', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2301840275, 'issue_id': 2464703271, 'author': 'Lee-W', 'body': ""if we're to add migration rule for this PR to https://github.com/apache/airflow/issues/41641, we probably could do the following 2?\r\n\r\n* `schedule_interval` -> `timetable_summary`\r\n* `schedule=NOTSET,` `schedule=None` -> `schedule=timedelta(days=1),`"", 'created_at': datetime.datetime(2024, 8, 21, 11, 38, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303606435, 'issue_id': 2464703271, 'author': 'uranusjr', 'body': '> schedule_interval -> timetable_summary\r\n\r\nThese two are sort of interchangable for display purposes, but not if you want to use the value for something else. For example:\r\n\r\n```python\r\nwith DAG(schedule=timedelta(days=2)) as d1:\r\n    ...\r\n\r\n# This can not be changed to timetable_summary.\r\n# d1.timetable would work, but fail for other use cases.\r\nwith DAG(schedule=d1.schedule_interval) as d2:\r\n    ...\r\n```\r\n\r\nIf weâ€™re going the linter (ruff-like) route, this would be a case for showing a linting error without an automated fix available.\r\n\r\n> schedule=NOTSET, schedule=None -> schedule=timedelta(days=1),\r\n\r\n`schedule=NOTSET` should be changed to `timedelta(days=1)`, but `schedule=None` should be kept as-is (its behaviour is not changed in 3.0)', 'created_at': datetime.datetime(2024, 8, 22, 3, 32, 25, tzinfo=datetime.timezone.utc)}]","Lee-W on (2024-08-21 11:38:25 UTC): if we're to add migration rule for this PR to https://github.com/apache/airflow/issues/41641, we probably could do the following 2?

* `schedule_interval` -> `timetable_summary`
* `schedule=NOTSET,` `schedule=None` -> `schedule=timedelta(days=1),`

uranusjr (Issue Creator) on (2024-08-22 03:32:25 UTC): These two are sort of interchangable for display purposes, but not if you want to use the value for something else. For example:

```python
with DAG(schedule=timedelta(days=2)) as d1:
    ...

# This can not be changed to timetable_summary.
# d1.timetable would work, but fail for other use cases.
with DAG(schedule=d1.schedule_interval) as d2:
    ...
```

If weâ€™re going the linter (ruff-like) route, this would be a case for showing a linting error without an automated fix available.


`schedule=NOTSET` should be changed to `timedelta(days=1)`, but `schedule=None` should be kept as-is (its behaviour is not changed in 3.0)

"
2464623444,pull_request,closed,,Bump axios from 1.6.1 to 1.7.4 in /airflow/www,"Bumps [axios](https://github.com/axios/axios) from 1.6.1 to 1.7.4.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/axios/axios/releases"">axios's releases</a>.</em></p>
<blockquote>
<h2>Release v1.7.4</h2>
<h2>Release notes:</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>sec:</strong> CVE-2024-39338 (<a href=""https://redirect.github.com/axios/axios/issues/6539"">#6539</a>) (<a href=""https://redirect.github.com/axios/axios/issues/6543"">#6543</a>) (<a href=""https://github.com/axios/axios/commit/6b6b605eaf73852fb2dae033f1e786155959de3a"">6b6b605</a>)</li>
<li><strong>sec:</strong> disregard protocol-relative URL to remediate SSRF (<a href=""https://redirect.github.com/axios/axios/issues/6539"">#6539</a>) (<a href=""https://github.com/axios/axios/commit/07a661a2a6b9092c4aa640dcc7f724ec5e65bdda"">07a661a</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/levpachmanov"" title=""+47/-11 ([#6543](https://github.com/axios/axios/issues/6543) )"">Lev Pachmanov</a></li>
<li><!-- raw HTML omitted --> <a href=""https://github.com/hainenber"" title=""+49/-4 ([#6539](https://github.com/axios/axios/issues/6539) )"">Äá»— Trá»ng Háº£i</a></li>
</ul>
<h2>Release v1.7.3</h2>
<h2>Release notes:</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>adapter:</strong> fix progress event emitting; (<a href=""https://redirect.github.com/axios/axios/issues/6518"">#6518</a>) (<a href=""https://github.com/axios/axios/commit/e3c76fc9bdd03aa4d98afaf211df943e2031453f"">e3c76fc</a>)</li>
<li><strong>fetch:</strong> fix withCredentials request config (<a href=""https://redirect.github.com/axios/axios/issues/6505"">#6505</a>) (<a href=""https://github.com/axios/axios/commit/85d4d0ea0aae91082f04e303dec46510d1b4e787"">85d4d0e</a>)</li>
<li><strong>xhr:</strong> return original config on errors from XHR adapter (<a href=""https://redirect.github.com/axios/axios/issues/6515"">#6515</a>) (<a href=""https://github.com/axios/axios/commit/8966ee7ea62ecbd6cfb39a905939bcdab5cf6388"">8966ee7</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/DigitalBrainJS"" title=""+211/-159 ([#6518](https://github.com/axios/axios/issues/6518) [#6519](https://github.com/axios/axios/issues/6519) )"">Dmitriy Mozgovoy</a></li>
<li><!-- raw HTML omitted --> <a href=""https://github.com/ValeraS"" title=""+3/-3 ([#6515](https://github.com/axios/axios/issues/6515) )"">Valerii Sidorenko</a></li>
<li><!-- raw HTML omitted --> <a href=""https://github.com/prianyu"" title=""+2/-2 ([#6505](https://github.com/axios/axios/issues/6505) )"">prianYu</a></li>
</ul>
<h2>Release v1.7.2</h2>
<h2>Release notes:</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>fetch:</strong> enhance fetch API detection; (<a href=""https://redirect.github.com/axios/axios/issues/6413"">#6413</a>) (<a href=""https://github.com/axios/axios/commit/4f79aef81b7c4644328365bfc33acf0a9ef595bc"">4f79aef</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/DigitalBrainJS"" title=""+3/-3 ([#6413](https://github.com/axios/axios/issues/6413) )"">Dmitriy Mozgovoy</a></li>
</ul>
<h2>Release v1.7.1</h2>
<h2>Release notes:</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>fetch:</strong> fixed ReferenceError issue when TextEncoder is not available in the environment; (<a href=""https://redirect.github.com/axios/axios/issues/6410"">#6410</a>) (<a href=""https://github.com/axios/axios/commit/733f15fe5bd2d67e1fadaee82e7913b70d45dc5e"">733f15f</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/DigitalBrainJS"" title=""+14/-9 ([#6410](https://github.com/axios/axios/issues/6410) )"">Dmitriy Mozgovoy</a></li>
</ul>
<h2>Release v1.7.0</h2>
<h2>Release notes:</h2>
<h3>Features</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/axios/axios/blob/v1.x/CHANGELOG.md"">axios's changelog</a>.</em></p>
<blockquote>
<h2><a href=""https://github.com/axios/axios/compare/v1.7.3...v1.7.4"">1.7.4</a> (2024-08-13)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>sec:</strong> CVE-2024-39338 (<a href=""https://redirect.github.com/axios/axios/issues/6539"">#6539</a>) (<a href=""https://redirect.github.com/axios/axios/issues/6543"">#6543</a>) (<a href=""https://github.com/axios/axios/commit/6b6b605eaf73852fb2dae033f1e786155959de3a"">6b6b605</a>)</li>
<li><strong>sec:</strong> disregard protocol-relative URL to remediate SSRF (<a href=""https://redirect.github.com/axios/axios/issues/6539"">#6539</a>) (<a href=""https://github.com/axios/axios/commit/07a661a2a6b9092c4aa640dcc7f724ec5e65bdda"">07a661a</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/levpachmanov"" title=""+47/-11 ([#6543](https://github.com/axios/axios/issues/6543) )"">Lev Pachmanov</a></li>
<li><!-- raw HTML omitted --> <a href=""https://github.com/hainenber"" title=""+49/-4 ([#6539](https://github.com/axios/axios/issues/6539) )"">Äá»— Trá»ng Háº£i</a></li>
</ul>
<h2><a href=""https://github.com/axios/axios/compare/v1.7.2...v1.7.3"">1.7.3</a> (2024-08-01)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>adapter:</strong> fix progress event emitting; (<a href=""https://redirect.github.com/axios/axios/issues/6518"">#6518</a>) (<a href=""https://github.com/axios/axios/commit/e3c76fc9bdd03aa4d98afaf211df943e2031453f"">e3c76fc</a>)</li>
<li><strong>fetch:</strong> fix withCredentials request config (<a href=""https://redirect.github.com/axios/axios/issues/6505"">#6505</a>) (<a href=""https://github.com/axios/axios/commit/85d4d0ea0aae91082f04e303dec46510d1b4e787"">85d4d0e</a>)</li>
<li><strong>xhr:</strong> return original config on errors from XHR adapter (<a href=""https://redirect.github.com/axios/axios/issues/6515"">#6515</a>) (<a href=""https://github.com/axios/axios/commit/8966ee7ea62ecbd6cfb39a905939bcdab5cf6388"">8966ee7</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/DigitalBrainJS"" title=""+211/-159 ([#6518](https://github.com/axios/axios/issues/6518) [#6519](https://github.com/axios/axios/issues/6519) )"">Dmitriy Mozgovoy</a></li>
<li><!-- raw HTML omitted --> <a href=""https://github.com/ValeraS"" title=""+3/-3 ([#6515](https://github.com/axios/axios/issues/6515) )"">Valerii Sidorenko</a></li>
<li><!-- raw HTML omitted --> <a href=""https://github.com/prianyu"" title=""+2/-2 ([#6505](https://github.com/axios/axios/issues/6505) )"">prianYu</a></li>
</ul>
<h2><a href=""https://github.com/axios/axios/compare/v1.7.1...v1.7.2"">1.7.2</a> (2024-05-21)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>fetch:</strong> enhance fetch API detection; (<a href=""https://redirect.github.com/axios/axios/issues/6413"">#6413</a>) (<a href=""https://github.com/axios/axios/commit/4f79aef81b7c4644328365bfc33acf0a9ef595bc"">4f79aef</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/DigitalBrainJS"" title=""+3/-3 ([#6413](https://github.com/axios/axios/issues/6413) )"">Dmitriy Mozgovoy</a></li>
</ul>
<h2><a href=""https://github.com/axios/axios/compare/v1.7.0...v1.7.1"">1.7.1</a> (2024-05-20)</h2>
<h3>Bug Fixes</h3>
<ul>
<li><strong>fetch:</strong> fixed ReferenceError issue when TextEncoder is not available in the environment; (<a href=""https://redirect.github.com/axios/axios/issues/6410"">#6410</a>) (<a href=""https://github.com/axios/axios/commit/733f15fe5bd2d67e1fadaee82e7913b70d45dc5e"">733f15f</a>)</li>
</ul>
<h3>Contributors to this release</h3>
<ul>
<li><!-- raw HTML omitted --> <a href=""https://github.com/DigitalBrainJS"" title=""+14/-9 ([#6410](https://github.com/axios/axios/issues/6410) )"">Dmitriy Mozgovoy</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/axios/axios/commit/abd24a7367726616e60dfc04cb394b4be37cf597""><code>abd24a7</code></a> chore(release): v1.7.4 (<a href=""https://redirect.github.com/axios/axios/issues/6544"">#6544</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/6b6b605eaf73852fb2dae033f1e786155959de3a""><code>6b6b605</code></a> fix(sec): CVE-2024-39338 (<a href=""https://redirect.github.com/axios/axios/issues/6539"">#6539</a>) (<a href=""https://redirect.github.com/axios/axios/issues/6543"">#6543</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/07a661a2a6b9092c4aa640dcc7f724ec5e65bdda""><code>07a661a</code></a> fix(sec): disregard protocol-relative URL to remediate SSRF (<a href=""https://redirect.github.com/axios/axios/issues/6539"">#6539</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/c6cce43cd94489f655f4488c5a50ecaf781c94f2""><code>c6cce43</code></a> chore(release): v1.7.3 (<a href=""https://redirect.github.com/axios/axios/issues/6521"">#6521</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/e3c76fc9bdd03aa4d98afaf211df943e2031453f""><code>e3c76fc</code></a> fix(adapter): fix progress event emitting; (<a href=""https://redirect.github.com/axios/axios/issues/6518"">#6518</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/85d4d0ea0aae91082f04e303dec46510d1b4e787""><code>85d4d0e</code></a> fix(fetch): fix withCredentials request config (<a href=""https://redirect.github.com/axios/axios/issues/6505"">#6505</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/92cd8ed94362f929d3d0ed85ca84296c0ac8fd6d""><code>92cd8ed</code></a> chore(github): update ISSUE_TEMPLATE.md (<a href=""https://redirect.github.com/axios/axios/issues/6519"">#6519</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/8966ee7ea62ecbd6cfb39a905939bcdab5cf6388""><code>8966ee7</code></a> fix(xhr): return original config on errors from XHR adapter (<a href=""https://redirect.github.com/axios/axios/issues/6515"">#6515</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/0e4f9fa29077ebee4499facea6be1492b42e8a26""><code>0e4f9fa</code></a> chore(release): v1.7.2 (<a href=""https://redirect.github.com/axios/axios/issues/6414"">#6414</a>)</li>
<li><a href=""https://github.com/axios/axios/commit/4f79aef81b7c4644328365bfc33acf0a9ef595bc""><code>4f79aef</code></a> fix(fetch): enhance fetch API detection; (<a href=""https://redirect.github.com/axios/axios/issues/6413"">#6413</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/axios/axios/compare/v1.6.1...v1.7.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=axios&package-manager=npm_and_yarn&previous-version=1.6.1&new-version=1.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-08-14 00:58:57+00:00,[],2024-08-14 16:02:56+00:00,2024-08-14 16:02:53+00:00,https://github.com/apache/airflow/pull/41451,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2464327470,pull_request,closed,,Fix tests/sensors/test_external_task_sensor.py for database isolation tests ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: #41067
Similar tests were skipped so I skipped these two. 

**TLDR**
The problem seems like the `dag` is not attached to any session and the `dag` method is called when it is `None`. The error specifying `...is not bound to a Session;...`. We could try to somehow use `dag_maker` in this file to create `self.dag` for skipped tests. In that case, I assume the dag won't be None via passing the session to dag_maker. I may be missing some parts and adding dag_maker into the test context won't solve all issues. What do you think? 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-13 22:18:33+00:00,[],2024-08-13 23:47:11+00:00,2024-08-13 23:47:11+00:00,https://github.com/apache/airflow/pull/41450,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2464324728,pull_request,closed,,Temporarily disable doc publishing waiting for  ASF self-hosted runners,"The self hosted runners from ASF behave strangely:

https://issues.apache.org/jira/projects/INFRA/issues/INFRA-25990

So we need to disable publishing docs.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-13 22:16:27+00:00,[],2024-08-14 00:58:53+00:00,2024-08-14 00:58:16+00:00,https://github.com/apache/airflow/pull/41449,"[('area:dev-tools', '')]",[],
2464264933,pull_request,closed,,rephrase max_tis_per_query config docs,"The current phrasing for this config doesn't seem to be accurate anymore.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",RNHTTR,2024-08-13 21:34:48+00:00,[],2024-08-14 16:06:50+00:00,2024-08-14 06:12:01+00:00,https://github.com/apache/airflow/pull/41448,[],[],
2464213595,pull_request,closed,,Add missing schedule,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-13 21:02:11+00:00,[],2024-08-13 21:04:04+00:00,2024-08-13 21:04:04+00:00,https://github.com/apache/airflow/pull/41447,"[('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API"")]",[],
2464040779,pull_request,closed,,Rename @span decorator to @add_span to avoid collisions,"Previously if we ever needed to get the current span and manipulate it, we needed to name it with leading or trailing underscores to avoid collisions with the span decorator function name, which was a bit awkward.
",dstandish,2024-08-13 19:14:25+00:00,[],2024-08-13 21:49:17+00:00,2024-08-13 21:49:16+00:00,https://github.com/apache/airflow/pull/41444,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Triggerer', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]",[],
2463981245,pull_request,closed,,Check breaking changes have a news fragment,This adds a CI step for PRs with the label `airflow3.0:breaking` and ensure they include a news fragment.,uranusjr,2024-08-13 18:40:38+00:00,[],2024-08-15 01:19:07+00:00,2024-08-14 01:45:21+00:00,https://github.com/apache/airflow/pull/41443,"[('area:dev-tools', '')]","[{'comment_id': 2286961372, 'issue_id': 2463981245, 'author': 'uranusjr', 'body': 'Finally figured this out; should be mergable after CI.', 'created_at': datetime.datetime(2024, 8, 13, 19, 16, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287674120, 'issue_id': 2463981245, 'author': 'uranusjr', 'body': 'Iâ€™m going to have this in main first and worry about improvements (might not be that much needed anyway) later.', 'created_at': datetime.datetime(2024, 8, 14, 1, 46, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289116061, 'issue_id': 2463981245, 'author': 'vincbeck', 'body': 'This test is failing in #41434 although there is one newsfragment', 'created_at': datetime.datetime(2024, 8, 14, 15, 28, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2290232696, 'issue_id': 2463981245, 'author': 'uranusjr', 'body': 'Thereâ€™s `Checks SKIPPED: news file changes detected.` so a file was found, but the test still failed. I think weâ€™re using the conditions wrongâ€¦', 'created_at': datetime.datetime(2024, 8, 15, 1, 19, 6, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-08-13 19:16:33 UTC): Finally figured this out; should be mergable after CI.

uranusjr (Issue Creator) on (2024-08-14 01:46:04 UTC): Iâ€™m going to have this in main first and worry about improvements (might not be that much needed anyway) later.

vincbeck on (2024-08-14 15:28:18 UTC): This test is failing in #41434 although there is one newsfragment

uranusjr (Issue Creator) on (2024-08-15 01:19:06 UTC): Thereâ€™s `Checks SKIPPED: news file changes detected.` so a file was found, but the test still failed. I think weâ€™re using the conditions wrongâ€¦

"
2463876092,pull_request,closed,,Remove deprecated param from BranchDayOfWeekOperator,"Remove deprication param use_task_execution_day in BranchDayOfWeekOperator

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-08-13 17:36:22+00:00,[],2024-10-09 18:37:18+00:00,2024-10-09 18:37:17+00:00,https://github.com/apache/airflow/pull/41441,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2288665404, 'issue_id': 2463876092, 'author': 'romsharon98', 'body': '> Temporary block.\r\n> \r\n> We may want to discuss introducing `common.time` provider. This will allow to extract several operators/sensor from core and will not put these breaking changes on Airflow 3\r\n\r\nI raised thread in mailing list \r\nhttps://lists.apache.org/thread/2dmlqkcmyomm4q7rrovygs6bw655zx07', 'created_at': datetime.datetime(2024, 8, 14, 12, 55, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288672991, 'issue_id': 2463876092, 'author': 'gopidesupavan', 'body': '> > Temporary block.\r\n> > We may want to discuss introducing `common.time` provider. This will allow to extract several operators/sensor from core and will not put these breaking changes on Airflow 3\r\n> \r\n> I raised thread in mailing list https://lists.apache.org/thread/2dmlqkcmyomm4q7rrovygs6bw655zx07\r\n\r\nThank you @romsharon98 ðŸ˜Š I am happy to help on this work. Please let me know if anything.', 'created_at': datetime.datetime(2024, 8, 14, 12, 58, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401026781, 'issue_id': 2463876092, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 9, 0, 15, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403020523, 'issue_id': 2463876092, 'author': 'gopidesupavan', 'body': 'Closing this pr, as we have moved operators inside standard provider.  #41564', 'created_at': datetime.datetime(2024, 10, 9, 18, 37, 17, tzinfo=datetime.timezone.utc)}]","romsharon98 on (2024-08-14 12:55:14 UTC): I raised thread in mailing list 
https://lists.apache.org/thread/2dmlqkcmyomm4q7rrovygs6bw655zx07

gopidesupavan (Issue Creator) on (2024-08-14 12:58:15 UTC): Thank you @romsharon98 ðŸ˜Š I am happy to help on this work. Please let me know if anything.

github-actions[bot] on (2024-10-09 00:15:06 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

gopidesupavan (Issue Creator) on (2024-10-09 18:37:17 UTC): Closing this pr, as we have moved operators inside standard provider.  #41564

"
2463874981,pull_request,closed,,Remove deprecated and unused methods / properties on DAG,"Removed the methods / properties in models/dag.py that were already deprecated and did not have any usages.

Low-hanging fruit, you might say.",dstandish,2024-08-13 17:35:38+00:00,[],2024-08-14 09:46:48+00:00,2024-08-14 01:02:55+00:00,https://github.com/apache/airflow/pull/41440,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2463817415,pull_request,closed,,Remove deprecated DAG.date_range method,"This method was already deprecated and is referenced only in a test, which I also remove.",dstandish,2024-08-13 17:01:56+00:00,[],2024-08-13 18:40:24+00:00,2024-08-13 18:40:23+00:00,https://github.com/apache/airflow/pull/41438,[],"[{'comment_id': 2286887220, 'issue_id': 2463817415, 'author': 'dstandish', 'body': 'going to fold this one into https://github.com/apache/airflow/pull/41440', 'created_at': datetime.datetime(2024, 8, 13, 18, 40, 23, tzinfo=datetime.timezone.utc)}]","dstandish (Issue Creator) on (2024-08-13 18:40:23 UTC): going to fold this one into https://github.com/apache/airflow/pull/41440

"
2463787857,pull_request,closed,,Separate FAB migration from Core Airflow migration,"This PR separates FAB migration from Airflow Core migration and provides a way for apps to integrate into Airflow and run their migrations.



",ephraimbuddy,2024-08-13 16:46:00+00:00,[],2024-08-25 19:26:31+00:00,2024-08-25 19:26:29+00:00,https://github.com/apache/airflow/pull/41437,"[('area:providers', ''), ('provider:fab', ''), ('AIP-79', '')]","[{'comment_id': 2291639815, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': ""Not sure why this test is failing but doesn't fail locally: https://github.com/apache/airflow/actions/runs/10406470435/job/28819881902?pr=41437#step:7:5512"", 'created_at': datetime.datetime(2024, 8, 15, 16, 20, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291647403, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': ""> Not sure why this test is failing but doesn't fail locally: https://github.com/apache/airflow/actions/runs/10406470435/job/28819881902?pr=41437#step:7:5512\r\n\r\nMostly tests related to logging: \r\nhttps://github.com/apache/airflow/actions/runs/10406470435/job/28819876941?pr=41437#step:7:5339"", 'created_at': datetime.datetime(2024, 8, 15, 16, 21, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293710232, 'issue_id': 2463787857, 'author': 'potiuk', 'body': ""Likely side-effect of other tests that have been somewhat masked or avoided before the change - where some setup/teardown removed the side-effect.\r\n\r\nYou can reproduce the set of tests run with `breeze testing db-tests --test-type CLI` locally (for example - for CLI tests) - that should run the tests in the same sequence as they are run in CI in each of the parallel runs and then they shoudl reproducibly fail as well. Also it could be caused by new version of dependencies - (look at `generate constraints` output of your build) but it's rather unlikely - https://github.com/apache/airflow/actions/runs/10420774982/ `canary` build just got green and updated constraints without any test failures, so it's rather unlikely (however you can always rebase and see if it will fail in the same way).\r\n\r\nGenerally those kind of side-effects are best investigated by a bit guessing and bi-secting - and trying to run a smaller-and-smaller subset of tests until you find the one that is the culprit. At least that's what I did in the past.\r\n\r\nYou should start by looking  at the pytest command that was run in the original test type - unfold the `red` failing test type and you will see:\r\n\r\n```\r\n  Starting the tests with those pytest arguments: tests/cli --verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes --junitxml=/files/test_result-cli-postgres.xml --timeouts-order moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 --disable-warnings -rfEX --run-db-tests-only --ignore=tests/system --ignore=tests/integration --warning-output-path=/files/warnings-cli-postgres.txt --ignore=helm_tests --with-db-init --no-cov\r\n  \r\n  ============================= test session starts ==============================\r\n  platform linux -- Python 3.8.19, pytest-8.3.2, pluggy-1.5.0\r\n  rootdir: /opt/airflow\r\n  configfile: pyproject.toml\r\n  plugins: icdiff-0.9, timeouts-1.2.1, instafail-0.5.0, custom-exit-code-0.3.0, rerunfailures-14.0, asyncio-0.23.8, time-machine-2.15.0, anyio-4.4.0, requests-mock-1.12.1, cov-5.0.0, mock-3.14.0, xdist-3.6.1\r\n  asyncio: mode=strict\r\n  setup timeout: 60.0s, execution timeout: 60.0s, teardown timeout: 60.0s\r\n  collected 406 items\r\n  \r\n  tests/cli/commands/test_celery_command.py ..........                     [  2%]\r\n  tests/cli/commands/test_cheat_sheet_command.py s                         [  2%]\r\n  tests/cli/commands/test_config_command.py ssssssssssssssssss             [  7%]\r\n  tests/cli/commands/test_connection_command.py .......................... [ 13%]\r\n  .....................                                                    [ 18%]\r\n  tests/cli/commands/test_dag_command.py ................................. [ 26%]\r\n  ....................                                                     [ 31%]\r\n  tests/cli/commands/test_dag_processor_command.py .                       [ 32%]\r\n  tests/cli/commands/test_db_command.py .................................. [ 40%]\r\n  .....................................                                    [ 49%]\r\n  tests/cli/commands/test_info_command.py sssssssss..s                     [ 52%]\r\n  tests/cli/commands/test_internal_api_command.py ssss...                  [ 54%]\r\n  tests/cli/commands/test_jobs_command.py ......                           [ 55%]\r\n  tests/cli/commands/test_kerberos_command.py ....                         [ 56%]\r\n  tests/cli/commands/test_kubernetes_command.py ..........                 [ 59%]\r\n  tests/cli/commands/test_legacy_commands.py sss                           [ 59%]\r\n  tests/cli/commands/test_plugins_command.py ...                           [ 60%]\r\n  tests/cli/commands/test_pool_command.py ...........                      [ 63%]\r\n  tests/cli/commands/test_rotate_fernet_key_command.py ..                  [ 63%]\r\n  tests/cli/commands/test_scheduler_command.py ...................         [ 68%]\r\n  tests/cli/commands/test_standalone_command.py ssssssssssssss             [ 71%]\r\n  tests/cli/commands/test_task_command.py ................................ [ 79%]\r\n  .F............                                                           [ 83%]\r\n  tests/cli/commands/test_triggerer_command.py ..                          [ 83%]\r\n  tests/cli/commands/test_variable_command.py ...........                  [ 86%]\r\n  tests/cli/commands/test_version_command.py s                             [ 86%]\r\n  tests/cli/commands/test_webserver_command.py sssssssssss....             [ 90%]\r\n  tests/cli/test_cli_parser.py ..................................s....     [100%]\r\n```\r\n\r\nIf your tests succeeds when run separately, but fails when run as `tests/cli` - then side-effect is almost certain root cause. And you can attempt guess which one is producing the side-effect and run only that test and the one that's failing to confirm your guess. Or attempt to bisect it:\r\n\r\nIn this case you might convert the single:\r\n\r\n* `pytest --run-db-tests-only tests/cli`  (that should fail locally for you as well)\r\n\r\ninto (looking at the output): \r\n\r\n* `pytest --run-db-tests-only  tests/cli/commands/test_celery_command.py tests/cli/commands/test_cheat_sheet_command.py ... tests/cli/commands/test_task_command.py` \r\n\r\nThen you can remove half of the modules from the list and run it again (then you will see whether side-effect comes from the removed half or the remaining half). And continue that path - even down to a single test that causes the side effect. Then usually fixing it is trivial by adding missing setup/teardown or changing the test so that it patches and restores any state.\r\n\r\nIt's slow and tedious, yes, but this is the way I've been successfully using in the past to trace root causes of similar issues, and have no other idea how to do it differently faster."", 'created_at': datetime.datetime(2024, 8, 16, 15, 23, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295262925, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': ""> Likely side-effect of other tests that have been somewhat masked or avoided before the change - where some setup/teardown removed the side-effect.\n> \n> \n> \n> You can reproduce the set of tests run with `breeze testing db-tests --test-type CLI` locally (for example - for CLI tests) - that should run the tests in the same sequence as they are run in CI in each of the parallel runs and then they shoudl reproducibly fail as well. Also it could be caused by new version of dependencies - (look at `generate constraints` output of your build) but it's rather unlikely - https://github.com/apache/airflow/actions/runs/10420774982/ `canary` build just got green and updated constraints without any test failures, so it's rather unlikely (however you can always rebase and see if it will fail in the same way).\n> \n> \n> \n> Generally those kind of side-effects are best investigated by a bit guessing and bi-secting - and trying to run a smaller-and-smaller subset of tests until you find the one that is the culprit. At least that's what I did in the past.\n> \n> \n> \n> You should start by looking  at the pytest command that was run in the original test type - unfold the `red` failing test type and you will see:\n> \n> \n> \n> ```\n> \n>   Starting the tests with those pytest arguments: tests/cli --verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes --junitxml=/files/test_result-cli-postgres.xml --timeouts-order moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 --disable-warnings -rfEX --run-db-tests-only --ignore=tests/system --ignore=tests/integration --warning-output-path=/files/warnings-cli-postgres.txt --ignore=helm_tests --with-db-init --no-cov\n> \n>   \n> \n>   ============================= test session starts ==============================\n> \n>   platform linux -- Python 3.8.19, pytest-8.3.2, pluggy-1.5.0\n> \n>   rootdir: /opt/airflow\n> \n>   configfile: pyproject.toml\n> \n>   plugins: icdiff-0.9, timeouts-1.2.1, instafail-0.5.0, custom-exit-code-0.3.0, rerunfailures-14.0, asyncio-0.23.8, time-machine-2.15.0, anyio-4.4.0, requests-mock-1.12.1, cov-5.0.0, mock-3.14.0, xdist-3.6.1\n> \n>   asyncio: mode=strict\n> \n>   setup timeout: 60.0s, execution timeout: 60.0s, teardown timeout: 60.0s\n> \n>   collected 406 items\n> \n>   \n> \n>   tests/cli/commands/test_celery_command.py ..........                     [  2%]\n> \n>   tests/cli/commands/test_cheat_sheet_command.py s                         [  2%]\n> \n>   tests/cli/commands/test_config_command.py ssssssssssssssssss             [  7%]\n> \n>   tests/cli/commands/test_connection_command.py .......................... [ 13%]\n> \n>   .....................                                                    [ 18%]\n> \n>   tests/cli/commands/test_dag_command.py ................................. [ 26%]\n> \n>   ....................                                                     [ 31%]\n> \n>   tests/cli/commands/test_dag_processor_command.py .                       [ 32%]\n> \n>   tests/cli/commands/test_db_command.py .................................. [ 40%]\n> \n>   .....................................                                    [ 49%]\n> \n>   tests/cli/commands/test_info_command.py sssssssss..s                     [ 52%]\n> \n>   tests/cli/commands/test_internal_api_command.py ssss...                  [ 54%]\n> \n>   tests/cli/commands/test_jobs_command.py ......                           [ 55%]\n> \n>   tests/cli/commands/test_kerberos_command.py ....                         [ 56%]\n> \n>   tests/cli/commands/test_kubernetes_command.py ..........                 [ 59%]\n> \n>   tests/cli/commands/test_legacy_commands.py sss                           [ 59%]\n> \n>   tests/cli/commands/test_plugins_command.py ...                           [ 60%]\n> \n>   tests/cli/commands/test_pool_command.py ...........                      [ 63%]\n> \n>   tests/cli/commands/test_rotate_fernet_key_command.py ..                  [ 63%]\n> \n>   tests/cli/commands/test_scheduler_command.py ...................         [ 68%]\n> \n>   tests/cli/commands/test_standalone_command.py ssssssssssssss             [ 71%]\n> \n>   tests/cli/commands/test_task_command.py ................................ [ 79%]\n> \n>   .F............                                                           [ 83%]\n> \n>   tests/cli/commands/test_triggerer_command.py ..                          [ 83%]\n> \n>   tests/cli/commands/test_variable_command.py ...........                  [ 86%]\n> \n>   tests/cli/commands/test_version_command.py s                             [ 86%]\n> \n>   tests/cli/commands/test_webserver_command.py sssssssssss....             [ 90%]\n> \n>   tests/cli/test_cli_parser.py ..................................s....     [100%]\n> \n> ```\n> \n> \n> \n> If your tests succeeds when run separately, but fails when run as `tests/cli` - then side-effect is almost certain root cause. And you can attempt guess which one is producing the side-effect and run only that test and the one that's failing to confirm your guess. Or attempt to bisect it:\n> \n> \n> \n> In this case you might convert the single:\n> \n> \n> \n> * `pytest --run-db-tests-only tests/cli`  (that should fail locally for you as well)\n> \n> \n> \n> into (looking at the output): \n> \n> \n> \n> * `pytest --run-db-tests-only  tests/cli/commands/test_celery_command.py tests/cli/commands/test_cheat_sheet_command.py ... tests/cli/commands/test_task_command.py` \n> \n> \n> \n> Then you can remove half of the modules from the list and run it again (then you will see whether side-effect comes from the removed half or the remaining half). And continue that path - even down to a single test that causes the side effect. Then usually fixing it is trivial by adding missing setup/teardown or changing the test so that it patches and restores any state.\n> \n> \n> \n> It's slow and tedious, yes, but this is the way I've been successfully using in the past to trace root causes of similar issues, and have no other idea how to do it differently faster.\n\nThanks @potiuk for always helping. I'll look into these and fix them ðŸ™"", 'created_at': datetime.datetime(2024, 8, 18, 13, 27, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298306201, 'issue_id': 2463787857, 'author': 'eladkal', 'body': 'wait.. what does this actually mean for users who is bumping providers only?\r\nWe have doc that explain upgrade procedure https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading.html#upgrading-airflow-to-a-newer-version\r\n\r\nIf now, migrations can also run from bumping provider only that changes the upgrade procedure users should take.', 'created_at': datetime.datetime(2024, 8, 20, 8, 42, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298583972, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': '> wait.. what does this actually mean for users who is bumping providers only? We have doc that explain upgrade procedure https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading.html#upgrading-airflow-to-a-newer-version\r\n> \r\n> If now, migrations can also run from bumping provider only that changes the upgrade procedure users should take.\r\n\r\nI will describe the upgrade procedure in my next PR when I add the upgrade command for FAB provider. It should be smooth', 'created_at': datetime.datetime(2024, 8, 20, 11, 3, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298616174, 'issue_id': 2463787857, 'author': 'eladkal', 'body': '> I will describe the upgrade procedure in my next PR when I add the upgrade command for FAB provider. It should be smooth\r\n\r\nI am worried here.\r\nWe may dismiss the impact here too lightly.\r\nDid I miss mailing thread on this topic?\r\n\r\nHere we are introducing something really new - bumping provider version which also runs DB migration.. that is not small change to how Airflow operatre.', 'created_at': datetime.datetime(2024, 8, 20, 11, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298627770, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': '> > I will describe the upgrade procedure in my next PR when I add the upgrade command for FAB provider. It should be smooth\r\n> \r\n> I am worried here. We may dismiss the impact here too lightly. Did I miss mailing thread on this topic?\r\n> \r\n> Here we are introducing something really new - bumping provider version which also runs DB migration.. that is not small change to how Airflow operatre.\r\n\r\nThese changes are part of AIP-79, do you think we still need another mailing thread on it?', 'created_at': datetime.datetime(2024, 8, 20, 11, 28, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298646418, 'issue_id': 2463787857, 'author': 'eladkal', 'body': '> These changes are part of AIP-79, do you think we still need another mailing thread on it?\r\n\r\nTo clarify, I am not saying no to the what (the merit of AIP-79)\r\nI am saying no to the how.\r\n\r\nLet me rephrase - for Airflow 2 users who runs fab provider in any future version (with this PR included) will there be migration scripts running as part of the provider? If the answer is yes then I have a concern here.', 'created_at': datetime.datetime(2024, 8, 20, 11, 38, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298690646, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': '> > These changes are part of AIP-79, do you think we still need another mailing thread on it?\r\n> \r\n> To clarify, I am not saying no to the what (the merit of AIP-79) I am saying no to the how.\r\n> \r\n> Let me rephrase - for Airflow 2 users who runs fab provider in any future version (with this PR included) will there be migration scripts running as part of the provider? If the answer is yes then I have a concern here.\r\n\r\nThere is no migration script currently. However, if anyone has migration to add, they can add it on the FAB provider side. What this PR intends to achieve is for users to add their migrations on the FAB side and have a way for airflow to run such migrations. Even before this PR, a pre-commit forbids adding FAB migration to the core.', 'created_at': datetime.datetime(2024, 8, 20, 12, 3, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298716531, 'issue_id': 2463787857, 'author': 'eladkal', 'body': "">There is no migration script currently. However, if anyone has migration to add, they can add it on the FAB provider side. What this PR intends to achieve is for users to add their migrations on the FAB side and have a way for airflow to run such migrations. \r\n\r\nGreat. Then there are no immediate concerns from my side.\r\nI do have several concerns regarding the first migration that we will add and I will raise it when it's relevant"", 'created_at': datetime.datetime(2024, 8, 20, 12, 16, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298862915, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': 'I would appreciate some help on this CI issue cc @potiuk @jedcunningham', 'created_at': datetime.datetime(2024, 8, 20, 13, 27, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299702693, 'issue_id': 2463787857, 'author': 'potiuk', 'body': '> I would appreciate some help on this CI issue cc @potiuk @jedcunningham\r\n\r\nWhich one :) ?', 'created_at': datetime.datetime(2024, 8, 20, 20, 25, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301069429, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': ""> > I would appreciate some help on this CI issue cc @potiuk @jedcunningham\r\n> \r\n> Which one :) ?\r\n\r\nHonestly, it's a lot. Something is fundamentally wrong, but I can't find it. It looks related to logging"", 'created_at': datetime.datetime(2024, 8, 21, 4, 59, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303237159, 'issue_id': 2463787857, 'author': 'potiuk', 'body': 'A lot to look at ... tomorrow.', 'created_at': datetime.datetime(2024, 8, 21, 22, 44, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306108057, 'issue_id': 2463787857, 'author': 'uranusjr', 'body': ""```\r\nWARNING: Requirement 'dist/apache_airflow_providers_fab-*.whl' looks like a filename, but the file does not exist\r\nERROR: apache_airflow_providers_fab-*.whl is not a valid wheel filename.\r\n```\r\n\r\nLooks like thereâ€™s a problem creating the new provider package?"", 'created_at': datetime.datetime(2024, 8, 23, 3, 22, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306444063, 'issue_id': 2463787857, 'author': 'ephraimbuddy', 'body': ""> ```\r\n> WARNING: Requirement 'dist/apache_airflow_providers_fab-*.whl' looks like a filename, but the file does not exist\r\n> ERROR: apache_airflow_providers_fab-*.whl is not a valid wheel filename.\r\n> ```\r\n> \r\n> Looks like thereâ€™s a problem creating the new provider package?\r\n\r\nA tag with the current fab version was just created, that makes it fail.:\r\n\r\n```\r\nThe 'final' tag providers-fab/1.3.0 exists. Skipping the package.\r\n\r\n\r\nSummary of prepared packages:\r\n\r\n\r\nNo packages prepared!\r\n```\r\n\r\nNeed to find a way to prepare it"", 'created_at': datetime.datetime(2024, 8, 23, 7, 12, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308818005, 'issue_id': 2463787857, 'author': 'potiuk', 'body': 'I do not know that much of alembic but this one looks good to me. I think we will yet heave to turn FAB provider into something more (airflow UI plugin)', 'created_at': datetime.datetime(2024, 8, 25, 12, 40, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-08-15 16:20:18 UTC): Not sure why this test is failing but doesn't fail locally: https://github.com/apache/airflow/actions/runs/10406470435/job/28819881902?pr=41437#step:7:5512

ephraimbuddy (Issue Creator) on (2024-08-15 16:21:44 UTC): Mostly tests related to logging: 
https://github.com/apache/airflow/actions/runs/10406470435/job/28819876941?pr=41437#step:7:5339

potiuk on (2024-08-16 15:23:32 UTC): Likely side-effect of other tests that have been somewhat masked or avoided before the change - where some setup/teardown removed the side-effect.

You can reproduce the set of tests run with `breeze testing db-tests --test-type CLI` locally (for example - for CLI tests) - that should run the tests in the same sequence as they are run in CI in each of the parallel runs and then they shoudl reproducibly fail as well. Also it could be caused by new version of dependencies - (look at `generate constraints` output of your build) but it's rather unlikely - https://github.com/apache/airflow/actions/runs/10420774982/ `canary` build just got green and updated constraints without any test failures, so it's rather unlikely (however you can always rebase and see if it will fail in the same way).

Generally those kind of side-effects are best investigated by a bit guessing and bi-secting - and trying to run a smaller-and-smaller subset of tests until you find the one that is the culprit. At least that's what I did in the past.

You should start by looking  at the pytest command that was run in the original test type - unfold the `red` failing test type and you will see:

```
  Starting the tests with those pytest arguments: tests/cli --verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes --junitxml=/files/test_result-cli-postgres.xml --timeouts-order moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 --disable-warnings -rfEX --run-db-tests-only --ignore=tests/system --ignore=tests/integration --warning-output-path=/files/warnings-cli-postgres.txt --ignore=helm_tests --with-db-init --no-cov
  
  ============================= test session starts ==============================
  platform linux -- Python 3.8.19, pytest-8.3.2, pluggy-1.5.0
  rootdir: /opt/airflow
  configfile: pyproject.toml
  plugins: icdiff-0.9, timeouts-1.2.1, instafail-0.5.0, custom-exit-code-0.3.0, rerunfailures-14.0, asyncio-0.23.8, time-machine-2.15.0, anyio-4.4.0, requests-mock-1.12.1, cov-5.0.0, mock-3.14.0, xdist-3.6.1
  asyncio: mode=strict
  setup timeout: 60.0s, execution timeout: 60.0s, teardown timeout: 60.0s
  collected 406 items
  
  tests/cli/commands/test_celery_command.py ..........                     [  2%]
  tests/cli/commands/test_cheat_sheet_command.py s                         [  2%]
  tests/cli/commands/test_config_command.py ssssssssssssssssss             [  7%]
  tests/cli/commands/test_connection_command.py .......................... [ 13%]
  .....................                                                    [ 18%]
  tests/cli/commands/test_dag_command.py ................................. [ 26%]
  ....................                                                     [ 31%]
  tests/cli/commands/test_dag_processor_command.py .                       [ 32%]
  tests/cli/commands/test_db_command.py .................................. [ 40%]
  .....................................                                    [ 49%]
  tests/cli/commands/test_info_command.py sssssssss..s                     [ 52%]
  tests/cli/commands/test_internal_api_command.py ssss...                  [ 54%]
  tests/cli/commands/test_jobs_command.py ......                           [ 55%]
  tests/cli/commands/test_kerberos_command.py ....                         [ 56%]
  tests/cli/commands/test_kubernetes_command.py ..........                 [ 59%]
  tests/cli/commands/test_legacy_commands.py sss                           [ 59%]
  tests/cli/commands/test_plugins_command.py ...                           [ 60%]
  tests/cli/commands/test_pool_command.py ...........                      [ 63%]
  tests/cli/commands/test_rotate_fernet_key_command.py ..                  [ 63%]
  tests/cli/commands/test_scheduler_command.py ...................         [ 68%]
  tests/cli/commands/test_standalone_command.py ssssssssssssss             [ 71%]
  tests/cli/commands/test_task_command.py ................................ [ 79%]
  .F............                                                           [ 83%]
  tests/cli/commands/test_triggerer_command.py ..                          [ 83%]
  tests/cli/commands/test_variable_command.py ...........                  [ 86%]
  tests/cli/commands/test_version_command.py s                             [ 86%]
  tests/cli/commands/test_webserver_command.py sssssssssss....             [ 90%]
  tests/cli/test_cli_parser.py ..................................s....     [100%]
```

If your tests succeeds when run separately, but fails when run as `tests/cli` - then side-effect is almost certain root cause. And you can attempt guess which one is producing the side-effect and run only that test and the one that's failing to confirm your guess. Or attempt to bisect it:

In this case you might convert the single:

* `pytest --run-db-tests-only tests/cli`  (that should fail locally for you as well)

into (looking at the output): 

* `pytest --run-db-tests-only  tests/cli/commands/test_celery_command.py tests/cli/commands/test_cheat_sheet_command.py ... tests/cli/commands/test_task_command.py` 

Then you can remove half of the modules from the list and run it again (then you will see whether side-effect comes from the removed half or the remaining half). And continue that path - even down to a single test that causes the side effect. Then usually fixing it is trivial by adding missing setup/teardown or changing the test so that it patches and restores any state.

It's slow and tedious, yes, but this is the way I've been successfully using in the past to trace root causes of similar issues, and have no other idea how to do it differently faster.

ephraimbuddy (Issue Creator) on (2024-08-18 13:27:53 UTC): Thanks @potiuk for always helping. I'll look into these and fix them ðŸ™

eladkal on (2024-08-20 08:42:09 UTC): wait.. what does this actually mean for users who is bumping providers only?
We have doc that explain upgrade procedure https://airflow.apache.org/docs/apache-airflow/stable/installation/upgrading.html#upgrading-airflow-to-a-newer-version

If now, migrations can also run from bumping provider only that changes the upgrade procedure users should take.

ephraimbuddy (Issue Creator) on (2024-08-20 11:03:52 UTC): I will describe the upgrade procedure in my next PR when I add the upgrade command for FAB provider. It should be smooth

eladkal on (2024-08-20 11:22:00 UTC): I am worried here.
We may dismiss the impact here too lightly.
Did I miss mailing thread on this topic?

Here we are introducing something really new - bumping provider version which also runs DB migration.. that is not small change to how Airflow operatre.

ephraimbuddy (Issue Creator) on (2024-08-20 11:28:32 UTC): These changes are part of AIP-79, do you think we still need another mailing thread on it?

eladkal on (2024-08-20 11:38:57 UTC): To clarify, I am not saying no to the what (the merit of AIP-79)
I am saying no to the how.

Let me rephrase - for Airflow 2 users who runs fab provider in any future version (with this PR included) will there be migration scripts running as part of the provider? If the answer is yes then I have a concern here.

ephraimbuddy (Issue Creator) on (2024-08-20 12:03:30 UTC): There is no migration script currently. However, if anyone has migration to add, they can add it on the FAB provider side. What this PR intends to achieve is for users to add their migrations on the FAB side and have a way for airflow to run such migrations. Even before this PR, a pre-commit forbids adding FAB migration to the core.

eladkal on (2024-08-20 12:16:41 UTC): Great. Then there are no immediate concerns from my side.
I do have several concerns regarding the first migration that we will add and I will raise it when it's relevant

ephraimbuddy (Issue Creator) on (2024-08-20 13:27:27 UTC): I would appreciate some help on this CI issue cc @potiuk @jedcunningham

potiuk on (2024-08-20 20:25:11 UTC): Which one :) ?

ephraimbuddy (Issue Creator) on (2024-08-21 04:59:10 UTC): Honestly, it's a lot. Something is fundamentally wrong, but I can't find it. It looks related to logging

potiuk on (2024-08-21 22:44:35 UTC): A lot to look at ... tomorrow.

uranusjr on (2024-08-23 03:22:17 UTC): ```
WARNING: Requirement 'dist/apache_airflow_providers_fab-*.whl' looks like a filename, but the file does not exist
ERROR: apache_airflow_providers_fab-*.whl is not a valid wheel filename.
```

Looks like thereâ€™s a problem creating the new provider package?

ephraimbuddy (Issue Creator) on (2024-08-23 07:12:30 UTC): A tag with the current fab version was just created, that makes it fail.:

```
The 'final' tag providers-fab/1.3.0 exists. Skipping the package.


Summary of prepared packages:


No packages prepared!
```

Need to find a way to prepare it

potiuk on (2024-08-25 12:40:00 UTC): I do not know that much of alembic but this one looks good to me. I think we will yet heave to turn FAB provider into something more (airflow UI plugin)

"
2463540000,pull_request,closed,,Move wrongly placed newsfragment,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-13 14:45:07+00:00,[],2024-09-20 21:27:07+00:00,2024-08-13 16:03:53+00:00,https://github.com/apache/airflow/pull/41435,[],[],
2463528759,pull_request,closed,,Delete experimental API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-13 14:40:08+00:00,[],2024-08-21 19:45:29+00:00,2024-08-16 17:11:35+00:00,https://github.com/apache/airflow/pull/41434,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2286436689, 'issue_id': 2463528759, 'author': 'eladkal', 'body': 'Needs also to be removed from the docs', 'created_at': datetime.datetime(2024, 8, 13, 14, 44, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286546806, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': 'I am unsure what to do with `airflow/api/client/local_client.py` and `airflow/api/client/json_client.py`. They both use the experimental APIs. Does someone have context on these clients?', 'created_at': datetime.datetime(2024, 8, 13, 15, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286930786, 'issue_id': 2463528759, 'author': 'jedcunningham', 'body': '> I am unsure what to do with `airflow/api/client/local_client.py` and `airflow/api/client/json_client.py`. They both use the experimental APIs. Does someone have context on these clients?\r\n\r\nThis is actually why I gave up removing the experimental API last Friday ðŸ™ƒ. I think we should remove the whole concept of a client and let AIP-81 handle reimagining it.', 'created_at': datetime.datetime(2024, 8, 13, 18, 59, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287178398, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': '> > I am unsure what to do with `airflow/api/client/local_client.py` and `airflow/api/client/json_client.py`. They both use the experimental APIs. Does someone have context on these clients?\r\n> \r\n> This is actually why I gave up removing the experimental API last Friday ðŸ™ƒ. I think we should remove the whole concept of a client and let AIP-81 handle reimagining it.\r\n\r\nDoes that mean that the current CI is using experimental API underneath?', 'created_at': datetime.datetime(2024, 8, 13, 21, 34, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287181649, 'issue_id': 2463528759, 'author': 'potiuk', 'body': '> This is actually why I gave up removing the experimental API last Friday ðŸ™ƒ. I think we should remove the whole concept of a client and let AIP-81 handle reimagining it.\r\n\r\nNo. It should not - we should just remove those IMHO. Full stop. There is no particular reason we should keep them', 'created_at': datetime.datetime(2024, 8, 13, 21, 37, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287306443, 'issue_id': 2463528759, 'author': 'jedcunningham', 'body': ""> > > I am unsure what to do with `airflow/api/client/local_client.py` and `airflow/api/client/json_client.py`. They both use the experimental APIs. Does someone have context on these clients?\r\n> > \r\n> > \r\n> > This is actually why I gave up removing the experimental API last Friday ðŸ™ƒ. I think we should remove the whole concept of a client and let AIP-81 handle reimagining it.\r\n> \r\n> Does that mean that the current CI is using experimental API underneath?\r\n\r\nHonestly, I didn't look closely at all once I saw the dependency. I'm not sure if those clients are even usable? I'm with Jarek, whack them."", 'created_at': datetime.datetime(2024, 8, 13, 22, 48, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289092407, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': ""These clients are used by the CI today so I wont be able to remove them entirely in this PR. I think this should be done as part of the AIP-81 effort. I'll do my best to remove as much as I can though"", 'created_at': datetime.datetime(2024, 8, 14, 15, 17, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2290288177, 'issue_id': 2463528759, 'author': 'uranusjr', 'body': 'I posted #41491 to fix the news fragment check.', 'created_at': datetime.datetime(2024, 8, 15, 1, 30, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291322427, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': '> I posted #41491 to fix the news fragment check.\r\n\r\nThank you!', 'created_at': datetime.datetime(2024, 8, 15, 14, 0, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291596918, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': ""Tests are passing (besides flaky tests I'll restart) ðŸŽ‰"", 'created_at': datetime.datetime(2024, 8, 15, 15, 58, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291598865, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': ""> These clients are used by the CI today so I wont be able to remove them entirely in this PR. I think this should be done as part of the AIP-81 effort. I'll do my best to remove as much as I can though\r\n\r\nI ended up deleting the client interface and configs associated to it. I had to keep the basic client implementation because it is used by the CI. It will be most likely be deleted/refactored in AIP-81 work"", 'created_at': datetime.datetime(2024, 8, 15, 15, 59, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291722478, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': ""The test `[Special tests / Pydantic v1 test / All:Pydantic-V1-Postgres:12:3.8]` is failing constantly without giving much information besides:\r\n\r\n```\r\nError 1. Dumping containers: ['airflow-test-externalpython-airflow-run-cfb004eac98f', 'airflow-test-branchpythonvenv-airflow-run-4ef438000926', \r\n  'airflow-test-branchexternalpython-airflow-run-fc0df5a6d7ad', 'airflow-test-externalpython-postgres-1', 'airflow-test-branchpythonvenv-postgres-1', 'airflow-test-branchexternalpython-postgres-1', \r\n  'airflow-test-api-postgres-1'] for api.\r\n```"", 'created_at': datetime.datetime(2024, 8, 15, 17, 0, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291892481, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': 'From logs:\r\n\r\n```\r\n2024-08-15T17:48:08.991440634Z  The files belonging to this database system will be owned by user ""postgres"".\r\n2024-08-15T17:48:08.993916422Z  This user must also own the server process.\r\n2024-08-15T17:48:08.993927093Z  \r\n2024-08-15T17:48:08.993936700Z  The database cluster will be initialized with locale ""en_US.utf8"".\r\n2024-08-15T17:48:08.993942531Z  The default database encoding has accordingly been set to ""UTF8"".\r\n2024-08-15T17:48:08.993948022Z  The default text search configuration will be set to ""english"".\r\n2024-08-15T17:48:08.993966947Z  \r\n2024-08-15T17:48:08.993971987Z  Data page checksums are disabled.\r\n2024-08-15T17:48:08.993976886Z  \r\n2024-08-15T17:48:08.993981735Z  fixing permissions on existing directory /var/lib/postgresql/data ... ok\r\n2024-08-15T17:48:08.995257685Z  creating subdirectories ... ok\r\n2024-08-15T17:48:08.995550183Z  selecting dynamic shared memory implementation ... posix\r\n2024-08-15T17:48:09.039424465Z  selecting default max_connections ... 100\r\n2024-08-15T17:48:09.071701216Z  selecting default shared_buffers ... 128MB\r\n2024-08-15T17:48:09.115526599Z  selecting default time zone ... Etc/UTC\r\n2024-08-15T17:48:09.115535896Z  creating configuration files ... ok\r\n2024-08-15T17:48:09.294766848Z  running bootstrap script ... ok\r\n2024-08-15T17:48:09.798739062Z  performing post-bootstrap initialization ... ok\r\n2024-08-15T17:48:09.885246230Z  syncing data to disk ... ok\r\n2024-08-15T17:48:09.885277910Z  \r\n2024-08-15T17:48:09.885283480Z  \r\n2024-08-15T17:48:09.885288139Z  Success. You can now start the database server using:\r\n2024-08-15T17:48:09.885292948Z  \r\n2024-08-15T17:48:09.885297587Z      pg_ctl -D /var/lib/postgresql/data -l logfile start\r\n2024-08-15T17:48:09.885303398Z  \r\n2024-08-15T17:48:09.949442941Z  waiting for server to start....2024-08-15 17:48:09.949 UTC [48] LOG:  starting PostgreSQL 12.20 (Debian 12.20-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit\r\n2024-08-15T17:48:09.950387580Z  2024-08-15 17:48:09.950 UTC [48] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""\r\n2024-08-15T17:48:09.964868351Z  2024-08-15 17:48:09.964 UTC [49] LOG:  database system was shut down at 2024-08-15 17:48:09 UTC\r\n2024-08-15T17:48:09.970375465Z  2024-08-15 17:48:09.970 UTC [48] LOG:  database system is ready to accept connections\r\n2024-08-15T17:48:10.020225032Z   done\r\n2024-08-15T17:48:10.020240311Z  server started\r\n2024-08-15T17:48:10.192255016Z  CREATE DATABASE\r\n2024-08-15T17:48:10.193187396Z  \r\n2024-08-15T17:48:10.193412647Z  \r\n2024-08-15T17:48:10.193532843Z  /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*\r\n2024-08-15T17:48:10.193614065Z  \r\n2024-08-15T17:48:10.194953890Z  2024-08-15 17:48:10.194 UTC [48] LOG:  received fast shutdown request\r\n2024-08-15T17:48:10.195528542Z  waiting for server to shut down....2024-08-15 17:48:10.195 UTC [48] LOG:  aborting any active transactions\r\n2024-08-15T17:48:10.197630300Z  2024-08-15 17:48:10.197 UTC [48] LOG:  background worker ""logical replication launcher"" (PID 55) exited with exit code 1\r\n2024-08-15T17:48:10.200565947Z  2024-08-15 17:48:10.200 UTC [50] LOG:  shutting down\r\n2024-08-15T17:48:10.210847981Z  2024-08-15 17:48:10.210 UTC [48] LOG:  database system is shut down\r\n2024-08-15T17:48:10.295198664Z   done\r\n2024-08-15T17:48:10.295221868Z  server stopped\r\n2024-08-15T17:48:10.296363270Z  \r\n2024-08-15T17:48:10.296375713Z  PostgreSQL init process complete; ready for start up.\r\n2024-08-15T17:48:10.296381053Z  \r\n\r\n```', 'created_at': datetime.datetime(2024, 8, 15, 18, 17, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293440619, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': 'Fix for this test in #41534', 'created_at': datetime.datetime(2024, 8, 16, 12, 41, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293763491, 'issue_id': 2463528759, 'author': 'vincbeck', 'body': 'All green :) Any additional reviews?', 'created_at': datetime.datetime(2024, 8, 16, 15, 59, 5, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-13 14:44:21 UTC): Needs also to be removed from the docs

vincbeck (Issue Creator) on (2024-08-13 15:34:00 UTC): I am unsure what to do with `airflow/api/client/local_client.py` and `airflow/api/client/json_client.py`. They both use the experimental APIs. Does someone have context on these clients?

jedcunningham on (2024-08-13 18:59:49 UTC): This is actually why I gave up removing the experimental API last Friday ðŸ™ƒ. I think we should remove the whole concept of a client and let AIP-81 handle reimagining it.

vincbeck (Issue Creator) on (2024-08-13 21:34:53 UTC): Does that mean that the current CI is using experimental API underneath?

potiuk on (2024-08-13 21:37:06 UTC): No. It should not - we should just remove those IMHO. Full stop. There is no particular reason we should keep them

jedcunningham on (2024-08-13 22:48:02 UTC): Honestly, I didn't look closely at all once I saw the dependency. I'm not sure if those clients are even usable? I'm with Jarek, whack them.

vincbeck (Issue Creator) on (2024-08-14 15:17:35 UTC): These clients are used by the CI today so I wont be able to remove them entirely in this PR. I think this should be done as part of the AIP-81 effort. I'll do my best to remove as much as I can though

uranusjr on (2024-08-15 01:30:31 UTC): I posted #41491 to fix the news fragment check.

vincbeck (Issue Creator) on (2024-08-15 14:00:48 UTC): Thank you!

vincbeck (Issue Creator) on (2024-08-15 15:58:04 UTC): Tests are passing (besides flaky tests I'll restart) ðŸŽ‰

vincbeck (Issue Creator) on (2024-08-15 15:59:09 UTC): I ended up deleting the client interface and configs associated to it. I had to keep the basic client implementation because it is used by the CI. It will be most likely be deleted/refactored in AIP-81 work

vincbeck (Issue Creator) on (2024-08-15 17:00:09 UTC): The test `[Special tests / Pydantic v1 test / All:Pydantic-V1-Postgres:12:3.8]` is failing constantly without giving much information besides:

```
Error 1. Dumping containers: ['airflow-test-externalpython-airflow-run-cfb004eac98f', 'airflow-test-branchpythonvenv-airflow-run-4ef438000926', 
  'airflow-test-branchexternalpython-airflow-run-fc0df5a6d7ad', 'airflow-test-externalpython-postgres-1', 'airflow-test-branchpythonvenv-postgres-1', 'airflow-test-branchexternalpython-postgres-1', 
  'airflow-test-api-postgres-1'] for api.
```

vincbeck (Issue Creator) on (2024-08-15 18:17:54 UTC): From logs:

```
2024-08-15T17:48:08.991440634Z  The files belonging to this database system will be owned by user ""postgres"".
2024-08-15T17:48:08.993916422Z  This user must also own the server process.
2024-08-15T17:48:08.993927093Z  
2024-08-15T17:48:08.993936700Z  The database cluster will be initialized with locale ""en_US.utf8"".
2024-08-15T17:48:08.993942531Z  The default database encoding has accordingly been set to ""UTF8"".
2024-08-15T17:48:08.993948022Z  The default text search configuration will be set to ""english"".
2024-08-15T17:48:08.993966947Z  
2024-08-15T17:48:08.993971987Z  Data page checksums are disabled.
2024-08-15T17:48:08.993976886Z  
2024-08-15T17:48:08.993981735Z  fixing permissions on existing directory /var/lib/postgresql/data ... ok
2024-08-15T17:48:08.995257685Z  creating subdirectories ... ok
2024-08-15T17:48:08.995550183Z  selecting dynamic shared memory implementation ... posix
2024-08-15T17:48:09.039424465Z  selecting default max_connections ... 100
2024-08-15T17:48:09.071701216Z  selecting default shared_buffers ... 128MB
2024-08-15T17:48:09.115526599Z  selecting default time zone ... Etc/UTC
2024-08-15T17:48:09.115535896Z  creating configuration files ... ok
2024-08-15T17:48:09.294766848Z  running bootstrap script ... ok
2024-08-15T17:48:09.798739062Z  performing post-bootstrap initialization ... ok
2024-08-15T17:48:09.885246230Z  syncing data to disk ... ok
2024-08-15T17:48:09.885277910Z  
2024-08-15T17:48:09.885283480Z  
2024-08-15T17:48:09.885288139Z  Success. You can now start the database server using:
2024-08-15T17:48:09.885292948Z  
2024-08-15T17:48:09.885297587Z      pg_ctl -D /var/lib/postgresql/data -l logfile start
2024-08-15T17:48:09.885303398Z  
2024-08-15T17:48:09.949442941Z  waiting for server to start....2024-08-15 17:48:09.949 UTC [48] LOG:  starting PostgreSQL 12.20 (Debian 12.20-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit
2024-08-15T17:48:09.950387580Z  2024-08-15 17:48:09.950 UTC [48] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""
2024-08-15T17:48:09.964868351Z  2024-08-15 17:48:09.964 UTC [49] LOG:  database system was shut down at 2024-08-15 17:48:09 UTC
2024-08-15T17:48:09.970375465Z  2024-08-15 17:48:09.970 UTC [48] LOG:  database system is ready to accept connections
2024-08-15T17:48:10.020225032Z   done
2024-08-15T17:48:10.020240311Z  server started
2024-08-15T17:48:10.192255016Z  CREATE DATABASE
2024-08-15T17:48:10.193187396Z  
2024-08-15T17:48:10.193412647Z  
2024-08-15T17:48:10.193532843Z  /usr/local/bin/docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
2024-08-15T17:48:10.193614065Z  
2024-08-15T17:48:10.194953890Z  2024-08-15 17:48:10.194 UTC [48] LOG:  received fast shutdown request
2024-08-15T17:48:10.195528542Z  waiting for server to shut down....2024-08-15 17:48:10.195 UTC [48] LOG:  aborting any active transactions
2024-08-15T17:48:10.197630300Z  2024-08-15 17:48:10.197 UTC [48] LOG:  background worker ""logical replication launcher"" (PID 55) exited with exit code 1
2024-08-15T17:48:10.200565947Z  2024-08-15 17:48:10.200 UTC [50] LOG:  shutting down
2024-08-15T17:48:10.210847981Z  2024-08-15 17:48:10.210 UTC [48] LOG:  database system is shut down
2024-08-15T17:48:10.295198664Z   done
2024-08-15T17:48:10.295221868Z  server stopped
2024-08-15T17:48:10.296363270Z  
2024-08-15T17:48:10.296375713Z  PostgreSQL init process complete; ready for start up.
2024-08-15T17:48:10.296381053Z  

```

vincbeck (Issue Creator) on (2024-08-16 12:41:45 UTC): Fix for this test in #41534

vincbeck (Issue Creator) on (2024-08-16 15:59:05 UTC): All green :) Any additional reviews?

"
2463432635,pull_request,closed,,Fix: DAGs are not marked as stale if the dags folder change,Closes: https://github.com/apache/airflow/issues/41432,utkarsharma2,2024-08-13 13:59:01+00:00,[],2024-08-30 09:21:53+00:00,2024-08-28 09:07:24+00:00,https://github.com/apache/airflow/pull/41433,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2303595688, 'issue_id': 2463432635, 'author': 'uranusjr', 'body': 'Is a test possible?', 'created_at': datetime.datetime(2024, 8, 22, 3, 18, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303802238, 'issue_id': 2463432635, 'author': 'utkarsharma2', 'body': ""> Is a test possible?\r\n\r\nYes, I'll add them."", 'created_at': datetime.datetime(2024, 8, 22, 5, 14, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2310104063, 'issue_id': 2463432635, 'author': 'utkarsharma2', 'body': '> Is a test possible?\r\n\r\n@uranusjr, @Lee-W I have added a test, PTAL.', 'created_at': datetime.datetime(2024, 8, 26, 12, 34, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314825758, 'issue_id': 2463432635, 'author': 'ephraimbuddy', 'body': '@utkarsharma2 , can you backport this to v2-10-test', 'created_at': datetime.datetime(2024, 8, 28, 9, 36, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314884125, 'issue_id': 2463432635, 'author': 'utkarsharma2', 'body': ""Thanks @ephraimbuddy I'll do that."", 'created_at': datetime.datetime(2024, 8, 28, 10, 3, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2315031251, 'issue_id': 2463432635, 'author': 'utkarsharma2', 'body': 'Cherry picked - https://github.com/apache/airflow/pull/41829', 'created_at': datetime.datetime(2024, 8, 28, 11, 15, 43, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-22 03:18:26 UTC): Is a test possible?

utkarsharma2 (Issue Creator) on (2024-08-22 05:14:49 UTC): Yes, I'll add them.

utkarsharma2 (Issue Creator) on (2024-08-26 12:34:01 UTC): @uranusjr, @Lee-W I have added a test, PTAL.

ephraimbuddy on (2024-08-28 09:36:21 UTC): @utkarsharma2 , can you backport this to v2-10-test

utkarsharma2 (Issue Creator) on (2024-08-28 10:03:46 UTC): Thanks @ephraimbuddy I'll do that.

utkarsharma2 (Issue Creator) on (2024-08-28 11:15:43 UTC): Cherry picked - https://github.com/apache/airflow/pull/41829

"
2463132007,pull_request,closed,,Add retry logic in the scheduler for updating trigger timeouts in case of deadlocks.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

related: #41428

The scheduler job raise exception on database dead lock and exist.
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job_runner.py"", line 845, in _execute
    self._run_scheduler_loop()
  File ""/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job_runner.py"", line 991, in _run_scheduler_loop
    next_event = timers.run(blocking=False)
  File ""/usr/lib/python3.8/sched.py"", line 151, in run
    action(*argument, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/airflow/utils/event_scheduler.py"", line 37, in repeat
    action(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/airflow/utils/session.py"", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/airflow/jobs/scheduler_job_runner.py"", line 1680, in check_trigger_timeouts
    num_timed_out_tasks = session.execute(
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/orm/session.py"", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py"", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/sql/elements.py"", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py"", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py"", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py"", line 2134, in _handle_dbapi_exception
    util.raise_(
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/util/compat.py"", line 211, in raise_
    raise exception
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/base.py"", line 1910, in _execute_context
    self.dialect.do_execute(
  File ""/usr/local/lib/python3.8/dist-packages/sqlalchemy/engine/default.py"", line 736, in do_execute
    cursor.execute(statement, parameters)
  File ""/usr/local/lib/python3.8/dist-packages/MySQLdb/cursors.py"", line 179, in execute
    res = self._query(mogrified_query)
  File ""/usr/local/lib/python3.8/dist-packages/MySQLdb/cursors.py"", line 330, in _query
    db.query(q)
  File ""/usr/local/lib/python3.8/dist-packages/MySQLdb/connections.py"", line 255, in query
    _mysql.connection.query(self, query)
sqlalchemy.exc.OperationalError: (MySQLdb.OperationalError) (1213, 'Deadlock found when trying to get lock; try restarting transaction')
[SQL: UPDATE task_instance SET state=%s, updated_at=%s, trigger_id=%s, next_method=%s, next_kwargs=%s WHERE task_instance.state = %s AND task_instance.trigger_timeout < %s]
[parameters: (<TaskInstanceState.SCHEDULED: 'scheduled'>, datetime.datetime(2024, 8, 2, 13, 14, 22, 215659), None, '__fail__', '{""__var"": {""error"": ""Trigger/execution timeout""}, ""__type"": ""dict""}', <TaskInstanceState.DEFERRED: 'deferred'>, datetime.datetime(2024, 8, 2, 13, 14, 22, 202306, tzinfo=Timezone('UTC')))]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2024-08-02T06:14:22.258-0700[0m] {[34mkubernetes_executor.py:[0m706} INFO[0m - Shutting down Kubernetes executor[0m
```

This should occur when the scheduler and trigger compete for a row lock, based on MySQL database query log analysis. Since the trigger already includes a retry mechanism on update(Trigger.clean_unused), we should add a retry mechanism here as well.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",TakawaAkirayo,2024-08-13 11:40:16+00:00,[],2024-11-21 08:06:15+00:00,2024-10-02 06:51:09+00:00,https://github.com/apache/airflow/pull/41429,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2340328343, 'issue_id': 2463132007, 'author': 'TakawaAkirayo', 'body': 'From our observations in production, the deadlock issue has not occurred since we applied our own patch to Airflow. It seems that retry can tolerate the issue to some extent. However, to completely eliminate it, processes need to maintain the same data access order. There is still room for further optimization.\r\n\r\nPlease kindly review this when you have time if this is the right fix, and if you have any suggestions, please let me know @kaxil @ashb @XD-DENG @shahar1', 'created_at': datetime.datetime(2024, 9, 10, 10, 51, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2381375739, 'issue_id': 2463132007, 'author': 'TakawaAkirayo', 'body': ""> Apologies for the delay, I accidentally overlooked this PR after your fixes - it looks OK, I'd be happy for a second opinion though. @TakawaAkirayo Could you please add a newsfragment?\r\n\r\n@shahar1 Many thanks for the review. I just added a newsfragment regarding this [https://github.com/apache/airflow/blob/main/contributing-docs/16_contribution_workflow.rst.](url) please have a check."", 'created_at': datetime.datetime(2024, 9, 29, 14, 18, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387481874, 'issue_id': 2463132007, 'author': 'TakawaAkirayo', 'body': ""> Approved, but static checks need to be fixed.\r\n\r\n@jscheffl Sure, I've already fixed the static check, and the checks have passed now."", 'created_at': datetime.datetime(2024, 10, 2, 1, 54, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387746392, 'issue_id': 2463132007, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 2, 6, 51, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485696226, 'issue_id': 2463132007, 'author': 'klacire', 'body': ""After upgrading from 2.9.0 to 2.10.3 the deadlock still exists. It's even worst, now it makes the sensor (in reschedule mode) fail after a random number of poke."", 'created_at': datetime.datetime(2024, 11, 19, 13, 19, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486576574, 'issue_id': 2463132007, 'author': 'potiuk', 'body': '> After upgrading from 2.9.0 to 2.10.3 the deadlock still exists. It\'s even worst, now it makes the sensor (in reschedule mode) fail after a random number of poke.\r\n\r\nPlease open new issue and provide all information about your case then and add reference to it as ""similar to #41429"". It might be the same or different issue manifesting tne same way and the more information you provide, the higher chance someone will attempt to look at it and try to diagnose and fix it.\r\n\r\nWhen you just comment on a closed issue ""thse issue is still not solved"" with very vague description and without details explaining what you mean, the chances that someone will look at it are very slim, almost none. You increase your chances by creating new issue with as detailed explanation of your circumstances as possible. Up to you if you want to increase your chances of getting help.', 'created_at': datetime.datetime(2024, 11, 19, 19, 29, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488339215, 'issue_id': 2463132007, 'author': 'TakawaAkirayo', 'body': ""@klacire This change primarily attempts to tolerate the scheduler's failure caused by the deadlock issue, rather than completely eliminating the deadlock. You can refer to the previous comments; we still have work to do to eliminate the deadlock entirely.\r\n\r\nCould you please open new issue and provide your error stack trace? Currently I don't see much of a definitive connection between your issue and this change."", 'created_at': datetime.datetime(2024, 11, 20, 11, 32, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488934125, 'issue_id': 2463132007, 'author': 'klacire', 'body': 'I already can find an issue mentioning the same problem : #41428', 'created_at': datetime.datetime(2024, 11, 20, 15, 45, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489862652, 'issue_id': 2463132007, 'author': 'TakawaAkirayo', 'body': ""@klacire Ok, what about this issue:\r\n 'now it makes the sensor (in reschedule mode) fail after a random number of poke'\r\nWhat's the stack trace of it? What's the direct reason of the sensor's faliure?"", 'created_at': datetime.datetime(2024, 11, 21, 1, 13, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490325962, 'issue_id': 2463132007, 'author': 'klacire', 'body': 'same root cause in my opinion. No need to duplicate for now.', 'created_at': datetime.datetime(2024, 11, 21, 8, 6, 14, tzinfo=datetime.timezone.utc)}]","TakawaAkirayo (Issue Creator) on (2024-09-10 10:51:45 UTC): From our observations in production, the deadlock issue has not occurred since we applied our own patch to Airflow. It seems that retry can tolerate the issue to some extent. However, to completely eliminate it, processes need to maintain the same data access order. There is still room for further optimization.

Please kindly review this when you have time if this is the right fix, and if you have any suggestions, please let me know @kaxil @ashb @XD-DENG @shahar1

TakawaAkirayo (Issue Creator) on (2024-09-29 14:18:43 UTC): @shahar1 Many thanks for the review. I just added a newsfragment regarding this [https://github.com/apache/airflow/blob/main/contributing-docs/16_contribution_workflow.rst.](url) please have a check.

TakawaAkirayo (Issue Creator) on (2024-10-02 01:54:08 UTC): @jscheffl Sure, I've already fixed the static check, and the checks have passed now.

boring-cyborg[bot] on (2024-10-02 06:51:11 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

klacire on (2024-11-19 13:19:52 UTC): After upgrading from 2.9.0 to 2.10.3 the deadlock still exists. It's even worst, now it makes the sensor (in reschedule mode) fail after a random number of poke.

potiuk on (2024-11-19 19:29:24 UTC): Please open new issue and provide all information about your case then and add reference to it as ""similar to #41429"". It might be the same or different issue manifesting tne same way and the more information you provide, the higher chance someone will attempt to look at it and try to diagnose and fix it.

When you just comment on a closed issue ""thse issue is still not solved"" with very vague description and without details explaining what you mean, the chances that someone will look at it are very slim, almost none. You increase your chances by creating new issue with as detailed explanation of your circumstances as possible. Up to you if you want to increase your chances of getting help.

TakawaAkirayo (Issue Creator) on (2024-11-20 11:32:49 UTC): @klacire This change primarily attempts to tolerate the scheduler's failure caused by the deadlock issue, rather than completely eliminating the deadlock. You can refer to the previous comments; we still have work to do to eliminate the deadlock entirely.

Could you please open new issue and provide your error stack trace? Currently I don't see much of a definitive connection between your issue and this change.

klacire on (2024-11-20 15:45:01 UTC): I already can find an issue mentioning the same problem : #41428

TakawaAkirayo (Issue Creator) on (2024-11-21 01:13:15 UTC): @klacire Ok, what about this issue:
 'now it makes the sensor (in reschedule mode) fail after a random number of poke'
What's the stack trace of it? What's the direct reason of the sensor's faliure?

klacire on (2024-11-21 08:06:14 UTC): same root cause in my opinion. No need to duplicate for now.

"
2463074604,pull_request,closed,,Fetch history dataset events based on DDRQ instead of the previous Dag Run,"## Why
Before this change, we used the previous DagRun to decide which dataset events should be append to a DagRun as its `consumed_dataset_events.` However, if we delete the previous run, these DatasetEvent will be added to the next DagRun, which is confusing.

## What
Instead of using the timestamp of the previous run as the start time to filter dataset events, it now fetches the dataset event created after the `create_at` timestamp of `DatasetDagRunQueue`s (a.k.a DDRQ). To achieve this, we also need to ensure the first created DDRQ is no later than the creation time of a dataset event. Thus, it also passes the timestamp of the dataset event that calls `_queue_dag_run` as the `created_at` timestamp of DDRQs

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-13 11:10:03+00:00,[],2024-11-07 00:14:58+00:00,2024-11-07 00:14:58+00:00,https://github.com/apache/airflow/pull/41427,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2286015380, 'issue_id': 2463074604, 'author': 'Lee-W', 'body': ""cc @uranusjr @dstandish \r\n\r\nI'll add some tests to this one, but it would be great if you could take a look. Thanks!"", 'created_at': datetime.datetime(2024, 8, 13, 11, 28, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286644077, 'issue_id': 2463074604, 'author': 'dstandish', 'body': 'The timestamp-based filtering is hard to reason about and, sorta imprecise.  Maybe we should take this opportunity to explore using parent-child relationships that don\'t rely on timestamps.\r\n\r\nBy that I mean, when a dataset event results in a queue record, stamp the association in a table.\r\n\r\nSo like add surrogate key autoincrementing integer `id` column to DDRQ, then...\r\nwhen dataset event results in ddrq creation, then we create the ddrq record and create a record in a mapping table (ddrq_id, dataset_event_id)\r\n\r\nThen we\'d be able to know the association precisely.\r\n\r\nThe challenge though is that we have have to deal with many concurrent writers.  There is a race condition when creating the DDRQ record, and there\'s another one when the DDRQ record is ""consumed"".  So we would have to deal with that.\r\n\r\nGiven that challenge and complexity, and since timestamp comparision was ""good enough"", I did not go that route initially.  But curious what y\'all think.  Is it worth exploring?', 'created_at': datetime.datetime(2024, 8, 13, 16, 22, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287711473, 'issue_id': 2463074604, 'author': 'Lee-W', 'body': '> The timestamp-based filtering is hard to reason about and, sorta imprecise. Maybe we should take this opportunity to explore using parent-child relationships that don\'t rely on timestamps.\r\n> \r\n> By that I mean, when a dataset event results in a queue record, stamp the association in a table.\r\n> \r\n> So like add surrogate key autoincrementing integer `id` column to DDRQ, then... when dataset event results in ddrq creation, then we create the ddrq record and create a record in a mapping table (ddrq_id, dataset_event_id)\r\n> \r\n> Then we\'d be able to know the association precisely.\r\n> \r\n> The challenge though is that we have have to deal with many concurrent writers. There is a race condition when creating the DDRQ record, and there\'s another one when the DDRQ record is ""consumed"". So we would have to deal with that.\r\n> \r\n> Given that challenge and complexity, and since timestamp comparision was ""good enough"", I did not go that route initially. But curious what y\'all think. Is it worth exploring?\r\n\r\nI have considered it, but I might sugest we keep it as it is for now. The original previous DAG run method has already resolved most scenarios. This rare case, where the previous DAG run is removed, was only discovered long after this feature was introduced. This PR should be able to move us one step forward.\r\n\r\nIn our current design, directly linking DDRQ and dataset events might introduce more complexity even before the race condition you mentioned. Also, we are now redesigning datasets as assets. If we\'re to explore the new way, we probably should do that during the assets change. What do you think?', 'created_at': datetime.datetime(2024, 8, 14, 2, 23, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287881763, 'issue_id': 2463074604, 'author': 'uranusjr', 'body': '> I thought of it but I would\r\n\r\nIs this sentence unfinished?', 'created_at': datetime.datetime(2024, 8, 14, 5, 25, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287944972, 'issue_id': 2463074604, 'author': 'Lee-W', 'body': ""> > I thought of it but I would\r\n> \r\n> Is this sentence unfinished?\r\n\r\nI've reworded it and didn't remove this sentence. Just updated it. Thanks!"", 'created_at': datetime.datetime(2024, 8, 14, 6, 21, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293082576, 'issue_id': 2463074604, 'author': 'uranusjr', 'body': 'This is not _that_ difficult to understand, at least when isolated like in this PR, but I agree with Daniel this may not be easy to follow otherwise. It is a bit too implicit to my liking.\r\n\r\nHow much work do you this would be neded to produced a POC for the explicit association solution? We donâ€™t have a tight deadline on this since this will be in 2.10.1 the earliest, which is still some time away.', 'created_at': datetime.datetime(2024, 8, 16, 8, 35, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293149861, 'issue_id': 2463074604, 'author': 'Lee-W', 'body': '> This is not _that_ difficult to understand, at least when isolated like in this PR, but I agree with Daniel this may not be easy to follow otherwise. It is a bit too implicit to my liking.\r\n> \r\n> How much work do you this would be neded to produced a POC for the explicit association solution? We donâ€™t have a tight deadline on this since this will be in 2.10.1 the earliest, which is still some time away.\r\n\r\nI think I should be able to have a POC early next week.', 'created_at': datetime.datetime(2024, 8, 16, 9, 18, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2451055863, 'issue_id': 2463074604, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 1, 0, 17, 8, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-08-13 11:28:39 UTC): cc @uranusjr @dstandish 

I'll add some tests to this one, but it would be great if you could take a look. Thanks!

dstandish on (2024-08-13 16:22:10 UTC): The timestamp-based filtering is hard to reason about and, sorta imprecise.  Maybe we should take this opportunity to explore using parent-child relationships that don't rely on timestamps.

By that I mean, when a dataset event results in a queue record, stamp the association in a table.

So like add surrogate key autoincrementing integer `id` column to DDRQ, then...
when dataset event results in ddrq creation, then we create the ddrq record and create a record in a mapping table (ddrq_id, dataset_event_id)

Then we'd be able to know the association precisely.

The challenge though is that we have have to deal with many concurrent writers.  There is a race condition when creating the DDRQ record, and there's another one when the DDRQ record is ""consumed"".  So we would have to deal with that.

Given that challenge and complexity, and since timestamp comparision was ""good enough"", I did not go that route initially.  But curious what y'all think.  Is it worth exploring?

Lee-W (Issue Creator) on (2024-08-14 02:23:14 UTC): I have considered it, but I might sugest we keep it as it is for now. The original previous DAG run method has already resolved most scenarios. This rare case, where the previous DAG run is removed, was only discovered long after this feature was introduced. This PR should be able to move us one step forward.

In our current design, directly linking DDRQ and dataset events might introduce more complexity even before the race condition you mentioned. Also, we are now redesigning datasets as assets. If we're to explore the new way, we probably should do that during the assets change. What do you think?

uranusjr on (2024-08-14 05:25:04 UTC): Is this sentence unfinished?

Lee-W (Issue Creator) on (2024-08-14 06:21:13 UTC): I've reworded it and didn't remove this sentence. Just updated it. Thanks!

uranusjr on (2024-08-16 08:35:49 UTC): This is not _that_ difficult to understand, at least when isolated like in this PR, but I agree with Daniel this may not be easy to follow otherwise. It is a bit too implicit to my liking.

How much work do you this would be neded to produced a POC for the explicit association solution? We donâ€™t have a tight deadline on this since this will be in 2.10.1 the earliest, which is still some time away.

Lee-W (Issue Creator) on (2024-08-16 09:18:40 UTC): I think I should be able to have a POC early next week.

github-actions[bot] on (2024-11-01 00:17:08 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2463022507,pull_request,closed,,Add 'name' to Dataset,"A part of [AIP-76](https://cwiki.apache.org/confluence/x/QQ2TEg).

The Dataset class now accepts *either* name or uri, and fills the other by the provided value if both are not explicitly set.

Although not strictly required by this change, 'name' on DatasetAlias also now received the same parse-time check as Dataset's name and uri fields so they emit the same errors on incorrectly inputs.

This conflicts with #41348. One must be rebased if we merge the other.

TODO:

* Modify the UI and CLI to show the name instead of/together with the URI.
* Add tests.",uranusjr,2024-08-13 10:43:20+00:00,[],2024-09-23 06:41:23+00:00,2024-09-23 06:41:23+00:00,https://github.com/apache/airflow/pull/41424,"[('area:serialization', ''), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2314509500, 'issue_id': 2463022507, 'author': 'uranusjr', 'body': 'Status:\r\n\r\n* Added `name` to Dataset. Model changes and migration added.\r\n* Both `name` and `uri` are optional, but the user must supply at least one of them. Thereâ€™s a check when a Dataset is created.\r\n* The database enforces _both `name` and `uri` must be unique_. This means you canâ€™t have two assets (different names) point to the same URI. It makes dataset resolution logic a lot simpler. Probably good enough in most cases?\r\n* The DAG processor (during `bulk_write_to_db`) collects all datasets and de-duplicate name and URI values. Currently this is done trivially (just randomly drop one of them). We might want to emit warnings, especially since the previous constraint can be confusing for users in edge cases.\r\n\r\nTodo:\r\n\r\n* Fix existing tests. Many tests currently do something like this `Dataset(uri)`. Should we fix all of them, or should we just make the positional argument the URI instead? Currently itâ€™s the name.\r\n* DatasetAliasâ€™s `add` interface (in `OutletEventAccessor`) currently only takes the URI. It should also accept the name and intelligently select the correct Dataset from the string value. Matching name over URI.\r\n* The `yield Metadata` interface might have the same issue?\r\n* Add tests for various name-URI combinations.', 'created_at': datetime.datetime(2024, 8, 28, 7, 19, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2367343788, 'issue_id': 2463022507, 'author': 'uranusjr', 'body': 'Iâ€™ll do a separate PR now that things are refactored (and this conflicts like hell)', 'created_at': datetime.datetime(2024, 9, 23, 6, 41, 23, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-08-28 07:19:13 UTC): Status:

* Added `name` to Dataset. Model changes and migration added.
* Both `name` and `uri` are optional, but the user must supply at least one of them. Thereâ€™s a check when a Dataset is created.
* The database enforces _both `name` and `uri` must be unique_. This means you canâ€™t have two assets (different names) point to the same URI. It makes dataset resolution logic a lot simpler. Probably good enough in most cases?
* The DAG processor (during `bulk_write_to_db`) collects all datasets and de-duplicate name and URI values. Currently this is done trivially (just randomly drop one of them). We might want to emit warnings, especially since the previous constraint can be confusing for users in edge cases.

Todo:

* Fix existing tests. Many tests currently do something like this `Dataset(uri)`. Should we fix all of them, or should we just make the positional argument the URI instead? Currently itâ€™s the name.
* DatasetAliasâ€™s `add` interface (in `OutletEventAccessor`) currently only takes the URI. It should also accept the name and intelligently select the correct Dataset from the string value. Matching name over URI.
* The `yield Metadata` interface might have the same issue?
* Add tests for various name-URI combinations.

uranusjr (Issue Creator) on (2024-09-23 06:41:23 UTC): Iâ€™ll do a separate PR now that things are refactored (and this conflicts like hell)

"
2463021960,pull_request,closed,,Support template hostname in NOTES.txt,"This PR support template hostname in NOTES.txt
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-13 10:43:03+00:00,[],2024-08-14 01:21:29+00:00,2024-08-14 01:21:29+00:00,https://github.com/apache/airflow/pull/41423,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2462903877,pull_request,closed,,add OpenLineage support to S3ToRedshiftOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Added `get_openlineage_facets_on_complete` method to `S3ToRedshiftOperator`. 
It extracts target table schema by querying redshift and creates identity column level lineage. 

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Artuz37,2024-08-13 09:45:41+00:00,[],2024-08-19 07:44:50+00:00,2024-08-19 07:44:50+00:00,https://github.com/apache/airflow/pull/41422,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2285832430, 'issue_id': 2462903877, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 13, 9, 45, 46, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-13 09:45:46 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2462210173,pull_request,closed,,add missing sync_hook_class to CloudDataTransferServiceAsyncHook,"Without this sync_hook_class, we cannot get the sync version hook and thus cannot sync_to_async to async version.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-13 01:58:30+00:00,[],2024-08-13 07:38:46+00:00,2024-08-13 07:38:44+00:00,https://github.com/apache/airflow/pull/41417,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2462143627,pull_request,closed,,Added logging device and logging device options,"Closes: https://github.com/apache/airflow/issues/40533
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #40533 
related: #40533 

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Updated the DockerSwarmOperator with logging device and logging device options parameters as requested. I restricted support for only 'json-file' and 'gelf', since that is all I was able to test locally. I can include support for other logging drivers (e.g. fluentd) if it makes sense. Also, I wasn't sure if I should have a check in place for valid logging options. Happy to explore if it makes sense. Here is some info on the GELF logging driver and its options, https://docs.docker.com/engine/logging/drivers/gelf/. 

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",geraj1010,2024-08-13 00:52:19+00:00,[],2024-08-27 13:47:33+00:00,2024-08-27 13:47:29+00:00,https://github.com/apache/airflow/pull/41416,"[('area:providers', ''), ('provider:docker', '')]","[{'comment_id': 2285144511, 'issue_id': 2462143627, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 13, 0, 52, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293009908, 'issue_id': 2462143627, 'author': 'Lee-W', 'body': 'We might need to add some unit tests to this change as well', 'created_at': datetime.datetime(2024, 8, 16, 7, 50, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293616313, 'issue_id': 2462143627, 'author': 'geraj1010', 'body': ""@Lee-W I'm not quite sure what kind of unit tests would be valid here, since this is an operator update. The operator doesn't return anything to check. I do have a test DAG if that counts, but you would need to have Docker Swarm and Graylog setup to test."", 'created_at': datetime.datetime(2024, 8, 16, 14, 29, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2294633490, 'issue_id': 2462143627, 'author': 'geraj1010', 'body': '@Lee-W \r\nI have added two unit tests for checking if `logging_driver` works and for entering an invalid/unsupported `logging_driver` value.', 'created_at': datetime.datetime(2024, 8, 17, 5, 23, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308577331, 'issue_id': 2462143627, 'author': 'geraj1010', 'body': '@Lee-W I have update the `spelling_wordlist.txt`, but the Static checks is still failing. Is there anything else I need to do?', 'created_at': datetime.datetime(2024, 8, 24, 23, 47, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312614254, 'issue_id': 2462143627, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 27, 13, 47, 32, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-13 00:52:23 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

Lee-W on (2024-08-16 07:50:11 UTC): We might need to add some unit tests to this change as well

geraj1010 (Issue Creator) on (2024-08-16 14:29:04 UTC): @Lee-W I'm not quite sure what kind of unit tests would be valid here, since this is an operator update. The operator doesn't return anything to check. I do have a test DAG if that counts, but you would need to have Docker Swarm and Graylog setup to test.

geraj1010 (Issue Creator) on (2024-08-17 05:23:27 UTC): @Lee-W 
I have added two unit tests for checking if `logging_driver` works and for entering an invalid/unsupported `logging_driver` value.

geraj1010 (Issue Creator) on (2024-08-24 23:47:56 UTC): @Lee-W I have update the `spelling_wordlist.txt`, but the Static checks is still failing. Is there anything else I need to do?

boring-cyborg[bot] on (2024-08-27 13:47:32 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2461895126,pull_request,closed,,Fix argument unpacking conflict with keyword argument,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",HAPPYJATT11,2024-08-12 21:05:28+00:00,[],2024-08-21 02:41:18+00:00,2024-08-21 02:41:18+00:00,https://github.com/apache/airflow/pull/41415,[],"[{'comment_id': 2284905614, 'issue_id': 2461895126, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 12, 21, 5, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298851114, 'issue_id': 2461895126, 'author': 'jabbera', 'body': 'This is dupe of PR https://github.com/apache/airflow/pull/41316', 'created_at': datetime.datetime(2024, 8, 20, 13, 22, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2300368865, 'issue_id': 2461895126, 'author': 'uranusjr', 'body': 'Closing in favour to the other one. This misses `VAR_KEYWORD`.', 'created_at': datetime.datetime(2024, 8, 21, 2, 41, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-12 21:05:31 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jabbera on (2024-08-20 13:22:18 UTC): This is dupe of PR https://github.com/apache/airflow/pull/41316

uranusjr on (2024-08-21 02:41:18 UTC): Closing in favour to the other one. This misses `VAR_KEYWORD`.

"
2461877463,pull_request,closed,,Fix tests/models/test_variable.py for database isolation mode,"Related: https://github.com/apache/airflow/pull/41067

This PR fixes the tests in `tests/models/test_variable.py`in database isolation mode.

This was a bit harder one. It wa snot just fixing tests but to make the API working the same way like w/o DB isolation the following needed to be adjusted:
- Cache need to be cleared on API client as well as server on update
  - This means I needed to add a facade and make internal methods for the backend to ensure cache is flushed on client
- KeyError and AttributeError are used by Variable API and need to be supported/transported by internal API w/o HTTP 500
  - Serialization for the two Exceptions needed to be added as well
- Some tests needed to be excluded because the distributed setup with API server does not allow mocking ENV or changing FernetKey during test",jscheffl,2024-08-12 20:55:04+00:00,[],2024-08-13 16:44:09+00:00,2024-08-13 16:44:09+00:00,https://github.com/apache/airflow/pull/41414,"[('area:serialization', '')]",[],
2461840911,pull_request,closed,,KubernetesHook kube_config extra can take dict,"Previously had to be json-encoded string which is less convenient when defining the conn in json.

E.g. before only this works
```
AIRFLOW_CONN_KUBERNETES_DEFAULT='{""extra"":{""cluster_context"":""orbstack"",""kube_config"":""{\""kind\"":\""Config\"",...
```

But after, now this also works:
```
AIRFLOW_CONN_KUBERNETES_DEFAULT='{""extra"":{""cluster_context"":""orbstack"",""kube_config"":{""kind"":""Config"",...
```",dstandish,2024-08-12 20:31:57+00:00,[],2024-09-30 15:58:39+00:00,2024-09-30 15:58:37+00:00,https://github.com/apache/airflow/pull/41413,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2381685372, 'issue_id': 2461840911, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 30, 0, 15, 46, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-09-30 00:15:46 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2461721995,pull_request,closed,,[FEAT] databricks repair run with reason match and appropriate new settings,"

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
[FEAT] databricks repair run with reason match and appropriate new settings in `DatabricksRunNowOperator`
This is useful in scenario like where we get databricks exception like `AWS_INSUFFICIENT_INSTANCE_CAPACITY_FAILURE (CLIENT_ERROR).`,  `AWS_MAX_SPOT_INSTANCE_COUNT_EXCEEDED_FAILURE ` where user want to repair run with let's say different zone of region or let's say with 100% ondemand  

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gaurav7261,2024-08-12 19:18:59+00:00,[],2024-09-12 11:27:43+00:00,2024-08-30 10:14:59+00:00,https://github.com/apache/airflow/pull/41412,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2307989361, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': '@Lee-W @shahar1 can you please review now', 'created_at': datetime.datetime(2024, 8, 24, 1, 56, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308661220, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': '@Lee-W require changes done, also added assert_called_with check for `update_job` method as well.', 'created_at': datetime.datetime(2024, 8, 25, 5, 26, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308671800, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': ""@Lee-W  should we have one more configurable like user want to repair only in case if `databricks_repair_reason_new_settings` dict key contains the reason, otherwise don't repair at all(as it is a legit error(like some job issue) and most probably will not get resolve even with one more repair run), I want to ask what you think for this ? and how can we enable that as well(have one more argument or `databricks_repair_reason_new_settings` is empty, don't repair or something in your mind) ?"", 'created_at': datetime.datetime(2024, 8, 25, 6, 13, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308675722, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': ""> @Lee-W should we have one more configurable like user want to repair only in case if `databricks_repair_reason_new_settings` dict key contains the reason, otherwise don't repair at all(as it is a legit error(like some job issue) and most probably will not get resolve even with one more repair run), I want to ask what you think for this ? and how can we enable that as well(have one more argument or `databricks_repair_reason_new_settings` is empty, don't repair or something in your mind) ?\r\n\r\nI though we already have `repair_run` config?"", 'created_at': datetime.datetime(2024, 8, 25, 6, 31, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308679006, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': ""> > @Lee-W should we have one more configurable like user want to repair only in case if `databricks_repair_reason_new_settings` dict key contains the reason, otherwise don't repair at all(as it is a legit error(like some job issue) and most probably will not get resolve even with one more repair run), I want to ask what you think for this ? and how can we enable that as well(have one more argument or `databricks_repair_reason_new_settings` is empty, don't repair or something in your mind) ?\r\n> \r\n> I though we already have `repair_run` config?\r\n\r\n`repair_run` is just a bool currently\r\n\r\ncurrently the flow is if `repair_run` bool is true, repair will get trigger always, if repair_reason matches in  `databricks_repair_reason_new_settings`, we are just updating databricks job before calling repair run api,."", 'created_at': datetime.datetime(2024, 8, 25, 6, 46, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2312598134, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': ""> > > @Lee-W should we have one more configurable like user want to repair only in case if `databricks_repair_reason_new_settings` dict key contains the reason, otherwise don't repair at all(as it is a legit error(like some job issue) and most probably will not get resolve even with one more repair run), I want to ask what you think for this ? and how can we enable that as well(have one more argument or `databricks_repair_reason_new_settings` is empty, don't repair or something in your mind) ?\r\n> > \r\n> > \r\n> > I though we already have `repair_run` config?\r\n> \r\n> `repair_run` is just a bool currently\r\n> \r\n> currently the flow is if `repair_run` bool is true, repair will get trigger always, if repair_reason matches in `databricks_repair_reason_new_settings`, we are just updating databricks job before calling repair run api,.\r\n\r\nYep, it sounds good. Is there anything missed?"", 'created_at': datetime.datetime(2024, 8, 27, 13, 40, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313980116, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': ""@Lee-W  I'm thinking for an option not to trigger repair if reason matches nothing in the dict `databricks_repair_reason_new_settings` , what's your thought on this?"", 'created_at': datetime.datetime(2024, 8, 28, 2, 35, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314696702, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': ""> @Lee-W I'm thinking for an option not to trigger repair if reason matches nothing in the dict `databricks_repair_reason_new_settings` , what's your thought on this?\r\n\r\nI don't think we need a new option. If the reason is provided and nothing is matched, then we should not repair. This should be the default behavior. If the user wants to repair at all cases, than the reason dict should not be passed"", 'created_at': datetime.datetime(2024, 8, 28, 8, 40, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314726476, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': 'thanks @Lee-W , making the changes, Yes, I also agree with same default behaviour.', 'created_at': datetime.datetime(2024, 8, 28, 8, 53, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2314990423, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': '@Lee-W changes are done, can you please review', 'created_at': datetime.datetime(2024, 8, 28, 10, 55, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320755725, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': 'LGTM ðŸ‘', 'created_at': datetime.datetime(2024, 8, 30, 10, 14, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2325875691, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': '@Lee-W currently we are checking in root state_message only, should we also check `error` key in every fail task array as well ?', 'created_at': datetime.datetime(2024, 9, 3, 8, 12, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2327834405, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': '> @Lee-W currently we are checking in root state_message only, should we also check `error` key in every fail task array as well ?\r\n\r\nCould you provide an example to illustrate this? Thanks!', 'created_at': datetime.datetime(2024, 9, 4, 3, 19, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2332298256, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': 'For example, sometime in case of custom exception, when user want to retry with another job config, in root state_message we get only below one, and main exception in insider array \r\n```Job run failed with terminal state: {\'life_cycle_state\': \'INTERNAL_ERROR\', \'result_state\': \'FAILED\', \'state_message\': \'Task t1 failed with message: Workload failed, see run output for details. This caused all downstream tasks to get skipped.\'} and with the errors [{\'task_key\': \'t1\', \'run_id\': 293420302889009, \'error\': \'<span class=\\\'ansi-red-fg\\\'>APIError</span>: <!DOCTYPE html>\\n<html lang=en>\\n  <meta charset=utf-8>\\n  <meta name=viewport content=""initial-scale=1, minimum-scale=1, width=device-width"">\\n  <title>Error 502 (Server Error)!!1</title>\\n  <style>\\n    {margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px} > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\\n  </style>\\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\\n  <p><b>502.</b> <ins>Thatâ€™s an error.</ins>\\n  <p>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.  <ins>Thatâ€™s all we know.</ins>\\n\'}]```', 'created_at': datetime.datetime(2024, 9, 5, 17, 39, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2340551364, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': '@Lee-W  any suggestions?', 'created_at': datetime.datetime(2024, 9, 10, 12, 20, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2342082260, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': 'It looks like the error is part of the `state_message`. the user can still match it in current implementation? or is there anything I missed', 'created_at': datetime.datetime(2024, 9, 10, 22, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2342581145, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': 'ya but not always, sometime root `state_message` = `Task t1, t2... failed with message: Workload failed, see run output for details. This caused all downstream tasks to get skipped.`, nothing more information, in that case can we also allow matching with `error` key inside array of tasks? what you think @Lee-W , what I have seen in case of AWS side failures, we get root state_message correct, but when user throw custom exception or some databricks errors, state_message is same line `Task failed: Workload failed, see run output for details...`, nothing about main exception string', 'created_at': datetime.datetime(2024, 9, 11, 4, 10, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2345335723, 'issue_id': 2461721995, 'author': 'Lee-W', 'body': ""if that's the case, it makes sense to have one"", 'created_at': datetime.datetime(2024, 9, 12, 5, 56, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2346033661, 'issue_id': 2461721995, 'author': 'gaurav7261', 'body': 'cool, will create a new pr for the same. Thanks', 'created_at': datetime.datetime(2024, 9, 12, 11, 27, 42, tzinfo=datetime.timezone.utc)}]","gaurav7261 (Issue Creator) on (2024-08-24 01:56:16 UTC): @Lee-W @shahar1 can you please review now

gaurav7261 (Issue Creator) on (2024-08-25 05:26:26 UTC): @Lee-W require changes done, also added assert_called_with check for `update_job` method as well.

gaurav7261 (Issue Creator) on (2024-08-25 06:13:32 UTC): @Lee-W  should we have one more configurable like user want to repair only in case if `databricks_repair_reason_new_settings` dict key contains the reason, otherwise don't repair at all(as it is a legit error(like some job issue) and most probably will not get resolve even with one more repair run), I want to ask what you think for this ? and how can we enable that as well(have one more argument or `databricks_repair_reason_new_settings` is empty, don't repair or something in your mind) ?

Lee-W on (2024-08-25 06:31:45 UTC): I though we already have `repair_run` config?

gaurav7261 (Issue Creator) on (2024-08-25 06:46:27 UTC): `repair_run` is just a bool currently

currently the flow is if `repair_run` bool is true, repair will get trigger always, if repair_reason matches in  `databricks_repair_reason_new_settings`, we are just updating databricks job before calling repair run api,.

Lee-W on (2024-08-27 13:40:52 UTC): Yep, it sounds good. Is there anything missed?

gaurav7261 (Issue Creator) on (2024-08-28 02:35:57 UTC): @Lee-W  I'm thinking for an option not to trigger repair if reason matches nothing in the dict `databricks_repair_reason_new_settings` , what's your thought on this?

Lee-W on (2024-08-28 08:40:45 UTC): I don't think we need a new option. If the reason is provided and nothing is matched, then we should not repair. This should be the default behavior. If the user wants to repair at all cases, than the reason dict should not be passed

gaurav7261 (Issue Creator) on (2024-08-28 08:53:14 UTC): thanks @Lee-W , making the changes, Yes, I also agree with same default behaviour.

gaurav7261 (Issue Creator) on (2024-08-28 10:55:59 UTC): @Lee-W changes are done, can you please review

Lee-W on (2024-08-30 10:14:35 UTC): LGTM ðŸ‘

gaurav7261 (Issue Creator) on (2024-09-03 08:12:47 UTC): @Lee-W currently we are checking in root state_message only, should we also check `error` key in every fail task array as well ?

Lee-W on (2024-09-04 03:19:08 UTC): Could you provide an example to illustrate this? Thanks!

gaurav7261 (Issue Creator) on (2024-09-05 17:39:23 UTC): For example, sometime in case of custom exception, when user want to retry with another job config, in root state_message we get only below one, and main exception in insider array 
```Job run failed with terminal state: {'life_cycle_state': 'INTERNAL_ERROR', 'result_state': 'FAILED', 'state_message': 'Task t1 failed with message: Workload failed, see run output for details. This caused all downstream tasks to get skipped.'} and with the errors [{'task_key': 't1', 'run_id': 293420302889009, 'error': '<span class=\'ansi-red-fg\'>APIError</span>: <!DOCTYPE html>\n<html lang=en>\n  <meta charset=utf-8>\n  <meta name=viewport content=""initial-scale=1, minimum-scale=1, width=device-width"">\n  <title>Error 502 (Server Error)!!1</title>\n  <style>\n    {margin:0;padding:0}html,code{font:15px/22px arial,sans-serif}html{background:#fff;color:#222;padding:15px}body{margin:7% auto 0;max-width:390px;min-height:180px;padding:30px 0 15px} > body{background:url(//www.google.com/images/errors/robot.png) 100% 5px no-repeat;padding-right:205px}p{margin:11px 0 22px;overflow:hidden}ins{color:#777;text-decoration:none}a img{border:0}@media screen and (max-width:772px){body{background:none;margin-top:0;max-width:none;padding-right:0}}#logo{background:url(//www.google.com/images/branding/googlelogo/1x/googlelogo_color_150x54dp.png) no-repeat;margin-left:-5px}@media only screen and (min-resolution:192dpi){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat 0% 0%/100% 100%;-moz-border-image:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) 0}}@media only screen and (-webkit-min-device-pixel-ratio:2){#logo{background:url(//www.google.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png) no-repeat;-webkit-background-size:100% 100%}}#logo{display:inline-block;height:54px;width:150px}\n  </style>\n  <a href=//www.google.com/><span id=logo aria-label=Google></span></a>\n  <p><b>502.</b> <ins>Thatâ€™s an error.</ins>\n  <p>The server encountered a temporary error and could not complete your request.<p>Please try again in 30 seconds.  <ins>Thatâ€™s all we know.</ins>\n'}]```

gaurav7261 (Issue Creator) on (2024-09-10 12:20:07 UTC): @Lee-W  any suggestions?

Lee-W on (2024-09-10 22:01:00 UTC): It looks like the error is part of the `state_message`. the user can still match it in current implementation? or is there anything I missed

gaurav7261 (Issue Creator) on (2024-09-11 04:10:25 UTC): ya but not always, sometime root `state_message` = `Task t1, t2... failed with message: Workload failed, see run output for details. This caused all downstream tasks to get skipped.`, nothing more information, in that case can we also allow matching with `error` key inside array of tasks? what you think @Lee-W , what I have seen in case of AWS side failures, we get root state_message correct, but when user throw custom exception or some databricks errors, state_message is same line `Task failed: Workload failed, see run output for details...`, nothing about main exception string

Lee-W on (2024-09-12 05:56:52 UTC): if that's the case, it makes sense to have one

gaurav7261 (Issue Creator) on (2024-09-12 11:27:42 UTC): cool, will create a new pr for the same. Thanks

"
2461666772,pull_request,closed,,update git-sync to 4.3.0,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Updating git-sync from 4.1.0 to 4.2.4

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JKrehling,2024-08-12 18:45:15+00:00,[],2024-11-08 18:53:41+00:00,2024-11-03 14:10:13+00:00,https://github.com/apache/airflow/pull/41411,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2287459936, 'issue_id': 2461666772, 'author': 'potiuk', 'body': 'Needs to fix pre-commit', 'created_at': datetime.datetime(2024, 8, 14, 0, 5, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2380308395, 'issue_id': 2461666772, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 28, 0, 14, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387497665, 'issue_id': 2461666772, 'author': 'potiuk', 'body': 'Could you rebase and fix static check @JKrehling ?', 'created_at': datetime.datetime(2024, 10, 2, 2, 12, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2452339365, 'issue_id': 2461666772, 'author': 'JKrehling', 'body': '4.3.0 released so I will go with that instead and I added the news fragment', 'created_at': datetime.datetime(2024, 11, 1, 18, 4, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2453441516, 'issue_id': 2461666772, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 3, 14, 10, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-14 00:05:16 UTC): Needs to fix pre-commit

github-actions[bot] on (2024-09-28 00:14:46 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

potiuk on (2024-10-02 02:12:03 UTC): Could you rebase and fix static check @JKrehling ?

JKrehling (Issue Creator) on (2024-11-01 18:04:20 UTC): 4.3.0 released so I will go with that instead and I added the news fragment

boring-cyborg[bot] on (2024-11-03 14:10:15 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2461637460,pull_request,closed,,document that running task instances will be marked as skipped when a dagrun times out,"The functionality contested/discussed in #30264 is not documented. Adding this documentation could reduce confusion.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",RNHTTR,2024-08-12 18:27:06+00:00,[],2024-09-11 18:17:44+00:00,2024-09-11 18:17:44+00:00,https://github.com/apache/airflow/pull/41410,[],"[{'comment_id': 2304103154, 'issue_id': 2461637460, 'author': 'potiuk', 'body': 'You shoudl back-port it to `v2-10-test` I guess @RNHTTR  once we merge it.', 'created_at': datetime.datetime(2024, 8, 22, 8, 39, 53, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-22 08:39:53 UTC): You shoudl back-port it to `v2-10-test` I guess @RNHTTR  once we merge it.

"
2461371395,pull_request,closed,,Remove label when Bug Report is not stale,"This will help in cases like https://github.com/apache/airflow/issues/31185 where although the original reporter commented, it is still showing as Stale.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-08-12 15:55:48+00:00,[],2024-08-12 23:19:54+00:00,2024-08-12 23:19:52+00:00,https://github.com/apache/airflow/pull/41408,"[('area:dev-tools', '')]",[],
2461282939,pull_request,closed,,Remove deprecated code is AWS provider,"Min Airflow version in providers moved to 2.8.0 in #41396. Some backward compatibility code in the Amazon provider package is only if the Airflow version is 2.7.1. Therefore, we can do some cleanup.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-12 15:18:33+00:00,[],2024-08-15 15:20:59+00:00,2024-08-15 15:20:57+00:00,https://github.com/apache/airflow/pull/41407,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2460682392,pull_request,closed,,fix broken main on news fragment,"Fixes:

```
pre-commit hook(s) made changes.
If you are seeing this message in CI, reproduce locally with: `pre-commit run --all-files`.
To run `pre-commit` as part of git workflow, use `pre-commit install`.
All changes made by hooks:
diff --git a/newsfragments/41395.significant.rst b/newsfragments/41395.significant.rst
index 844fc91..77be51a 100644
--- a/newsfragments/41395.significant.rst
+++ b/newsfragments/41395.significant.rst
@@ -8,4 +8,3 @@ The following deprecated functions, constants, and classes have been removed as
 - ``airflow.utils.file.mkdirs`` function: Use ``pathlib.Path.mkdir`` instead.
 - ``airflow.utils.state.SHUTDOWN`` state: No action needed; this state is no longer used.
 - ``airflow.utils.state.terminating_states`` constant: No action needed; this constant is no longer used.
-

This error means that you have to fix the issues listed above:
```


Example failure
https://github.com/apache/airflow/actions/runs/10350376109/job/28646831125?pr=41402#step:8:189

",eladkal,2024-08-12 11:00:41+00:00,[],2024-08-12 11:09:09+00:00,2024-08-12 11:03:34+00:00,https://github.com/apache/airflow/pull/41404,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2283680066, 'issue_id': 2460682392, 'author': 'kaxil', 'body': 'My bad, sry', 'created_at': datetime.datetime(2024, 8, 12, 11, 9, 7, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-08-12 11:09:07 UTC): My bad, sry

"
2460672949,pull_request,closed,,Fix missing source link for the mapped task with index 0,"When the source map index is 0, ""0 || undefined"" passes ""undefined"" which causes this error

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-12 10:56:07+00:00,[],2024-08-12 13:55:38+00:00,2024-08-12 13:55:21+00:00,https://github.com/apache/airflow/pull/41403,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2284005076, 'issue_id': 2460672949, 'author': 'Lee-W', 'body': '> Do we need to cherry pick to 2.10 or raise PR for 2.10 test branch on this one?\r\n\r\n@ephraimbuddy @utkarsharma2 would like to check are we still be able to include this one?', 'created_at': datetime.datetime(2024, 8, 12, 13, 31, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284057128, 'issue_id': 2460672949, 'author': 'ephraimbuddy', 'body': ""> > Do we need to cherry pick to 2.10 or raise PR for 2.10 test branch on this one?\r\n> \r\n> @ephraimbuddy @utkarsharma2 would like to check are we still be able to include this one?\r\n\r\nIt won't make it to 2.10 except if we have RC2"", 'created_at': datetime.datetime(2024, 8, 12, 13, 54, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284060218, 'issue_id': 2460672949, 'author': 'Lee-W', 'body': 'Got it. Thanks!', 'created_at': datetime.datetime(2024, 8, 12, 13, 55, 37, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-08-12 13:31:25 UTC): @ephraimbuddy @utkarsharma2 would like to check are we still be able to include this one?

ephraimbuddy on (2024-08-12 13:54:14 UTC): It won't make it to 2.10 except if we have RC2

Lee-W (Issue Creator) on (2024-08-12 13:55:37 UTC): Got it. Thanks!

"
2460643892,pull_request,closed,,Add comment on methodtools in mssql provider.yaml,followup on https://github.com/apache/airflow/pull/41392,eladkal,2024-08-12 10:41:53+00:00,[],2024-08-12 12:46:05+00:00,2024-08-12 12:46:02+00:00,https://github.com/apache/airflow/pull/41402,"[('area:providers', ''), ('provider:microsoft-mssql', '')]",[],
2460585184,pull_request,closed,,Drop FAB ForeignKey link to Airflow DB,"This is necessary to separate FAB DB from Airflow Core DB

Depends on https://github.com/apache/airflow/pull/41120. Only review the last commit",ephraimbuddy,2024-08-12 10:15:17+00:00,[],2024-08-20 11:34:13+00:00,2024-08-13 09:33:51+00:00,https://github.com/apache/airflow/pull/41401,"[('area:CLI', ''), ('area:dev-tools', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-79', '')]",[],
2460430884,pull_request,closed,,also try to fetch Tenant Id from extra_dejson.tenantId instead of extâ€¦,"Microsoft graph API operator: try to fetch Tenant Id from extra_dejson.tenantId instead of extra_dejson.tenant_id
fixes https://github.com/apache/airflow/issues/41399 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",w0ut0,2024-08-12 09:05:51+00:00,[],2024-10-23 06:25:29+00:00,2024-10-23 06:25:29+00:00,https://github.com/apache/airflow/pull/41400,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2284283303, 'issue_id': 2460430884, 'author': 'w0ut0', 'body': 'So it seems that the MS Graph operator does not expect an Azure Connection, but rather an HTTP connection, with extra_dejson `tenantId`.\r\nWould it be ok if I do a check on `conn.conn_type`?\r\n```\r\nif conn.conn_type == \'http\':\r\n    tenant_id = config.get(""tenant_id"")\r\nelif conn.conn_type == \'azure\':\r\n    tenant_id = config.get(""tenantId"")\r\n```\r\n\r\nMy use case is that we use the same credentials (service principals) to authenticate the Airflow instance, both to the Azure Resource Manager, as well as to the MS Graph API.\r\n\r\nAlternatively, we can raise an exception if the supplied `conn_id` is of the wrong type? \r\n\r\ncc @dabla', 'created_at': datetime.datetime(2024, 8, 12, 15, 27, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284387706, 'issue_id': 2460430884, 'author': 'dabla', 'body': '> So it seems that the MS Graph operator does not expect an Azure Connection, but rather an HTTP connection, with extra_dejson `tenantId`. Would it be ok if I do a check on `conn.conn_type`?\r\n> \r\n> ```\r\n> if conn.conn_type == \'http\':\r\n>     tenant_id = config.get(""tenant_id"")\r\n> elif conn.conn_type == \'azure\':\r\n>     tenant_id = config.get(""tenantId"")\r\n> ```\r\n> \r\n> My use case is that we use the same credentials (service principals) to authenticate the Airflow instance, both to the Azure Resource Manager, as well as to the MS Graph API.\r\n> \r\n> Alternatively, we can raise an exception if the supplied `conn_id` is of the wrong type?\r\n> \r\n> cc @dabla\r\n\r\nWe could raise an exception once the MSGraph operator would require an Azure connection type, something that would be nice once all parameters vould also be specified in the Azure connection type.  At the moment I would keep the original solution and allow both cases with conn_type check.  Maybe add a unit test which also test the other tenantId case.', 'created_at': datetime.datetime(2024, 8, 12, 16, 14, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331397387, 'issue_id': 2460430884, 'author': 'dabla', 'body': ""@eladkal I think you can close this one, I've added the support in this [PR](https://github.com/apache/airflow/pull/41331)."", 'created_at': datetime.datetime(2024, 9, 5, 12, 25, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2430545098, 'issue_id': 2460430884, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 23, 0, 15, 17, tzinfo=datetime.timezone.utc)}]","w0ut0 (Issue Creator) on (2024-08-12 15:27:13 UTC): So it seems that the MS Graph operator does not expect an Azure Connection, but rather an HTTP connection, with extra_dejson `tenantId`.
Would it be ok if I do a check on `conn.conn_type`?
```
if conn.conn_type == 'http':
    tenant_id = config.get(""tenant_id"")
elif conn.conn_type == 'azure':
    tenant_id = config.get(""tenantId"")
```

My use case is that we use the same credentials (service principals) to authenticate the Airflow instance, both to the Azure Resource Manager, as well as to the MS Graph API.

Alternatively, we can raise an exception if the supplied `conn_id` is of the wrong type? 

cc @dabla

dabla on (2024-08-12 16:14:22 UTC): We could raise an exception once the MSGraph operator would require an Azure connection type, something that would be nice once all parameters vould also be specified in the Azure connection type.  At the moment I would keep the original solution and allow both cases with conn_type check.  Maybe add a unit test which also test the other tenantId case.

dabla on (2024-09-05 12:25:04 UTC): @eladkal I think you can close this one, I've added the support in this [PR](https://github.com/apache/airflow/pull/41331).

github-actions[bot] on (2024-10-23 00:15:17 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2460228192,pull_request,closed,,fix DagPriorityParsingRequest unique constraint error when dataset aliases are resolved into new datasets,"## Why
This happens when dynamic task mapping is used as each task create the exact same `DagPriorityParsingRequest`s.

## What
Follow how dataset queue a DagRun. ignore the conflict trasctions

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-12 07:21:11+00:00,[],2024-08-29 05:13:09+00:00,2024-08-12 09:24:59+00:00,https://github.com/apache/airflow/pull/41398,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2283269327, 'issue_id': 2460228192, 'author': 'Lee-W', 'body': 'will create another PR point to main once merged', 'created_at': datetime.datetime(2024, 8, 12, 7, 23, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283278664, 'issue_id': 2460228192, 'author': 'potiuk', 'body': 'FYI - this one has a lot more commits than intended I think', 'created_at': datetime.datetime(2024, 8, 12, 7, 29, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283281058, 'issue_id': 2460228192, 'author': 'Lee-W', 'body': 'ah yes, I should rebase from `v2-10-test` once. Thanks for reminding me!', 'created_at': datetime.datetime(2024, 8, 12, 7, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283343193, 'issue_id': 2460228192, 'author': 'utkarsharma2', 'body': ""@Lee-W We should raise this PR against the main and once merged, we'll do a cherry-pick to `v2-10-test` branch."", 'created_at': datetime.datetime(2024, 8, 12, 8, 8, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283347960, 'issue_id': 2460228192, 'author': 'Lee-W', 'body': 'Got it. Thanks @utkarsharma2 ! let me change it', 'created_at': datetime.datetime(2024, 8, 12, 8, 10, 56, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-08-12 07:23:25 UTC): will create another PR point to main once merged

potiuk on (2024-08-12 07:29:38 UTC): FYI - this one has a lot more commits than intended I think

Lee-W (Issue Creator) on (2024-08-12 07:31:07 UTC): ah yes, I should rebase from `v2-10-test` once. Thanks for reminding me!

utkarsharma2 on (2024-08-12 08:08:07 UTC): @Lee-W We should raise this PR against the main and once merged, we'll do a cherry-pick to `v2-10-test` branch.

Lee-W (Issue Creator) on (2024-08-12 08:10:56 UTC): Got it. Thanks @utkarsharma2 ! let me change it

"
2460179296,pull_request,closed,,Add config to default schedule to None,"Alternative to #41321. This is easier for 2.10 since all tests would behave the same for now.

We still need to fix those DAGs when we change the default for Airflow 3, but we will have a bit more time (hopefullyâ€¦) for that.",uranusjr,2024-08-12 06:51:54+00:00,[],2024-08-13 23:27:24+00:00,2024-08-13 23:27:24+00:00,https://github.com/apache/airflow/pull/41397,"[('kind:documentation', '')]","[{'comment_id': 2283444090, 'issue_id': 2460179296, 'author': 'uranusjr', 'body': 'Hmm, if the majority opinion is\r\n\r\n1. _Not_ have a config in 3 (unconditionally defaults to None or make the argument explicit)\r\n2. Have a deprecation warning on 2\r\n\r\nMaybe the best avenue would be to do #41321, but simply suppress the warnings in tests for now? That way fixing the DAGs can be delayed to not block 2.10. We just need to remember to do that.', 'created_at': datetime.datetime(2024, 8, 12, 9, 1, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283495449, 'issue_id': 2460179296, 'author': 'potiuk', 'body': ""Why not fixing the dags' now in the other PR ? Looks like about 20 failing cases and addng daily schedule for this dags should be safe and probably same amount of time as warning suppresssion"", 'created_at': datetime.datetime(2024, 8, 12, 9, 28, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284672048, 'issue_id': 2460179296, 'author': 'jscheffl', 'body': 'Thanks @uranusjr for the alternative proposal! This opens the door to ""not deed"" to make schedule argument as required as original PR and not needing to change default. I think this is a very good idea.\r\n\r\nI very much dislike (today) that there is a default schedule which is not matching 95% of (my) use cases. Actually a schedule of `None` would be very much reasonable for all defaults but of course coming from legacy this would be a breaking change.\r\n\r\nMain challenge that I see is:\r\n- This might need a bit of discussion and as 2.10 is almost closing to be completed I don\'t know if we can have a vote before release. I would be +1 for the change\r\n- Small feedback: Config setting is made with ""negative phrases"", maybe it would yield a bit better if working of config param is reversed/negated?', 'created_at': datetime.datetime(2024, 8, 12, 18, 36, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285492985, 'issue_id': 2460179296, 'author': 'uranusjr', 'body': 'We have a schedule to follow (no pun intended) for 2.10 and fixing the DAGs do take some time. Iâ€™ve made the easy fixes in the other PR, but the rest are not as straightfoward (finding the offending DAG/s is more work than I anticipated). I would prefer to defer the work so we have a stable 2.10 code base for testing sooner.', 'created_at': datetime.datetime(2024, 8, 13, 7, 3, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285497533, 'issue_id': 2460179296, 'author': 'uranusjr', 'body': '> Config setting is made with ""negative phrases"", maybe it would yield a bit better if working of config param is reversed/negated?\r\n\r\nThe idea is to make the config toggle â€œsetting the default schedule to Noneâ€ (positive action), not â€œnot setting a default scheduleâ€ (negative action), but I can see the wording being confusing. What is a positive action alternative you have in mind?', 'created_at': datetime.datetime(2024, 8, 13, 7, 5, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286692509, 'issue_id': 2460179296, 'author': 'jscheffl', 'body': '> > Config setting is made with ""negative phrases"", maybe it would yield a bit better if working of config param is reversed/negated?\r\n> \r\n> The idea is to make the config toggle â€œsetting the default schedule to Noneâ€ (positive action), not â€œnot setting a default scheduleâ€ (negative action), but I can see the wording being confusing. What is a positive action alternative you have in mind?\r\n\r\nYeah, you are right. Was feeling like ""none schedule"" feels negative. But actually it is not. Anyway it feels double negated. So if you inverse it would be `default_daily_schedule=True` which you could set to false such that the default schedule is none. Or even it could be made that you make the config like `default_schedule=0 0 * * *` and then you even have more options than True/False, like empty-string or ""None"" renders to None.', 'created_at': datetime.datetime(2024, 8, 13, 16, 49, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287023261, 'issue_id': 2460179296, 'author': 'uranusjr', 'body': 'The problem with `default_schedule=0 0 * * *` is I donâ€™t really want to spend time on additional parsing for `timedelta(days=1)` (the current default and must be supported), something that almost no people need in the first place.\r\n\r\n`default_daily_schedule` sounds fine to me.\r\n\r\nWhat do you think about the strategy though @eladkal @potiuk? As I mentioned, fixing the tests for 2.10 is not really viable, so if we want to emit a deprecation warning, the best way is to ignore it in configs and fix them later. And do you feel strongly the config should or should not exist in 3.0?', 'created_at': datetime.datetime(2024, 8, 13, 19, 58, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287110846, 'issue_id': 2460179296, 'author': 'potiuk', 'body': ""> fixing the tests for 2.10 is not really viable,\r\n\r\nI think it is - by a quick look it's really few fixtures in conftest that create those warnings in https://github.com/apache/airflow/pull/41321.  (new_dag_to_delete, create_dag etc. )  - and they really **should** be fixed as part of this change"", 'created_at': datetime.datetime(2024, 8, 13, 20, 47, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287119005, 'issue_id': 2460179296, 'author': 'potiuk', 'body': 'Plus few places in the test_views', 'created_at': datetime.datetime(2024, 8, 13, 20, 53, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287121825, 'issue_id': 2460179296, 'author': 'uranusjr', 'body': 'Err, if you insistâ€¦ feel free to try, I guess?', 'created_at': datetime.datetime(2024, 8, 13, 20, 55, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287148179, 'issue_id': 2460179296, 'author': 'potiuk', 'body': 'Sure I did it right away https://github.com/astronomer/airflow/pull/1512', 'created_at': datetime.datetime(2024, 8, 13, 21, 13, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287150267, 'issue_id': 2460179296, 'author': 'potiuk', 'body': 'I think ""let\'s remember to do it some time later"" is often more problematic and error prone than ""do it now"". ""Buy time"" might often mean ""we will loose even more time in the future when we forget to do it""', 'created_at': datetime.datetime(2024, 8, 13, 21, 14, 56, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-08-12 09:01:55 UTC): Hmm, if the majority opinion is

1. _Not_ have a config in 3 (unconditionally defaults to None or make the argument explicit)
2. Have a deprecation warning on 2

Maybe the best avenue would be to do #41321, but simply suppress the warnings in tests for now? That way fixing the DAGs can be delayed to not block 2.10. We just need to remember to do that.

potiuk on (2024-08-12 09:28:42 UTC): Why not fixing the dags' now in the other PR ? Looks like about 20 failing cases and addng daily schedule for this dags should be safe and probably same amount of time as warning suppresssion

jscheffl on (2024-08-12 18:36:47 UTC): Thanks @uranusjr for the alternative proposal! This opens the door to ""not deed"" to make schedule argument as required as original PR and not needing to change default. I think this is a very good idea.

I very much dislike (today) that there is a default schedule which is not matching 95% of (my) use cases. Actually a schedule of `None` would be very much reasonable for all defaults but of course coming from legacy this would be a breaking change.

Main challenge that I see is:
- This might need a bit of discussion and as 2.10 is almost closing to be completed I don't know if we can have a vote before release. I would be +1 for the change
- Small feedback: Config setting is made with ""negative phrases"", maybe it would yield a bit better if working of config param is reversed/negated?

uranusjr (Issue Creator) on (2024-08-13 07:03:12 UTC): We have a schedule to follow (no pun intended) for 2.10 and fixing the DAGs do take some time. Iâ€™ve made the easy fixes in the other PR, but the rest are not as straightfoward (finding the offending DAG/s is more work than I anticipated). I would prefer to defer the work so we have a stable 2.10 code base for testing sooner.

uranusjr (Issue Creator) on (2024-08-13 07:05:23 UTC): The idea is to make the config toggle â€œsetting the default schedule to Noneâ€ (positive action), not â€œnot setting a default scheduleâ€ (negative action), but I can see the wording being confusing. What is a positive action alternative you have in mind?

jscheffl on (2024-08-13 16:49:46 UTC): Yeah, you are right. Was feeling like ""none schedule"" feels negative. But actually it is not. Anyway it feels double negated. So if you inverse it would be `default_daily_schedule=True` which you could set to false such that the default schedule is none. Or even it could be made that you make the config like `default_schedule=0 0 * * *` and then you even have more options than True/False, like empty-string or ""None"" renders to None.

uranusjr (Issue Creator) on (2024-08-13 19:58:02 UTC): The problem with `default_schedule=0 0 * * *` is I donâ€™t really want to spend time on additional parsing for `timedelta(days=1)` (the current default and must be supported), something that almost no people need in the first place.

`default_daily_schedule` sounds fine to me.

What do you think about the strategy though @eladkal @potiuk? As I mentioned, fixing the tests for 2.10 is not really viable, so if we want to emit a deprecation warning, the best way is to ignore it in configs and fix them later. And do you feel strongly the config should or should not exist in 3.0?

potiuk on (2024-08-13 20:47:38 UTC): I think it is - by a quick look it's really few fixtures in conftest that create those warnings in https://github.com/apache/airflow/pull/41321.  (new_dag_to_delete, create_dag etc. )  - and they really **should** be fixed as part of this change

potiuk on (2024-08-13 20:53:06 UTC): Plus few places in the test_views

uranusjr (Issue Creator) on (2024-08-13 20:55:07 UTC): Err, if you insistâ€¦ feel free to try, I guess?

potiuk on (2024-08-13 21:13:24 UTC): Sure I did it right away https://github.com/astronomer/airflow/pull/1512

potiuk on (2024-08-13 21:14:56 UTC): I think ""let's remember to do it some time later"" is often more problematic and error prone than ""do it now"". ""Buy time"" might often mean ""we will loose even more time in the future when we forget to do it""

"
2460084139,pull_request,closed,,Bump minimum Airflow version in providers to Airflow 2.8.0,Note: the changelog entry about version bump will be updated during release time,eladkal,2024-08-12 05:40:11+00:00,[],2024-08-12 15:29:39+00:00,2024-08-12 15:29:36+00:00,https://github.com/apache/airflow/pull/41396,"[('area:providers', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:apache-kafka', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-beam', ''), ('provider:apache-livy', ''), ('provider:apache-drill', ''), ('provider:apache-cassandra', ''), ('provider:apache-flink', ''), ('provider:apache-hdfs', ''), ('provider:apache-kylin', ''), ('provider:apache-impala', ''), ('provider:apache-iceberg', '')]",[],
2459866685,pull_request,closed,,Remove deprecations from `airflow.executors` & `airflow.utils`,"Remove deprecated features in preparation for Airflow 3.0

- Removed `UNPICKLEABLE_EXECUTORS` from `airflow.executors.executor_loader`.
- Removed `test_cycle` function from `airflow.utils.dag_cycle_tester`.
- Removed `TemporaryDirectory` function from `airflow.utils.file`.
- Removed `mkdirs` function from `airflow.utils.file`.
- Removed `SHUTDOWN` state and `terminating_states` constant from `airflow.utils.state`.

These deprecated features were previously marked for removal and are no longer needed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-08-12 01:15:53+00:00,[],2024-08-12 10:34:06+00:00,2024-08-12 10:34:04+00:00,https://github.com/apache/airflow/pull/41395,"[('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2459840562,pull_request,closed,,Remove deprecated ``TaskMixin`` class,"The ``airflow.models.taskMixin.TaskMixin`` class has been removed. It was previously deprecated in favor of the ``airflow.models.taskMixin.DependencyMixin`` class.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-08-12 00:34:26+00:00,[],2024-08-12 02:31:18+00:00,2024-08-12 02:31:16+00:00,https://github.com/apache/airflow/pull/41394,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2282993695, 'issue_id': 2459840562, 'author': 'kaxil', 'body': '> If TaskMixin is removed, should we update the comments in\r\n> \r\n> https://github.com/apache/airflow/blob/aa047d7b46c2a466b7c981f34e690347e5aa3ff1/airflow/models/xcom_arg.py#L138\r\n> \r\n> as well?\r\n\r\nDone', 'created_at': datetime.datetime(2024, 8, 12, 1, 51, 26, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-08-12 01:51:26 UTC): Done

"
2459835658,pull_request,closed,,Remove deprecated param in `DayOfWeekSensor`,"The `use_task_execution_day` param is deprecated

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-08-12 00:26:54+00:00,[],2024-08-12 01:16:16+00:00,2024-08-12 01:16:14+00:00,https://github.com/apache/airflow/pull/41393,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2459828706,pull_request,closed,,Add methodtools as dependency to mssql provider,"Fixes: #41330

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-12 00:16:27+00:00,[],2024-08-12 00:27:45+00:00,2024-08-12 00:27:43+00:00,https://github.com/apache/airflow/pull/41392,"[('area:providers', ''), ('provider:microsoft-mssql', '')]",[],
2459824645,pull_request,closed,,Remove deprecated `ExternalTaskSensorLink`,"It is replaced by `airflow.sensors.external_task.ExternalDagLink`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-08-12 00:10:00+00:00,[],2024-08-12 01:46:16+00:00,2024-08-12 01:46:15+00:00,https://github.com/apache/airflow/pull/41391,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2282938360, 'issue_id': 2459824645, 'author': 'kaxil', 'body': '@uranusjr / @Lee-W  -- These are the kind of things I think we can easily automate using Migration tool for users since those are just import changes', 'created_at': datetime.datetime(2024, 8, 12, 0, 10, 42, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-08-12 00:10:42 UTC): @uranusjr / @Lee-W  -- These are the kind of things I think we can easily automate using Migration tool for users since those are just import changes

"
2459814195,pull_request,closed,,Remove deprecated SubDags,"This PR removes SubDags in favor of TaskGroups fro Airflow 3.0

Subdags have been removed from the following locations:

- CLI
- API
- ``SubDagOperator``

This removal marks the end of Subdag support across all interfaces. Users should transition to using TaskGroups as a more efficient and maintainable alternative.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-08-11 23:45:38+00:00,[],2024-09-02 20:12:51+00:00,2024-08-13 20:34:24+00:00,https://github.com/apache/airflow/pull/41390,"[('provider:google', 'Google (including GCP) related issues'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:celery', ''), ('provider:fab', ''), ('area:db-migrations', 'PRs with DB migration'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2283658897, 'issue_id': 2459814195, 'author': 'eladkal', 'body': 'We also have the UI part of Subdag (The zoom in button)\r\n\r\nhttps://github.com/apache/airflow/blob/1074b8eed680af9668f11c63cf28e72db5470fde/airflow/www/static/js/dag/details/taskInstance/Nav.tsx#L70-L85', 'created_at': datetime.datetime(2024, 8, 12, 10, 57, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286202866, 'issue_id': 2459814195, 'author': 'kaxil', 'body': '> Concerning the root_dag_id, I guess `security/permissions.py` should also be updated but then, I think Airflow 3 might no longer be compatible with current providers.\r\n\r\nYeah, that is mainly to be handled on the Auth provider implementation rather than core Airflow so it works for Airflow 2 & Airflow 3', 'created_at': datetime.datetime(2024, 8, 13, 12, 57, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286361006, 'issue_id': 2459814195, 'author': 'kaxil', 'body': ""> We'll also need to remove docs/apache-airflow/img/subdag_after.png , docs/apache-airflow/img/subdag_before.png and docs/apache-airflow/img/subdag_zoom.png\r\n\r\nDone, removed"", 'created_at': datetime.datetime(2024, 8, 13, 14, 11, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286702630, 'issue_id': 2459814195, 'author': 'jscheffl', 'body': 'Oh, in numer of LoC removed as PR this is a high chance to get PR of the month :-D', 'created_at': datetime.datetime(2024, 8, 13, 16, 55, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287097771, 'issue_id': 2459814195, 'author': 'potiuk', 'body': 'BTW. One more comment https://github.com/apache/airflow/issues/21867 -> I believe retry for failed task group is the only serious missing feature for Task Groups comparing to SubDags. \r\n\r\nRetry for Task Groups: https://github.com/apache/airflow/issues/21867\r\n\r\nWe should likely consider implementing it.', 'created_at': datetime.datetime(2024, 8, 13, 20, 38, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287112187, 'issue_id': 2459814195, 'author': 'kaxil', 'body': '> BTW. One more comment https://github.com/apache/airflow/issues/21867 -> I believe retry for failed task group is the only serious missing feature for Task Groups comparing to SubDags. \n> \n> \n> \n> Retry for Task Groups: https://github.com/apache/airflow/issues/21867\n> \n> \n> \n> We should likely consider implementing it.\n\nYup, added a label to that issue to track it', 'created_at': datetime.datetime(2024, 8, 13, 20, 48, 34, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-12 10:57:21 UTC): We also have the UI part of Subdag (The zoom in button)

https://github.com/apache/airflow/blob/1074b8eed680af9668f11c63cf28e72db5470fde/airflow/www/static/js/dag/details/taskInstance/Nav.tsx#L70-L85

kaxil (Issue Creator) on (2024-08-13 12:57:52 UTC): Yeah, that is mainly to be handled on the Auth provider implementation rather than core Airflow so it works for Airflow 2 & Airflow 3

kaxil (Issue Creator) on (2024-08-13 14:11:11 UTC): Done, removed

jscheffl on (2024-08-13 16:55:23 UTC): Oh, in numer of LoC removed as PR this is a high chance to get PR of the month :-D

potiuk on (2024-08-13 20:38:41 UTC): BTW. One more comment https://github.com/apache/airflow/issues/21867 -> I believe retry for failed task group is the only serious missing feature for Task Groups comparing to SubDags. 

Retry for Task Groups: https://github.com/apache/airflow/issues/21867

We should likely consider implementing it.

kaxil (Issue Creator) on (2024-08-13 20:48:34 UTC): Yup, added a label to that issue to track it

"
2459795367,pull_request,closed,,Simpler task retrieval for taskinstance test,"The test has been updated for DB isolation but the retrieval of task was not intuitive and it could lead to flaky tests possibly

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-11 22:50:52+00:00,[],2024-09-17 11:09:11+00:00,2024-08-12 06:42:49+00:00,https://github.com/apache/airflow/pull/41389,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2459775070,pull_request,closed,,Fix  tests/decorators/test_python.py for database isolation tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: https://github.com/apache/airflow/pull/41067
Fixes `tests/decorators/test_python.py` for database isolation. Passing `serialized` parameter to dag_maker


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-11 21:47:12+00:00,[],2024-08-11 23:11:51+00:00,2024-08-11 23:10:55+00:00,https://github.com/apache/airflow/pull/41387,[],"[{'comment_id': 2282907095, 'issue_id': 2459775070, 'author': 'potiuk', 'body': 'Some tests are failing - same as in the #41067 PR :(', 'created_at': datetime.datetime(2024, 8, 11, 22, 19, 7, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-11 22:19:07 UTC): Some tests are failing - same as in the #41067 PR :(

"
2459766185,pull_request,closed,,Fix mypy checks for new azure libraries,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-11 21:20:19+00:00,[],2024-08-11 22:12:22+00:00,2024-08-11 21:36:19+00:00,https://github.com/apache/airflow/pull/41386,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('upgrade to newer dependencies', 'If set, upgrade to newer dependencies is forced')]",[],
2459763164,pull_request,closed,,Skip docs publishing on non-main branches,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-11 21:11:30+00:00,[],2024-08-11 22:12:31+00:00,2024-08-11 21:20:39+00:00,https://github.com/apache/airflow/pull/41385,"[('area:dev-tools', '')]","[{'comment_id': 2282891135, 'issue_id': 2459763164, 'author': 'potiuk', 'body': 'Better fix for the temporary one added to v2-10-test.', 'created_at': datetime.datetime(2024, 8, 11, 21, 11, 56, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-11 21:11:56 UTC): Better fix for the temporary one added to v2-10-test.

"
2459735873,pull_request,closed,,Better map_index and downstream/upstream tasks handling,"- Fixes ""Clearing a Mapped Task (with Downstream included) clears all Downstream tasks instead of mapped downstream tasks #41278""
- Fixes ""control state of individual taskflow in mapped task-group #40543""

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-08-11 19:46:53+00:00,[],2024-10-31 00:15:30+00:00,2024-10-31 00:15:30+00:00,https://github.com/apache/airflow/pull/41384,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:webserver', 'Webserver related Issues')]","[{'comment_id': 2285650554, 'issue_id': 2459735873, 'author': 'uranusjr', 'body': 'Tests are failing', 'created_at': datetime.datetime(2024, 8, 13, 8, 20, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285786429, 'issue_id': 2459735873, 'author': 'harjeevanmaan', 'body': '@uranusjr Working on it', 'created_at': datetime.datetime(2024, 8, 13, 9, 26, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2286761387, 'issue_id': 2459735873, 'author': 'harjeevanmaan', 'body': 'All unit tests passed. Working on the static checks now.', 'created_at': datetime.datetime(2024, 8, 13, 17, 27, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288994355, 'issue_id': 2459735873, 'author': 'harjeevanmaan', 'body': ""I've committed changes to fix the static-check failures. I would appreciate any feedback or review."", 'created_at': datetime.datetime(2024, 8, 14, 14, 42, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2433857547, 'issue_id': 2459735873, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 24, 0, 15, 16, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-13 08:20:40 UTC): Tests are failing

harjeevanmaan (Issue Creator) on (2024-08-13 09:26:01 UTC): @uranusjr Working on it

harjeevanmaan (Issue Creator) on (2024-08-13 17:27:54 UTC): All unit tests passed. Working on the static checks now.

harjeevanmaan (Issue Creator) on (2024-08-14 14:42:52 UTC): I've committed changes to fix the static-check failures. I would appreciate any feedback or review.

github-actions[bot] on (2024-10-24 00:15:16 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2459732779,pull_request,closed,,Limit parallelism for constraints generation in CI,"Apparently constraints generation in 4 parallel docker containers causes ""no space left on device"" error for public runners. This one limits parallelism to 3 to limit disk usage

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-11 19:37:41+00:00,[],2024-08-12 00:20:05+00:00,2024-08-12 00:20:05+00:00,https://github.com/apache/airflow/pull/41383,"[('area:dev-tools', ''), ('upgrade to newer dependencies', 'If set, upgrade to newer dependencies is forced'), ('canary', 'When set on PR running from apache repo - behave as canary run'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2282866994, 'issue_id': 2459732779, 'author': 'potiuk', 'body': 'Example error here (in main - likely will affect v2-10-test/stble as well):\r\n\r\nhttps://github.com/apache/airflow/actions/runs/10340160246/job/28620494570#step:10:5663\r\n\r\n\r\n```\r\n  src/krb5/_ccache.c:37124:1: fatal error: error writing to /tmp/ccGVRTgE.s: No space left on device\r\n```', 'created_at': datetime.datetime(2024, 8, 11, 19, 39, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282893530, 'issue_id': 2459732779, 'author': 'potiuk', 'body': 'Extracted the MyPy fixes to https://github.com/apache/airflow/pull/41386', 'created_at': datetime.datetime(2024, 8, 11, 21, 21, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282930542, 'issue_id': 2459732779, 'author': 'potiuk', 'body': 'Looks like it works and should bring back main to be `green`', 'created_at': datetime.datetime(2024, 8, 11, 23, 51, 8, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-11 19:39:22 UTC): Example error here (in main - likely will affect v2-10-test/stble as well):

https://github.com/apache/airflow/actions/runs/10340160246/job/28620494570#step:10:5663


```
  src/krb5/_ccache.c:37124:1: fatal error: error writing to /tmp/ccGVRTgE.s: No space left on device
```

potiuk (Issue Creator) on (2024-08-11 21:21:07 UTC): Extracted the MyPy fixes to https://github.com/apache/airflow/pull/41386

potiuk (Issue Creator) on (2024-08-11 23:51:08 UTC): Looks like it works and should bring back main to be `green`

"
2459495918,pull_request,closed,,"Retain the function ""resource_name_for_dag"" for backwards compatibility","When using older FAB providers on the new airflow, this function is called in the old provider and is no longer available in the new airflow. This PR brings this back to fix issue in main and v2-10-test branch where all DAGs fail because of lack of this function

Alternative to https://github.com/apache/airflow/pull/41379",ephraimbuddy,2024-08-11 08:55:46+00:00,[],2024-08-12 01:46:28+00:00,2024-08-11 13:23:33+00:00,https://github.com/apache/airflow/pull/41382,"[('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2282697381, 'issue_id': 2459495918, 'author': 'ephraimbuddy', 'body': 'Error in sync PR: https://github.com/apache/airflow/actions/runs/10338227507/job/28616625788?pr=41280#step:9:1258', 'created_at': datetime.datetime(2024, 8, 11, 9, 40, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282990623, 'issue_id': 2459495918, 'author': 'joaopamaral', 'body': 'Thanks @ephraimbuddy!!', 'created_at': datetime.datetime(2024, 8, 12, 1, 46, 28, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-08-11 09:40:05 UTC): Error in sync PR: https://github.com/apache/airflow/actions/runs/10338227507/job/28616625788?pr=41280#step:9:1258

joaopamaral on (2024-08-12 01:46:28 UTC): Thanks @ephraimbuddy!!

"
2459475776,pull_request,closed,,Typo docstring eks trigger in aws provider,"during #41380, i found wrong docstring for trigger class.",jx2lee,2024-08-11 08:00:55+00:00,[],2024-08-11 11:53:51+00:00,2024-08-11 11:53:50+00:00,https://github.com/apache/airflow/pull/41381,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2459472235,pull_request,closed,,Enable EksPodOperator when deferrable is true,(TBD) closes: https://github.com/apache/airflow/issues/39685,jx2lee,2024-08-11 07:50:07+00:00,[],2024-10-31 00:15:32+00:00,2024-10-31 00:15:32+00:00,https://github.com/apache/airflow/pull/41380,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2282661724, 'issue_id': 2459472235, 'author': 'jx2lee', 'body': '#41377 was closed because branch was renamed', 'created_at': datetime.datetime(2024, 8, 11, 7, 54, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2299197837, 'issue_id': 2459472235, 'author': 'o-nikolas', 'body': 'I was under the impression this was already fixed by #41178 and the deferrable logic was inherited through the k8s pod operator itself. Were you testing with an older version of the provider packages?', 'created_at': datetime.datetime(2024, 8, 20, 15, 56, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307363389, 'issue_id': 2459472235, 'author': 'jx2lee', 'body': ""@o-nikolas you're right.\r\n- Deferrable logic was inherited throught the k8s pod operator. ([execute](https://github.com/apache/airflow/blob/c0ffa9c5d96625c68ded9562632674ed366b5eb3/airflow/providers/amazon/aws/operators/eks.py#L1075) in eks.py EksPodOperator)\r\n- It seems that issue in this PR was resolved by the fix in [#41178](https://github.com/apache/airflow/pull/41178) . The direction to address the issue was incorrect. I have two options: either close the issue or update the relevant test code in [#39685](https://github.com/apache/airflow/issues/39685). What do you think?"", 'created_at': datetime.datetime(2024, 8, 23, 15, 52, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2307471516, 'issue_id': 2459472235, 'author': 'o-nikolas', 'body': ""> @o-nikolas you're right.\r\n> \r\n>     * Deferrable logic was inherited through the k8s pod operator. ([execute](https://github.com/apache/airflow/blob/c0ffa9c5d96625c68ded9562632674ed366b5eb3/airflow/providers/amazon/aws/operators/eks.py#L1075) in eks.py EksPodOperator)\r\n> \r\n>     * It seems that issue in this PR was resolved by the fix in [#41178](https://github.com/apache/airflow/pull/41178) . The direction to address the issue was incorrect. I have two options: either close the issue or update the relevant test code in [#39685](https://github.com/apache/airflow/issues/39685). What do you think?\r\n\r\nIn particular reference to this:\r\n> I have two options: either close the issue or update the relevant test code in [#39685](https://github.com/apache/airflow/issues/39685). What do you think?\r\n \r\n What exactly is still broken? Can you describe that more, it would help me provide further direction. Thanks for sticking with this!"", 'created_at': datetime.datetime(2024, 8, 23, 16, 59, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331805027, 'issue_id': 2459472235, 'author': 'jx2lee', 'body': 'Sorry for late reply! ðŸ¥²\r\n\r\n> What exactly is still broken? Can you describe that more, it would help me provide further direction. Thanks for sticking with this!\r\n\r\nThe issue is no longer reproducible. `EksPodOperator` created with the `deferrable` parameter runs without any problems. Initially, I thought issue was due to it not being deferrable, but that was my mistake.\r\n\r\n- Error in [#39695](https://github.com/apache/airflow/issues/39685) is not reproducible in commits prior to [#41178](https://github.com/apache/airflow/pull/41178).\r\n- Since this PR inherits from the `PodOperator` and modifies it to a deferrable mode, the approach is incorrect. Deferrable tests work fine in commits prior to #41178.\r\n\r\n\r\nand, look at full logs in Anything else [#39695](https://github.com/apache/airflow/issues/39685)\r\n`kubernetes.config.config_exception.ConfigException: Invalid kube-config file. No configuration found.` often occurred. i think that kube config file in created pod was broken, because It could be related to network issue or others. I donâ€™t think fix in #41178 resolved #39695.\r\n-> Please let me know if Iâ€™m mistaken.\r\n\r\nIâ€™d like to dig deeper into the problem and request more information from the reporter (such as the full log when `deferrable=False`, etc).', 'created_at': datetime.datetime(2024, 9, 5, 14, 16, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2430545118, 'issue_id': 2459472235, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 23, 0, 15, 18, tzinfo=datetime.timezone.utc)}]","jx2lee (Issue Creator) on (2024-08-11 07:54:43 UTC): #41377 was closed because branch was renamed

o-nikolas on (2024-08-20 15:56:45 UTC): I was under the impression this was already fixed by #41178 and the deferrable logic was inherited through the k8s pod operator itself. Were you testing with an older version of the provider packages?

jx2lee (Issue Creator) on (2024-08-23 15:52:48 UTC): @o-nikolas you're right.
- Deferrable logic was inherited throught the k8s pod operator. ([execute](https://github.com/apache/airflow/blob/c0ffa9c5d96625c68ded9562632674ed366b5eb3/airflow/providers/amazon/aws/operators/eks.py#L1075) in eks.py EksPodOperator)
- It seems that issue in this PR was resolved by the fix in [#41178](https://github.com/apache/airflow/pull/41178) . The direction to address the issue was incorrect. I have two options: either close the issue or update the relevant test code in [#39685](https://github.com/apache/airflow/issues/39685). What do you think?

o-nikolas on (2024-08-23 16:59:19 UTC): In particular reference to this:
 
 What exactly is still broken? Can you describe that more, it would help me provide further direction. Thanks for sticking with this!

jx2lee (Issue Creator) on (2024-09-05 14:16:48 UTC): Sorry for late reply! ðŸ¥²


The issue is no longer reproducible. `EksPodOperator` created with the `deferrable` parameter runs without any problems. Initially, I thought issue was due to it not being deferrable, but that was my mistake.

- Error in [#39695](https://github.com/apache/airflow/issues/39685) is not reproducible in commits prior to [#41178](https://github.com/apache/airflow/pull/41178).
- Since this PR inherits from the `PodOperator` and modifies it to a deferrable mode, the approach is incorrect. Deferrable tests work fine in commits prior to #41178.


and, look at full logs in Anything else [#39695](https://github.com/apache/airflow/issues/39685)
`kubernetes.config.config_exception.ConfigException: Invalid kube-config file. No configuration found.` often occurred. i think that kube config file in created pod was broken, because It could be related to network issue or others. I donâ€™t think fix in #41178 resolved #39695.
-> Please let me know if Iâ€™m mistaken.

Iâ€™d like to dig deeper into the problem and request more information from the reporter (such as the full log when `deferrable=False`, etc).

github-actions[bot] on (2024-10-23 00:15:18 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2459461637,pull_request,closed,,"Revert ""Feature: Allow set Dag Run resource into Dag Level permission (#40703)""","This reverts commit 090607d92a7995c75b9d25f5324d11a3dae683ce.

This PR did not handle backward compatibility on the `permissions.resource_name_for_dag` rename and was difficult to debug. It has stalled the 2.10.0 RC release. 
",ephraimbuddy,2024-08-11 07:15:31+00:00,[],2024-08-11 13:24:12+00:00,2024-08-11 13:24:12+00:00,https://github.com/apache/airflow/pull/41379,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:fab', '')]","[{'comment_id': 2282652599, 'issue_id': 2459461637, 'author': 'ephraimbuddy', 'body': '{\\\'/opt/airflow/dags/example_sensors.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  \r\nFile ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    \r\ndag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\',\\\'/opt/airflow/dags/example_skip_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_trigger_target_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/tutorial_taskflow_api_virtualenv.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_subdag_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_branch_python_dop_operator_3.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_passing_params_via_test_command.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_nested_branch_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_complex.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_branch_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_latest_only.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_dag_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_params_ui_tutorial.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_bash_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/tutorial_taskflow_api.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_task_group_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_branch_day_of_week_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_latest_only_with_trigger.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_trigger_controller_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_sla_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_dynamic_task_mapping_with_no_taskflow_operators.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_outlet_event_extra.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_time_delta_sensor_async.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_external_task_marker_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_sensor_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_workday_timetable.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 603, in serialize_to_json\\\\n    serialized_object[key] = encode_timetable(value)\\\\n                             ^^^^^^^^^^^^^^^^^^^^^^^\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 313, in encode_timetable\\\\n    raise _TimetableNotRegistered(importable_string)\\\\nairflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class \\\\\\\'airflow.example_dags.plugins.workday.AfterWorkdayTimetable\\\\\\\' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.\\\\n\\\\nDuring handling of the above exception, another exception occurred:\\\\n\\\\nTraceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 1747, in to_dict\\\\n    json_dict = {""__version"": cls.SERIALIZER_VERSION, ""dag"": cls.serialize_dag(var)}\\\\n                                                             ^^^^^^^^^^^^^^^^^^^^^^\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 1656, in serialize_dag\\\\n    raise SerializationError(f""Failed to serialize DAG {dag.dag_id!r}: {e}"")\\\\nairflow.exceptions.SerializationError: Failed to serialize DAG \\\\\\\'example_workday_timetable\\\\\\\': Timetable class \\\\\\\'airflow.example_dags.plugins.workday.AfterWorkdayTimetable\\\\\\\' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.\\\\n\\\', \\\'/opt/airflow/dags/example_inlet_event_extra.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_bash_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_branch_datetime_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_python_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_local_kubernetes_executor.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_short_circuit_operator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_display_name.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_dataset_alias.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/tutorial_objectstorage.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_setup_teardown.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_datasets.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_task_group.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/tutorial.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_xcomargs.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_short_circuit_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/tutorial_dag.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_setup_teardown_taskflow.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_xcom.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_params_trigger_ui.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_kubernetes_executor.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_dynamic_task_mapping.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_python_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_branch_labels.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_branch_operator_decorator.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\', \\\'/opt/airflow/dags/example_dataset_alias_with_no_taskflow.py\\\': \\\'Traceback (most recent call last):\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\\\nAttributeError: module \\\\\\\'airflow.security.permissions\\\\\\\' has no attribute \\\\\\\'resource_name_for_dag\\\\\\\'\\\\n\\\'}', 'created_at': datetime.datetime(2024, 8, 11, 7, 16, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282652984, 'issue_id': 2459461637, 'author': 'ephraimbuddy', 'body': 'cc @joaopamaral', 'created_at': datetime.datetime(2024, 8, 11, 7, 18, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282697788, 'issue_id': 2459461637, 'author': 'ephraimbuddy', 'body': 'The error link: Error in sync PR: https://github.com/apache/airflow/actions/runs/10338227507/job/28616625788?pr=41280#step:9:1258', 'created_at': datetime.datetime(2024, 8, 11, 9, 41, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282747580, 'issue_id': 2459461637, 'author': 'ephraimbuddy', 'body': 'Alternate PR: https://github.com/apache/airflow/pull/41382', 'created_at': datetime.datetime(2024, 8, 11, 12, 39, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282760502, 'issue_id': 2459461637, 'author': 'ephraimbuddy', 'body': 'closing in favour of the alternative', 'created_at': datetime.datetime(2024, 8, 11, 13, 24, 12, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-08-11 07:16:32 UTC): {\'/opt/airflow/dags/example_sensors.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  
File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    
dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\',\'/opt/airflow/dags/example_skip_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_trigger_target_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/tutorial_taskflow_api_virtualenv.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_subdag_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_branch_python_dop_operator_3.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_passing_params_via_test_command.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_nested_branch_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_complex.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_branch_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_latest_only.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_dag_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_params_ui_tutorial.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_bash_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/tutorial_taskflow_api.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_task_group_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_branch_day_of_week_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_latest_only_with_trigger.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_trigger_controller_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_sla_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_dynamic_task_mapping_with_no_taskflow_operators.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_outlet_event_extra.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_time_delta_sensor_async.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_external_task_marker_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_sensor_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_workday_timetable.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 603, in serialize_to_json\\n    serialized_object[key] = encode_timetable(value)\\n                             ^^^^^^^^^^^^^^^^^^^^^^^\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 313, in encode_timetable\\n    raise _TimetableNotRegistered(importable_string)\\nairflow.serialization.serialized_objects._TimetableNotRegistered: Timetable class \\\'airflow.example_dags.plugins.workday.AfterWorkdayTimetable\\\' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.\\n\\nDuring handling of the above exception, another exception occurred:\\n\\nTraceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 1747, in to_dict\\n    json_dict = {""__version"": cls.SERIALIZER_VERSION, ""dag"": cls.serialize_dag(var)}\\n                                                             ^^^^^^^^^^^^^^^^^^^^^^\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/serialization/serialized_objects.py"", line 1656, in serialize_dag\\n    raise SerializationError(f""Failed to serialize DAG {dag.dag_id!r}: {e}"")\\nairflow.exceptions.SerializationError: Failed to serialize DAG \\\'example_workday_timetable\\\': Timetable class \\\'airflow.example_dags.plugins.workday.AfterWorkdayTimetable\\\' is not registered or you have a top level database access that disrupted the session. Please check the airflow best practices documentation.\\n\', \'/opt/airflow/dags/example_inlet_event_extra.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_bash_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_branch_datetime_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_python_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_local_kubernetes_executor.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_short_circuit_operator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_display_name.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_dataset_alias.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/tutorial_objectstorage.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_setup_teardown.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_datasets.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_task_group.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/tutorial.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_xcomargs.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_short_circuit_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/tutorial_dag.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_setup_teardown_taskflow.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_xcom.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_params_trigger_ui.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_kubernetes_executor.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_dynamic_task_mapping.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_python_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_branch_labels.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_branch_operator_decorator.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\', \'/opt/airflow/dags/example_dataset_alias_with_no_taskflow.py\': \'Traceback (most recent call last):\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py"", line 748, in _sync_perm_for_dag\\n    security_manager.sync_perm_for_dag(root_dag_id, dag.access_control)\\n  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/fab/auth_manager/security_manager/override.py"", line 1109, in sync_perm_for_dag\\n    dag_resource_name = permissions.resource_name_for_dag(dag_id)\\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\nAttributeError: module \\\'airflow.security.permissions\\\' has no attribute \\\'resource_name_for_dag\\\'\\n\'}

ephraimbuddy (Issue Creator) on (2024-08-11 07:18:15 UTC): cc @joaopamaral

ephraimbuddy (Issue Creator) on (2024-08-11 09:41:32 UTC): The error link: Error in sync PR: https://github.com/apache/airflow/actions/runs/10338227507/job/28616625788?pr=41280#step:9:1258

ephraimbuddy (Issue Creator) on (2024-08-11 12:39:43 UTC): Alternate PR: https://github.com/apache/airflow/pull/41382

ephraimbuddy (Issue Creator) on (2024-08-11 13:24:12 UTC): closing in favour of the alternative

"
2459405911,pull_request,closed,,Enable EksPodOperator defferable,(TBD) closes: #39685 ,jx2lee,2024-08-11 03:51:51+00:00,[],2024-08-11 07:54:25+00:00,2024-08-11 07:50:21+00:00,https://github.com/apache/airflow/pull/41377,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2282660416, 'issue_id': 2459405911, 'author': 'jx2lee', 'body': 'renamed branch name. closed', 'created_at': datetime.datetime(2024, 8, 11, 7, 50, 21, tzinfo=datetime.timezone.utc)}]","jx2lee (Issue Creator) on (2024-08-11 07:50:21 UTC): renamed branch name. closed

"
2459238441,pull_request,closed,,Fix k8s test: Try building base airflow image,,utkarsharma2,2024-08-10 18:02:19+00:00,[],2024-08-11 20:32:47+00:00,2024-08-11 20:29:53+00:00,https://github.com/apache/airflow/pull/41376,"[('area:dev-tools', '')]","[{'comment_id': 2282841814, 'issue_id': 2459238441, 'author': 'potiuk', 'body': 'Any reason why ? The base images are pulled in one of the previous steps and tagged as latest images, so rebuilding them should be unnecesary. Is there any problem it was going  to solve?\r\n\r\n```\r\n- name: Pull PROD images ${{ inputs.python-versions-list-as-string }}:${{ inputs.image-tag }}\r\n        run: breeze prod-image pull --run-in-parallel --tag-as-latest\r\n        env:\r\n          PYTHON_VERSIONS: ${{ inputs.python-versions-list-as-string }}\r\n          # Force more parallelism for pull even on public images\r\n          PARALLELISM: 6\r\n```', 'created_at': datetime.datetime(2024, 8, 11, 18, 6, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282880055, 'issue_id': 2459238441, 'author': 'utkarsharma2', 'body': '> Any reason why ? The base images are pulled in one of the previous steps and tagged as latest images, so rebuilding them should be unnecesary. Is there any problem it was going to solve?\r\n> \r\n> ```\r\n> - name: Pull PROD images ${{ inputs.python-versions-list-as-string }}:${{ inputs.image-tag }}\r\n>         run: breeze prod-image pull --run-in-parallel --tag-as-latest\r\n>         env:\r\n>           PYTHON_VERSIONS: ${{ inputs.python-versions-list-as-string }}\r\n>           # Force more parallelism for pull even on public images\r\n>           PARALLELISM: 6\r\n> ```\r\n\r\n@potiuk We can close this PR. It was a long shot to fix some of the K8s tests that were blocking the 2.10 release. \r\n\r\nWe observed some import errors in the dag, which I assumed could be because of some new dependencies added in the code but were not part of the Airflow base image used to run the tests.', 'created_at': datetime.datetime(2024, 8, 11, 20, 29, 53, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-11 18:06:23 UTC): Any reason why ? The base images are pulled in one of the previous steps and tagged as latest images, so rebuilding them should be unnecesary. Is there any problem it was going  to solve?

```
- name: Pull PROD images ${{ inputs.python-versions-list-as-string }}:${{ inputs.image-tag }}
        run: breeze prod-image pull --run-in-parallel --tag-as-latest
        env:
          PYTHON_VERSIONS: ${{ inputs.python-versions-list-as-string }}
          # Force more parallelism for pull even on public images
          PARALLELISM: 6
```

utkarsharma2 (Issue Creator) on (2024-08-11 20:29:53 UTC): @potiuk We can close this PR. It was a long shot to fix some of the K8s tests that were blocking the 2.10 release. 

We observed some import errors in the dag, which I assumed could be because of some new dependencies added in the code but were not part of the Airflow base image used to run the tests.

"
2459205403,pull_request,closed,,Fix pytests for Core except Variable for DB Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

This PR fixes the leftover core tests failing in DB isolation mode - except the onces failing in `test_variable.py` - these are covered in PR #41370 by @bugraoz93 ",jscheffl,2024-08-10 17:21:22+00:00,[],2024-08-11 18:07:13+00:00,2024-08-11 18:07:13+00:00,https://github.com/apache/airflow/pull/41375,"[('area:Triggerer', '')]",[],
2459168000,pull_request,closed,,Properly implement termination grace period seconds,"For services except Redis, this PR results in no behavior change but allows users to configure `terminationGracePeriodSeconds` if they want.

Redis is unusual in that the chart had an entry for `terminationGracePeriodSeconds` already with a default of 600. So it seems the author wanted Redis to have a grace period of 600 but actually was getting 30 since it wasn't properly configured. Therefore I properly added the `terminationGracePeriodSeconds` for Redis which will change the behavior from 30 seconds (since one wasn't provided) to 600. I could also change the default to 30 to maintain current behavior but my interpretation of the chart is that current behavior is a bug. A longer termination grace period seconds for Redis can make sense if you want to ensure you don't have data loss.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",eakmanrq,2024-08-10 16:44:02+00:00,['eakmanrq'],2024-08-14 00:59:52+00:00,2024-08-14 00:48:33+00:00,https://github.com/apache/airflow/pull/41374,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2282205878, 'issue_id': 2459168000, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 10, 16, 44, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282742123, 'issue_id': 2459168000, 'author': 'romsharon98', 'body': 'can you please add tests for your changes?\r\nyou can find more information about testing helm [here](https://github.com/romsharon98/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst)', 'created_at': datetime.datetime(2024, 8, 11, 12, 22, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284390238, 'issue_id': 2459168000, 'author': 'eakmanrq', 'body': '> can you please add tests for your changes? you can find more information about testing helm [here](https://github.com/romsharon98/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst)\r\n\r\nAh this is great, I missed there were tests for Helm. Will update with tests.', 'created_at': datetime.datetime(2024, 8, 12, 16, 15, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284463653, 'issue_id': 2459168000, 'author': 'eakmanrq', 'body': '@romsharon98 \r\n\r\nAdded tests and addressed typo: https://github.com/apache/airflow/pull/41374/commits/f980282c461a0f6424acc056930780388e426ea3\r\n\r\nLooking for more feedback on the 60 second concern.', 'created_at': datetime.datetime(2024, 8, 12, 16, 35, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287545418, 'issue_id': 2459168000, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 14, 0, 48, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287548124, 'issue_id': 2459168000, 'author': 'jedcunningham', 'body': 'Thanks @eakmanrq! Congrats on your first commit ðŸŽ‰ \r\n\r\nSo close to being the 3,000th contributor, but alas you are the 2,999th (still kinda cool imo).', 'created_at': datetime.datetime(2024, 8, 14, 0, 50, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287553411, 'issue_id': 2459168000, 'author': 'potiuk', 'body': '> So close to being the 3,000th contributor, but alas you are the 2,999th (still kinda cool imo).\r\n\r\nðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€', 'created_at': datetime.datetime(2024, 8, 14, 0, 52, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287568507, 'issue_id': 2459168000, 'author': 'eakmanrq', 'body': '> Thanks @eakmanrq! Congrats on your first commit ðŸŽ‰\r\n> \r\n> So close to being the 3,000th contributor, but alas you are the 2,999th (still kinda cool imo).\r\n\r\nWow congrats to you all! That says so much about the impact Airflow has had and the great community that has grown around it. ðŸš€', 'created_at': datetime.datetime(2024, 8, 14, 0, 59, 51, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-10 16:44:06 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

romsharon98 on (2024-08-11 12:22:06 UTC): can you please add tests for your changes?
you can find more information about testing helm [here](https://github.com/romsharon98/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst)

eakmanrq (Issue Creator) on (2024-08-12 16:15:31 UTC): Ah this is great, I missed there were tests for Helm. Will update with tests.

eakmanrq (Issue Creator) on (2024-08-12 16:35:17 UTC): @romsharon98 

Added tests and addressed typo: https://github.com/apache/airflow/pull/41374/commits/f980282c461a0f6424acc056930780388e426ea3

Looking for more feedback on the 60 second concern.

boring-cyborg[bot] on (2024-08-14 00:48:36 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

jedcunningham on (2024-08-14 00:50:31 UTC): Thanks @eakmanrq! Congrats on your first commit ðŸŽ‰ 

So close to being the 3,000th contributor, but alas you are the 2,999th (still kinda cool imo).

potiuk on (2024-08-14 00:52:53 UTC): ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€ðŸ‘€

eakmanrq (Issue Creator) on (2024-08-14 00:59:51 UTC): Wow congrats to you all! That says so much about the impact Airflow has had and the great community that has grown around it. ðŸš€

"
2459023443,pull_request,closed,,spark kubernetes operator arguments description reordering,Right now the spark kubernetes operator arguments description order is not same as the args order. This PR aligns the args description order same as args order.,dirrao,2024-08-10 10:23:04+00:00,[],2024-08-12 05:25:32+00:00,2024-08-12 05:25:32+00:00,https://github.com/apache/airflow/pull/41372,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2458895100,pull_request,closed,,Add support in MongoHook for `mongodb+srv://` URIs ,"This change adds support for `mongodb+srv://` URIs when the MongoHook interprets the Connection parameters, while maintaining the existing option of an `srv` query parameter.

#### Current Behavior
If you are:
* using the MongoHook AND
* using the [SRV/seed list feature](https://www.mongodb.com/docs/manual/reference/connection-string/#srv-connection-format) in your MongoDB cluster AND
* creating your Connection from a URI string starting with `mongodb+srv://`

you need to manually change your connection URI by adding a query parameter `srv=true` (the URI scheme is in fact ignored completely). 

If you do not add the query param, the hook will munge the scheme to `mongodb://`, attempt to use the SRV locator as a direct service location, and fail to connect properly.

#### New Behavior
After this change:
* Connections created with URIs beginning with `mongodb+srv://`, or with `conn_type=mongodb+srv`, will cause the MongoHook to interpret the connection as an SRV locator
* `srv=true` forces SRV behavior, as before

Tests have been added to verify the new behavior with both `uri` and `conn_type` arguments.

#### Justification
My organization uses the Mongo-supported form of `mongodb+srv://` which we get from the service vendor who hosts our MongoDB instances. (The introduction of SRV to Mongo was blogged [here](https://www.mongodb.com/developer/products/mongodb/srv-connection-strings/)). 

The lack of support for the standard URI scheme means that every time we add or change a MongoDB URL in our Airflow connections, the Ops team can't simply copy the URL from the service vendor to a config file or secret; they have to manually add the query param, or rope in the relevant dev team to do so (or worse, we all have to respond to a production failure and then decide under pressure who's going to modify the URL).

Merging this change will make coordinating Mongo clients in our Airflow stack simpler and more robust.
",topherinternational,2024-08-10 04:38:28+00:00,[],2024-09-08 21:24:16+00:00,2024-09-07 22:51:30+00:00,https://github.com/apache/airflow/pull/41371,"[('area:providers', ''), ('provider:mongo', '')]","[{'comment_id': 2279182696, 'issue_id': 2458895100, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 10, 4, 38, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2279294047, 'issue_id': 2458895100, 'author': 'eladkal', 'body': ""> Connections created with URIs beginning with mongodb+srv://, or with conn_type=mongodb+srv, will cause the MongoHook to interpret the connection as an SRV locator\r\n\r\nPlease let's not do that. Adding a new connection type will cause more confusion (consider that we have dozens of providers, we must make sure we don't overwhelm users with options).\r\n\r\nSpecifically for the mongo case, can you please explain further why `srv=True` isn't enough to deduce about the URI? Is it because the current behavior isn't wire as you expect? We can introduce breaking changes if we think it's best (preferably with deprecating first)\r\n\r\nAlso, I see that `srv=True` needs to be defined in the extra which makes it less visable. We can set it as boolean field in the connection form like we do for Snowflake:\r\nhttps://github.com/apache/airflow/blob/6b810b89c3f63dd2d2cf107c568be40ba9da0ba2/airflow/providers/snowflake/hooks/snowflake.py#L113-L115"", 'created_at': datetime.datetime(2024, 8, 10, 5, 5, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2294619308, 'issue_id': 2458895100, 'author': 'topherinternational', 'body': '@eladkal ah I see what you are concerned about...in my org we use environment variables to pass connection params, so we don\'t use the connections UI at all. Yes I totally agree that we don\'t want to add connection types that increase confusion.\r\n\r\nMy aim here is to prevent future devs (including my own) from hitting the same issue we did, naively passing a ""mongodb+srv://"" URI as an env var and getting a cryptic pymongo error. It would be better if we got a legible error from the hook or operator code.\r\n\r\nWould it be an acceptable approach to tighten up the connection validation inside MongoHook? I.e., if the `connection.conn_type` isn\'t `mongo` raise an error, if the conn_type has ""srv"" in it error/warn the user about using `srv=true`? (Currently the hook doesn\'t examine the conn_type at all, this seems loose.)\r\n\r\nAnd if so, would that validation be considered a breaking change in the provider? Previously-working connections might fail to validate and thus stop working.\r\n\r\n> Also, I see that srv=True needs to be defined in the extra which makes it less visable. We can set it as boolean field in the connection form like we do for Snowflake\r\n\r\nThat is a good idea, I\'m not very front-end-y but I might try to do that in a separate MR.', 'created_at': datetime.datetime(2024, 8, 17, 4, 22, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2336473186, 'issue_id': 2458895100, 'author': 'topherinternational', 'body': 'Closing in favor of #41717.', 'created_at': datetime.datetime(2024, 9, 7, 22, 51, 30, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-10 04:38:32 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-08-10 05:05:42 UTC): Please let's not do that. Adding a new connection type will cause more confusion (consider that we have dozens of providers, we must make sure we don't overwhelm users with options).

Specifically for the mongo case, can you please explain further why `srv=True` isn't enough to deduce about the URI? Is it because the current behavior isn't wire as you expect? We can introduce breaking changes if we think it's best (preferably with deprecating first)

Also, I see that `srv=True` needs to be defined in the extra which makes it less visable. We can set it as boolean field in the connection form like we do for Snowflake:
https://github.com/apache/airflow/blob/6b810b89c3f63dd2d2cf107c568be40ba9da0ba2/airflow/providers/snowflake/hooks/snowflake.py#L113-L115

topherinternational (Issue Creator) on (2024-08-17 04:22:02 UTC): @eladkal ah I see what you are concerned about...in my org we use environment variables to pass connection params, so we don't use the connections UI at all. Yes I totally agree that we don't want to add connection types that increase confusion.

My aim here is to prevent future devs (including my own) from hitting the same issue we did, naively passing a ""mongodb+srv://"" URI as an env var and getting a cryptic pymongo error. It would be better if we got a legible error from the hook or operator code.

Would it be an acceptable approach to tighten up the connection validation inside MongoHook? I.e., if the `connection.conn_type` isn't `mongo` raise an error, if the conn_type has ""srv"" in it error/warn the user about using `srv=true`? (Currently the hook doesn't examine the conn_type at all, this seems loose.)

And if so, would that validation be considered a breaking change in the provider? Previously-working connections might fail to validate and thus stop working.


That is a good idea, I'm not very front-end-y but I might try to do that in a separate MR.

topherinternational (Issue Creator) on (2024-09-07 22:51:30 UTC): Closing in favor of #41717.

"
2458811556,pull_request,closed,,Fix Variable and KubernetesJobOperator Tests for Database Isolation Tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: #41067
Fixing remaining Variable tests for db isolation mode or skipping the ones which aren't working with internal_api. 
It also includes a small fix for KubernetesJobOperator tests, I forgot to pass the session in the previous fix.

**Edit:** 
* From the checks, I can see there are side effects. I will check them tomorrow.
* I checked and reverted the part concerning secret_backend and fixed some failing things. Updated the PR content. 
* Reverted the setDefault to internal_api, strangely it failed random lowest dependency tests even though they are fine in the local. Updated the PR content.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-10 00:12:12+00:00,[],2024-08-11 18:02:02+00:00,2024-08-11 18:01:43+00:00,https://github.com/apache/airflow/pull/41370,"[('area:providers', ''), ('area:secrets', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2458704775,pull_request,closed,,Fix core tests from start to SkipMixin for Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Adjusted a lot of core pytests to make database isolation mode tests green
This PR covers all current leftover core tests from start to skip mixin.",jscheffl,2024-08-09 21:48:10+00:00,[],2024-08-11 20:41:11+00:00,2024-08-10 14:21:14+00:00,https://github.com/apache/airflow/pull/41369,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', ''), ('area:Triggerer', '')]",[],
2458685104,pull_request,closed,,Remove support for deprecated imports like operators/hooks/sensors,,jedcunningham,2024-08-09 21:24:54+00:00,[],2024-08-14 01:16:01+00:00,2024-08-14 01:15:59+00:00,https://github.com/apache/airflow/pull/41368,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2458666478,pull_request,closed,,Remove deprecated ``ImportError`` from ``airflow.models``,,jedcunningham,2024-08-09 21:05:13+00:00,[],2024-08-12 01:03:44+00:00,2024-08-12 01:03:42+00:00,https://github.com/apache/airflow/pull/41367,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2458651324,pull_request,closed,,Remove `contrib`,,jedcunningham,2024-08-09 20:50:31+00:00,[],2024-08-11 13:03:09+00:00,2024-08-11 13:03:08+00:00,https://github.com/apache/airflow/pull/41366,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2458401425,pull_request,closed,,Fix tests/models/test_taskinstance.py for Database Isolation Tests (#â€¦,"Related: https://github.com/apache/airflow/pull/41067

Backport pytest fixes to 2-10-test branch

Cherry-pick of https://github.com/apache/airflow/commit/f811ac304e3d49b015ffb1e326863fe1cce14523",jscheffl,2024-08-09 17:54:30+00:00,[],2024-08-12 18:42:19+00:00,2024-08-12 18:42:18+00:00,https://github.com/apache/airflow/pull/41364,"[('area:serialization', '')]","[{'comment_id': 2283293624, 'issue_id': 2458401425, 'author': 'potiuk', 'body': 'I cherry-picked that one already to v2-10-test', 'created_at': datetime.datetime(2024, 8, 12, 7, 39, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284682257, 'issue_id': 2458401425, 'author': 'jscheffl', 'body': 'Then we can close...', 'created_at': datetime.datetime(2024, 8, 12, 18, 42, 18, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-12 07:39:12 UTC): I cherry-picked that one already to v2-10-test

jscheffl (Issue Creator) on (2024-08-12 18:42:18 UTC): Then we can close...

"
2458305006,pull_request,closed,,Send context using in venv operator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

origin: #41039 
related: #41362 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-09 16:49:07+00:00,[],2024-08-14 04:00:19+00:00,2024-08-14 00:06:22+00:00,https://github.com/apache/airflow/pull/41363,"[('type:improvement', 'Changelog: Improvements'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2278356767, 'issue_id': 2458305006, 'author': 'eladkal', 'body': '~something is wrong as it shows 0 files changed~\r\nah you need to wait till the revert PR is merged. otherwise the diff is nothing', 'created_at': datetime.datetime(2024, 8, 9, 16, 52, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278362410, 'issue_id': 2458305006, 'author': 'phi-friday', 'body': ""> ~something is wrong as it shows 0 files changed~ ah you need to wait till the revert PR is merged. otherwise the diff is nothing\r\n\r\nI'm not sure what to do as I've never seen this before.\r\nIf #41362  is merged, should I just rebase it?"", 'created_at': datetime.datetime(2024, 8, 9, 16, 56, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278412868, 'issue_id': 2458305006, 'author': 'phi-friday', 'body': 'Based on the error message given by #41362, I checked and it only works with `pydantic>=2`.\r\nI think we need to either modify the function `_pydantic_model_dump` or set `use_pydantic_models` to `False`.\r\nWe could also make this only available for `pydantic>=2`.', 'created_at': datetime.datetime(2024, 8, 9, 17, 29, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278522365, 'issue_id': 2458305006, 'author': 'phi-friday', 'body': ""I don't know if this is allowed.\r\nModifying the model as follows did not cause the problem,\r\neven if it was `pydantic<2` or `none` (I checked in local, only pydantic test).\r\n\r\n#### in `airflow.utils.pydantic`\r\n\r\n```python\r\nif is_pydantic_2_installed():\r\n    from pydantic import BaseModel, ConfigDict, PlainSerializer, PlainValidator, ValidationInfo\r\nelse:\r\n\r\n    class BaseModel:  # type: ignore[no-redef]  # noqa: D101\r\n        def __init__(self, *args, **kwargs):\r\n            self.__dict__.update(kwargs)\r\n\r\n        @classmethod\r\n        def model_validate(cls, value: object):\r\n            args = {name: getattr(value, name, None) for name in cls.__annotations__}\r\n            return cls(**args)\r\n\r\n        def model_dump(self, *args, **kwargs):\r\n            from airflow.serialization.serialized_objects import BaseSerialization\r\n\r\n            return {\r\n                name: BaseSerialization.serialize(getattr(self, name, None), use_pydantic_models=True)\r\n                for name in self.__annotations__\r\n            }\r\n```"", 'created_at': datetime.datetime(2024, 8, 9, 18, 34, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282859662, 'issue_id': 2458305006, 'author': 'potiuk', 'body': ""Ah yes. This is because serialization uses Pydantic currently to serialize DB models that are part of the context and that requires Pydantic v2 to be installed. I'd say we should make this feature only available if Pydantic2 is installed (with approproate documentation and error messages) - and skip the tests if Pydantic 2 is not installed."", 'created_at': datetime.datetime(2024, 8, 11, 19, 11, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284276583, 'issue_id': 2458305006, 'author': 'phi-friday', 'body': 'https://github.com/apache/airflow/blob/4e62909ff5fc92eb19676fb3266cd935cd42df55/airflow/serialization/serialized_objects.py#L630\r\n\r\nIf AIP44 is not enabled, an error is thrown.\r\nSo I made it so that an error is thrown if `pydantic<2` or AIP44 is not enabled. \r\nAnd I added test cases for each of them.', 'created_at': datetime.datetime(2024, 8, 12, 15, 24, 30, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-09 16:52:23 UTC): ~something is wrong as it shows 0 files changed~
ah you need to wait till the revert PR is merged. otherwise the diff is nothing

phi-friday (Issue Creator) on (2024-08-09 16:56:08 UTC): I'm not sure what to do as I've never seen this before.
If #41362  is merged, should I just rebase it?

phi-friday (Issue Creator) on (2024-08-09 17:29:25 UTC): Based on the error message given by #41362, I checked and it only works with `pydantic>=2`.
I think we need to either modify the function `_pydantic_model_dump` or set `use_pydantic_models` to `False`.
We could also make this only available for `pydantic>=2`.

phi-friday (Issue Creator) on (2024-08-09 18:34:03 UTC): I don't know if this is allowed.
Modifying the model as follows did not cause the problem,
even if it was `pydantic<2` or `none` (I checked in local, only pydantic test).

#### in `airflow.utils.pydantic`

```python
if is_pydantic_2_installed():
    from pydantic import BaseModel, ConfigDict, PlainSerializer, PlainValidator, ValidationInfo
else:

    class BaseModel:  # type: ignore[no-redef]  # noqa: D101
        def __init__(self, *args, **kwargs):
            self.__dict__.update(kwargs)

        @classmethod
        def model_validate(cls, value: object):
            args = {name: getattr(value, name, None) for name in cls.__annotations__}
            return cls(**args)

        def model_dump(self, *args, **kwargs):
            from airflow.serialization.serialized_objects import BaseSerialization

            return {
                name: BaseSerialization.serialize(getattr(self, name, None), use_pydantic_models=True)
                for name in self.__annotations__
            }
```

potiuk on (2024-08-11 19:11:31 UTC): Ah yes. This is because serialization uses Pydantic currently to serialize DB models that are part of the context and that requires Pydantic v2 to be installed. I'd say we should make this feature only available if Pydantic2 is installed (with approproate documentation and error messages) - and skip the tests if Pydantic 2 is not installed.

phi-friday (Issue Creator) on (2024-08-12 15:24:30 UTC): https://github.com/apache/airflow/blob/4e62909ff5fc92eb19676fb3266cd935cd42df55/airflow/serialization/serialized_objects.py#L630

If AIP44 is not enabled, an error is thrown.
So I made it so that an error is thrown if `pydantic<2` or AIP44 is not enabled. 
And I added test cases for each of them.

"
2458271603,pull_request,closed,,"Revert ""Send context using in venv operator (#41039)""","This reverts commit da553935d248f22695124c40777d3ea29e04d57f.

The two tests added here are failing both in the main and 2.10 release branch",ephraimbuddy,2024-08-09 16:26:10+00:00,[],2024-08-09 16:59:28+00:00,2024-08-09 16:59:26+00:00,https://github.com/apache/airflow/pull/41362,"[('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2278318289, 'issue_id': 2458271603, 'author': 'ephraimbuddy', 'body': 'cc [phi-friday](https://github.com/apache/airflow/commits?author=phi-friday)', 'created_at': datetime.datetime(2024, 8, 9, 16, 27, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278325402, 'issue_id': 2458271603, 'author': 'ephraimbuddy', 'body': 'On main: https://github.com/apache/airflow/actions/runs/10317957180/job/28563448609?pr=41348#step:7:16218\r\n\r\nV2-10: https://github.com/apache/airflow/actions/runs/10317331885/job/28569089548?pr=41280#step:7:14514', 'created_at': datetime.datetime(2024, 8, 9, 16, 31, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278325957, 'issue_id': 2458271603, 'author': 'eladkal', 'body': '@phi-friday please open a new PR and we will run full tests on it to see what is the problem\r\ncc @shahar1', 'created_at': datetime.datetime(2024, 8, 9, 16, 32, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278353571, 'issue_id': 2458271603, 'author': 'phi-friday', 'body': '@eladkal I created a new PR. #41363', 'created_at': datetime.datetime(2024, 8, 9, 16, 50, 18, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-08-09 16:27:22 UTC): cc [phi-friday](https://github.com/apache/airflow/commits?author=phi-friday)

ephraimbuddy (Issue Creator) on (2024-08-09 16:31:59 UTC): On main: https://github.com/apache/airflow/actions/runs/10317957180/job/28563448609?pr=41348#step:7:16218

V2-10: https://github.com/apache/airflow/actions/runs/10317331885/job/28569089548?pr=41280#step:7:14514

eladkal on (2024-08-09 16:32:24 UTC): @phi-friday please open a new PR and we will run full tests on it to see what is the problem
cc @shahar1

phi-friday on (2024-08-09 16:50:18 UTC): @eladkal I created a new PR. #41363

"
2458253380,pull_request,closed,,Typo fix dataset guide,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #41353

This PR ports the commit in #41353 to the `main`

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-08-09 16:13:32+00:00,[],2024-08-09 17:01:11+00:00,2024-08-09 17:01:11+00:00,https://github.com/apache/airflow/pull/41361,"[('kind:documentation', '')]",[],
2458158095,pull_request,closed,,Enable Audience validation options for azure,"Enable the possibility to validate an audience for azure jwt tokens. Without this function the security manager does not care what the azure token is for, as long as it can decode it. Making it pretty simple to bypass authentication all together

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gschuurman,2024-08-09 15:20:15+00:00,[],2024-11-13 00:15:15+00:00,2024-11-13 00:15:15+00:00,https://github.com/apache/airflow/pull/41360,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2463470098, 'issue_id': 2458158095, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 8, 0, 14, 43, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-08 00:14:43 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2458044079,pull_request,closed,,fix: resolve AirflowProviderDeprecationWarning in spark provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #41326

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-09 14:23:11+00:00,[],2024-08-14 08:50:12+00:00,2024-08-09 16:22:28+00:00,https://github.com/apache/airflow/pull/41358,"[('area:providers', ''), ('provider:apache-spark', '')]",[],
2457919716,pull_request,closed,,Add `v2-10-test` to the protected branch after `2.10.0rc1`,"This would prevent force pushes, and the development of Airflow 2 will continue on this branch. After development, we sync with the v2-10-stable branch for release

",ephraimbuddy,2024-08-09 13:26:24+00:00,[],2024-08-12 17:31:47+00:00,2024-08-12 17:31:45+00:00,https://github.com/apache/airflow/pull/41357,"[('area:dev-tools', '')]",[],
2457782092,pull_request,closed,,feat(docker): Replace `use_dill` with `serializer`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Made `@task.docker` use `serializer` instead of `use_dill`.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-08-09 12:11:04+00:00,[],2024-08-14 11:23:49+00:00,2024-08-14 10:42:47+00:00,https://github.com/apache/airflow/pull/41356,"[('area:providers', ''), ('provider:docker', '')]","[{'comment_id': 2288066380, 'issue_id': 2457782092, 'author': 'phi-friday', 'body': 'error in `common.sql`\r\nrelated: #41460', 'created_at': datetime.datetime(2024, 8, 14, 7, 43, 1, tzinfo=datetime.timezone.utc)}]","phi-friday (Issue Creator) on (2024-08-14 07:43:01 UTC): error in `common.sql`
related: #41460

"
2457780076,pull_request,closed,,[DRAFT] POC Sensor Improvements,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
Did couple of runs with this example in async results are really impressive. I could not able to assess really the downsides if using dagbag and TaskInstance inisde the trigger.

```
from __future__ import annotations

import asyncio
from datetime import datetime

from airflow import DAG
from airflow.sensors.base import BaseSensorOperator, PokeReturnValue
from airflow.sensors.python import PythonSensor
from airflow.utils.context import Context

DAG_ID = ""test_async_and_sync_sensor_in_trigger""


class TestAsyncSensorExecuteInTrigger(BaseSensorOperator):

    def __init__(self, some_id, **kwargs):
        super().__init__(**kwargs)
        self.some_id = some_id

    async def poke(self, context: Context) -> bool | PokeReturnValue:
        self.log.info(context)
        self.log.info(self.some_id)
        await asyncio.sleep(120)
        self.log.info(""Done.."")
        return True


class TestSyncSensorExecuteInTrigger(BaseSensorOperator):

    def __init__(self, some_id, **kwargs):
        super().__init__(**kwargs)
        self.some_id = some_id

    def poke(self, context: Context) -> bool | PokeReturnValue:
        self.log.info(context)
        self.log.info(self.some_id)
        self.log.info(""Done.."")
        return True


with DAG(
    dag_id=DAG_ID,
    schedule=None,
    start_date=datetime(2021, 1, 1),
    tags=[""example""],
    catchup=False,
) as dag:
    def success_callable():
        return False


    op_async_sensor = TestAsyncSensorExecuteInTrigger.partial(task_id=""test_async_sensor"",
                                                              start_from_trigger=True,
                                                              ).expand(some_id=list(range(2)))

    op_sync_sensor = TestSyncSensorExecuteInTrigger.partial(task_id=""test_sync_sensor"",
                                                             start_from_trigger=True,
                                                             ).expand(some_id=list(range(2)))

    python_sensor = PythonSensor(task_id=""test_python_sensor"",
                                 start_from_trigger=True,
                                 reschedule_time_threshold=240,
                                 python_callable=success_callable)

```
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-08-09 12:09:54+00:00,[],2024-11-25 00:16:40+00:00,2024-11-25 00:16:40+00:00,https://github.com/apache/airflow/pull/41355,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2381033305, 'issue_id': 2457780076, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 29, 0, 16, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387628691, 'issue_id': 2457780076, 'author': 'gopidesupavan', 'body': 'No stale', 'created_at': datetime.datetime(2024, 10, 2, 5, 1, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482395236, 'issue_id': 2457780076, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 18, 9, 25, 9, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-09-29 00:16:36 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

gopidesupavan (Issue Creator) on (2024-10-02 05:01:39 UTC): No stale

github-actions[bot] on (2024-11-18 09:25:09 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2457710033,pull_request,closed,,Update the contributing doc now that the main branch is Airflow 3,"The main branch is now Airflow 3. We need to update the contributing docs
so contributors know where to PR against.",ephraimbuddy,2024-08-09 11:26:28+00:00,[],2025-01-27 11:24:50+00:00,2024-08-09 13:15:04+00:00,https://github.com/apache/airflow/pull/41354,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2277926577, 'issue_id': 2457710033, 'author': 'vincbeck', 'body': 'Should we add a section to explain how to create a bug fix ONLY for Airflow 2.x? That can happen if the code between Airflow 2 and Airflow 3 diverges and the bug fix is no longer relevant for Airflow 3', 'created_at': datetime.datetime(2024, 8, 9, 13, 17, 14, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-08-09 13:17:14 UTC): Should we add a section to explain how to create a bug fix ONLY for Airflow 2.x? That can happen if the code between Airflow 2 and Airflow 3 diverges and the bug fix is no longer relevant for Airflow 3

"
2457625749,pull_request,closed,,Typo fix dataset guide ,A (edit: two and a two missing words) typos and a missing period. This time against the right branch :),TJaniF,2024-08-09 10:34:21+00:00,[],2024-08-09 16:16:17+00:00,2024-08-09 15:54:57+00:00,https://github.com/apache/airflow/pull/41353,"[('area:dev-tools', ''), ('kind:documentation', '')]","[{'comment_id': 2278263208, 'issue_id': 2457625749, 'author': 'jedcunningham', 'body': '@TJaniF can you also open a PR against main?\r\n\r\n(@Lee-W @shahar1 we need to make sure these also land in main)', 'created_at': datetime.datetime(2024, 8, 9, 15, 56, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278276059, 'issue_id': 2457625749, 'author': 'jedcunningham', 'body': '(Oh, and this should have gone to v2-10-test, not stable)', 'created_at': datetime.datetime(2024, 8, 9, 16, 3, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278300354, 'issue_id': 2457625749, 'author': 'shahar1', 'body': '> @TJaniF can you also open a PR against main?\r\n> \r\n> (@Lee-W @shahar1 we need to make sure these also land in main)\r\n\r\nI took care of the PR to main (#41361)', 'created_at': datetime.datetime(2024, 8, 9, 16, 16, 16, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2024-08-09 15:56:51 UTC): @TJaniF can you also open a PR against main?

(@Lee-W @shahar1 we need to make sure these also land in main)

jedcunningham on (2024-08-09 16:03:34 UTC): (Oh, and this should have gone to v2-10-test, not stable)

shahar1 on (2024-08-09 16:16:16 UTC): I took care of the PR to main (#41361)

"
2457595269,pull_request,closed,,Fix typo docs - dataset guide,"Just a one character docs typo fix :) 

EDIT: and a missing period.",TJaniF,2024-08-09 10:17:10+00:00,[],2024-08-09 17:26:57+00:00,2024-08-09 17:26:56+00:00,https://github.com/apache/airflow/pull/41351,"[('kind:documentation', '')]","[{'comment_id': 2277637157, 'issue_id': 2457595269, 'author': 'TJaniF', 'body': 'Just learned main is Airflow 3 now, will make a new PR for this before my gitting becomes even more embarrassing ðŸ‘€ apologies to those who got pinged!', 'created_at': datetime.datetime(2024, 8, 9, 10, 24, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277647005, 'issue_id': 2457595269, 'author': 'ephraimbuddy', 'body': ""> Just learned main is Airflow 3 now, will make a new PR for this before my gitting becomes even more embarrassing ðŸ‘€ apologies to those who got pinged!\r\n\r\nWe can still backport fixes to Airflow v2-10-stable. A fix like this one can be backported, so it's not wrong to PR against main"", 'created_at': datetime.datetime(2024, 8, 9, 10, 30, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277654481, 'issue_id': 2457595269, 'author': 'TJaniF', 'body': ""Oh, thats good to know thank you! I wasn't sure how to not have all the other commits in here so now I branched off v2-10-stable and re-PRed :) \r\n\r\nThe solution probably would be for me to finally learn git ðŸ˜…"", 'created_at': datetime.datetime(2024, 8, 9, 10, 35, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278288747, 'issue_id': 2457595269, 'author': 'TJaniF', 'body': '@jedcunningham The same docs PR against main as requested :)', 'created_at': datetime.datetime(2024, 8, 9, 16, 9, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278311829, 'issue_id': 2457595269, 'author': 'eladkal', 'body': 'Seems the same as https://github.com/apache/airflow/pull/41361 ?', 'created_at': datetime.datetime(2024, 8, 9, 16, 23, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278409122, 'issue_id': 2457595269, 'author': 'TJaniF', 'body': 'Yes, @eladkal I did not see that @shahar1 had already taken care of it before reopening this, apologies. Will close for good now :)', 'created_at': datetime.datetime(2024, 8, 9, 17, 26, 56, tzinfo=datetime.timezone.utc)}]","TJaniF (Issue Creator) on (2024-08-09 10:24:30 UTC): Just learned main is Airflow 3 now, will make a new PR for this before my gitting becomes even more embarrassing ðŸ‘€ apologies to those who got pinged!

ephraimbuddy on (2024-08-09 10:30:31 UTC): We can still backport fixes to Airflow v2-10-stable. A fix like this one can be backported, so it's not wrong to PR against main

TJaniF (Issue Creator) on (2024-08-09 10:35:22 UTC): Oh, thats good to know thank you! I wasn't sure how to not have all the other commits in here so now I branched off v2-10-stable and re-PRed :) 

The solution probably would be for me to finally learn git ðŸ˜…

TJaniF (Issue Creator) on (2024-08-09 16:09:42 UTC): @jedcunningham The same docs PR against main as requested :)

eladkal on (2024-08-09 16:23:22 UTC): Seems the same as https://github.com/apache/airflow/pull/41361 ?

TJaniF (Issue Creator) on (2024-08-09 17:26:56 UTC): Yes, @eladkal I did not see that @shahar1 had already taken care of it before reopening this, apologies. Will close for good now :)

"
2457543959,pull_request,closed,,Add WebEncoder for trigger page rendering to avoid render failure,"Add WebEncoder for trigger page rendering to avoid render failure

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",molcay,2024-08-09 09:48:45+00:00,[],2024-08-30 08:53:35+00:00,2024-08-12 19:06:55+00:00,https://github.com/apache/airflow/pull/41350,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2278212936, 'issue_id': 2457543959, 'author': 'bbovenzi', 'body': 'Thanks! Could you expand on what render failures were happening?', 'created_at': datetime.datetime(2024, 8, 9, 15, 31, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283788502, 'issue_id': 2457543959, 'author': 'molcay', 'body': 'Hi @bbovenzi,\r\nAfter checking the second time, ""failure"" is a bit too much but here is the situation:\r\n\r\n- I have the following simple DAG:\r\n```python\r\nimport datetime\r\n\r\nimport airflow\r\nimport pendulum\r\nfrom airflow.operators.bash import BashOperator\r\n\r\n\r\nwith airflow.DAG(\r\n    dag_id=""basic_dag"",\r\n    start_date=pendulum.datetime(2024, 5, 14, tz=""UTC""),\r\n    catchup=False,\r\n    schedule=""@once"",\r\n    tags=[""basic""],\r\n    params={\r\n        \'d\': datetime.datetime.utcnow(),\r\n    }\r\n):\r\n    task = BashOperator(task_id=""normal"", bash_command=""echo \'I am just a normal task\'"")\r\n```\r\n\r\nWhen I try to trigger this DAG, in the trigger form page I am getting the following info message (I am saying info because it is a blueish color)\r\n```\r\nCould not pre-populate conf field due to non-JSON-serializable data-types\r\n```\r\nThe UI:\r\n![Screenshot 2024-08-12 1 24 18 PM](https://github.com/user-attachments/assets/bca00b35-7853-4b2b-b399-c37e0c03edf3)\r\n\r\nWhen I try to click the Trigger button, I am getting the same info message again and the trigger is not successful. \r\nHere is the current process:\r\n![output](https://github.com/user-attachments/assets/90a2347c-d20e-43f4-a175-51a5cef15b1e)\r\n\r\n> NOTE: If I run the command `airflow dags trigger basic_dag` it will succeed. \r\n\r\nWith this PR, we will use the `WebEncoder` for current and recent configurations, so it will not give this message.\r\nThe result:\r\n![output (1)](https://github.com/user-attachments/assets/5096242e-da64-4357-a280-2704452f8224)', 'created_at': datetime.datetime(2024, 8, 12, 12, 4, 30, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-08-09 15:31:10 UTC): Thanks! Could you expand on what render failures were happening?

molcay (Issue Creator) on (2024-08-12 12:04:30 UTC): Hi @bbovenzi,
After checking the second time, ""failure"" is a bit too much but here is the situation:

- I have the following simple DAG:
```python
import datetime

import airflow
import pendulum
from airflow.operators.bash import BashOperator


with airflow.DAG(
    dag_id=""basic_dag"",
    start_date=pendulum.datetime(2024, 5, 14, tz=""UTC""),
    catchup=False,
    schedule=""@once"",
    tags=[""basic""],
    params={
        'd': datetime.datetime.utcnow(),
    }
):
    task = BashOperator(task_id=""normal"", bash_command=""echo 'I am just a normal task'"")
```

When I try to trigger this DAG, in the trigger form page I am getting the following info message (I am saying info because it is a blueish color)
```
Could not pre-populate conf field due to non-JSON-serializable data-types
```
The UI:
![Screenshot 2024-08-12 1 24 18 PM](https://github.com/user-attachments/assets/bca00b35-7853-4b2b-b399-c37e0c03edf3)

When I try to click the Trigger button, I am getting the same info message again and the trigger is not successful. 
Here is the current process:
![output](https://github.com/user-attachments/assets/90a2347c-d20e-43f4-a175-51a5cef15b1e)


With this PR, we will use the `WebEncoder` for current and recent configurations, so it will not give this message.
The result:
![output (1)](https://github.com/user-attachments/assets/5096242e-da64-4357-a280-2704452f8224)

"
2457301692,pull_request,closed,,Rename dataset related python variable names to asset,"## Why
as part of AIP-74

part of https://github.com/apache/airflow/issues/42307

## What

Rename the variable names in Airflow. DB, API, and UI changes will be done in the following PRs

* Rename module ``airflow.api_connexion.schemas.dataset_schema`` as ``airflow.api_connexion.schemas.asset_schema``

  * Rename variable ``create_dataset_event_schema`` as ``create_asset_event_schema``
  * Rename variable ``dataset_collection_schema`` as ``asset_collection_schema``
  * Rename variable ``dataset_event_collection_schema`` as ``asset_event_collection_schema``
  * Rename variable ``dataset_event_schema`` as ``asset_event_schema``
  * Rename variable ``dataset_schema`` as ``asset_schema``
  * Rename class ``TaskOutletDatasetReferenceSchema`` as ``TaskOutletAssetReferenceSchema``
  * Rename class ``DagScheduleDatasetReferenceSchema`` as ``DagScheduleAssetReferenceSchema``
  * Rename class ``DatasetAliasSchema`` as ``AssetAliasSchema``
  * Rename class ``DatasetSchema`` as ``AssetSchema``
  * Rename class ``DatasetCollection`` as ``AssetCollection``
  * Rename class ``DatasetEventSchema`` as ``AssetEventSchema``
  * Rename class ``DatasetEventCollection`` as ``AssetEventCollection``
  * Rename class ``DatasetEventCollectionSchema`` as ``AssetEventCollectionSchema``
  * Rename class ``CreateDatasetEventSchema`` as ``CreateAssetEventSchema``

* Rename module ``airflow.datasets`` as ``airflow.assets``

  * Rename class ``DatasetAlias`` as ``AssetAlias``
  * Rename class ``DatasetAll`` as ``AssetAll``
  * Rename class ``DatasetAny`` as ``AssetAny``
  * Rename function ``expand_alias_to_datasets`` as ``expand_alias_to_assets``
  * Rename class ``DatasetAliasEvent`` as ``AssetAliasEvent``

    * Rename method ``dest_dataset_uri`` as ``dest_asset_uri``

  * Rename class ``BaseDataset`` as ``BaseAsset``

    * Rename method ``iter_datasets`` as ``iter_assets``
    * Rename method ``iter_dataset_aliases`` as ``iter_asset_aliases``

  * Rename class ``Dataset`` as ``Asset``

    * Rename method ``iter_datasets`` as ``iter_assets``
    * Rename method ``iter_dataset_aliases`` as ``iter_asset_aliases``

  * Rename class ``_DatasetBooleanCondition`` as ``_AssetBooleanCondition``

    * Rename method ``iter_datasets`` as ``iter_assets``
    * Rename method ``iter_dataset_aliases`` as ``iter_asset_aliases``

* Rename module ``airflow.datasets.manager`` as ``airflow.assets.manager``

  * Rename variable ``dataset_manager`` as ``asset_manager``
  * Rename function ``resolve_dataset_manager`` as ``resolve_asset_manager``
  * Rename class ``DatasetManager`` as ``AssetManager``

      * Rename method ``register_dataset_change`` as ``register_asset_change``
      * Rename method ``create_datasets`` as ``create_assets``
      * Rename method ``register_dataset_change`` as ``notify_asset_created``
      * Rename method ``notify_dataset_changed`` as ``notify_asset_changed``

* Rename module ``airflow.models.dataset`` as ``airflow.models.asset``

    * Rename class ``DatasetDagRunQueue`` as ``AssetDagRunQueue``
    * Rename class ``DatasetEvent`` as ``AssetEvent``
    * Rename class ``DatasetModel`` as ``AssetModel``
    * Rename class ``DatasetAliasModel`` as ``AssetAliasModel``
    * Rename class ``DagScheduleDatasetReference`` as ``DagScheduleAssetReference``
    * Rename class ``TaskOutletDatasetReference`` as ``TaskOutletAssetReference``
    * Rename class ``DagScheduleDatasetAliasReference`` as ``DagScheduleAssetAliasReference``

* Rename module ``airflow.api_ui.views.datasets`` as ``airflow.api_ui.views.assets``

    * Rename variable ``dataset_router`` as ``asset_rounter``

* Rename module ``airflow.listeners.spec.dataset`` as ``airflow.listeners.spec.asset``

    * Rename function ``on_dataset_created`` as ``on_asset_created``
    * Rename function ``on_dataset_changed`` as ``on_asset_changed``

* Rename module ``airflow.timetables.datasets`` as ``airflow.timetables.assets``

    * Rename class ``DatasetOrTimeSchedule`` as ``AssetOrTimeSchedule``

* Rename module ``airflow.serialization.pydantic.dataset`` as ``airflow.serialization.pydantic.asset``

    * Rename class ``DagScheduleDatasetReferencePydantic`` as ``DagScheduleAssetReferencePydantic``
    * Rename class ``TaskOutletDatasetReferencePydantic`` as ``TaskOutletAssetReferencePydantic``
    * Rename class ``DatasetPydantic`` as ``AssetPydantic``
    * Rename class ``DatasetEventPydantic`` as ``AssetEventPydantic``

* Rename module ``airflow.datasets.metadata`` as ``airflow.assets.metadata``

* In module ``airflow.jobs.scheduler_job_runner``

    * and its class ``SchedulerJobRunner``

        * Rename method ``_create_dag_runs_dataset_triggered`` as ``_create_dag_runs_asset_triggered``
        * Rename method ``_orphan_unreferenced_datasets`` as ``_orphan_unreferenced_datasets``

* In module ``airflow.api_connexion.security``

    * Rename decorator ``requires_access_dataset`` as ``requires_access_asset``

* In module ``airflow.auth.managers.models.resource_details``

    * Rename class ``DatasetDetails`` as ``AssetDetails``

* In module ``airflow.auth.managers.base_auth_manager``

    * Rename function ``is_authorized_dataset`` as ``is_authorized_asset``

* In module ``airflow.timetables.simple``

    * Rename class ``DatasetTriggeredTimetable`` as ``AssetTriggeredTimetable``

* In module ``airflow.lineage.hook``

    * Rename class ``DatasetLineageInfo`` as ``AssetLineageInfo``

        * Rename attribute ``dataset`` as ``asset``

    * In its class ``HookLineageCollector``

        * Rename method ``create_dataset`` as ``create_asset``
        * Rename method ``add_input_dataset`` as ``add_input_asset``
        * Rename method ``add_output_dataset`` as ``add_output_asset``
        * Rename method ``collected_datasets`` as ``collected_assets``

* In module ``airflow.models.dag``

    * Rename function ``get_dataset_triggered_next_run_info`` as ``get_asset_triggered_next_run_info``

    * In its class ``DagModel``

        * Rename method ``get_dataset_triggered_next_run_info`` as ``get_asset_triggered_next_run_info``

* In module ``airflow.models.taskinstance``

    * and its class ``TaskInstance``

        * Rename method ``_register_dataset_changes`` as ``_register_asset_changes``

* In module ``airflow.providers_manager``

    * and its class ``ProvidersManager``

        * Rename method ``initialize_providers_dataset_uri_resources`` as ``initialize_providers_asset_uri_resources``
        * Rename attribute ``_discover_dataset_uri_resources`` as ``_discover_asset_uri_resources``
        * Rename property ``dataset_factories`` as ``asset_factories``
        * Rename property ``dataset_uri_handlers`` as ``asset_uri_handlers``
        * Rename property ``dataset_to_openlineage_converters`` as ``asset_to_openlineage_converters``

* In module ``airflow.security.permissions``

    * Rename constant ``RESOURCE_DATASET`` as ``RESOURCE_ASSET``

* In module ``airflow.serialization.enums``

    * and its class DagAttributeTypes

        * Rename attribute ``DATASET_EVENT_ACCESSORS`` as ``ASSET_EVENT_ACCESSORS``
        * Rename attribute ``DATASET_EVENT_ACCESSOR`` as ``ASSET_EVENT_ACCESSOR``
        * Rename attribute ``DATASET`` as ``ASSET``
        * Rename attribute ``DATASET_ALIAS`` as ``ASSET_ALIAS``
        * Rename attribute ``DATASET_ANY`` as ``ASSET_ANY``
        * Rename attribute ``DATASET_ALL`` as ``ASSET_ALL``

* In module ``airflow.serialization.pydantic.taskinstance``

    * and its class ``TaskInstancePydantic``

        * Rename method ``_register_dataset_changes`` as ``_register_dataset_changes``

* In module ``airflow.serialization.serialized_objects``

    * Rename function ``encode_dataset_condition`` as ``encode_asset_condition``
    * Rename function ``decode_dataset_condition`` as ``decode_asset_condition``

* In module ``airflow.timetables.base``

    * Rename class ```_NullDataset``` as ```_NullAsset```

        * Rename method ``iter_datasets`` as ``iter_assets``

* In module ``airflow.utils.context``

    * Rename class ``LazyDatasetEventSelectSequence`` as ``LazyAssetEventSelectSequence``

* In module ``airflow.www.auth``

    * Rename function ``has_access_dataset`` as ``has_access_asset``

* Rename configuration ``core.strict_dataset_uri_validation`` as ``core.strict_asset_uri_validation``, ``core.dataset_manager_class`` as ``core.asset_manager_class`` and ``core.dataset_manager_class`` as ``core.asset_manager_class``
* Rename example dags  ``example_dataset_alias.py``, ``example_dataset_alias_with_no_taskflow.py``, ``example_datasets.py`` as ``example_asset_alias.py``, ``example_asset_alias_with_no_taskflow.py``, ``example_assets.py``
* Rename DagDependency name ``dataset-alias``, ``dataset`` as ``asset-alias``, ``asset``
* Rename context key ``triggering_dataset_events`` as ``triggering_asset_events``
* Rename resource key ``dataset-uris`` as ``asset-uris`` for providers amazon, common.io, mysql, fab, postgres, trino

* In provider ``airflow.providers.amazon.aws``

    * Rename package ``datasets`` as ``assets``

        * In its module ``s3``

            * Rename method ``create_dataset`` as ``create_asset``
            * Rename method ``convert_dataset_to_openlineage`` as ``convert_asset_to_openlineage``

  * and its module ``auth_manager.avp.entities``

    * Rename attribute ``AvpEntities.DATASET`` as ``AvpEntities.ASSET``

  * and its module ``auth_manager.auth_manager.aws_auth_manager``

    * Rename function ``is_authorized_dataset`` as ``is_authorized_asset``

* In provider ``airflow.providers.common.io``

  * Rename package ``datasets``  as ``assets``

    * in its module ``file``

        * Rename method ``create_dataset`` as ``create_asset``
        * Rename method ``convert_dataset_to_openlineage`` as ``convert_asset_to_openlineage``

* In provider ``airflow.providers.fab``

  * in its module ``auth_manager.fab_auth_manager``

    * Rename function ``is_authorized_dataset`` as ``is_authorized_asset``

* In provider ``airflow.providers.openlineage``

  * in its module ``utils.utils``

    * Rename class ``DatasetInfo`` as ``AssetInfo``
    * Rename function ``translate_airflow_dataset`` as ``translate_airflow_asset``

* Rename package ``airflow.providers.postgres.datasets`` as ``airflow.providers.postgres.assets``
* Rename package ``airflow.providers.mysql.datasets`` as ``airflow.providers.mysql.assets``
* Rename package ``airflow.providers.trino.datasets`` as ``airflow.providers.trino.assets``
* Add module ``airflow.providers.common.compat.assets``
* Add module ``airflow.providers.common.compat.openlineage.utils.utils``
* Add moddule ``airflow.providers.common.compat.security.permissions.RESOURCE_ASSET``

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-09 07:31:55+00:00,['Lee-W'],2024-10-28 06:21:18+00:00,2024-09-30 05:30:25+00:00,https://github.com/apache/airflow/pull/41348,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:lineage', ''), ('provider:openlineage', 'AIP-53'), ('provider:common-io', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('AIP-74', 'Dataset -> Asset')]","[{'comment_id': 2285939577, 'issue_id': 2457301692, 'author': 'uranusjr', 'body': 'I have created #41424 to add the `name` attribute. These two will conflict, so remember to rebase.', 'created_at': datetime.datetime(2024, 8, 13, 10, 43, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285944211, 'issue_id': 2457301692, 'author': 'Lee-W', 'body': 'sure, will do', 'created_at': datetime.datetime(2024, 8, 13, 10, 46, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2367209018, 'issue_id': 2457301692, 'author': 'uranusjr', 'body': 'OK I think the rest all makes sense (assuming you didnâ€™t sneak in changes between renamesâ€¦ I did not check character-by-character). Now we just(?) need to make tests pass I guess.', 'created_at': datetime.datetime(2024, 9, 23, 4, 19, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2367305335, 'issue_id': 2457301692, 'author': 'Lee-W', 'body': 'The remaining test failures are due to amazon-provider. will create a separate PR based on that', 'created_at': datetime.datetime(2024, 9, 23, 6, 10, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2370938431, 'issue_id': 2457301692, 'author': 'Lee-W', 'body': '@uranusjr Finally got it green! Would be great if you could take one last check. Thanks!', 'created_at': datetime.datetime(2024, 9, 24, 10, 58, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2375474299, 'issue_id': 2457301692, 'author': 'Lee-W', 'body': ""> Has the UI been tested if all is working? Some changes in UI very probably are not automatically be tested. Did not make a test and opened the UI. Might be a good point to double check not to break any link/HTML.\r\n\r\nI've done some testing, and it worked fine. I tried to keep UI changes unrelated to the backend change in another separate PR (not yet there). As there are many conflicts today (sometime missing something during rebasing ðŸ¤¦\u200dâ™‚ï¸), I'll try to resolve them and test them again. Thanks!"", 'created_at': datetime.datetime(2024, 9, 26, 0, 3, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2381872858, 'issue_id': 2457301692, 'author': 'Lee-W', 'body': ""> > Has the UI been tested if all is working? Some changes in UI very probably are not automatically be tested. Did not make a test and opened the UI. Might be a good point to double check not to break any link/HTML.\r\n> \r\n> I've done some testing, and it worked fine. I tried to keep UI changes unrelated to the backend change in another separate PR (not yet there). As there are many conflicts today (sometime missing something during rebasing ðŸ¤¦\u200dâ™‚ï¸), I'll try to resolve them and test them again. Thanks!\r\n\r\nJust a quick update. I've done the test on my local end and it work fine. And the CI is finally green again! ðŸŽ‰"", 'created_at': datetime.datetime(2024, 9, 30, 2, 14, 42, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-08-13 10:43:55 UTC): I have created #41424 to add the `name` attribute. These two will conflict, so remember to rebase.

Lee-W (Issue Creator) on (2024-08-13 10:46:38 UTC): sure, will do

uranusjr on (2024-09-23 04:19:35 UTC): OK I think the rest all makes sense (assuming you didnâ€™t sneak in changes between renamesâ€¦ I did not check character-by-character). Now we just(?) need to make tests pass I guess.

Lee-W (Issue Creator) on (2024-09-23 06:10:35 UTC): The remaining test failures are due to amazon-provider. will create a separate PR based on that

Lee-W (Issue Creator) on (2024-09-24 10:58:59 UTC): @uranusjr Finally got it green! Would be great if you could take one last check. Thanks!

Lee-W (Issue Creator) on (2024-09-26 00:03:15 UTC): I've done some testing, and it worked fine. I tried to keep UI changes unrelated to the backend change in another separate PR (not yet there). As there are many conflicts today (sometime missing something during rebasing ðŸ¤¦â€â™‚ï¸), I'll try to resolve them and test them again. Thanks!

Lee-W (Issue Creator) on (2024-09-30 02:14:42 UTC): Just a quick update. I've done the test on my local end and it work fine. And the CI is finally green again! ðŸŽ‰

"
2457146764,pull_request,closed,,Recommend reserializing DAGs after downgrade,"We should recommend that users reserialize DAGs after finishing their downgrades - the older version may have a different representation and can cause odd failures.

<img width=""1096"" alt=""Screenshot 2024-08-08 at 11 29 55â€¯PM"" src=""https://github.com/user-attachments/assets/fb124c58-ff9f-4d91-9090-012729bcd992"">
",jedcunningham,2024-08-09 05:41:26+00:00,[],2024-08-09 16:00:42+00:00,2024-08-09 09:04:18+00:00,https://github.com/apache/airflow/pull/41347,"[('area:CLI', ''), ('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2457087120,pull_request,closed,,Fix wrong logs depupe in UI,"related: #41225

In this PR, a bug with removing duplicate lines in a single log has been fixed.",artemSSSS,2024-08-09 04:39:44+00:00,[],2024-08-22 08:00:22+00:00,2024-08-22 08:00:21+00:00,https://github.com/apache/airflow/pull/41346,"[('area:logging', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2277139006, 'issue_id': 2457087120, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 9, 4, 39, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277498876, 'issue_id': 2457087120, 'author': 'eladkal', 'body': 'Can you fix the static checks?', 'created_at': datetime.datetime(2024, 8, 9, 9, 5, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278573614, 'issue_id': 2457087120, 'author': 'artemSSSS', 'body': 'All checks have passed', 'created_at': datetime.datetime(2024, 8, 9, 19, 7, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303884108, 'issue_id': 2457087120, 'author': 'uranusjr', 'body': 'Should this be considered a bugfix and backported to 2.10?', 'created_at': datetime.datetime(2024, 8, 22, 6, 29, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304028366, 'issue_id': 2457087120, 'author': 'potiuk', 'body': ""> Should this be considered a bugfix and backported to 2.10?\r\n\r\nI'd say so. @artemSSSS - can you please back-port it and make a PR to `v2-10-test` branch ?"", 'created_at': datetime.datetime(2024, 8, 22, 8, 0, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-09 04:39:47 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-08-09 09:05:30 UTC): Can you fix the static checks?

artemSSSS (Issue Creator) on (2024-08-09 19:07:18 UTC): All checks have passed

uranusjr on (2024-08-22 06:29:28 UTC): Should this be considered a bugfix and backported to 2.10?

potiuk on (2024-08-22 08:00:18 UTC): I'd say so. @artemSSSS - can you please back-port it and make a PR to `v2-10-test` branch ?

"
2456804919,pull_request,closed,,Fix tests/models/test_taskinstance.py for Database Isolation Tests,"Related: https://github.com/apache/airflow/pull/41067

Fixes the `tests/models/test_taskinstance.py` for Database Isolation Tests.

Small adjustments on conftest allowing to pass the serialization parameter also for task_instance only creations.

As I was reworking the tests, I needed to notice that the function `get_previous_start_date()` was missing on the pydantic model - added in scope of this PR.

FYI @bugraoz93 ",jscheffl,2024-08-08 23:07:16+00:00,[],2024-08-11 20:41:48+00:00,2024-08-09 17:48:31+00:00,https://github.com/apache/airflow/pull/41344,"[('area:serialization', '')]","[{'comment_id': 2277285781, 'issue_id': 2456804919, 'author': 'bugraoz93', 'body': 'This is used from multiple sources in the tests. Thanks for the change! I think it will make it easy to fix the test using this method from conftest.', 'created_at': datetime.datetime(2024, 8, 9, 7, 6, 36, tzinfo=datetime.timezone.utc)}]","bugraoz93 on (2024-08-09 07:06:36 UTC): This is used from multiple sources in the tests. Thanks for the change! I think it will make it easy to fix the test using this method from conftest.

"
2456749976,pull_request,closed,,Allow setting run_id in xcom_pull method,"Enable users to pull from a different run id that does not match the current task instance's run id.  The current task instance's run id is set as the default if the run_id filter is not specified.  The main use case for this is pulling data from a DAG dependency.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",fredthomsen,2024-08-08 22:31:15+00:00,[],2024-11-12 10:37:52+00:00,2024-11-12 07:02:32+00:00,https://github.com/apache/airflow/pull/41343,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('type:improvement', 'Changelog: Improvements')]","[{'comment_id': 2372030640, 'issue_id': 2456749976, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 24, 18, 39, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2375745357, 'issue_id': 2456749976, 'author': 'fredthomsen', 'body': '@uranusjr is there anything outstanding here?', 'created_at': datetime.datetime(2024, 9, 26, 3, 2, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469334521, 'issue_id': 2456749976, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 12, 0, 14, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470175028, 'issue_id': 2456749976, 'author': 'kunaljubce', 'body': '@uranusjr @eladkal This change seems to have broken mypy provider checks due to an inheritance: \r\n\r\n```\r\nâ†’ pre-commit run --color always --verbose --hook-stage manual mypy-providers --all-files\r\nRun mypy for providers (manual)..........................................Failed\r\n- hook id: mypy-providers\r\n- duration: 95.38s\r\n- exit code: 1\r\n\r\nRunning /opt/airflow/scripts/in_container/run_mypy.sh with arguments:  [\'providers/src/airflow/providers\', \'providers/tests\', \'--namespace-packages\']\r\n\r\nUsing \'uv\' to install Airflow\r\n\r\n\r\nUsing airflow version from current sources\r\n\r\n\r\nUsing \'uv\' to install Airflow\r\n\r\nproviders/tests/system/snowflake/example_snowpark_decorator.py:68: note: ""__call__"" is considered instance variable, to make it class variable use ClassVar[...]\r\nproviders/tests/system/snowflake/example_snowpark_decorator.py:68: note: Error code ""misc"" not covered by ""type: ignore"" comment\r\nproviders/tests/microsoft/conftest.py:133: error: Signature of ""xcom_pull""\r\nincompatible with supertype ""TaskInstance""  [override]\r\n            def xcom_pull(\r\n            ^\r\nproviders/tests/microsoft/conftest.py:133: note:      Superclass:\r\nproviders/tests/microsoft/conftest.py:133: note:          def xcom_pull(task_ids: Union[str, Iterable[str], None] = ..., dag_id: Optional[str] = ..., key: str = ..., include_prior_dates: bool = ..., session: Any = ..., *, map_indexes: Union[int, Iterable[int], None] = ..., default: Any = ..., run_id: Optional[str] = ...) -> Any\r\nproviders/tests/microsoft/conftest.py:133: note:      Subclass:\r\nproviders/tests/microsoft/conftest.py:133: note:          def xcom_pull(self, task_ids: Union[Iterable[str], str, None] = ..., dag_id: Optional[str] = ..., key: str = ..., include_prior_dates: bool = ..., session: Any = ..., *, map_indexes: Union[Iterable[int], int, None] = ..., default: Optional[Any] = ...) -> Any\r\nFound 1 error in 1 file (checked 3334 source files)\r\nError 1 returned\r\n```', 'created_at': datetime.datetime(2024, 11, 12, 10, 36, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470178825, 'issue_id': 2456749976, 'author': 'kunaljubce', 'body': 'Ahh never mind, I see fix pushed by @potiuk in #43920 ðŸ¤­', 'created_at': datetime.datetime(2024, 11, 12, 10, 37, 51, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-09-24 18:39:50 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

fredthomsen (Issue Creator) on (2024-09-26 03:02:13 UTC): @uranusjr is there anything outstanding here?

github-actions[bot] on (2024-11-12 00:14:50 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

kunaljubce on (2024-11-12 10:36:10 UTC): @uranusjr @eladkal This change seems to have broken mypy provider checks due to an inheritance: 

```
â†’ pre-commit run --color always --verbose --hook-stage manual mypy-providers --all-files
Run mypy for providers (manual)..........................................Failed
- hook id: mypy-providers
- duration: 95.38s
- exit code: 1

Running /opt/airflow/scripts/in_container/run_mypy.sh with arguments:  ['providers/src/airflow/providers', 'providers/tests', '--namespace-packages']

Using 'uv' to install Airflow


Using airflow version from current sources


Using 'uv' to install Airflow

providers/tests/system/snowflake/example_snowpark_decorator.py:68: note: ""__call__"" is considered instance variable, to make it class variable use ClassVar[...]
providers/tests/system/snowflake/example_snowpark_decorator.py:68: note: Error code ""misc"" not covered by ""type: ignore"" comment
providers/tests/microsoft/conftest.py:133: error: Signature of ""xcom_pull""
incompatible with supertype ""TaskInstance""  [override]
            def xcom_pull(
            ^
providers/tests/microsoft/conftest.py:133: note:      Superclass:
providers/tests/microsoft/conftest.py:133: note:          def xcom_pull(task_ids: Union[str, Iterable[str], None] = ..., dag_id: Optional[str] = ..., key: str = ..., include_prior_dates: bool = ..., session: Any = ..., *, map_indexes: Union[int, Iterable[int], None] = ..., default: Any = ..., run_id: Optional[str] = ...) -> Any
providers/tests/microsoft/conftest.py:133: note:      Subclass:
providers/tests/microsoft/conftest.py:133: note:          def xcom_pull(self, task_ids: Union[Iterable[str], str, None] = ..., dag_id: Optional[str] = ..., key: str = ..., include_prior_dates: bool = ..., session: Any = ..., *, map_indexes: Union[Iterable[int], int, None] = ..., default: Optional[Any] = ...) -> Any
Found 1 error in 1 file (checked 3334 source files)
Error 1 returned
```

kunaljubce on (2024-11-12 10:37:51 UTC): Ahh never mind, I see fix pushed by @potiuk in #43920 ðŸ¤­

"
2456444995,pull_request,closed,,Fix Gantt Task Tries,"We had a few issues with rendering task tries in the Gantt view during auto-refresh and when switching between dag runs.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-08 19:03:06+00:00,[],2024-08-09 09:57:56+00:00,2024-08-09 09:55:25+00:00,https://github.com/apache/airflow/pull/41342,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2456400914,pull_request,closed,,Setting least permissive securitycontexts possible ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

Added emptyDir volumes for volumes being utilized by airflow and least permissive securityContexts by default. 
closes: #35350 


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JKrehling,2024-08-08 18:34:38+00:00,[],2024-12-30 00:16:21+00:00,2024-12-30 00:16:21+00:00,https://github.com/apache/airflow/pull/41341,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('area:helm-chart', 'Airflow Helm Chart'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2276429337, 'issue_id': 2456400914, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 8, 18, 34, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291400466, 'issue_id': 2456400914, 'author': 'JKrehling', 'body': ""The only thing that doesn't have readonlyfileystem is git-sync because it requires writing to /etc/passwd.  \r\nI could mount /etc/passwd as a configmap to support it but since its just an init container I don't think it's as important to use hardened scc by default. \r\n\r\nI am curious about redis.  \r\nI don't know how prevalently used it is but it might be better to pull the bitnami chart as a dependency."", 'created_at': datetime.datetime(2024, 8, 15, 14, 32, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2381685449, 'issue_id': 2456400914, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 30, 0, 15, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383689969, 'issue_id': 2456400914, 'author': 'JKrehling', 'body': ""I see this got added to a milestone for the 1.16 helm chart release but I'm not sure what else is needed from this PR."", 'created_at': datetime.datetime(2024, 9, 30, 16, 43, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409047498, 'issue_id': 2456400914, 'author': 'potiuk', 'body': 'Generally rebaase and making sure all tests pass. I rebased it. As a new contributor, your workflows need to be approved so any time you rebase and fix you need to ask here (just make a comment without mentioning anyone) - to approve and run your workflow.\r\n\r\nOnce first pr of your will be merged, the workflows will run automatically.', 'created_at': datetime.datetime(2024, 10, 13, 16, 49, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560459466, 'issue_id': 2456400914, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 24, 0, 15, 38, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-08 18:34:44 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

JKrehling (Issue Creator) on (2024-08-15 14:32:02 UTC): The only thing that doesn't have readonlyfileystem is git-sync because it requires writing to /etc/passwd.  
I could mount /etc/passwd as a configmap to support it but since its just an init container I don't think it's as important to use hardened scc by default. 

I am curious about redis.  
I don't know how prevalently used it is but it might be better to pull the bitnami chart as a dependency.

github-actions[bot] on (2024-09-30 00:15:48 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

JKrehling (Issue Creator) on (2024-09-30 16:43:46 UTC): I see this got added to a milestone for the 1.16 helm chart release but I'm not sure what else is needed from this PR.

potiuk on (2024-10-13 16:49:03 UTC): Generally rebaase and making sure all tests pass. I rebased it. As a new contributor, your workflows need to be approved so any time you rebase and fix you need to ask here (just make a comment without mentioning anyone) - to approve and run your workflow.

Once first pr of your will be merged, the workflows will run automatically.

github-actions[bot] on (2024-12-24 00:15:38 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2456235679,pull_request,closed,,Draft: Fix Models Trigger Tests for Database Isolation Tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: https://github.com/apache/airflow/pull/41067
Attempt to fix trigger test via using fixture session and disabling methods which aren't usable in internal_api.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-08 16:49:49+00:00,[],2024-08-11 14:26:14+00:00,2024-08-11 14:26:14+00:00,https://github.com/apache/airflow/pull/41338,"[('area:Triggerer', '')]",[],
2456225635,pull_request,closed,,Fix improper script tag usage for dark theme toggle,"We weren't importing the toggle dark theme js file correctly.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-08 16:43:54+00:00,[],2024-08-08 17:24:05+00:00,2024-08-08 17:19:09+00:00,https://github.com/apache/airflow/pull/41337,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2455873182,pull_request,closed,,fix(graph/index): prevent reading properties of undefined (reading 'id'),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #41332

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",josix,2024-08-08 13:51:58+00:00,[],2024-08-08 17:28:44+00:00,2024-08-08 15:56:57+00:00,https://github.com/apache/airflow/pull/41335,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2455751764,pull_request,closed,,bump uv version to 0.2.34,bump uv version to 0.2.34,dirrao,2024-08-08 13:02:39+00:00,[],2024-08-11 18:56:55+00:00,2024-08-11 18:56:55+00:00,https://github.com/apache/airflow/pull/41334,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2455478593,pull_request,closed,,Allow custom api versions in MSGraphAsyncOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

We also use the MSGraphAsyncOperator to trigger Fabric pipelines, unfortunately the MS Fabric REST API doesn't follow the same versioning convention like MS Graph or PowerBI.  In MS Graph and PowerBI, the version is v1.0, while in Fabric it is v1.  So in order to be able to also invoke MS Fabric endpoints, we had to define the absolute URL instead of the relative one in order to make it work, as with relative url's we where unable to specify v1 as api_version.  This PR solves this issue.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-08-08 10:46:55+00:00,[],2024-10-25 20:02:05+00:00,2024-09-05 09:11:01+00:00,https://github.com/apache/airflow/pull/41331,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2288068395, 'issue_id': 2455478593, 'author': 'dabla', 'body': '@potiuk Could this one also be merged?  It allows using custom API versions, everything seems fine and already tested this solution in our local environment.', 'created_at': datetime.datetime(2024, 8, 14, 7, 44, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288115925, 'issue_id': 2455478593, 'author': 'potiuk', 'body': ""Of course. It's just a metter of making tests pass."", 'created_at': datetime.datetime(2024, 8, 14, 8, 11, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301913426, 'issue_id': 2455478593, 'author': 'potiuk', 'body': 'You will need to make some tests db -tests and apparently `power-bi` connection is not created in older versions of airlfow (why would they be - so some test compat code should be added - creating the connection to make the tests pass for 2.8/2.9.', 'created_at': datetime.datetime(2024, 8, 21, 12, 18, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2305455305, 'issue_id': 2455478593, 'author': 'dabla', 'body': '> You will need to make some tests db -tests and apparently `power-bi` connection is not created in older versions of airlfow (why would they be - so some test compat code should be added - creating the connection to make the tests pass for 2.8/2.9.\r\n\r\nStill, weird those tests start failing now while those where merged by another PR.', 'created_at': datetime.datetime(2024, 8, 22, 19, 11, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308774970, 'issue_id': 2455478593, 'author': 'potiuk', 'body': '> Still, weird those tests start failing now while those where merged by another PR.\r\n\r\nWhat I see now is that ""test_powerbi"" fails - which it looks it needs ""power_bi"" connection from the DB - so it should be \'db test"" - i am not sure if see other ""merged"" things that influence it ?', 'created_at': datetime.datetime(2024, 8, 25, 10, 43, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326159383, 'issue_id': 2455478593, 'author': 'dabla', 'body': '> You will need to make some tests db -tests and apparently `power-bi` connection is not created in older versions of airlfow (why would they be - so some test compat code should be added - creating the connection to make the tests pass for 2.8/2.9.\r\n\r\nShould I just create a Connection instance like for example in test_mssql.py at top of the file?\r\n\r\n```\r\nPYMSSQL_CONN = Connection(\r\n    conn_type=""mssql"", host=""ip"", schema=""share"", login=""username"", password=""password"", port=8081\r\n)\r\n```', 'created_at': datetime.datetime(2024, 9, 3, 10, 24, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326161561, 'issue_id': 2455478593, 'author': 'dabla', 'body': '@potiuk I would also like to have this PR merged for the next providers release as this fixes also fixes proxy issue with PowerBIDatasetRefreshOperator and allows custom api versions to be specified.', 'created_at': datetime.datetime(2024, 9, 3, 10, 25, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326824353, 'issue_id': 2455478593, 'author': 'potiuk', 'body': 'Tests failing though', 'created_at': datetime.datetime(2024, 9, 3, 15, 30, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2328372437, 'issue_id': 2455478593, 'author': 'dabla', 'body': ""> Tests failing though\r\n\r\nYes I'm working on it ;)"", 'created_at': datetime.datetime(2024, 9, 4, 9, 31, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2330989793, 'issue_id': 2455478593, 'author': 'dabla', 'body': '@potiuk I think the PR is ready now', 'created_at': datetime.datetime(2024, 9, 5, 9, 2, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331006696, 'issue_id': 2455478593, 'author': 'potiuk', 'body': 'Indeed.', 'created_at': datetime.datetime(2024, 9, 5, 9, 10, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2331194752, 'issue_id': 2455478593, 'author': 'dabla', 'body': '> Indeed.\r\n\r\nThanks @potiuk', 'created_at': datetime.datetime(2024, 9, 5, 10, 41, 33, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2024-08-14 07:44:10 UTC): @potiuk Could this one also be merged?  It allows using custom API versions, everything seems fine and already tested this solution in our local environment.

potiuk on (2024-08-14 08:11:14 UTC): Of course. It's just a metter of making tests pass.

potiuk on (2024-08-21 12:18:21 UTC): You will need to make some tests db -tests and apparently `power-bi` connection is not created in older versions of airlfow (why would they be - so some test compat code should be added - creating the connection to make the tests pass for 2.8/2.9.

dabla (Issue Creator) on (2024-08-22 19:11:45 UTC): Still, weird those tests start failing now while those where merged by another PR.

potiuk on (2024-08-25 10:43:25 UTC): What I see now is that ""test_powerbi"" fails - which it looks it needs ""power_bi"" connection from the DB - so it should be 'db test"" - i am not sure if see other ""merged"" things that influence it ?

dabla (Issue Creator) on (2024-09-03 10:24:42 UTC): Should I just create a Connection instance like for example in test_mssql.py at top of the file?

```
PYMSSQL_CONN = Connection(
    conn_type=""mssql"", host=""ip"", schema=""share"", login=""username"", password=""password"", port=8081
)
```

dabla (Issue Creator) on (2024-09-03 10:25:57 UTC): @potiuk I would also like to have this PR merged for the next providers release as this fixes also fixes proxy issue with PowerBIDatasetRefreshOperator and allows custom api versions to be specified.

potiuk on (2024-09-03 15:30:36 UTC): Tests failing though

dabla (Issue Creator) on (2024-09-04 09:31:14 UTC): Yes I'm working on it ;)

dabla (Issue Creator) on (2024-09-05 09:02:40 UTC): @potiuk I think the PR is ready now

potiuk on (2024-09-05 09:10:48 UTC): Indeed.

dabla (Issue Creator) on (2024-09-05 10:41:33 UTC): Thanks @potiuk

"
2455465934,pull_request,closed,,Add SIGHUP signal before SIGTERM for task runner termination,"This PR will add the ideal signal sequence for task runner termination mentioned here: https://github.com/apache/airflow/issues/35474#issuecomment-1801988073.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",molcay,2024-08-08 10:40:00+00:00,[],2024-12-06 07:08:37+00:00,2024-12-06 07:08:37+00:00,https://github.com/apache/airflow/pull/41329,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2276356762, 'issue_id': 2455465934, 'author': 'eladkal', 'body': ""Tests are failing. Can you fix them?\r\n```\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_mark_success_no_kill - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_local_task_return_code_metric - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_localtaskjob_maintain_heart_rate - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_mark_failure_on_failure_callback - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_dagrun_timeout_logged_in_task_logs - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_mark_success_on_success_callback - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_success_slow_listeners_executed_kill - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_success_slow_task_not_killed_by_overtime_but_regular_timeout - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_process_sigsegv_error_message - AttributeError: 'Process' object has no attribute 'id'\r\nFAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[fork-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83\r\nFAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[fork-non-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83\r\nFAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[spawn-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83\r\nFAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[spawn-non-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83\r\n```"", 'created_at': datetime.datetime(2024, 8, 8, 17, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284007891, 'issue_id': 2455465934, 'author': 'potiuk', 'body': ""The PR needs to be rebased and conflicts removed - it's actually 149 commits behind main, so rebasing is a good thing."", 'created_at': datetime.datetime(2024, 8, 12, 13, 32, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285601366, 'issue_id': 2455465934, 'author': 'molcay', 'body': 'Hi @eladkal,\r\nI fixed the first part of the failing tests but I did not find a solution for the last 4. If you have any idea how I can approach, please feel free to share them with me.\r\n\r\nHi @potiuk, I rebased and pushed the code again. thank you for the warning', 'created_at': datetime.datetime(2024, 8, 13, 7, 57, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288248416, 'issue_id': 2455465934, 'author': 'VladaZakharova', 'body': 'hi @kaxil @potiuk !\r\nCan you please take a look on the changes? Thanks you!', 'created_at': datetime.datetime(2024, 8, 14, 9, 10, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2293889509, 'issue_id': 2455465934, 'author': 'potiuk', 'body': 'IF I am not mistaken - this one also adds timeout in supervising process. Was that intentional ? (the commint message only mentions adding SIGHUP/SIGTERM) ?', 'created_at': datetime.datetime(2024, 8, 16, 17, 29, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304139636, 'issue_id': 2455465934, 'author': 'molcay', 'body': 'Hi @potiuk,\r\nYes, it was on purpose. I was reading the first discussion and there is this comment written by Taragolis: https://github.com/apache/airflow/issues/35474#issuecomment-1801897704\r\nI was trying to implement the 2nd step also. \r\n\r\nIf you think this is too complicated for single commit, I can split the change into two commits:\r\n- 1 commit for the changes in signaling (reap_process_group function)\r\n- 1 commit for the changes in `local_task_job_runner.py`.\r\n\r\nAlso, One test case (with 4 different parameter groups) is failing. I could not fix the problem with that test case. If you can give me some help, would be very much appreciated!', 'created_at': datetime.datetime(2024, 8, 22, 8, 57, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308829954, 'issue_id': 2455465934, 'author': 'potiuk', 'body': ""Hmm. I am not sure @ashb  - how much this one will be affected by AIP-72? It's quite likely (almost certain) that starting task will be heavily affected in Airflow 3, and since this change is really a new feature. possibly we should defer it till AIP-72 start taking shape."", 'created_at': datetime.datetime(2024, 8, 25, 13, 8, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308829974, 'issue_id': 2455465934, 'author': 'potiuk', 'body': '@ashb?', 'created_at': datetime.datetime(2024, 8, 25, 13, 8, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308845138, 'issue_id': 2455465934, 'author': 'ashb', 'body': ""Yeah the task runner interface is being completed rewritten (poc almost far enough along that I know where it will go and start prs)\n\nI'll also need to re-read the motivation for this as I think right now we do INT -> TERM, so I'll need to see what difference HUP instead would make"", 'created_at': datetime.datetime(2024, 8, 25, 13, 35, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2309758649, 'issue_id': 2455465934, 'author': 'VladaZakharova', 'body': ""Hi @potiuk @ashb ! Can you share please some more details about AIP-72? As i can see, there was a page dedicated to some proposals but not implementation itself.\r\nWe've spent quite some time implementing this, so maybe we can discuss the way our implementation can be used based on your proposals? :)"", 'created_at': datetime.datetime(2024, 8, 26, 9, 24, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2323501360, 'issue_id': 2455465934, 'author': 'potiuk', 'body': ""> Hi @potiuk @ashb ! Can you share please some more details about AIP-72? As i can see, there was a page dedicated to some proposals but not implementation itself. We've spent quite some time implementing this, so maybe we can discuss the way our implementation can be used based on your proposals? :)\r\n\r\nWe are waiting for @ashb POC implementation on that one."", 'created_at': datetime.datetime(2024, 9, 1, 21, 21, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2324285724, 'issue_id': 2455465934, 'author': 'VladaZakharova', 'body': 'Hi @ashb ! Do you have some estimation for implementation of this logic?', 'created_at': datetime.datetime(2024, 9, 2, 9, 39, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2360491308, 'issue_id': 2455465934, 'author': 'VladaZakharova', 'body': 'Hi @potiuk @ashb ! Can we please check the changes again? Is there a way for someone else to review them ?:)', 'created_at': datetime.datetime(2024, 9, 19, 9, 31, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387367367, 'issue_id': 2455465934, 'author': 'potiuk', 'body': ""> Hi @potiuk @ashb ! Can we please check the changes again? Is there a way for someone else to review them ?:)\r\n\r\nI think it would really be sensible to wait for the new implementation to be merged and do it then. It's kinda waste of time (especially that tests are failing) to get it merged before."", 'created_at': datetime.datetime(2024, 10, 2, 0, 48, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484438993, 'issue_id': 2455465934, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 19, 0, 16, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484664520, 'issue_id': 2455465934, 'author': 'potiuk', 'body': 'removed stale.', 'created_at': datetime.datetime(2024, 11, 19, 4, 6, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506098454, 'issue_id': 2455465934, 'author': 'ashb', 'body': ""> This PR will add the ideal signal sequence for task runner termination mentioned here: https://github.com/apache/airflow/issues/35474#issuecomment-1801988073.\r\n\r\n@potiuk Why do we want to send a SIGHUP first? That seems like a very odd signal to send. SIGINT followed by SIGTERM is what Docker/podman/every other container runtime(?) does and feels like a much more normal sequence of signals. Especially given that SIGINT being sent to a python process will raise a KeyboardInterupt signal won't it, where as by default SIGHUP would just kill the process outright (as it doesn't have a default signal handler, so default behaviour is to just exit!)\r\n\r\n@molcay The new implementation has now been merged and lives in https://github.com/apache/airflow/blob/main/task_sdk/src/airflow/sdk/execution_time/supervisor.py (as of today only LocalExecutor has been ported over to use this new code path, other executors will follow soon.) However before spending time to update this PR I'd like Jarek to answer the above Q."", 'created_at': datetime.datetime(2024, 11, 28, 13, 11, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506166072, 'issue_id': 2455465934, 'author': 'potiuk', 'body': '> @potiuk Why do we want to send a SIGHUP first? That seems like a very odd signal to send. SIGINT followed by SIGTERM is what Docker/podman/every other container runtime(?) does and feels like a much more normal sequence of signals. Especially given that SIGINT being sent to a python process will raise a KeyboardInterupt signal won\'t it, where as by default SIGHUP would just kill the process outright (as it doesn\'t have a default signal handler, so default behaviour is to just exit!)\r\n\r\nYes, we could skip SIGHUP, but whatever we do we should clearly document our signal escalation policy. I am not very strong on it because I don\'t think there is a default and always followed path of escalation of signals. HUP/TERM/INT is what I\'ve been using in the past for all kind of processes, because this is what most processes which have not been ""deamon desgined"" will normally experience in their lifecycle.\r\n\r\nGenerally speaking docker sends just ""TERM/KILL"" sequence (without INT) -  `docker stop` (but you can change the TERM by `--signal NN` or you can instruct docker to use another signal by declaring STOPSIGNAL in your Dockerfile or when you build or run your container you can override the default `TERM`: https://docs.docker.com/reference/cli/docker/container/stop/ - so they are really not doing signal escalation except very basic one.\r\n\r\nMore on the why I proposed HUP/TERM/INT/KILL over TERM/INT/KILL:\r\n\r\n* HUP is a signal that is always sent when your terminal disconnects  - so if you have any CLI that you run via AIRFLOW, they should be prepared to handle it as the first thing that happens. Most of the daemons will reload configuration when they receive HUP, most of the CLI programs will handle it exactly the way as if the user disconnected - if they are prepared for being disconnected, they will detach the stdin/stdout and stop writing to it basically (and few other things - switching to ""non-interactive mode""). If not then the programs will stop (and usually in some graceful way if possible). But all the apps generally **should** have a reasonable response to it. Also HUP is something that is not a deliberate action of the user - the idea behind HUP that this is really ""what happens when your connection from terminal breakes""\r\n\r\nI think this is why Docker does not really send HUP, because by default there is no terminal connected to the running app (you have to run your container with `-t` to  get the terminal connected).\r\n\r\nI think airlfow is in a bit different league though - many of the tasks our users run as ""tasks"" are really ""interactive"" CLIs wrapped in airflow tasks, rather than long running docker processes (which is the default mode of docker).\r\n\r\nBut - not so strong about it (see INT below).\r\n\r\n* INT is the weak interruption that is sent to non-interactive programs (or those who switched from interactive to non-interactive mode. It\'s the same which is sent with Ctrl-C, which means that it is deliberate action of the user. \r\nAnd yes - I think what we have here is deliberate action from the ""user"" (""airflow worker"" in this case). So maybe we indeed want to skip the HUP one.\r\n\r\n* TERM is regular, stronger kill request\r\n\r\nWe could also consider QUIT after TERM\r\n\r\n* QUIT - quit is the ""application misbehaves and we **really** want to quit it"". The advantage of using it is that by default in C programs (also Python) it should produce debuggable core-dump. Which is a good idea I think if the process did not respond in reasonable time for TERM. In case of docker, it makes little sense because generally such core-dump would be lost when container exits, so maybe that\'s why they are not using it.\r\n\r\n* KILL - of course, non-ignorable last resort signal \r\n\r\nSo maybe what we really want is `INT/TERM/QUIT/KILL`   ?', 'created_at': datetime.datetime(2024, 11, 28, 13, 46, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506242627, 'issue_id': 2455465934, 'author': 'ashb', 'body': ""My default approach here would be to follow what containers to as these days it's an expected pattern, so TERM -> KILL after timeout. and no other signals. I don't personally see much value in a second quit signal, if it doesn't finish after the first one (wether that is INT, TERM or QUIT) I don't think there's really much value in sending it a second signal -- either it was well-behaved and is busy (in which case what would the task do? Try really hard to stop :grin:?) or it ignored the signal and will ignore this one tho.\r\n\r\nSo my vote is just TERM -> ...timeout ... -> KILL ala Docker.\r\n\r\nGood point about INT on docker, I was remembering wrongly."", 'created_at': datetime.datetime(2024, 11, 28, 14, 24, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506561310, 'issue_id': 2455465934, 'author': 'potiuk', 'body': '> So my vote is just TERM -> ...timeout ... -> KILL ala Docker.\r\n\r\nThe simpler, the better, yes. I am ok with it - as long as we also document the reasoning and the fact that we took deliberate decision on it. \r\n\r\nThe second part is more important than the choice we make as it will effectively become part of the Public Airlfow Interface - users have to know what to expect.', 'created_at': datetime.datetime(2024, 11, 28, 17, 32, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506576044, 'issue_id': 2455465934, 'author': 'potiuk', 'body': 'Also we should document (alongside the escalation of signals) whether we send signal to the process or to process group and whether we have separate process group.  \r\n\r\nThis makes a lot of difference. \r\n\r\nFor example we have whole section of it and handling it differently for celery workers because signal propagation for Celery should work differently than for most other cases https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation (in celery we cannot send signals in docker to the whole process group for example if we want celery to handle putting the workers in offline state, but for all other containers we want to send signals to the whole process group in order to make sure we kill everything regardless if signals are properly propagated - for example to handle bash that does not propagate signals to it\'s children).\r\n\r\nSo we need to make deliberate decision on that one as well. @ashb - what\'s your thinking on process groups and signal propagation?\r\n\r\nI personally think we should create a new process group when we create ""task"" process and send the signal to the whole process group, not just to the process. WDYT?', 'created_at': datetime.datetime(2024, 11, 28, 17, 39, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506804789, 'issue_id': 2455465934, 'author': 'ashb', 'body': '@kaxil has made a start on a decent TERM->KILL in https://github.com/apache/airflow/pull/44465, though yes, we will need to document this and handle process groups etc.', 'created_at': datetime.datetime(2024, 11, 28, 22, 11, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518434562, 'issue_id': 2455465934, 'author': 'molcay', 'body': ""> > This PR will add the ideal signal sequence for task runner termination mentioned here: [#35474 (comment)](https://github.com/apache/airflow/issues/35474#issuecomment-1801988073).\r\n> \r\n> @potiuk Why do we want to send a SIGHUP first? That seems like a very odd signal to send. SIGINT followed by SIGTERM is what Docker/podman/every other container runtime(?) does and feels like a much more normal sequence of signals. Especially given that SIGINT being sent to a python process will raise a KeyboardInterupt signal won't it, where as by default SIGHUP would just kill the process outright (as it doesn't have a default signal handler, so default behaviour is to just exit!)\r\n> \r\n> @molcay The new implementation has now been merged and lives in https://github.com/apache/airflow/blob/main/task_sdk/src/airflow/sdk/execution_time/supervisor.py (as of today only LocalExecutor has been ported over to use this new code path, other executors will follow soon.) However before spending time to update this PR I'd like Jarek to answer the above Q.\r\n\r\nI read the discussion and  thank you for the discussion, it was illuminating for me :)\r\nAs far as I understand, there is no need for this implementation (after #44465), right?"", 'created_at': datetime.datetime(2024, 12, 4, 19, 54, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522289332, 'issue_id': 2455465934, 'author': 'potiuk', 'body': '> I read the discussion and thank you for the discussion, it was illuminating for me :)\r\n> As far as I understand, there is no need for this implementation (after #44465), right?\r\n\r\nIndeed - we can close it. There is still open point  about sending signals to process group and creating new process group, in order to handle things like bash not propagating signals by default. https://github.com/apache/airflow/pull/44465#discussion_r1863114700  (I am not sure if there was a new PR for that - I am catching up with opened PRs after some private errands).', 'created_at': datetime.datetime(2024, 12, 6, 7, 8, 33, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-08 17:49:00 UTC): Tests are failing. Can you fix them?
```
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_mark_success_no_kill - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_local_task_return_code_metric - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_localtaskjob_maintain_heart_rate - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_mark_failure_on_failure_callback - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_dagrun_timeout_logged_in_task_logs - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_mark_success_on_success_callback - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_success_slow_listeners_executed_kill - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_success_slow_task_not_killed_by_overtime_but_regular_timeout - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestLocalTaskJob::test_process_sigsegv_error_message - AttributeError: 'Process' object has no attribute 'id'
FAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[fork-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83
FAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[fork-non-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83
FAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[spawn-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83
FAILED tests/jobs/test_local_task_job.py::TestSigtermOnRunner::test_process_sigterm_works_with_retries[spawn-non-daemon] - airflow.exceptions.AirflowTaskTimeout: Timeout during waiting callback, PID: 83
```

potiuk on (2024-08-12 13:32:32 UTC): The PR needs to be rebased and conflicts removed - it's actually 149 commits behind main, so rebasing is a good thing.

molcay (Issue Creator) on (2024-08-13 07:57:31 UTC): Hi @eladkal,
I fixed the first part of the failing tests but I did not find a solution for the last 4. If you have any idea how I can approach, please feel free to share them with me.

Hi @potiuk, I rebased and pushed the code again. thank you for the warning

VladaZakharova on (2024-08-14 09:10:33 UTC): hi @kaxil @potiuk !
Can you please take a look on the changes? Thanks you!

potiuk on (2024-08-16 17:29:30 UTC): IF I am not mistaken - this one also adds timeout in supervising process. Was that intentional ? (the commint message only mentions adding SIGHUP/SIGTERM) ?

molcay (Issue Creator) on (2024-08-22 08:57:56 UTC): Hi @potiuk,
Yes, it was on purpose. I was reading the first discussion and there is this comment written by Taragolis: https://github.com/apache/airflow/issues/35474#issuecomment-1801897704
I was trying to implement the 2nd step also. 

If you think this is too complicated for single commit, I can split the change into two commits:
- 1 commit for the changes in signaling (reap_process_group function)
- 1 commit for the changes in `local_task_job_runner.py`.

Also, One test case (with 4 different parameter groups) is failing. I could not fix the problem with that test case. If you can give me some help, would be very much appreciated!

potiuk on (2024-08-25 13:08:03 UTC): Hmm. I am not sure @ashb  - how much this one will be affected by AIP-72? It's quite likely (almost certain) that starting task will be heavily affected in Airflow 3, and since this change is really a new feature. possibly we should defer it till AIP-72 start taking shape.

potiuk on (2024-08-25 13:08:08 UTC): @ashb?

ashb on (2024-08-25 13:35:17 UTC): Yeah the task runner interface is being completed rewritten (poc almost far enough along that I know where it will go and start prs)

I'll also need to re-read the motivation for this as I think right now we do INT -> TERM, so I'll need to see what difference HUP instead would make

VladaZakharova on (2024-08-26 09:24:41 UTC): Hi @potiuk @ashb ! Can you share please some more details about AIP-72? As i can see, there was a page dedicated to some proposals but not implementation itself.
We've spent quite some time implementing this, so maybe we can discuss the way our implementation can be used based on your proposals? :)

potiuk on (2024-09-01 21:21:49 UTC): We are waiting for @ashb POC implementation on that one.

VladaZakharova on (2024-09-02 09:39:14 UTC): Hi @ashb ! Do you have some estimation for implementation of this logic?

VladaZakharova on (2024-09-19 09:31:43 UTC): Hi @potiuk @ashb ! Can we please check the changes again? Is there a way for someone else to review them ?:)

potiuk on (2024-10-02 00:48:48 UTC): I think it would really be sensible to wait for the new implementation to be merged and do it then. It's kinda waste of time (especially that tests are failing) to get it merged before.

github-actions[bot] on (2024-11-19 00:16:01 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

potiuk on (2024-11-19 04:06:32 UTC): removed stale.

ashb on (2024-11-28 13:11:46 UTC): @potiuk Why do we want to send a SIGHUP first? That seems like a very odd signal to send. SIGINT followed by SIGTERM is what Docker/podman/every other container runtime(?) does and feels like a much more normal sequence of signals. Especially given that SIGINT being sent to a python process will raise a KeyboardInterupt signal won't it, where as by default SIGHUP would just kill the process outright (as it doesn't have a default signal handler, so default behaviour is to just exit!)

@molcay The new implementation has now been merged and lives in https://github.com/apache/airflow/blob/main/task_sdk/src/airflow/sdk/execution_time/supervisor.py (as of today only LocalExecutor has been ported over to use this new code path, other executors will follow soon.) However before spending time to update this PR I'd like Jarek to answer the above Q.

potiuk on (2024-11-28 13:46:10 UTC): Yes, we could skip SIGHUP, but whatever we do we should clearly document our signal escalation policy. I am not very strong on it because I don't think there is a default and always followed path of escalation of signals. HUP/TERM/INT is what I've been using in the past for all kind of processes, because this is what most processes which have not been ""deamon desgined"" will normally experience in their lifecycle.

Generally speaking docker sends just ""TERM/KILL"" sequence (without INT) -  `docker stop` (but you can change the TERM by `--signal NN` or you can instruct docker to use another signal by declaring STOPSIGNAL in your Dockerfile or when you build or run your container you can override the default `TERM`: https://docs.docker.com/reference/cli/docker/container/stop/ - so they are really not doing signal escalation except very basic one.

More on the why I proposed HUP/TERM/INT/KILL over TERM/INT/KILL:

* HUP is a signal that is always sent when your terminal disconnects  - so if you have any CLI that you run via AIRFLOW, they should be prepared to handle it as the first thing that happens. Most of the daemons will reload configuration when they receive HUP, most of the CLI programs will handle it exactly the way as if the user disconnected - if they are prepared for being disconnected, they will detach the stdin/stdout and stop writing to it basically (and few other things - switching to ""non-interactive mode""). If not then the programs will stop (and usually in some graceful way if possible). But all the apps generally **should** have a reasonable response to it. Also HUP is something that is not a deliberate action of the user - the idea behind HUP that this is really ""what happens when your connection from terminal breakes""

I think this is why Docker does not really send HUP, because by default there is no terminal connected to the running app (you have to run your container with `-t` to  get the terminal connected).

I think airlfow is in a bit different league though - many of the tasks our users run as ""tasks"" are really ""interactive"" CLIs wrapped in airflow tasks, rather than long running docker processes (which is the default mode of docker).

But - not so strong about it (see INT below).

* INT is the weak interruption that is sent to non-interactive programs (or those who switched from interactive to non-interactive mode. It's the same which is sent with Ctrl-C, which means that it is deliberate action of the user. 
And yes - I think what we have here is deliberate action from the ""user"" (""airflow worker"" in this case). So maybe we indeed want to skip the HUP one.

* TERM is regular, stronger kill request

We could also consider QUIT after TERM

* QUIT - quit is the ""application misbehaves and we **really** want to quit it"". The advantage of using it is that by default in C programs (also Python) it should produce debuggable core-dump. Which is a good idea I think if the process did not respond in reasonable time for TERM. In case of docker, it makes little sense because generally such core-dump would be lost when container exits, so maybe that's why they are not using it.

* KILL - of course, non-ignorable last resort signal 

So maybe what we really want is `INT/TERM/QUIT/KILL`   ?

ashb on (2024-11-28 14:24:13 UTC): My default approach here would be to follow what containers to as these days it's an expected pattern, so TERM -> KILL after timeout. and no other signals. I don't personally see much value in a second quit signal, if it doesn't finish after the first one (wether that is INT, TERM or QUIT) I don't think there's really much value in sending it a second signal -- either it was well-behaved and is busy (in which case what would the task do? Try really hard to stop :grin:?) or it ignored the signal and will ignore this one tho.

So my vote is just TERM -> ...timeout ... -> KILL ala Docker.

Good point about INT on docker, I was remembering wrongly.

potiuk on (2024-11-28 17:32:47 UTC): The simpler, the better, yes. I am ok with it - as long as we also document the reasoning and the fact that we took deliberate decision on it. 

The second part is more important than the choice we make as it will effectively become part of the Public Airlfow Interface - users have to know what to expect.

potiuk on (2024-11-28 17:39:08 UTC): Also we should document (alongside the escalation of signals) whether we send signal to the process or to process group and whether we have separate process group.  

This makes a lot of difference. 

For example we have whole section of it and handling it differently for celery workers because signal propagation for Celery should work differently than for most other cases https://airflow.apache.org/docs/docker-stack/entrypoint.html#signal-propagation (in celery we cannot send signals in docker to the whole process group for example if we want celery to handle putting the workers in offline state, but for all other containers we want to send signals to the whole process group in order to make sure we kill everything regardless if signals are properly propagated - for example to handle bash that does not propagate signals to it's children).

So we need to make deliberate decision on that one as well. @ashb - what's your thinking on process groups and signal propagation?

I personally think we should create a new process group when we create ""task"" process and send the signal to the whole process group, not just to the process. WDYT?

ashb on (2024-11-28 22:11:05 UTC): @kaxil has made a start on a decent TERM->KILL in https://github.com/apache/airflow/pull/44465, though yes, we will need to document this and handle process groups etc.

molcay (Issue Creator) on (2024-12-04 19:54:41 UTC): I read the discussion and  thank you for the discussion, it was illuminating for me :)
As far as I understand, there is no need for this implementation (after #44465), right?

potiuk on (2024-12-06 07:08:33 UTC): Indeed - we can close it. There is still open point  about sending signals to process group and creating new process group, in order to handle things like bash not propagating signals by default. https://github.com/apache/airflow/pull/44465#discussion_r1863114700  (I am not sure if there was a new PR for that - I am catching up with opened PRs after some private errands).

"
2455396795,pull_request,closed,,Introduce notion of dialects in DbApiHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR introduces the notion of an SQL Dialect class in the DbApiHook.

Let me first elaborate why I did such an approach, this PR is a proposition and can of course be changed where needed but gives an idea on how it could be implemented.  The reason why I wanted to introduce this is because I experienced that the _insert_statement_format and _replace_statement_format string formatting properties in the `DbApiHook` are a bit of a naÃ¯ve approach.  Yes, this approach is generic and doesn't ty the code to a specific database, hence why I want to introduce some kind of dialect, but it's also limited as the parameters passed to the string format are hard-coded and aren't always sufficient for certain databases.

We, for example are using MsSQL and SAP Hana a lot in our DAG's, and since we are using the `insert_rows` methods as much as possible for inserting/updating data, we liked the approach of the replace parameter which allows you to specify if you want to insert or replace data.  That way all our inserts/replace tasks in our DAG's are using the same generic code independently of which database we want to write to.  We also use the `GenericTransfer` operator across multiple databases that way which is great.  Beside that, we also implemented a custom `SQLInsertRowsOperator` which does the same as the GenericTransfer operator but then get's the data from an XCom instead of another database,  I'll also propose a PR for that once we have a good solution for the current problem we try to solve in this PR.

So the issue with the current approach for automatically generating the replace statement is when we want to use MsSQL.  For SAP Hana it was easy, we just had to override the `replace_statement_format` parameter in the connection extra field and we were done.  For MsSQL that was not possible, that's why I created another [PR](https://github.com/apache/airflow/pull/40836) that is already merged in Airflow for the `MsSqlHook`, in which I override the `_generate_insert_sql` method of the `DbApiHook` to allow a more complex replace statement generation to support the replace option.

The problem with this approach is that this functionality will only work when using the MsSQL connection type (which underneath uses the pymssql library).  Unfortunately, we experienced a lot of [connection issues](https://stackoverflow.com/questions/19348255/pymssql-operationalerror-db-lib-error-message-20009-severity-9) and even deadlocks (later one is maybe unrelated) when writing data to MsSQL using the `MsSQLHook`.  Our DBA suggested using the `OdbcHook`, unfortunately the `OdbcHook` doesn't have the enhanced _generate_insert_sql for MsSQL as `OdbcHook` is agnostic of which database you connect to.  So in order to check if the `OdbcHook` would solve our connection issues with MsSQL, I temporarily patched the `_generate_insert_sql` method of the `OdbcHook` to test if the issues are solved using the `OdbcHook`. 
 So we did a load test and indeed we did not experience any connection issues nor deadlocks and the performance was also a lot better compared to the `MsSqlHook`.  With the `MsSqlHook`, we had to specify the `max_active_tis_per_dag=1` parameter to prevent concurrent tasks and avoid deadlocks, with the `OdbcHook` we didn't have to but once again this can be pure coincidence due to the concurrency nature.

So that's why I started thinking about a more generic approach of this problem, which would work independently of which Connection type you use, and move all the logic to the `DbApiHook`, hence why I wanted to introduce the notion of a `Dialect` which can then be specialized where needed per database.  Of course we would need to think how we want it to be implemented, here I just did a bit of a naÃ¯ve implemented to show the idea.  We are already using this in our Airflow environment through patched code and it works great, now we have to find a way to implement this idea (if accepted) in a good/clean and future proof approach.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-08-08 10:04:56+00:00,[],2025-01-01 10:32:23+00:00,2024-12-31 19:57:20+00:00,https://github.com/apache/airflow/pull/41327,"[('area:providers', ''), ('provider:common-sql', ''), ('provider:microsoft-mssql', '')]","[{'comment_id': 2325860567, 'issue_id': 2455396795, 'author': 'dabla', 'body': '@eladkal and @potiuk what do you think about this implementation?  I would ideally want to use entry points to register the dialects, so that additional dialects can be loaded through different providers, but couldn\'t find such mechanism in the Airflow code base, apparently, according to ChatGPT, it is possible to do it either via a setup.py or via pyproject.toml.  So if you have any suggestions on that case, that would be helpful, unless you guys have other ideas or suggestions or don\'t like the implementation at all of course.  Atm the dialects (for the moment there is only MSSQL) are registered in a hard-coded way in the common-sql provider to make it work, it would be nice if those would be dynamically registered from the dedicated providers.\r\n\r\nBellow the answer from ChatGPT:\r\n\r\n```\r\nWhen dealing with a monolithic repository like Apache Airflow, where the setup for each provider isn\'t handled through separate setup.py or pyproject.toml files, but rather as part of a larger project, you\'ll need to use a different approach to define and register entry points.\r\n\r\nIn the context of Apache Airflow, which uses a monolithic repository structure with multiple providers, you typically interact with entry points through the main projectâ€™s setup configuration. Here\'s how you can handle entry points within such a setup:\r\n\r\nSteps to Define Entry Points in a Monolithic Repo like Airflow\r\nFind the Main setup.py or pyproject.toml:\r\n\r\nIn a monolithic project like Airflow, there will be a main setup.py or pyproject.toml at the root of the repository. This is the file that defines how the entire project is built and installed.\r\nLocate Entry Points Definition:\r\n\r\nLook for a section in the main setup.py or pyproject.toml dedicated to entry points. This section typically aggregates all the entry points from different parts of the project. For Airflow, the entry points for plugins, executors, or other components are defined here.\r\nAdd Your Entry Point:\r\n\r\nModify the entry points section to include your specific entry point. This might involve editing a Python dictionary in setup.py or adding a TOML table in pyproject.toml.\r\nHereâ€™s how you might define an entry point in setup.py for an Airflow provider:\r\n\r\n# In setup.py of the main Airflow project\r\n\r\nsetup(\r\n    # other setup arguments...\r\n    entry_points={\r\n        \'sqlalchemy.dialects\': [\r\n            \'mydb = myprovider.mydialect:MyDialect\',  # Your custom dialect entry point\r\n        ],\r\n        \'airflow.plugins\': [\r\n            \'myplugin = myprovider.myplugin:MyAirflowPlugin\',  # Example of Airflow plugin entry point\r\n        ],\r\n        # other entry points...\r\n    },\r\n    # other setup arguments...\r\n)\r\nIf you\'re using pyproject.toml:\r\n\r\n[project.entry-points.""sqlalchemy.dialects""]\r\nmydb = ""myprovider.mydialect:MyDialect""\r\n\r\n[project.entry-points.""airflow.plugins""]\r\nmyplugin = ""myprovider.myplugin:MyAirflowPlugin""\r\n```', 'created_at': datetime.datetime(2024, 9, 3, 8, 5, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326136008, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'We actually already use entrypoints - the `provider.yaml` ""subset"" is already exposed in providers and various provider\'s capabilities are available this way. They are even automatically extracted from provider.yaml\'s and exported to documentation https://airflow.apache.org/docs/apache-airflow-providers/core-extensions/index.html \r\n\r\nYou can also see decription of it in https://airflow.apache.org/docs/apache-airflow-providers/howto/create-custom-providers.html#custom-provider-packages \r\n\r\nGenerally speaking you will have two do few things:\r\n\r\n* Update `provider.yaml` schema https://github.com/apache/airflow/blob/main/airflow/provider.yaml.schema.json to add dialects\r\n\r\n* Update `proovider.info` schema https://github.com/apache/airflow/blob/main/airflow/provider_info.schema.json  - this is the subset of provider.yaml that gets exposed via provider\'s entrypoint as dictionary\r\n\r\n* Update ProvidersManager https://github.com/apache/airflow/blob/main/airflow/providers_manager.py to discover dialects automatically and expose them via Python API - but with care about efficiency - there is some caching and lazy loading implemented there so you should follow what other components are doing there.\r\n\r\n* Add documentation generation to include dialect information in documentation: https://github.com/apache/airflow/blob/main/docs/exts/providers_packages_ref.py + https://github.com/apache/airflow/blob/main/docs/exts/providers_extensions.py\r\n\r\n* Update `airflow providers` cli to expose that information as well https://github.com/apache/airflow/blob/main/airflow/cli/commands/provider_command.py\r\n\r\n* Add provider.yaml entries for all the providers that need to expose them\r\n\r\nOnce you do it all, the  `breeze release-management prepare-provider-packages` command wil automatically build and expose the dictionaries retrieved from provider.yaml into entrypoints. This is happening dynamically - we are building `pyproject.toml` for providers while preparing the packages from this JINJA templates:\r\n\r\n* [The entrypoint template](https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/templates/get_provider_info_TEMPLATE.py.jinja2)\r\n* [The pyproject template](https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/templates/pyproject_TEMPLATE.toml.jinja2)\r\n\r\nAnother benefit of doing it this way is that ""ProvidersManager"" will see if provider is available directly in airflow sources and when you run `breeze` where providers are just available in `airflow/providers` sources and not installed as separate packages, ProvidersManager will read the dialect information directly from provider.yaml rather than from entrypoint, so inside breeze it will work as if it was installed as package.', 'created_at': datetime.datetime(2024, 9, 3, 10, 12, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326411953, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> We actually already use entrypoints - the `provider.yaml` ""subset"" is already exposed in providers and various provider\'s capabilities are available this way. They are even automatically extracted from provider.yaml\'s and exported to documentation https://airflow.apache.org/docs/apache-airflow-providers/core-extensions/index.html\r\n> \r\n> You can also see decription of it in https://airflow.apache.org/docs/apache-airflow-providers/howto/create-custom-providers.html#custom-provider-packages\r\n> \r\n> Generally speaking you will have two do few things:\r\n> \r\n> * Update `provider.yaml` schema https://github.com/apache/airflow/blob/main/airflow/provider.yaml.schema.json to add dialects\r\n> * Update `proovider.info` schema https://github.com/apache/airflow/blob/main/airflow/provider_info.schema.json  - this is the subset of provider.yaml that gets exposed via provider\'s entrypoint as dictionary\r\n> * Update ProvidersManager https://github.com/apache/airflow/blob/main/airflow/providers_manager.py to discover dialects automatically and expose them via Python API - but with care about efficiency - there is some caching and lazy loading implemented there so you should follow what other components are doing there.\r\n> * Add documentation generation to include dialect information in documentation: https://github.com/apache/airflow/blob/main/docs/exts/providers_packages_ref.py + https://github.com/apache/airflow/blob/main/docs/exts/providers_extensions.py\r\n> * Update `airflow providers` cli to expose that information as well https://github.com/apache/airflow/blob/main/airflow/cli/commands/provider_command.py\r\n> * Add provider.yaml entries for all the providers that need to expose them\r\n> \r\n> Once you do it all, the `breeze release-management prepare-provider-packages` command wil automatically build and expose the dictionaries retrieved from provider.yaml into entrypoints. This is happening dynamically - we are building `pyproject.toml` for providers while preparing the packages from this JINJA templates:\r\n> \r\n> * [The entrypoint template](https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/templates/get_provider_info_TEMPLATE.py.jinja2)\r\n> * [The pyproject template](https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/templates/pyproject_TEMPLATE.toml.jinja2)\r\n> \r\n> Another benefit of doing it this way is that ""ProvidersManager"" will see if provider is available directly in airflow sources and when you run `breeze` where providers are just available in `airflow/providers` sources and not installed as separate packages, ProvidersManager will read the dialect information directly from provider.yaml rather than from entrypoint, so inside breeze it will work as if it was installed as package.\r\n\r\nThank you @potiuk for the explanation, will have a look at it and see how to implement it for common sql provider.  Another question, at the moment the MsSqlDialect class is also located within the common sql provider just so that it works but where would you put it?\r\n\r\n1. in another new (mssql) dialect provider (bit overkill for just a dialect I would say, unless we would create a dialects provider but still seems odd to me)?\r\n2. or in the mssql provider (but that one is actually only needed for pymssql and in fact not necessary for odbc, but seems most logical)?', 'created_at': datetime.datetime(2024, 9, 3, 12, 35, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326559107, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'I think in mssql provider, we do have a few ""loosely related"" things in providers  already and cross-provider dependencies (both explicit and implicit) and sometimes where things are ""between"" we make arbitrary decisions.\r\n\r\nWhen we introduced providers we implement a bit ""soft and not 100% compilable"" rule on where to put such things and the rule is ....\r\n\r\n""Where it would be likely maintained best by the major stakeholder of the provider - assuming there is one""\r\n\r\nFor example when we have S3 -> GCS transfer operator we put it in Google Provider and GCS-> S3 we put it in Amazon provider. The very ""soft"" and ""political"" reason for that is that Amazon will be keen on bringing data from GCS and migrating people over from Google and Google will be keen on bringing the data from S3 to GCS.\r\n\r\nNot very scientific, I know and sometimes you can argue the decision, but it\'s best ""rule of thumb"" we can have on that.\r\n\r\nSo Assuming that Microsoft (which is not happening BTW) is the key stakeholder in `mssql` provider - would they want to maintain ODBC dialect there? I certainly think so. Is there anyone who owns ""ODBC"" who would be interested in maintaining MSSQL dialect there ? While ODBC came from Microsoft, it\'s a long time ""de-facto"" standard and there are some independent bodies that standardized the specification https://en.wikipedia.org/wiki/Open_Database_Connectivity - so I think those standard bodies would prefer each ""specific"" dialect is maintained by whoever is interested in the particular dialect.\r\n\r\nSo `mssql` seems like a good place to put it.', 'created_at': datetime.datetime(2024, 9, 3, 13, 40, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326753141, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> I think in mssql provider, we do have a few ""loosely related"" things in providers already and cross-provider dependencies (both explicit and implicit) and sometimes where things are ""between"" we make arbitrary decisions.\r\n> \r\n> When we introduced providers we implement a bit ""soft and not 100% compilable"" rule on where to put such things and the rule is ....\r\n> \r\n> ""Where it would be likely maintained best by the major stakeholder of the provider - assuming there is one""\r\n> \r\n> For example when we have S3 -> GCS transfer operator we put it in Google Provider and GCS-> S3 we put it in Amazon provider. The very ""soft"" and ""political"" reason for that is that Amazon will be keen on bringing data from GCS and migrating people over from Google and Google will be keen on bringing the data from S3 to GCS.\r\n> \r\n> Not very scientific, I know and sometimes you can argue the decision, but it\'s best ""rule of thumb"" we can have on that.\r\n> \r\n> So Assuming that Microsoft (which is not happening BTW) is the key stakeholder in `mssql` provider - would they want to maintain ODBC dialect there? I certainly think so. Is there anyone who owns ""ODBC"" who would be interested in maintaining MSSQL dialect there ? While ODBC came from Microsoft, it\'s a long time ""de-facto"" standard and there are some independent bodies that standardized the specification https://en.wikipedia.org/wiki/Open_Database_Connectivity - so I think those standard bodies would prefer each ""specific"" dialect is maintained by whoever is interested in the particular dialect.\r\n> \r\n> So `mssql` seems like a good place to put it.\r\n\r\nThank you @jarek for your fast and elaborate answer, what you are saying makes sense and is indeed logical.  Will try to implement those changes as quickly as possible.  Thanks again :)', 'created_at': datetime.datetime(2024, 9, 3, 15, 0, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2376522499, 'issue_id': 2455396795, 'author': 'dabla', 'body': ""@eladkal @potiuk \r\n\r\nI'm getting following error, I know what it means but don't understand what it causes:\r\n\r\n```\r\nFound 5 errors in providers\r\nError: The `airflow.providers.apache.hive.transfers.mssql_to_hive` object in transfers list in airflow/providers/apache/hive/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined\r\nError: The `airflow.providers.google.cloud.transfers.mssql_to_gcs` object in transfers list in airflow/providers/google/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined\r\nError: The `airflow.providers.google.cloud.transfers.bigquery_to_mssql` object in transfers list in airflow/providers/google/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined\r\nError: The `airflow.providers.microsoft.mssql.hooks.mssql.MsSqlHook` object in connection-types list in airflow/providers/microsoft/mssql/provider.yaml does not exist or is not a class: name 'TYPE_CHECKING' is not defined\r\nError: The `airflow.providers.microsoft.mssql.hooks.mssql` object in hooks list in airflow/providers/microsoft/mssql/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined\r\nError 1 returned\r\nChanged ownership of 3 files back to 1001:127.\r\n/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/tempfile.py:830: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmperqkniqg'>\r\n  _warnings.warn(warn_message, ResourceWarning)\r\n```"", 'created_at': datetime.datetime(2024, 9, 26, 10, 10, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396867467, 'issue_id': 2455396795, 'author': 'dabla', 'body': '@potiuk As I needed to add the dialects notion to ProvidersManager, and the common sql provider now needs the dialects from the ProvidersManager, I also had to change the min required Airflow version to the current one in the common sql provider.yaml.  Currently the version of the common sql provider is 1.17.1, I suppose this now will have to change to 1.18.0?  If so how do I do this for one provider?  Is there a breeze command for that?  This change would also mean that all sql dependant providers would required Airflow 3.0', 'created_at': datetime.datetime(2024, 10, 7, 13, 1, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397892461, 'issue_id': 2455396795, 'author': 'potiuk', 'body': '> Currently the version of the common sql provider is 1.17.1, I suppose this now will have to change to 1.18.0? If so how do I do this for one provider?\r\n\r\nThis can be done by adding >= in provider.yaml in dependencies (`apache-airflow-providers-common-sql>=1.18.0` - it\'s all that it needs.\r\n\r\n> This change would also mean that all sql dependant providers would required Airflow 3.0\r\n\r\nThat\'s probably out of the question for now. We don\'t really want that. This should be turned in optional feature of the provider and should work also for Airflow 2 in backwards-compatible way (until min-airflow-version for the providers is set to 3.0 - which is no sooner than say 12 months after 3.0 is out most likely - we have not decided yet for how long we will be supporting provifders for Airflow 2.\r\n\r\nThis is all possible. Provider-info is extendable - so if provider exposes new entries in provider-info, they will be ignored by Airflow 2\'s providers manager. So basically we need to make sure that sql providers (and common.sql provider) installed on Airlfow 2 will continue to work. This should be actually even automatically tested by our ""Provider compatibility check"" - which work in the way that they build provider packages, install them for Airflow 2.8, 2.9, 2.10 (and 2.11 in the future) and run test suite from main to test if they continue to work. The test suite will need to be written in the way to handle those tests - so for example all ""dialect discovery"" tests should be skipped when Airflow 2 is used - this is all described in https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#compatibility-provider-unit-tests-against-older-airflow-releases', 'created_at': datetime.datetime(2024, 10, 7, 21, 4, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399152180, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> > Currently the version of the common sql provider is 1.17.1, I suppose this now will have to change to 1.18.0? If so how do I do this for one provider?\r\n> \r\n> This can be done by adding >= in provider.yaml in dependencies (`apache-airflow-providers-common-sql>=1.18.0` - it\'s all that it needs.\r\n> \r\n> > This change would also mean that all sql dependant providers would required Airflow 3.0\r\n> \r\n> That\'s probably out of the question for now. We don\'t really want that. This should be turned in optional feature of the provider and should work also for Airflow 2 in backwards-compatible way (until min-airflow-version for the providers is set to 3.0 - which is no sooner than say 12 months after 3.0 is out most likely - we have not decided yet for how long we will be supporting provifders for Airflow 2.\r\n> \r\n> This is all possible. Provider-info is extendable - so if provider exposes new entries in provider-info, they will be ignored by Airflow 2\'s providers manager. So basically we need to make sure that sql providers (and common.sql provider) installed on Airlfow 2 will continue to work. This should be actually even automatically tested by our ""Provider compatibility check"" - which work in the way that they build provider packages, install them for Airflow 2.8, 2.9, 2.10 (and 2.11 in the future) and run test suite from main to test if they continue to work. The test suite will need to be written in the way to handle those tests - so for example all ""dialect discovery"" tests should be skipped when Airflow 2 is used - this is all described in https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#compatibility-provider-unit-tests-against-older-airflow-releases\r\n\r\nHello @potiuk, ok, I\'ve updated the code so it has a fallback mechanism if Airflow isn\'t 3.0.0 yet.  I also added a [test](https://github.com/apache/airflow/pull/41327/files#diff-a91bec33e53465a63ae38047552046160a3d20976fddd3942cb27ba6cbefbd62R287) which will start to fail once min airflow version for common sql provider is 3.0.0 so we don\'t forget to remove the code for backward compatibility.', 'created_at': datetime.datetime(2024, 10, 8, 8, 10, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399155321, 'issue_id': 2455396795, 'author': 'dabla', 'body': ""> > Currently the version of the common sql provider is 1.17.1, I suppose this now will have to change to 1.18.0? If so how do I do this for one provider?\r\n> \r\n> This can be done by adding >= in provider.yaml in dependencies (`apache-airflow-providers-common-sql>=1.18.0` - it's all that it needs.\r\n> \r\n\r\nWhat I meant here was how do I update the apache-airflow-providers-common-sql version to 1.18.0?"", 'created_at': datetime.datetime(2024, 10, 8, 8, 11, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404127481, 'issue_id': 2455396795, 'author': 'dabla', 'body': 'I have something weird going on with mysql integration tests, this PR hasn\'t changed anything (directly at least) related to MySQL:\r\n\r\n```\r\nWarnings saved into /files/warnings-operators-mysql.txt file.\r\n=========================== short test summary info ============================\r\nFAILED tests/operators/test_generic_transfer.py::TestMySql::test_mysql_to_mysql[mysqlclient] - MySQLdb.ProgrammingError: (1064, ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (\' at line 1"")\r\nFAILED tests/operators/test_generic_transfer.py::TestMySql::test_mysql_to_mysql[mysql-connector-python] - MySQLdb.ProgrammingError: (1064, ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (\' at line 1"")\r\n```\r\n\r\nI\'ve enabled logging of generated insert SQL statement used by the insert_rows method in GenericTransfer:\r\n\r\n```\r\nINFO  [airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook] Generated sql: INSERT INTO test_mysql_to_mysql (id, conn_id, conn_type, description, host, schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\r\nERROR [airflow.task] Task failed with exception\r\nTraceback (most recent call last):\r\n  File ""/opt/airflow/airflow/models/taskinstance.py"", line 761, in _execute_task\r\n    result = _execute_callable(context=context, **execute_callable_kwargs)\r\n  File ""/opt/airflow/airflow/models/taskinstance.py"", line 727, in _execute_callable\r\n    return ExecutionCallableRunner(\r\n  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 258, in run\r\n    return self.func(*args, **kwargs)\r\n  File ""/opt/airflow/airflow/models/baseoperator.py"", line 407, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File ""/opt/airflow/airflow/operators/generic_transfer.py"", line 108, in execute\r\n    insert_rows(table=self.destination_table, rows=results, **self.insert_args)\r\n  File ""/opt/airflow/airflow/providers/common/sql/hooks/sql.py"", line 696, in insert_rows\r\n    cur.execute(sql, values)\r\n  File ""/usr/local/lib/python3.9/site-packages/MySQLdb/cursors.py"", line 179, in execute\r\n    res = self._query(mogrified_query)\r\n  File ""/usr/local/lib/python3.9/site-packages/MySQLdb/cursors.py"", line 330, in _query\r\n    db.query(q)\r\n  File ""/usr/local/lib/python3.9/site-packages/MySQLdb/connections.py"", line 261, in query\r\n    _mysql.connection.query(self, query)\r\nMySQLdb.ProgrammingError: (1064, ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \'schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (\' at line 1"")\r\nINFO  [airflow.models.taskinstance] Marking task as FAILED. dag_id=unit_test_dag, task_id=test_m2m, run_id=manual__2015-01-01T00:00:00+00:00, execution_date=20150101T000000, start_date=20241009T190454, end_date=20241009T190454\r\n```\r\n\r\nThe error makes sense as indeed ""schema"" is a reserved word and should be escaped, but when looking in the MySQLHook I didn\'t find any code which escapes column names in case it\'s a reserved word?  So how come this suddenly starts failing?\r\n\r\nFound the isue.', 'created_at': datetime.datetime(2024, 10, 10, 6, 13, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417503938, 'issue_id': 2455396795, 'author': 'dabla', 'body': '@eladkal @potiuk I think the dialects are ready, what do you guys think?\r\n\r\nA new feature within this PR is that if the developer doesn\'t need to specify the target_fields anymore, those can be resolved automatically through the inspector of the sqlalchemy engine or the specific dialect if it exists.  This feature is disabled by default so we don\'t have an impact on the current behaviour in Airflow.  This is done through the ""core.dbapihook_resolve_target_fields"" configuration parameter I added.  This feature is handy, as you need to specify the target_fields when you want to use the replace (e.g. upsert) functionality in MSSQL and Postgres, so to avoid to have to pass all target_fields manually, which can be a pain when you have a table with lot\'s of columns, the DbApiHook can do it for you as it will try to resolve all target_fields which are insertable (not an identity or autoincrement field or primary key).\r\n\r\nAlso when generating the INSERT/UPSERT sql, the dialect will check if the column name is a reserved word and escape it for the corresponding dialect, the escape format can be changed through the ""_escape_column_name_format"" property of the DbApiHook.\r\n\r\nWe have tested those functionalities on our patched Airflow infra for MySql, MsSql, Postgres and SAP Hana.', 'created_at': datetime.datetime(2024, 10, 16, 17, 46, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435250032, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'That\'s a big one. There are two comments here:\r\n\r\n1) We are rethinking packaging/ providers/plugins APIs and very likely we are going to have several different ""types"" of Airflow extensions - separate secret backends, separate ""operators/hooks providers"", separate log handlers, separate UI plugins. And while this one looks like classic ""operator/hooks type provider"" I think we should decide what to do before we merge that one (we are going to discuss it today at the dev call and discussion will start shortly in devlist I think) \r\n\r\ncc: @kaxil @ashb @vikramkoka \r\n\r\n2) I think that one is good as a ""base"" PR, but once this one is green and we more or less know that the common part is stable, you should split that one into first adding the functionality to provider\'s manager and other common parts (and maybe even split that one), followed by separate change for every provider. That would make it WAY easier to review and is relatively easy to do - this is the favourite way for me to do such changes - because once you get the common part merged, you rebase the ""big"" PR and it gest smaller - and it gets smaller and smaller with every provider added later until it disappears.\r\n\r\nThis helps with fast and effective reviews of such PRs.', 'created_at': datetime.datetime(2024, 10, 24, 13, 7, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435371078, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> That\'s a big one. There are two comments here:\r\n> \r\n> 1. We are rethinking packaging/ providers/plugins APIs and very likely we are going to have several different ""types"" of Airflow extensions - separate secret backends, separate ""operators/hooks providers"", separate log handlers, separate UI plugins. And while this one looks like classic ""operator/hooks type provider"" I think we should decide what to do before we merge that one (we are going to discuss it today at the dev call and discussion will start shortly in devlist I think)\r\n> \r\n> cc: @kaxil @ashb @vikramkoka\r\n> \r\n> 2. I think that one is good as a ""base"" PR, but once this one is green and we more or less know that the common part is stable, you should split that one into first adding the functionality to provider\'s manager and other common parts (and maybe even split that one), followed by separate change for every provider. That would make it WAY easier to review and is relatively easy to do - this is the favourite way for me to do such changes - because once you get the common part merged, you rebase the ""big"" PR and it gest smaller - and it gets smaller and smaller with every provider added later until it disappears.\r\n> \r\n> This helps with fast and effective reviews of such PRs.\r\n\r\nHello Jarek, how do you see the second point?  Shall I start a new PR which only contains main changes to support dialects in common part?', 'created_at': datetime.datetime(2024, 10, 24, 13, 56, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2436288414, 'issue_id': 2455396795, 'author': 'potiuk', 'body': '> Hello Jarek, how do you see the second point? Shall I start a new PR which only contains main changes to support dialects in common part?\r\n\r\nYep', 'created_at': datetime.datetime(2024, 10, 24, 20, 33, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438661211, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'Also - for reference see this PR from @jscheffl :\r\n\r\nOriginal PR: https://github.com/apache/airflow/pull/41729  \r\n\r\nIt has been closed when all the ""split"" PRs have been merged)\r\n\r\n\r\nResulting PRs:\r\n\r\n* https://github.com/apache/airflow/pull/41730\r\n* https://github.com/apache/airflow/pull/41731\r\n* https://github.com/apache/airflow/pull/42046\r\n* https://github.com/apache/airflow/pull/42047\r\n* https://github.com/apache/airflow/pull/42048\r\n* https://github.com/apache/airflow/pull/42049\r\n* https://github.com/apache/airflow/pull/42050\r\n* https://github.com/apache/airflow/pull/42051\r\n* https://github.com/apache/airflow/pull/43139\r\n\r\n(Maybe I do not have all of that right - but this is more or less the idea @dabla )', 'created_at': datetime.datetime(2024, 10, 25, 19, 39, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438686357, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> Also - for reference see this PR from @jscheffl :\r\n> \r\n> Original PR: #41729\r\n> \r\n> It has been closed when all the ""split"" PRs have been merged)\r\n> \r\n> Resulting PRs:\r\n> \r\n> * [AIP-69: Airflow Core adjustments for introduction of Edge Executor\xa0#41730](https://github.com/apache/airflow/pull/41730)\r\n> * [AIP-69: Breeze adjustments for introduction of Edge Executor\xa0#41731](https://github.com/apache/airflow/pull/41731)\r\n> * [AIP-69: Adding Empty Edge Provider Package\xa0#42046](https://github.com/apache/airflow/pull/42046)\r\n> * [AIP-69: Adding Edge Provider DB Models\xa0#42047](https://github.com/apache/airflow/pull/42047)\r\n> * [AIP-69: Add Executor to Edge Provider\xa0#42048](https://github.com/apache/airflow/pull/42048)\r\n> * [AIP-69: Add API and Plugin to Edge Provider\xa0#42049](https://github.com/apache/airflow/pull/42049)\r\n> * [AIP-69: Add CLI to Edge Provider\xa0#42050](https://github.com/apache/airflow/pull/42050)\r\n> * [AIP-69: Add leftover glue of all pieces to Edge Provider\xa0#42051](https://github.com/apache/airflow/pull/42051)\r\n> * [ AIP-69: Breeze adjustments for introduction of Edge Executor (#41731)\xa0#43139](https://github.com/apache/airflow/pull/43139)\r\n> \r\n> (Maybe I do not have all of that right - but this is more or less the idea @dabla )\r\n\r\nThanks Jarek, this is indeed a nice split and good example. I was thinking of first creating a PR defining the dialect in the providers manager and defining the types but without actually implementing it. Anyway will try to split it up in as much little PRs as posisble.', 'created_at': datetime.datetime(2024, 10, 25, 19, 55, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464191358, 'issue_id': 2455396795, 'author': 'dabla', 'body': ""I now have some error regarding an invalid import, but other test cases also import the same without any issues:\r\n\r\n```\r\n________ ERROR collecting providers/tests/common/sql/hooks/test_sql.py _________\r\nImportError while importing test module '/opt/airflow/providers/tests/common/sql/hooks/test_sql.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nproviders/tests/common/sql/hooks/test_sql.py:37: in <module>\r\n    from tests_common.test_utils.compat import AIRFLOW_V_2_8_PLUS\r\nE   ImportError: cannot import name 'AIRFLOW_V_2_8_PLUS' from 'tests_common.test_utils.compat' (/opt/airflow/tests_common/test_utils/compat.py)\r\n```"", 'created_at': datetime.datetime(2024, 11, 8, 9, 10, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469083239, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'Needs rebase now.', 'created_at': datetime.datetime(2024, 11, 11, 21, 41, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470200349, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> Needs rebase now.\r\n\r\nDo you think additional PR will be needed once [43747](https://github.com/apache/airflow/pull/43747) is merged?  Because then only the dialects will be here and the adapted corresponding hooks.  We could split up per dialect implementation (default/mssql/postgres/...)', 'created_at': datetime.datetime(2024, 11, 12, 10, 47, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529369568, 'issue_id': 2455396795, 'author': 'dabla', 'body': ""@potiuk For the backward compatibility, I was wondering maybe we should ditch it here, and only support it for Airflow 3.x  The dialects will work any for native hooks like mssql, mysql and postgres, but wouldn't for odbc/jdbc unless you use Airflow 3.x.  So it would mean everything would work as it worked before, unless you want dialect support with odbc/jdbc, then you'll need Airflow 3.x.  What do you think, because the we could remove the ugly backward compat code for Airflow 2.x and it would also be a good reason to migrate to Airflow 3.x?  I'm refering to [this](https://github.com/apache/airflow/pull/41327/files#diff-c3afa418f798fc0fc7eccbd2c5f071cca39ecd5aaa64af1ae711143b7f31bf07R91) code which I personally don't like very much."", 'created_at': datetime.datetime(2024, 12, 9, 20, 24, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529399390, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'Yes. it could be Airflow 3-only feature. As long as the providers as a whole work for Airlfow 2 as well and we document it well I agree this could be a nice feature of the provider only enabled by migration to Airflow 3. We should have quite a few such incentives.', 'created_at': datetime.datetime(2024, 12, 9, 20, 39, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530861432, 'issue_id': 2455396795, 'author': 'dabla', 'body': ""> Yes. it could be Airflow 3-only feature. As long as the providers as a whole work for Airlfow 2 as well and we document it well I agree this could be a nice feature of the provider only enabled by migration to Airflow 3. We should have quite a few such incentives.\r\n\r\nI was wrong for the last part, it can stay as is, I thought the resolve_dialect methods directly returned the dialect but it's not, it returns a dataclass (e.g. dict) DialectInfo.  So I think it's ok as it is if it's ok for you."", 'created_at': datetime.datetime(2024, 12, 10, 8, 57, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566551465, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'This is really nice- finally had a chance to review it. @dabla  - can you rebase it pleaase :)', 'created_at': datetime.datetime(2024, 12, 31, 15, 51, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566667634, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> This is really nice- finally had a chance to review it. @dabla - can you rebase it pleaase :)\r\n\r\nThanks @potiuk just rebased it ;) and have a good new year!!!', 'created_at': datetime.datetime(2024, 12, 31, 19, 13, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566687755, 'issue_id': 2455396795, 'author': 'potiuk', 'body': 'Well. We have the saying ... what happens for you on New Years Eve - you will do the whole year :)\r\n\r\nHappy New Year', 'created_at': datetime.datetime(2024, 12, 31, 20, 2, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566888167, 'issue_id': 2455396795, 'author': 'eladkal', 'body': '@dabla it would be great to add docs to explain what dialects are, what problem it solves and how to use it. Most of this information is already mentioned in the PR so it just need to be added to the common.sql docs', 'created_at': datetime.datetime(2025, 1, 1, 7, 28, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566933497, 'issue_id': 2455396795, 'author': 'potiuk', 'body': '> @dabla it would be great to add docs to explain what dialects are, what problem it solves and how to use it. Most of this information is already mentioned in the PR so it just need to be added to the common.sql docs\r\n\r\nGood point!', 'created_at': datetime.datetime(2025, 1, 1, 9, 48, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566934807, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> @dabla it would be great to add docs to explain what dialects are, what problem it solves and how to use it. Most of this information is already mentioned in the PR so it just need to be added to the common.sql docs\r\n\r\nYeah will create a new PR for that, also need to explain the new Airlow config parameter (disabled by default) which automatically fills the target_fields if not specified.\r\n\r\nCould one of you guys also check my question in the other [PR](https://github.com/apache/airflow/pull/44809) regarding the GenericTransfer operator?', 'created_at': datetime.datetime(2025, 1, 1, 9, 52, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566944382, 'issue_id': 2455396795, 'author': 'potiuk', 'body': '> Could one of you guys also check my question in the other [PR](https://github.com/apache/airflow/pull/44809) regarding the GenericTransfer operator?\r\n\r\nCan you rebase it and mention us there :) ? Then it will be bumped on top of my list :)', 'created_at': datetime.datetime(2025, 1, 1, 10, 19, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566948820, 'issue_id': 2455396795, 'author': 'dabla', 'body': '> > Could one of you guys also check my question in the other [PR](https://github.com/apache/airflow/pull/44809) regarding the GenericTransfer operator?\r\n> \r\n> Can you rebase it and mention us there :) ? Then it will be bumped on top of my list :)\r\n\r\nYup just did it now thx', 'created_at': datetime.datetime(2025, 1, 1, 10, 32, 22, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2024-09-03 08:05:27 UTC): @eladkal and @potiuk what do you think about this implementation?  I would ideally want to use entry points to register the dialects, so that additional dialects can be loaded through different providers, but couldn't find such mechanism in the Airflow code base, apparently, according to ChatGPT, it is possible to do it either via a setup.py or via pyproject.toml.  So if you have any suggestions on that case, that would be helpful, unless you guys have other ideas or suggestions or don't like the implementation at all of course.  Atm the dialects (for the moment there is only MSSQL) are registered in a hard-coded way in the common-sql provider to make it work, it would be nice if those would be dynamically registered from the dedicated providers.

Bellow the answer from ChatGPT:

```
When dealing with a monolithic repository like Apache Airflow, where the setup for each provider isn't handled through separate setup.py or pyproject.toml files, but rather as part of a larger project, you'll need to use a different approach to define and register entry points.

In the context of Apache Airflow, which uses a monolithic repository structure with multiple providers, you typically interact with entry points through the main projectâ€™s setup configuration. Here's how you can handle entry points within such a setup:

Steps to Define Entry Points in a Monolithic Repo like Airflow
Find the Main setup.py or pyproject.toml:

In a monolithic project like Airflow, there will be a main setup.py or pyproject.toml at the root of the repository. This is the file that defines how the entire project is built and installed.
Locate Entry Points Definition:

Look for a section in the main setup.py or pyproject.toml dedicated to entry points. This section typically aggregates all the entry points from different parts of the project. For Airflow, the entry points for plugins, executors, or other components are defined here.
Add Your Entry Point:

Modify the entry points section to include your specific entry point. This might involve editing a Python dictionary in setup.py or adding a TOML table in pyproject.toml.
Hereâ€™s how you might define an entry point in setup.py for an Airflow provider:

# In setup.py of the main Airflow project

setup(
    # other setup arguments...
    entry_points={
        'sqlalchemy.dialects': [
            'mydb = myprovider.mydialect:MyDialect',  # Your custom dialect entry point
        ],
        'airflow.plugins': [
            'myplugin = myprovider.myplugin:MyAirflowPlugin',  # Example of Airflow plugin entry point
        ],
        # other entry points...
    },
    # other setup arguments...
)
If you're using pyproject.toml:

[project.entry-points.""sqlalchemy.dialects""]
mydb = ""myprovider.mydialect:MyDialect""

[project.entry-points.""airflow.plugins""]
myplugin = ""myprovider.myplugin:MyAirflowPlugin""
```

potiuk on (2024-09-03 10:12:34 UTC): We actually already use entrypoints - the `provider.yaml` ""subset"" is already exposed in providers and various provider's capabilities are available this way. They are even automatically extracted from provider.yaml's and exported to documentation https://airflow.apache.org/docs/apache-airflow-providers/core-extensions/index.html 

You can also see decription of it in https://airflow.apache.org/docs/apache-airflow-providers/howto/create-custom-providers.html#custom-provider-packages 

Generally speaking you will have two do few things:

* Update `provider.yaml` schema https://github.com/apache/airflow/blob/main/airflow/provider.yaml.schema.json to add dialects

* Update `proovider.info` schema https://github.com/apache/airflow/blob/main/airflow/provider_info.schema.json  - this is the subset of provider.yaml that gets exposed via provider's entrypoint as dictionary

* Update ProvidersManager https://github.com/apache/airflow/blob/main/airflow/providers_manager.py to discover dialects automatically and expose them via Python API - but with care about efficiency - there is some caching and lazy loading implemented there so you should follow what other components are doing there.

* Add documentation generation to include dialect information in documentation: https://github.com/apache/airflow/blob/main/docs/exts/providers_packages_ref.py + https://github.com/apache/airflow/blob/main/docs/exts/providers_extensions.py

* Update `airflow providers` cli to expose that information as well https://github.com/apache/airflow/blob/main/airflow/cli/commands/provider_command.py

* Add provider.yaml entries for all the providers that need to expose them

Once you do it all, the  `breeze release-management prepare-provider-packages` command wil automatically build and expose the dictionaries retrieved from provider.yaml into entrypoints. This is happening dynamically - we are building `pyproject.toml` for providers while preparing the packages from this JINJA templates:

* [The entrypoint template](https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/templates/get_provider_info_TEMPLATE.py.jinja2)
* [The pyproject template](https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/templates/pyproject_TEMPLATE.toml.jinja2)

Another benefit of doing it this way is that ""ProvidersManager"" will see if provider is available directly in airflow sources and when you run `breeze` where providers are just available in `airflow/providers` sources and not installed as separate packages, ProvidersManager will read the dialect information directly from provider.yaml rather than from entrypoint, so inside breeze it will work as if it was installed as package.

dabla (Issue Creator) on (2024-09-03 12:35:21 UTC): Thank you @potiuk for the explanation, will have a look at it and see how to implement it for common sql provider.  Another question, at the moment the MsSqlDialect class is also located within the common sql provider just so that it works but where would you put it?

1. in another new (mssql) dialect provider (bit overkill for just a dialect I would say, unless we would create a dialects provider but still seems odd to me)?
2. or in the mssql provider (but that one is actually only needed for pymssql and in fact not necessary for odbc, but seems most logical)?

potiuk on (2024-09-03 13:40:36 UTC): I think in mssql provider, we do have a few ""loosely related"" things in providers  already and cross-provider dependencies (both explicit and implicit) and sometimes where things are ""between"" we make arbitrary decisions.

When we introduced providers we implement a bit ""soft and not 100% compilable"" rule on where to put such things and the rule is ....

""Where it would be likely maintained best by the major stakeholder of the provider - assuming there is one""

For example when we have S3 -> GCS transfer operator we put it in Google Provider and GCS-> S3 we put it in Amazon provider. The very ""soft"" and ""political"" reason for that is that Amazon will be keen on bringing data from GCS and migrating people over from Google and Google will be keen on bringing the data from S3 to GCS.

Not very scientific, I know and sometimes you can argue the decision, but it's best ""rule of thumb"" we can have on that.

So Assuming that Microsoft (which is not happening BTW) is the key stakeholder in `mssql` provider - would they want to maintain ODBC dialect there? I certainly think so. Is there anyone who owns ""ODBC"" who would be interested in maintaining MSSQL dialect there ? While ODBC came from Microsoft, it's a long time ""de-facto"" standard and there are some independent bodies that standardized the specification https://en.wikipedia.org/wiki/Open_Database_Connectivity - so I think those standard bodies would prefer each ""specific"" dialect is maintained by whoever is interested in the particular dialect.

So `mssql` seems like a good place to put it.

dabla (Issue Creator) on (2024-09-03 15:00:12 UTC): Thank you @jarek for your fast and elaborate answer, what you are saying makes sense and is indeed logical.  Will try to implement those changes as quickly as possible.  Thanks again :)

dabla (Issue Creator) on (2024-09-26 10:10:07 UTC): @eladkal @potiuk 

I'm getting following error, I know what it means but don't understand what it causes:

```
Found 5 errors in providers
Error: The `airflow.providers.apache.hive.transfers.mssql_to_hive` object in transfers list in airflow/providers/apache/hive/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined
Error: The `airflow.providers.google.cloud.transfers.mssql_to_gcs` object in transfers list in airflow/providers/google/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined
Error: The `airflow.providers.google.cloud.transfers.bigquery_to_mssql` object in transfers list in airflow/providers/google/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined
Error: The `airflow.providers.microsoft.mssql.hooks.mssql.MsSqlHook` object in connection-types list in airflow/providers/microsoft/mssql/provider.yaml does not exist or is not a class: name 'TYPE_CHECKING' is not defined
Error: The `airflow.providers.microsoft.mssql.hooks.mssql` object in hooks list in airflow/providers/microsoft/mssql/provider.yaml does not exist or is not a module: name 'TYPE_CHECKING' is not defined
Error 1 returned
Changed ownership of 3 files back to 1001:127.
/opt/hostedtoolcache/Python/3.9.20/x64/lib/python3.9/tempfile.py:830: ResourceWarning: Implicitly cleaning up <TemporaryDirectory '/tmp/tmperqkniqg'>
  _warnings.warn(warn_message, ResourceWarning)
```

dabla (Issue Creator) on (2024-10-07 13:01:17 UTC): @potiuk As I needed to add the dialects notion to ProvidersManager, and the common sql provider now needs the dialects from the ProvidersManager, I also had to change the min required Airflow version to the current one in the common sql provider.yaml.  Currently the version of the common sql provider is 1.17.1, I suppose this now will have to change to 1.18.0?  If so how do I do this for one provider?  Is there a breeze command for that?  This change would also mean that all sql dependant providers would required Airflow 3.0

potiuk on (2024-10-07 21:04:09 UTC): This can be done by adding >= in provider.yaml in dependencies (`apache-airflow-providers-common-sql>=1.18.0` - it's all that it needs.


That's probably out of the question for now. We don't really want that. This should be turned in optional feature of the provider and should work also for Airflow 2 in backwards-compatible way (until min-airflow-version for the providers is set to 3.0 - which is no sooner than say 12 months after 3.0 is out most likely - we have not decided yet for how long we will be supporting provifders for Airflow 2.

This is all possible. Provider-info is extendable - so if provider exposes new entries in provider-info, they will be ignored by Airflow 2's providers manager. So basically we need to make sure that sql providers (and common.sql provider) installed on Airlfow 2 will continue to work. This should be actually even automatically tested by our ""Provider compatibility check"" - which work in the way that they build provider packages, install them for Airflow 2.8, 2.9, 2.10 (and 2.11 in the future) and run test suite from main to test if they continue to work. The test suite will need to be written in the way to handle those tests - so for example all ""dialect discovery"" tests should be skipped when Airflow 2 is used - this is all described in https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#compatibility-provider-unit-tests-against-older-airflow-releases

dabla (Issue Creator) on (2024-10-08 08:10:10 UTC): Hello @potiuk, ok, I've updated the code so it has a fallback mechanism if Airflow isn't 3.0.0 yet.  I also added a [test](https://github.com/apache/airflow/pull/41327/files#diff-a91bec33e53465a63ae38047552046160a3d20976fddd3942cb27ba6cbefbd62R287) which will start to fail once min airflow version for common sql provider is 3.0.0 so we don't forget to remove the code for backward compatibility.

dabla (Issue Creator) on (2024-10-08 08:11:33 UTC): What I meant here was how do I update the apache-airflow-providers-common-sql version to 1.18.0?

dabla (Issue Creator) on (2024-10-10 06:13:57 UTC): I have something weird going on with mysql integration tests, this PR hasn't changed anything (directly at least) related to MySQL:

```
Warnings saved into /files/warnings-operators-mysql.txt file.
=========================== short test summary info ============================
FAILED tests/operators/test_generic_transfer.py::TestMySql::test_mysql_to_mysql[mysqlclient] - MySQLdb.ProgrammingError: (1064, ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (' at line 1"")
FAILED tests/operators/test_generic_transfer.py::TestMySql::test_mysql_to_mysql[mysql-connector-python] - MySQLdb.ProgrammingError: (1064, ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (' at line 1"")
```

I've enabled logging of generated insert SQL statement used by the insert_rows method in GenericTransfer:

```
INFO  [airflow.task.hooks.airflow.providers.mysql.hooks.mysql.MySqlHook] Generated sql: INSERT INTO test_mysql_to_mysql (id, conn_id, conn_type, description, host, schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
ERROR [airflow.task] Task failed with exception
Traceback (most recent call last):
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 761, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 727, in _execute_callable
    return ExecutionCallableRunner(
  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 258, in run
    return self.func(*args, **kwargs)
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 407, in wrapper
    return func(self, *args, **kwargs)
  File ""/opt/airflow/airflow/operators/generic_transfer.py"", line 108, in execute
    insert_rows(table=self.destination_table, rows=results, **self.insert_args)
  File ""/opt/airflow/airflow/providers/common/sql/hooks/sql.py"", line 696, in insert_rows
    cur.execute(sql, values)
  File ""/usr/local/lib/python3.9/site-packages/MySQLdb/cursors.py"", line 179, in execute
    res = self._query(mogrified_query)
  File ""/usr/local/lib/python3.9/site-packages/MySQLdb/cursors.py"", line 330, in _query
    db.query(q)
  File ""/usr/local/lib/python3.9/site-packages/MySQLdb/connections.py"", line 261, in query
    _mysql.connection.query(self, query)
MySQLdb.ProgrammingError: (1064, ""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'schema, login, password, port, is_encrypted, is_extra_encrypted, extra) VALUES (' at line 1"")
INFO  [airflow.models.taskinstance] Marking task as FAILED. dag_id=unit_test_dag, task_id=test_m2m, run_id=manual__2015-01-01T00:00:00+00:00, execution_date=20150101T000000, start_date=20241009T190454, end_date=20241009T190454
```

The error makes sense as indeed ""schema"" is a reserved word and should be escaped, but when looking in the MySQLHook I didn't find any code which escapes column names in case it's a reserved word?  So how come this suddenly starts failing?

Found the isue.

dabla (Issue Creator) on (2024-10-16 17:46:20 UTC): @eladkal @potiuk I think the dialects are ready, what do you guys think?

A new feature within this PR is that if the developer doesn't need to specify the target_fields anymore, those can be resolved automatically through the inspector of the sqlalchemy engine or the specific dialect if it exists.  This feature is disabled by default so we don't have an impact on the current behaviour in Airflow.  This is done through the ""core.dbapihook_resolve_target_fields"" configuration parameter I added.  This feature is handy, as you need to specify the target_fields when you want to use the replace (e.g. upsert) functionality in MSSQL and Postgres, so to avoid to have to pass all target_fields manually, which can be a pain when you have a table with lot's of columns, the DbApiHook can do it for you as it will try to resolve all target_fields which are insertable (not an identity or autoincrement field or primary key).

Also when generating the INSERT/UPSERT sql, the dialect will check if the column name is a reserved word and escape it for the corresponding dialect, the escape format can be changed through the ""_escape_column_name_format"" property of the DbApiHook.

We have tested those functionalities on our patched Airflow infra for MySql, MsSql, Postgres and SAP Hana.

potiuk on (2024-10-24 13:07:30 UTC): That's a big one. There are two comments here:

1) We are rethinking packaging/ providers/plugins APIs and very likely we are going to have several different ""types"" of Airflow extensions - separate secret backends, separate ""operators/hooks providers"", separate log handlers, separate UI plugins. And while this one looks like classic ""operator/hooks type provider"" I think we should decide what to do before we merge that one (we are going to discuss it today at the dev call and discussion will start shortly in devlist I think) 

cc: @kaxil @ashb @vikramkoka 

2) I think that one is good as a ""base"" PR, but once this one is green and we more or less know that the common part is stable, you should split that one into first adding the functionality to provider's manager and other common parts (and maybe even split that one), followed by separate change for every provider. That would make it WAY easier to review and is relatively easy to do - this is the favourite way for me to do such changes - because once you get the common part merged, you rebase the ""big"" PR and it gest smaller - and it gets smaller and smaller with every provider added later until it disappears.

This helps with fast and effective reviews of such PRs.

dabla (Issue Creator) on (2024-10-24 13:56:52 UTC): Hello Jarek, how do you see the second point?  Shall I start a new PR which only contains main changes to support dialects in common part?

potiuk on (2024-10-24 20:33:32 UTC): Yep

potiuk on (2024-10-25 19:39:40 UTC): Also - for reference see this PR from @jscheffl :

Original PR: https://github.com/apache/airflow/pull/41729  

It has been closed when all the ""split"" PRs have been merged)


Resulting PRs:

* https://github.com/apache/airflow/pull/41730
* https://github.com/apache/airflow/pull/41731
* https://github.com/apache/airflow/pull/42046
* https://github.com/apache/airflow/pull/42047
* https://github.com/apache/airflow/pull/42048
* https://github.com/apache/airflow/pull/42049
* https://github.com/apache/airflow/pull/42050
* https://github.com/apache/airflow/pull/42051
* https://github.com/apache/airflow/pull/43139

(Maybe I do not have all of that right - but this is more or less the idea @dabla )

dabla (Issue Creator) on (2024-10-25 19:55:34 UTC): Thanks Jarek, this is indeed a nice split and good example. I was thinking of first creating a PR defining the dialect in the providers manager and defining the types but without actually implementing it. Anyway will try to split it up in as much little PRs as posisble.

dabla (Issue Creator) on (2024-11-08 09:10:37 UTC): I now have some error regarding an invalid import, but other test cases also import the same without any issues:

```
________ ERROR collecting providers/tests/common/sql/hooks/test_sql.py _________
ImportError while importing test module '/opt/airflow/providers/tests/common/sql/hooks/test_sql.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
providers/tests/common/sql/hooks/test_sql.py:37: in <module>
    from tests_common.test_utils.compat import AIRFLOW_V_2_8_PLUS
E   ImportError: cannot import name 'AIRFLOW_V_2_8_PLUS' from 'tests_common.test_utils.compat' (/opt/airflow/tests_common/test_utils/compat.py)
```

potiuk on (2024-11-11 21:41:15 UTC): Needs rebase now.

dabla (Issue Creator) on (2024-11-12 10:47:31 UTC): Do you think additional PR will be needed once [43747](https://github.com/apache/airflow/pull/43747) is merged?  Because then only the dialects will be here and the adapted corresponding hooks.  We could split up per dialect implementation (default/mssql/postgres/...)

dabla (Issue Creator) on (2024-12-09 20:24:30 UTC): @potiuk For the backward compatibility, I was wondering maybe we should ditch it here, and only support it for Airflow 3.x  The dialects will work any for native hooks like mssql, mysql and postgres, but wouldn't for odbc/jdbc unless you use Airflow 3.x.  So it would mean everything would work as it worked before, unless you want dialect support with odbc/jdbc, then you'll need Airflow 3.x.  What do you think, because the we could remove the ugly backward compat code for Airflow 2.x and it would also be a good reason to migrate to Airflow 3.x?  I'm refering to [this](https://github.com/apache/airflow/pull/41327/files#diff-c3afa418f798fc0fc7eccbd2c5f071cca39ecd5aaa64af1ae711143b7f31bf07R91) code which I personally don't like very much.

potiuk on (2024-12-09 20:39:41 UTC): Yes. it could be Airflow 3-only feature. As long as the providers as a whole work for Airlfow 2 as well and we document it well I agree this could be a nice feature of the provider only enabled by migration to Airflow 3. We should have quite a few such incentives.

dabla (Issue Creator) on (2024-12-10 08:57:59 UTC): I was wrong for the last part, it can stay as is, I thought the resolve_dialect methods directly returned the dialect but it's not, it returns a dataclass (e.g. dict) DialectInfo.  So I think it's ok as it is if it's ok for you.

potiuk on (2024-12-31 15:51:28 UTC): This is really nice- finally had a chance to review it. @dabla  - can you rebase it pleaase :)

dabla (Issue Creator) on (2024-12-31 19:13:44 UTC): Thanks @potiuk just rebased it ;) and have a good new year!!!

potiuk on (2024-12-31 20:02:42 UTC): Well. We have the saying ... what happens for you on New Years Eve - you will do the whole year :)

Happy New Year

eladkal on (2025-01-01 07:28:52 UTC): @dabla it would be great to add docs to explain what dialects are, what problem it solves and how to use it. Most of this information is already mentioned in the PR so it just need to be added to the common.sql docs

potiuk on (2025-01-01 09:48:48 UTC): Good point!

dabla (Issue Creator) on (2025-01-01 09:52:39 UTC): Yeah will create a new PR for that, also need to explain the new Airlow config parameter (disabled by default) which automatically fills the target_fields if not specified.

Could one of you guys also check my question in the other [PR](https://github.com/apache/airflow/pull/44809) regarding the GenericTransfer operator?

potiuk on (2025-01-01 10:19:41 UTC): Can you rebase it and mention us there :) ? Then it will be bumped on top of my list :)

dabla (Issue Creator) on (2025-01-01 10:32:22 UTC): Yup just did it now thx

"
2455222040,pull_request,closed,,"Add ""@asset"" to decorate a function as a DAG and an asset","## Why
As part of [AIP-75](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=311627076#AIP75NewAssetCentricSyntax-ReferenceanAsset)

## What
Add an `asset` decorator which can be used to decorate a function and create a DAG and an asset.

```python
@asset(uri=""s3://bucket/object"", schedule=None)
def asset2_producer(self, context, asset1_producer):
    print(self)
    print(context[""inlet_events""][asset1_producer])
```

In the example above, it create a `DAG(dag_id=""asset2_producer"", schedule=None, ...)` and an `Asset(name=""asset2_producer"", uri=""s3://bucket/object"")`. Inside the function, `self` can be used to access the asset with name `asset2_producer`, `context` is just like `context` in a normal task and `asset1_producer` is used to access an asset with name=asset1_producer


Closes: https://github.com/apache/airflow/issues/42314",uranusjr,2024-08-08 08:42:32+00:00,[],2024-11-14 14:59:59+00:00,2024-11-14 09:14:46+00:00,https://github.com/apache/airflow/pull/41325,[],"[{'comment_id': 2372030699, 'issue_id': 2455222040, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 24, 18, 39, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2446772859, 'issue_id': 2455222040, 'author': 'Lee-W', 'body': ""@uranusjr I tried to make the `@asset` work and added an example DAG and some unit tests. The next thing I will work on is accessing `self` and `context`. But would be great if you could take a look in advance in case I'm doing something wrong. Thanks!"", 'created_at': datetime.datetime(2024, 10, 30, 11, 38, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475781903, 'issue_id': 2455222040, 'author': 'uranusjr', 'body': 'GitHub seems to have changed something and now I canâ€™t approve my own PR. So consider this as a manual approval. âœ…', 'created_at': datetime.datetime(2024, 11, 14, 9, 4, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475802671, 'issue_id': 2455222040, 'author': 'Lee-W', 'body': '> GitHub seems to have changed something and now I canâ€™t approve my own PR. So consider this as a manual approval. âœ…\r\n\r\nThanks! Let me merge it now', 'created_at': datetime.datetime(2024, 11, 14, 9, 14, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476599806, 'issue_id': 2455222040, 'author': 'potiuk', 'body': '> GitHub seems to have changed something and now I canâ€™t approve my own PR. So consider this as a manual approval. âœ…\r\n\r\nThey are really experimenting with Approvals it seems......', 'created_at': datetime.datetime(2024, 11, 14, 14, 59, 57, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-09-24 18:39:51 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

Lee-W on (2024-10-30 11:38:49 UTC): @uranusjr I tried to make the `@asset` work and added an example DAG and some unit tests. The next thing I will work on is accessing `self` and `context`. But would be great if you could take a look in advance in case I'm doing something wrong. Thanks!

uranusjr (Issue Creator) on (2024-11-14 09:04:38 UTC): GitHub seems to have changed something and now I canâ€™t approve my own PR. So consider this as a manual approval. âœ…

Lee-W on (2024-11-14 09:14:29 UTC): Thanks! Let me merge it now

potiuk on (2024-11-14 14:59:57 UTC): They are really experimenting with Approvals it seems......

"
2454946739,pull_request,closed,,Adds new `triggerer.capacity_left[.<hostname>]` metric,"This PR introduces a new metric for the capacity left on each Triggerer.

After reducing the default capacity our deployment, it is rather close to the total capacity at certain times and having visibility on the remaining capacity becomes more important.

The new metric will enable better alerting and even auto-scaling if wished for. The same can be achieved currently but it requires knowledge of the currently configured capacity, which makes it rather ugly.

Regarding the naming: I initially wanted to prefix the new metric with `triggers.` but decided not to because all `triggers.*` metrics are really just counting/measuring actual triggers. That's why I decided to go with a new prefix `triggerer.` which may be used in the future for more Triggerer specific metrics.",Usiel,2024-08-08 06:07:17+00:00,[],2024-10-02 01:41:11+00:00,2024-10-02 01:41:11+00:00,https://github.com/apache/airflow/pull/41323,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('area:Triggerer', '')]","[{'comment_id': 2372030746, 'issue_id': 2454946739, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 24, 18, 39, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2372869971, 'issue_id': 2454946739, 'author': 'Usiel', 'body': ""I'm still interested in getting this merged. We have been running this as a patch for our clusters for the last 60 days or so and it helped us to get on top of capacity issues."", 'created_at': datetime.datetime(2024, 9, 25, 4, 4, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387470757, 'issue_id': 2454946739, 'author': 'potiuk', 'body': 'LGTM', 'created_at': datetime.datetime(2024, 10, 2, 1, 40, 56, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-09-24 18:39:53 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

Usiel (Issue Creator) on (2024-09-25 04:04:46 UTC): I'm still interested in getting this merged. We have been running this as a patch for our clusters for the last 60 days or so and it helped us to get on top of capacity issues.

potiuk on (2024-10-02 01:40:56 UTC): LGTM

"
2454514874,pull_request,closed,,Fix all tests in Other group for Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

This PR fixes all tests in ""Other"" to be working with Database Isolation Mode - mainly broken tests are skipped with a comment making the PR #41067 green",jscheffl,2024-08-07 23:33:57+00:00,[],2024-08-08 21:18:05+00:00,2024-08-08 21:18:05+00:00,https://github.com/apache/airflow/pull/41322,"[('area:plugins', ''), ('area:lineage', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:Triggerer', '')]","[{'comment_id': 2275948719, 'issue_id': 2454514874, 'author': 'vincbeck', 'body': 'Are you sure the tests are broken and not the underlying function?', 'created_at': datetime.datetime(2024, 8, 8, 14, 17, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276413265, 'issue_id': 2454514874, 'author': 'jscheffl', 'body': '> Are you sure the tests are broken and not the underlying function?\r\n\r\nMain target was to make the ""Other"" tests green in isolation mode allowing to merge #41067 - I\'d propose to qualify this later. But else we don\'t have tests at-all which would mean the already stable functions could degrade.\r\n\r\nSo, yes I did not quality for all tests if the test is failing or the function is broken. There might be some residual risk of broken and un-discovered errors.\r\nDo you have a proposal for better wording of the comment I added to respective skip markers?', 'created_at': datetime.datetime(2024, 8, 8, 18, 23, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276453419, 'issue_id': 2454514874, 'author': 'vincbeck', 'body': '> > Are you sure the tests are broken and not the underlying function?\r\n> \r\n> Main target was to make the ""Other"" tests green in isolation mode allowing to merge #41067 - I\'d propose to qualify this later. But else we don\'t have tests at-all which would mean the already stable functions could degrade.\r\n> \r\n> So, yes I did not quality for all tests if the test is failing or the function is broken. There might be some residual risk of broken and un-discovered errors. Do you have a proposal for better wording of the comment I added to respective skip markers?\r\n\r\nNop, I am fine. I also understand the timeline', 'created_at': datetime.datetime(2024, 8, 8, 18, 50, 12, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-08-08 14:17:50 UTC): Are you sure the tests are broken and not the underlying function?

jscheffl (Issue Creator) on (2024-08-08 18:23:53 UTC): Main target was to make the ""Other"" tests green in isolation mode allowing to merge #41067 - I'd propose to qualify this later. But else we don't have tests at-all which would mean the already stable functions could degrade.

So, yes I did not quality for all tests if the test is failing or the function is broken. There might be some residual risk of broken and un-discovered errors.
Do you have a proposal for better wording of the comment I added to respective skip markers?

vincbeck on (2024-08-08 18:50:12 UTC): Nop, I am fine. I also understand the timeline

"
2454424759,pull_request,closed,,Deprecate implicit default DAG schedule,"Currently, if a DAG is created without the 'schedule' argument, Airflow sets the DAG to run daily. This is almost never what people want, and every best practice tells you to always specify the argument explicitly, but we couldn't change the default due to compatibility considerations.

We can finally change this in Airflow 3.0, but first we need to tell users about it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",uranusjr,2024-08-07 21:59:13+00:00,[],2024-08-30 09:14:13+00:00,2024-08-14 10:50:13+00:00,https://github.com/apache/airflow/pull/41321,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2282852128, 'issue_id': 2454424759, 'author': 'kaxil', 'body': '@uranusjr @ephraimbuddy - Do we need to get this for 2.10.0rc1?', 'created_at': datetime.datetime(2024, 8, 11, 18, 44, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283178774, 'issue_id': 2454424759, 'author': 'uranusjr', 'body': 'Iâ€™m going to do this another way to not break the tests for now. We still need to eventually fix all the tests when we migrate to 3.0, but itâ€™ll buy us some time.', 'created_at': datetime.datetime(2024, 8, 12, 6, 13, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2283227079, 'issue_id': 2454424759, 'author': 'uranusjr', 'body': 'Alternative PR posted https://github.com/apache/airflow/pull/41397', 'created_at': datetime.datetime(2024, 8, 12, 6, 53, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287141021, 'issue_id': 2454424759, 'author': 'potiuk', 'body': 'https://github.com/astronomer/airflow/pull/1512/ -should fix those warnings.', 'created_at': datetime.datetime(2024, 8, 13, 21, 8, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287382099, 'issue_id': 2454424759, 'author': 'uranusjr', 'body': 'This should be ready if CI passes.\r\n\r\n**A backport to the 2.10 branch is needed.**', 'created_at': datetime.datetime(2024, 8, 13, 23, 27, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287385800, 'issue_id': 2454424759, 'author': 'potiuk', 'body': ""> A backport to the 2.10 branch is needed.\r\n\r\nAccording to the new rules it's on the committer who merges it to backport it and create a new PR if I read them right."", 'created_at': datetime.datetime(2024, 8, 13, 23, 30, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287957990, 'issue_id': 2454424759, 'author': 'eladkal', 'body': ""> > A backport to the 2.10 branch is needed.\r\n> \r\n> According to the new rules it's on the committer who merges it to backport it and create a new PR if I read them right.\r\n\r\nI raised https://github.com/apache/airflow/pull/41457 to document the protocols"", 'created_at': datetime.datetime(2024, 8, 14, 6, 31, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288433134, 'issue_id': 2454424759, 'author': 'uranusjr', 'body': 'Finallyâ€¦ now merge and work on bacporting.', 'created_at': datetime.datetime(2024, 8, 14, 10, 50, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2290585497, 'issue_id': 2454424759, 'author': 'malthe', 'body': 's/with/without a â€˜scheduleâ€™ argument.', 'created_at': datetime.datetime(2024, 8, 15, 4, 41, 8, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-08-11 18:44:54 UTC): @uranusjr @ephraimbuddy - Do we need to get this for 2.10.0rc1?

uranusjr (Issue Creator) on (2024-08-12 06:13:43 UTC): Iâ€™m going to do this another way to not break the tests for now. We still need to eventually fix all the tests when we migrate to 3.0, but itâ€™ll buy us some time.

uranusjr (Issue Creator) on (2024-08-12 06:53:31 UTC): Alternative PR posted https://github.com/apache/airflow/pull/41397

potiuk on (2024-08-13 21:08:11 UTC): https://github.com/astronomer/airflow/pull/1512/ -should fix those warnings.

uranusjr (Issue Creator) on (2024-08-13 23:27:11 UTC): This should be ready if CI passes.

**A backport to the 2.10 branch is needed.**

potiuk on (2024-08-13 23:30:42 UTC): According to the new rules it's on the committer who merges it to backport it and create a new PR if I read them right.

eladkal on (2024-08-14 06:31:32 UTC): I raised https://github.com/apache/airflow/pull/41457 to document the protocols

uranusjr (Issue Creator) on (2024-08-14 10:50:07 UTC): Finallyâ€¦ now merge and work on bacporting.

malthe on (2024-08-15 04:41:08 UTC): s/with/without a â€˜scheduleâ€™ argument.

"
2454381873,pull_request,closed,,Fix Variables Tests for Database Isolation Tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: https://github.com/apache/airflow/pull/41067
I think using a fixture session solved the problem before no session was provided for creating and updating objects.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-07 21:27:36+00:00,[],2024-08-08 21:17:55+00:00,2024-08-08 21:17:55+00:00,https://github.com/apache/airflow/pull/41320,[],"[{'comment_id': 2276623280, 'issue_id': 2454381873, 'author': 'bugraoz93', 'body': 'Many thanks for the review and approval, @jscheffl! Could you please merge when you have time?', 'created_at': datetime.datetime(2024, 8, 8, 20, 45, 38, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-08-08 20:45:38 UTC): Many thanks for the review and approval, @jscheffl! Could you please merge when you have time?

"
2454294457,pull_request,closed,,Clarify that the TI try selector only appears when you have multiple tries,"Also refactor the existing note to be an actual note block.

Before:
![Screenshot 2024-08-07 at 2 26 53â€¯PM](https://github.com/user-attachments/assets/77c44599-e5fe-4545-b68b-269c21608852)
![Screenshot 2024-08-07 at 2 27 00â€¯PM](https://github.com/user-attachments/assets/a81f27a2-104a-4296-9087-29e776d373fe)

After:

![Screenshot 2024-08-07 at 2 26 03â€¯PM](https://github.com/user-attachments/assets/bfdfa865-0cbe-4aa0-8de6-29bb970cfd88)
![Screenshot 2024-08-07 at 2 26 13â€¯PM](https://github.com/user-attachments/assets/2328da5b-c596-4010-b802-9143efc9ab05)

",jedcunningham,2024-08-07 20:30:19+00:00,[],2024-08-08 14:30:59+00:00,2024-08-08 05:11:58+00:00,https://github.com/apache/airflow/pull/41319,"[('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('AIP-64', 'Task Instance history')]","[{'comment_id': 2274353200, 'issue_id': 2454294457, 'author': 'merobi-hub', 'body': 'Thanks for adding this helpful clarification @jedcunningham', 'created_at': datetime.datetime(2024, 8, 7, 21, 10, 1, tzinfo=datetime.timezone.utc)}]","merobi-hub on (2024-08-07 21:10:01 UTC): Thanks for adding this helpful clarification @jedcunningham

"
2454185701,pull_request,closed,,Add plugin data to scarf usage data collection,"This will give us counts for the following:

- plugins in use
- flask blueprints
- FAB specific usage
  - custom appbuilder views
  - custom appbuilder menu items
- timetables",jedcunningham,2024-08-07 19:28:43+00:00,[],2024-08-09 05:48:50+00:00,2024-08-08 10:52:20+00:00,https://github.com/apache/airflow/pull/41318,"[('area:webserver', 'Webserver related Issues'), ('type:new-feature', 'Changelog: New Features')]",[],
2454165758,pull_request,closed,,Fixing Object is already attached to session problem for Database Isolation Tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: https://github.com/apache/airflow/pull/41067
Fixes `already attached to the session` problem with passing session object from the fixture.
I have tested with the same parameters running in the `Special tests/Database isolation` test CI and all seems like passing. 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-07 19:17:21+00:00,[],2024-08-07 21:12:50+00:00,2024-08-07 21:12:50+00:00,https://github.com/apache/airflow/pull/41317,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:databricks', '')]","[{'comment_id': 2274311123, 'issue_id': 2454165758, 'author': 'bugraoz93', 'body': ""I was going to merge the PR but I couldn't. I resolved the thread since you said good to go and directly searched the merge button, habits :( @jscheffl Could you please merge the PR when you have time? Many thanks!"", 'created_at': datetime.datetime(2024, 8, 7, 20, 40, 57, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-08-07 20:40:57 UTC): I was going to merge the PR but I couldn't. I resolved the thread since you said good to go and directly searched the merge button, habits :( @jscheffl Could you please merge the PR when you have time? Many thanks!

"
2454146006,pull_request,closed,,Support the unpack operator in signature,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

Support the unpack operator in operator signature.

Closes: #41286

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:



How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jabbera,2024-08-07 19:05:10+00:00,[],2024-10-28 15:03:47+00:00,2024-08-30 06:23:59+00:00,https://github.com/apache/airflow/pull/41316,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2274160028, 'issue_id': 2454146006, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 7, 19, 5, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276163772, 'issue_id': 2454146006, 'author': 'romsharon98', 'body': 'The changes look good â€” great work for a first PR! ðŸ˜‰\r\nI think better add tests [here](https://github.com/apache/airflow/blob/463e28b9ce6b58a64795c96ae7b94aba37770c93/tests/utils/test_operator_helpers.py), let me know what you think.', 'created_at': datetime.datetime(2024, 8, 8, 15, 55, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276300979, 'issue_id': 2454146006, 'author': 'jabbera', 'body': ""> I think better add tests [here](https://github.com/apache/airflow/blob/463e28b9ce6b58a64795c96ae7b94aba37770c93/tests/utils/test_operator_helpers.py), let me know what you think.\r\n\r\n@romsharon98 test_operator_helpers doesn't have the create_ti function/infrastructure that's available in test_python. I could put the determine method under test directly in test_operator_helpers instead of actually executing a task if that's what you mean?"", 'created_at': datetime.datetime(2024, 8, 8, 17, 16, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2281841387, 'issue_id': 2454146006, 'author': 'romsharon98', 'body': ""> > I think better add tests [here](https://github.com/apache/airflow/blob/463e28b9ce6b58a64795c96ae7b94aba37770c93/tests/utils/test_operator_helpers.py), let me know what you think.\r\n> \r\n> @romsharon98 test_operator_helpers doesn't have the create_ti function/infrastructure that's available in test_python. I could put the determine method under test directly in test_operator_helpers instead of actually executing a task if that's what you mean?\r\n\r\nYes, this is what I meant."", 'created_at': datetime.datetime(2024, 8, 10, 13, 42, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2296907593, 'issue_id': 2454146006, 'author': 'jabbera', 'body': '@romsharon98 Sorry for the delay. This is all set. Branch rebased.', 'created_at': datetime.datetime(2024, 8, 19, 15, 54, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2297479711, 'issue_id': 2454146006, 'author': 'romsharon98', 'body': 'changes looks good!\r\nstatic tests failed, better working with [pre-commit](https://github.com/apache/airflow/blob/main/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit) and prevent those errors.', 'created_at': datetime.datetime(2024, 8, 19, 21, 21, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298849502, 'issue_id': 2454146006, 'author': 'jabbera', 'body': '> static tests failed, better working with [pre-commit](https://github.com/apache/airflow/blob/main/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit) and prevent those errors.\r\n\r\nAll set!', 'created_at': datetime.datetime(2024, 8, 20, 13, 21, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2313877524, 'issue_id': 2454146006, 'author': 'jabbera', 'body': 'Hi, is there anything else needed for this PR? Thanks!', 'created_at': datetime.datetime(2024, 8, 28, 0, 55, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2320199146, 'issue_id': 2454146006, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 30, 6, 24, 2, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-07 19:05:14 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

romsharon98 on (2024-08-08 15:55:46 UTC): The changes look good â€” great work for a first PR! ðŸ˜‰
I think better add tests [here](https://github.com/apache/airflow/blob/463e28b9ce6b58a64795c96ae7b94aba37770c93/tests/utils/test_operator_helpers.py), let me know what you think.

jabbera (Issue Creator) on (2024-08-08 17:16:44 UTC): @romsharon98 test_operator_helpers doesn't have the create_ti function/infrastructure that's available in test_python. I could put the determine method under test directly in test_operator_helpers instead of actually executing a task if that's what you mean?

romsharon98 on (2024-08-10 13:42:33 UTC): Yes, this is what I meant.

jabbera (Issue Creator) on (2024-08-19 15:54:06 UTC): @romsharon98 Sorry for the delay. This is all set. Branch rebased.

romsharon98 on (2024-08-19 21:21:55 UTC): changes looks good!
static tests failed, better working with [pre-commit](https://github.com/apache/airflow/blob/main/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit) and prevent those errors.

jabbera (Issue Creator) on (2024-08-20 13:21:34 UTC): All set!

jabbera (Issue Creator) on (2024-08-28 00:55:19 UTC): Hi, is there anything else needed for this PR? Thanks!

boring-cyborg[bot] on (2024-08-30 06:24:02 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2454106968,pull_request,closed,,AIP-59 Performance testing framework,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

Initial version of performance testing framework - AIP-59.

Note: PR created for early review, testing in progress - not ready for merge.

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bjankie1,2024-08-07 18:43:07+00:00,[],2025-01-06 09:41:58+00:00,2024-10-24 00:15:17+00:00,https://github.com/apache/airflow/pull/41315,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2274226069, 'issue_id': 2454106968, 'author': 'vincbeck', 'body': 'Is there any chance you could split up this PR in multiple PRs? 15k lines of code is really hard to review :)', 'created_at': datetime.datetime(2024, 8, 7, 19, 45, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2282954955, 'issue_id': 2454106968, 'author': 'potiuk', 'body': 'Agree. Would be nice to separate out piece by piece and review them in smaller increments. Generally review time is at least O(n^2)', 'created_at': datetime.datetime(2024, 8, 12, 0, 39, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2285464579, 'issue_id': 2454106968, 'author': 'vatsrahul1001', 'body': 'I also suggest breaking this down into separate PRs. Also, can we have some documentation in the README file for installation of airflow_gepard', 'created_at': datetime.datetime(2024, 8, 13, 6, 47, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2295382245, 'issue_id': 2454106968, 'author': 'bjankie1', 'body': 'I will make an attempt to divide the code into several PRs.\r\n1.  Framework for building performance DAGs\r\n1.  Framework for collecting instance metrics in kubernetes.\r\n1.  Framework for collecting instance metrics in Cloud Composer.\r\n1.  Glue code - performance tests execution', 'created_at': datetime.datetime(2024, 8, 18, 20, 33, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420906951, 'issue_id': 2454106968, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 18, 0, 15, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572736639, 'issue_id': 2454106968, 'author': 'mathiaHT', 'body': 'Hello, any update about this ?', 'created_at': datetime.datetime(2025, 1, 6, 9, 41, 57, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-08-07 19:45:41 UTC): Is there any chance you could split up this PR in multiple PRs? 15k lines of code is really hard to review :)

potiuk on (2024-08-12 00:39:31 UTC): Agree. Would be nice to separate out piece by piece and review them in smaller increments. Generally review time is at least O(n^2)

vatsrahul1001 on (2024-08-13 06:47:24 UTC): I also suggest breaking this down into separate PRs. Also, can we have some documentation in the README file for installation of airflow_gepard

bjankie1 (Issue Creator) on (2024-08-18 20:33:45 UTC): I will make an attempt to divide the code into several PRs.
1.  Framework for building performance DAGs
1.  Framework for collecting instance metrics in kubernetes.
1.  Framework for collecting instance metrics in Cloud Composer.
1.  Glue code - performance tests execution

github-actions[bot] on (2024-10-18 00:15:06 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

mathiaHT on (2025-01-06 09:41:57 UTC): Hello, any update about this ?

"
2454009895,pull_request,closed,,Add `languages` field to `get_ui_field_behaviour`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #41010 

Following the context of https://github.com/apache/airflow/issues/41010, add languages to get_ui_field_behaviour to enable the CodeMirror JSON editor for a specific field on the Connection Add/Edit page.

I considered YAML support, but JSON alone should be sufficient for users to define the Connection in the connection hook. I've left room for future modifications if the need arises.

### screenshot: Add Connection for `Kubernetes Cluster Connection`

![image](https://github.com/user-attachments/assets/fe19bc0c-1dec-4b8f-9b30-180577a71a5f)

Previously, the entire textarea was set to be changed to CodeMirror, but now only the fields set with json in languages and `extra` will be changed to CodeMirror.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",softyoungha,2024-08-07 17:45:38+00:00,[],2024-08-24 12:37:33+00:00,2024-08-22 14:35:36+00:00,https://github.com/apache/airflow/pull/41314,"[('provider:google', 'Google (including GCP) related issues'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('provider:apprise', ''), ('provider:yandex', ''), ('provider:ydb', '')]","[{'comment_id': 2303048392, 'issue_id': 2454009895, 'author': 'bbovenzi', 'body': '@jscheffl What are your thoughts?', 'created_at': datetime.datetime(2024, 8, 21, 21, 32, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303065500, 'issue_id': 2454009895, 'author': 'jscheffl', 'body': 'I think the current behavior is not well and deserves an extension. Actually I am wondering how it ever worked because in SnowflakeHook also a private key is expected (like you would see in SSH) and JSON would also be non-appropriate.\r\n\r\nSo thanks for providing an extension.\r\n\r\nI just believe it is at the wrong moment of time. We are currently planning to move on to a Airflow 3 release. For this we need to re-work especially the connection form widgets. So all efforts here would need to be thrown away for Airflow 3. Alongside also we are only accepting new features for Airflow 3, means the code you want to contribute will never go live. Probably (Except we miserably fail in planning or change our mind). We defined Airflow 2.10 being the last feature release in the Airflow 2 line and plan only to cut patch releases from there.\r\n\r\nI assume we need to put this on the wish list for Airflow 3 and also would be happy if you like to contribute there. But as said, the UI is planned to be fully re-written, which also will affect the connection form. Basics are not settled so as of today it is a bit too early to show something off.', 'created_at': datetime.datetime(2024, 8, 21, 21, 46, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2303192628, 'issue_id': 2454009895, 'author': 'potiuk', 'body': ""100% with @jscheffl -> let's not loose time and mental energy for improving it for Airflow 2, we need to redesign it from scratch basically fof Airflow 3 basically."", 'created_at': datetime.datetime(2024, 8, 21, 22, 35, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2304835388, 'issue_id': 2454009895, 'author': 'bbovenzi', 'body': ""Closing for now. I'll let everyone know when the new UI is read for contributions. @softyoungha I would love if you want to get involved when we rebuild these forms."", 'created_at': datetime.datetime(2024, 8, 22, 14, 35, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2308380312, 'issue_id': 2454009895, 'author': 'softyoungha', 'body': ""@bbovenzi @jscheffl @potiuk \r\nThank you for all your responses. \r\nI understand the situation, and I'll look forward to 3.0 with excitement :)"", 'created_at': datetime.datetime(2024, 8, 24, 12, 37, 32, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-08-21 21:32:09 UTC): @jscheffl What are your thoughts?

jscheffl on (2024-08-21 21:46:11 UTC): I think the current behavior is not well and deserves an extension. Actually I am wondering how it ever worked because in SnowflakeHook also a private key is expected (like you would see in SSH) and JSON would also be non-appropriate.

So thanks for providing an extension.

I just believe it is at the wrong moment of time. We are currently planning to move on to a Airflow 3 release. For this we need to re-work especially the connection form widgets. So all efforts here would need to be thrown away for Airflow 3. Alongside also we are only accepting new features for Airflow 3, means the code you want to contribute will never go live. Probably (Except we miserably fail in planning or change our mind). We defined Airflow 2.10 being the last feature release in the Airflow 2 line and plan only to cut patch releases from there.

I assume we need to put this on the wish list for Airflow 3 and also would be happy if you like to contribute there. But as said, the UI is planned to be fully re-written, which also will affect the connection form. Basics are not settled so as of today it is a bit too early to show something off.

potiuk on (2024-08-21 22:35:07 UTC): 100% with @jscheffl -> let's not loose time and mental energy for improving it for Airflow 2, we need to redesign it from scratch basically fof Airflow 3 basically.

bbovenzi on (2024-08-22 14:35:36 UTC): Closing for now. I'll let everyone know when the new UI is read for contributions. @softyoungha I would love if you want to get involved when we rebuild these forms.

softyoungha (Issue Creator) on (2024-08-24 12:37:32 UTC): @bbovenzi @jscheffl @potiuk 
Thank you for all your responses. 
I understand the situation, and I'll look forward to 3.0 with excitement :)

"
2453662638,pull_request,closed,,feat: add fileloc to DAG info in AirflowRunFacet,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adding `fileloc` to DAG info in AirflowRunFacet.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-07 14:39:05+00:00,[],2024-08-08 09:50:04+00:00,2024-08-08 09:42:20+00:00,https://github.com/apache/airflow/pull/41311,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2453658483,pull_request,closed,,chore: remove openlineage client deprecated from_environment() method,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Just removing call to a deprecated method.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-07 14:37:07+00:00,[],2024-08-08 09:49:59+00:00,2024-08-08 09:42:03+00:00,https://github.com/apache/airflow/pull/41310,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2453515632,pull_request,closed,,Fix render template task_instance tests for db isolation mode,"Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-07 13:39:26+00:00,[],2024-08-07 13:54:51+00:00,2024-08-07 13:54:49+00:00,https://github.com/apache/airflow/pull/41309,[],[],
2453509245,pull_request,closed,,XCom tests pass DB isolation mode,"The tests are disabled that are not supposed to work:

* warnings are raised on internal API side
* get_many is excluded

Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-07 13:37:09+00:00,['aritra24'],2024-08-07 14:38:36+00:00,2024-08-07 14:38:34+00:00,https://github.com/apache/airflow/pull/41308,[],[],
2453379421,pull_request,closed,,fix(rest-api): Add order_by query param to TI listing APIs (#41283),"closes #41283.

This adds db-level sorting with order_by query param to the following TI listing APIs:
1. List task instances - `/api/v1/dags/~/dagRuns/~/taskInstances`
2. List task instances (batch) - `/api/v1/dags/~/dagRuns/~/taskInstances/list`

order_by defaults to sorting by start_date (ascending) for above mentioned 2 APIs. Please note that this does NOT change the default sorting param for the List mapped task instances API.

This also adds corresponding unit tests.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",omkar-foss,2024-08-07 12:36:24+00:00,[],2024-10-09 07:45:12+00:00,2024-08-21 14:07:34+00:00,https://github.com/apache/airflow/pull/41307,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2299246662, 'issue_id': 2453379421, 'author': 'omkar-foss', 'body': 'Fixed all linting issues and added all your suggestions from comments above. Please review when you get a chance, thanks.', 'created_at': datetime.datetime(2024, 8, 20, 16, 17, 37, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-08-20 16:17:37 UTC): Fixed all linting issues and added all your suggestions from comments above. Please review when you get a chance, thanks.

"
2453255131,pull_request,closed,,Add incremental export and cross account export functionality in `DynamoDBToS3Operator`,"# Problem
1. Currently the DynamoDBToS3Operator only supports 2 ways of downloading data: ""full export using `scan`"" or ""full exports using boto3's `export_table_to_point_in_time`"". When using `export_table_to_point_in_time` method, you can also use ""Incremental Export"" instead of ""Full Export"" if you only wish for the delta of the data changes between the specified period. However this functionality is currently not supported in the DynamoDBToS3Operator. 
2. There are times we need to export the data from 1 AWS account (Account A) to another account (Account B). In the full export using `scan` method, you can specify 2 aws connection to facilitate this need. But for `export_table_to_point_in_time`, we would need an additional argument (`s3_bucket_owner`) to allow cross account export.

# Proposed Changes
1. Replace the export_time arg with a boolean value make the Operator more visible that it is doing a point in time export. 
2. Add `export_type`, `incremental_export_from_time` , `incremental_export_to_time` , `incremental_export_view_type` arguments to allow Incremental Export.
3. Add `s3_bucket_owner` arguments to allow cross-account export

closes: #40737
related: #40737

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:



How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Ghoul-SSZ,2024-08-07 11:31:27+00:00,[],2024-08-16 19:16:07+00:00,2024-08-15 16:56:33+00:00,https://github.com/apache/airflow/pull/41304,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', ''), ('kind:documentation', ''), ('provider:fab', '')]","[{'comment_id': 2273254713, 'issue_id': 2453255131, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 7, 11, 31, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287195266, 'issue_id': 2453255131, 'author': 'vincbeck', 'body': 'Static checks are failing. Could you please [run them](https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst)', 'created_at': datetime.datetime(2024, 8, 13, 21, 46, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287411949, 'issue_id': 2453255131, 'author': 'Ghoul-SSZ', 'body': 'I have ran and update the import so that the Static checks should pass. \r\n\r\nHowever, I have noticed that documentation build and spell checks have failed in the GitHub Action for commit [0a195aa](https://github.com/apache/airflow/pull/41304/commits/0a195aa77f4782ae5dfb20215f4b13f9e097d20e) but are not related to my changes. \r\n\r\nShould I try to fix those now or maybe open a different Pull Request for it?', 'created_at': datetime.datetime(2024, 8, 13, 23, 51, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289020989, 'issue_id': 2453255131, 'author': 'vincbeck', 'body': '> I have ran and update the import so that the Static checks should pass.\r\n> \r\n> However, I have noticed that documentation build and spell checks have failed in the GitHub Action for commit [0a195aa](https://github.com/apache/airflow/pull/41304/commits/0a195aa77f4782ae5dfb20215f4b13f9e097d20e) but are not related to my changes.\r\n> \r\n> Should I try to fix those now or maybe open a different Pull Request for it?\r\n\r\nI think it has been fixed by #41449, could you please update your fork and update this branch? It should solve the issue', 'created_at': datetime.datetime(2024, 8, 14, 14, 46, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289753714, 'issue_id': 2453255131, 'author': 'Ghoul-SSZ', 'body': '> > I have ran and update the import so that the Static checks should pass.\r\n> > However, I have noticed that documentation build and spell checks have failed in the GitHub Action for commit [0a195aa](https://github.com/apache/airflow/pull/41304/commits/0a195aa77f4782ae5dfb20215f4b13f9e097d20e) but are not related to my changes.\r\n> > Should I try to fix those now or maybe open a different Pull Request for it?\r\n> \r\n> I think it has been fixed by #41449, could you please update your fork and update this branch? It should solve the issue\r\n\r\nLooks like it is still failing. ðŸ˜ž', 'created_at': datetime.datetime(2024, 8, 14, 19, 53, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289805921, 'issue_id': 2453255131, 'author': 'vincbeck', 'body': 'I resolved the doc building issue. Now, there is one unit test (Kubernetes provider) that is failing. It is definitely not related to this PR', 'created_at': datetime.datetime(2024, 8, 14, 20, 22, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289823738, 'issue_id': 2453255131, 'author': 'vincbeck', 'body': 'But I am not sure what is going on either ....', 'created_at': datetime.datetime(2024, 8, 14, 20, 32, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289927258, 'issue_id': 2453255131, 'author': 'Ghoul-SSZ', 'body': '> But I am not sure what is going on either ....\r\n\r\nyeah it is strange. I will also try to look at it tomorrow when I have time', 'created_at': datetime.datetime(2024, 8, 14, 21, 21, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291331784, 'issue_id': 2453255131, 'author': 'vincbeck', 'body': 'It has been fixed in #41500, please rebase your PR :)', 'created_at': datetime.datetime(2024, 8, 15, 14, 6, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291709935, 'issue_id': 2453255131, 'author': 'Ghoul-SSZ', 'body': '> It has been fixed in #41500, please rebase your PR :)\r\n\r\nAll checks have passed! ðŸŽ‰', 'created_at': datetime.datetime(2024, 8, 15, 16, 52, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291716606, 'issue_id': 2453255131, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 15, 16, 56, 35, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-07 11:31:33 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

vincbeck on (2024-08-13 21:46:57 UTC): Static checks are failing. Could you please [run them](https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst)

Ghoul-SSZ (Issue Creator) on (2024-08-13 23:51:50 UTC): I have ran and update the import so that the Static checks should pass. 

However, I have noticed that documentation build and spell checks have failed in the GitHub Action for commit [0a195aa](https://github.com/apache/airflow/pull/41304/commits/0a195aa77f4782ae5dfb20215f4b13f9e097d20e) but are not related to my changes. 

Should I try to fix those now or maybe open a different Pull Request for it?

vincbeck on (2024-08-14 14:46:02 UTC): I think it has been fixed by #41449, could you please update your fork and update this branch? It should solve the issue

Ghoul-SSZ (Issue Creator) on (2024-08-14 19:53:58 UTC): Looks like it is still failing. ðŸ˜ž

vincbeck on (2024-08-14 20:22:37 UTC): I resolved the doc building issue. Now, there is one unit test (Kubernetes provider) that is failing. It is definitely not related to this PR

vincbeck on (2024-08-14 20:32:55 UTC): But I am not sure what is going on either ....

Ghoul-SSZ (Issue Creator) on (2024-08-14 21:21:30 UTC): yeah it is strange. I will also try to look at it tomorrow when I have time

vincbeck on (2024-08-15 14:06:02 UTC): It has been fixed in #41500, please rebase your PR :)

Ghoul-SSZ (Issue Creator) on (2024-08-15 16:52:19 UTC): All checks have passed! ðŸŽ‰

boring-cyborg[bot] on (2024-08-15 16:56:35 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2453170567,pull_request,closed,,"ydb provider: add database to table name in bulk upsert, use bulk upsert in system test","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
append database name to table name in bulk upsert
cover bulk upsert in system test
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",uzhastik,2024-08-07 10:45:37+00:00,[],2024-08-14 07:07:44+00:00,2024-08-14 00:05:40+00:00,https://github.com/apache/airflow/pull/41303,"[('area:providers', ''), ('area:system-tests', ''), ('provider:ydb', '')]","[{'comment_id': 2275469149, 'issue_id': 2453170567, 'author': 'uzhastik', 'body': 'PR is ready for review, thank you in advance $)', 'created_at': datetime.datetime(2024, 8, 8, 10, 20, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284686518, 'issue_id': 2453170567, 'author': 'uzhastik', 'body': 'still ready :)', 'created_at': datetime.datetime(2024, 8, 12, 18, 44, 50, tzinfo=datetime.timezone.utc)}]","uzhastik (Issue Creator) on (2024-08-08 10:20:15 UTC): PR is ready for review, thank you in advance $)

uzhastik (Issue Creator) on (2024-08-12 18:44:50 UTC): still ready :)

"
2453083390,pull_request,closed,,Adding Dataset Alias Example DAG with classic operators,"Adding Dataset Alias Example DAG with classic operators
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-08-07 10:01:07+00:00,[],2024-08-09 05:49:23+00:00,2024-08-08 07:35:21+00:00,https://github.com/apache/airflow/pull/41302,"[('type:new-feature', 'Changelog: New Features')]",[],
2453021465,pull_request,closed,,fix wrong link to the source DAG in consumer DAG's dataset event section ,"## Why
The dataset event link to the source DAG in consumer DAG is incorrect due to error replacement.

## What
Get the correct dagId and replace that value to generate the correct link to source DAG

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-07 09:31:42+00:00,[],2024-08-08 03:56:12+00:00,2024-08-08 03:56:10+00:00,https://github.com/apache/airflow/pull/41301,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2452943821,pull_request,closed,,Show only the source on the consumer DAG page and only triggered DAG run in the producer DAG page ,"## Why
Before this change, the dataset event producer DAG will get information about the source that points to itself and vice versa, which is not useful and might be misleading.

## What
Show only the source on the consumer DAG page and only trigger DAG run in the producer DAG page 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-07 08:55:31+00:00,[],2024-08-09 05:47:22+00:00,2024-08-08 05:08:17+00:00,https://github.com/apache/airflow/pull/41300,"[('area:webserver', 'Webserver related Issues'), ('type:improvement', 'Changelog: Improvements'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2451899958,pull_request,closed,,Fix PlainAsserts tests in Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Fix PlainAsserts - was an endless recursion of fetching attribute for better error text...",jscheffl,2024-08-07 00:35:24+00:00,[],2024-08-09 05:46:16+00:00,2024-08-07 02:19:27+00:00,https://github.com/apache/airflow/pull/41299,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2451879278,pull_request,closed,,Fix TriggerDagRunOperator Tests for Database Isolation Tests,"Related: https://github.com/apache/airflow/pull/41067

I attempted to adjust the tests for TriggerDagRunOperator but going into details and after fixing some serialization and adding one API I realized that at least 3 more internal API calls would be needed (marked with TODO) - feels like for an internal API support for all corner cases (good cases are working!) the operator probably needs rather a full rewrite based on stable API. Currently too much specific logic is in there.

Therefore the non working options now are explicit markes as not working in Database Isolation Mode and tests are skipped",jscheffl,2024-08-07 00:11:07+00:00,[],2024-08-11 20:41:28+00:00,2024-08-09 18:54:20+00:00,https://github.com/apache/airflow/pull/41298,"[('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2273482491, 'issue_id': 2451879278, 'author': 'potiuk', 'body': 'I think it makes sense to mark Trigger DAG Run as not working currently with internal API with TODO and comment that this is yet-another-thing that currently does not work with it.', 'created_at': datetime.datetime(2024, 8, 7, 13, 30, 31, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-07 13:30:31 UTC): I think it makes sense to mark Trigger DAG Run as not working currently with internal API with TODO and comment that this is yet-another-thing that currently does not work with it.

"
2451785359,pull_request,closed,,Fixing tests/providers/cncf/kubernetes/operators Failures for Database Isolation Mode,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: #41067
Planning to fix both providers tests.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-06 22:26:18+00:00,[],2024-08-07 18:56:32+00:00,2024-08-07 18:56:32+00:00,https://github.com/apache/airflow/pull/41297,[],"[{'comment_id': 2274143296, 'issue_id': 2451785359, 'author': 'bugraoz93', 'body': 'Sorry everyone for the flood! I merged the changes locally rather than updating the branch. It included all of the changes. I will close this one and create it from the top so as not to continue to flood you. Good day!', 'created_at': datetime.datetime(2024, 8, 7, 18, 56, 30, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-08-07 18:56:30 UTC): Sorry everyone for the flood! I merged the changes locally rather than updating the branch. It included all of the changes. I will close this one and create it from the top so as not to continue to flood you. Good day!

"
2451757689,pull_request,closed,,Fix almost 100 tests for taskinstance for DB isolation mode,"Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-06 22:00:13+00:00,[],2024-08-07 06:43:43+00:00,2024-08-07 06:43:43+00:00,https://github.com/apache/airflow/pull/41296,[],"[{'comment_id': 2272242288, 'issue_id': 2451757689, 'author': 'potiuk', 'body': 'Also fixed 25 more tests by adding serialized=True', 'created_at': datetime.datetime(2024, 8, 6, 22, 16, 7, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-06 22:16:07 UTC): Also fixed 25 more tests by adding serialized=True

"
2451693715,pull_request,closed,,Fix tests/operators/test_weekday.py for Database Isolation Mode #41294,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: #41067
Using `dag_maker` for scoped dag creation and deleting `dag.clear()` calls. 
Fix for `tests/operators/test_weekday.py`.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-06 21:05:30+00:00,[],2024-08-06 21:25:14+00:00,2024-08-06 21:25:14+00:00,https://github.com/apache/airflow/pull/41295,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2451671921,pull_request,closed,,Fix tests/operators/test_weekday.py for Database Isolation Mode,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Related: #41067
Using `dag_maker` for scoped dag creation and deleting `dag.clear()` calls. 
Fix for `tests/operators/test_weekday.py`.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-06 20:50:19+00:00,[],2024-08-06 21:04:12+00:00,2024-08-06 21:04:12+00:00,https://github.com/apache/airflow/pull/41294,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:serialization', '')]",[],
2451651267,pull_request,closed,,Update providers metadata 2024-08-06,,eladkal,2024-08-06 20:36:38+00:00,[],2024-08-07 13:40:01+00:00,2024-08-07 13:32:59+00:00,https://github.com/apache/airflow/pull/41292,[],[],
2451641508,pull_request,closed,,Skip trigger related tests in DB isolation mode,"Related #41067

Triggers are run in the triggerer,  which is a trusted component. No need to run these tests in DB isolation mode

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-06 20:29:48+00:00,[],2024-08-13 15:00:37+00:00,2024-08-06 20:39:44+00:00,https://github.com/apache/airflow/pull/41291,"[('area:Triggerer', '')]","[{'comment_id': 2272104119, 'issue_id': 2451641508, 'author': 'potiuk', 'body': ""> Triggers are run in the triggerer, which is a trusted component. No need to run these tests in DB isolation mode\r\n\r\nActually it's not trusted :( Triggerer should also communicate over Internal API (and it does). Those are the endpoints:\r\n\r\n```\r\n        Trigger.from_object,\r\n        Trigger.bulk_fetch,\r\n        Trigger.clean_unused,\r\n        Trigger.submit_event,\r\n        Trigger.submit_failure,\r\n        Trigger.ids_for_triggerer,\r\n        Trigger.assign_unassigned,\r\n```"", 'created_at': datetime.datetime(2024, 8, 6, 20, 36, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2272109179, 'issue_id': 2451641508, 'author': 'vincbeck', 'body': ""> > Triggers are run in the triggerer, which is a trusted component. No need to run these tests in DB isolation mode\r\n> \r\n> Actually it's not trusted :( Triggerer should also communicate over Internal API (and it does). Those are the endpoints:\r\n> \r\n> ```\r\n>         Trigger.from_object,\r\n>         Trigger.bulk_fetch,\r\n>         Trigger.clean_unused,\r\n>         Trigger.submit_event,\r\n>         Trigger.submit_failure,\r\n>         Trigger.ids_for_triggerer,\r\n>         Trigger.assign_unassigned,\r\n> ```\r\n\r\nOops! I thought! Let me close this one then. I'll try to fix it instead of skipping it"", 'created_at': datetime.datetime(2024, 8, 6, 20, 39, 44, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-06 20:36:27 UTC): Actually it's not trusted :( Triggerer should also communicate over Internal API (and it does). Those are the endpoints:

```
        Trigger.from_object,
        Trigger.bulk_fetch,
        Trigger.clean_unused,
        Trigger.submit_event,
        Trigger.submit_failure,
        Trigger.ids_for_triggerer,
        Trigger.assign_unassigned,
```

vincbeck (Issue Creator) on (2024-08-06 20:39:44 UTC): Oops! I thought! Let me close this one then. I'll try to fix it instead of skipping it

"
2451621153,pull_request,closed,,Fix some mor operators tests for Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Fix all operators except TriggerDagRunOperator",jscheffl,2024-08-06 20:15:50+00:00,[],2024-08-06 20:44:59+00:00,2024-08-06 20:44:59+00:00,https://github.com/apache/airflow/pull/41290,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2451545642,pull_request,closed,,docs: adding tip on configuration for healthcheck,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Goal:
I as a airflow deployer would like to enable kubernetes liveness probes. 

Issue:
On my installation, worker_enable_remote_control was set to False, leading to following return:

```
airflow@airflow-worker-0:/opt/airflow$ celery -A airflow.providers.celery.executors.celery_executor.app inspect ping
/home/airflow/.local/lib/python3.11/site-packages/airflow/metrics/statsd_logger.py:184 RemovedInAirflow3Warning: The basic metric validator will be deprecated in the futu
re in favor of pattern-matching.  You can try this now by setting config option metrics_use_pattern_match to True.
Error: No nodes replied within time constraint
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",EvertonSA,2024-08-06 19:25:26+00:00,[],2024-08-08 16:16:05+00:00,2024-08-08 16:16:01+00:00,https://github.com/apache/airflow/pull/41289,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2271990271, 'issue_id': 2451545642, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 6, 19, 25, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2272804500, 'issue_id': 2451545642, 'author': 'EvertonSA', 'body': 'i can fix later thanks for reviewing!', 'created_at': datetime.datetime(2024, 8, 7, 7, 27, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273710038, 'issue_id': 2451545642, 'author': 'EvertonSA', 'body': '@uranusjr thank you for the fixes!', 'created_at': datetime.datetime(2024, 8, 7, 15, 11, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276200887, 'issue_id': 2451545642, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 8, 16, 16, 4, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-06 19:25:29 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

EvertonSA (Issue Creator) on (2024-08-07 07:27:44 UTC): i can fix later thanks for reviewing!

EvertonSA (Issue Creator) on (2024-08-07 15:11:59 UTC): @uranusjr thank you for the fixes!

boring-cyborg[bot] on (2024-08-08 16:16:04 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2451360359,pull_request,closed,,Simplify log message for connection retrieval,"All we know here is that the connection is being retrieved.  We don't know that it is for task execution. It might be for uploading of logs, or callback execution, webserver logs reader, etc.  So let's say less in order to tell the truth.
",dstandish,2024-08-06 17:21:47+00:00,[],2024-08-09 05:43:49+00:00,2024-08-06 20:47:22+00:00,https://github.com/apache/airflow/pull/41288,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2451306771,pull_request,closed,,Fix sagemaker experiments cleanup,"We had some experiment cleanup logic, for cleaning up the experiment created by the create experiment task, but more experiments are created as side-effects of other tasks (such as creating pipelines and tuning jobs). These changes clean up the remaining experiments.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-08-06 16:47:41+00:00,[],2024-08-06 18:50:29+00:00,2024-08-06 18:50:28+00:00,https://github.com/apache/airflow/pull/41287,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2451181347,pull_request,closed,,Added Datapipes to the list of companies using Apache Airflow,Added Datapipes to INTHEWILD.md,rishabh-cldcvr,2024-08-06 15:35:49+00:00,[],2024-08-06 19:55:53+00:00,2024-08-06 19:55:50+00:00,https://github.com/apache/airflow/pull/41285,[],"[{'comment_id': 2271586757, 'issue_id': 2451181347, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 6, 15, 35, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2272039369, 'issue_id': 2451181347, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 6, 19, 55, 52, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-06 15:35:52 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-08-06 19:55:52 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2450898594,pull_request,closed,,chore: remove OpenLineage deprecation warnings,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
We still intend to remove these facets and they are still deprecated, but the current warnings are being shown to users, which could be misleading since users are not involved with these facetsâ€”they are called internally. We need a better method to inform OL consumers about the deprecation of certain facets. For now, I am removing these warnings and logging a debug message regarding the deprecation. 

Also I'm removing `normalize_sql()` from `utils.py` as it's not used anywhere and has been deprecated for a while.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-06 13:29:36+00:00,[],2024-08-08 09:41:28+00:00,2024-08-08 09:24:32+00:00,https://github.com/apache/airflow/pull/41284,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2450831608,pull_request,closed,,Make remaining provider tests pass in DB isolation mode,"All provider's tests should pass now in DB isolation mode

* some tests are fixed
* some modules are excluded as it makes no sense
* some modules are excluded and note about adding information about incompatibilities left to be added in the documentation

Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-06 13:00:34+00:00,[],2024-08-09 05:42:57+00:00,2024-08-06 16:54:11+00:00,https://github.com/apache/airflow/pull/41282,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:databricks', ''), ('provider:openlineage', 'AIP-53'), ('provider:apache-livy', '')]",[],
2450716393,pull_request,closed,,Sync v2-10-stable with v2-10-test to release 2.10.0rc1,Time for 2.10.0rc1!,utkarsharma2,2024-08-06 12:04:56+00:00,[],2024-08-12 14:54:14+00:00,2024-08-12 14:54:14+00:00,https://github.com/apache/airflow/pull/41280,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2274966507, 'issue_id': 2450716393, 'author': 'eladkal', 'body': 'There were several more merged PRs for 2.10 milestone we need to add them', 'created_at': datetime.datetime(2024, 8, 8, 5, 13, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274968120, 'issue_id': 2450716393, 'author': 'ephraimbuddy', 'body': '> There were several more merged PRs for 2.10 milestone we need to add them\n\nWe shall still sync with main on Friday. We currently want to get all reviews done', 'created_at': datetime.datetime(2024, 8, 8, 5, 14, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277336480, 'issue_id': 2450716393, 'author': 'ephraimbuddy', 'body': ""Thanks, @jedcunningham, for the meticulous reviews and for updating the PR labels as part of the reviews. That's huge!"", 'created_at': datetime.datetime(2024, 8, 9, 7, 32, 33, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-08 05:13:05 UTC): There were several more merged PRs for 2.10 milestone we need to add them

ephraimbuddy on (2024-08-08 05:14:48 UTC): We shall still sync with main on Friday. We currently want to get all reviews done

ephraimbuddy on (2024-08-09 07:32:33 UTC): Thanks, @jedcunningham, for the meticulous reviews and for updating the PR labels as part of the reviews. That's huge!

"
