id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2726735805,pull_request,closed,,AIP-72: Handling skipped tasks in task_sdk,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


related: https://github.com/apache/airflow/issues/44414

We already have support for handling terminal states from the task execution side as well as the task SDK client side. (almost).

This PR extends the task runner's `run` function to handle when an AirflowSkipException is thrown.


1. Extended the task runner with the right `msg` when a AirflowSkipException is thrown
2. Added a test in the `test_handle_requests` test of supervisor to show that no `client` call is made from `handle_requests` but is instead controlled by the `wait` function.
3. Added an example DAG that throws AirflowSkipException and the task runner test that handles that.

Postman working example:
1. Create a DAG run:
<img width=""1709"" alt=""image"" src=""https://github.com/user-attachments/assets/e23388fb-db2d-446b-bfa5-6da1a5710a82"">

2. Login into metadata DB and get the task_id for the task you want to skip
![image](https://github.com/user-attachments/assets/7166c3fc-4106-441a-b682-6450a5783e9a)


3. Once you have the task_id, send a patch request like this:
```
curl --location --request PATCH 'http://localhost:29091/execution/task-instances/0193ab1b-df6a-72bb-b888-04c541e6bf12/state' \
--data '{
    ""state"": ""skipped"",
    ""end_date"": ""2024-10-31T12:00:00Z""
}'
```

![image](https://github.com/user-attachments/assets/8e127f65-b7e1-48f4-a909-29d34f09f11c)

4. Check the Airflow UI if the task was marked as ""skipped""
<img width=""1552"" alt=""image"" src=""https://github.com/user-attachments/assets/5ea09da6-4e99-4ae6-8a1f-8d4231770be0"">



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-09 11:14:22+00:00,['amoghrajesh'],2024-12-10 10:24:37+00:00,2024-12-10 10:24:34+00:00,https://github.com/apache/airflow/pull/44786,"[('area:task-sdk', None)]","[{'comment_id': 2531135686, 'issue_id': 2726735805, 'author': 'amoghrajesh', 'body': 'This one is pretty straight forward. Merging it', 'created_at': datetime.datetime(2024, 12, 10, 10, 24, 32, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-10 10:24:32 UTC): This one is pretty straight forward. Merging it

"
2726419941,pull_request,closed,,Adding back the XCOM client tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

https://github.com/apache/airflow/pull/44723 removed the XCOM client tests by mistake during rebase. Adding it back


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-09 09:01:38+00:00,[],2024-12-09 09:34:35+00:00,2024-12-09 09:34:33+00:00,https://github.com/apache/airflow/pull/44784,"[('area:task-sdk', None)]",[],
2726409146,pull_request,closed,,feat: add OpenLineage support for BigQuery Create Table operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for BigQueryCreateExternalTableOperator and BigQueryCreateEmptyTableOperator.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-09 08:57:27+00:00,[],2024-12-10 10:40:44+00:00,2024-12-10 10:35:14+00:00,https://github.com/apache/airflow/pull/44783,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2726263495,pull_request,closed,,Added output_processor parameter to SQLQueryOperator and fixed bug with return_single_query_results handler when None is passed as split_statements,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Added output_processor parameter to SQLQueryOperator to allow customizing return of results as by default descriptions get ignored.  This parameter allows us to customized that if needed.

Also fixed an issue with the return_single_query_results handler method when None is passed as split_statements, which wasn't allowed in the handler method but is for the split_statements parameter in the SQLQueryOperator.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-12-09 07:46:38+00:00,[],2024-12-09 21:49:48+00:00,2024-12-09 21:49:47+00:00,https://github.com/apache/airflow/pull/44781,"[('area:providers', ''), ('provider:common-sql', '')]","[{'comment_id': 2527366270, 'issue_id': 2726263495, 'author': 'potiuk', 'body': 'Nice. But tests have to pass :)', 'created_at': datetime.datetime(2024, 12, 9, 9, 21, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527629149, 'issue_id': 2726263495, 'author': 'dabla', 'body': ""> Nice. But tests have to pass :)\r\n\r\nYeah, that's when I discovered the bug in the  return_single_query_results handler method.\r\nDon't know if the fix will be approved, we could do it the way around and force the split_statements parameter not to be None in the SQLQueryOperator.  So that's up to you guys ;-)"", 'created_at': datetime.datetime(2024, 12, 9, 11, 14, 53, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-09 09:21:25 UTC): Nice. But tests have to pass :)

dabla (Issue Creator) on (2024-12-09 11:14:53 UTC): Yeah, that's when I discovered the bug in the  return_single_query_results handler method.
Don't know if the fix will be approved, we could do it the way around and force the split_statements parameter not to be None in the SQLQueryOperator.  So that's up to you guys ;-)

"
2726110290,pull_request,closed,,Set Autocomplete Off on Login Form,"Closes #44019

Updated main Javascript to apply `autocomplete=""off""` to both username and password inputs on login page. This will help prevent the browser from providing hints for the username (and password), as requested in the Issue.

Based on Flask-AppBuilder source code, i.e. https://github.com/dpgaspar/Flask-AppBuilder/tree/master/flask_appbuilder/templates/appbuilder/general/security (see `login_db.html` and `login_ldap.html`), this should work for both `AUTH_DB` (default) and `AUTH_LDAP` authentication, since they both apparently use the same HTML elements in the form. ",geraj1010,2024-12-09 06:21:52+00:00,[],2024-12-14 05:51:23+00:00,2024-12-14 05:38:02+00:00,https://github.com/apache/airflow/pull/44780,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]","[{'comment_id': 2538340062, 'issue_id': 2726110290, 'author': 'ephraimbuddy', 'body': '> Nice, tested locally, working as expected.\r\n> \r\n> Should we target `main` and backport instead of specifically targeting `v2-10-test`. When changes are compatible I believe main then backport is better to limit drift between the two branches, I tend to directly target `v2-10-test` for changes that are completely different and incompatible with main anymore. @ephraimbuddy what do you think ?\r\n\r\nI agree with you. Main then backport, for changes that are a bit compatible otherwise a different PR targeting the test branch would be better', 'created_at': datetime.datetime(2024, 12, 12, 9, 25, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542834817, 'issue_id': 2726110290, 'author': 'geraj1010', 'body': 'Closing this PR, since we decided to push this one to `main` and backtrack to `v2-10-test`. \r\n\r\nNew PR: https://github.com/apache/airflow/pull/44929', 'created_at': datetime.datetime(2024, 12, 14, 5, 37, 59, tzinfo=datetime.timezone.utc)}]","ephraimbuddy on (2024-12-12 09:25:22 UTC): I agree with you. Main then backport, for changes that are a bit compatible otherwise a different PR targeting the test branch would be better

geraj1010 (Issue Creator) on (2024-12-14 05:37:59 UTC): Closing this PR, since we decided to push this one to `main` and backtrack to `v2-10-test`. 

New PR: https://github.com/apache/airflow/pull/44929

"
2726068620,pull_request,closed,,Change default asset alias group to 'asset',"And empty default group name is really unhelpful. I'm not entirely sure if we should dump everything into 'asset' by default, or should aliases be separated into their own default 'alias' group. We might have a better idea when we have a real UI for this.",uranusjr,2024-12-09 05:55:05+00:00,[],2024-12-09 21:13:22+00:00,2024-12-09 21:13:20+00:00,https://github.com/apache/airflow/pull/44778,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('area:task-sdk', None)]",[],
2725942671,pull_request,closed,,Implement asset alias list endpoint in FastAPI,A new filter name_pattern is also added to the asset list endpoint (and asset alias list).,uranusjr,2024-12-09 04:19:15+00:00,[],2024-12-09 21:11:21+00:00,2024-12-09 21:11:19+00:00,https://github.com/apache/airflow/pull/44777,"[('area:CLI', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2725382017,pull_request,closed,,Fix flaky task_sdk test by comparing the list in unordered fashion,"The test_reading_from_pipes can sometimes return the logs in a different order, because the order in which messages will be read from stdout and stderr and values are put in the log are not deterministic. Unfortunately this is comparing list of dicts and dicts are not hashable, so we cannot use the usual trick of converting the list to set. Instead we are using ""pytest-unordered"" library that implements `unordered` helper to run such asserts.

The native pytest for unordered collection comparision is highly requested but apparently stalled by maintainers. See the https://github.com/pytest-dev/pytest/issues/10032 issue.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-08 16:56:17+00:00,[],2024-12-10 03:50:05+00:00,2024-12-08 19:36:34+00:00,https://github.com/apache/airflow/pull/44776,"[('area:task-sdk', None)]","[{'comment_id': 2526223731, 'issue_id': 2725382017, 'author': 'potiuk', 'body': 'BTW: @ashb @kaxil -> while this should fix the test, I wonder if this is our concern that stdout /stderr might come in different order than they were produced. That is generally I think quite impossible to prevent if you have parallel threads reading from two different pipees, the only ""practical"" way I know is to make sure both stdout and stderr are joined as single stderr+out pipe by the process that produces them. So i am not sure if there is anything we can do here if we want to keep the stdout/stderr separation. \r\n\r\nThat\'s usual issue with separating stdout/stderr (been there, done that).', 'created_at': datetime.datetime(2024, 12, 8, 17, 0, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526227590, 'issue_id': 2725382017, 'author': 'potiuk', 'body': ""Example failure where I saw this happened: https://github.com/apache/airflow/actions/runs/12223335598/job/34094868625?pr=44686#step:9:670\r\n\r\n```python\r\n________________ TestWatchedSubprocess.test_reading_from_pipes _________________\r\n[gw1] linux -- Python 3.9.21 /usr/local/bin/python\r\ntask_sdk/tests/execution_time/test_supervisor.py:113: in test_reading_from_pipes\r\n    assert captured_logs == [\r\nE   AssertionError: assert equals failed\r\nE         'level': 'info',                 'level': 'info',            \r\nE         'logger': 'task',                'logger': 'task',           \r\nE         'timestamp': '2024-11-07T12      'timestamp': '2024-11-07T12 \r\nE     :34:56.078901Z',                 :34:56.078901Z',                \r\nE       },                               },                            \r\nE       {                                {                             \r\nE         'chan': 'stdout',                'chan': 'stderr',           \r\nE         'event': 'Message split acr      'event': 'stderr message',  \r\nE     oss two writes',                                                 \r\nE         'level': 'info',                 'level': 'error',           \r\nE         'logger': 'task',                'logger': 'task',           \r\nE         'timestamp': '2024-11-07T12      'timestamp': '2024-11-07T12 \r\nE     :34:56.078901Z',                 :34:56.078901Z',                \r\nE       },                               },                            \r\nE       {                                {                             \r\nE         'chan': 'stderr',                'chan': 'stdout',           \r\nE         'event': 'stderr message',       'event': 'Message split acr \r\nE                                      oss two writes',                \r\nE         'level': 'error',                'level': 'info',            \r\nE         'logger': 'task',                'logger': 'task',           \r\nE         'timestamp': '2024-11-07T12      'timestamp': '2024-11-07T12 \r\nE     :34:56.078901Z',                 :34:56.078901Z',                \r\nE       },                               },                            \r\nE       {                                {                             \r\nE         'event': 'An error message'      'event': 'An error message' \r\nE     ,                                ,\r\n\r\n```"", 'created_at': datetime.datetime(2024, 12, 8, 17, 3, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527225781, 'issue_id': 2725382017, 'author': 'kaxil', 'body': '>This is a good fix, or another option is to compare stdout and stderr messages independently.\r\n\r\nI think doing independently might be better as we do want to make sure this come ordered, no @ashb ?', 'created_at': datetime.datetime(2024, 12, 9, 8, 14, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527381548, 'issue_id': 2725382017, 'author': 'potiuk', 'body': 'Side comment. Regardless - looked at the code and see there are selectors used - nice :)', 'created_at': datetime.datetime(2024, 12, 9, 9, 26, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527853383, 'issue_id': 2725382017, 'author': 'ashb', 'body': ""> > This is a good fix, or another option is to compare stdout and stderr messages independently.\r\n> \r\n> I think doing independently might be better as we do want to make sure this come ordered, no @ashb ?\r\n\r\n@kaxil Yeah, though honestly I can't really think of any practical way it would be possible to make them\xa0come out not ordered within the individual stream. If you want to PR it to update each go for it, but it's not super important to my mind.\r\n\r\n> Side comment. Regardless - looked at the code and see there are selectors used - nice :)\r\n\r\nI'm nothing if not oldschool."", 'created_at': datetime.datetime(2024, 12, 9, 12, 56, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530201474, 'issue_id': 2725382017, 'author': 'kaxil', 'body': ""> @kaxil Yeah, though honestly I can't really think of any practical way it would be possible to make them\xa0come out not ordered within the individual stream. If you want to PR it to update each go for it, but it's not super important to my mind.\r\n \r\nYeah not going to bother for now"", 'created_at': datetime.datetime(2024, 12, 10, 3, 50, 4, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-08 17:00:14 UTC): BTW: @ashb @kaxil -> while this should fix the test, I wonder if this is our concern that stdout /stderr might come in different order than they were produced. That is generally I think quite impossible to prevent if you have parallel threads reading from two different pipees, the only ""practical"" way I know is to make sure both stdout and stderr are joined as single stderr+out pipe by the process that produces them. So i am not sure if there is anything we can do here if we want to keep the stdout/stderr separation. 

That's usual issue with separating stdout/stderr (been there, done that).

potiuk (Issue Creator) on (2024-12-08 17:03:03 UTC): Example failure where I saw this happened: https://github.com/apache/airflow/actions/runs/12223335598/job/34094868625?pr=44686#step:9:670

```python
________________ TestWatchedSubprocess.test_reading_from_pipes _________________
[gw1] linux -- Python 3.9.21 /usr/local/bin/python
task_sdk/tests/execution_time/test_supervisor.py:113: in test_reading_from_pipes
    assert captured_logs == [
E   AssertionError: assert equals failed
E         'level': 'info',                 'level': 'info',            
E         'logger': 'task',                'logger': 'task',           
E         'timestamp': '2024-11-07T12      'timestamp': '2024-11-07T12 
E     :34:56.078901Z',                 :34:56.078901Z',                
E       },                               },                            
E       {                                {                             
E         'chan': 'stdout',                'chan': 'stderr',           
E         'event': 'Message split acr      'event': 'stderr message',  
E     oss two writes',                                                 
E         'level': 'info',                 'level': 'error',           
E         'logger': 'task',                'logger': 'task',           
E         'timestamp': '2024-11-07T12      'timestamp': '2024-11-07T12 
E     :34:56.078901Z',                 :34:56.078901Z',                
E       },                               },                            
E       {                                {                             
E         'chan': 'stderr',                'chan': 'stdout',           
E         'event': 'stderr message',       'event': 'Message split acr 
E                                      oss two writes',                
E         'level': 'error',                'level': 'info',            
E         'logger': 'task',                'logger': 'task',           
E         'timestamp': '2024-11-07T12      'timestamp': '2024-11-07T12 
E     :34:56.078901Z',                 :34:56.078901Z',                
E       },                               },                            
E       {                                {                             
E         'event': 'An error message'      'event': 'An error message' 
E     ,                                ,

```

kaxil on (2024-12-09 08:14:35 UTC): I think doing independently might be better as we do want to make sure this come ordered, no @ashb ?

potiuk (Issue Creator) on (2024-12-09 09:26:46 UTC): Side comment. Regardless - looked at the code and see there are selectors used - nice :)

ashb on (2024-12-09 12:56:02 UTC): @kaxil Yeah, though honestly I can't really think of any practical way it would be possible to make them come out not ordered within the individual stream. If you want to PR it to update each go for it, but it's not super important to my mind.


I'm nothing if not oldschool.

kaxil on (2024-12-10 03:50:04 UTC): Yeah not going to bother for now

"
2725344231,pull_request,closed,,Extract version compatibility constant in tests to version_compat,"This is extracted out of #44686 - pre-requisite for consistency check and consistency change to always use version_compat embedded in providers and avoid mistakes with importing the compat from tests in the providers code.

This is purely extraction of constants that use to be in compat module to version_compat - which will make it easy to write the pre-commit to check if version_compat from tests_modules is used accidentally.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-08 15:44:24+00:00,[],2024-12-08 16:12:44+00:00,2024-12-08 16:12:43+00:00,https://github.com/apache/airflow/pull/44774,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:logging', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:celery', ''), ('provider:apache-hive', ''), ('provider:apache-spark', ''), ('provider:apache-kylin', ''), ('provider:common-compat', '')]",[],
2725323669,pull_request,closed,,Add timeout on total pytest execution time in parallel tests,"When there is a test that does not allow pytest command to quit cleanly, in case of parallell commands, we have no chance to see the outputs of test command that failed, because whole CI job is cancelled and we only upload the logs on failure in the following step of the job.

Adding timeout for parallel tests that is a little shorter than the job timeout will give a chance for our tests to get cancelled before the job timeout occur, and even if we will not see the logs in the output of the cancelled `breeze testing` command, the logs should be uploaded as artifacts in this case.

Also we are serving ""cancelled"" status of job, because it's likely
that will also be possible to do ""something"" in case test gets
cancelled due to timeout.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-08 15:08:43+00:00,[],2024-12-08 17:01:37+00:00,2024-12-08 17:01:35+00:00,https://github.com/apache/airflow/pull/44772,"[('area:dev-tools', '')]",[],
2725044455,pull_request,closed,,Extract version compatibility constant in tests to version_compat,"This is extracted out of #44686 - pre-requisite for consistency check and consistency change to always use version_compat embedded in providers and avoid mistakes with importing the compat from tests in the providers code.

This is purely extraction of constants that use to be in compat module to version_compat - which will make it easy to write the pre-commit to check if version_compat from tests_modules is used accidentally.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-08 08:14:54+00:00,[],2024-12-08 15:56:13+00:00,2024-12-08 15:45:54+00:00,https://github.com/apache/airflow/pull/44770,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:logging', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:celery', ''), ('provider:elasticsearch', ''), ('provider:apache-hive', ''), ('provider:apache-spark', ''), ('provider:apache-kylin', ''), ('provider:common-compat', '')]","[{'comment_id': 2526188515, 'issue_id': 2725044455, 'author': 'potiuk', 'body': 'Interestingly enough - that one got a conversation started by someone who has been apparently malicious user and deleted since ... And I cannot merge it as the conversation is gone. I will raise the issue to Github and open a new PR.', 'created_at': datetime.datetime(2024, 12, 8, 15, 43, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526189301, 'issue_id': 2725044455, 'author': 'potiuk', 'body': '@hussein-awala @gopidesupavan @jscheffl -> https://github.com/apache/airflow/pull/44774 kind request to transfer your approvals there :)', 'created_at': datetime.datetime(2024, 12, 8, 15, 45, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526193139, 'issue_id': 2725044455, 'author': 'potiuk', 'body': 'Ticket created in Github Support: https://support.github.com/ticket/personal/0/3130863', 'created_at': datetime.datetime(2024, 12, 8, 15, 56, 12, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-08 15:43:38 UTC): Interestingly enough - that one got a conversation started by someone who has been apparently malicious user and deleted since ... And I cannot merge it as the conversation is gone. I will raise the issue to Github and open a new PR.

potiuk (Issue Creator) on (2024-12-08 15:45:38 UTC): @hussein-awala @gopidesupavan @jscheffl -> https://github.com/apache/airflow/pull/44774 kind request to transfer your approvals there :)

potiuk (Issue Creator) on (2024-12-08 15:56:12 UTC): Ticket created in Github Support: https://support.github.com/ticket/personal/0/3130863

"
2724808342,pull_request,closed,,[BACKPORT (modified)] Prevent using `trigger_rule=TriggerRule.ALWAYS` in a task-generated mapping within bare tasks (#44751),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Backports: #44751

Due to breaking changes I couldn't backport as-is, so I had to modify it for compatibility.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-07 20:48:10+00:00,[],2024-12-08 06:16:36+00:00,2024-12-08 06:16:33+00:00,https://github.com/apache/airflow/pull/44769,"[('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', ''), ('area:dynamic-task-mapping', 'AIP-42')]",[],
2724703862,pull_request,closed,,Ensure that we don't try sending any more heartbeat messages once the process has exited.,"We noticed sometimes in CI that we would get 3 requests made, which
""shouldn't"" happen, once it gets the 4xx error to the heartbeat it is meant to
kill the task process.

The vause of this was mostly an artifect of the short heartbeat interval we
used in the tests, and how we poll for the subprocess exit code. I don't think
it could have happened in practice (and it wouldn't affect anything if it did)
but I've made it more-robust anyway.

This is the longer term fix for #44760
",ashb,2024-12-07 16:11:17+00:00,[],2024-12-09 08:11:54+00:00,2024-12-07 17:31:51+00:00,https://github.com/apache/airflow/pull/44767,"[('area:task-sdk', None)]",[],
2724701271,pull_request,closed,,Correctly ensure that we give subprocesses time to exit after signalling it,"We had a bug hidden in our tests by our use of mocks -- if the subprocess
returned any output, then `self.selector.select()` would return straight away,
not waiting for the maximum timeout, which would result in the ""escalation""
signal being sent after one outout, not after the given interval.

Discovered while looking into https://github.com/apache/airflow/pull/44760#issuecomment-2525196659
",ashb,2024-12-07 16:07:18+00:00,[],2024-12-07 16:41:15+00:00,2024-12-07 16:41:10+00:00,https://github.com/apache/airflow/pull/44766,"[('area:task-sdk', None)]",[],
2724669710,pull_request,closed,,Remove provider deprecations in Apache Druid,"Relates to #44559.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-12-07 15:16:13+00:00,[],2024-12-07 16:11:13+00:00,2024-12-07 16:11:13+00:00,https://github.com/apache/airflow/pull/44765,"[('area:providers', ''), ('provider:apache-druid', '')]",[],
2724663731,pull_request,closed,,Remove Provider Deprecations in Apprise,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider Apprise

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-07 15:03:14+00:00,[],2024-12-07 17:38:38+00:00,2024-12-07 17:38:38+00:00,https://github.com/apache/airflow/pull/44764,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:apprise', '')]",[],
2724646822,pull_request,closed,,Remove Provider Deprecations in Microsoft-AZURE,"Relates to https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-07 14:22:46+00:00,[],2024-12-07 19:42:42+00:00,2024-12-07 19:42:42+00:00,https://github.com/apache/airflow/pull/44763,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('area:secrets', '')]",[],
2724574932,pull_request,closed,,Remove Provider Deprecations in Microsoft-MSSQL,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Microsoft-MSSQL

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-07 12:36:13+00:00,[],2024-12-07 15:01:40+00:00,2024-12-07 15:01:40+00:00,https://github.com/apache/airflow/pull/44762,"[('area:providers', ''), ('kind:documentation', ''), ('provider:microsoft-mssql', '')]",[],
2724570936,pull_request,closed,,Remove Provider Deprecations in Microsoft-PSRP,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Microsoft-PSRP

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-07 12:26:29+00:00,[],2024-12-07 14:47:31+00:00,2024-12-07 14:47:30+00:00,https://github.com/apache/airflow/pull/44761,"[('area:providers', ''), ('provider:microsoft-psrp', '')]",[],
2724522334,pull_request,closed,,Fix flaky supervisor conflict test,"The test sometimes runs for a longer time and generates more requests - thus producing slightly different output and count of requests. This PR accepts bigger request count.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-07 10:17:51+00:00,[],2024-12-07 14:57:37+00:00,2024-12-07 12:41:44+00:00,https://github.com/apache/airflow/pull/44760,"[('area:task-sdk', None)]","[{'comment_id': 2525107100, 'issue_id': 2724522334, 'author': 'ashb', 'body': 'Ah okay I see what has happened, when we receive the failed response we enter the kill loop, and as part of letting the task shutdown cleanly we can _re-enter_ the send_heartbeat if needed bath.\r\n\r\nPR coming to prevent that', 'created_at': datetime.datetime(2024, 12, 7, 13, 4, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525194810, 'issue_id': 2724522334, 'author': 'potiuk', 'body': '> Ah okay I see what has happened, when we receive the failed response we enter the kill loop, and as part of letting the task shutdown cleanly we can _re-enter_ the send_heartbeat if needed bath.\r\n> \r\n> PR coming to prevent that\r\n\r\nCool.', 'created_at': datetime.datetime(2024, 12, 7, 14, 50, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525196659, 'issue_id': 2724522334, 'author': 'ashb', 'body': ""Okay, it wasn't quite that, it was an artifact of the short heartbeat interval we use in the tests, and how we poll for the subprocess exit code. I don't think it will happen in practice. I've made it more-robust anyway.\r\n\r\nLooking at this also made me notice that we don't correctly handle the wait between TERM and KILL when we kill the subprocess."", 'created_at': datetime.datetime(2024, 12, 7, 14, 57, 36, tzinfo=datetime.timezone.utc)}]","ashb on (2024-12-07 13:04:22 UTC): Ah okay I see what has happened, when we receive the failed response we enter the kill loop, and as part of letting the task shutdown cleanly we can _re-enter_ the send_heartbeat if needed bath.

PR coming to prevent that

potiuk (Issue Creator) on (2024-12-07 14:50:34 UTC): Cool.

ashb on (2024-12-07 14:57:36 UTC): Okay, it wasn't quite that, it was an artifact of the short heartbeat interval we use in the tests, and how we poll for the subprocess exit code. I don't think it will happen in practice. I've made it more-robust anyway.

Looking at this also made me notice that we don't correctly handle the wait between TERM and KILL when we kill the subprocess.

"
2724498701,pull_request,closed,,[v2-10-test] Random doc typos (#44750),"* Random doc typos

* Update contributing-docs/testing/unit_tests.rst

Co-authored-by: Shahar Epstein <60007259+shahar1@users.noreply.github.com>

* Update contributing-docs/testing/unit_tests.rst

---------

(cherry picked from commit 909ff713a47d6217592f919cddbbb6967e0fddf0)

Co-authored-by: D. Ferruzzi <ferruzzi@amazon.com>
Co-authored-by: Shahar Epstein <60007259+shahar1@users.noreply.github.com>",github-actions[bot],2024-12-07 09:11:07+00:00,[],2024-12-10 06:39:29+00:00,2024-12-07 10:14:14+00:00,https://github.com/apache/airflow/pull/44758,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2724433676,pull_request,closed,,Remove deprecations from Tableau Provider ,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-07 07:08:52+00:00,[],2024-12-07 10:34:34+00:00,2024-12-07 10:34:34+00:00,https://github.com/apache/airflow/pull/44757,"[('area:providers', ''), ('provider:tableau', '')]",[],
2724418534,pull_request,closed,,Remove deprecations from Snowflake Provider,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-07 06:40:16+00:00,[],2024-12-07 10:33:07+00:00,2024-12-07 10:33:07+00:00,https://github.com/apache/airflow/pull/44756,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]",[],
2724366253,pull_request,closed,,"Remove fallback for old, pre 2.7, providers","In ~2.7, we moved provider config from core into the providers themselves. However, if providers that were released before that change was used on 2.7+, there could be failures because the config wouldn't be in those providers! So, we added a fallback for all of the configs that were moved.

As we move toward Airflow 3, we don't need to carry this baggage forever. This does mean provider released in earlier than mid 2023 won't work with Airflow 3 (and I'd imagine there will be other reasons they wont work as well).",jedcunningham,2024-12-07 05:15:53+00:00,[],2024-12-12 16:55:02+00:00,2024-12-12 16:52:02+00:00,https://github.com/apache/airflow/pull/44755,"[('area:logging', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2532897106, 'issue_id': 2724366253, 'author': 'jedcunningham', 'body': 'Spun the removal of the kubernetes commands from core out of this PR here: #44826', 'created_at': datetime.datetime(2024, 12, 10, 21, 9, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539491588, 'issue_id': 2724366253, 'author': 'jedcunningham', 'body': 'Thanks @potiuk for running this one down with me 🍻', 'created_at': datetime.datetime(2024, 12, 12, 16, 52, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539499328, 'issue_id': 2724366253, 'author': 'potiuk', 'body': '> Thanks @potiuk for running this one down with me 🍻\r\n\r\nI am sorry you had to suffer it :( . And yes we should definietely - when we restructure our packaging and ""distributions"" simplify the configuration loading and removing the double-loading if possible.', 'created_at': datetime.datetime(2024, 12, 12, 16, 55, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-10 21:09:29 UTC): Spun the removal of the kubernetes commands from core out of this PR here: #44826

jedcunningham (Issue Creator) on (2024-12-12 16:52:20 UTC): Thanks @potiuk for running this one down with me 🍻

potiuk on (2024-12-12 16:55:00 UTC): I am sorry you had to suffer it :( . And yes we should definietely - when we restructure our packaging and ""distributions"" simplify the configuration loading and removing the double-loading if possible.

"
2724233264,pull_request,closed,,Remove Provider Deprecations in Yandex provider,related to #44559,rawwar,2024-12-07 01:23:12+00:00,[],2024-12-07 14:51:48+00:00,2024-12-07 14:51:48+00:00,https://github.com/apache/airflow/pull/44754,"[('area:providers', ''), ('provider:yandex', '')]",[],
2724095775,pull_request,closed,,Run the task with the configured dag bundle,"Here we ensure that when a dag run is created, we stamp the current bundle version on the dag run so that we can ensure the run is run with the right bundle version.  Then i make sure it flows through properly to the task run context where it's checked out and loaded.

I also rename 'path' or 'file' to `dag_rel_path` in some parts of the execution machinery, so that it's clear where we are using the relative path and the absolute path.",dstandish,2024-12-06 23:00:39+00:00,[],2025-01-15 00:19:28+00:00,2025-01-15 00:19:26+00:00,https://github.com/apache/airflow/pull/44752,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('AIP-66: DAG Bundle/Manifest', ''), ('area:task-sdk', None)]",[],
2724008448,pull_request,closed,,Prevent using `trigger_rule=TriggerRule.ALWAYS` in a task-generated mapping within bare tasks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #43368

Thanks to Jed's [comment](https://github.com/apache/airflow/pull/43368#issuecomment-2523903356) in the previous PR, I've realized that:
1. I've made a mistake in terminology, and mixed up **dynamic task mapping** with **task-generated mapping**.
2. The previous PR covered only the case of mapped task groups, but didn't cover the case of bare tasks (see example in the comment / test).

This PR fixes related docs and newsfragment of #43368, while applying the prevention for bare tasks.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-06 22:06:18+00:00,[],2024-12-07 20:44:00+00:00,2024-12-07 16:35:19+00:00,https://github.com/apache/airflow/pull/44751,"[('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', ''), ('area:dynamic-task-mapping', 'AIP-42'), ('area:task-sdk', None), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2525305387, 'issue_id': 2724008448, 'author': 'shahar1', 'body': 'Working on a backport :)', 'created_at': datetime.datetime(2024, 12, 7, 20, 43, 59, tzinfo=datetime.timezone.utc)}]","shahar1 (Issue Creator) on (2024-12-07 20:43:59 UTC): Working on a backport :)

"
2724004346,pull_request,closed,,Random doc typos,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-12-06 22:03:10+00:00,[],2024-12-10 06:39:13+00:00,2024-12-07 09:10:19+00:00,https://github.com/apache/airflow/pull/44750,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2525044476, 'issue_id': 2724004346, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44758""><img src=""https://img.shields.io/badge/PR-44758-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 7, 9, 11, 10, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-07 09:11:10 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44758""><img src=""https://img.shields.io/badge/PR-44758-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2723984888,pull_request,closed,,Remove Provider Deprecations in Redis,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Redis

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-06 21:48:48+00:00,[],2024-12-06 22:15:52+00:00,2024-12-06 22:15:52+00:00,https://github.com/apache/airflow/pull/44749,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:redis', '')]","[{'comment_id': 2524284371, 'issue_id': 2723984888, 'author': 'jscheffl', 'body': 'Closed in favor of #44633', 'created_at': datetime.datetime(2024, 12, 6, 22, 15, 52, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-06 22:15:52 UTC): Closed in favor of #44633

"
2723971957,pull_request,closed,,Remove Provider Deprecations in Vertica,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Vertica

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-06 21:38:39+00:00,[],2024-12-07 06:36:01+00:00,2024-12-07 06:36:01+00:00,https://github.com/apache/airflow/pull/44748,"[('area:providers', ''), ('provider:vertica', '')]",[],
2723841240,pull_request,closed,,Fix main,"Fix static check failures in main

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-06 20:15:42+00:00,[],2025-01-10 23:42:35+00:00,2024-12-06 20:22:51+00:00,https://github.com/apache/airflow/pull/44747,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2723835219,pull_request,closed,,Remove deprecations from Teradata Provider,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-06 20:11:20+00:00,[],2024-12-07 07:07:39+00:00,2024-12-07 07:07:38+00:00,https://github.com/apache/airflow/pull/44746,"[('area:providers', ''), ('provider:teradata', '')]",[],
2723797395,pull_request,closed,,Remove deprecations from Weaviate Provider,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-06 19:45:52+00:00,[],2024-12-07 08:00:24+00:00,2024-12-07 08:00:24+00:00,https://github.com/apache/airflow/pull/44745,"[('area:providers', ''), ('provider:weaviate', '')]",[],
2723795064,pull_request,closed,,AIP-79 Generate assets for Flask application in FAB provider,"Follow up of #44464.

In #44464, we copied a minimal version of the Flask application in FAB provider to support Airflow 2 plugins. This Flask application required assets (like the Flask application in core).

In this PR I update the script `compile_www_assets.py` to also generate the assets for the Flash application in FAB provider. 

For later: when the current UI is gone, we'll be able to stop generating the assets for the main Flask application in core (then maybe move the script to FAB provider?).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-06 19:44:11+00:00,[],2024-12-18 20:48:57+00:00,2024-12-18 18:40:54+00:00,https://github.com/apache/airflow/pull/44744,"[('area:dev-tools', '')]","[{'comment_id': 2524059146, 'issue_id': 2723795064, 'author': 'vincbeck', 'body': '> Overall, lgtm. Do we need to add a step to run this into the provider release process for FAB?\r\n\r\nI think so. Do you know where is this provider release process?', 'created_at': datetime.datetime(2024, 12, 6, 20, 1, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2524060936, 'issue_id': 2723795064, 'author': 'vincbeck', 'body': 'I just had a double thought. Would not it be better to copy paste this script in FAB provider and generate only the assets for FAB provider in this script, update the release process of FAB provider to run this script? That way, when we remove the entire Flash application from core, we can safely remove the script from core?', 'created_at': datetime.datetime(2024, 12, 6, 20, 2, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2524940846, 'issue_id': 2723795064, 'author': 'jedcunningham', 'body': 'Oh, that probably is a better idea.\r\n\r\nThese are the docs for the release process: https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PROVIDER_PACKAGES.md', 'created_at': datetime.datetime(2024, 12, 7, 5, 30, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2528345118, 'issue_id': 2723795064, 'author': 'vincbeck', 'body': ""> Oh, that probably is a better idea.\r\n> \r\n> These are the docs for the release process: https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PROVIDER_PACKAGES.md\r\n\r\nCool :) I'll update the PR"", 'created_at': datetime.datetime(2024, 12, 9, 15, 23, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2528543670, 'issue_id': 2723795064, 'author': 'vincbeck', 'body': ""> > Oh, that probably is a better idea.\r\n> > These are the docs for the release process: https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PROVIDER_PACKAGES.md\r\n> \r\n> Cool :) I'll update the PR\r\n\r\nI just realized, the release should not be updated because the assets are not released. It should be in the install process"", 'created_at': datetime.datetime(2024, 12, 9, 16, 18, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2528560275, 'issue_id': 2723795064, 'author': 'vincbeck', 'body': ""Also it seems there is already some plumbing and automations set up to generate the assets automatically when creating a virtual env with hatch so I think I'll keep everything in that file. That will simplify things. I added a test in the script to do it only if the fab provider package is installed"", 'created_at': datetime.datetime(2024, 12, 9, 16, 25, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536425607, 'issue_id': 2723795064, 'author': 'vincbeck', 'body': ""> Also it seems there is already some plumbing and automations set up to generate the assets automatically when creating a virtual env with hatch so I think I'll keep everything in that file. That will simplify things. I added a test in the script to do it only if the fab provider package is installed\r\n\r\n@jedcunningham WDYT?"", 'created_at': datetime.datetime(2024, 12, 11, 16, 9, 27, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-12-06 20:01:08 UTC): I think so. Do you know where is this provider release process?

vincbeck (Issue Creator) on (2024-12-06 20:02:18 UTC): I just had a double thought. Would not it be better to copy paste this script in FAB provider and generate only the assets for FAB provider in this script, update the release process of FAB provider to run this script? That way, when we remove the entire Flash application from core, we can safely remove the script from core?

jedcunningham on (2024-12-07 05:30:06 UTC): Oh, that probably is a better idea.

These are the docs for the release process: https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PROVIDER_PACKAGES.md

vincbeck (Issue Creator) on (2024-12-09 15:23:27 UTC): Cool :) I'll update the PR

vincbeck (Issue Creator) on (2024-12-09 16:18:25 UTC): I just realized, the release should not be updated because the assets are not released. It should be in the install process

vincbeck (Issue Creator) on (2024-12-09 16:25:07 UTC): Also it seems there is already some plumbing and automations set up to generate the assets automatically when creating a virtual env with hatch so I think I'll keep everything in that file. That will simplify things. I added a test in the script to do it only if the fab provider package is installed

vincbeck (Issue Creator) on (2024-12-11 16:09:27 UTC): @jedcunningham WDYT?

"
2723784829,pull_request,closed,,Add constant for airflow base version,"This is meant to be used in providers.  E.g.

```
if AIRFLOW_BASE_VERSION >= ""2.10.0"":
    do_something()
```
",dstandish,2024-12-06 19:37:04+00:00,[],2025-01-26 23:20:05+00:00,2025-01-26 23:20:00+00:00,https://github.com/apache/airflow/pull/44743,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2575546944, 'issue_id': 2723784829, 'author': 'eladkal', 'body': 'I think we no longer need this PR? cc @potiuk', 'created_at': datetime.datetime(2025, 1, 7, 15, 14, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614630466, 'issue_id': 2723784829, 'author': 'potiuk', 'body': 'Yep', 'created_at': datetime.datetime(2025, 1, 26, 23, 20, 4, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-01-07 15:14:29 UTC): I think we no longer need this PR? cc @potiuk

potiuk on (2025-01-26 23:20:04 UTC): Yep

"
2723779535,pull_request,closed,,Add DagsFolderDagBundle to db during migration/init,"This adds the DagsFolderDagBundle (aka the bundle exposing the folder configured in `[core] DAGS_FOLDER`) as a bundle in the db.

It will be added during migrations, and when you init a fresh db from the ORM models. It will not, however, recreate it you've chosen to remove it from an existing instance when that instance starts.",jedcunningham,2024-12-06 19:33:18+00:00,[],2024-12-13 22:28:12+00:00,2024-12-13 22:28:07+00:00,https://github.com/apache/airflow/pull/44742,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2542482306, 'issue_id': 2723779535, 'author': 'jedcunningham', 'body': 'Replaced by #44924, which moves this into config.', 'created_at': datetime.datetime(2024, 12, 13, 22, 28, 4, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-13 22:28:04 UTC): Replaced by #44924, which moves this into config.

"
2723765695,pull_request,closed,,Fix #43349 newsfragment,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
I accidentally named #43349 's newsfragment for the wrong PR.
This should fix it.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-06 19:24:19+00:00,[],2024-12-06 20:05:09+00:00,2024-12-06 20:05:06+00:00,https://github.com/apache/airflow/pull/44741,[],[],
2723744778,pull_request,closed,,Remove deprecations from SFTP Provider,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-06 19:10:06+00:00,[],2024-12-07 08:12:40+00:00,2024-12-07 08:12:40+00:00,https://github.com/apache/airflow/pull/44740,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:sftp', '')]","[{'comment_id': 2524288049, 'issue_id': 2723744778, 'author': 'jscheffl', 'body': 'There is something wrong with selective tests,  making full tests here, then I assume good to merge if green', 'created_at': datetime.datetime(2024, 12, 6, 22, 19, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2524288425, 'issue_id': 2723744778, 'author': 'jscheffl', 'body': 'Need to close/open to force a re-build...', 'created_at': datetime.datetime(2024, 12, 6, 22, 19, 43, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-06 22:19:19 UTC): There is something wrong with selective tests,  making full tests here, then I assume good to merge if green

jscheffl on (2024-12-06 22:19:43 UTC): Need to close/open to force a re-build...

"
2723458859,pull_request,closed,,AIP-84 Add filter by dag_id in recent_dag_runs,"

closes: #44606


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-06 16:25:58+00:00,[],2024-12-11 11:06:48+00:00,2024-12-11 11:06:48+00:00,https://github.com/apache/airflow/pull/44737,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2723395188,pull_request,closed,,AIP-84 Filter task instances list by task id and display name,"

closes: #44670




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-06 16:00:43+00:00,[],2024-12-10 21:27:35+00:00,2024-12-10 21:27:34+00:00,https://github.com/apache/airflow/pull/44736,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2528666042, 'issue_id': 2723395188, 'author': 'jason810496', 'body': 'Just resolve, move `QueryTaskDisplayNamePatternSearch` to common paramters.', 'created_at': datetime.datetime(2024, 12, 9, 16, 45, 8, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-12-09 16:45:08 UTC): Just resolve, move `QueryTaskDisplayNamePatternSearch` to common paramters.

"
2723122895,pull_request,closed,,[Edge] Fix edge worker api support none default base api url,"# Description

If Airflow deployment runs on none default base url the Edge worker api auth fails. The Edge worker api auth compares the method names which include  the url path. But auth does not know on which sub url it is running. Auth detects a mismatch and blocks the request.

# Details about changes
* Edge worker uses pure method name (url path without base url)
* Edge worker api auth compares method name without using the url_prefix",AutomationDev85,2024-12-06 13:55:57+00:00,[],2024-12-09 21:08:04+00:00,2024-12-09 21:08:04+00:00,https://github.com/apache/airflow/pull/44732,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2723096651,pull_request,closed,,Fix system test for Dataform operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have fixed system test and updated documentation for Dataform operators

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-12-06 13:44:40+00:00,[],2024-12-06 14:41:07+00:00,2024-12-06 14:41:07+00:00,https://github.com/apache/airflow/pull/44729,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2723072003,pull_request,closed,,Bumping common compat to 1.3.0,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Saw a failure here https://github.com/apache/airflow/actions/runs/12198668361/job/34031197381?pr=44723

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-06 13:31:56+00:00,[],2024-12-06 13:34:50+00:00,2024-12-06 13:34:50+00:00,https://github.com/apache/airflow/pull/44728,"[('area:providers', ''), ('provider:common-compat', '')]","[{'comment_id': 2523268063, 'issue_id': 2723072003, 'author': 'potiuk', 'body': 'Ah yes. cross-PRs merged', 'created_at': datetime.datetime(2024, 12, 6, 13, 33, 46, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-06 13:33:46 UTC): Ah yes. cross-PRs merged

"
2723052698,pull_request,closed,,Add retry to the PowerBIDatasetRefreshOperator refresh status requests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/44618

In the issue, we notice an inconsistent behavior from the task: while the dataset refresh is successful, the task may (or not) fail. From what I understood, it seems that the task fails when the request to get the refresh status is ""too fast"" (right after the refresh creation) and the API does not recognize the refreshId.

To fix this, I suggest to add a retry decorator on the function that requests the refresh status, as well as an `api_timeout` variable (stored in a field in both the trigger and the operator). This way, if the first request fails to get the refresh status, other requests are sent (during a period of `api_timeout` seconds).

For example, here is what the logs could look like (in case of failure):

![image](https://github.com/user-attachments/assets/8a82edae-4005-43fb-adbd-8d8f6bf26f96)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Ohashiro,2024-12-06 13:22:04+00:00,[],2024-12-27 13:41:28+00:00,2024-12-27 13:41:28+00:00,https://github.com/apache/airflow/pull/44726,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2563695959, 'issue_id': 2723052698, 'author': 'dabla', 'body': ""This PR can be closed as we don't want to introduce custom retry mechanism within an operator.  A new PR should be opened as discussed in issue [#44618](https://github.com/apache/airflow/issues/44618) in which we decrease the check_interval to 10 seconds by default and also add a validation that check_interval must be lower than the timeout, otherwise the check_interval has no effect."", 'created_at': datetime.datetime(2024, 12, 27, 13, 19, 50, tzinfo=datetime.timezone.utc)}]","dabla on (2024-12-27 13:19:50 UTC): This PR can be closed as we don't want to introduce custom retry mechanism within an operator.  A new PR should be opened as discussed in issue [#44618](https://github.com/apache/airflow/issues/44618) in which we decrease the check_interval to 10 seconds by default and also add a validation that check_interval must be lower than the timeout, otherwise the check_interval has no effect.

"
2723004234,pull_request,closed,,AIP-72: Scaffold task instance RTIF API calls during task startup,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Dependent on https://github.com/apache/airflow/pull/44692 and only commit: 91ec0388dd1df79eecf3400120fc5ec94966d939 onwards is relevant.

This PR adds an example of how we should be calling the `set_rtif` endpoint as introduced in https://github.com/apache/airflow/pull/44692 from the task runner.

The idea is to implement a portion where we call this API using maybe dummy values from task sdk - startup(). Later when we have mechanism for ""rendering"", we can replace the params


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-06 12:58:04+00:00,['amoghrajesh'],2024-12-10 12:58:42+00:00,2024-12-10 12:58:40+00:00,https://github.com/apache/airflow/pull/44725,"[('area:task-sdk', None)]","[{'comment_id': 2531568683, 'issue_id': 2723004234, 'author': 'amoghrajesh', 'body': 'Thanks for the review, merging this one.', 'created_at': datetime.datetime(2024, 12, 10, 12, 58, 29, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-10 12:58:29 UTC): Thanks for the review, merging this one.

"
2722770186,pull_request,closed,,AIP-72: Adding client tests for all task instance operations,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

We have basic sanity tests for every type of operation in the SDK API client, like variables, xcom. We do not have this for task instances, adding it through this PR. The aim is to maintain client sanity while developing new APIs for the execution API

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-06 11:20:17+00:00,['amoghrajesh'],2024-12-09 08:58:06+00:00,2024-12-09 08:07:21+00:00,https://github.com/apache/airflow/pull/44723,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2722601538,pull_request,closed,,[Backport] Update Dependency Detector to handle dependencies set via partial,"Original PR - https://github.com/apache/airflow/pull/42578

The DAG dependency view shows dependencies for DAGs that are available at DAG parsing/serialization time.  Dynamically mapped tasks that trigger (via `TriggerDagRunOperator`) or wait for (via `ExternalTaskSensor`) external DAGs are now listed as DAG dependencies provided that those dependencies are set via `partial`, and not dynamically expanded.

(cherry picked from commit 0a136f96cc3652c860e159a06364e3107bdaaa6d)
",utkarsharma2,2024-12-06 10:07:40+00:00,[],2025-02-07 00:15:16+00:00,2025-02-07 00:15:16+00:00,https://github.com/apache/airflow/pull/44721,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:serialization', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2628605351, 'issue_id': 2722601538, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 1, 0, 16, 17, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-02-01 00:16:17 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2722569146,pull_request,closed,,Add information about chicken-egg providers in contributing docs,"Chicken-egg providers have not been fully described - the case where two providers depend on each other have not been mentioned as a use case in release management docs, also the providers have not been mentioned in provider's contributing docs.

This PR addresses both problems.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-06 09:51:56+00:00,[],2024-12-06 15:33:19+00:00,2024-12-06 15:33:17+00:00,https://github.com/apache/airflow/pull/44720,"[('area:dev-tools', '')]",[],
2722504437,pull_request,closed,,Deprecate VertexAI PaLM text generative model,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have deprecated VertexAI PaLM text generative model. Here is the link for documentation with deprecation dates: https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/palm

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-12-06 09:19:39+00:00,[],2024-12-06 13:15:01+00:00,2024-12-06 13:15:01+00:00,https://github.com/apache/airflow/pull/44719,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2722353326,pull_request,closed,,Made get_conn in JdbcHook threadsafe to avoid OSError: JVM is already started,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

When using our in house [IterableOperator](https://github.com/apache/airflow/pull/42572/) to allow easy multithreading with operators within the same worker, we discovered a thread safety issue with the JdbcHook.  As multiple threads where trying to get a connection through the jaydebeapi libary, we sometimes got random ""OSError: JVM is already started"" errors, due to the high concurrency/parallelism, something you won't experience if you do the same using the expand mapped task as each task instance is then run on a different Python process.

To fix the issue I made the get_conn method of the JdbcHook synchronized and added a unit test which simulates the behaviour to avoid regression in the future so this is well documented through a test.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-12-06 08:07:12+00:00,[],2024-12-13 16:53:50+00:00,2024-12-13 16:53:50+00:00,https://github.com/apache/airflow/pull/44718,"[('area:providers', ''), ('provider:jdbc', '')]","[{'comment_id': 2541445005, 'issue_id': 2722353326, 'author': 'dabla', 'body': '@potiuk modified the code as you asked I think this one is ok now', 'created_at': datetime.datetime(2024, 12, 13, 13, 17, 7, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2024-12-13 13:17:07 UTC): @potiuk modified the code as you asked I think this one is ok now

"
2722332787,pull_request,closed,,Remove Provider Deprecations in Trino ,"Related: #44559 

Remove deprecated code from trino provider from operators and test. Update Changelog

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2024-12-06 07:58:50+00:00,[],2024-12-10 16:02:51+00:00,2024-12-10 07:30:56+00:00,https://github.com/apache/airflow/pull/44717,"[('area:providers', ''), ('provider:trino', '')]","[{'comment_id': 2526368289, 'issue_id': 2722332787, 'author': 'potiuk', 'body': 'Can you fix the tests please ?', 'created_at': datetime.datetime(2024, 12, 8, 20, 32, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527775508, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': 'Would you please tell me how to fix this test ? \r\n\r\nThere is only one deprecated class  `TrinoOperator` in [providers/src/airflow/providers/trino/operators/trino.py](url) \r\n\r\nWhen I fixed `mypy` and removed that files , they showed me deprecated module error \r\n\r\nTo fix I have added that files again but but it failed here.', 'created_at': datetime.datetime(2024, 12, 9, 12, 20, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2528147494, 'issue_id': 2722332787, 'author': 'potiuk', 'body': 'This tests uses TrinoOperator:\r\n\r\n```python\r\n    @mock.patch.dict(""os.environ"", AIRFLOW_CONN_TRINO_DEFAULT=""trino://airflow@trino:8080/"")\r\n    def test_openlineage_methods(self):\r\n        op = TrinoOperator(task_id=""trino_test"", sql=""SELECT name FROM tpch.sf1.customer LIMIT 3"")\r\n        op.execute({})\r\n        lineage = op.get_openlineage_facets_on_start()\r\n        assert lineage.inputs[0].namespace == ""trino://trino:8080""\r\n        assert lineage.inputs[0].name == ""tpch.sf1.customer""\r\n        assert ""schema"" in lineage.inputs[0].facets\r\n        assert lineage.job_facets[""sql""].query == ""SELECT name FROM tpch.sf1.customer LIMIT 3""\r\n\r\n```\r\n\r\nReplace with SQLExecuteQueryOperator -as suggested by deprecation message.', 'created_at': datetime.datetime(2024, 12, 9, 14, 41, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530242795, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': 'Done!', 'created_at': datetime.datetime(2024, 12, 10, 4, 6, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531641343, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': 'I am Sorry \r\nCould you please tell me where I can add this test code ?\r\n\r\n[providers/tests/trino/hooks/test_trino.py](url) ? here ?', 'created_at': datetime.datetime(2024, 12, 10, 13, 28, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531642130, 'issue_id': 2722332787, 'author': 'eladkal', 'body': '> [providers/tests/trino/hooks/test_trino.py](https://github.com/apache/airflow/pull/url) ? here ?\r\n\r\nThat would be ok', 'created_at': datetime.datetime(2024, 12, 10, 13, 29, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531658819, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': 'Would you please tell me which test I should run to check if it is okay or not ? \r\n\r\nDoes this work ? \r\n` breeze testing providers-tests --test-type ""Providers[trino]""`\r\n\r\nit passed at that time', 'created_at': datetime.datetime(2024, 12, 10, 13, 36, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531694352, 'issue_id': 2722332787, 'author': 'kacpermuda', 'body': '[Here](https://github.com/apache/airflow/actions/runs/12254530942/job/34193202147?pr=44477) is an example where this test failed. It was triggered with `./scripts/ci/testing/run_integration_tests_with_retry.sh providers ""trino""`, maybe try that?', 'created_at': datetime.datetime(2024, 12, 10, 13, 50, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531698603, 'issue_id': 2722332787, 'author': 'kacpermuda', 'body': 'Ah, sorry you meant the other test. Yes, the breeze command looks good.', 'created_at': datetime.datetime(2024, 12, 10, 13, 51, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531716376, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': 'No, you are right. I am asking about the provider test, not Breeze, so I can know about that.\r\nThe Breeze tests failed due to my mistakes. \r\nSorry, I am a newbie, so I don’t know about all this. I am trying to learn', 'created_at': datetime.datetime(2024, 12, 10, 13, 59, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532097393, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': '@eladkal  ,I am confused. Would You please tell me if I should add this method here \r\n\r\n[providers/tests/integration/trino/hooks/test_trino.py](url)  because this file contains similar methods\r\nor [[providers/tests/trino/hooks/test_trino.py]](url)', 'created_at': datetime.datetime(2024, 12, 10, 15, 41, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532129025, 'issue_id': 2722332787, 'author': 'eladkal', 'body': ""I'm not sure I follow the issue.\r\nThe test this PR removed was in `providers/tests/trino/operators/test_trino.py`\r\nSo we just need to bring it back, the best candidate is `providers/tests/trino/hooks/test_trino.py`\r\n\r\nWhy are we discussing system tests path?"", 'created_at': datetime.datetime(2024, 12, 10, 15, 53, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532145196, 'issue_id': 2722332787, 'author': 'Prab-27', 'body': 'Sorry , You are right I have noticed a similar method `test_openlineage_methods`  at here so I asked [providers/tests/integration/trino/hooks/test_trino.py](url)', 'created_at': datetime.datetime(2024, 12, 10, 16, 0, 7, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-08 20:32:01 UTC): Can you fix the tests please ?

Prab-27 (Issue Creator) on (2024-12-09 12:20:33 UTC): Would you please tell me how to fix this test ? 

There is only one deprecated class  `TrinoOperator` in [providers/src/airflow/providers/trino/operators/trino.py](url) 

When I fixed `mypy` and removed that files , they showed me deprecated module error 

To fix I have added that files again but but it failed here.

potiuk on (2024-12-09 14:41:26 UTC): This tests uses TrinoOperator:

```python
    @mock.patch.dict(""os.environ"", AIRFLOW_CONN_TRINO_DEFAULT=""trino://airflow@trino:8080/"")
    def test_openlineage_methods(self):
        op = TrinoOperator(task_id=""trino_test"", sql=""SELECT name FROM tpch.sf1.customer LIMIT 3"")
        op.execute({})
        lineage = op.get_openlineage_facets_on_start()
        assert lineage.inputs[0].namespace == ""trino://trino:8080""
        assert lineage.inputs[0].name == ""tpch.sf1.customer""
        assert ""schema"" in lineage.inputs[0].facets
        assert lineage.job_facets[""sql""].query == ""SELECT name FROM tpch.sf1.customer LIMIT 3""

```

Replace with SQLExecuteQueryOperator -as suggested by deprecation message.

Prab-27 (Issue Creator) on (2024-12-10 04:06:36 UTC): Done!

Prab-27 (Issue Creator) on (2024-12-10 13:28:38 UTC): I am Sorry 
Could you please tell me where I can add this test code ?

[providers/tests/trino/hooks/test_trino.py](url) ? here ?

eladkal on (2024-12-10 13:29:01 UTC): That would be ok

Prab-27 (Issue Creator) on (2024-12-10 13:36:35 UTC): Would you please tell me which test I should run to check if it is okay or not ? 

Does this work ? 
` breeze testing providers-tests --test-type ""Providers[trino]""`

it passed at that time

kacpermuda on (2024-12-10 13:50:29 UTC): [Here](https://github.com/apache/airflow/actions/runs/12254530942/job/34193202147?pr=44477) is an example where this test failed. It was triggered with `./scripts/ci/testing/run_integration_tests_with_retry.sh providers ""trino""`, maybe try that?

kacpermuda on (2024-12-10 13:51:51 UTC): Ah, sorry you meant the other test. Yes, the breeze command looks good.

Prab-27 (Issue Creator) on (2024-12-10 13:59:24 UTC): No, you are right. I am asking about the provider test, not Breeze, so I can know about that.
The Breeze tests failed due to my mistakes. 
Sorry, I am a newbie, so I don’t know about all this. I am trying to learn

Prab-27 (Issue Creator) on (2024-12-10 15:41:35 UTC): @eladkal  ,I am confused. Would You please tell me if I should add this method here 

[providers/tests/integration/trino/hooks/test_trino.py](url)  because this file contains similar methods
or [[providers/tests/trino/hooks/test_trino.py]](url)

eladkal on (2024-12-10 15:53:43 UTC): I'm not sure I follow the issue.
The test this PR removed was in `providers/tests/trino/operators/test_trino.py`
So we just need to bring it back, the best candidate is `providers/tests/trino/hooks/test_trino.py`

Why are we discussing system tests path?

Prab-27 (Issue Creator) on (2024-12-10 16:00:07 UTC): Sorry , You are right I have noticed a similar method `test_openlineage_methods`  at here so I asked [providers/tests/integration/trino/hooks/test_trino.py](url)

"
2722215950,pull_request,closed,,[Edge] Make edge executor db access multi instance save,"# Description

We see in our multi scheduler deployment cyclic crashes of the scheduler. This points to the issue that different edge executors trying to work on the same DB items during cleaning up the edge jobs items. Add usage of locks so that the edge executor only works which DB items which are not used by other edge executors.

# Details about changes
* Usage of locks on DB items with are used by the edge executor.
* Locked items are ignored by the other edge executors.",AutomationDev85,2024-12-06 06:57:35+00:00,[],2024-12-06 08:49:49+00:00,2024-12-06 08:49:49+00:00,https://github.com/apache/airflow/pull/44716,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2722194033,pull_request,closed,,Remove deprecations from Apache hive Provider,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-06 06:42:13+00:00,[],2024-12-07 04:03:00+00:00,2024-12-07 04:02:58+00:00,https://github.com/apache/airflow/pull/44715,"[('area:providers', ''), ('provider:apache-hive', '')]",[],
2722192429,pull_request,closed,,Remove unnecessary compatibility code in S3 asset import,"The S3 asset import had a conditional code to import assets but
it is unnecessary, because the compatibility code is added to
common.compat provider - but only in the upcoming version so we have
to make sure that common.compat is added to ""chicken-egg"" providers,
so that constaraints are properly generated for PyPI packages.

This is also the case where we can bump manually provider version
without waiting for release time - because we need to depend on the
new provider version in amazon provider.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-06 06:40:57+00:00,[],2024-12-06 09:53:28+00:00,2024-12-06 09:53:26+00:00,https://github.com/apache/airflow/pull/44714,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('provider:common-compat', '')]","[{'comment_id': 2522262068, 'issue_id': 2722192429, 'author': 'potiuk', 'body': 'Extracted from #44686 - I found this unnecessary compatibility code while looing and consistency of version checks across all providers.', 'created_at': datetime.datetime(2024, 12, 6, 6, 46, 42, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-06 06:46:42 UTC): Extracted from #44686 - I found this unnecessary compatibility code while looing and consistency of version checks across all providers.

"
2722092840,pull_request,closed,,Prevent __init__.py in providers from being modified,"Fixes: #44024

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-06 05:16:52+00:00,[],2024-12-06 10:17:10+00:00,2024-12-06 10:17:07+00:00,https://github.com/apache/airflow/pull/44713,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:fab', ''), ('provider:common-compat', '')]","[{'comment_id': 2522165135, 'issue_id': 2722092840, 'author': 'potiuk', 'body': 'Extracted  from #44686', 'created_at': datetime.datetime(2024, 12, 6, 5, 17, 57, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-06 05:17:57 UTC): Extracted  from #44686

"
2721917497,pull_request,closed,,"[AIP-86] Add Deadline Alerts table, model, and supporting tests.","First step on implementingAIP-86 is to add a new db table.

Adds the new table and related migrations, models, unit tests, etc.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-12-06 02:45:47+00:00,[],2024-12-19 19:06:26+00:00,2024-12-19 19:06:24+00:00,https://github.com/apache/airflow/pull/44712,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2524068248, 'issue_id': 2721917497, 'author': 'ferruzzi', 'body': ""I think maybe this needs the Airflow3: Breaking label to pass a couple of those tests?  I'm not entirely sure though, so I'll hold off on that for now.  If anyone knows for sure, please feel free to add it.\r\n\r\nMany of the failing tests seem to revolve around the new `deadline` table I'm adding here not existing.  I'll have to look at the contributing docs and see if I can figure out what I missed."", 'created_at': datetime.datetime(2024, 12, 6, 20, 7, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532485096, 'issue_id': 2721917497, 'author': 'ferruzzi', 'body': ""I've implemented the suggested change to the table schema.\r\n\r\nI had assumed the auto-generated sha file would meet static check requirements, silly me.  I'll add a commit fixing that and adding the newsfragment, and I have added the 3.0-breaking label.  Let's see if that gets me green."", 'created_at': datetime.datetime(2024, 12, 10, 18, 3, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532503249, 'issue_id': 2721917497, 'author': 'vincbeck', 'body': ""> I've implemented the suggested change to the table schema.\r\n> \r\n> I had assumed the auto-generated sha file would meet static check requirements, silly me. I'll add a commit fixing that and adding the newsfragment, and I have added the 3.0-breaking label. Let's see if that gets me green.\r\n\r\nDo we need a newsfragment? As far as I know this is not a breaking change"", 'created_at': datetime.datetime(2024, 12, 10, 18, 10, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532518432, 'issue_id': 2721917497, 'author': 'ferruzzi', 'body': ""> Do we need a newsfragment? As far as I know this is not a breaking change\r\n\r\nThe CI test was failing because I didn't have one, so I added one.    I made it 44712.significant, but maybe it should be 44712.feature?"", 'created_at': datetime.datetime(2024, 12, 10, 18, 15, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532564992, 'issue_id': 2721917497, 'author': 'vincbeck', 'body': ""> > Do we need a newsfragment? As far as I know this is not a breaking change\r\n> \r\n> The CI test was failing because I didn't have one, so I added one. I made it 44712.significant, but maybe it should be 44712.feature?\r\n\r\nInteresting. I did not know we had such tests. At least, yes, I'd say `.feature` is better"", 'created_at': datetime.datetime(2024, 12, 10, 18, 26, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532566490, 'issue_id': 2721917497, 'author': 'vincbeck', 'body': 'Why do you need the label ""airflow3.0:breaking""?', 'created_at': datetime.datetime(2024, 12, 10, 18, 27, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547274165, 'issue_id': 2721917497, 'author': 'ferruzzi', 'body': 'Cool, looks like that fixed the migration part.   I have to fix static checks and rework the unit tests now to account for those changes.  Thanks to Ephraim and Daniel for your help on that.', 'created_at': datetime.datetime(2024, 12, 17, 0, 55, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547380381, 'issue_id': 2721917497, 'author': 'ferruzzi', 'body': ""Since we are using DagRun.id (a sequential integer) instead of DagRun.run_id (a string) I think calling it `run_id` is going to cause confusion.  Is there any precedent or any suggestion on how to rename that parameter in the Deadline?\r\n\r\nI also can't seem to figure out how to fix that fkey constraint failure.  I don't suppose one of you might have a sec to have a look at it for me?  (@vincbeck @ephraimbuddy @dstandish)  I've added asserts to the test to make sure the dagrun is being created in the db and that the dagun.id is what I expect it to be.   I'm not sure what the mismatch is, here.\r\n\r\n[EDIT]   Is this maybe because the DagRun.id is NOT NULLABLE but Deadline.run_id is NULLABLE?   I bet that's it....\r\n\r\n[EDIT 2]  It wasn't.   It was because the dag_run.id is always 1 when ruin in series, but unpredictable when tests are run in parallel.   Adjusted the unit test accordingly."", 'created_at': datetime.datetime(2024, 12, 17, 2, 40, 1, tzinfo=datetime.timezone.utc)}]","ferruzzi (Issue Creator) on (2024-12-06 20:07:12 UTC): I think maybe this needs the Airflow3: Breaking label to pass a couple of those tests?  I'm not entirely sure though, so I'll hold off on that for now.  If anyone knows for sure, please feel free to add it.

Many of the failing tests seem to revolve around the new `deadline` table I'm adding here not existing.  I'll have to look at the contributing docs and see if I can figure out what I missed.

ferruzzi (Issue Creator) on (2024-12-10 18:03:43 UTC): I've implemented the suggested change to the table schema.

I had assumed the auto-generated sha file would meet static check requirements, silly me.  I'll add a commit fixing that and adding the newsfragment, and I have added the 3.0-breaking label.  Let's see if that gets me green.

vincbeck on (2024-12-10 18:10:31 UTC): Do we need a newsfragment? As far as I know this is not a breaking change

ferruzzi (Issue Creator) on (2024-12-10 18:15:30 UTC): The CI test was failing because I didn't have one, so I added one.    I made it 44712.significant, but maybe it should be 44712.feature?

vincbeck on (2024-12-10 18:26:22 UTC): Interesting. I did not know we had such tests. At least, yes, I'd say `.feature` is better

vincbeck on (2024-12-10 18:27:09 UTC): Why do you need the label ""airflow3.0:breaking""?

ferruzzi (Issue Creator) on (2024-12-17 00:55:03 UTC): Cool, looks like that fixed the migration part.   I have to fix static checks and rework the unit tests now to account for those changes.  Thanks to Ephraim and Daniel for your help on that.

ferruzzi (Issue Creator) on (2024-12-17 02:40:01 UTC): Since we are using DagRun.id (a sequential integer) instead of DagRun.run_id (a string) I think calling it `run_id` is going to cause confusion.  Is there any precedent or any suggestion on how to rename that parameter in the Deadline?

I also can't seem to figure out how to fix that fkey constraint failure.  I don't suppose one of you might have a sec to have a look at it for me?  (@vincbeck @ephraimbuddy @dstandish)  I've added asserts to the test to make sure the dagrun is being created in the db and that the dagun.id is what I expect it to be.   I'm not sure what the mismatch is, here.

[EDIT]   Is this maybe because the DagRun.id is NOT NULLABLE but Deadline.run_id is NULLABLE?   I bet that's it....

[EDIT 2]  It wasn't.   It was because the dag_run.id is always 1 when ruin in series, but unpredictable when tests are run in parallel.   Adjusted the unit test accordingly.

"
2721871473,pull_request,closed,,Implement asset.multi,"This allows a function to emit multiple assets. In this case, you are on your own providing proper names to each asset, but it would work.

Also includes refactoring to the existing decorator mechanism so we don't need to repeat code (especially arguments).

Close #42316.",uranusjr,2024-12-06 02:05:09+00:00,[],2024-12-06 14:22:29+00:00,2024-12-06 14:22:26+00:00,https://github.com/apache/airflow/pull/44711,"[('AIP-75', 'Asset-Centric Syntax'), ('area:task-sdk', None)]",[],
2721858918,pull_request,closed,,AIP-67 - Introduce team id to executor names and loader,"When multi team (AIP-67) is eventually in place, the scheduler will need to initialize a set of executors for each team. This change is a first step towards that which updates the ExecutorName data model and the executor loader to be ""team aware"".

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-12-06 01:52:57+00:00,[],2024-12-14 06:12:28+00:00,2024-12-13 22:58:03+00:00,https://github.com/apache/airflow/pull/44710,"[('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('aip-67', 'multi-team')]","[{'comment_id': 2523712402, 'issue_id': 2721858918, 'author': 'o-nikolas', 'body': 'CC @potiuk', 'created_at': datetime.datetime(2024, 12, 6, 16, 45, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542515566, 'issue_id': 2721858918, 'author': 'o-nikolas', 'body': ""> I assume that it is done as part of AIP-67 - I think that it's worth mentioning it in the title and contents, as well as creating a project for that so it will become easier to track.\r\n\r\nYupp this is AIP-67. That's a fair call out, I'll update the description, title and add a tag.\r\nI have a [project plan document here](https://docs.google.com/document/d/11rKo5D2QpT5NvMtDR1RZDjaih5jT5H-dt0aepkfmXSE/edit?usp=sharing) which you can read if you're interested. I planned to also create a project board but am still working through the process of disambiguation and really feeling out how it will be pulled off. Once I have a few of the more foundational topics sorted and I have more clarity I will put a board together.\r\n\r\n> Before merging this one, it would be nice to have a roadmap so it would be clearer to understand the broaded context of this task :slightly_smiling_face:\r\n\r\nAs I said above, I'll work on this, but it has never before been a requirement of merging PRs. And I don't think it's wise to add that barrier to our contribution process. So I don't think it should block this PR's merge."", 'created_at': datetime.datetime(2024, 12, 13, 22, 55, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542846977, 'issue_id': 2721858918, 'author': 'shahar1', 'body': ""> > I assume that it is done as part of AIP-67 - I think that it's worth mentioning it in the title and contents, as well as creating a project for that so it will become easier to track.\r\n> \r\n> Yupp this is AIP-67. That's a fair call out, I'll update the description, title and add a tag. I have a [project plan document here](https://docs.google.com/document/d/11rKo5D2QpT5NvMtDR1RZDjaih5jT5H-dt0aepkfmXSE/edit?usp=sharing) which you can read if you're interested. I planned to also create a project board but am still working through the process of disambiguation and really feeling out how it will be pulled off. Once I have a few of the more foundational topics sorted and I have more clarity I will put a board together.\r\n> \r\n> > Before merging this one, it would be nice to have a roadmap so it would be clearer to understand the broaded context of this task 🙂\r\n> \r\n> As I said above, I'll work on this, but it has never before been a requirement of merging PRs. And I don't think it's wise to add that barrier to our contribution process. So I don't think it should block this PR's merge.\r\n\r\nI apologize if it was interpreted as a barrier/blocker - it wasn't my intention at all. The doc that you created is exactly what I was looking for, just to understand how it's going to work."", 'created_at': datetime.datetime(2024, 12, 14, 6, 12, 28, tzinfo=datetime.timezone.utc)}]","o-nikolas (Issue Creator) on (2024-12-06 16:45:23 UTC): CC @potiuk

o-nikolas (Issue Creator) on (2024-12-13 22:55:07 UTC): Yupp this is AIP-67. That's a fair call out, I'll update the description, title and add a tag.
I have a [project plan document here](https://docs.google.com/document/d/11rKo5D2QpT5NvMtDR1RZDjaih5jT5H-dt0aepkfmXSE/edit?usp=sharing) which you can read if you're interested. I planned to also create a project board but am still working through the process of disambiguation and really feeling out how it will be pulled off. Once I have a few of the more foundational topics sorted and I have more clarity I will put a board together.


As I said above, I'll work on this, but it has never before been a requirement of merging PRs. And I don't think it's wise to add that barrier to our contribution process. So I don't think it should block this PR's merge.

shahar1 on (2024-12-14 06:12:28 UTC): I apologize if it was interpreted as a barrier/blocker - it wasn't my intention at all. The doc that you created is exactly what I was looking for, just to understand how it's going to work.

"
2721666694,pull_request,closed,,Make AssetAliasEvent a class context.py,"We don't use this class anywhere else, so it's better for it to live in this module instead.

I also changed it into a simple class instead since it does not really make sense for it to be a dict.

~~⚠️ IMPORTANT ⚠️ We need to do some deprecation in the 2.x branch later.~~ Actually, maybe not? This is never intended as public API at all. Although technically users technically can access them with `context[""outlet_events""][dataset].dataset_alias_events`, the attribute is not documented anywhere (we only ever said there’s `extras` available), and the values are not useful to users.",uranusjr,2024-12-05 23:28:51+00:00,[],2024-12-06 03:06:14+00:00,2024-12-06 03:06:13+00:00,https://github.com/apache/airflow/pull/44709,"[('area:providers', ''), ('area:serialization', ''), ('provider:common-compat', ''), ('area:task-sdk', None)]",[],
2721592860,pull_request,closed,,Get rid of AssetAliasCondition,"Instead of having a separate class for condition evaluation, we can just use the main AssetAlias class directly. While it technically makes sense to subclass AssetAny, AssetAliasCondition does not really reuse much of its implementation, and we can just implement the missing methods ourselves instead. Whether the class actually is an AssetAny does not really make much of a difference.

This actually allows us to simplify quite some code (including tests) a bit since we don't need to rewrap AssetAlias back and forth.",uranusjr,2024-12-05 22:44:15+00:00,[],2024-12-06 03:05:57+00:00,2024-12-06 03:05:55+00:00,https://github.com/apache/airflow/pull/44708,"[('area:serialization', ''), ('area:task-sdk', None)]",[],
2721481013,pull_request,closed,,Remove Provider Deprecations in Sqlite,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Sqlite

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-05 21:37:12+00:00,[],2024-12-10 21:12:15+00:00,2024-12-07 09:13:10+00:00,https://github.com/apache/airflow/pull/44707,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:sqlite', '')]","[{'comment_id': 2521517064, 'issue_id': 2721481013, 'author': 'gopidesupavan', 'body': 'Can you please also update the docs? https://github.com/apache/airflow/blob/main/docs/apache-airflow-providers-sqlite/operators.rst?plain=1#L20', 'created_at': datetime.datetime(2024, 12, 5, 21, 44, 38, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-12-05 21:44:38 UTC): Can you please also update the docs? https://github.com/apache/airflow/blob/main/docs/apache-airflow-providers-sqlite/operators.rst?plain=1#L20

"
2721393400,pull_request,closed,,Remove deprecated cli commands from the `db` group,"I've added these to the ""legacy commands"" list, so Airflow will return a
helpful error message if someone does run them.
    
e.g.

```
$ airflow db upgrade
Usage: airflow db [-h] COMMAND ...

Database operations

Positional Arguments:
  COMMAND
    check             Check if the database can be reached
    check-migrations  Check if migration have finished
    clean             Purge old records in metastore tables
    downgrade         Downgrade the schema of the metadata database.
    drop-archived     Drop archived tables created through the db clean command
    export-archived   Export archived data from the archive tables
    migrate           Migrates the metadata database to the latest version
    reset             Burn down and rebuild the metadata database
    shell             Runs a shell to access the database

Options:
  -h, --help          show this help message and exit

airflow db command error: argument COMMAND: Command `db upgrade` has been removed. Please use `airflow db migrate`, see help above.
```    ",jedcunningham,2024-12-05 21:00:02+00:00,[],2024-12-06 18:40:12+00:00,2024-12-06 18:40:11+00:00,https://github.com/apache/airflow/pull/44706,"[('area:CLI', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2721354125,pull_request,closed,,Remove Provider Deprecations in Postgres,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Postgres

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-05 20:44:09+00:00,[],2024-12-06 18:43:51+00:00,2024-12-06 18:43:51+00:00,https://github.com/apache/airflow/pull/44705,"[('area:providers', ''), ('provider:postgres', '')]",[],
2721289406,pull_request,closed,,Remove Provider Deprecations in Oracle,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is for the provider Oracle

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-05 20:06:17+00:00,[],2024-12-06 21:50:17+00:00,2024-12-06 21:50:17+00:00,https://github.com/apache/airflow/pull/44704,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:oracle', '')]","[{'comment_id': 2521523451, 'issue_id': 2721289406, 'author': 'gopidesupavan', 'body': 'Doc updates please https://github.com/apache/airflow/blob/main/docs/apache-airflow-providers-oracle/operators/index.rst?plain=1#L29?', 'created_at': datetime.datetime(2024, 12, 5, 21, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2521525435, 'issue_id': 2721289406, 'author': 'jscheffl', 'body': '> Doc updates please https://github.com/apache/airflow/blob/main/docs/apache-airflow-providers-oracle/operators/index.rst?plain=1#L29?\r\n\r\nuuups, yeah, totally over-looked this :-( Thanks for the hints!', 'created_at': datetime.datetime(2024, 12, 5, 21, 49, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2521529731, 'issue_id': 2721289406, 'author': 'gopidesupavan', 'body': '> > Doc updates please https://github.com/apache/airflow/blob/main/docs/apache-airflow-providers-oracle/operators/index.rst?plain=1#L29?\r\n> \r\n> uuups, yeah, totally over-looked this :-( Thanks for the hints!\r\n\r\nBetter to verifying docs if the deprecation is completely removing the class :)', 'created_at': datetime.datetime(2024, 12, 5, 21, 52, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2524117766, 'issue_id': 2721289406, 'author': 'gopidesupavan', 'body': '@jscheffl it seems the test failures are because of this https://github.com/apache/airflow/pull/44704/files#diff-a1ced97245f107006f7a972734c2e5e7ff79da3816f5762c6c2bc1fc2e17f806R26. may be removing these deprecations  `providers/src/airflow/providers/common/sql/hooks/sql.py` solve ?', 'created_at': datetime.datetime(2024, 12, 6, 20, 32, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2524132509, 'issue_id': 2721289406, 'author': 'gopidesupavan', 'body': '> @jscheffl it seems the test failures are because of this https://github.com/apache/airflow/pull/44704/files#diff-a1ced97245f107006f7a972734c2e5e7ff79da3816f5762c6c2bc1fc2e17f806R26. may be removing these deprecations `providers/src/airflow/providers/common/sql/hooks/sql.py` solve ?\r\n\r\nor is it something related dag versioning', 'created_at': datetime.datetime(2024, 12, 6, 20, 36, 39, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-12-05 21:48:00 UTC): Doc updates please https://github.com/apache/airflow/blob/main/docs/apache-airflow-providers-oracle/operators/index.rst?plain=1#L29?

jscheffl (Issue Creator) on (2024-12-05 21:49:23 UTC): uuups, yeah, totally over-looked this :-( Thanks for the hints!

gopidesupavan on (2024-12-05 21:52:15 UTC): Better to verifying docs if the deprecation is completely removing the class :)

gopidesupavan on (2024-12-06 20:32:37 UTC): @jscheffl it seems the test failures are because of this https://github.com/apache/airflow/pull/44704/files#diff-a1ced97245f107006f7a972734c2e5e7ff79da3816f5762c6c2bc1fc2e17f806R26. may be removing these deprecations  `providers/src/airflow/providers/common/sql/hooks/sql.py` solve ?

gopidesupavan on (2024-12-06 20:36:39 UTC): or is it something related dag versioning

"
2721192192,pull_request,closed,,AIP-38 Fix Graph not updating,"Under certain circumstances, the graph would not update. (When switching between two dags with the same number of nodes).

For instance switching from:
- `asset_consumes_1`
- to `asset1_producer`

Would still display the old graph. (1 node in both)",pierrejeambrun,2024-12-05 19:05:41+00:00,['pierrejeambrun'],2024-12-05 19:27:13+00:00,2024-12-05 19:27:10+00:00,https://github.com/apache/airflow/pull/44702,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2721171084,pull_request,closed,,AIP-84 Add external dependencies to GET Structure Data Endpoint,"Related to: https://github.com/apache/airflow/issues/42367

Adds the `external_dependencies` query parameter.

Supports `trigger`, `sensor`, `asset`, `asset_aliases`.

Sensor is back because `ExternalTaskSensor` is creating a `sensor` dependency type.

For now all that is `external` to the dag, and not specific to the `task_level`. Meaning that they are attached to the dag (first task of the dag) and not to the specific tasks. (i.e task outlets for assets for instance)",pierrejeambrun,2024-12-05 18:53:19+00:00,['pierrejeambrun'],2024-12-12 23:28:49+00:00,2024-12-12 23:28:47+00:00,https://github.com/apache/airflow/pull/44701,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2539140079, 'issue_id': 2721171084, 'author': 'pierrejeambrun', 'body': ""> example_external_task_marker_parent: did not have any downstream deps\r\n\r\nIndeed. That's a limitation we have at the moment in the backend in `detect_task_dependencies`.  only `TriggerDagRunOperator` and `ExternalTaskSensor` are supported. `ExternalTaskMarker` is not. We might want to add it but this will impact the serialized dags and I'm not sure yet how free we are of updating that. (and how this dependencies are then used by the scheduler I assume). We will need to discuss that with other to confirm the feasibility of that approach.\r\n\r\nI will open a dedicated issue to track that because its not straight forward.\r\n\r\nedit: Dedicated issue here https://github.com/apache/airflow/issues/44879"", 'created_at': datetime.datetime(2024, 12, 12, 14, 40, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539282868, 'issue_id': 2721171084, 'author': 'pierrejeambrun', 'body': '> example_trigger_controller_dag`: the dependency comes back as upstream when it should be downstream\r\n\r\nGood catch, fixed, also added a test for that.', 'created_at': datetime.datetime(2024, 12, 12, 15, 26, 28, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-12-12 14:40:04 UTC): Indeed. That's a limitation we have at the moment in the backend in `detect_task_dependencies`.  only `TriggerDagRunOperator` and `ExternalTaskSensor` are supported. `ExternalTaskMarker` is not. We might want to add it but this will impact the serialized dags and I'm not sure yet how free we are of updating that. (and how this dependencies are then used by the scheduler I assume). We will need to discuss that with other to confirm the feasibility of that approach.

I will open a dedicated issue to track that because its not straight forward.

edit: Dedicated issue here https://github.com/apache/airflow/issues/44879

pierrejeambrun (Issue Creator) on (2024-12-12 15:26:28 UTC): Good catch, fixed, also added a test for that.

"
2721099556,pull_request,closed,,Removed deprecated code from provider Apach.beam,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Relates to: #44559 
Remove deprecated code from apache.beam

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ajitg25,2024-12-05 18:17:18+00:00,[],2024-12-06 12:02:33+00:00,2024-12-06 12:02:33+00:00,https://github.com/apache/airflow/pull/44700,"[('area:providers', ''), ('provider:apache-beam', '')]",[],
2721049103,pull_request,closed,,Add DagFolderDagBundle to expose the DAG folder as a bundle,Why not simply use LocalDagBundle? This keeps the config for the traditional `[core] dags_folder` in the Airflow config system.,jedcunningham,2024-12-05 17:49:10+00:00,[],2024-12-05 21:16:09+00:00,2024-12-05 21:16:07+00:00,https://github.com/apache/airflow/pull/44699,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2721009056,pull_request,closed,,Set explicit branch name in GitDagBundle tests,"Instead of relying on the default value of `init.defaultBranch`, lets explicitly set a branch name so the tests work regardless of the config setting.",jedcunningham,2024-12-05 17:28:23+00:00,[],2024-12-05 19:06:50+00:00,2024-12-05 19:06:49+00:00,https://github.com/apache/airflow/pull/44698,"[('AIP-66: DAG Bundle/Manifest', '')]",[],
2720771987,pull_request,closed,,feat: automatically inject OL info into spark properties in DataprocInstantiateInlineWorkflowTemplateOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Wait for #44477 and #44612 to be merged.

This PR integrates a newly introduced (#44477) OpenLineage feature into another Dataproc operator. With this enhancement, users no longer need to manually provide parent job information for the OpenLineage Spark integration to generate the parent job facet. Detailed information about this feature can be found in the description of #44477.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-05 15:50:21+00:00,[],2025-01-02 08:15:06+00:00,2025-01-02 08:14:19+00:00,https://github.com/apache/airflow/pull/44697,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:openlineage', 'AIP-53'), ('provider:common-compat', '')]",[],
2720482868,pull_request,closed,,PowerBIDatasetRefreshOperator should fail when refresh fails,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/44613

The PR aims to:
- make the `PowerBIDatasetRefreshOperator` check the dataset refresh status, so that the task fails if the refresh has failed
- transmit the refresh error message in the logs if the refresh has failed:

<img width=""750"" alt=""image"" src=""https://github.com/user-attachments/assets/c06c3c0f-a4be-4253-8c61-496a719e6805"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Ohashiro,2024-12-05 13:53:11+00:00,[],2024-12-19 20:45:45+00:00,2024-12-19 20:45:41+00:00,https://github.com/apache/airflow/pull/44696,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2520389824, 'issue_id': 2720482868, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 5, 13, 53, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2555741743, 'issue_id': 2720482868, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 19, 20, 45, 43, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-05 13:53:15 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-12-19 20:45:43 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2720379836,pull_request,closed,,Add an event status in powerbi.py,"closes: #44613

Add the following statuses:

```python
INTERMEDIATE_STATES = (
    ""Unknown""
)

SUCCESS_STATES = (
    ""Completed""
)

FAILURE_STATES = (
    ""Failed"",
    ""Disabled""
)

TERMINAL_STATES = (
    ""Completed"",
    ""Failed"",
    ""Disabled""
)
```

Change `powerbi.py` line 144 (original line 129) 
from:
* `if event[""status""] == ""error"":`
to:
* `if event[""status""] in self.FAILURE_STATES:`

related document:
https://learn.microsoft.com/en-us/rest/api/power-bi/datasets/get-refresh-history#refresh
",JE-Chen,2024-12-05 13:10:26+00:00,[],2024-12-05 14:04:52+00:00,2024-12-05 14:04:51+00:00,https://github.com/apache/airflow/pull/44695,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2520286961, 'issue_id': 2720379836, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 5, 13, 10, 33, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-05 13:10:33 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2720198251,pull_request,closed,,Remove deprecations from Slack Provider,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-05 11:50:51+00:00,[],2024-12-06 18:51:15+00:00,2024-12-06 18:51:15+00:00,https://github.com/apache/airflow/pull/44693,"[('area:providers', ''), ('provider:slack', '')]",[],
2720133312,pull_request,closed,,AIP-72: Adding Endpoint to set rendered task instance fields,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44359 

### Why is it needed?
The change is needed so that we can support templating `rendered_fields` with the airflow tasks. We can provide jinja templated values for the fields that support templating, like `bash_command` for BashOperator or `op_kwargs` for PythonOperator. Example DAG:
```
with DAG(
    'simple_bash_dag',
    default_args=default_args,
    schedule=None,
    start_date=datetime(2024, 1, 1),
) as dag:

    def _extract_data(current_dag_run_date):
        print(""the date is"", current_dag_run_date)


    PythonOperator(
        task_id=""extract_task"",
        python_callable=_extract_data,
        op_kwargs={
            ""current_dag_run_date"": ""{{ds}}""
        }
    )
```

### Brief of changes

#### Execution API
Added an endpoint under task_instances route to be able to set rendered task instance fields. This will be called by the task runner (actually task directly)

The intended call flow would be like so:
1. Task proc launches, waits for StartupDetails
2. Supervisor sends that
3. Task parses dag, gets task
4. Task sends RTIF up to supervisor
5. Supervisor sends start request inc. RTIF
6. Task only executes task when it gets response

So the execution API need not care about what data has come in, all it cares is if the task sent the data in form of:
`dict[<field>: <rendered format of the field>]`. The job of rendering is of the task itself.

Added a RootModel instead of a BaseModel to avoid an uneccesary level in the request.

#### Client
Adding the client endpoint for `set_rtif`. This will send an API call to the execution API to set RTIF for a task instance.

### Testing

#### Testing the API directly using API client like postman
1. Go to your Airflow UI and run any DAG you wish with atleast one normal task. I am using this one:
![image](https://github.com/user-attachments/assets/c0845184-b980-4c52-bde4-3b6ebe02aeee)

2. Gather the dag id, run id, task id from the UI

3. Go to your metadata DB and get the `id` for the task instance from the `task_instance` table.
![image](https://github.com/user-attachments/assets/258a177f-84dd-4b39-a27d-3304cbe27f1c)

4. Send the PUT request. I am using postman
![image](https://github.com/user-attachments/assets/11e94613-472a-43fd-bf26-39e6944ad7e2)

5. Check the RTIF table
![image](https://github.com/user-attachments/assets/579cd437-b154-4a94-9c7a-bc72c78e845e)

![image](https://github.com/user-attachments/assets/fd201663-4245-4c30-9c9a-40f0f7927388)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-05 11:22:09+00:00,['amoghrajesh'],2024-12-09 07:40:34+00:00,2024-12-09 06:05:07+00:00,https://github.com/apache/airflow/pull/44692,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]","[{'comment_id': 2525000510, 'issue_id': 2720133312, 'author': 'amoghrajesh', 'body': 'Thanks for the review, I will merge this one @ashb', 'created_at': datetime.datetime(2024, 12, 7, 8, 4, 15, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-07 08:04:15 UTC): Thanks for the review, I will merge this one @ashb

"
2720054711,pull_request,closed,,Remove deprecations from Oracle Provider ,"related: https://github.com/apache/airflow/issues/44559

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-05 10:46:42+00:00,[],2024-12-06 06:19:02+00:00,2024-12-06 06:19:02+00:00,https://github.com/apache/airflow/pull/44691,"[('area:providers', ''), ('provider:oracle', '')]","[{'comment_id': 2522231720, 'issue_id': 2720054711, 'author': 'vatsrahul1001', 'body': 'closing in favour of https://github.com/apache/airflow/pull/44704', 'created_at': datetime.datetime(2024, 12, 6, 6, 19, 2, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-12-06 06:19:02 UTC): closing in favour of https://github.com/apache/airflow/pull/44704

"
2720010456,pull_request,closed,,Fix accidental db tests in Task SDK,"We accidentally added some db tests in the SDK test suite, which has been incorrectly skipped since the SDK is not supposed to interact with db. The test is legistimate (it’s for a custom operator only used on task execution), but we need to mock those db calls instead.

Calls that need db are now always done lazily (when Airflow core is available), and functions all moved to `airflow.models` and tested there instead.

A Pytest hook is also added to check the `db_test` marker does not exist, to ensure this does not happen again.",uranusjr,2024-12-05 10:28:10+00:00,[],2024-12-08 22:22:50+00:00,2024-12-05 21:58:46+00:00,https://github.com/apache/airflow/pull/44690,"[('area:providers', ''), ('provider:common-compat', ''), ('area:task-sdk', None)]","[{'comment_id': 2526410469, 'issue_id': 2720010456, 'author': 'potiuk', 'body': 'Maybe we should add some code to fail, rather than skip if db_tests are run in `task_sdk`?', 'created_at': datetime.datetime(2024, 12, 8, 22, 22, 48, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-08 22:22:48 UTC): Maybe we should add some code to fail, rather than skip if db_tests are run in `task_sdk`?

"
2719965710,pull_request,closed,,Add foreign key ti_id in `TaskReschedule` and other models,"This PR attempts to fix #44147.

I added `ti_id` to `TaskReschedule` , `BaseXcom`, `TaskInstanceNote`, `RenderedTIFields` and `TaskMap`

TODO
----

- [ ]  Update unit tests",SuccessMoses,2024-12-05 10:14:13+00:00,[],2025-02-09 00:16:31+00:00,2025-02-09 00:16:31+00:00,https://github.com/apache/airflow/pull/44687,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2556981462, 'issue_id': 2719965710, 'author': 'SuccessMoses', 'body': '@potiuk, is it a good idea to remove `task_id`, `run_id`, `dag_id` and `map_index` ?', 'created_at': datetime.datetime(2024, 12, 20, 13, 14, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2632467008, 'issue_id': 2719965710, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 4, 0, 14, 55, tzinfo=datetime.timezone.utc)}]","SuccessMoses (Issue Creator) on (2024-12-20 13:14:20 UTC): @potiuk, is it a good idea to remove `task_id`, `run_id`, `dag_id` and `map_index` ?

github-actions[bot] on (2025-02-04 00:14:55 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2719846712,pull_request,closed,,Consistent way of checking Airflow version in providers,"This PR introduces consistent way of checking version of Airflow
by Airflow providers. So far there were about 6 different ways on
how Providers checked for Airflow version - this PR aims to unify
this approach for now and in the future - at least until minimum
version of Airflow set to 2.11 where we are likely to introduce
a simpler check via https://github.com/apache/airflow/pull/44607. Until then all providers are going
to have `version_references.py` module copied in their sources
that they will be importing the constants from.

This PR also adds pre-commit that checks if the
``version_compat.py`` module is imported from local package copy
or maybe from another provider or test code - both causing
unneeded dependencies from the provider - to another package or
to test code respectively.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-05 09:25:18+00:00,[],2024-12-10 07:35:52+00:00,2024-12-10 07:35:51+00:00,https://github.com/apache/airflow/pull/44686,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-io', ''), ('provider:common-compat', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2519944796, 'issue_id': 2719846712, 'author': 'kacpermuda', 'body': 'Great idea, thanks Jarek !', 'created_at': datetime.datetime(2024, 12, 5, 10, 44, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520464515, 'issue_id': 2719846712, 'author': 'ashb', 'body': '> Such constants can be imported in the code and used to implement conditional logic for different versions of Airflow.\r\n\r\nWhy do we even need this?', 'created_at': datetime.datetime(2024, 12, 5, 14, 23, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520491105, 'issue_id': 2719846712, 'author': 'ashb', 'body': '> to me, this seems like too much. all we really need is for it to be just a little bit easier to know the core airflow version, it seems to me.\r\n\r\nWhich we already have:\r\n\r\n```\r\nAIRFLOW_VERSION = Version(airflow_version)\r\nAIRFLOW_V_3_0_PLUS = Version(AIRFLOW_VERSION.base_version) >= Version(""3.0.0"")\r\n```', 'created_at': datetime.datetime(2024, 12, 5, 14, 33, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520492675, 'issue_id': 2719846712, 'author': 'ashb', 'body': 'There are also changes in this PR like version bumps etc that are entirely unrelated to the PR as given in the description.', 'created_at': datetime.datetime(2024, 12, 5, 14, 34, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520500823, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'Well previous atetmpts led to multiple errors - like updating `__init__.py` that is already auto generated, importing version checks from multiple unrelated places or lack of dependency to a common compat provider where it was needed. \r\n\r\nNone of the previous proposals solved all those problems, so I am not sure what is the constructive idea to solve them differently. I would really like to see another, simpler solution for those.', 'created_at': datetime.datetime(2024, 12, 5, 14, 37, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520503534, 'issue_id': 2719846712, 'author': 'potiuk', 'body': '> There are also changes in this PR like version bumps etc that are entirely unrelated to the PR as given in the description.\r\n\r\nYep. the changelog was excessive - I just fixed the generateio in latest push and I am going to remove those changes from this PR', 'created_at': datetime.datetime(2024, 12, 5, 14, 38, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520541705, 'issue_id': 2719846712, 'author': 'potiuk', 'body': ""Generally when you come to checking airflow version and having compat code we have two choices:\r\n\r\n* rely on compat provider -> and then maintain dependencies and add dependency to the compat providers\r\n* not DRY version code in each provider\r\n\r\nThis is a variant of not DRY version code in Airflow provider - that people tried to update in a few places over last few weeks and made at least 4 mistakes  - like overwriting __init__.py (where it makes most sense to keep it), adding constans in different packages, importing constants from different packages, importing constants from test code instead of providers. \r\n\r\nI mean - yes, it's not **simple** code - but it addreses at least 4 problems I know that happened recently in the way that all this is automated so that those mistakes are impossible or very difficult to make. \r\n\r\nWhat's wrong with that? Would you prefer to keep release manager fixing mistakes of those people at the relaase time (happened already once https://github.com/apache/airflow/pull/44011#discussion_r1841786333  and was supposed to happen again: https://github.com/apache/airflow/pull/43773#discussion_r1867636526\r\n\r\nNone of the solution proposed in the last two day addressed those."", 'created_at': datetime.datetime(2024, 12, 5, 14, 54, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520561868, 'issue_id': 2719846712, 'author': 'potiuk', 'body': ""> > There are also changes in this PR like version bumps etc that are entirely unrelated to the PR as given in the description.\r\n> \r\n> Yep. the changelog was excessive - I just fixed the generateio in latest push and I am going to remove those changes from this PR\r\n\r\nThose changes are now removed (and bug in breeze that caused it is fixed as part of that PR). Happy to extract this fix to separate PR if you think it's a good idea @ashb"", 'created_at': datetime.datetime(2024, 12, 5, 15, 1, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522179806, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'After - unnecessary i think - heated discussion I decided to split off (following suggestion of @dstandish) the ""non-controversial part of this PR to https://github.com/apache/airflow/pull/44713/ - and will follow up with rebasing/fixing this one after a devlist discussion I am going to start in a moment.', 'created_at': datetime.datetime(2024, 12, 6, 5, 34, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522245217, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'Devlist discussion started https://lists.apache.org/thread/px36w3ph2mf0pmv377dtfc2nhpq8dqw1', 'created_at': datetime.datetime(2024, 12, 6, 6, 31, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522271167, 'issue_id': 2719846712, 'author': 'potiuk', 'body': '> Very cool - THANKS!\r\n\r\nThanks @jscheffl and @kacpermuda  for that, really appreciated.  I was really buffled and I thought I am loosing sanity as I saw very clearly how this one is needed - seeing how strongly @ashb and @dstandish reacted to it. But I see that this is maybe they did not understand the full context and reasoning for the change, or that it is just strong difference in opinions (and that others have different opinions). \r\n\r\nSo I extracted all pieces that should be ""uncontroversial"" from it and started the devlist  discussion above and I hope we can  get to consensus, rebase this PR eventually and maybe apply some comments that might arise separately. I think this is one is pretty useful to have in this form or another, because we already experienced problems with inconsistent version handling.', 'created_at': datetime.datetime(2024, 12, 6, 6, 54, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522904089, 'issue_id': 2719846712, 'author': 'ashb', 'body': 'A quick POC knocked up using `ruff analyze graph` output:\r\n\r\n```\r\npython ./scripts/ci/pre_commit/check_provider_cross_deps.py\r\nwarning: `ruff analyze graph` is experimental and may change without warning\r\n\'providers/src/airflow/providers/airbyte/hooks/airbyte.py\' imports from the \'common.compat\' but doesn\'t list it as a dependency!\r\n\'providers/src/airflow/providers/celery/executors/celery_executor_utils.py\' imports from the \'standard\' but doesn\'t list it as a dependency!\r\n\'providers/src/airflow/providers/edge/example_dags/integration_test.py\' imports from the \'standard\' but doesn\'t list it as a dependency!\r\n```\r\n\r\nThe first was me adding an import to test, the other two are \r\n\r\n```\r\ntry:\r\n    from airflow.providers.standard.operators.bash import BashOperator\r\nexcept ImportError:\r\n    from airflow.operators.bash import BashOperator  # type: ignore[no-redef,attr-defined]\r\n```\r\n\r\n\r\n<details>\r\n\r\n<summary>POC code in here:</summary>\r\n\r\n```python\r\nfrom __future__ import annotations\r\n\r\nimport json\r\nimport os\r\nimport subprocess\r\nimport sys\r\nfrom functools import cache\r\nfrom pathlib import Path\r\n\r\nAIRFLOW_ROOT_PATH = Path(__file__).parents[3].resolve()\r\nGENERATED_PROVIDERS_DEPENDENCIES_FILE = AIRFLOW_ROOT_PATH / ""generated"" / ""provider_dependencies.json""\r\nPROVIDER_DEPENDENCIES = json.loads(GENERATED_PROVIDERS_DEPENDENCIES_FILE.read_text())\r\n\r\nPROVIDERS_REL_SRC = Path(""providers/src/"")\r\nPROVIDERS_NS_REL_SRC = Path(""providers/src/airflow/providers/"")\r\n\r\n\r\n@cache\r\ndef rel_file_to_provider_name(rel_name: str):\r\n    try:\r\n        rel = Path(rel_name).relative_to(PROVIDERS_NS_REL_SRC)\r\n\r\n    except ValueError:\r\n        # Not a provider file\r\n        return None\r\n\r\n    if rel.suffix == "".py"":\r\n        rel = rel.parent\r\n\r\n    # This checks for two levels existing as a key in PROVIDER_DEPENDENCIES (i.e. ""airbyte"" or\r\n    # ""common.compat"") -- if we ever have an ""airflow.providers.ns1.ns2.packge"" we will need to change this\r\n    for name in (rel.parts[0], ""."".join(rel.parts[0:2])):\r\n        if name in PROVIDER_DEPENDENCIES:\r\n            return name\r\n    return None\r\n\r\n\r\ndef main():\r\n    # Ask ruff to analyze the import graphs\r\n    import_tree_str = subprocess.check_output(\r\n        [""ruff"", ""analyze"", ""graph"", os.fspath(AIRFLOW_ROOT_PATH / PROVIDERS_REL_SRC)]\r\n    )\r\n\r\n    import_tree = json.loads(import_tree_str)\r\n    invalid_imports_found = False\r\n\r\n    for file, imports in import_tree.items():\r\n        this_provider = rel_file_to_provider_name(file)\r\n        imported_cross_providers = set(\r\n            filter(\r\n                lambda x: x not in (None, this_provider),\r\n                (rel_file_to_provider_name(imported_file) for imported_file in imports),\r\n            )\r\n        )\r\n        for cross_provider in imported_cross_providers:\r\n            if cross_provider not in PROVIDER_DEPENDENCIES[this_provider][""cross-providers-deps""]:\r\n                # TODO: rich\r\n                print(\r\n                    f""{file!r} imports from the {cross_provider!r} but doesn\'t list it as a dependency!"",\r\n                    file=sys.stderr,\r\n                )\r\n                invalid_imports_found = True\r\n\r\n\r\nif __name__ == ""__main__"":\r\n    main()\r\n```\r\n\r\n</details>', 'created_at': datetime.datetime(2024, 12, 6, 11, 9, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525233126, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'Interestig. This ""ruff analyze graph"" is cool. We could use it to replace some of the stuff we do when we generate cross-provider dependencies - we were using it by AST analysis, but we can likely get the speed of rust for that . Really cool tool.\r\n\r\nThings like this - make it really useful to get it even more accurate:\r\n\r\n```\r\n  --detect-string-imports\r\n          Attempt to detect imports from string literals\r\n```', 'created_at': datetime.datetime(2024, 12, 7, 16, 19, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525298095, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'OK. I reworked it to follow the suggestion by @ashb (i.e. using `ruff analyze graph`. I managed to work out to work it out to catch both `other provider` imports and `tests_common` wrong import - and added documentation explaining why we are doing it and what the contributors should do, when they want to add version check support to their provider:\r\n\r\nExample pre-commit errors:\r\n\r\nWhen you import from tests_common:\r\n\r\n![image](https://github.com/user-attachments/assets/76d7164e-fdd9-43e9-869c-cc7503fedab4)\r\n\r\nWhen you import from another provider:\r\n\r\n![image](https://github.com/user-attachments/assets/d74eae7c-2349-4568-a86a-f357534f5287)\r\n\r\nThe change is way bigger than the original one, because I had to extract the `version` commands from `tests_utils.compat` to `version_compat` - because `ruff analyze graph`  produces output on a file level, and that was the easy way to check - if `version_compat` is being imported, it should be from the same provider.\r\n\r\nLookig forward to feedback and comments.', 'created_at': datetime.datetime(2024, 12, 7, 20, 13, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525301976, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'BTW. If needs be - I can very easily split that change into extracting the version constants in tests to `version_compat.py` (big but straightforward change) and separately making the ""provider version code"" usage consistent + pre-commit.', 'created_at': datetime.datetime(2024, 12, 7, 20, 29, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525315426, 'issue_id': 2719846712, 'author': 'ashb', 'body': 'Thanks very much for making these changes Jarek', 'created_at': datetime.datetime(2024, 12, 7, 21, 26, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525535313, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'I think this one should be green. I also extracted out the pure refactor of test version constants to ""version_compat"" module - that will make this one much smaller (and makes it way easier to see if version_compat is used properly in the `ruff analyze graph` json output - #44770. If we merge #44770, this one will be much easier to review', 'created_at': datetime.datetime(2024, 12, 8, 8, 17, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526203789, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'Rebased after merging #44774  - this should be now much easier to review :)', 'created_at': datetime.datetime(2024, 12, 8, 16, 16, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530677457, 'issue_id': 2719846712, 'author': 'potiuk', 'body': 'Merging it `as is` then. We can always iterate on it later.', 'created_at': datetime.datetime(2024, 12, 10, 7, 35, 41, tzinfo=datetime.timezone.utc)}]","kacpermuda on (2024-12-05 10:44:09 UTC): Great idea, thanks Jarek !

ashb on (2024-12-05 14:23:14 UTC): Why do we even need this?

ashb on (2024-12-05 14:33:46 UTC): Which we already have:

```
AIRFLOW_VERSION = Version(airflow_version)
AIRFLOW_V_3_0_PLUS = Version(AIRFLOW_VERSION.base_version) >= Version(""3.0.0"")
```

ashb on (2024-12-05 14:34:23 UTC): There are also changes in this PR like version bumps etc that are entirely unrelated to the PR as given in the description.

potiuk (Issue Creator) on (2024-12-05 14:37:39 UTC): Well previous atetmpts led to multiple errors - like updating `__init__.py` that is already auto generated, importing version checks from multiple unrelated places or lack of dependency to a common compat provider where it was needed. 

None of the previous proposals solved all those problems, so I am not sure what is the constructive idea to solve them differently. I would really like to see another, simpler solution for those.

potiuk (Issue Creator) on (2024-12-05 14:38:50 UTC): Yep. the changelog was excessive - I just fixed the generateio in latest push and I am going to remove those changes from this PR

potiuk (Issue Creator) on (2024-12-05 14:54:02 UTC): Generally when you come to checking airflow version and having compat code we have two choices:

* rely on compat provider -> and then maintain dependencies and add dependency to the compat providers
* not DRY version code in each provider

This is a variant of not DRY version code in Airflow provider - that people tried to update in a few places over last few weeks and made at least 4 mistakes  - like overwriting __init__.py (where it makes most sense to keep it), adding constans in different packages, importing constants from different packages, importing constants from test code instead of providers. 

I mean - yes, it's not **simple** code - but it addreses at least 4 problems I know that happened recently in the way that all this is automated so that those mistakes are impossible or very difficult to make. 

What's wrong with that? Would you prefer to keep release manager fixing mistakes of those people at the relaase time (happened already once https://github.com/apache/airflow/pull/44011#discussion_r1841786333  and was supposed to happen again: https://github.com/apache/airflow/pull/43773#discussion_r1867636526

None of the solution proposed in the last two day addressed those.

potiuk (Issue Creator) on (2024-12-05 15:01:57 UTC): Those changes are now removed (and bug in breeze that caused it is fixed as part of that PR). Happy to extract this fix to separate PR if you think it's a good idea @ashb

potiuk (Issue Creator) on (2024-12-06 05:34:24 UTC): After - unnecessary i think - heated discussion I decided to split off (following suggestion of @dstandish) the ""non-controversial part of this PR to https://github.com/apache/airflow/pull/44713/ - and will follow up with rebasing/fixing this one after a devlist discussion I am going to start in a moment.

potiuk (Issue Creator) on (2024-12-06 06:31:32 UTC): Devlist discussion started https://lists.apache.org/thread/px36w3ph2mf0pmv377dtfc2nhpq8dqw1

potiuk (Issue Creator) on (2024-12-06 06:54:35 UTC): Thanks @jscheffl and @kacpermuda  for that, really appreciated.  I was really buffled and I thought I am loosing sanity as I saw very clearly how this one is needed - seeing how strongly @ashb and @dstandish reacted to it. But I see that this is maybe they did not understand the full context and reasoning for the change, or that it is just strong difference in opinions (and that others have different opinions). 

So I extracted all pieces that should be ""uncontroversial"" from it and started the devlist  discussion above and I hope we can  get to consensus, rebase this PR eventually and maybe apply some comments that might arise separately. I think this is one is pretty useful to have in this form or another, because we already experienced problems with inconsistent version handling.

ashb on (2024-12-06 11:09:12 UTC): A quick POC knocked up using `ruff analyze graph` output:

```
python ./scripts/ci/pre_commit/check_provider_cross_deps.py
warning: `ruff analyze graph` is experimental and may change without warning
'providers/src/airflow/providers/airbyte/hooks/airbyte.py' imports from the 'common.compat' but doesn't list it as a dependency!
'providers/src/airflow/providers/celery/executors/celery_executor_utils.py' imports from the 'standard' but doesn't list it as a dependency!
'providers/src/airflow/providers/edge/example_dags/integration_test.py' imports from the 'standard' but doesn't list it as a dependency!
```

The first was me adding an import to test, the other two are 

```
try:
    from airflow.providers.standard.operators.bash import BashOperator
except ImportError:
    from airflow.operators.bash import BashOperator  # type: ignore[no-redef,attr-defined]
```


<details>

<summary>POC code in here:</summary>

```python
from __future__ import annotations

import json
import os
import subprocess
import sys
from functools import cache
from pathlib import Path

AIRFLOW_ROOT_PATH = Path(__file__).parents[3].resolve()
GENERATED_PROVIDERS_DEPENDENCIES_FILE = AIRFLOW_ROOT_PATH / ""generated"" / ""provider_dependencies.json""
PROVIDER_DEPENDENCIES = json.loads(GENERATED_PROVIDERS_DEPENDENCIES_FILE.read_text())

PROVIDERS_REL_SRC = Path(""providers/src/"")
PROVIDERS_NS_REL_SRC = Path(""providers/src/airflow/providers/"")


@cache
def rel_file_to_provider_name(rel_name: str):
    try:
        rel = Path(rel_name).relative_to(PROVIDERS_NS_REL_SRC)

    except ValueError:
        # Not a provider file
        return None

    if rel.suffix == "".py"":
        rel = rel.parent

    # This checks for two levels existing as a key in PROVIDER_DEPENDENCIES (i.e. ""airbyte"" or
    # ""common.compat"") -- if we ever have an ""airflow.providers.ns1.ns2.packge"" we will need to change this
    for name in (rel.parts[0], ""."".join(rel.parts[0:2])):
        if name in PROVIDER_DEPENDENCIES:
            return name
    return None


def main():
    # Ask ruff to analyze the import graphs
    import_tree_str = subprocess.check_output(
        [""ruff"", ""analyze"", ""graph"", os.fspath(AIRFLOW_ROOT_PATH / PROVIDERS_REL_SRC)]
    )

    import_tree = json.loads(import_tree_str)
    invalid_imports_found = False

    for file, imports in import_tree.items():
        this_provider = rel_file_to_provider_name(file)
        imported_cross_providers = set(
            filter(
                lambda x: x not in (None, this_provider),
                (rel_file_to_provider_name(imported_file) for imported_file in imports),
            )
        )
        for cross_provider in imported_cross_providers:
            if cross_provider not in PROVIDER_DEPENDENCIES[this_provider][""cross-providers-deps""]:
                # TODO: rich
                print(
                    f""{file!r} imports from the {cross_provider!r} but doesn't list it as a dependency!"",
                    file=sys.stderr,
                )
                invalid_imports_found = True


if __name__ == ""__main__"":
    main()
```

</details>

potiuk (Issue Creator) on (2024-12-07 16:19:59 UTC): Interestig. This ""ruff analyze graph"" is cool. We could use it to replace some of the stuff we do when we generate cross-provider dependencies - we were using it by AST analysis, but we can likely get the speed of rust for that . Really cool tool.

Things like this - make it really useful to get it even more accurate:

```
  --detect-string-imports
          Attempt to detect imports from string literals
```

potiuk (Issue Creator) on (2024-12-07 20:13:15 UTC): OK. I reworked it to follow the suggestion by @ashb (i.e. using `ruff analyze graph`. I managed to work out to work it out to catch both `other provider` imports and `tests_common` wrong import - and added documentation explaining why we are doing it and what the contributors should do, when they want to add version check support to their provider:

Example pre-commit errors:

When you import from tests_common:

![image](https://github.com/user-attachments/assets/76d7164e-fdd9-43e9-869c-cc7503fedab4)

When you import from another provider:

![image](https://github.com/user-attachments/assets/d74eae7c-2349-4568-a86a-f357534f5287)

The change is way bigger than the original one, because I had to extract the `version` commands from `tests_utils.compat` to `version_compat` - because `ruff analyze graph`  produces output on a file level, and that was the easy way to check - if `version_compat` is being imported, it should be from the same provider.

Lookig forward to feedback and comments.

potiuk (Issue Creator) on (2024-12-07 20:29:31 UTC): BTW. If needs be - I can very easily split that change into extracting the version constants in tests to `version_compat.py` (big but straightforward change) and separately making the ""provider version code"" usage consistent + pre-commit.

ashb on (2024-12-07 21:26:21 UTC): Thanks very much for making these changes Jarek

potiuk (Issue Creator) on (2024-12-08 08:17:03 UTC): I think this one should be green. I also extracted out the pure refactor of test version constants to ""version_compat"" module - that will make this one much smaller (and makes it way easier to see if version_compat is used properly in the `ruff analyze graph` json output - #44770. If we merge #44770, this one will be much easier to review

potiuk (Issue Creator) on (2024-12-08 16:16:57 UTC): Rebased after merging #44774  - this should be now much easier to review :)

potiuk (Issue Creator) on (2024-12-10 07:35:41 UTC): Merging it `as is` then. We can always iterate on it later.

"
2719792147,pull_request,closed,,Bump uv to 0.5.6,"https://pypi.org/project/uv/

https://github.com/astral-sh/uv/blob/main/CHANGELOG.md

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-05 09:01:00+00:00,[],2024-12-05 10:02:35+00:00,2024-12-05 10:02:30+00:00,https://github.com/apache/airflow/pull/44684,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2719557312,pull_request,closed,,Add dag filter button links to homepage.,"Closes #44673 

Add a dag filter button similar to import errors using the badge used in metrics section. The counts will be added once the data is available from API.

![image](https://github.com/user-attachments/assets/2eba6746-b51a-4c1b-ab7b-886051abdea6)

![image](https://github.com/user-attachments/assets/1574d51d-2f8a-4e96-8dbd-da273aa0bee9)
",tirkarthi,2024-12-05 07:12:58+00:00,[],2024-12-05 14:41:10+00:00,2024-12-05 14:41:10+00:00,https://github.com/apache/airflow/pull/44682,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2719532381,pull_request,closed,,fix(providers/common/compat): add back add_input_dataset and add_output_dataset to NoOpCollector,"## Why
When the user has airflow < 2.10 installed, a provider that has not yet renamed datasets as assets (e.g., `apache-airflow-providers-amazon==8.28.0`) and `apache-airflow-providers-common-compat>=1.2.1` (with asset rename backward compatibility layer.), the user will get the following `hook_lineage_collector` after calling `get_hook_lineage_collector`.

```python
    class NoOpCollector:
        """"""
        NoOpCollector is a hook lineage collector that does nothing.

        It is used when you want to disable lineage collection.
        """"""


        def add_input_asset(self, *_, **__):
            pass

        def add_output_asset(self, *_, **__):
            pass
```

As the provider has not yet been updated to use asset methods, it is still called `add_input_dataset`, which causes an AttributeError as `add_input_dataset` does not exist in the returned `NoOpCollector`

## What

add back `add_input_dataset` and `add_output_dataset` for backward compat

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-05 07:02:44+00:00,[],2024-12-05 08:41:21+00:00,2024-12-05 08:41:18+00:00,https://github.com/apache/airflow/pull/44681,"[('area:providers', ''), ('provider:common-compat', '')]",[],
2719488321,pull_request,closed,,Fix name of private function in compat provider,This fixes the name to reflect the behavior - it changes asset kwargs to dataset kwargs.,jedcunningham,2024-12-05 06:40:21+00:00,[],2024-12-05 07:17:07+00:00,2024-12-05 07:17:05+00:00,https://github.com/apache/airflow/pull/44680,"[('area:providers', ''), ('provider:common-compat', '')]",[],
2719295746,pull_request,closed,,Fixing cli test failure in CI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fixing https://github.com/apache/airflow/actions/runs/12171824313/job/33949649869

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-05 04:38:29+00:00,[],2024-12-06 04:44:10+00:00,2024-12-06 04:44:10+00:00,https://github.com/apache/airflow/pull/44679,"[('area:CLI', '')]","[{'comment_id': 2519249724, 'issue_id': 2719295746, 'author': 'amoghrajesh', 'body': 'This PR might not be needed', 'created_at': datetime.datetime(2024, 12, 5, 5, 57, 34, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-05 05:57:34 UTC): This PR might not be needed

"
2719210788,pull_request,closed,,Use `StringID` for `bundle.name`,"This will automatically set collation for us, plus it's more consistent with string ids across the rest of Airflow.",jedcunningham,2024-12-05 03:16:51+00:00,[],2024-12-05 17:50:44+00:00,2024-12-05 17:50:43+00:00,https://github.com/apache/airflow/pull/44678,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2719107460,pull_request,closed,,Show version in new UI sidebar,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
related: #43710

Edited to move version to bottom of navbar.
<img width=""1173"" alt=""Screenshot 2024-12-05 at 3 36 41 PM"" src=""https://github.com/user-attachments/assets/e9321ed7-9bd3-4342-b695-6e9b23f94576"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dauinh,2024-12-05 01:27:47+00:00,[],2024-12-06 21:55:59+00:00,2024-12-06 15:41:48+00:00,https://github.com/apache/airflow/pull/44677,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2518889638, 'issue_id': 2719107460, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 5, 1, 27, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519003647, 'issue_id': 2719107460, 'author': 'jedcunningham', 'body': 'Thanks for the PR!\r\n\r\nI don\'t think shoving it in the users settings is the right place though. Can we maybe put it just under the user settings, here:\r\n\r\n\r\n![Screenshot 2024-12-04 at 8 19 53\u202fPM](https://github.com/user-attachments/assets/7bcd6a43-9d37-4931-bfa4-e3a19caf947e)\r\n\r\n\r\n\r\nWe also probably don\'t need the ""version"" part either.\r\n\r\nEdit: I see that was one idea @bbovenzi threw out, but I think out of the user settings menu would be better myself.', 'created_at': datetime.datetime(2024, 12, 5, 3, 21, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2521733878, 'issue_id': 2719107460, 'author': 'dauinh', 'body': 'Thank you everyone for your review! I have made changes as requested.', 'created_at': datetime.datetime(2024, 12, 5, 23, 45, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2523524171, 'issue_id': 2719107460, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 6, 15, 41, 51, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-05 01:27:52 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jedcunningham on (2024-12-05 03:21:19 UTC): Thanks for the PR!

I don't think shoving it in the users settings is the right place though. Can we maybe put it just under the user settings, here:


![Screenshot 2024-12-04 at 8 19 53 PM](https://github.com/user-attachments/assets/7bcd6a43-9d37-4931-bfa4-e3a19caf947e)



We also probably don't need the ""version"" part either.

Edit: I see that was one idea @bbovenzi threw out, but I think out of the user settings menu would be better myself.

dauinh (Issue Creator) on (2024-12-05 23:45:50 UTC): Thank you everyone for your review! I have made changes as requested.

boring-cyborg[bot] on (2024-12-06 15:41:51 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2719073049,pull_request,closed,,Added the ArangoDBCollectionOperator that executes collection operations in a ArangoDB database,"- Insert, replace, update and delete documents functionality included

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-12-05 00:48:36+00:00,[],2024-12-06 11:20:39+00:00,2024-12-06 11:20:39+00:00,https://github.com/apache/airflow/pull/44676,"[('area:providers', ''), ('provider:arangodb', '')]",[],
2718960935,pull_request,open,,Add request-reply operator to Microsoft Azure provider,"This PR adds a request-reply operator to implement the design pattern from Enterprise Integration Patterns, Hohpe, Woolf,
   Addison-Wesley, 2003

In particular, this means one could:
a) Create a service bus queue and topic for a batch process
b) set up an auto-scaling Azure Container Job listening to an Azure Service Bus queue for messages
c) create a DAG using the request-reply operator to start the Azure Container Job and capture the reply when it finishes.

Potential improvements:
* have the operator background itself while waiting for a reply. No need to tie up a worker thread while a remote process runs
* Provide more parameters to control the subscription to the reply queue. Right now it deregisters itself if not used for 6 hours and drops messages after 1 hour. This seems reasonable to me since this subscription should only exist for the life of the operator, but more configuration might help some use case I haven't thought of.


A working Azure Container App Job can be built using the scripts/event-job-aca.zsh in the repo https://github.com/perry2of5/http-file-rtrvr

A working DAG is provided below:

```
from datetime import datetime
from airflow import DAG
from airflow.utils.context import Context
from airflow.operators.python import PythonOperator
from airflow.providers.microsoft.azure.operators.asb import AzureServiceBusRequestReplyOperator
from azure.servicebus import ServiceBusMessage
import json

dag = DAG('test-http-req-reply-dag', description='Test sending message to HTTP download service',
          schedule_interval='0 12 * * *',
          start_date=datetime(2017, 3, 20), catchup=False)


def print_hello():
    return 'Hello world from first Airflow DAG!'


def body_generator(context: Context):
    # Define the request body here
    return '''
        {
            ""method"": ""GET"",
            ""url"": ""http://example.com/index.html"",
            ""save_to"": ""example/dag/1"",
            ""timeout_seconds"": 5
        }
        '''


def process_reply(message: ServiceBusMessage, context: Context):
    # Process the reply message here
    print(f""Received reply: {message}"")
    body = json.loads(str(message))
    context['ti'].xcom_push(key='URL', value=body['saved_to_fqn'])
    context['ti'].xcom_push(key='STATUS_CODE', value=body['status'])


def print_url(**context):
    url = context['ti'].xcom_pull(task_ids='send_request', key='URL')
    print('url:', url)


def print_status_code(**context):
    status_code = context['ti'].xcom_pull(task_ids='send_request', key='STATUS_CODE')
    print(""status_code"", status_code)


hello_operator = PythonOperator(task_id='hello_task', dag=dag, python_callable=print_hello)

send_request = AzureServiceBusRequestReplyOperator(
        task_id='send_request',
        dag=dag,
        request_queue_name=""file-rtrvr-request"",
        request_body_generator=body_generator,
        reply_topic_name=""file-rtrvr-complete"",
        max_wait_time=360, # 6 minutes, poll for messages is 5 minutes in Azure Container App Job
        reply_message_callback=process_reply,
        azure_service_bus_conn_id=""azure_service_bus_default"",
)

status_operator = PythonOperator(
    task_id='print_status_task',
    dag=dag,
    python_callable=print_status_code,
    provide_context=True,
)

url_operator = PythonOperator(
    task_id='done',
    dag=dag,
    python_callable=print_url,
    provide_context=True,
)


hello_operator >> send_request >> url_operator >> status_operator
```
",perry2of5,2024-12-04 23:07:09+00:00,[],2025-02-09 00:54:53+00:00,,https://github.com/apache/airflow/pull/44675,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2532331911, 'issue_id': 2718960935, 'author': 'perry2of5', 'body': 'Thank you for the review.', 'created_at': datetime.datetime(2024, 12, 10, 17, 17, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532375809, 'issue_id': 2718960935, 'author': 'perry2of5', 'body': 'Just want to check, right now several of the existing operators get a handle to the connection and call the Microsoft Azure library directly. These should really be refactored down into the hook as well, right? For example this: https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/microsoft/azure/operators/asb.py#L316-L339', 'created_at': datetime.datetime(2024, 12, 10, 17, 37, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533943215, 'issue_id': 2718960935, 'author': 'dabla', 'body': ""> Just want to check, right now several of the existing operators get a handle to the connection and call the Microsoft Azure library directly. These should really be refactored down into the hook as well, right? For example this: https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/microsoft/azure/operators/asb.py#L316-L339\r\n\r\nGood catch, indeed it would be better that this code resides within the hook, the hook should take care of the connection handling and exposes the logic within a public method which on it's turn is called from the operator, that way the same operation can also be executed from the hook within a PythonOperator.\r\n\r\nBut don't worry, there are still a lot of operators written that way unfortunately, but if we clean up every time we need to modify an operator, we will get there one day :-)"", 'created_at': datetime.datetime(2024, 12, 11, 7, 17, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536375618, 'issue_id': 2718960935, 'author': 'perry2of5', 'body': ""When I was working on this new operator I thought about moving some of those down into the hooks so I could reuse. I'll go ahead and put in a PR to address that and then update this PR to use those. It will reduce duplication and be a good thing. I'll try and do it this afternoon...we'll see, I have day-job work to do suddenly."", 'created_at': datetime.datetime(2024, 12, 11, 15, 51, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536947290, 'issue_id': 2718960935, 'author': 'perry2of5', 'body': 'It seems to me if a message is sent from an airflow DAG then the DAG author probably wants a message back at some point to confirm completion, check for errors, et cetera. To the best of my knowledge, the logic in this PR implements the standard design pattern for doing that. \r\n\r\nAlso, after the refactors that dabla requested this will be much smaller and the hooks will be more useful.', 'created_at': datetime.datetime(2024, 12, 11, 19, 36, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2632467029, 'issue_id': 2718960935, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 4, 0, 14, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2643616065, 'issue_id': 2718960935, 'author': 'perry2of5', 'body': 'Need to rewrite to use a dedicated response queue because there is a race condition between adding the subscription and modifying the filter. The alternatives are to discard any messages before sending the request or to fix the python SDK for ASB but seems simpler to use a queue.', 'created_at': datetime.datetime(2025, 2, 7, 17, 56, 19, tzinfo=datetime.timezone.utc)}]","perry2of5 (Issue Creator) on (2024-12-10 17:17:39 UTC): Thank you for the review.

perry2of5 (Issue Creator) on (2024-12-10 17:37:50 UTC): Just want to check, right now several of the existing operators get a handle to the connection and call the Microsoft Azure library directly. These should really be refactored down into the hook as well, right? For example this: https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/microsoft/azure/operators/asb.py#L316-L339

dabla on (2024-12-11 07:17:24 UTC): Good catch, indeed it would be better that this code resides within the hook, the hook should take care of the connection handling and exposes the logic within a public method which on it's turn is called from the operator, that way the same operation can also be executed from the hook within a PythonOperator.

But don't worry, there are still a lot of operators written that way unfortunately, but if we clean up every time we need to modify an operator, we will get there one day :-)

perry2of5 (Issue Creator) on (2024-12-11 15:51:51 UTC): When I was working on this new operator I thought about moving some of those down into the hooks so I could reuse. I'll go ahead and put in a PR to address that and then update this PR to use those. It will reduce duplication and be a good thing. I'll try and do it this afternoon...we'll see, I have day-job work to do suddenly.

perry2of5 (Issue Creator) on (2024-12-11 19:36:10 UTC): It seems to me if a message is sent from an airflow DAG then the DAG author probably wants a message back at some point to confirm completion, check for errors, et cetera. To the best of my knowledge, the logic in this PR implements the standard design pattern for doing that. 

Also, after the refactors that dabla requested this will be much smaller and the hooks will be more useful.

github-actions[bot] on (2025-02-04 00:14:56 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

perry2of5 (Issue Creator) on (2025-02-07 17:56:19 UTC): Need to rewrite to use a dedicated response queue because there is a race condition between adding the subscription and modifying the filter. The alternatives are to discard any messages before sending the request or to fix the python SDK for ASB but seems simpler to use a queue.

"
2718839295,pull_request,closed,,Remove hash on GitDagBundle,"It's a bit sketchy to to make this hashable, I think.  The idea of what is the identity of a dag bundle is not very well defined.  In the orm sense, it's just the name.  But in another context it might mean name + version. So, we should just leave it to the call site to be explicit about it.  Meanwhile, I add a better repr.

My assumption is this isn't being used at this point.  If there's a really compelling reason to add it later we can.",dstandish,2024-12-04 21:38:15+00:00,[],2024-12-05 03:26:46+00:00,2024-12-05 03:26:37+00:00,https://github.com/apache/airflow/pull/44666,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2718834030,pull_request,closed,,Remove Provider Deprecations in MySQL,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider **MySQL**

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-04 21:36:02+00:00,[],2024-12-06 15:33:01+00:00,2024-12-06 15:33:00+00:00,https://github.com/apache/airflow/pull/44665,"[('area:providers', ''), ('provider:mysql', '')]",[],
2718829488,pull_request,closed,,Add an example DAG for aip-82,"Add an example for AIP-82 so that users have an example of DAG scheduled based on external event. I'll use that example DAG in a future PR for documentation purposes.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-04 21:33:00+00:00,[],2024-12-05 20:26:53+00:00,2024-12-05 20:26:52+00:00,https://github.com/apache/airflow/pull/44664,[],[],
2718823340,pull_request,closed,,Remove Provider Deprecations in JDBC,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider **JDBC**

Relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-04 21:28:51+00:00,[],2024-12-05 20:05:03+00:00,2024-12-05 20:05:03+00:00,https://github.com/apache/airflow/pull/44662,"[('area:providers', ''), ('provider:jdbc', '')]",[],
2718786154,pull_request,closed,,Include .ssh dir when --forward-credentials,"This is helpful e.g. when trying to use git in breez env.
",dstandish,2024-12-04 21:05:52+00:00,[],2024-12-04 22:36:25+00:00,2024-12-04 22:36:23+00:00,https://github.com/apache/airflow/pull/44661,"[('area:dev-tools', '')]",[],
2718735018,pull_request,closed,,Add basic tmux for dummies section,Basic tmux info for airflow developers who aren't familiar with its idiosyncrasies.  I had a pretty difficult time figuring it out.,dstandish,2024-12-04 20:34:12+00:00,[],2024-12-04 22:37:52+00:00,2024-12-04 22:37:51+00:00,https://github.com/apache/airflow/pull/44660,"[('area:dev-tools', '')]",[],
2718707046,pull_request,closed,,Correct new changelog breaking changes header,"Relates to #44559
Correct changelogs after feedback from https://github.com/apache/airflow/issues/44559#issuecomment-2513590038",jscheffl,2024-12-04 20:18:01+00:00,[],2024-12-05 19:42:59+00:00,2024-12-05 19:42:58+00:00,https://github.com/apache/airflow/pull/44659,"[('area:providers', ''), ('provider:docker', ''), ('provider:http', ''), ('provider:ssh', ''), ('provider:standard', '')]",[],
2718574312,pull_request,closed,,Task instance details,"Initialize a basic task instance details page. To be merged after the dag run details PR: https://github.com/apache/airflow/pull/44656

<img width=""1086"" alt=""Screenshot 2024-12-04 at 1 59 59 PM"" src=""https://github.com/user-attachments/assets/fd9256b5-32df-4f21-bf47-15686658313e"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-04 19:03:56+00:00,[],2024-12-04 20:57:40+00:00,2024-12-04 20:56:01+00:00,https://github.com/apache/airflow/pull/44658,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2718480766,pull_request,closed,,AIP-84 Remove sensor from structure node type and rename attribute,"This wasn't tested and is actually not working. As of today we cannot retrieve from the `SerializedBaseOperator` the information if an Operator is a Sensor or a regular operator.

Removing this from the possible types for now. More effort would be required for it to work.",pierrejeambrun,2024-12-04 18:16:44+00:00,['pierrejeambrun'],2024-12-04 18:46:43+00:00,2024-12-04 18:46:41+00:00,https://github.com/apache/airflow/pull/44657,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2718416239,pull_request,closed,,Fill out Dag Run and Task Instance Details pages with Grid and Gantt buttons.,"Make a shared DetailsLayout component to help render the pages for a Dag, Dag Run, and Task Instance. The layout handles errors, loading, tabs and the visualizations modal. Also updated the visualizations modal to include space for the Grid and Gantt charts

<img width=""1246"" alt=""Screenshot 2024-12-04 at 4 00 01 PM"" src=""https://github.com/user-attachments/assets/b25473e9-6859-4400-add8-569afe084715"">
<img width=""1243"" alt=""Screenshot 2024-12-04 at 4 00 09 PM"" src=""https://github.com/user-attachments/assets/f40bca39-39a6-46f3-86ae-5c374be2ca0c"">
<img width=""1225"" alt=""Screenshot 2024-12-04 at 4 00 16 PM"" src=""https://github.com/user-attachments/assets/a069e2f1-f6f7-42ce-ad58-a39cb554fb5b"">
---

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-04 17:44:45+00:00,[],2024-12-10 17:53:46+00:00,2024-12-10 17:53:44+00:00,https://github.com/apache/airflow/pull/44656,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2519482854, 'issue_id': 2718416239, 'author': 'tirkarthi', 'body': 'The components and pages can later have clipboard button in relevant places to copy dag_id, run_id, task_id etc. which was present in the old UI and was handy.\r\n\r\nhttps://www.chakra-ui.com/docs/components/clipboard', 'created_at': datetime.datetime(2024, 12, 5, 7, 44, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519606200, 'issue_id': 2718416239, 'author': 'tirkarthi', 'body': 'One way to handle mapped task instances might be to pass `map_index` as a query parameter in the URL and then handle it. Below is a rough approach but this could be discussed in a separate issue since this will involve URL changes.\r\n\r\n```patch\r\ndiff --git a/airflow/ui/src/pages/Events/Events.tsx b/airflow/ui/src/pages/Events/Events.tsx\r\nindex 60663aefec..d311471252 100644\r\n--- a/airflow/ui/src/pages/Events/Events.tsx\r\n+++ b/airflow/ui/src/pages/Events/Events.tsx\r\n@@ -18,7 +18,7 @@\r\n  */\r\n import { Box } from ""@chakra-ui/react"";\r\n import type { ColumnDef } from ""@tanstack/react-table"";\r\n-import { useParams } from ""react-router-dom"";\r\n+import { useSearchParams, useParams } from ""react-router-dom"";\r\n \r\n import { useEventLogServiceGetEventLogs } from ""openapi/queries"";\r\n import type { EventLogResponse } from ""openapi/requests/types.gen"";\r\n@@ -113,6 +113,8 @@ const eventsColumn = (\r\n \r\n export const Events = () => {\r\n   const { dagId, runId, taskId } = useParams();\r\n+  const [searchParams, setSearchParams] = useSearchParams();\r\n+  const mapIndex = searchParams.get(""map_index"");\r\n   const { setTableURLState, tableURLState } = useTableURLState({\r\n     sorting: [{ desc: true, id: ""when"" }],\r\n   });\r\n@@ -132,6 +134,8 @@ export const Events = () => {\r\n     offset: pagination.pageIndex * pagination.pageSize,\r\n     orderBy,\r\n     runId,\r\n+    taskId,\r\n+    mapIndex,\r\n   });\r\n \r\n   return (\r\ndiff --git a/airflow/ui/src/pages/Run/TaskInstances.tsx b/airflow/ui/src/pages/Run/TaskInstances.tsx\r\nindex e96ff55d46..4e4127cdfc 100644\r\n--- a/airflow/ui/src/pages/Run/TaskInstances.tsx\r\n+++ b/airflow/ui/src/pages/Run/TaskInstances.tsx\r\n@@ -35,7 +35,7 @@ const columns: Array<ColumnDef<TaskInstanceResponse>> = [\r\n     cell: ({ row: { original } }) => (\r\n       <Link asChild color=""fg.info"" fontWeight=""bold"">\r\n         <RouterLink\r\n-          to={`/dags/${original.dag_id}/runs/${original.dag_run_id}/tasks/${original.task_id}`}\r\n+          to={`/dags/${original.dag_id}/runs/${original.dag_run_id}/tasks/${original.task_id}?map_index=${original.map_index}`}\r\n         >\r\n           {original.task_display_name}\r\n         </RouterLink>\r\ndiff --git a/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx b/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx\r\nindex b9e41de93d..d0f5ca9930 100644\r\n--- a/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx\r\n+++ b/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx\r\n@@ -17,37 +17,51 @@\r\n  * under the License.\r\n  */\r\n import { LiaSlashSolid } from ""react-icons/lia"";\r\n-import { useParams, Link as RouterLink } from ""react-router-dom"";\r\n+import {\r\n+  useParams,\r\n+  useSearchParams,\r\n+  Link as RouterLink,\r\n+} from ""react-router-dom"";\r\n \r\n import {\r\n   useDagServiceGetDagDetails,\r\n   useTaskInstanceServiceGetTaskInstance,\r\n+  useTaskInstanceServiceGetMappedTaskInstance,\r\n } from ""openapi/queries"";\r\n import { Breadcrumb } from ""src/components/ui"";\r\n import { DetailsLayout } from ""src/layouts/Details/DetailsLayout"";\r\n \r\n import { Header } from ""./Header"";\r\n \r\n-const tabs = [\r\n-  { label: ""Logs"", value: """" },\r\n-  { label: ""Events"", value: ""events"" },\r\n-  { label: ""XCom"", value: ""xcom"" },\r\n-  { label: ""Code"", value: ""code"" },\r\n-  { label: ""Details"", value: ""details"" },\r\n-];\r\n-\r\n export const TaskInstance = () => {\r\n   const { dagId = """", runId = """", taskId = """" } = useParams();\r\n+  const [searchParams, setSearchParams] = useSearchParams();\r\n+  const mapIndex = searchParams.get(""map_index"");\r\n+\r\n+  const tabs = [\r\n+    { label: ""Logs"", value: """" },\r\n+    { label: ""Events"", value: `events?map_index=${mapIndex}` },\r\n+    { label: ""XCom"", value: `xcom?map_index=${mapIndex}` },\r\n+    { label: ""Code"", value: `code?map_index=${mapIndex}` },\r\n+    { label: ""Details"", value: `details?map_index=${mapIndex}` },\r\n+  ];\r\n \r\n   const {\r\n     data: taskInstance,\r\n     error,\r\n     isLoading,\r\n-  } = useTaskInstanceServiceGetTaskInstance({\r\n-    dagId,\r\n-    dagRunId: runId,\r\n-    taskId,\r\n-  });\r\n+  } = Boolean(mapIndex) && mapIndex > -1\r\n+    ? useTaskInstanceServiceGetMappedTaskInstance({\r\n+        dagId,\r\n+        dagRunId: runId,\r\n+        taskId,\r\n+        mapIndex,\r\n+      })\r\n+    : useTaskInstanceServiceGetTaskInstance({\r\n+        dagId,\r\n+        dagRunId: runId,\r\n+        taskId,\r\n+      });\r\n \r\n   const {\r\n     data: dag,\r\n```', 'created_at': datetime.datetime(2024, 12, 5, 8, 28, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2523916324, 'issue_id': 2718416239, 'author': 'bbovenzi', 'body': '> One way to handle mapped task instances might be to pass `map_index` as a query parameter in the URL and then handle it. Below is a rough approach but this could be discussed in a separate issue since this will involve URL changes.\r\n\r\nUpdated everything to accept `map_index=X` search param or to at least forward the param around. Also, I realized we can just use `useTaskInstanceServiceGetMappedTaskInstance` and pass `-1` for regular task instances.', 'created_at': datetime.datetime(2024, 12, 6, 18, 30, 31, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-12-05 07:44:43 UTC): The components and pages can later have clipboard button in relevant places to copy dag_id, run_id, task_id etc. which was present in the old UI and was handy.

https://www.chakra-ui.com/docs/components/clipboard

tirkarthi on (2024-12-05 08:28:30 UTC): One way to handle mapped task instances might be to pass `map_index` as a query parameter in the URL and then handle it. Below is a rough approach but this could be discussed in a separate issue since this will involve URL changes.

```patch
diff --git a/airflow/ui/src/pages/Events/Events.tsx b/airflow/ui/src/pages/Events/Events.tsx
index 60663aefec..d311471252 100644
--- a/airflow/ui/src/pages/Events/Events.tsx
+++ b/airflow/ui/src/pages/Events/Events.tsx
@@ -18,7 +18,7 @@
  */
 import { Box } from ""@chakra-ui/react"";
 import type { ColumnDef } from ""@tanstack/react-table"";
-import { useParams } from ""react-router-dom"";
+import { useSearchParams, useParams } from ""react-router-dom"";
 
 import { useEventLogServiceGetEventLogs } from ""openapi/queries"";
 import type { EventLogResponse } from ""openapi/requests/types.gen"";
@@ -113,6 +113,8 @@ const eventsColumn = (
 
 export const Events = () => {
   const { dagId, runId, taskId } = useParams();
+  const [searchParams, setSearchParams] = useSearchParams();
+  const mapIndex = searchParams.get(""map_index"");
   const { setTableURLState, tableURLState } = useTableURLState({
     sorting: [{ desc: true, id: ""when"" }],
   });
@@ -132,6 +134,8 @@ export const Events = () => {
     offset: pagination.pageIndex * pagination.pageSize,
     orderBy,
     runId,
+    taskId,
+    mapIndex,
   });
 
   return (
diff --git a/airflow/ui/src/pages/Run/TaskInstances.tsx b/airflow/ui/src/pages/Run/TaskInstances.tsx
index e96ff55d46..4e4127cdfc 100644
--- a/airflow/ui/src/pages/Run/TaskInstances.tsx
+++ b/airflow/ui/src/pages/Run/TaskInstances.tsx
@@ -35,7 +35,7 @@ const columns: Array<ColumnDef<TaskInstanceResponse>> = [
     cell: ({ row: { original } }) => (
       <Link asChild color=""fg.info"" fontWeight=""bold"">
         <RouterLink
-          to={`/dags/${original.dag_id}/runs/${original.dag_run_id}/tasks/${original.task_id}`}
+          to={`/dags/${original.dag_id}/runs/${original.dag_run_id}/tasks/${original.task_id}?map_index=${original.map_index}`}
           {original.task_display_name}
         </RouterLink>
diff --git a/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx b/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx
index b9e41de93d..d0f5ca9930 100644
--- a/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx
+++ b/airflow/ui/src/pages/TaskInstance/TaskInstance.tsx
@@ -17,37 +17,51 @@
  * under the License.
  */
 import { LiaSlashSolid } from ""react-icons/lia"";
-import { useParams, Link as RouterLink } from ""react-router-dom"";
+import {
+  useParams,
+  useSearchParams,
+  Link as RouterLink,
+} from ""react-router-dom"";
 
 import {
   useDagServiceGetDagDetails,
   useTaskInstanceServiceGetTaskInstance,
+  useTaskInstanceServiceGetMappedTaskInstance,
 } from ""openapi/queries"";
 import { Breadcrumb } from ""src/components/ui"";
 import { DetailsLayout } from ""src/layouts/Details/DetailsLayout"";
 
 import { Header } from ""./Header"";
 
-const tabs = [
-  { label: ""Logs"", value: """" },
-  { label: ""Events"", value: ""events"" },
-  { label: ""XCom"", value: ""xcom"" },
-  { label: ""Code"", value: ""code"" },
-  { label: ""Details"", value: ""details"" },
-];
-
 export const TaskInstance = () => {
   const { dagId = """", runId = """", taskId = """" } = useParams();
+  const [searchParams, setSearchParams] = useSearchParams();
+  const mapIndex = searchParams.get(""map_index"");
+
+  const tabs = [
+    { label: ""Logs"", value: """" },
+    { label: ""Events"", value: `events?map_index=${mapIndex}` },
+    { label: ""XCom"", value: `xcom?map_index=${mapIndex}` },
+    { label: ""Code"", value: `code?map_index=${mapIndex}` },
+    { label: ""Details"", value: `details?map_index=${mapIndex}` },
+  ];
 
   const {
     data: taskInstance,
     error,
     isLoading,
-  } = useTaskInstanceServiceGetTaskInstance({
-    dagId,
-    dagRunId: runId,
-    taskId,
-  });
+  } = Boolean(mapIndex) && mapIndex > -1
+    ? useTaskInstanceServiceGetMappedTaskInstance({
+        dagId,
+        dagRunId: runId,
+        taskId,
+        mapIndex,
+      })
+    : useTaskInstanceServiceGetTaskInstance({
+        dagId,
+        dagRunId: runId,
+        taskId,
+      });
 
   const {
     data: dag,
```

bbovenzi (Issue Creator) on (2024-12-06 18:30:31 UTC): Updated everything to accept `map_index=X` search param or to at least forward the param around. Also, I realized we can just use `useTaskInstanceServiceGetMappedTaskInstance` and pass `-1` for regular task instances.

"
2718339506,pull_request,closed,,AIP-38 Add operator name and type to graph,"Depends on: https://github.com/apache/airflow/pull/44651

Only the last commit is relevant.

This add the `operator_name` to the graph as well as general `type` handling.

Before:
![Screenshot 2024-12-04 at 18 06 33](https://github.com/user-attachments/assets/56606e80-eae8-42c7-ad54-6ae991e1e6d3)


After:
![Screenshot 2024-12-04 at 19 28 30](https://github.com/user-attachments/assets/25f0e2cb-051f-4d94-900f-a10c3f562204)

",pierrejeambrun,2024-12-04 17:07:24+00:00,['pierrejeambrun'],2024-12-04 18:40:00+00:00,2024-12-04 18:39:58+00:00,https://github.com/apache/airflow/pull/44655,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2718337641,pull_request,closed,,Expose timestamp filter on dataset event endpoint,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Exposes a timestamp filter for the dataset event endpoint.
closes: https://github.com/apache/airflow/issues/41126
",nishant-gupta-sh,2024-12-04 17:06:29+00:00,[],2024-12-12 08:45:19+00:00,2024-12-12 08:45:19+00:00,https://github.com/apache/airflow/pull/44654,"[('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2518045462, 'issue_id': 2718337641, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 4, 17, 6, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532182875, 'issue_id': 2718337641, 'author': 'nishant-gupta-sh', 'body': ""@pierrejeambrun I've added the test and the separate PR for Airflow 3: https://github.com/apache/airflow/pull/44795"", 'created_at': datetime.datetime(2024, 12, 10, 16, 14, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535572015, 'issue_id': 2718337641, 'author': 'pierrejeambrun', 'body': ""Tests need fixing, I'm also double checking for our release policy on how to handle this one. (new feature targeted for 2.x)"", 'created_at': datetime.datetime(2024, 12, 11, 11, 16, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538217648, 'issue_id': 2718337641, 'author': 'pierrejeambrun', 'body': 'Hi @nishant-gupta-sh,\r\n\r\nAfter discussion with other contributors, this cannot be release in airflow 2.x. (Next 2.10 patch release cannot hold feature, and next 2.11.0 feature release cannot either because as mentioned in [this thread](https://lists.apache.org/thread/0d3dlly0mbps8n58hlxmmpvdcv9kx68s) it holds no feature.\r\n\r\nI am closing this one.', 'created_at': datetime.datetime(2024, 12, 12, 8, 45, 19, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-04 17:06:34 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

nishant-gupta-sh (Issue Creator) on (2024-12-10 16:14:43 UTC): @pierrejeambrun I've added the test and the separate PR for Airflow 3: https://github.com/apache/airflow/pull/44795

pierrejeambrun on (2024-12-11 11:16:42 UTC): Tests need fixing, I'm also double checking for our release policy on how to handle this one. (new feature targeted for 2.x)

pierrejeambrun on (2024-12-12 08:45:19 UTC): Hi @nishant-gupta-sh,

After discussion with other contributors, this cannot be release in airflow 2.x. (Next 2.10 patch release cannot hold feature, and next 2.11.0 feature release cannot either because as mentioned in [this thread](https://lists.apache.org/thread/0d3dlly0mbps8n58hlxmmpvdcv9kx68s) it holds no feature.

I am closing this one.

"
2718320883,pull_request,closed,,Remove deprecated code from Pagerduty provider ,"related: #44559 

remove-deprecated-code, remove test ,update changelog from-pagerduty provider
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2024-12-04 16:58:35+00:00,[],2024-12-07 19:40:12+00:00,2024-12-07 19:40:03+00:00,https://github.com/apache/airflow/pull/44653,"[('area:providers', ''), ('provider:pagerduty', '')]","[{'comment_id': 2525044409, 'issue_id': 2718320883, 'author': 'jscheffl', 'body': 'Just a static check is failing, when this is fixed I assume this can be merged.', 'created_at': datetime.datetime(2024, 12, 7, 9, 10, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525252509, 'issue_id': 2718320883, 'author': 'Prab-27', 'body': ""> Just a static check is failing, when this is fixed I assume this can be merged.\r\n\r\nI have modified test_pagerduty.py and another check has failed due to this statement from [providers/src/airflow/providers/pagerduty/hooks/pagerduty.py](url)  \r\n`airflow.providers.pagerduty.hooks.pagerduty_events import PagerdutyEventsHook`\r\n\r\nHowever, fixing the second static check caused the unit test to fail.\r\n\r\n```\r\n__ ERROR collecting providers/tests/pagerduty/hooks/test_pagerduty_events.py ___\r\nImportError while importing test module '/opt/airflow/providers/tests/pagerduty/hooks/test_pagerduty_events.py'.\r\nHint: make sure your test modules/packages have valid Python names.\r\n```"", 'created_at': datetime.datetime(2024, 12, 7, 17, 25, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525259851, 'issue_id': 2718320883, 'author': 'jscheffl', 'body': '> > Just a static check is failing, when this is fixed I assume this can be merged.\r\n> \r\n> I have modified test_pagerduty.py and another check has failed due to this statement from [providers/src/airflow/providers/pagerduty/hooks/pagerduty.py](url) `airflow.providers.pagerduty.hooks.pagerduty_events import PagerdutyEventsHook`\r\n> \r\n> However, fixing the second static check caused the unit test to fail.\r\n> \r\n> ```\r\n> __ ERROR collecting providers/tests/pagerduty/hooks/test_pagerduty_events.py ___\r\n> ImportError while importing test module \'/opt/airflow/providers/tests/pagerduty/hooks/test_pagerduty_events.py\'.\r\n> Hint: make sure your test modules/packages have valid Python names.\r\n> ```\r\n\r\nYes, because previously the pytest imported ""wrong"" as a re-import. In `providers/tests/pagerduty/hooks/test_pagerduty_events.py:23` you need to import via:\r\n\r\n```\r\nfrom airflow.providers.pagerduty.hooks.pagerduty_events import PagerdutyEventsHook\r\n```\r\n\r\n...and then of course also commit the fix in static checks, easiest run `pre-commit run -a`', 'created_at': datetime.datetime(2024, 12, 7, 17, 50, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525278497, 'issue_id': 2718320883, 'author': 'Prab-27', 'body': 'Done !', 'created_at': datetime.datetime(2024, 12, 7, 18, 57, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525289563, 'issue_id': 2718320883, 'author': 'jscheffl', 'body': 'Green! Merged! Thanks!', 'created_at': datetime.datetime(2024, 12, 7, 19, 40, 11, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-07 09:10:54 UTC): Just a static check is failing, when this is fixed I assume this can be merged.

Prab-27 (Issue Creator) on (2024-12-07 17:25:19 UTC): I have modified test_pagerduty.py and another check has failed due to this statement from [providers/src/airflow/providers/pagerduty/hooks/pagerduty.py](url)  
`airflow.providers.pagerduty.hooks.pagerduty_events import PagerdutyEventsHook`

However, fixing the second static check caused the unit test to fail.

```
__ ERROR collecting providers/tests/pagerduty/hooks/test_pagerduty_events.py ___
ImportError while importing test module '/opt/airflow/providers/tests/pagerduty/hooks/test_pagerduty_events.py'.
Hint: make sure your test modules/packages have valid Python names.
```

jscheffl on (2024-12-07 17:50:32 UTC): Yes, because previously the pytest imported ""wrong"" as a re-import. In `providers/tests/pagerduty/hooks/test_pagerduty_events.py:23` you need to import via:

```
from airflow.providers.pagerduty.hooks.pagerduty_events import PagerdutyEventsHook
```

...and then of course also commit the fix in static checks, easiest run `pre-commit run -a`

Prab-27 (Issue Creator) on (2024-12-07 18:57:13 UTC): Done !

jscheffl on (2024-12-07 19:40:11 UTC): Green! Merged! Thanks!

"
2718206157,pull_request,closed,,AIP-84 Add operator name field to structure data endpoint response,Small PR that adds the `operator` name to the returned payload of the `structure_data` endpoint.,pierrejeambrun,2024-12-04 16:07:17+00:00,['pierrejeambrun'],2024-12-04 17:58:55+00:00,2024-12-04 17:58:53+00:00,https://github.com/apache/airflow/pull/44651,"[('AIP-84', 'Modern Rest API')]",[],
2718170304,pull_request,closed,,Fix failing OpenLineage emition for InsertBigQueryOperator ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

InsertBigQueryOperator OpenLineage emition fails with google.api_core.exceptions.NotFound when a non-default location is used, added location argument in BigQuery client to prevent this.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",spapi17,2024-12-04 15:53:46+00:00,[],2024-12-10 14:43:01+00:00,2024-12-10 14:42:56+00:00,https://github.com/apache/airflow/pull/44650,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2531607986, 'issue_id': 2718170304, 'author': 'amoghrajesh', 'body': 'cc @mobuchowski @kacpermuda\r\nI am approving the workflow', 'created_at': datetime.datetime(2024, 12, 10, 13, 15, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531829263, 'issue_id': 2718170304, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 10, 14, 42, 58, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2024-12-10 13:15:47 UTC): cc @mobuchowski @kacpermuda
I am approving the workflow

boring-cyborg[bot] on (2024-12-10 14:42:58 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2717606028,pull_request,closed,,Fix test_deprecated_options_with_new_section,"This [PR](https://github.com/apache/airflow/commit/a58ed9d53b43dcfaf7e95ed17baaa15e0202efcb) is causing the the CI to break, on branch v2-10-test. It's working in main because we removed the test in this [PR](https://github.com/apache/airflow/pull/42100/files). We cannot backport the  [PR](https://github.com/apache/airflow/pull/42100/files) from main as it contains breaking changes. This PR makes the CI green for v2-10-test branch.",utkarsharma2,2024-12-04 12:33:01+00:00,[],2024-12-04 16:20:27+00:00,2024-12-04 13:34:46+00:00,https://github.com/apache/airflow/pull/44647,[],"[{'comment_id': 2517920087, 'issue_id': 2717606028, 'author': 'zachliu', 'body': 'my pr https://github.com/apache/airflow/pull/44148 (causing the the CI to break on branch v2-10-test) was to fix issue https://github.com/apache/airflow/issues/43794, which, i guess, is caused by harmless miscommunication among contributors (https://github.com/apache/airflow/pull/43040 and https://github.com/apache/airflow/pull/42126 plus only https://github.com/apache/airflow/pull/43040 is incorporated into 2.10.3) `¯\\_(ツ)_/¯`', 'created_at': datetime.datetime(2024, 12, 4, 16, 20, 24, tzinfo=datetime.timezone.utc)}]","zachliu on (2024-12-04 16:20:24 UTC): my pr https://github.com/apache/airflow/pull/44148 (causing the the CI to break on branch v2-10-test) was to fix issue https://github.com/apache/airflow/issues/43794, which, i guess, is caused by harmless miscommunication among contributors (https://github.com/apache/airflow/pull/43040 and https://github.com/apache/airflow/pull/42126 plus only https://github.com/apache/airflow/pull/43040 is incorporated into 2.10.3) `¯\_(ツ)_/¯`

"
2717605580,pull_request,closed,,Fixed thread local _sentinel.callers defect and added test cases,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rahulgoyal2987,2024-12-04 12:32:49+00:00,[],2025-01-29 15:42:18+00:00,2024-12-11 10:45:21+00:00,https://github.com/apache/airflow/pull/44646,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2521026017, 'issue_id': 2717605580, 'author': 'ashb', 'body': 'Please add a meaningful description to this pr, and likely unit tests too', 'created_at': datetime.datetime(2024, 12, 5, 17, 38, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533969734, 'issue_id': 2717605580, 'author': 'dabla', 'body': ""Is there a reason why this PR isn't merged yet as it fixes a thread safety issues with the ExecutorSafeguard?"", 'created_at': datetime.datetime(2024, 12, 11, 7, 19, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535496564, 'issue_id': 2717605580, 'author': 'potiuk', 'body': 'I thi k we mostly overlooked it :(', 'created_at': datetime.datetime(2024, 12, 11, 10, 45, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2579552641, 'issue_id': 2717605580, 'author': 'kulkarni-sp', 'body': 'What is the target release version for this fix?', 'created_at': datetime.datetime(2025, 1, 9, 9, 19, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580012103, 'issue_id': 2717605580, 'author': 'potiuk', 'body': 'Currently Airflow 3. Why? Is this worthwhile to make an attempt to backport it to Airflow 2.* ? If so - why? What would be your arguments @kulkarni-sp ?', 'created_at': datetime.datetime(2025, 1, 9, 12, 15, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580038390, 'issue_id': 2717605580, 'author': 'kulkarni-sp', 'body': '> Currently Airflow 3. Why? Is this worthwhile to make an attempt to backport it to Airflow 2.* ? If so - why? What would be your arguments @kulkarni-sp ?\r\n\r\nWe are currently using Airflow 2.9.3 and encountered the same errors during our attempt to upgrade to 2.10.3. Therefore, this fix is essential to unblock our upgrade path.', 'created_at': datetime.datetime(2025, 1, 9, 12, 29, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580691416, 'issue_id': 2717605580, 'author': 'potiuk', 'body': '> We are currently using Airflow 2.9.3 and encountered the same errors during our attempt to upgrade to 2.10.3. Therefore, this fix is essential to unblock our upgrade path. \r\n\r\nCould you please be more specific - what exactly error you experienced - i think that one has no clear issue that it marks as ""solving"" ? And is it possible that you apply that patch to verify that this one solves it ?', 'created_at': datetime.datetime(2025, 1, 9, 16, 13, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582690885, 'issue_id': 2717605580, 'author': 'kulkarni-sp', 'body': '> > We are currently using Airflow 2.9.3 and encountered the same errors during our attempt to upgrade to 2.10.3. Therefore, this fix is essential to unblock our upgrade path.\r\n> \r\n> Could you please be more specific - what exactly error you experienced - i think that one has no clear issue that it marks as ""solving"" ? And is it possible that you apply that patch to verify that this one solves it ?\r\n\r\nWe are utilizing Airflow with KubernetesExecutor and have several long-running pods that continuously monitor specified locations for input files. Initially, we used mapped tasks to specify different input locations, but this led to a higher number of pods and caused stability issues on our AKS cluster. Now, we are employing ThreadPoolExecutor for parallel processing, which triggers the processor DAG upon receiving a valid input file. However, with Airflow 2.10.3, we encounter the following errors when triggering the processor DAG:\r\n\r\n\r\n\r\n**[2025-01-10, 12:53:29 UTC] {ThreadPoolExecutor-1_3 logging_mixin.py:190} INFO - pa: Error while calling processor DAG: \'_thread._local\' object has no attribute \'callers\'**\r\n\r\n```\r\n@task(executor_config=k8s_poller_exec_config_resource_requirements)\r\n    def poll_adls_driver(config_list, **kwargs):\r\n        args_list = []\r\n\r\n        for upstream_config in config_list:\r\n            args_list.append((upstream_config, kwargs,))\r\n\r\n        with ThreadPoolExecutor(max_workers=5) as executor:\r\n            # Unpack the argument tuples\r\n            futures = [executor.submit(poll_adls, *args) for args in args_list]\r\n        for future in futures:\r\n            future.result()\r\n```', 'created_at': datetime.datetime(2025, 1, 10, 13, 14, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2592834933, 'issue_id': 2717605580, 'author': 'kulkarni-sp', 'body': '@potiuk We have also applied this patch, Requires minor change for it to work in multithreaded env i.e. getattr check and initialization should be done before sentinel check OR It could work with this PR https://github.com/apache/airflow/pull/44240/files\r\n\r\n            sentinel_key = f""{self.__class__.__name__}__sentinel""\r\n            sentinel = kwargs.pop(sentinel_key, None)\r\n            //Initialize attribute callers\r\n             if not getattr(cls._sentinel, ""callers"", None):\r\n                cls._sentinel.callers = {}\r\n            if sentinel:                \r\n                cls._sentinel.callers[sentinel_key] = sentinel\r\n            else:                \r\n                sentinel = cls._sentinel.callers.pop(f""{func.__qualname__.split(\'.\')[0]}__sentinel"", None)\r\n            ----', 'created_at': datetime.datetime(2025, 1, 15, 13, 17, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618128435, 'issue_id': 2717605580, 'author': 'eladkal', 'body': 'I guess this issue fixes https://github.com/apache/airflow/issues/44648 which is a bug on 2.10.3\r\n@utkarsharma2 can we backport the fix to v2-10 branch?', 'created_at': datetime.datetime(2025, 1, 28, 7, 40, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2621833113, 'issue_id': 2717605580, 'author': 'potiuk', 'body': 'I marked it as 2.10.5 milestone to not forget about it.', 'created_at': datetime.datetime(2025, 1, 29, 14, 36, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622004840, 'issue_id': 2717605580, 'author': 'kulkarni-sp', 'body': '@utkarsharma2  Is it possible for you to include this make minor change? Essentially doing getattr check before if statement.\r\n         //Initialize attribute callers\r\n         if not getattr(cls._sentinel, ""callers"", None):\r\n            cls._sentinel.callers = {}\r\n        if sentinel:                \r\n            cls._sentinel.callers[sentinel_key] = sentinel\r\n        else:                \r\n            sentinel = cls._sentinel.callers.pop(f""{func.__qualname__.split(\'.\')[0]}__sentinel"", None)\r\n        ----', 'created_at': datetime.datetime(2025, 1, 29, 15, 42, 16, tzinfo=datetime.timezone.utc)}]","ashb on (2024-12-05 17:38:40 UTC): Please add a meaningful description to this pr, and likely unit tests too

dabla on (2024-12-11 07:19:41 UTC): Is there a reason why this PR isn't merged yet as it fixes a thread safety issues with the ExecutorSafeguard?

potiuk on (2024-12-11 10:45:09 UTC): I thi k we mostly overlooked it :(

kulkarni-sp on (2025-01-09 09:19:26 UTC): What is the target release version for this fix?

potiuk on (2025-01-09 12:15:12 UTC): Currently Airflow 3. Why? Is this worthwhile to make an attempt to backport it to Airflow 2.* ? If so - why? What would be your arguments @kulkarni-sp ?

kulkarni-sp on (2025-01-09 12:29:21 UTC): We are currently using Airflow 2.9.3 and encountered the same errors during our attempt to upgrade to 2.10.3. Therefore, this fix is essential to unblock our upgrade path.

potiuk on (2025-01-09 16:13:31 UTC): Could you please be more specific - what exactly error you experienced - i think that one has no clear issue that it marks as ""solving"" ? And is it possible that you apply that patch to verify that this one solves it ?

kulkarni-sp on (2025-01-10 13:14:58 UTC): We are utilizing Airflow with KubernetesExecutor and have several long-running pods that continuously monitor specified locations for input files. Initially, we used mapped tasks to specify different input locations, but this led to a higher number of pods and caused stability issues on our AKS cluster. Now, we are employing ThreadPoolExecutor for parallel processing, which triggers the processor DAG upon receiving a valid input file. However, with Airflow 2.10.3, we encounter the following errors when triggering the processor DAG:



**[2025-01-10, 12:53:29 UTC] {ThreadPoolExecutor-1_3 logging_mixin.py:190} INFO - pa: Error while calling processor DAG: '_thread._local' object has no attribute 'callers'**

```
@task(executor_config=k8s_poller_exec_config_resource_requirements)
    def poll_adls_driver(config_list, **kwargs):
        args_list = []

        for upstream_config in config_list:
            args_list.append((upstream_config, kwargs,))

        with ThreadPoolExecutor(max_workers=5) as executor:
            # Unpack the argument tuples
            futures = [executor.submit(poll_adls, *args) for args in args_list]
        for future in futures:
            future.result()
```

kulkarni-sp on (2025-01-15 13:17:15 UTC): @potiuk We have also applied this patch, Requires minor change for it to work in multithreaded env i.e. getattr check and initialization should be done before sentinel check OR It could work with this PR https://github.com/apache/airflow/pull/44240/files

            sentinel_key = f""{self.__class__.__name__}__sentinel""
            sentinel = kwargs.pop(sentinel_key, None)
            //Initialize attribute callers
             if not getattr(cls._sentinel, ""callers"", None):
                cls._sentinel.callers = {}
            if sentinel:                
                cls._sentinel.callers[sentinel_key] = sentinel
            else:                
                sentinel = cls._sentinel.callers.pop(f""{func.__qualname__.split('.')[0]}__sentinel"", None)
            ----

eladkal on (2025-01-28 07:40:15 UTC): I guess this issue fixes https://github.com/apache/airflow/issues/44648 which is a bug on 2.10.3
@utkarsharma2 can we backport the fix to v2-10 branch?

potiuk on (2025-01-29 14:36:52 UTC): I marked it as 2.10.5 milestone to not forget about it.

kulkarni-sp on (2025-01-29 15:42:16 UTC): @utkarsharma2  Is it possible for you to include this make minor change? Essentially doing getattr check before if statement.
         //Initialize attribute callers
         if not getattr(cls._sentinel, ""callers"", None):
            cls._sentinel.callers = {}
        if sentinel:                
            cls._sentinel.callers[sentinel_key] = sentinel
        else:                
            sentinel = cls._sentinel.callers.pop(f""{func.__qualname__.split('.')[0]}__sentinel"", None)
        ----

"
2717547157,pull_request,closed,,Remove Provider Deprecations in Common SQL,"
related: #44559



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 12:08:58+00:00,[],2024-12-10 18:33:20+00:00,2024-12-05 20:00:00+00:00,https://github.com/apache/airflow/pull/44645,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:common-sql', '')]",[],
2717491321,pull_request,closed,,Remove Provider Deprecations in Atlassian Jira,"
related: #44559




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 11:49:48+00:00,[],2024-12-05 20:13:19+00:00,2024-12-05 20:13:19+00:00,https://github.com/apache/airflow/pull/44644,"[('area:providers', ''), ('provider:atlassian-jira', '')]",[],
2717347735,pull_request,closed,,"Test DagFileProcessorManager directly, not via the JobRunner","90% of these tests created a DagProcessorJobRunner with the Manager inside it,
then did absolutely nothing with the JobRunner object. This makes the tests
more directly use what they are testing. (The rest of the time already created 
the Manager directly)

(DagProcessorJobRunner itself is as simple as can be -- it calls `start()` ->
`terminate()` -> `end()` so we don't loose much of anything by not testing it
explicitly)
",ashb,2024-12-04 10:59:23+00:00,[],2024-12-04 11:32:45+00:00,2024-12-04 11:32:42+00:00,https://github.com/apache/airflow/pull/44642,[],[],
2717193946,pull_request,closed,,Sync v2-10-stable with v2-10-test(sync_v2_10_test) to release 2.10.4,Time for 2.10.4rc1!,utkarsharma2,2024-12-04 10:06:06+00:00,[],2025-01-11 19:43:49+00:00,2024-12-10 12:16:23+00:00,https://github.com/apache/airflow/pull/44641,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]",[],
2717123485,pull_request,closed,,Remove pandas and pyarrow dependencies from `apache-airflow-providers-databricks`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Recently our project was flagged to have a vulnerability due to dependency on `pandas`, related vulnerability here; [CVE-2024-9880](https://huntr.com/bounties/a49baae1-4652-4d6c-a179-313c21c41a8d). I saw that our project has `pandas` as a transtivie dependency due to [`apache-airflow-providers-databricks`](https://airflow.apache.org/docs/apache-airflow-providers-databricks/stable/index.html) having it listed as a dependency. Upon inspection of the code, it seems it is only listed as a dependency, but not it does not seem to actually be used in the codebase:

```
➜  databricks git:(main) pwd
/Users/florian/git/airflow/providers/src/airflow/providers/databricks

➜  databricks git:(main) grep -r ""pandas"" .     
./CHANGELOG.rst:* ``Update pandas minimum requirement for Python 3.12 (#40272)``
./provider.yaml:  - pandas>=2.1.2,<2.2;python_version>=""3.9""
./provider.yaml:  - pandas>=1.5.3,<2.2;python_version<""3.9""

➜  databricks git:(main) grep -r ""pyarrow"" .
./provider.yaml:  - pyarrow>=14.0.1
```

As you can see, the same holds for `pyarrow`. I assume this means the dependencies are not needed? I am not familiar with Airflow's codebase, so apologies in advance if I am overlooking something here. I did find some explanation about cross-dependencies with other providers packages, and the `generated/provider_dependencies.json` file, but not quite sure if that applies here. In any case; feel free to close this PR if you think it is not valid.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",fpgmaas,2024-12-04 09:40:36+00:00,[],2024-12-06 08:03:36+00:00,2024-12-06 08:03:25+00:00,https://github.com/apache/airflow/pull/44640,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2516706891, 'issue_id': 2717123485, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 4, 9, 40, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522449434, 'issue_id': 2717123485, 'author': 'potiuk', 'body': 'No. This is not going to work. Both pandas and pyarrow are required dependencies of `databricks-sql-connector`. We only have them added to workaround the fact that there are other providers that also need them and we want to keep all the minimum versions in sync - but they will come anyway from the connector.\r\n\r\nHere are deps of the `databricks-sql-connector` 3.6.0 for example. \r\n\r\n```\r\nRequires-Dist: alembic (>=1.0.11,<2.0.0) ; extra == ""alembic""\r\nRequires-Dist: lz4 (>=4.0.2,<5.0.0)\r\nRequires-Dist: numpy (>=1.16.6,<2.0.0) ; python_version >= ""3.8"" and python_version < ""3.11""\r\nRequires-Dist: numpy (>=1.23.4,<2.0.0) ; python_version >= ""3.11""\r\nRequires-Dist: oauthlib (>=3.1.0,<4.0.0)\r\nRequires-Dist: openpyxl (>=3.0.10,<4.0.0)\r\nRequires-Dist: pandas (>=1.2.5,<2.3.0) ; python_version >= ""3.8""\r\nRequires-Dist: pyarrow (>=14.0.1,<17)\r\nRequires-Dist: requests (>=2.18.1,<3.0.0)\r\nRequires-Dist: sqlalchemy (>=2.0.21) ; extra == ""sqlalchemy"" or extra == ""alembic""\r\nRequires-Dist: thrift (>=0.16.0,<0.21.0)\r\nRequires-Dist: urllib3 (>=1.26)\r\nProject-URL: Bug Tracker, https://github.com/databricks/databricks-sql-python/issues\r\nProject-URL: Homepage, https://github.com/databricks/databricks-sql-python\r\nDescription-Content-Type: text/markdown\r\n```', 'created_at': datetime.datetime(2024, 12, 6, 8, 3, 13, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-04 09:40:41 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-06 08:03:13 UTC): No. This is not going to work. Both pandas and pyarrow are required dependencies of `databricks-sql-connector`. We only have them added to workaround the fact that there are other providers that also need them and we want to keep all the minimum versions in sync - but they will come anyway from the connector.

Here are deps of the `databricks-sql-connector` 3.6.0 for example. 

```
Requires-Dist: alembic (>=1.0.11,<2.0.0) ; extra == ""alembic""
Requires-Dist: lz4 (>=4.0.2,<5.0.0)
Requires-Dist: numpy (>=1.16.6,<2.0.0) ; python_version >= ""3.8"" and python_version < ""3.11""
Requires-Dist: numpy (>=1.23.4,<2.0.0) ; python_version >= ""3.11""
Requires-Dist: oauthlib (>=3.1.0,<4.0.0)
Requires-Dist: openpyxl (>=3.0.10,<4.0.0)
Requires-Dist: pandas (>=1.2.5,<2.3.0) ; python_version >= ""3.8""
Requires-Dist: pyarrow (>=14.0.1,<17)
Requires-Dist: requests (>=2.18.1,<3.0.0)
Requires-Dist: sqlalchemy (>=2.0.21) ; extra == ""sqlalchemy"" or extra == ""alembic""
Requires-Dist: thrift (>=0.16.0,<0.21.0)
Requires-Dist: urllib3 (>=1.26)
Project-URL: Bug Tracker, https://github.com/databricks/databricks-sql-python/issues
Project-URL: Homepage, https://github.com/databricks/databricks-sql-python
Description-Content-Type: text/markdown
```

"
2717058597,pull_request,closed,,Respect Asset.name when accessing inlet and outlet events,"## Why
AIP-74 introduces the name attribute to the asset (previously dataset) class, but the `outlet_events` and `inlet_events` still only respect the URI attribute.

## What

When the users try to access an inlet/outlet event with the asset object, it tries to fetch the asset that matches both the name and URI.

```python
        @task(outlets=[Asset(name=""example"", uri=""test://uri"")])
        def produce_asset_events(*, outlet_events):
            outlet_events[Asset(name=""example"", uri=""test://uri"")]].extra = {""k"": ""v""}
```

before this change, it tries to fetch `Asset(uri=""test://uri"", name=""test://uri"")` instead

close: https://github.com/apache/airflow/issues/44601

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-04 09:13:06+00:00,[],2024-12-11 08:19:20+00:00,2024-12-11 08:19:18+00:00,https://github.com/apache/airflow/pull/44639,"[('area:serialization', ''), ('kind:documentation', ''), ('area:task-sdk', None)]",[],
2716766463,pull_request,closed,,Remove Provider Deprecations in DBT,"
related: #44559 



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 07:19:46+00:00,[],2024-12-06 13:19:04+00:00,2024-12-06 13:19:04+00:00,https://github.com/apache/airflow/pull/44638,"[('area:providers', ''), ('provider:dbt-cloud', '')]",[],
2716741191,pull_request,closed,,Remove Provider Deprecations in SendGrid,"

related: #44559



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 07:05:06+00:00,[],2024-12-06 07:56:11+00:00,2024-12-06 07:56:11+00:00,https://github.com/apache/airflow/pull/44637,"[('area:providers', '')]",[],
2716584391,pull_request,closed,,Remove Provider Deprecations in OpenLineage,"
related: #44559



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 05:16:13+00:00,[],2024-12-06 10:51:59+00:00,2024-12-06 10:51:59+00:00,https://github.com/apache/airflow/pull/44636,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2716559604,pull_request,closed,,"feat(datasets): add backward compat for DatasetAll, DatasetAny, expand_alias_to_datasets and DatasetAliasEvent","## Why
Ease the migration of dataset to asset

## What

allow `from airflow.datasets import DatasetAll, DatasetAny, expand_alias_to_datasets and DatasetAliasEvent`

Closes: #44375

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-04 04:54:12+00:00,[],2024-12-07 07:43:52+00:00,2024-12-07 07:43:50+00:00,https://github.com/apache/airflow/pull/44635,"[('area:datasets', 'Issues related to the datasets feature'), ('AIP-74', 'Dataset -> Asset')]",[],
2716496729,pull_request,closed,,Remove Provider Deprecations in Redis,"
related: #44559



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 03:54:16+00:00,[],2024-12-06 22:16:13+00:00,2024-12-06 22:16:13+00:00,https://github.com/apache/airflow/pull/44633,"[('area:providers', ''), ('provider:redis', '')]","[{'comment_id': 2517066324, 'issue_id': 2716496729, 'author': 'jason810496', 'body': ""It seems like the CI failed due to changes related to Assets, rather than the current removal changes. The failing test case hasn’t been modified and doesn’t appear to be related to the provider changes.\r\n\r\n```\r\nE   sqlalchemy.exc.InvalidRequestError: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\n```"", 'created_at': datetime.datetime(2024, 12, 4, 11, 30, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519656337, 'issue_id': 2716496729, 'author': 'Lee-W', 'body': ""> It seems like the CI failed due to changes related to Assets, rather than the current removal changes. The failing test case hasn’t been modified and doesn’t appear to be related to the provider changes.\r\n> \r\n> ```\r\n> E   sqlalchemy.exc.InvalidRequestError: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\n> ```\r\n\r\nLooks like an AIP-82 one, not sure what's happening 🤔 let me rebase and see how it works"", 'created_at': datetime.datetime(2024, 12, 5, 8, 52, 59, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-12-04 11:30:27 UTC): It seems like the CI failed due to changes related to Assets, rather than the current removal changes. The failing test case hasn’t been modified and doesn’t appear to be related to the provider changes.

```
E   sqlalchemy.exc.InvalidRequestError: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
```

Lee-W on (2024-12-05 08:52:59 UTC): Looks like an AIP-82 one, not sure what's happening 🤔 let me rebase and see how it works

"
2716465429,pull_request,closed,,Remove Provider Deprecations in Mongo,"


related: #44559



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 03:24:33+00:00,[],2024-12-04 06:02:26+00:00,2024-12-04 06:02:25+00:00,https://github.com/apache/airflow/pull/44632,"[('area:providers', ''), ('provider:mongo', '')]",[],
2716434281,pull_request,closed,,Remove Provider Deprecations in Apache Livy,"
related: #44559




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 02:53:49+00:00,[],2024-12-04 05:54:35+00:00,2024-12-04 05:54:35+00:00,https://github.com/apache/airflow/pull/44631,"[('area:providers', ''), ('provider:apache-livy', '')]",[],
2716422448,pull_request,closed,,Remove Provider Deprecations in Jenkins,"
related: #44559


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 02:42:55+00:00,[],2024-12-04 05:51:54+00:00,2024-12-04 05:51:54+00:00,https://github.com/apache/airflow/pull/44630,"[('area:providers', ''), ('provider:jenkins', '')]",[],
2716394252,pull_request,closed,,Remove Provider Deprecations in Elasticsearch,"
related: #44559



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-04 02:14:36+00:00,[],2024-12-06 10:52:41+00:00,2024-12-06 10:52:41+00:00,https://github.com/apache/airflow/pull/44629,"[('area:providers', ''), ('area:logging', ''), ('provider:elasticsearch', '')]",[],
2716174365,pull_request,closed,,Introduce gcp advance (V3) API translate native models operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-12-03 23:26:32+00:00,[],2024-12-06 13:16:37+00:00,2024-12-06 13:16:37+00:00,https://github.com/apache/airflow/pull/44627,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2522478194, 'issue_id': 2716174365, 'author': 'potiuk', 'body': 'cc: @VladaZakharova -> any comments?', 'created_at': datetime.datetime(2024, 12, 6, 8, 14, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522693550, 'issue_id': 2716174365, 'author': 'VladaZakharova', 'body': '> cc: @VladaZakharova -> any comments?\r\n\r\nLGTM for these changes,\r\nThank you :)', 'created_at': datetime.datetime(2024, 12, 6, 9, 51, 58, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-06 08:14:56 UTC): cc: @VladaZakharova -> any comments?

VladaZakharova on (2024-12-06 09:51:58 UTC): LGTM for these changes,
Thank you :)

"
2716161526,pull_request,closed,,AIP-72: Handle `SIGTERM` signal on Supervisor,"As part of AIP-72, this PR introduces proper signal handling for the supervisor process. The supervisor now intercepts `SIGTERM` signals to ensure that child processes (task processes) are terminated gracefully.

Without signal handling, terminating the supervisor process (e.g., via `kill -TERM`) could leave child processes running as orphaned tasks. This change ensures that when the supervisor is stopped, all managed subprocesses are also terminated cleanly.

Sample Output when Superviser receives SIGTERM with (`kill -TERM 138`):
```
2024-12-09 09:28:53 [debug    ] DAG file parsed                [task] [task] file=/files/dags/example_bash_operator.py
2024-12-09 09:28:53 [warning  ] BashOperator.execute cannot be called outside TaskInstance! [airflow.task.operators.airflow.providers.standard.operators.bash.BashOperator] [task]
2024-12-09 09:28:53 [info     ] Tmp dir root location: /tmp    [airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook] [task]
2024-12-09 09:28:53 [info     ] Running command: ['/usr/bin/bash', '-c', 'sleep 10000000'] [airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook] [task]
2024-12-09 09:28:53 [info     ] Output:                        [airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook] [task]
[2024-12-09T09:28:58.945+0000] {_client.py:1026} INFO - HTTP Request: PUT http://localhost:9091/execution/task-instances/01938d9d-a579-7b8e-aa91-0a2093a318d5/heartbeat ""HTTP/1.1 204 No Content""
[2024-12-09T09:29:04.176+0000] {_client.py:1026} INFO - HTTP Request: PUT http://localhost:9091/execution/task-instances/01938d9d-a579-7b8e-aa91-0a2093a318d5/heartbeat ""HTTP/1.1 204 No Content""
[2024-12-09T09:29:09.229+0000] {_client.py:1026} INFO - HTTP Request: PUT http://localhost:9091/execution/task-instances/01938d9d-a579-7b8e-aa91-0a2093a318d5/heartbeat ""HTTP/1.1 204 No Content""
2024-12-09 09:29:09 [error    ] Received termination signal in supervisor. Terminating watched subprocess [supervisor] process_pid=139 signal=15 supervisor_pid=138
2024-12-09 09:29:09 [debug    ] Task process exited            [supervisor] exit_code=<Negsignal.SIGTERM: -15>
2024-12-09 09:29:09 [info     ] Process exited                 [supervisor] exit_code=<Negsignal.SIGTERM: -15> pid=139 signal=SIGTERM
[2024-12-09T09:29:14.262+0000] {_client.py:1026} INFO - HTTP Request: PATCH http://localhost:9091/execution/task-instances/01938d9d-a579-7b8e-aa91-0a2093a318d5/state ""HTTP/1.1 204 No Content""
2024-12-09 09:29:14 [info     ] Task finished                  [supervisor] duration=21.38433257100405 exit_code=<Negsignal.SIGTERM: -15> final_state=failed
```
<img width=""1613"" alt=""image"" src=""https://github.com/user-attachments/assets/c1548856-facb-4ebe-b389-89af4da4014b"">

vs without signal handling:

```
024-12-09 09:34:47 [debug    ] Loaded DAG <DAG: example_bash_op> [airflow.models.dagbag.DagBag] [task]
2024-12-09 09:34:47 [debug    ] DAG file parsed                [task] [task] file=/files/dags/example_bash_operator.py
2024-12-09 09:34:47 [warning  ] BashOperator.execute cannot be called outside TaskInstance! [airflow.task.operators.airflow.providers.standard.operators.bash.BashOperator] [task]
2024-12-09 09:34:47 [info     ] Tmp dir root location: /tmp    [airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook] [task]
2024-12-09 09:34:47 [info     ] Running command: ['/usr/bin/bash', '-c', 'sleep 10000000'] [airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook] [task]
2024-12-09 09:34:47 [info     ] Output:                        [airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook] [task]
[2024-12-09T09:34:52.417+0000] {_client.py:1026} INFO - HTTP Request: PUT http://localhost:9091/execution/task-instances/01938d9d-a579-7b8e-aa91-0a2093a318d5/heartbeat ""HTTP/1.1 204 No Content""
Terminated
```

<img width=""1553"" alt=""image"" src=""https://github.com/user-attachments/assets/6e076549-2312-4ab1-9c7e-2048b5946051"">


A key difference is in first case the task is also set to `failed` state as it should while before it kept the TI as `running`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-03 23:14:28+00:00,[],2025-02-03 00:15:46+00:00,2025-02-03 00:15:46+00:00,https://github.com/apache/airflow/pull/44626,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:task-sdk', None)]","[{'comment_id': 2527338436, 'issue_id': 2716161526, 'author': 'kaxil', 'body': 'I will follow-up with a PR to handle signals for the actual Task process', 'created_at': datetime.datetime(2024, 12, 9, 9, 9, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529361237, 'issue_id': 2716161526, 'author': 'kaxil', 'body': 'Parking this for now to work on https://github.com/apache/airflow/issues/44481. If someone wants to take it (and propagating signals to subprocess & its childrens) on, go for it', 'created_at': datetime.datetime(2024, 12, 9, 20, 19, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620313881, 'issue_id': 2716161526, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 29, 0, 14, 54, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-12-09 09:09:25 UTC): I will follow-up with a PR to handle signals for the actual Task process

kaxil (Issue Creator) on (2024-12-09 20:19:34 UTC): Parking this for now to work on https://github.com/apache/airflow/issues/44481. If someone wants to take it (and propagating signals to subprocess & its childrens) on, go for it

github-actions[bot] on (2025-01-29 00:14:54 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2716138127,pull_request,closed,,feat: retrieve sftp file attrs onces instead multiple time,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adding a new method for the `SFTPHook` to retrieve all files including their sftp attributes.

Currently, when listing files, all files are retrieved first and then another request is sent for each file to retrieve the file attributes. Listing many files slows down this behavior.

I tested the performance with 500 files and it dropped from about 49 seconds to 1-2 seconds.



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dondaum,2024-12-03 22:58:28+00:00,[],2024-12-06 07:17:13+00:00,2024-12-06 07:17:13+00:00,https://github.com/apache/airflow/pull/44625,"[('area:providers', ''), ('provider:sftp', '')]","[{'comment_id': 2522299932, 'issue_id': 2716138127, 'author': 'potiuk', 'body': 'Intermittent error - not related. Merging.', 'created_at': datetime.datetime(2024, 12, 6, 7, 16, 59, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-06 07:16:59 UTC): Intermittent error - not related. Merging.

"
2716111662,pull_request,closed,,Add ability to list active backfills both across cluster and per-dag,"Closes [#44396](https://github.com/apache/airflow/issues/44396)
",prabhusneha,2024-12-03 22:39:14+00:00,[],2024-12-11 11:46:53+00:00,2024-12-11 11:46:51+00:00,https://github.com/apache/airflow/pull/44624,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2519920462, 'issue_id': 2716111662, 'author': 'pierrejeambrun', 'body': 'CI need fixing I think.', 'created_at': datetime.datetime(2024, 12, 5, 10, 33, 35, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-12-05 10:33:35 UTC): CI need fixing I think.

"
2716087534,pull_request,closed,,Fix a couple comments,"Trivial fixes to a couple comments I noticed while working on something unrelated.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-12-03 22:20:38+00:00,[],2024-12-04 06:04:01+00:00,2024-12-04 06:04:01+00:00,https://github.com/apache/airflow/pull/44623,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2716020335,pull_request,closed,,Advise using pre-commit-uv when installing pre-commit with uv,"We already issue a reminder to do it since it'll be faster, so we should just tell folks to do it from the get go.

I also fixed up a bit of the whitespace while I was at it :)

Before:
![Screenshot 2024-12-03 at 2 24 18 PM](https://github.com/user-attachments/assets/67360e23-eac7-46e1-a34b-f65715aa4c82)

After:

![Screenshot 2024-12-03 at 2 33 30 PM](https://github.com/user-attachments/assets/182fea76-4556-4e69-8186-e1ee637462ad)
",jedcunningham,2024-12-03 21:34:08+00:00,[],2024-12-04 05:47:38+00:00,2024-12-03 22:32:30+00:00,https://github.com/apache/airflow/pull/44622,"[('area:dev-tools', '')]",[],
2715496954,pull_request,closed,,AIP-84 Standardize patch behavior across endpoints in fast api,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

Closes issue: #43650 

Standardize patch behavior across endpoints in fast api based on these key points:
1. When a mask is provided, use the values as specified by the mask.
2. When no mask is provided, ensure the payload is validated independently as a fully-formed database entity, allowing for explicit setting of fields to None.


**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ajitg25,2024-12-03 16:38:08+00:00,[],2024-12-11 12:44:45+00:00,2024-12-11 12:44:45+00:00,https://github.com/apache/airflow/pull/44619,"[('area:providers', ''), ('provider:ssh', ''), ('provider:sftp', '')]","[{'comment_id': 2520801606, 'issue_id': 2715496954, 'author': 'ajitg25', 'body': '@pierrejeambrun Need one help from you, currently I am using this `breeze testing core-tests --test-type ""API""` to run the unit test cases which takes a lot of time as it runs for all the APIs. Is there any command to make it run for a specific file?\r\nI tried to find in doc but for breeze didnt find any command for single file for API', 'created_at': datetime.datetime(2024, 12, 5, 16, 13, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2521212960, 'issue_id': 2715496954, 'author': 'pierrejeambrun', 'body': ""We use to be able to do something like `breeze testing  tests -- tests/api_fastapi` but this command has been removed.\r\nThe best way now would be to enter breeze shell, and run pytest command there (cc: @potiuk maybe there's even better):\r\n```shell\r\nbreeze shell\r\n```\r\nOr you can run them in your local virtual environment (faster but you might be missing external dependencies, and not identical to the CI)\r\n\r\nhttps://github.com/apache/airflow/blob/main/dev/breeze/doc/05_test_commands.rst\r\nhttps://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst"", 'created_at': datetime.datetime(2024, 12, 5, 19, 19, 1, tzinfo=datetime.timezone.utc)}]","ajitg25 (Issue Creator) on (2024-12-05 16:13:48 UTC): @pierrejeambrun Need one help from you, currently I am using this `breeze testing core-tests --test-type ""API""` to run the unit test cases which takes a lot of time as it runs for all the APIs. Is there any command to make it run for a specific file?
I tried to find in doc but for breeze didnt find any command for single file for API

pierrejeambrun on (2024-12-05 19:19:01 UTC): We use to be able to do something like `breeze testing  tests -- tests/api_fastapi` but this command has been removed.
The best way now would be to enter breeze shell, and run pytest command there (cc: @potiuk maybe there's even better):
```shell
breeze shell
```
Or you can run them in your local virtual environment (faster but you might be missing external dependencies, and not identical to the CI)

https://github.com/apache/airflow/blob/main/dev/breeze/doc/05_test_commands.rst
https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst

"
2715420568,pull_request,closed,,add clear_number to OpenLineage's dagrun-level event run id generation,"Right now, when task gets cleared via UI, and dag run gets scheduled again, the OpenLineage integration will emit the event with same OL run_id as in the first execution. This is confusing for OpenLineage consumers, as the run that's already received terminal state should not receive following events.

To fix that, use `clear_number` introduced in Airflow 2.8.0 as additional information used in generating OpenLineage's `run_id` to distinguish between those runs.",mobuchowski,2024-12-03 16:03:34+00:00,[],2025-01-11 19:43:51+00:00,2024-12-07 12:23:48+00:00,https://github.com/apache/airflow/pull/44617,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2715416974,pull_request,closed,,Add basic Airflow error guide,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/43171

This PR introduces a very basic guide with  Airflow error codes mapping to some common errors. This can be treated as a starting point for the mapping to which we can all start adding to and improving the coverage of errors and their mapping to possible causes and resolutions. ",omkar-foss,2024-12-03 16:02:00+00:00,['omkar-foss'],2025-02-09 03:58:14+00:00,2025-02-08 21:57:18+00:00,https://github.com/apache/airflow/pull/44616,"[('area:dev-tools', '')]","[{'comment_id': 2514990373, 'issue_id': 2715416974, 'author': 'omkar-foss', 'body': ""List of core Airflow exceptions from `airflow/exceptions.py` as below. I've started with `AirflowException` for now. Also error logs are good source of common errors that users face, which we should map - I've mapped a few as `Error Log` in the markdown table.\r\n\r\n```python\r\nAirflowException\r\nAirflowBadRequest\r\nAirflowNotFoundException\r\nDagNotFound\r\nDagCodeNotFound\r\nDagRunNotFound\r\nAirflowConfigException\r\nAirflowSensorTimeout\r\nAirflowRescheduleException\r\nInvalidStatsNameException\r\nAirflowTaskTimeout\r\nAirflowTaskTerminated\r\nAirflowWebServerTimeout\r\nAirflowSkipException\r\nAirflowFailException\r\nAirflowOptionalProviderFeatureException\r\nAirflowInternalRuntimeError\r\nXComNotFound\r\nUnmappableOperator\r\nXComForMappingNotPushed\r\nUnmappableXComTypePushed\r\nUnmappableXComLengthPushed\r\nAirflowDagCycleException\r\nAirflowDagDuplicatedIdException\r\nAirflowClusterPolicyViolation\r\nAirflowClusterPolicySkipDag\r\nAirflowClusterPolicyError\r\nAirflowTimetableInvalid\r\nAirflowFileParseException\r\nFileSyntaxError\r\nConnectionNotUnique\r\nTaskDeferred\r\nTaskDeferralError\r\nPodMutationHookException\r\nPodReconciliationError\r\nRemovedInAirflow3Warning\r\nAirflowProviderDeprecationWarning\r\nDeserializingResultError\r\nUnknownExecutorException\r\n```"", 'created_at': datetime.datetime(2024, 12, 3, 16, 11, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522953660, 'issue_id': 2715416974, 'author': 'potiuk', 'body': 'One comment here @omkar-foss.  This is quite some change in how we treat errors, so it would be great to announce intention to implement those error numbers and messages at the devlist. While there was survey and few people discussed that this is a good idea, ""What did not happen on devlist, did not happen"" - so likely start a discussion on devlist - with intention to run lazy consensus / (or vote in case there will be any doubts).', 'created_at': datetime.datetime(2024, 12, 6, 11, 27, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546101772, 'issue_id': 2715416974, 'author': 'omkar-foss', 'body': '> One comment here @omkar-foss. This is quite some change in how we treat errors, so it would be great to announce intention to implement those error numbers and messages at the devlist. While there was survey and few people discussed that this is a good idea, ""What did not happen on devlist, did not happen"" - so likely start a discussion on devlist - with intention to run lazy consensus / (or vote in case there will be any doubts).\r\n\r\nDone, sent on devlist ✅\r\n\r\nApologies for the delayed response! I\'ll continue adding error mappings to this PR while we await responses on devlist and finalize items etc.', 'created_at': datetime.datetime(2024, 12, 16, 16, 34, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565229888, 'issue_id': 2715416974, 'author': 'omkar-foss', 'body': ""In accordance with @ashb's feedback on [this slack thread](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1734712796105699) to include errors relevant to end users, I've updated the Airflow Error Codes list in this PR with **top 100 user-facing errors** with their descriptions and newly assigned (tentative) error codes. \r\n\r\nI've created this top 100 errors list by referring to Airflow-related questions on StackOverflow, suggestions from ChatGPT and also by referring to few questions asked on [#user-troubleshooting](https://apache-airflow.slack.com/archives/CCQ7EGB1P) slack channel.\r\n\r\nThere's a lot of scope for improving this list so would be great if you can check it out and drop a comment on this PR as necessary. Thank you :)\r\n\r\nMarkdown-rendered view here: https://github.com/apache/airflow/blob/86fc8b10bd248e41aba2d80de76bac04280e2c03/dev/AIRFLOW_ERROR_GUIDE.md"", 'created_at': datetime.datetime(2024, 12, 30, 9, 24, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566446819, 'issue_id': 2715416974, 'author': 'potiuk', 'body': 'As discussed in slack - value of that list and the page is going to be WAY better if there is an action that the user can make for all of those. Users often do not look for description of what is going on, they are looking after the solutions. And in a number of cases we can at the very least guide them where to look for such solutions, which part ofthe documentation should they look for (i.e. link to relevant documentation) . In some other cases we can suspect that this is a deployment issue and tell the users to look there, In many other cases we can even point them to actual configuration parameters that could be changed, or typical resolutions and aras they should look for. In many other cases you can add some examples what could be done.\r\n\r\nThe ruff rules for one are very good way of approaching it  lilke https://docs.astral.sh/ruff/rules/#legend - many of those rules explain what happen, and a number of thos provide a proposal for a solution/example of fixes. While it\'s a bit ""easier"" with ruff, as the rules are simpler than potential Airflow errors, I see no reason why we should not be able to at least guide the people to the solutions. That might significantly decrease the number of issues people will open in our repo, and even if not - it will make it easier for all contributors and committers and triage team to be able to respond to such issue and direct the users to those pages, providing first liine of support for our users.\r\n\r\nAll those do not haave to be there in the PR to get it merged, but IMHO we should design it in the way that it is possible - and ""crowdsource"" filling that information (via an issue where we will have) \r\n\r\n- [ ] ERR1\r\n- [ ] ERR2\r\n\r\nAnd let the community people contribute the possible solutions and things to look at there.\r\n\r\n\r\nPossibly table like that is a bit to ""small"" to keep that information.', 'created_at': datetime.datetime(2024, 12, 31, 13, 14, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634025515, 'issue_id': 2715416974, 'author': 'omkar-foss', 'body': ""@potiuk Sorry about the delay on this. As per your suggestions in [above comment](https://github.com/apache/airflow/pull/44616#issuecomment-2566446819), I've added 2 new sections to the markdown table:\r\n- `First Steps`: First steps to be taken by the user to resolve the issue \r\n- `Documentation`: Appropriate Airflow documentation link for more information\r\n\r\nQuick preview of the markdown table: [here](https://github.com/apache/airflow/blob/a0b9dc83f705564057eac8920b6e966a2bab3d6e/dev/AIRFLOW_ERROR_GUIDE.md)"", 'created_at': datetime.datetime(2025, 2, 4, 13, 49, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634064600, 'issue_id': 2715416974, 'author': 'omkar-foss', 'body': "">And let the community people contribute the possible solutions and things to look at there.\r\n\r\nIndeed, so the idea is to treat this more like a template on which others in the community can build upon.\r\n\r\nThis single table of course won't be able to accommodate all prevalent Airflow issues, but like you suggested, I suppose we can sprout out of this table to separate solutions pages or so as required - so again, we can treat this table as a starting point and can go ahead from there :)\r\n\r\nLet me know your thoughts on this, thanks."", 'created_at': datetime.datetime(2025, 2, 4, 14, 2, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2639787911, 'issue_id': 2715416974, 'author': 'potiuk', 'body': 'I like the thing as it is now. This has all the basic structure and information about the errors I want to see. And while I do not have concrete comments to all the issues I think it\'s as good as it can be to merge it. I think the next step could be to add a framework, where we could have a way to add the ERRORID to (say) AirflowException - or maybe beetter create AirflowEnumeratedException with obligatory error ID following the convention described here). \r\n\r\nThe next step could be to create an issue with all those errors as ""tasks"" to do and let others contribute back adding the error IDs in the right places. Once we do it we could think about reviewing the code and adding the errors ""as we go"".\r\n\r\nWhat do you think @omkar-foss  ?', 'created_at': datetime.datetime(2025, 2, 6, 13, 10, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2645954394, 'issue_id': 2715416974, 'author': 'omkar-foss', 'body': 'Sounds like a nice plan @potiuk 👍🏽', 'created_at': datetime.datetime(2025, 2, 8, 21, 42, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2645958205, 'issue_id': 2715416974, 'author': 'potiuk', 'body': '> Sounds like a nice plan @potiuk 👍🏽\r\n\r\nDo it :) . Merged!', 'created_at': datetime.datetime(2025, 2, 8, 21, 57, 47, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-12-03 16:11:14 UTC): List of core Airflow exceptions from `airflow/exceptions.py` as below. I've started with `AirflowException` for now. Also error logs are good source of common errors that users face, which we should map - I've mapped a few as `Error Log` in the markdown table.

```python
AirflowException
AirflowBadRequest
AirflowNotFoundException
DagNotFound
DagCodeNotFound
DagRunNotFound
AirflowConfigException
AirflowSensorTimeout
AirflowRescheduleException
InvalidStatsNameException
AirflowTaskTimeout
AirflowTaskTerminated
AirflowWebServerTimeout
AirflowSkipException
AirflowFailException
AirflowOptionalProviderFeatureException
AirflowInternalRuntimeError
XComNotFound
UnmappableOperator
XComForMappingNotPushed
UnmappableXComTypePushed
UnmappableXComLengthPushed
AirflowDagCycleException
AirflowDagDuplicatedIdException
AirflowClusterPolicyViolation
AirflowClusterPolicySkipDag
AirflowClusterPolicyError
AirflowTimetableInvalid
AirflowFileParseException
FileSyntaxError
ConnectionNotUnique
TaskDeferred
TaskDeferralError
PodMutationHookException
PodReconciliationError
RemovedInAirflow3Warning
AirflowProviderDeprecationWarning
DeserializingResultError
UnknownExecutorException
```

potiuk on (2024-12-06 11:27:41 UTC): One comment here @omkar-foss.  This is quite some change in how we treat errors, so it would be great to announce intention to implement those error numbers and messages at the devlist. While there was survey and few people discussed that this is a good idea, ""What did not happen on devlist, did not happen"" - so likely start a discussion on devlist - with intention to run lazy consensus / (or vote in case there will be any doubts).

omkar-foss (Issue Creator) on (2024-12-16 16:34:03 UTC): Done, sent on devlist ✅

Apologies for the delayed response! I'll continue adding error mappings to this PR while we await responses on devlist and finalize items etc.

omkar-foss (Issue Creator) on (2024-12-30 09:24:15 UTC): In accordance with @ashb's feedback on [this slack thread](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1734712796105699) to include errors relevant to end users, I've updated the Airflow Error Codes list in this PR with **top 100 user-facing errors** with their descriptions and newly assigned (tentative) error codes. 

I've created this top 100 errors list by referring to Airflow-related questions on StackOverflow, suggestions from ChatGPT and also by referring to few questions asked on [#user-troubleshooting](https://apache-airflow.slack.com/archives/CCQ7EGB1P) slack channel.

There's a lot of scope for improving this list so would be great if you can check it out and drop a comment on this PR as necessary. Thank you :)

Markdown-rendered view here: https://github.com/apache/airflow/blob/86fc8b10bd248e41aba2d80de76bac04280e2c03/dev/AIRFLOW_ERROR_GUIDE.md

potiuk on (2024-12-31 13:14:37 UTC): As discussed in slack - value of that list and the page is going to be WAY better if there is an action that the user can make for all of those. Users often do not look for description of what is going on, they are looking after the solutions. And in a number of cases we can at the very least guide them where to look for such solutions, which part ofthe documentation should they look for (i.e. link to relevant documentation) . In some other cases we can suspect that this is a deployment issue and tell the users to look there, In many other cases we can even point them to actual configuration parameters that could be changed, or typical resolutions and aras they should look for. In many other cases you can add some examples what could be done.

The ruff rules for one are very good way of approaching it  lilke https://docs.astral.sh/ruff/rules/#legend - many of those rules explain what happen, and a number of thos provide a proposal for a solution/example of fixes. While it's a bit ""easier"" with ruff, as the rules are simpler than potential Airflow errors, I see no reason why we should not be able to at least guide the people to the solutions. That might significantly decrease the number of issues people will open in our repo, and even if not - it will make it easier for all contributors and committers and triage team to be able to respond to such issue and direct the users to those pages, providing first liine of support for our users.

All those do not haave to be there in the PR to get it merged, but IMHO we should design it in the way that it is possible - and ""crowdsource"" filling that information (via an issue where we will have) 

- [ ] ERR1
- [ ] ERR2

And let the community people contribute the possible solutions and things to look at there.


Possibly table like that is a bit to ""small"" to keep that information.

omkar-foss (Issue Creator) on (2025-02-04 13:49:07 UTC): @potiuk Sorry about the delay on this. As per your suggestions in [above comment](https://github.com/apache/airflow/pull/44616#issuecomment-2566446819), I've added 2 new sections to the markdown table:
- `First Steps`: First steps to be taken by the user to resolve the issue 
- `Documentation`: Appropriate Airflow documentation link for more information

Quick preview of the markdown table: [here](https://github.com/apache/airflow/blob/a0b9dc83f705564057eac8920b6e966a2bab3d6e/dev/AIRFLOW_ERROR_GUIDE.md)

omkar-foss (Issue Creator) on (2025-02-04 14:02:53 UTC): Indeed, so the idea is to treat this more like a template on which others in the community can build upon.

This single table of course won't be able to accommodate all prevalent Airflow issues, but like you suggested, I suppose we can sprout out of this table to separate solutions pages or so as required - so again, we can treat this table as a starting point and can go ahead from there :)

Let me know your thoughts on this, thanks.

potiuk on (2025-02-06 13:10:06 UTC): I like the thing as it is now. This has all the basic structure and information about the errors I want to see. And while I do not have concrete comments to all the issues I think it's as good as it can be to merge it. I think the next step could be to add a framework, where we could have a way to add the ERRORID to (say) AirflowException - or maybe beetter create AirflowEnumeratedException with obligatory error ID following the convention described here). 

The next step could be to create an issue with all those errors as ""tasks"" to do and let others contribute back adding the error IDs in the right places. Once we do it we could think about reviewing the code and adding the errors ""as we go"".

What do you think @omkar-foss  ?

omkar-foss (Issue Creator) on (2025-02-08 21:42:19 UTC): Sounds like a nice plan @potiuk 👍🏽

potiuk on (2025-02-08 21:57:47 UTC): Do it :) . Merged!

"
2715277792,pull_request,closed,,feat: automatically inject OL info into spark properties in DataprocCreateBatchOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR integrates a newly introduced (#44477) OpenLineage feature into another Dataproc operator. With this enhancement, users no longer need to manually provide parent job information for the OpenLineage Spark integration to generate the parent job facet. Detailed information about this feature can be found in the description of #44477.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-03 15:03:36+00:00,[],2024-12-30 10:54:16+00:00,2024-12-30 10:48:30+00:00,https://github.com/apache/airflow/pull/44612,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:openlineage', 'AIP-53'), ('provider:common-compat', '')]",[],
2715228810,pull_request,closed,,Fix SQLite condition for detecting pickled data,"In [PR](https://github.com/apache/airflow/pull/44166) we added migration for removing pickled data from `xcom` table. During my testing I noticed with `SQLite`  [insert](https://github.com/apache/airflow/blob/main/airflow/migrations/versions/0049_3_0_0_remove_pickled_data_from_xcom_table.py#L88) statement is not working in case of upgrade. Changing condition to `hex(substr(value, 1, 1)) = '80'` works. Tested [here](https://github.com/apache/airflow/pull/44533#discussion_r1867742628).

related: https://github.com/apache/airflow/pull/44166



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-03 14:44:40+00:00,[],2024-12-03 15:03:04+00:00,2024-12-03 15:03:02+00:00,https://github.com/apache/airflow/pull/44611,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2715152566,pull_request,closed,,fix(proivders/common/compat): move airflow versions out of __init__.py,"## Why
https://github.com/apache/airflow/pull/43773#discussion_r1867636526

## What
compare airflow versions in each modules

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-03 14:14:46+00:00,['Lee-W'],2024-12-05 09:28:02+00:00,2024-12-05 09:28:02+00:00,https://github.com/apache/airflow/pull/44610,"[('area:providers', ''), ('provider:common-compat', '')]","[{'comment_id': 2519737394, 'issue_id': 2715152566, 'author': 'potiuk', 'body': 'Better and more complete (""eat cake and have it too"") in https://github.com/apache/airflow/pull/44686', 'created_at': datetime.datetime(2024, 12, 5, 9, 27, 14, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-05 09:27:14 UTC): Better and more complete (""eat cake and have it too"") in https://github.com/apache/airflow/pull/44686

"
2715095680,pull_request,closed,,AIP-84 De-nest Dag Tags endpoint,`dagTags` route was conflicting with `dags/<dag_id>`. (Basically a dag with dag_id = `tags` would cause problem),pierrejeambrun,2024-12-03 13:53:09+00:00,['pierrejeambrun'],2024-12-04 12:26:19+00:00,2024-12-04 12:26:17+00:00,https://github.com/apache/airflow/pull/44608,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2514631049, 'issue_id': 2715095680, 'author': 'pierrejeambrun', 'body': 'cc: @uranusjr', 'created_at': datetime.datetime(2024, 12, 3, 13, 56, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516931520, 'issue_id': 2715095680, 'author': 'pierrejeambrun', 'body': ""> The react hooks are the same? Great!\r\n\r\nyes that's also what I told myself. If the signature of the service (parameters and return type) does not change, then basically the new autogenerated code will work right away without needing any adaptation on the front-end. That's really cool. (for instance here the endpoint path changes, that's automatically handled in the deeper layer of the service)"", 'created_at': datetime.datetime(2024, 12, 4, 10, 46, 33, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-12-03 13:56:45 UTC): cc: @uranusjr

pierrejeambrun (Issue Creator) on (2024-12-04 10:46:33 UTC): yes that's also what I told myself. If the signature of the service (parameters and return type) does not change, then basically the new autogenerated code will work right away without needing any adaptation on the front-end. That's really cool. (for instance here the endpoint path changes, that's automatically handled in the deeper layer of the service)

"
2715079955,pull_request,closed,,Add get_airflow_version helper,"The point of this helper is to make it simpler to figure out what airflow version is installed, in particular to implement conditional logic in providers.

Currently the logic is too complicated and this has resulted in the proliferation of sort of redundant constants.  Here's an example:

```
from airflow import __version__ as AIRFLOW_VERSION

AIRFLOW_V_3_0_PLUS = Version(Version(AIRFLOW_VERSION).base_version) >= Version(""3.0.0"")
if AIRFLOW_V_3_0_PLUS:
    from airflow.sdk.definitions.asset import Asset
```

With this helper, we can do this instead:

```
from airflow import get_airflow_version

if get_airflow_version() > Version(""3.0.0""):
    from airflow.sdk.definitions.asset import Asset
```

We can't make use of this helper in providers until they are bumped to min airflow version == 2.11.0.",dstandish,2024-12-03 13:46:43+00:00,[],2025-02-03 00:15:47+00:00,2025-02-03 00:15:47+00:00,https://github.com/apache/airflow/pull/44607,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2519738811, 'issue_id': 2715079955, 'author': 'potiuk', 'body': 'This should be not needed any more (at least for providers) after the better and more complete fix (""eat cake and have it too"") in https://github.com/apache/airflow/pull/44686', 'created_at': datetime.datetime(2024, 12, 5, 9, 27, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620313905, 'issue_id': 2715079955, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 29, 0, 14, 56, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-05 09:27:48 UTC): This should be not needed any more (at least for providers) after the better and more complete fix (""eat cake and have it too"") in https://github.com/apache/airflow/pull/44686

github-actions[bot] on (2025-01-29 00:14:56 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2714847783,pull_request,closed,,AIP-72: Adding support to Set an XCom from Task SDK,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/44350

Adding support to be able to put/create xcoms from the task sdk side.

### Brief of changes:

#### Supervisor
The supervisor would receive a request from the task runner to CREATE a xcoms.
The handle_request method handles this part and is responsible to send a request to the API client to send it to the tas execution interface.
In this case, SetXCom is the body that will be passed down to the api client.

#### API Client
The client receives a request from the supervisor to CREATE a xcom. The client then sends it to the task execution interface over HTTP. It send a POST request with the received body. The key isn't stripped off but is sent in the payload even though the server doesn't serialise it.
The client receives a response {""message"": ""XCom successfully set""} if all's good.
It passes this response back down to the supervisor which then writes it in the buffer.

#### Testing
Since end to end isn't possible, the test case https://github.com/apache/airflow/compare/main...astronomer:airflow:AIP72-set-xcom-tasksdk?expand=1#diff-f55b9ba6be46de22b2838085bf1e0aa4193797c3ff7d0cdc4e06a626c96df1baR693-R713 checks for supervisor side of things, if supervisor processes ""request"" of correct format correctly. Checks for call args, responses, even buffer.

The test https://github.com/apache/airflow/compare/main...astronomer:airflow:AIP72-set-xcom-tasksdk?expand=1#diff-048659c5ed2897cd0ed24a340885d5950c964ea451ccc359e1ab592bf8a59f0dR138-R165 checks if the client can handle requests of type SetXCom properly and respond accordingly.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-03 12:07:20+00:00,['amoghrajesh'],2024-12-06 17:05:53+00:00,2024-12-06 17:05:50+00:00,https://github.com/apache/airflow/pull/44605,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2714823411,pull_request,closed,,Implement card view for tasks view of a dag,"Use `tasks` endpoint to fill the card view first. Get dag's recent dagruns and get the last dagrun id and pass it to taskinstances endpoint to get the last run and the corresponding task instance state. 

Comments for reviewers and self :

1. Disable pagination since tasks and task instances doesn't support limit or pagination.
2. Colors are slightly off with `stateColor` and the theme which will be fixed overall. Please let me know if I am missing some other configuration.
3. The historical view of the task instances which is the last column in the card view is using list task instances endpoint which returns like 100 task instances and the limit is easily reached with 14 task instances per task. All task instance attributes are also not used with only start_date, end_date, try_number, duration and state used which could be fetched efficiently.
4. Do we need to display a tooltip for the last run. Perhaps the start time, end time and try number of the last task instance.

This PR probably needs a rebase after https://github.com/apache/airflow/pull/44269 is merged.

![image](https://github.com/user-attachments/assets/71d01a4a-93af-43bf-8b63-b6f2886293a9)

![image](https://github.com/user-attachments/assets/adbe71c5-57aa-401b-8db7-c2f5389e04e7)
",tirkarthi,2024-12-03 11:58:22+00:00,[],2024-12-06 21:56:04+00:00,2024-12-06 15:20:49+00:00,https://github.com/apache/airflow/pull/44604,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2524246554, 'issue_id': 2714823411, 'author': 'tirkarthi', 'body': 'Thanks @bbovenzi', 'created_at': datetime.datetime(2024, 12, 6, 21, 56, 3, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-12-06 21:56:03 UTC): Thanks @bbovenzi

"
2714776846,pull_request,closed,,Add 'airflow assets materialize' (again),Initial PR #44558 reverted in #44602.,uranusjr,2024-12-03 11:38:39+00:00,[],2024-12-03 16:08:14+00:00,2024-12-03 14:22:33+00:00,https://github.com/apache/airflow/pull/44603,"[('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2514706986, 'issue_id': 2714776846, 'author': 'potiuk', 'body': 'nice! Thanks @uranusjr !', 'created_at': datetime.datetime(2024, 12, 3, 14, 22, 43, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-03 14:22:43 UTC): nice! Thanks @uranusjr !

"
2714688555,pull_request,closed,,"Revert ""Add 'airflow assets materialize' (#44558)""","This reverts commit 3505f9ab8c9c39985a64285fad5742407793db44.

Let’s see if this fixes things…
",uranusjr,2024-12-03 11:01:25+00:00,[],2024-12-03 11:34:13+00:00,2024-12-03 11:34:11+00:00,https://github.com/apache/airflow/pull/44602,"[('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2514300325, 'issue_id': 2714688555, 'author': 'uranusjr', 'body': 'Looks like it does?', 'created_at': datetime.datetime(2024, 12, 3, 11, 34, 4, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-12-03 11:34:04 UTC): Looks like it does?

"
2714525228,pull_request,closed,,AIP-84 structure_data endpoint 404 not found for missing dag,"When the dag is missing, raise a 404 not found error instead of an unhandled 500 server error.",pierrejeambrun,2024-12-03 09:55:03+00:00,['pierrejeambrun'],2024-12-04 10:58:43+00:00,2024-12-04 10:58:41+00:00,https://github.com/apache/airflow/pull/44599,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2714346370,pull_request,closed,,Removed deprecated code from hashicorp provider,"related: #44559 

Removed deprecated code from hashicorp provider




<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2024-12-03 08:38:50+00:00,[],2024-12-06 21:22:48+00:00,2024-12-06 21:22:37+00:00,https://github.com/apache/airflow/pull/44598,"[('area:providers', ''), ('provider:hashicorp', 'Hashicorp provider related issues')]","[{'comment_id': 2517513719, 'issue_id': 2714346370, 'author': 'Prab-27', 'body': 'Done', 'created_at': datetime.datetime(2024, 12, 4, 14, 7, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2524198596, 'issue_id': 2714346370, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 6, 21, 22, 46, tzinfo=datetime.timezone.utc)}]","Prab-27 (Issue Creator) on (2024-12-04 14:07:11 UTC): Done

boring-cyborg[bot] on (2024-12-06 21:22:46 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2714262891,pull_request,closed,,Add dag docs and dag reparsing button to details page.,"Add dag documentation and dag reparse button to the header. `Dag Docs` opens a modal similar to graph view and uses `react-markdown` to render the markdown docs from `doc_md` attribute. `Reparse Dag` triggers reparsing and invalidates dag details and code queries for refetch. Reparsing is done by scheduler and probably a toast message might be displayed on successful reparsing using chakra. Screenshots as below

https://www.chakra-ui.com/docs/components/toast

![image](https://github.com/user-attachments/assets/2c90ccf4-7719-4b14-87eb-a50c609582fe)

![image](https://github.com/user-attachments/assets/3a317725-ddeb-4384-a75f-13e069c2b8b5)

![image](https://github.com/user-attachments/assets/1bc30a9c-46be-433b-9adf-25fd2f881fed)



",tirkarthi,2024-12-03 07:56:11+00:00,[],2024-12-04 21:28:27+00:00,2024-12-04 20:40:41+00:00,https://github.com/apache/airflow/pull/44597,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2517757959, 'issue_id': 2714262891, 'author': 'tirkarthi', 'body': 'Renamed the files as per convention since they were generated using the chakra cli.', 'created_at': datetime.datetime(2024, 12, 4, 15, 20, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517993904, 'issue_id': 2714262891, 'author': 'tirkarthi', 'body': ""Thanks @bbovenzi rephrased the toast messages as suggested. For the error message I will see what are the related scenarios and see if I can update it or use a generic message. Thanks for the tip to refactor Dag Documentation button it simplified a lot of things and deleted boilerplate state management. Now it's a standalone component on it's own and docs button is shown only when dag has `doc_md` ."", 'created_at': datetime.datetime(2024, 12, 4, 16, 44, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518517182, 'issue_id': 2714262891, 'author': 'pierrejeambrun', 'body': 'Code looks good', 'created_at': datetime.datetime(2024, 12, 4, 20, 40, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518583326, 'issue_id': 2714262891, 'author': 'jscheffl', 'body': 'One side note, not related to the implementation... but rather to UI. I was wondering also in 2.10 that the ""reparse DAG"" button is so prominent. I would like tpo understand what the reason is making this so prominent. Usually DAG parsing should be running in background silently. Are there really many cases where an individual trigger is needed? Is the system not rather missing a different function? For me this looks very much like an admin/troubleshooting option.\r\n\r\nVery much reminds me to https://github.com/apache/airflow/pull/34487', 'created_at': datetime.datetime(2024, 12, 4, 21, 19, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518597944, 'issue_id': 2714262891, 'author': 'bbovenzi', 'body': 'Yeah, the button does feel too prominent to me. I am happy to move it inside of a ""..."" more options button.', 'created_at': datetime.datetime(2024, 12, 4, 21, 28, 25, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-12-04 15:20:23 UTC): Renamed the files as per convention since they were generated using the chakra cli.

tirkarthi (Issue Creator) on (2024-12-04 16:44:06 UTC): Thanks @bbovenzi rephrased the toast messages as suggested. For the error message I will see what are the related scenarios and see if I can update it or use a generic message. Thanks for the tip to refactor Dag Documentation button it simplified a lot of things and deleted boilerplate state management. Now it's a standalone component on it's own and docs button is shown only when dag has `doc_md` .

pierrejeambrun on (2024-12-04 20:40:39 UTC): Code looks good

jscheffl on (2024-12-04 21:19:44 UTC): One side note, not related to the implementation... but rather to UI. I was wondering also in 2.10 that the ""reparse DAG"" button is so prominent. I would like tpo understand what the reason is making this so prominent. Usually DAG parsing should be running in background silently. Are there really many cases where an individual trigger is needed? Is the system not rather missing a different function? For me this looks very much like an admin/troubleshooting option.

Very much reminds me to https://github.com/apache/airflow/pull/34487

bbovenzi on (2024-12-04 21:28:25 UTC): Yeah, the button does feel too prominent to me. I am happy to move it inside of a ""..."" more options button.

"
2714210654,pull_request,closed,,Show alises with assets 'list' and 'details' CLI,"Last parts for #42317.

I also took the chance to change the model dump format from ""python"" to ""json"". This is more inline with the REST API, and also seems more CLI friendly?

Close #42317.",uranusjr,2024-12-03 07:26:25+00:00,[],2024-12-04 23:37:17+00:00,2024-12-04 23:37:15+00:00,https://github.com/apache/airflow/pull/44595,"[('area:CLI', '')]",[],
2713871658,pull_request,closed,,Bump `ruff` to `0.8.1`,"https://pypi.org/project/ruff/0.8.1/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-03 03:04:41+00:00,"['amoghrajesh', 'jedcunningham']",2024-12-03 07:08:47+00:00,2024-12-03 07:08:47+00:00,https://github.com/apache/airflow/pull/44591,"[('area:dev-tools', '')]",[],
2713792868,pull_request,closed,,AIP-72: Port task success overtime to the Supervisor,"This PR ports the overtime feature on `LocalTaskJob` (added in https://github.com/apache/airflow/pull/39890) to the Supervisor. It allows the Task process to terminate when it is exceeding the configured overtime threshold which is useful when we add Listenener to the Task process.

The overtime configured here applies to all states not just success, as was the case with LTJ.

closes https://github.com/apache/airflow/issues/44356

Also added `TaskState` to update state and send end_date from task process to the supervisor.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-03 02:03:03+00:00,[],2024-12-03 15:47:45+00:00,2024-12-03 15:47:43+00:00,https://github.com/apache/airflow/pull/44590,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2713769861,pull_request,closed,,Add back `eval-type-backport` to entrypoint_ci.sh as pydantic workaround,"We need to install `eval-type-backport` to avoid problems with Pydantic 2.10.+ released in November 2024 for python 3.8 and 3.9. While Pydantic 2.10.0/2.10.1 completely broke Airflow 2 installation and Pydantic 2.10.2 fixed the issue for past versions of Airflow, there are still Some Typing constructs that are not handled well by Pydantic and in case Pydantic fails with those errors, it will STILL fall back to `eval-type-backport` to handle those cases (if if `eval-type-backport` is installed. Therefore - until we have Airflow 2.10.3 for backwards compatibility tests and we attempt to install ""edge"" provider that might use such breaking constructs, we need to install `eval-type-backport` to avoid problems with Pydantic 2.10.2+ as well. As soon as we move to Airflow 2.10.4, we can remove this workaround because Airflow 2.10.4 adds ""eval-type-backport"" as a dependency and it will be installed automatically.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-03 01:43:07+00:00,[],2024-12-03 14:29:13+00:00,2024-12-03 14:29:11+00:00,https://github.com/apache/airflow/pull/44589,"[('area:dev-tools', '')]","[{'comment_id': 2514722160, 'issue_id': 2713769861, 'author': 'potiuk', 'body': ""> should we add backport to v2-10-test?\r\n\r\nNo need - there we do not run back-compatibility tests - and it's test-only change."", 'created_at': datetime.datetime(2024, 12, 3, 14, 28, 56, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-03 14:28:56 UTC): No need - there we do not run back-compatibility tests - and it's test-only change.

"
2713759698,pull_request,closed,,Remove comment about removing eval type backport,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-03 01:32:51+00:00,[],2024-12-04 08:47:13+00:00,2024-12-03 06:42:38+00:00,https://github.com/apache/airflow/pull/44588,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2713671349,pull_request,closed,,[v2-10-test] Fix tests badge in README.md (#44505),"(cherry picked from commit a242ff6edb51db6e8ac1ced72b5bf327dd98c1b4)

Co-authored-by: Shahar Epstein <60007259+shahar1@users.noreply.github.com>",github-actions[bot],2024-12-03 00:22:41+00:00,[],2024-12-03 20:58:13+00:00,2024-12-03 20:58:10+00:00,https://github.com/apache/airflow/pull/44587,[],[],
2713603612,pull_request,closed,,Add DAG bundles model,"This adds the initial model and FK for DAG Bundles. For now it is left as nullable (and left empty), but once parsing changes are complete it will become required.

The approach is very similar to triggerer, in that you have a classpath and kwargs so a bundle entity can be created.",jedcunningham,2024-12-02 23:22:37+00:00,[],2024-12-05 03:17:31+00:00,2024-12-03 20:57:24+00:00,https://github.com/apache/airflow/pull/44586,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2713579871,pull_request,closed,,Rename `head` to `tracking_ref` in `GitDagBundle`,"Head is confusing cus in git speak it means ""what you have checked out"".  That's not what we mean here.  Here we're trying to describe the branch in the repo that the user wants this bundle to track or ""follow"".  Technically it could be a tag but that makes less sense since you shouldn't really be moving tags should you...
",dstandish,2024-12-02 23:02:49+00:00,[],2024-12-03 22:40:45+00:00,2024-12-03 22:40:43+00:00,https://github.com/apache/airflow/pull/44585,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2713530416,pull_request,closed,,"Revert ""Revert Edge Datamodelling for Pydantic problems in Py3.9""","Reverts apache/airflow#44550

This is an example test to re-apply correct Python 3.10 style Pydantic modelling to Edge Provider.... which fails in backport. Therefore we double check here... or use the tests as a check to raise a bug with Pydantic team.",jscheffl,2024-12-02 22:27:28+00:00,[],2025-01-11 19:43:50+00:00,2024-12-04 19:44:11+00:00,https://github.com/apache/airflow/pull/44584,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('include success outputs', 'Whether to include success outputs in test results'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2513319664, 'issue_id': 2713530416, 'author': 'potiuk', 'body': 'Really strange it works.', 'created_at': datetime.datetime(2024, 12, 3, 1, 8, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513332222, 'issue_id': 2713530416, 'author': 'potiuk', 'body': 'I KNOW', 'created_at': datetime.datetime(2024, 12, 3, 1, 20, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513355449, 'issue_id': 2713530416, 'author': 'potiuk', 'body': 'We need to add-back the workaround until we release and start using for backport Airflow 2.10.4. Detailed explanation in https://github.com/apache/airflow/pull/44589', 'created_at': datetime.datetime(2024, 12, 3, 1, 43, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513369679, 'issue_id': 2713530416, 'author': 'potiuk', 'body': 'I added ""include success outputs"" to see the output of what happens in the successful builds here. And If I am right, the back-compat test for 2.10.3 installs the ""eval-types-backport"" because of a fallback of not using constraints, but I need to be sure.', 'created_at': datetime.datetime(2024, 12, 3, 1, 56, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516354126, 'issue_id': 2713530416, 'author': 'jscheffl', 'body': '> We need to add-back the workaround until we release and start using for backport Airflow 2.10.4. Detailed explanation in #44589\r\n\r\nAs I see #44589 is merged - should we merge this then?\r\n\r\n(I would have waited the ""few days"" until 2.10.4 is released to clean this PR up but if the test ENV is now fixed anyway... we just need to remember that we clean it up post 2.10.4 release.', 'created_at': datetime.datetime(2024, 12, 4, 6, 57, 12, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-03 01:08:28 UTC): Really strange it works.

potiuk on (2024-12-03 01:20:04 UTC): I KNOW

potiuk on (2024-12-03 01:43:55 UTC): We need to add-back the workaround until we release and start using for backport Airflow 2.10.4. Detailed explanation in https://github.com/apache/airflow/pull/44589

potiuk on (2024-12-03 01:56:27 UTC): I added ""include success outputs"" to see the output of what happens in the successful builds here. And If I am right, the back-compat test for 2.10.3 installs the ""eval-types-backport"" because of a fallback of not using constraints, but I need to be sure.

jscheffl (Issue Creator) on (2024-12-04 06:57:12 UTC): As I see #44589 is merged - should we merge this then?

(I would have waited the ""few days"" until 2.10.4 is released to clean this PR up but if the test ENV is now fixed anyway... we just need to remember that we clean it up post 2.10.4 release.

"
2713460624,pull_request,closed,,Remove Provider Deprecations in Docker,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider **Docker**

Relates to #44559",jscheffl,2024-12-02 21:46:01+00:00,[],2024-12-02 22:53:13+00:00,2024-12-02 22:53:13+00:00,https://github.com/apache/airflow/pull/44583,"[('area:providers', ''), ('provider:docker', '')]",[],
2713402831,pull_request,closed,,Add support for a subdir in GitDagBundle,"This adds support for a `subdir` in GitDagBundle, allowing you to consume DAGs for a sub directory instead of the root of a git repo.

Why isn't this in base instead? Not every bundle will need the concept, and `path` is an abstractmethod.",jedcunningham,2024-12-02 21:14:59+00:00,[],2024-12-02 23:24:16+00:00,2024-12-02 23:24:14+00:00,https://github.com/apache/airflow/pull/44582,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2713279478,pull_request,closed,,Add missing changelog to breaking change for Standard provider breaking changes,"Follow-up of #44541

Didi I correctly understood how breaking changes are added to providers?

relates to https://github.com/apache/airflow/issues/44559",jscheffl,2024-12-02 20:31:02+00:00,[],2024-12-02 22:24:25+00:00,2024-12-02 22:24:25+00:00,https://github.com/apache/airflow/pull/44581,"[('area:providers', ''), ('provider:standard', '')]",[],
2713249291,pull_request,closed,,Add fallback during `[core] dag_bundle_storage_path` retrieval,Turns out a default of `None` doesn't actually work. And we want people to be able to use the default!,jedcunningham,2024-12-02 20:16:32+00:00,[],2024-12-02 21:15:49+00:00,2024-12-02 21:15:48+00:00,https://github.com/apache/airflow/pull/44580,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2713168046,pull_request,closed,,AIP-72: Improve handling of `deferred` state in Supervisor,"- Added `_terminal_state` in `WatchedSubprocess` to manage task final states like `deferred` directly.
- Updated `wait` method in `WatchedSubprocess` to finalize task states and call the API with the terminal states (success, failure, etc)
- Simplified the `final_state` property by removing unnecessary setter logic.
- Fixed a bug where `make_buffered_socket_reader` was using `memoryview` and `msg = decoder.validate_json(line)` expected bytes.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-02 19:36:42+00:00,[],2024-12-03 02:46:41+00:00,2024-12-02 20:23:25+00:00,https://github.com/apache/airflow/pull/44579,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2712733104,pull_request,closed,,Remove deprecated code from Airbyte provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: [#44559 ](https://github.com/apache/airflow/issues/44559)
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

---

Relates to: [#44559 ](https://github.com/apache/airflow/issues/44559)

Removed deprecated code from the `Airbyte` providers.

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ajitg25,2024-12-02 17:23:15+00:00,[],2024-12-04 20:47:28+00:00,2024-12-04 20:47:28+00:00,https://github.com/apache/airflow/pull/44577,"[('area:providers', ''), ('provider:airbyte', '')]",[],
2712728753,pull_request,closed,,Removed deprecated code from Alibaba provider package,"Relates to: https://github.com/apache/airflow/issues/44559

Removed deprecated code from the Alibaba providers.

^ Add meaningful description above
Read the [Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines) for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named {pr_number}.significant.rst or {issue_number}.significant.rst, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).

",Tushar4432,2024-12-02 17:21:11+00:00,[],2024-12-16 18:10:06+00:00,2024-12-16 18:10:02+00:00,https://github.com/apache/airflow/pull/44576,"[('area:providers', ''), ('provider:alibaba', '')]","[{'comment_id': 2512215760, 'issue_id': 2712728753, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 2, 17, 21, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530667302, 'issue_id': 2712728753, 'author': 'potiuk', 'body': ""That's the LAST one @Tushar4432 -> shall you rebase/apply the comments so that we can close #44559 🚀 ?"", 'created_at': datetime.datetime(2024, 12, 10, 7, 32, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546312863, 'issue_id': 2712728753, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 16, 18, 10, 5, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-02 17:21:16 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-10 07:32:29 UTC): That's the LAST one @Tushar4432 -> shall you rebase/apply the comments so that we can close #44559 🚀 ?

boring-cyborg[bot] on (2024-12-16 18:10:05 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2712699327,pull_request,closed,,Remove provider deprecations in Apache Drill,"Relates to #44559.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-12-02 17:09:56+00:00,[],2024-12-09 20:33:48+00:00,2024-12-09 08:40:13+00:00,https://github.com/apache/airflow/pull/44575,"[('area:providers', ''), ('provider:apache-drill', '')]",[],
2712693670,pull_request,closed,,Versionless bundles return None vs raising,,jedcunningham,2024-12-02 17:07:36+00:00,[],2024-12-02 19:34:19+00:00,2024-12-02 19:34:18+00:00,https://github.com/apache/airflow/pull/44574,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2712556849,pull_request,closed,,[v2-10-test] Update XCom docs around containers/helm (#44570),"This removes the whole section about helm, as it really isn't directly related to the XCom concept at all. I also simplified the section about containers as well - this one is a bit more practical, so I've left it.
(cherry picked from commit 3747c91afdcd0470ca29e911c589b334b357b778)

Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>",github-actions[bot],2024-12-02 16:37:20+00:00,[],2024-12-04 08:47:51+00:00,2024-12-02 16:42:40+00:00,https://github.com/apache/airflow/pull/44573,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2712499736,pull_request,closed,,AIP-38 Plug Graph on backend endpoint,"This is just the rewiring. A follow up PR will take care of cleaning the types and simplify the interface. There are a lot of type casting, undefined / null check everywhere. I think we can simplify this.

![Screenshot 2024-12-02 at 18 02 32](https://github.com/user-attachments/assets/e130ed1f-c3c9-40d0-822f-5fad2d61cb3d)
![Screenshot 2024-12-02 at 18 02 53](https://github.com/user-attachments/assets/e1afd18a-5b48-4556-b25f-2bc7e663e511)


",pierrejeambrun,2024-12-02 16:18:09+00:00,['pierrejeambrun'],2024-12-04 15:02:56+00:00,2024-12-04 15:02:53+00:00,https://github.com/apache/airflow/pull/44572,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application'), ('area:task-sdk', None)]","[{'comment_id': 2513532882, 'issue_id': 2712499736, 'author': 'tirkarthi', 'body': ""Thanks for the PR, I was also working on the same thing yesterday but couldn't fix linters and typescript issues as a draft PR. Many of them were related to undefined vs null checks and the structure used in `./data` file being different compared to the API response causing type incompatibility.\r\n\r\nhttps://github.com/tirkarthi/airflow/commit/e444d8459c70c1349271fa3b91d5d129480dc564"", 'created_at': datetime.datetime(2024, 12, 3, 4, 36, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513533987, 'issue_id': 2712499736, 'author': 'tirkarthi', 'body': 'Related issue for tracking https://github.com/apache/airflow/issues/44200', 'created_at': datetime.datetime(2024, 12, 3, 4, 37, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513540866, 'issue_id': 2712499736, 'author': 'tirkarthi', 'body': 'I also remember seeing some errors in backend from pydantic where `rx` and `ry` were missing. Sample example dag example_setup_teardown had the issue.', 'created_at': datetime.datetime(2024, 12, 3, 4, 44, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514016258, 'issue_id': 2712499736, 'author': 'pierrejeambrun', 'body': 'Yes, one of the issue we have is that I am not aware yet of a way to have a datamodel generates something like:\r\n\r\n```python\r\n{\r\n    field?: string\r\n}\r\n```\r\n\r\ni.e have the field `optional/can be missing from the payload` (`?:`), but has no default value / not nullable...\r\n\r\nInstead we currently have:\r\n```python\r\n{\r\n    field?: string | null\r\n}\r\n```', 'created_at': datetime.datetime(2024, 12, 3, 9, 42, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514106717, 'issue_id': 2712499736, 'author': 'pierrejeambrun', 'body': '> I also remember seeing some errors in backend from pydantic where rx and ry were missing. Sample example dag example_setup_teardown had the issue.\r\n\r\nBoth setup and teardown example dags (`example_setup_teardown` and `example_setup_teardown_taskflow`) seem to render properly (things have been updated since you last tried, especially the API side):\r\n![Screenshot 2024-12-03 at 11 09 18](https://github.com/user-attachments/assets/13e3ed18-40ff-4cd6-9284-b70cf5a08e31)\r\n![Screenshot 2024-12-03 at 11 09 36](https://github.com/user-attachments/assets/54cbfc2f-8ec0-406e-8bfd-34c8e086ef4b)', 'created_at': datetime.datetime(2024, 12, 3, 10, 9, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514494899, 'issue_id': 2712499736, 'author': 'tirkarthi', 'body': '> Both setup and teardown example dags (`example_setup_teardown` and `example_setup_teardown_taskflow`) seem to render properly (things have been updated since you last tried, especially the API side): \r\n\r\nThanks for validating. I rebased my branch with latest main and now it\'s working fine as expected. Probably fixed as part of #44459 . Below was the old traceback,\r\n\r\n```\r\n  File ""/home/karthikeyan/stuff/python/airflow/airflow/api_fastapi/core_api/routes/ui/graph.py"", line 60, in graph_data\r\n    return GraphDataResponse(**data)\r\n  File ""/home/karthikeyan/stuff/python/airflow/.env/lib/python3.10/site-packages/pydantic/main.py"", line 214, in __init__\r\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\r\npydantic_core._pydantic_core.ValidationError: 2 validation errors for GraphDataResponse\r\nnodes.children.3.children.3.value.rx\r\n  Field required [type=missing, input_value={\'label\': \'\', \'labelStyle...ue;\', \'shape\': \'circle\'}, input_type=dict]\r\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\r\nnodes.children.3.children.3.value.ry\r\n  Field required [type=missing, input_value={\'label\': \'\', \'labelStyle...ue;\', \'shape\': \'circle\'}, input_type=dict]\r\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\r\n```', 'created_at': datetime.datetime(2024, 12, 3, 12, 58, 46, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-12-03 04:36:33 UTC): Thanks for the PR, I was also working on the same thing yesterday but couldn't fix linters and typescript issues as a draft PR. Many of them were related to undefined vs null checks and the structure used in `./data` file being different compared to the API response causing type incompatibility.

https://github.com/tirkarthi/airflow/commit/e444d8459c70c1349271fa3b91d5d129480dc564

tirkarthi on (2024-12-03 04:37:43 UTC): Related issue for tracking https://github.com/apache/airflow/issues/44200

tirkarthi on (2024-12-03 04:44:51 UTC): I also remember seeing some errors in backend from pydantic where `rx` and `ry` were missing. Sample example dag example_setup_teardown had the issue.

pierrejeambrun (Issue Creator) on (2024-12-03 09:42:30 UTC): Yes, one of the issue we have is that I am not aware yet of a way to have a datamodel generates something like:

```python
{
    field?: string
}
```

i.e have the field `optional/can be missing from the payload` (`?:`), but has no default value / not nullable...

Instead we currently have:
```python
{
    field?: string | null
}
```

pierrejeambrun (Issue Creator) on (2024-12-03 10:09:57 UTC): Both setup and teardown example dags (`example_setup_teardown` and `example_setup_teardown_taskflow`) seem to render properly (things have been updated since you last tried, especially the API side):
![Screenshot 2024-12-03 at 11 09 18](https://github.com/user-attachments/assets/13e3ed18-40ff-4cd6-9284-b70cf5a08e31)
![Screenshot 2024-12-03 at 11 09 36](https://github.com/user-attachments/assets/54cbfc2f-8ec0-406e-8bfd-34c8e086ef4b)

tirkarthi on (2024-12-03 12:58:46 UTC): Thanks for validating. I rebased my branch with latest main and now it's working fine as expected. Probably fixed as part of #44459 . Below was the old traceback,

```
  File ""/home/karthikeyan/stuff/python/airflow/airflow/api_fastapi/core_api/routes/ui/graph.py"", line 60, in graph_data
    return GraphDataResponse(**data)
  File ""/home/karthikeyan/stuff/python/airflow/.env/lib/python3.10/site-packages/pydantic/main.py"", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 2 validation errors for GraphDataResponse
nodes.children.3.children.3.value.rx
  Field required [type=missing, input_value={'label': '', 'labelStyle...ue;', 'shape': 'circle'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
nodes.children.3.children.3.value.ry
  Field required [type=missing, input_value={'label': '', 'labelStyle...ue;', 'shape': 'circle'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/missing
```

"
2712300546,pull_request,closed,,Update XCom docs around containers/helm,"This removes the whole section about helm, as it really isn't directly related to the XCom concept at all. I also simplified the section about containers as well - this one is a bit more practical, so I've left it.",jedcunningham,2024-12-02 15:19:57+00:00,[],2024-12-02 16:37:26+00:00,2024-12-02 16:33:57+00:00,https://github.com/apache/airflow/pull/44570,"[('kind:documentation', '')]","[{'comment_id': 2512078947, 'issue_id': 2712300546, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44573""><img src=""https://img.shields.io/badge/PR-44573-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 2, 16, 37, 24, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-02 16:37:24 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44573""><img src=""https://img.shields.io/badge/PR-44573-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2712286533,pull_request,closed,,New Kubernetes Kueue Operators,"- implement new operators: `KubernetesInstallKueueOperator`, `KubernetesStartKueueJobOperator` in `cncf-kubernetes` provider
- refactor GKE operators in `google` provider in order to reduce complexity and code duplication
",moiseenkov,2024-12-02 15:14:28+00:00,[],2024-12-11 13:13:42+00:00,2024-12-11 13:13:42+00:00,https://github.com/apache/airflow/pull/44568,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2517821458, 'issue_id': 2712286533, 'author': 'moiseenkov', 'body': ""@eladkal , @potiuk,\r\n \r\nThis PR contains changes for both Google and cncf-kubernetes providers, and the Google provider depends on changes in cncf-kuberneets. For this reason I had to bump cncf-kubernetes version in Google provider's [dependencies](https://github.com/apache/airflow/pull/44568/files#diff-bfccba1ff8b4b3e462131ef3d0869d7760d64a2f3b6f1a15b89157a4c7d68404L191) and it now breaks CI because it can't install cncf-kubernetes provider that wasn't released yet.\r\nTherefore, should I split this PR, so we could release these changes gradually (cncf first, and google later) or we are OK with merging it all together now."", 'created_at': datetime.datetime(2024, 12, 4, 15, 43, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522646768, 'issue_id': 2712286533, 'author': 'potiuk', 'body': '> @eladkal , @potiuk,\r\n> \r\n> This PR contains changes for both Google and cncf-kubernetes providers, and the Google provider depends on changes in cncf-kuberneets. For this reason I had to bump cncf-kubernetes version in Google provider\'s [dependencies](https://github.com/apache/airflow/pull/44568/files#diff-bfccba1ff8b4b3e462131ef3d0869d7760d64a2f3b6f1a15b89157a4c7d68404L191) and it now breaks CI because it can\'t install cncf-kubernetes provider that wasn\'t released yet. Therefore, should I split this PR, so we could release these changes gradually (cncf first, and google later) or we are OK with merging it all together now.\r\n\r\nThis is one option yes. There is another option. You can add the `cncf.kubernetes` provider to the list of ""chicken-egg"" providers in `src/airflow_breeze/global_constants.py` ->  similarly to what I\'ve done in https://github.com/apache/airflow/pull/44714 (about to be merged).', 'created_at': datetime.datetime(2024, 12, 6, 9, 34, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522694789, 'issue_id': 2712286533, 'author': 'potiuk', 'body': 'Also updated documentation about it here https://github.com/apache/airflow/pull/44720', 'created_at': datetime.datetime(2024, 12, 6, 9, 52, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522777142, 'issue_id': 2712286533, 'author': 'eladkal', 'body': '> > @eladkal , @potiuk,\r\n> > This PR contains changes for both Google and cncf-kubernetes providers, and the Google provider depends on changes in cncf-kuberneets. For this reason I had to bump cncf-kubernetes version in Google provider\'s [dependencies](https://github.com/apache/airflow/pull/44568/files#diff-bfccba1ff8b4b3e462131ef3d0869d7760d64a2f3b6f1a15b89157a4c7d68404L191) and it now breaks CI because it can\'t install cncf-kubernetes provider that wasn\'t released yet. Therefore, should I split this PR, so we could release these changes gradually (cncf first, and google later) or we are OK with merging it all together now.\r\n> \r\n> This is one option yes. There is another option. You can add the `cncf.kubernetes` provider to the list of ""chicken-egg"" providers in `src/airflow_breeze/global_constants.py` -> similarly to what I\'ve done in #44714 (about to be merged).\r\n\r\n\r\nWhy not just using `AirflowOptionalProviderFeatureException`?', 'created_at': datetime.datetime(2024, 12, 6, 10, 34, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2522918768, 'issue_id': 2712286533, 'author': 'moiseenkov', 'body': '> This is one option yes. There is another option. You can add the `cncf.kubernetes` provider to the list of ""chicken-egg"" providers in `src/airflow_breeze/global_constants.py` -> similarly to what I\'ve done in #44714 (about to be merged).\r\n\r\n@potiuk , thank you for the suggestion! I followed this idea. But it seems to me that the new version of Kubernetes provider should be announced in provider.yaml anyway... I can update my PR once it happens.\r\n\r\n> Why not just using AirflowOptionalProviderFeatureException?\r\n\r\nI\'ve also considered this, but unfortunately provided changes aren\'t optional. For example the `GKEStartKueueInsideClusterOperator` now inherits from `KubernetesInstallKueueOperator` which was introduced in this PR. At the same time the `GKEStartKueueInsideClusterOperator` is a bit older and will be broken if the Kubernetes provider isn\'t upgraded. Thus I had to bump the cncf-kubernetes provider version in google provider\'s dependencies.', 'created_at': datetime.datetime(2024, 12, 6, 11, 12, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2523459474, 'issue_id': 2712286533, 'author': 'potiuk', 'body': 'Tests failing - breeze (easier to fix) and compatibility tests with airflow 2.8 - 2.9 (a bit more difficult). The way how to run compatibilty test is described in detail in https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#compatibility-provider-unit-tests-against-older-airflow-releases - with some examples how to deal with the tests.', 'created_at': datetime.datetime(2024, 12, 6, 15, 10, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535376231, 'issue_id': 2712286533, 'author': 'moiseenkov', 'body': 'Hi @potiuk ,\r\nThe CI is finally green. Thank you very much for your guidance!\r\nThe PR is ready for review and merging hopefully.', 'created_at': datetime.datetime(2024, 12, 11, 10, 3, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535957319, 'issue_id': 2712286533, 'author': 'potiuk', 'body': 'Cool. The good things that all deprecations have been removed already in the previous wave - so we will not have another bump in k8s provider MAJOR version, so this one is good to go.', 'created_at': datetime.datetime(2024, 12, 11, 13, 13, 37, tzinfo=datetime.timezone.utc)}]","moiseenkov (Issue Creator) on (2024-12-04 15:43:37 UTC): @eladkal , @potiuk,
 
This PR contains changes for both Google and cncf-kubernetes providers, and the Google provider depends on changes in cncf-kuberneets. For this reason I had to bump cncf-kubernetes version in Google provider's [dependencies](https://github.com/apache/airflow/pull/44568/files#diff-bfccba1ff8b4b3e462131ef3d0869d7760d64a2f3b6f1a15b89157a4c7d68404L191) and it now breaks CI because it can't install cncf-kubernetes provider that wasn't released yet.
Therefore, should I split this PR, so we could release these changes gradually (cncf first, and google later) or we are OK with merging it all together now.

potiuk on (2024-12-06 09:34:31 UTC): This is one option yes. There is another option. You can add the `cncf.kubernetes` provider to the list of ""chicken-egg"" providers in `src/airflow_breeze/global_constants.py` ->  similarly to what I've done in https://github.com/apache/airflow/pull/44714 (about to be merged).

potiuk on (2024-12-06 09:52:37 UTC): Also updated documentation about it here https://github.com/apache/airflow/pull/44720

eladkal on (2024-12-06 10:34:31 UTC): Why not just using `AirflowOptionalProviderFeatureException`?

moiseenkov (Issue Creator) on (2024-12-06 11:12:12 UTC): @potiuk , thank you for the suggestion! I followed this idea. But it seems to me that the new version of Kubernetes provider should be announced in provider.yaml anyway... I can update my PR once it happens.


I've also considered this, but unfortunately provided changes aren't optional. For example the `GKEStartKueueInsideClusterOperator` now inherits from `KubernetesInstallKueueOperator` which was introduced in this PR. At the same time the `GKEStartKueueInsideClusterOperator` is a bit older and will be broken if the Kubernetes provider isn't upgraded. Thus I had to bump the cncf-kubernetes provider version in google provider's dependencies.

potiuk on (2024-12-06 15:10:11 UTC): Tests failing - breeze (easier to fix) and compatibility tests with airflow 2.8 - 2.9 (a bit more difficult). The way how to run compatibilty test is described in detail in https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#compatibility-provider-unit-tests-against-older-airflow-releases - with some examples how to deal with the tests.

moiseenkov (Issue Creator) on (2024-12-11 10:03:21 UTC): Hi @potiuk ,
The CI is finally green. Thank you very much for your guidance!
The PR is ready for review and merging hopefully.

potiuk on (2024-12-11 13:13:37 UTC): Cool. The good things that all deprecations have been removed already in the previous wave - so we will not have another bump in k8s provider MAJOR version, so this one is good to go.

"
2712103194,pull_request,closed,,Remove deprecated code from apache spark provider,"Relates to #44559. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-12-02 14:24:33+00:00,[],2024-12-06 07:10:26+00:00,2024-12-06 07:10:26+00:00,https://github.com/apache/airflow/pull/44567,"[('area:providers', ''), ('provider:apache-spark', '')]",[],
2711648728,pull_request,closed,,Remove deprecations from Databricks Provider,"related: https://github.com/apache/airflow/issues/44559





<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-02 11:40:38+00:00,[],2024-12-04 20:44:59+00:00,2024-12-04 20:44:59+00:00,https://github.com/apache/airflow/pull/44566,"[('area:providers', ''), ('provider:databricks', '')]",[],
2711557637,pull_request,closed,,Add host_proxy_cmd parameter to SSHHook and SFTPHook,"
closes: [#43636](https://github.com/apache/airflow/issues/43636)

Added the `host_proxy_cmd` parameter to `SSHHook` and `SFTPHook`.
Added unit tests to validate the changes in `SSHHook` and `SFTPHook`.
",ajitg25,2024-12-02 11:20:01+00:00,[],2024-12-03 10:22:31+00:00,2024-12-03 10:22:27+00:00,https://github.com/apache/airflow/pull/44565,"[('area:providers', ''), ('provider:ssh', ''), ('provider:sftp', '')]","[{'comment_id': 2511261712, 'issue_id': 2711557637, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 2, 11, 20, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513222378, 'issue_id': 2711557637, 'author': 'potiuk', 'body': 'LGTM', 'created_at': datetime.datetime(2024, 12, 2, 23, 57, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513237087, 'issue_id': 2711557637, 'author': 'potiuk', 'body': 'Tests need to be fixed @ajitg25 - apparently those tests depend on ncat being available in the environment, and we should not rely on it.', 'created_at': datetime.datetime(2024, 12, 3, 0, 10, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513457822, 'issue_id': 2711557637, 'author': 'ajitg25', 'body': '> Tests need to be fixed @ajitg25 - apparently those tests depend on ncat being available in the environment, and we should not rely on it.\r\n\r\n@potiuk Apologies, it was a miss from my side. Now, I have fixed the unit test cases in both files. PTAL!!\r\n\r\ntest_ssh\r\n<img width=""1109"" alt=""Screenshot 2024-12-03 at 8 31 33\u202fAM"" src=""https://github.com/user-attachments/assets/596fda4b-ae36-4d08-9b48-c31b9b2e8e4d"">\r\n\r\ntest_sftp\r\n![WhatsApp Image 2024-12-03 at 08 39 54](https://github.com/user-attachments/assets/f80d9c71-51ab-4173-8c2b-251b05cd43cd)', 'created_at': datetime.datetime(2024, 12, 3, 3, 14, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514135018, 'issue_id': 2711557637, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 3, 10, 22, 30, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-02 11:20:06 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-02 23:57:12 UTC): LGTM

potiuk on (2024-12-03 00:10:19 UTC): Tests need to be fixed @ajitg25 - apparently those tests depend on ncat being available in the environment, and we should not rely on it.

ajitg25 (Issue Creator) on (2024-12-03 03:14:10 UTC): @potiuk Apologies, it was a miss from my side. Now, I have fixed the unit test cases in both files. PTAL!!

test_ssh
<img width=""1109"" alt=""Screenshot 2024-12-03 at 8 31 33 AM"" src=""https://github.com/user-attachments/assets/596fda4b-ae36-4d08-9b48-c31b9b2e8e4d"">

test_sftp
![WhatsApp Image 2024-12-03 at 08 39 54](https://github.com/user-attachments/assets/f80d9c71-51ab-4173-8c2b-251b05cd43cd)

boring-cyborg[bot] on (2024-12-03 10:22:30 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2711351796,pull_request,open,,Add service account impersonation with Cloud SQL Proxy and version co…,"Closes: #39546

## Add service account impersonation with Cloud SQL Proxy and version compatibility

### **Summary of Changes:**
* Added service account impersonation support for Cloud SQL Proxy operations

 1. Single service account impersonation via impersonation_chain parameter
 2. Service account chain impersonation for delegated access
 3. Proper credential parameter handling and validation
 
* Updated Cloud SQL Proxy version support
 1. Added v2 parameter format support (--impersonate-service-account)
 2. Maintained v1 backward compatibility (-impersonate-service-account)
 3. Added version detection and parameter format handling
 
**Testing and Validation:** 
1. Added unit tests for CloudSQLCreateInstanceOperator with impersonation 
2. Added tests for CloudSqlProxyRunner parameter handling 
3. Added version-specific command line parameter tests 
4. Added impersonation chain validation tests 
5. All tests passing under providers/tests/google/cloud/hooks/test_cloud_sql.py & providers/tests/google/cloud/operators/test_cloud_sql.py

**Documentation Updates:** 
1. Updated class docstrings with impersonation details 
2. Added version compatibility information 
3. Added usage examples for both single SA and chain impersonation

**Use Case:** 

Enables teams in shared Google Cloud Composer environments to access Cloud SQL databases through project-specific service accounts via impersonation, similar to other Google Cloud operators. 

Issue Reference: Closes #39546 

**Example Usage:** 

```python 

# Using v2 with single service account 

runner = CloudSqlProxyRunner( path_prefix=""test"", instance_specification=""proj:region:instance"", impersonation_chain=""sa@project.iam"", sql_proxy_version=""v2.0.0"" ) 

# Using v1 with impersonation chain 

runner = CloudSqlProxyRunner( path_prefix=""test"", instance_specification=""proj:region:instance"", impersonation_chain=[""sa1@proj.iam"", ""sa2@proj.iam""], sql_proxy_version=""v1.0.0"" ) 


",jasonmar310,2024-12-02 10:15:42+00:00,[],2025-02-01 12:18:31+00:00,,https://github.com/apache/airflow/pull/44564,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2511115096, 'issue_id': 2711351796, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 2, 10, 15, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511186254, 'issue_id': 2711351796, 'author': 'potiuk', 'body': 'cc: @VladaZakharova -> maybe you can take a look as well?', 'created_at': datetime.datetime(2024, 12, 2, 10, 45, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513148244, 'issue_id': 2711351796, 'author': 'jasonmar310', 'body': 'Hi! Please disregard this merge attempt ""cc2f73c"". I accidentally clicked the update branch before the review was complete. Thanks!', 'created_at': datetime.datetime(2024, 12, 2, 22, 54, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513384100, 'issue_id': 2711351796, 'author': 'p13rr0m', 'body': '1. The CloudSQLExecuteQueryOperator is not yet offering the impersonation_chain parameter.\r\n\r\nhttps://github.com/apache/airflow/blob/a242ff6edb51db6e8ac1ced72b5bf327dd98c1b4/providers/src/airflow/providers/google/cloud/operators/cloud_sql.py#L1290\r\n\r\n\r\n2. The download mechanism currently supports only CloudSQL Proxies with versions below 2. Updating this method and always downloading the latest version by default could introduce backward compatibility issues, such as conflicts with user-specified command line parameters.\r\n\r\nhttps://github.com/apache/airflow/blob/cc2f73c934526a13decee02db88a93561560b4fa/providers/src/airflow/providers/google/cloud/hooks/cloud_sql.py#L595\r\n\r\n3. Ruff tells me there are some blank lines that contain whitespaces.\r\n4. It looks like there a some merge commits in the PR. I believe Airflow recommends to use rebase commits.', 'created_at': datetime.datetime(2024, 12, 3, 2, 8, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513424079, 'issue_id': 2711351796, 'author': 'jasonmar310', 'body': ""Hi @p13rr0m! Thanks for the detailed review. As this is my first PR to Airflow, I really appreciate your thorough feedback!\r\n\r\n1. You're right - I'll add the `impersonation_chain` parameter to the CloudSQLExecuteQueryOperator.\r\n2. Good catch on the proxy version handling - I'll update it to maintain backward compatibility by default while properly supporting v2.\r\nFor 3,4 I'll clean up and rebase the commits to follow Airflow's guidelines.\r\n\r\nI'll push these updates shortly. Thanks for helping me improve this implementation!"", 'created_at': datetime.datetime(2024, 12, 3, 2, 42, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582842501, 'issue_id': 2711351796, 'author': 'MaksYermak', 'body': 'Hi @jasonmar310 !\r\nCould you please share the status of this PR? Are you planning to finish the implementation?', 'created_at': datetime.datetime(2025, 1, 10, 14, 31, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585477860, 'issue_id': 2711351796, 'author': 'jasonmar310', 'body': ""Hi! @MaksYermak,\r\n\r\nThanks for checking in. I'm still working through some implementation challenges with this PR. Feel free to take it over if needed, or I'll continue working on it and update soon. Sorry for the delay!"", 'created_at': datetime.datetime(2025, 1, 11, 23, 27, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589606116, 'issue_id': 2711351796, 'author': 'VladaZakharova', 'body': ""> Hi! @MaksYermak,\r\n> \r\n> Thanks for checking in. I'm still working through some implementation challenges with this PR. Feel free to take it over if needed, or I'll continue working on it and update soon. Sorry for the delay!\r\n\r\nHi! Thank you for contribution, we will wait for your implementation and then review it"", 'created_at': datetime.datetime(2025, 1, 14, 10, 56, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2628930476, 'issue_id': 2711351796, 'author': 'potiuk', 'body': 'We are moving Google to the new provider structure, so you will have to rebase your PR and adapt to moved files.', 'created_at': datetime.datetime(2025, 2, 1, 12, 18, 30, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-02 10:15:48 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-02 10:45:52 UTC): cc: @VladaZakharova -> maybe you can take a look as well?

jasonmar310 (Issue Creator) on (2024-12-02 22:54:01 UTC): Hi! Please disregard this merge attempt ""cc2f73c"". I accidentally clicked the update branch before the review was complete. Thanks!

p13rr0m on (2024-12-03 02:08:20 UTC): 1. The CloudSQLExecuteQueryOperator is not yet offering the impersonation_chain parameter.

https://github.com/apache/airflow/blob/a242ff6edb51db6e8ac1ced72b5bf327dd98c1b4/providers/src/airflow/providers/google/cloud/operators/cloud_sql.py#L1290


2. The download mechanism currently supports only CloudSQL Proxies with versions below 2. Updating this method and always downloading the latest version by default could introduce backward compatibility issues, such as conflicts with user-specified command line parameters.

https://github.com/apache/airflow/blob/cc2f73c934526a13decee02db88a93561560b4fa/providers/src/airflow/providers/google/cloud/hooks/cloud_sql.py#L595

3. Ruff tells me there are some blank lines that contain whitespaces.
4. It looks like there a some merge commits in the PR. I believe Airflow recommends to use rebase commits.

jasonmar310 (Issue Creator) on (2024-12-03 02:42:48 UTC): Hi @p13rr0m! Thanks for the detailed review. As this is my first PR to Airflow, I really appreciate your thorough feedback!

1. You're right - I'll add the `impersonation_chain` parameter to the CloudSQLExecuteQueryOperator.
2. Good catch on the proxy version handling - I'll update it to maintain backward compatibility by default while properly supporting v2.
For 3,4 I'll clean up and rebase the commits to follow Airflow's guidelines.

I'll push these updates shortly. Thanks for helping me improve this implementation!

MaksYermak on (2025-01-10 14:31:11 UTC): Hi @jasonmar310 !
Could you please share the status of this PR? Are you planning to finish the implementation?

jasonmar310 (Issue Creator) on (2025-01-11 23:27:20 UTC): Hi! @MaksYermak,

Thanks for checking in. I'm still working through some implementation challenges with this PR. Feel free to take it over if needed, or I'll continue working on it and update soon. Sorry for the delay!

VladaZakharova on (2025-01-14 10:56:06 UTC): Hi! Thank you for contribution, we will wait for your implementation and then review it

potiuk on (2025-02-01 12:18:30 UTC): We are moving Google to the new provider structure, so you will have to rebase your PR and adapt to moved files.

"
2711345225,pull_request,closed,,Avoid lambda assignments,"Just a warning Ruff picked up. We don't enable this, but it's good practice anyway and has no downsides.

https://docs.astral.sh/ruff/rules/lambda-assignment/",uranusjr,2024-12-02 10:13:07+00:00,[],2024-12-02 12:39:36+00:00,2024-12-02 12:39:34+00:00,https://github.com/apache/airflow/pull/44563,"[('area:serialization', '')]",[],
2711162555,pull_request,closed,,AIP-72: Adding support to Set an Airflow Variable from Task SDK,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/44358

Adding support to be able to put/create a variable from the task sdk side.

### Brief of changes:

#### Supervisor
1. The supervisor would receive a request from the task runner to CREATE / PUT a variable.
2. The `handle_request` method handles this part and is responsible to send a request to the API client to send it to the tas execution interface.
3. In this case, `PutVariable` is the body that will be passed down to the api client.

#### API Client
1. The client receives a request from the supervisor to CREATE / PUT a variable. The client then sends it to the task execution interface over HTTP. It send a put request with the received body. The key isn't stripped off but is sent in the payload even though the server doesn't serialise it.
2. The client receives a response `{""message"": ""Variable successfully set""}` if all's good.
3. It passes this response back down to the supervisor which then writes it in the buffer.

### Testing
1. Since end to end isn't possible, the test case https://github.com/apache/airflow/compare/main...astronomer:airflow:AIP72-set-variable-task-sdk?expand=1#diff-f55b9ba6be46de22b2838085bf1e0aa4193797c3ff7d0cdc4e06a626c96df1baR693-R704 checks for supervisor side of things, if supervisor processes ""request"" of correct format correctly. Checks for call args, responses, even buffer.
2. The test https://github.com/apache/airflow/compare/main...astronomer:airflow:AIP72-set-variable-task-sdk?expand=1#diff-048659c5ed2897cd0ed24a340885d5950c964ea451ccc359e1ab592bf8a59f0dR138-R154 checks if the client can handle requests of type `PutVariable` properly and respond accordingly.



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-02 09:17:37+00:00,['amoghrajesh'],2024-12-05 07:29:38+00:00,2024-12-05 07:29:36+00:00,https://github.com/apache/airflow/pull/44562,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2711043696,pull_request,closed,,Add mTLS support to WebHDFSHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adds support for mutual TLS authentication in WebHDFSHook by allowing users to configure client certificates through connection extras.

Users can now specify either:
- Separate certificate and key files using `cert` and `key` parameters
- A combined certificate file using just the `cert` parameter

Added simple tests and updated documentation.

<!-- Please keep an empty line above the dashes. -->
---
",markhatch,2024-12-02 08:47:06+00:00,[],2024-12-02 23:55:08+00:00,2024-12-02 23:55:08+00:00,https://github.com/apache/airflow/pull/44561,"[('area:providers', ''), ('kind:documentation', ''), ('provider:apache-hdfs', '')]","[{'comment_id': 2511191131, 'issue_id': 2711043696, 'author': 'potiuk', 'body': 'Looks good, but some static checks failed. I recommend installing pre-commit, rebasing and running `breeze static-checks --only-my-changes` before re-submitting', 'created_at': datetime.datetime(2024, 12, 2, 10, 47, 57, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-02 10:47:57 UTC): Looks good, but some static checks failed. I recommend installing pre-commit, rebasing and running `breeze static-checks --only-my-changes` before re-submitting

"
2711043550,pull_request,closed,,Small refactoring of example_cloud_sql_iam and example_composer system tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-12-02 08:47:04+00:00,[],2024-12-02 23:55:47+00:00,2024-12-02 23:55:47+00:00,https://github.com/apache/airflow/pull/44560,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2511048020, 'issue_id': 2711043550, 'author': 'potiuk', 'body': 'small pre-commit issue :).', 'created_at': datetime.datetime(2024, 12, 2, 9, 47, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511058587, 'issue_id': 2711043550, 'author': 'VladaZakharova', 'body': '> small pre-commit issue :).\r\n\r\n![image](https://github.com/user-attachments/assets/138a0dc4-b8f1-409a-8875-5a5000f225bc)', 'created_at': datetime.datetime(2024, 12, 2, 9, 52, 26, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-02 09:47:48 UTC): small pre-commit issue :).

VladaZakharova (Issue Creator) on (2024-12-02 09:52:26 UTC): ![image](https://github.com/user-attachments/assets/138a0dc4-b8f1-409a-8875-5a5000f225bc)

"
2710910969,pull_request,closed,,Add 'airflow assets materialize',"Next one for https://github.com/apache/airflow/issues/42317.

The command is designed for ""given an asset, do what you need to do to make it emit an event"". The procedure is

1. Find a DAG that has a task that defines the asset as outlet.
2. Trigger that DAG.
3. Return the scheduled DAG run.

Currently we error out if more than one DAG defines the asset as outlet. This is arguably bad practice anyway, but this may make some sense if the DAGs have dependency between them? We'll figure this out when someone thinks of a use case.

I have some doubts returning a DAG run from this. Intuitively we should have more of a distinction? There's no good alternative though; the closest thing we have related to assets is AssetEvent, but that does not get created *after* the DAG run finishes, and we don't want to block until then. DAG run is the only reasonable thing to return here. I guess we could wrap it? We still have a chance to change it before 3.0 is released.

Also, I needed to add a bunch of session management to trigger_dag so the same session is passed down correctly. Previously, trigger_dag always create a DagRun object detached to a session because it creates its own session that only lives inside the function. This causes an issue when we serialize it into a Pydantic model since it can no longer access the related fields.",uranusjr,2024-12-02 07:43:47+00:00,[],2024-12-03 07:13:23+00:00,2024-12-03 07:13:22+00:00,https://github.com/apache/airflow/pull/44558,"[('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('AIP-75', 'Asset-Centric Syntax')]",[],
2710778070,pull_request,open,,Deferrable HttpSensor does not move to Triggerer when using response_check,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Closes: https://github.com/apache/airflow/issues/40209

DAG Code:
<img width=""691"" alt=""image"" src=""https://github.com/user-attachments/assets/0e1091f1-55b9-4289-b000-e2110a5cb2c9"">

Task going to Deferrable mode:
<img width=""1483"" alt=""image"" src=""https://github.com/user-attachments/assets/89c8bd8e-286a-4033-bda2-e33be64cae1d"">

Output of the task:
<img width=""1486"" alt=""image"" src=""https://github.com/user-attachments/assets/75919a53-11bf-4099-b173-60ed8ad65daa"">


<!-- Please keep an empty line above the dashes. -->
---

",kandharvishnu,2024-12-02 06:56:31+00:00,[],2025-01-14 02:46:20+00:00,,https://github.com/apache/airflow/pull/44557,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2563624817, 'issue_id': 2710778070, 'author': 'subbota19', 'body': 'Hi @kandharvishnu !\r\nIs there anything that needs to be added to move it forward?', 'created_at': datetime.datetime(2024, 12, 27, 11, 55, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573469836, 'issue_id': 2710778070, 'author': 'kandharvishnu', 'body': '> Hi @kandharvishnu ! Is there anything that needs to be added to move it forward?\r\n\r\ntest cases were pending and completed them now', 'created_at': datetime.datetime(2025, 1, 6, 16, 32, 10, tzinfo=datetime.timezone.utc)}]","subbota19 on (2024-12-27 11:55:40 UTC): Hi @kandharvishnu !
Is there anything that needs to be added to move it forward?

kandharvishnu (Issue Creator) on (2025-01-06 16:32:10 UTC): test cases were pending and completed them now

"
2710091557,pull_request,closed,,Remove Pydanitc models introduced for AIP-44,"The Pudanic models have been used in a number of places still and we are using them also for context passing for PythonVirtualEnv and ExternaPythonOperator  - this PR removes all the models and their usages.

Closes: #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 23:41:09+00:00,[],2024-12-12 21:36:46+00:00,2024-12-12 21:36:44+00:00,https://github.com/apache/airflow/pull/44552,"[('area:serialization', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2510307818, 'issue_id': 2710091557, 'author': 'potiuk', 'body': ""It's not likely this one will be green, but it's likely it will show which parts have to be fixed because they used implicitly Pydantic Models synchronisation.\r\n\r\nBut generally speaking it is ready to take a first pass of review."", 'created_at': datetime.datetime(2024, 12, 1, 23, 42, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510318588, 'issue_id': 2710091557, 'author': 'potiuk', 'body': 'BTW. This is the last one in the #44436 series !', 'created_at': datetime.datetime(2024, 12, 2, 0, 5, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512152947, 'issue_id': 2710091557, 'author': 'dstandish', 'body': ""happy we're removing `use_pydantic_models`"", 'created_at': datetime.datetime(2024, 12, 2, 16, 55, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513304981, 'issue_id': 2710091557, 'author': 'potiuk', 'body': "">  happy we're removing use_pydantic_models\r\n\r\nYeah ... I had no time to look at the failures today ... but tomorrow 🤞 is the day :). I just feel that there will be some left-overs with the context and some TODOs to fix - it's worth to do it anyway :)"", 'created_at': datetime.datetime(2024, 12, 3, 0, 58, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526280913, 'issue_id': 2710091557, 'author': 'potiuk', 'body': 'Speaking of which.  I think we have to agree on Pydantic strategy here.\r\n\r\nThere are two reasons why this one is ""red""\r\n\r\n* as discussed before - we are passing Context in PythonVirtualenv operator to virtualenv when `use_airflow_context=True` - which is likely not good idea for Standard provider.\r\n\r\nSo far it was really a ""future"" feature - only working with Airflow 3  and in  Airflow 2 it was only working with AIP-44 enabled (which was never a production option, except a few crazy people (cc: @jscheffl ;). So we could possibly even drop it. Or we can likely serialize it using the same mechanism serialization will happen for TaskSDK (@kaxil @ashb)? What would it be? I looked at the datamodels in task_sdk and have not seen context autogenerated yet (did I look in the right place?) maybe it\'s somewhere else. \r\nSo far context was serializable with assumption that AIP-44 is enabled and the ""ORM"" objects were serialized to their Pydantic counterparts - the whole contex serialization was added here https://github.com/apache/airflow/pull/38567  by @dstandish  and it assumed all the ORM models that were part of the context were serializable (this will stop being true once we remove the `*Pydantic classes\' )\r\n\r\nWhat plans do you have for for context serialization ?\r\n\r\n* also current Fast API implementation uses DagTagPydantic as serialization layer. I am not sure if we can do it differently @pierrejeambrun but that sounds like there should be an easy way to do so?', 'created_at': datetime.datetime(2024, 12, 8, 17, 46, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530790614, 'issue_id': 2710091557, 'author': 'pierrejeambrun', 'body': ""> also current Fast API implementation uses DagTagPydantic as serialization layer. I am not sure if we can do it differently @pierrejeambrun but that sounds like there should be an easy way to do so?\r\n\r\nWe just need to copy into the `api_fastapi/core_api/datamodels` the `DagTagPydantic`. (and rename it into `DagTagResponse`, those are specific RestAPI serializers). The API has it own serializers, but this one was common so I re-used it, but I'm not sure it was even a good idea in the first place. (Now that all those are going away there's no hesitation anymore 😀)"", 'created_at': datetime.datetime(2024, 12, 10, 8, 29, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530919845, 'issue_id': 2710091557, 'author': 'potiuk', 'body': 'So from those two responses:\r\n\r\n> We haven\'t tackled context yet, but these models can be removed and we\'ll add back the ones we need in the execution SDK (some will be very different, some similar) so merge when ever you are happy with this\r\n\r\n> We just need to copy into the `api_fastapi/core_api/datamodels` the `DagTagPydantic`. (and rename it into `DagTagResponse`, those are specific RestAPI serializers). The API has it own serializers, but this one was common so I re-used it, but I\'m not sure it was even a good idea in the first place. (Now that all those are going away there\'s no hesitation anymore 😀)\r\n\r\nThanks for those answers!\r\n\r\nLet me try to complete this one then. I will leave the ""use_airflow_context"" as a feature of Python Virtualenv that only (will) work in Airflow 3 and leave to DO to add context propagation once we have it done for AIP-72. \r\n\r\nAnd we should be able to close this one.', 'created_at': datetime.datetime(2024, 12, 10, 9, 14, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539354385, 'issue_id': 2710091557, 'author': 'potiuk', 'body': 'Reopen with full-tests-needed', 'created_at': datetime.datetime(2024, 12, 12, 15, 55, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539765453, 'issue_id': 2710091557, 'author': 'potiuk', 'body': 'Ok. Looks like Pydantic classes removal is ready to merge - any last pass? I moved the DagTag to fast_api models, and added error messages/conditional tests/ left TODOs to bring `use_airflow_context` when we have serializable context for AIP-72.\r\n\r\nIf anyone want to have last pass -> feel free.', 'created_at': datetime.datetime(2024, 12, 12, 18, 46, 7, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-01 23:42:40 UTC): It's not likely this one will be green, but it's likely it will show which parts have to be fixed because they used implicitly Pydantic Models synchronisation.

But generally speaking it is ready to take a first pass of review.

potiuk (Issue Creator) on (2024-12-02 00:05:41 UTC): BTW. This is the last one in the #44436 series !

dstandish on (2024-12-02 16:55:09 UTC): happy we're removing `use_pydantic_models`

potiuk (Issue Creator) on (2024-12-03 00:58:36 UTC): Yeah ... I had no time to look at the failures today ... but tomorrow 🤞 is the day :). I just feel that there will be some left-overs with the context and some TODOs to fix - it's worth to do it anyway :)

potiuk (Issue Creator) on (2024-12-08 17:46:40 UTC): Speaking of which.  I think we have to agree on Pydantic strategy here.

There are two reasons why this one is ""red""

* as discussed before - we are passing Context in PythonVirtualenv operator to virtualenv when `use_airflow_context=True` - which is likely not good idea for Standard provider.

So far it was really a ""future"" feature - only working with Airflow 3  and in  Airflow 2 it was only working with AIP-44 enabled (which was never a production option, except a few crazy people (cc: @jscheffl ;). So we could possibly even drop it. Or we can likely serialize it using the same mechanism serialization will happen for TaskSDK (@kaxil @ashb)? What would it be? I looked at the datamodels in task_sdk and have not seen context autogenerated yet (did I look in the right place?) maybe it's somewhere else. 
So far context was serializable with assumption that AIP-44 is enabled and the ""ORM"" objects were serialized to their Pydantic counterparts - the whole contex serialization was added here https://github.com/apache/airflow/pull/38567  by @dstandish  and it assumed all the ORM models that were part of the context were serializable (this will stop being true once we remove the `*Pydantic classes' )

What plans do you have for for context serialization ?

* also current Fast API implementation uses DagTagPydantic as serialization layer. I am not sure if we can do it differently @pierrejeambrun but that sounds like there should be an easy way to do so?

pierrejeambrun on (2024-12-10 08:29:11 UTC): We just need to copy into the `api_fastapi/core_api/datamodels` the `DagTagPydantic`. (and rename it into `DagTagResponse`, those are specific RestAPI serializers). The API has it own serializers, but this one was common so I re-used it, but I'm not sure it was even a good idea in the first place. (Now that all those are going away there's no hesitation anymore 😀)

potiuk (Issue Creator) on (2024-12-10 09:14:02 UTC): So from those two responses:



Thanks for those answers!

Let me try to complete this one then. I will leave the ""use_airflow_context"" as a feature of Python Virtualenv that only (will) work in Airflow 3 and leave to DO to add context propagation once we have it done for AIP-72. 

And we should be able to close this one.

potiuk (Issue Creator) on (2024-12-12 15:55:04 UTC): Reopen with full-tests-needed

potiuk (Issue Creator) on (2024-12-12 18:46:07 UTC): Ok. Looks like Pydantic classes removal is ready to merge - any last pass? I moved the DagTag to fast_api models, and added error messages/conditional tests/ left TODOs to bring `use_airflow_context` when we have serializable context for AIP-72.

If anyone want to have last pass -> feel free.

"
2709951846,pull_request,closed,,"Remove all remnants of ""internal_api_call""","Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 22:28:44+00:00,[],2024-12-01 23:11:34+00:00,2024-12-01 23:11:32+00:00,https://github.com/apache/airflow/pull/44551,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2709940035,pull_request,closed,,Revert Edge Datamodelling for Pydantic problems in Py3.9,"Fixes broken tests on main for back-compat, e.g. in https://github.com/apache/airflow/actions/runs/12105919009/job/33751221753

Somehow in Python 3.9 even with the fixes applied from Pydantic 2.10.3 some constructs still have parsing problems in Python 3.9. This was merged previously in https://github.com/apache/airflow/pull/44433/files#diff-88d01fd8e9c200de55dff8065993cdbdac3ff23cfcc2d4d01b0680a0a2f53f6dR60

FYI @kaxil ",jscheffl,2024-12-01 22:09:28+00:00,[],2024-12-01 23:38:01+00:00,2024-12-01 23:38:01+00:00,https://github.com/apache/airflow/pull/44550,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2510276330, 'issue_id': 2709940035, 'author': 'jscheffl', 'body': 'Good idea with the full tests! Then we see if I missed something...', 'created_at': datetime.datetime(2024, 12, 1, 22, 19, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510276526, 'issue_id': 2709940035, 'author': 'potiuk', 'body': 'Added `full tests needed` and `all versions` - to test for all versions of python/k8s/airlflow back-compatibility tetss', 'created_at': datetime.datetime(2024, 12, 1, 22, 19, 43, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-01 22:19:17 UTC): Good idea with the full tests! Then we see if I missed something...

potiuk on (2024-12-01 22:19:43 UTC): Added `full tests needed` and `all versions` - to test for all versions of python/k8s/airlflow back-compatibility tetss

"
2709864877,pull_request,closed,,Removes AIP-44 from dag processing manager and internal_api_call,"This is the last ""internal_api_call"" change from AIP-44 removal and it not only removes the dag_processsing/manager calls but also the internal_api_call itself.

Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 21:23:42+00:00,[],2024-12-01 22:23:27+00:00,2024-12-01 22:23:26+00:00,https://github.com/apache/airflow/pull/44549,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2510257482, 'issue_id': 2709864877, 'author': 'potiuk', 'body': 'cc: @jason810496', 'created_at': datetime.datetime(2024, 12, 1, 21, 24, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510275889, 'issue_id': 2709864877, 'author': 'jscheffl', 'body': ""...ah wheres still some cleaning and removal in airflow/serialization/pydantic/** is needed as well?\r\nWill airflow/serialization/** actually also be removed or will this stay? (I assume we don't need this with the old API, correct?)"", 'created_at': datetime.datetime(2024, 12, 1, 22, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510277714, 'issue_id': 2709864877, 'author': 'potiuk', 'body': '> ...ah wheres still some cleaning and removal in airflow/serialization/pydantic/** is needed as well?\r\nWill airflow/serialization/** actually also be removed or will this stay? (I assume we don\'t need this with the old API, correct?)\r\n\r\n\r\nYep. there is one more step in #44436 - remove all `*Pydantic` classes aand that\'s part of it. One problem there is that `Pydantic` classes are currently used as a way to serialize Context for `PythonVirtualenvOperator` and `ExternalPythonOperator` - so we cannot remove them ""as-is"" - we have to provide a replacement - which is likely tied to the Task SDK API changes - cc: @ashb @kaxil', 'created_at': datetime.datetime(2024, 12, 1, 22, 22, 59, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-01 21:24:32 UTC): cc: @jason810496

jscheffl on (2024-12-01 22:18:09 UTC): ...ah wheres still some cleaning and removal in airflow/serialization/pydantic/** is needed as well?
Will airflow/serialization/** actually also be removed or will this stay? (I assume we don't need this with the old API, correct?)

potiuk (Issue Creator) on (2024-12-01 22:22:59 UTC): Will airflow/serialization/** actually also be removed or will this stay? (I assume we don't need this with the old API, correct?)


Yep. there is one more step in #44436 - remove all `*Pydantic` classes aand that's part of it. One problem there is that `Pydantic` classes are currently used as a way to serialize Context for `PythonVirtualenvOperator` and `ExternalPythonOperator` - so we cannot remove them ""as-is"" - we have to provide a replacement - which is likely tied to the Task SDK API changes - cc: @ashb @kaxil

"
2709832197,pull_request,closed,,Merge _get_task_map_lenght with public method,"Follow up after #44499

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 20:36:51+00:00,[],2024-12-01 22:31:35+00:00,2024-12-01 22:31:33+00:00,https://github.com/apache/airflow/pull/44548,[],"[{'comment_id': 2510242017, 'issue_id': 2709832197, 'author': 'potiuk', 'body': 'CC: @jason810496', 'created_at': datetime.datetime(2024, 12, 1, 20, 38, 26, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-01 20:38:26 UTC): CC: @jason810496

"
2709776440,pull_request,closed,,do not push stale update to related DagRun on TI update after task execution,"When TI is marked as failed via UI, and later fails itself, scheduler changes the state to failed twice. 

(some extra logs for clarity)
```
[2024-11-28T14:48:11.276+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 75
[2024-11-28T14:48:11.284+0000] {scheduler_job_runner.py:1666} ERROR - Scheduling dag run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731
025+00:00: manual__2024-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered:
True> state running
[2024-11-28T14:48:11.287+0000] {dagrun.py:906} ERROR - Marking run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731025+00:00: manual__202
4-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered: True> failed - from st
ate running at 2024-11-28 14:48:11.286513+00:00
[2024-11-28T14:48:11.288+0000] {dagrun.py:1101} ERROR - NOTIFYING STATE CHANGED TO failed
[2024-11-28T14:48:11.289+0000] {dagrun.py:989} INFO - DagRun Finished: dag_id=wait_to_fail, logical_date=2024-11-28 14:48:04.731025+00:
00, run_id=manual__2024-11-28T14:48:04.731025+00:00, run_start_date=2024-11-28 14:48:05.186397+00:00, run_end_date=2024-11-28 14:48:11.
288084+00:00, run_duration=6.101687, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-11-28 14:48:04.7310
25+00:00, data_interval_end=2024-11-28 14:48:04.731025+00:00, dag_version_name=wait_to_fail-1
[2024-11-28T14:48:11.299+0000] {client.py:110} INFO - OpenLineageClient will use `http` transport
[2024-11-28T14:48:12.307+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 76
[2024-11-28T14:48:13.344+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 77
[2024-11-28T14:48:14.382+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 78
[2024-11-28T14:48:15.274+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 79
[2024-11-28T14:48:16.309+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 80
[2024-11-28T14:48:17.345+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 81
[2024-11-28T14:48:17.361+0000] {scheduler_job_runner.py:1666} ERROR - Scheduling dag run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731
025+00:00: manual__2024-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered:
True> state running
[2024-11-28T14:48:17.366+0000] {dagrun.py:906} ERROR - Marking run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731025+00:00: manual__202
4-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered: True> failed - from st
ate running at 2024-11-28 14:48:17.364879+00:00
[2024-11-28T14:48:17.366+0000] {dagrun.py:1101} ERROR - NOTIFYING STATE CHANGED TO failed
[2024-11-28T14:48:17.367+0000] {dagrun.py:989} INFO - DagRun Finished: dag_id=wait_to_fail, logical_date=2024-11-28 14:48:04.731025+00:
00, run_id=manual__2024-11-28T14:48:04.731025+00:00, run_start_date=2024-11-28 14:48:05.186397+00:00, run_end_date=2024-11-28 14:48:17.
366330+00:00, run_duration=12.179933, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-11-28 14:48:04.731
025+00:00, data_interval_end=2024-11-28 14:48:04.731025+00:00, dag_version_name=wait_to_fail-1
[2024-11-28T14:48:17.370+0000] {client.py:110} INFO - OpenLineageClient will use `http` transport
``` 

This happens because on `handle_failure`, `TaskInstance.save_to_db` not only updates state of that task instance, it also pushes stale DagRun state - the one it got on TI start. So the actual DR state goes `running` -> `failed` -> `running` -> `failed`. 

This causes other unintended behavior, such as calling `on_dag_run_failed` listeners twice. 

The solution just loads DR state from db before pushing TI state. However, there probably is better solution, that someone with more knowledge of SQLAlchemy might help with. 

Link to discussion on Airflow slack: https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1732805503889679",mobuchowski,2024-12-01 20:20:15+00:00,[],2025-01-08 18:33:25+00:00,2025-01-02 12:35:25+00:00,https://github.com/apache/airflow/pull/44547,[],[],
2709760710,pull_request,closed,,Remove AIP-44 code from renderedtifields.py,"Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 19:54:15+00:00,[],2024-12-01 20:21:16+00:00,2024-12-01 20:21:14+00:00,https://github.com/apache/airflow/pull/44546,"[('area:providers', ''), ('provider:standard', '')]",[],
2709753175,pull_request,closed,,Add core operators/sensors/triggers module deprecations,"related: #43641

Added missing deprecation module references. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-01 19:43:50+00:00,[],2024-12-01 21:15:10+00:00,2024-12-01 21:10:13+00:00,https://github.com/apache/airflow/pull/44545,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2709747447,pull_request,closed,,Remove Provider Deprecations in SSH,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider **SSH**
",jscheffl,2024-12-01 19:36:05+00:00,[],2024-12-02 22:35:13+00:00,2024-12-02 22:35:12+00:00,https://github.com/apache/airflow/pull/44544,"[('area:providers', ''), ('provider:ssh', '')]","[{'comment_id': 2512412351, 'issue_id': 2709747447, 'author': 'jscheffl', 'body': 'relates to #44559', 'created_at': datetime.datetime(2024, 12, 2, 18, 44, 58, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-02 18:44:58 UTC): relates to #44559

"
2709681962,pull_request,closed,,Merge internal methods with public ones in model variables,"Follow up after #44525

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 19:00:55+00:00,[],2024-12-01 20:19:34+00:00,2024-12-01 20:19:32+00:00,https://github.com/apache/airflow/pull/44543,[],[],
2709616496,pull_request,closed,,Remove Provider Deprecations in HTTP,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider **HTTP**",jscheffl,2024-12-01 18:35:11+00:00,[],2024-12-02 22:25:23+00:00,2024-12-02 22:25:23+00:00,https://github.com/apache/airflow/pull/44542,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2510204851, 'issue_id': 2709616496, 'author': 'eladkal', 'body': 'We need also update to the changelog (simiar to what we did for cncf.kubenetes and amazon). I will create tracking issue with all the details tomorrow', 'created_at': datetime.datetime(2024, 12, 1, 18, 47, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510234190, 'issue_id': 2709616496, 'author': 'jscheffl', 'body': '> We need also update to the changelog (simiar to what we did for cncf.kubenetes and amazon). I will create tracking issue with all the details tomorrow\r\n\r\nIf you give me a hint I do that... do I need to edit the CHANGELOG.rst and add the future major version like in k8s? Or do I need to drop a newfragment somewhere that is sourced in the provider production process?\r\n\r\nLike in `providers/src/airflow/providers/http/CHANGELOG.rst`\r\n```\r\n5.0.0\r\n......\r\n\r\n\r\nBreaking changes\r\n~~~~~~~~~~~~~~~~\r\n\r\n.. warning::\r\n  All deprecated classes, parameters and features have been removed from the Kubernetes provider package.\r\n  The following breaking changes were introduced:\r\n\r\n  * Operators\r\n     * Remove ``airflow.providers.http.operators.http.SimpleHttpOperator``. Use ``airflow.providers.http.operators.http.HttpOperator`` instead.\r\n\r\n```', 'created_at': datetime.datetime(2024, 12, 1, 20, 15, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511928143, 'issue_id': 2709616496, 'author': 'vincbeck', 'body': '> > We need also update to the changelog (simiar to what we did for cncf.kubenetes and amazon). I will create tracking issue with all the details tomorrow\r\n> \r\n> If you give me a hint I do that... do I need to edit the CHANGELOG.rst and add the future major version like in k8s? Or do I need to drop a newfragment somewhere that is sourced in the provider production process?\r\n> \r\n> Like in `providers/src/airflow/providers/http/CHANGELOG.rst`\r\n> \r\n> ```\r\n> 5.0.0\r\n> ......\r\n> \r\n> \r\n> Breaking changes\r\n> ~~~~~~~~~~~~~~~~\r\n> \r\n> .. warning::\r\n>   All deprecated classes, parameters and features have been removed from the Kubernetes provider package.\r\n>   The following breaking changes were introduced:\r\n> \r\n>   * Operators\r\n>      * Remove ``airflow.providers.http.operators.http.SimpleHttpOperator``. Use ``airflow.providers.http.operators.http.HttpOperator`` instead.\r\n> ```\r\n\r\nThe former :)', 'created_at': datetime.datetime(2024, 12, 2, 16, 0, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512411665, 'issue_id': 2709616496, 'author': 'jscheffl', 'body': 'relates to #44559', 'created_at': datetime.datetime(2024, 12, 2, 18, 44, 45, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-12-01 18:47:46 UTC): We need also update to the changelog (simiar to what we did for cncf.kubenetes and amazon). I will create tracking issue with all the details tomorrow

jscheffl (Issue Creator) on (2024-12-01 20:15:20 UTC): If you give me a hint I do that... do I need to edit the CHANGELOG.rst and add the future major version like in k8s? Or do I need to drop a newfragment somewhere that is sourced in the provider production process?

Like in `providers/src/airflow/providers/http/CHANGELOG.rst`
```
5.0.0
......


Breaking changes
~~~~~~~~~~~~~~~~

.. warning::
  All deprecated classes, parameters and features have been removed from the Kubernetes provider package.
  The following breaking changes were introduced:

  * Operators
     * Remove ``airflow.providers.http.operators.http.SimpleHttpOperator``. Use ``airflow.providers.http.operators.http.HttpOperator`` instead.

```

vincbeck on (2024-12-02 16:00:36 UTC): The former :)

jscheffl (Issue Creator) on (2024-12-02 18:44:45 UTC): relates to #44559

"
2709612142,pull_request,closed,,Remove Provider Deprecations in Standard,"In Airflow 3 Dev Call we discussed and made a LAZY CONSENSUS to remove all deprecation's in providers prior 2.11 release in https://lists.apache.org/thread/lhy7zhz8yxo3jjpln0ds8ogszgb9b469.

This PR is the first for the provider **Standard**

As I fear a bit of side-effects, I force full tests.",jscheffl,2024-12-01 18:28:39+00:00,[],2024-12-02 18:44:31+00:00,2024-12-01 21:11:27+00:00,https://github.com/apache/airflow/pull/44541,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:standard', '')]","[{'comment_id': 2510254198, 'issue_id': 2709612142, 'author': 'potiuk', 'body': 'One thing more I realized - I think we need to add a CHANGELOG entry - that will eventually will land in a single ""1.0"" changelog for ""standard"" provider. Cc: @eladkal -> we need to find out a way to tell our users - surely, you can use the ""standar"" operators from here - but here is the list of things that changed in it since the ""built-in"" ones.', 'created_at': datetime.datetime(2024, 12, 1, 21, 14, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510268779, 'issue_id': 2709612142, 'author': 'jscheffl', 'body': 'Yes, actually discussed the same with @eladkal in #44542 - just someone need to tell me ""how to make it right""', 'created_at': datetime.datetime(2024, 12, 1, 21, 59, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510275662, 'issue_id': 2709612142, 'author': 'potiuk', 'body': '> Yes, actually discussed the same with @eladkal in #44542 - just someone need to tell me ""how to make it right""\r\n\r\nJust add messages to CHANGELOG.rst for the provider ?  - we can then combine all the changelog entries for 0.* versions when we release 1.0. Does it sound good as ""making things right"" @eladkal @jscheffl :D ?', 'created_at': datetime.datetime(2024, 12, 1, 22, 17, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510690865, 'issue_id': 2709612142, 'author': 'eladkal', 'body': ""I don't think it's right to wait for 1.0\r\nThe 0.0.x provider still goes into constraints file. We need the change log to explain users how to migrate"", 'created_at': datetime.datetime(2024, 12, 2, 6, 34, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511041304, 'issue_id': 2709612142, 'author': 'potiuk', 'body': '> I don\'t think it\'s right to wait for 1.0 The 0.0.x provider still goes into constraints file. We need the change log to explain users how to migrate\r\n\r\nCorrect. What I proposed, was to continue adding it (as usual) and release in `0.n` - but then when we release 1.0 with the target of being ready for ""prime time"" we could consolidate it manually and make a single ""what\'s changed vs. built-in operators"" release notes (and remove all the 0.* ones from 1.0 changelog). That sounds like an easy way to communicate to users - who will be looking at the changelog while migrating to Airflow 3, putting it all in 1.0 changelog will just give them all information in one place.', 'created_at': datetime.datetime(2024, 12, 2, 9, 45, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512410925, 'issue_id': 2709612142, 'author': 'jscheffl', 'body': 'relates to #44559', 'created_at': datetime.datetime(2024, 12, 2, 18, 44, 30, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-01 21:14:38 UTC): One thing more I realized - I think we need to add a CHANGELOG entry - that will eventually will land in a single ""1.0"" changelog for ""standard"" provider. Cc: @eladkal -> we need to find out a way to tell our users - surely, you can use the ""standar"" operators from here - but here is the list of things that changed in it since the ""built-in"" ones.

jscheffl (Issue Creator) on (2024-12-01 21:59:27 UTC): Yes, actually discussed the same with @eladkal in #44542 - just someone need to tell me ""how to make it right""

potiuk on (2024-12-01 22:17:33 UTC): Just add messages to CHANGELOG.rst for the provider ?  - we can then combine all the changelog entries for 0.* versions when we release 1.0. Does it sound good as ""making things right"" @eladkal @jscheffl :D ?

eladkal on (2024-12-02 06:34:08 UTC): I don't think it's right to wait for 1.0
The 0.0.x provider still goes into constraints file. We need the change log to explain users how to migrate

potiuk on (2024-12-02 09:45:15 UTC): Correct. What I proposed, was to continue adding it (as usual) and release in `0.n` - but then when we release 1.0 with the target of being ready for ""prime time"" we could consolidate it manually and make a single ""what's changed vs. built-in operators"" release notes (and remove all the 0.* ones from 1.0 changelog). That sounds like an easy way to communicate to users - who will be looking at the changelog while migrating to Airflow 3, putting it all in 1.0 changelog will just give them all information in one place.

jscheffl (Issue Creator) on (2024-12-02 18:44:30 UTC): relates to #44559

"
2709518856,pull_request,closed,,Remove AIP-44 from taskinstance,"Part of https://github.com/apache/airflow/issues/44436


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 17:12:27+00:00,[],2024-12-01 18:47:01+00:00,2024-12-01 18:47:00+00:00,https://github.com/apache/airflow/pull/44540,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:logging', ''), ('area:serialization', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2510060412, 'issue_id': 2709518856, 'author': 'potiuk', 'body': 'I want to make this one pass - and then - separately - do refactoring with merging those changes in task instance.', 'created_at': datetime.datetime(2024, 12, 1, 17, 13, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510103501, 'issue_id': 2709518856, 'author': 'jscheffl', 'body': 'I\'m adding ""full tests needed"" as I think especially the task instance is a ""danger zone"" of side effects - same as we had with sensor base.py changes.', 'created_at': datetime.datetime(2024, 12, 1, 17, 30, 47, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-01 17:13:19 UTC): I want to make this one pass - and then - separately - do refactoring with merging those changes in task instance.

jscheffl on (2024-12-01 17:30:47 UTC): I'm adding ""full tests needed"" as I think especially the task instance is a ""danger zone"" of side effects - same as we had with sensor base.py changes.

"
2709424252,pull_request,closed,,"AIP-81 Move CLI Commands to directories according to Hybrid, Local and Remote","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
closes: #44204
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-12-01 16:01:51+00:00,[],2025-01-01 00:26:27+00:00,2024-12-03 22:16:01+00:00,https://github.com/apache/airflow/pull/44538,"[('area:CLI', ''), ('area:dev-tools', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('AIP-81', 'Enhanced Security in CLI via Integration of API')]","[{'comment_id': 2509900783, 'issue_id': 2709424252, 'author': 'jscheffl', 'body': ""Good that you separate big re-factoring and shifting files. Let's see if CI turns green, then after short screening I have no issue for fast merge."", 'created_at': datetime.datetime(2024, 12, 1, 16, 10, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510059795, 'issue_id': 2709424252, 'author': 'bugraoz93', 'body': ""> Good that you separate big re-factoring and shifting files. Let's see if CI turns green, then after short screening I have no issue for fast merge.\n\nSome turns out red :( I will check it out shortly"", 'created_at': datetime.datetime(2024, 12, 1, 17, 13, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510081458, 'issue_id': 2709424252, 'author': 'bugraoz93', 'body': ""I am surprised that my local pre-commit didn't catch this. They were there but weren't added to with git :sweat:"", 'created_at': datetime.datetime(2024, 12, 1, 17, 21, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514875868, 'issue_id': 2709424252, 'author': 'potiuk', 'body': 'You need to rebase / solve conflicts now @bugraoz93', 'created_at': datetime.datetime(2024, 12, 3, 15, 25, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515037874, 'issue_id': 2709424252, 'author': 'bugraoz93', 'body': 'Rebased, thanks a lot for the reviews! :heart:', 'created_at': datetime.datetime(2024, 12, 3, 16, 31, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563910508, 'issue_id': 2709424252, 'author': 'millin', 'body': ""This broke airflow 2.10 + apache-airflow-providers-celery 3.9.0\r\n```python\r\nModuleNotFoundError: No module named 'airflow.cli.commands.local_commands'\r\n```"", 'created_at': datetime.datetime(2024, 12, 27, 17, 52, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565952611, 'issue_id': 2709424252, 'author': 'bugraoz93', 'body': ""> This broke airflow 2.10 + apache-airflow-providers-celery 3.9.0\n> ```python\n> ModuleNotFoundError: No module named 'airflow.cli.commands.local_commands'\n> ```\n\nThanks @millin for bringing this up!"", 'created_at': datetime.datetime(2024, 12, 30, 21, 56, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566770430, 'issue_id': 2709424252, 'author': 'kurtrwall', 'body': 'Thanks for the catch. When is this fix expected to be released?', 'created_at': datetime.datetime(2025, 1, 1, 0, 26, 25, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-01 16:10:39 UTC): Good that you separate big re-factoring and shifting files. Let's see if CI turns green, then after short screening I have no issue for fast merge.

bugraoz93 (Issue Creator) on (2024-12-01 17:13:04 UTC): Some turns out red :( I will check it out shortly

bugraoz93 (Issue Creator) on (2024-12-01 17:21:33 UTC): I am surprised that my local pre-commit didn't catch this. They were there but weren't added to with git :sweat:

potiuk on (2024-12-03 15:25:28 UTC): You need to rebase / solve conflicts now @bugraoz93

bugraoz93 (Issue Creator) on (2024-12-03 16:31:02 UTC): Rebased, thanks a lot for the reviews! :heart:

millin on (2024-12-27 17:52:27 UTC): This broke airflow 2.10 + apache-airflow-providers-celery 3.9.0
```python
ModuleNotFoundError: No module named 'airflow.cli.commands.local_commands'
```

bugraoz93 (Issue Creator) on (2024-12-30 21:56:01 UTC): Thanks @millin for bringing this up!

kurtrwall on (2025-01-01 00:26:25 UTC): Thanks for the catch. When is this fix expected to be released?

"
2709419748,pull_request,closed,,fix test_long_stalled_task_is_killed_by_listener_overtime_if_ol_timeout_long_enough,"...and rename it to `test_success_overtime_kills_tasks`.

It was failing because heartbeat was failing due to primary key duplication:

```
WARNING  airflow.jobs.local_task_job_runner.LocalTaskJobRunner:local_task_job_runner.py:215 Heartbeat failed with Exception: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint ""job_pkey""
DETAIL:  Key (id)=(1) already exists.

[SQL: INSERT INTO job (id, dag_id, state, job_type, start_date, end_date, latest_heartbeat, executor_class, hostname, unixname) VALUES (%(id)s, %(dag_id)s, %(state)s, %(job_type)s, %(start_date)s, %(end_date)s, %(latest_heartbeat)s, %(executor_class)s, %(hostname)s, %(unixname)s)]
[parameters: ({'id': '1', 'dag_id': 'test_openlineage_execution', 'state': None, 'job_type': 'LocalTaskJob', 'start_date': datetime.datetime(2024, 12, 1, 15, 43, 57, 356380, tzinfo=Timezone('UTC')), 'end_date': None, 'latest_heartbeat': datetime.datetime(2024, 12, 1, 15, 44, 2, 585608, tzinfo=Timezone('UTC')), 'executor_class': None, 'hostname': '3b984b754931', 'unixname': 'root'}, {'id': '1', 'dag_id': 'test_openlineage_execution', 'state': None, 'job_type': 'LocalTaskJob', 'start_date': datetime.datetime(2024, 12, 1, 15, 43, 57, 356380, tzinfo=Timezone('UTC')), 'end_date': None, 'latest_heartbeat': datetime.datetime(2024, 12, 1, 15, 44, 2, 585608, tzinfo=Timezone('UTC')), 'executor_class': None, 'hostname': '3b984b754931', 'unixname': 'root'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj)
```

Removing id when passing job fixes that issue. ",mobuchowski,2024-12-01 15:55:48+00:00,[],2024-12-01 16:43:09+00:00,2024-12-01 16:43:09+00:00,https://github.com/apache/airflow/pull/44537,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2509872103, 'issue_id': 2709419748, 'author': 'potiuk', 'body': 'Any chance for making the test method name shorter 😛 ?', 'created_at': datetime.datetime(2024, 12, 1, 15, 59, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509874500, 'issue_id': 2709419748, 'author': 'potiuk', 'body': '(alternatively you just can announce you won that competition ;)', 'created_at': datetime.datetime(2024, 12, 1, 16, 0, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509927430, 'issue_id': 2709419748, 'author': 'mobuchowski', 'body': ""@potiuk I've renamed it and put more explanation into tested behavior into the comment."", 'created_at': datetime.datetime(2024, 12, 1, 16, 20, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509950279, 'issue_id': 2709419748, 'author': 'potiuk', 'body': ""> @potiuk I've renamed it and put more explanation into tested behavior into the comment.\r\n\r\n❤️"", 'created_at': datetime.datetime(2024, 12, 1, 16, 29, 22, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-01 15:59:29 UTC): Any chance for making the test method name shorter 😛 ?

potiuk on (2024-12-01 16:00:24 UTC): (alternatively you just can announce you won that competition ;)

mobuchowski (Issue Creator) on (2024-12-01 16:20:30 UTC): @potiuk I've renamed it and put more explanation into tested behavior into the comment.

potiuk on (2024-12-01 16:29:22 UTC): ❤️

"
2709417550,pull_request,closed,,Make Edge API retries configurable,"In https://github.com/apache/airflow/pull/44311#discussion_r1862825630 @kaxil, @potiuk and me had a bit of discussion. As promised to come back with this, this PR implements (as promised) a way to make the retries in Edge worker configurable.

But it is also opening the box of debates because:

- Do we want to add a new config? (Some people start screaming?)
    - (My position: Sensible default and make it configurable)
- Should we really retry 10 times?
    - (My position: 10 attempts was the former default in internal API, in a small prod outage I can say at least this is good such that tasks do not fail in small webserver outages or connection interrupts. We see daily flakiness on our WAN. As Zombie threshold is at 300s per default retrying more than 5min might not be needed. But also we should faster on small glitches... so the exponential back-off is good. I tested with the parameters below and I think for waiting 5min max it is reasonable to test 10 times in between before fail.
- Oh, why specific in Edge? (I saw multiple occasions in retries in different places in the repo. But also moving to TaskSDK I think we also should consider making this more common - at least Edge API retries from far away should be matching to the calls that are made to TaskSDK!)
    - (My position: I'd favor to make such setting common in Edge API and at least TaskSDK calls)

@ashb would also call for your opinion.

And if needed - but I assume it can be made within this PR - we could also call for an open [DISCUSS] or loop-in other stakeholders. Le me know.

UPDATE 28.12.2024: Updated after merge of https://github.com/apache/airflow/pull/45121",jscheffl,2024-12-01 15:53:20+00:00,[],2025-01-04 16:06:24+00:00,2025-01-04 16:06:24+00:00,https://github.com/apache/airflow/pull/44536,"[('area:providers', ''), ('AIP-69', 'Edge Executor'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2558201189, 'issue_id': 2709417550, 'author': 'jscheffl', 'body': ""Note: I'd make the implementation consistent to PR https://github.com/apache/airflow/pull/45121 which adds the same to TaskSDK... once the review and merge of the other PR has been made."", 'created_at': datetime.datetime(2024, 12, 21, 18, 44, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571284213, 'issue_id': 2709417550, 'author': 'jscheffl', 'body': '> LGTM +1 with respect to changes in this PR.\r\n> \r\n> On related note, I see that there are no tests present for the api_client at all, @jscheffl. Is that intentional or was it missed out?\r\n\r\nThanks for hinting me to missing pytests... added them and by this also found an error... so good to have tests now.', 'created_at': datetime.datetime(2025, 1, 4, 13, 10, 29, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-21 18:44:39 UTC): Note: I'd make the implementation consistent to PR https://github.com/apache/airflow/pull/45121 which adds the same to TaskSDK... once the review and merge of the other PR has been made.

jscheffl (Issue Creator) on (2025-01-04 13:10:29 UTC): Thanks for hinting me to missing pytests... added them and by this also found an error... so good to have tests now.

"
2709334250,pull_request,closed,,Update social accounts links,"We have now Bluesky account as well, and Twitter is now X.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 15:19:02+00:00,[],2024-12-03 00:14:23+00:00,2024-12-01 19:36:58+00:00,https://github.com/apache/airflow/pull/44535,"[('area:dev-tools', '')]","[{'comment_id': 2511715461, 'issue_id': 2709334250, 'author': 'ryanahamilton', 'body': 'I\'m curious if Apache allows adding a DNS record so a ""verified"" `@airflow.apache.org` handle [could be used](https://bsky.social/about/blog/4-28-2023-domain-handle-tutorial) on Bluesky?', 'created_at': datetime.datetime(2024, 12, 2, 14, 37, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513241719, 'issue_id': 2709334250, 'author': 'potiuk', 'body': '> I\'m curious if Apache allows adding a DNS record so a ""verified"" `@airflow.apache.org` handle [could be used](https://bsky.social/about/blog/4-28-2023-domain-handle-tutorial) on Bluesky?\r\n\r\nYeah. Good idea. I saw that option yesterday and want to test it for my own account first. I **think** that might require JIRA issue to create with infra. So if you would like to open such issue - maybe you could? @ryanahamilton ? the necessary information on all the infra services is here: https://infra.apache.org/', 'created_at': datetime.datetime(2024, 12, 3, 0, 14, 22, tzinfo=datetime.timezone.utc)}]","ryanahamilton on (2024-12-02 14:37:26 UTC): I'm curious if Apache allows adding a DNS record so a ""verified"" `@airflow.apache.org` handle [could be used](https://bsky.social/about/blog/4-28-2023-domain-handle-tutorial) on Bluesky?

potiuk (Issue Creator) on (2024-12-03 00:14:22 UTC): Yeah. Good idea. I saw that option yesterday and want to test it for my own account first. I **think** that might require JIRA issue to create with infra. So if you would like to open such issue - maybe you could? @ryanahamilton ? the necessary information on all the infra services is here: https://infra.apache.org/

"
2709176452,pull_request,closed,,Update conf column in dag_run table type from bytes to JSON,"closes: https://github.com/apache/airflow/issues/43933

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-01 13:11:21+00:00,[],2025-01-13 14:01:09+00:00,2025-01-13 14:01:07+00:00,https://github.com/apache/airflow/pull/44533,"[('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2511170203, 'issue_id': 2709176452, 'author': 'vatsrahul1001', 'body': ""While Testing this I noticed an issue in the downgrade case. We are not removing the data from downgrade and just perform below conversion.\r\n       \r\n```\r\n          ALTER TABLE dag_run\r\n          ALTER COLUMN conf TYPE BYTEA\r\n          USING CASE\r\n              WHEN conf IS NOT NULL THEN CONVERT_TO(conf::TEXT, 'UTF8')\r\n              ELSE NULL\r\n          END\r\n \r\n```\r\n\r\nI am getting `UnpicklingError` error with this when I try to open DAG page.\r\n![image](https://github.com/user-attachments/assets/93d7a456-448c-4d60-956d-50cbef968de3)\r\n\r\nShould we also move data to the archive table in case of a downgrade as well?\r\ncc: @kaxil"", 'created_at': datetime.datetime(2024, 12, 2, 10, 39, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511643750, 'issue_id': 2709176452, 'author': 'kaxil', 'body': ""> While Testing this I noticed an issue in the downgrade case. We are not removing the data from downgrade and just perform below conversion.\r\n> \r\n> ```\r\n>           ALTER TABLE dag_run\r\n>           ALTER COLUMN conf TYPE BYTEA\r\n>           USING CASE\r\n>               WHEN conf IS NOT NULL THEN CONVERT_TO(conf::TEXT, 'UTF8')\r\n>               ELSE NULL\r\n>           END\r\n>  \r\n> ```\r\n> \r\n> I am getting `UnpicklingError` error with this when I try to open DAG page. ![image](https://private-user-images.githubusercontent.com/43964496/391508491-93d7a456-448c-4d60-956d-50cbef968de3.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzMxNDg0NDIsIm5iZiI6MTczMzE0ODE0MiwicGF0aCI6Ii80Mzk2NDQ5Ni8zOTE1MDg0OTEtOTNkN2E0NTYtNDQ4Yy00ZDYwLTk1NmQtNTBjYmVmOTY4ZGUzLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEyMDIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMjAyVDE0MDIyMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNlYTc4ODBiYTMxZjk5ZjFmZGM2YjU0NmJhYWRkMDE4NjIwMDgwMjI5MmQ4OTZjMzY0ZTZlY2Y4Y2MyNjdmMWMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.hJxNgnZc2QuLnUp1EPHdb787rac6U-UHX7f2rPZVQl4)\r\n> \r\n> Should we also move data to the archive table in case of a downgrade as well? cc: @kaxil\r\n\r\nYeah, it is different than XCom, because XCom code had handling of both JSON & pickle type -- for dagrun conf it would be different. For downgrade you might just want to insert all records from the archive table back here."", 'created_at': datetime.datetime(2024, 12, 2, 14, 8, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567497133, 'issue_id': 2709176452, 'author': 'jscheffl', 'body': ""I don't see why the two failing tests are failing - they are really unrelated to the PR - but they are green on canary builds.\r\nI think the comment from @kaxil requires some double check, else from point of data and migration I am good with it."", 'created_at': datetime.datetime(2025, 1, 2, 9, 38, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567576961, 'issue_id': 2709176452, 'author': 'potiuk', 'body': ""> I don't see why the two failing tests are failing - they are really unrelated to the PR - but they are green on canary builds. I think the comment from @kaxil requires some double check, else from point of data and migration I am good with it.\r\n\r\nThose tests are run with `full tests needed` so they are very likely going to fail in `canary` (and for others tests as well after this one is merged. @vatsrahul1001 - if you can rebase it again and ping me when it fails, I might want to have a deeper look or maybe @dabla  might take a look.  \r\n\r\nIt definitely comes from https://github.com/apache/airflow/pull/41327 becasue that's where `get_primary_keys` was introduced."", 'created_at': datetime.datetime(2025, 1, 2, 10, 44, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567651592, 'issue_id': 2709176452, 'author': 'potiuk', 'body': 'This is a very interesting one. It looks like for **some** reason the compat tests were running the version of tests that were there before #41327   - which it should not - tests should always be taken from main.\r\n\r\nFirst time where #45287 might prove to be useful @gopidesupavan !', 'created_at': datetime.datetime(2025, 1, 2, 11, 45, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567656106, 'issue_id': 2709176452, 'author': 'potiuk', 'body': 'Ah yeah. I think it just needs rebase.', 'created_at': datetime.datetime(2025, 1, 2, 11, 49, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567658221, 'issue_id': 2709176452, 'author': 'vatsrahul1001', 'body': '@potiuk I have rebased. Test are running now.', 'created_at': datetime.datetime(2025, 1, 2, 11, 51, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567692396, 'issue_id': 2709176452, 'author': 'jscheffl', 'body': 'Oh, we had another issue fixed in https://github.com/apache/airflow/pull/45347 - maybe you need to re-base another time, not generating the same again :-(', 'created_at': datetime.datetime(2025, 1, 2, 12, 20, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567692539, 'issue_id': 2709176452, 'author': 'potiuk', 'body': 'Can you rebase AGAIN @vatsrahul1001 :)  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. So I think that could be the reason', 'created_at': datetime.datetime(2025, 1, 2, 12, 20, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567693026, 'issue_id': 2709176452, 'author': 'potiuk', 'body': ':D @jscheffl -> same thought', 'created_at': datetime.datetime(2025, 1, 2, 12, 20, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567701446, 'issue_id': 2709176452, 'author': 'gopidesupavan', 'body': '> This is a very interesting one. It looks like for **some** reason the compat tests were running the version of tests that were there before #41327 - which it should not - tests should always be taken from main.\r\n> \r\n> First time where #45287 might prove to be useful @gopidesupavan !\r\n\r\nI think we are uploading some images differently by seeing workflows?', 'created_at': datetime.datetime(2025, 1, 2, 12, 27, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567778020, 'issue_id': 2709176452, 'author': 'potiuk', 'body': '> I think we are uploading some images differently by seeing workflows?\r\n\r\nWe were not uploading them AT ALL', 'created_at': datetime.datetime(2025, 1, 2, 13, 29, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567778245, 'issue_id': 2709176452, 'author': 'potiuk', 'body': ':scream:', 'created_at': datetime.datetime(2025, 1, 2, 13, 29, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567781849, 'issue_id': 2709176452, 'author': 'potiuk', 'body': 'I am sorry @vatsrahul1001  -> you have to rebase AGAIN - the #45347 caused that #45335 was merged as ""green"" but it had some issues. It\' s now reverted so after you rebase .... you should get a clean green state (minus flaky asyncio test we know about but this one needs further investigation and mostly happens  in Python 3.12', 'created_at': datetime.datetime(2025, 1, 2, 13, 32, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567966568, 'issue_id': 2709176452, 'author': 'vatsrahul1001', 'body': 'thanks @jedcunningham. @potiuk all test passed now :)', 'created_at': datetime.datetime(2025, 1, 2, 15, 39, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568037340, 'issue_id': 2709176452, 'author': 'potiuk', 'body': '> thanks @jedcunningham. @potiuk all test passed now :)\r\n\r\nUFF! Goood.... That was it then :)', 'created_at': datetime.datetime(2025, 1, 2, 16, 25, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568041110, 'issue_id': 2709176452, 'author': 'potiuk', 'body': 'BTW. @vatsrahul1001  I also submitted this https://github.com/apache/infrastructure-actions/pull/88 so that in the futur we can protect against similar mistakes (of mine this time). That was a good learning :)', 'created_at': datetime.datetime(2025, 1, 2, 16, 28, 5, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-12-02 10:39:07 UTC): While Testing this I noticed an issue in the downgrade case. We are not removing the data from downgrade and just perform below conversion.
       
```
          ALTER TABLE dag_run
          ALTER COLUMN conf TYPE BYTEA
          USING CASE
              WHEN conf IS NOT NULL THEN CONVERT_TO(conf::TEXT, 'UTF8')
              ELSE NULL
          END
 
```

I am getting `UnpicklingError` error with this when I try to open DAG page.
![image](https://github.com/user-attachments/assets/93d7a456-448c-4d60-956d-50cbef968de3)

Should we also move data to the archive table in case of a downgrade as well?
cc: @kaxil

kaxil on (2024-12-02 14:08:35 UTC): Yeah, it is different than XCom, because XCom code had handling of both JSON & pickle type -- for dagrun conf it would be different. For downgrade you might just want to insert all records from the archive table back here.

jscheffl on (2025-01-02 09:38:51 UTC): I don't see why the two failing tests are failing - they are really unrelated to the PR - but they are green on canary builds.
I think the comment from @kaxil requires some double check, else from point of data and migration I am good with it.

potiuk on (2025-01-02 10:44:40 UTC): Those tests are run with `full tests needed` so they are very likely going to fail in `canary` (and for others tests as well after this one is merged. @vatsrahul1001 - if you can rebase it again and ping me when it fails, I might want to have a deeper look or maybe @dabla  might take a look.  

It definitely comes from https://github.com/apache/airflow/pull/41327 becasue that's where `get_primary_keys` was introduced.

potiuk on (2025-01-02 11:45:39 UTC): This is a very interesting one. It looks like for **some** reason the compat tests were running the version of tests that were there before #41327   - which it should not - tests should always be taken from main.

First time where #45287 might prove to be useful @gopidesupavan !

potiuk on (2025-01-02 11:49:21 UTC): Ah yeah. I think it just needs rebase.

vatsrahul1001 (Issue Creator) on (2025-01-02 11:51:11 UTC): @potiuk I have rebased. Test are running now.

jscheffl on (2025-01-02 12:20:10 UTC): Oh, we had another issue fixed in https://github.com/apache/airflow/pull/45347 - maybe you need to re-base another time, not generating the same again :-(

potiuk on (2025-01-02 12:20:18 UTC): Can you rebase AGAIN @vatsrahul1001 :)  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. So I think that could be the reason

potiuk on (2025-01-02 12:20:40 UTC): :D @jscheffl -> same thought

gopidesupavan on (2025-01-02 12:27:38 UTC): I think we are uploading some images differently by seeing workflows?

potiuk on (2025-01-02 13:29:37 UTC): We were not uploading them AT ALL

potiuk on (2025-01-02 13:29:46 UTC): :scream:

potiuk on (2025-01-02 13:32:33 UTC): I am sorry @vatsrahul1001  -> you have to rebase AGAIN - the #45347 caused that #45335 was merged as ""green"" but it had some issues. It' s now reverted so after you rebase .... you should get a clean green state (minus flaky asyncio test we know about but this one needs further investigation and mostly happens  in Python 3.12

vatsrahul1001 (Issue Creator) on (2025-01-02 15:39:29 UTC): thanks @jedcunningham. @potiuk all test passed now :)

potiuk on (2025-01-02 16:25:27 UTC): UFF! Goood.... That was it then :)

potiuk on (2025-01-02 16:28:05 UTC): BTW. @vatsrahul1001  I also submitted this https://github.com/apache/infrastructure-actions/pull/88 so that in the futur we can protect against similar mistakes (of mine this time). That was a good learning :)

"
2709171811,pull_request,closed,,Remove AIP-44 from airflow/dag_processing/processor.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/dag_processing/processor.py: update_import_errors
- [x] ./airflow/dag_processing/processor.py: _validate_task_pools_and_update_dag_warnings
- [x] ./airflow/dag_processing/processor.py: execute_callbacks
- [x] ./airflow/dag_processing/processor.py: execute_callbacks_without_dag
- [x] ./airflow/dag_processing/processor.py: _execute_task_callbacks
- [x] ./airflow/dag_processing/processor.py: save_dag_to_db",jscheffl,2024-12-01 13:08:57+00:00,[],2024-12-01 14:17:31+00:00,2024-12-01 14:17:31+00:00,https://github.com/apache/airflow/pull/44532,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]",[],
2709117696,pull_request,closed,,AIP-81 Implement POST/Insert Multiple Connections in REST API (FastAPI),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #43652

- Move the validate key for connections to `pydantic` model
- Leave unique check to database session for post endpoints
- Implement bulk connection insert endpoint

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-12-01 12:34:59+00:00,[],2025-01-23 09:14:57+00:00,2024-12-01 14:19:45+00:00,https://github.com/apache/airflow/pull/44531,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('AIP-81', 'Enhanced Security in CLI via Integration of API')]",[],
2709103821,pull_request,closed,,Remove AIP-44 from task_sdk/src/airflow/sdk/definitions/asset/__init__.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./task_sdk/src/airflow/sdk/definitions/asset/init.py: expand_alias_to_assets",jscheffl,2024-12-01 12:11:58+00:00,[],2024-12-01 12:57:09+00:00,2024-12-01 12:57:08+00:00,https://github.com/apache/airflow/pull/44530,"[('area:task-sdk', None)]",[],
2708839998,pull_request,closed,,Remove AIP-44 from airflow/sensors/base.py (2nd Attempt),"related: https://github.com/apache/airflow/issues/44436

Second attempt of #44518, hoping to NOT hit mypy issues again in all providers. Implemented it as it was prior Internal API w/o touching the sensor interface.

- [x] ./airflow/sensors/base.py: _orig_start_date",jscheffl,2024-12-01 09:13:17+00:00,[],2024-12-01 14:18:31+00:00,2024-12-01 14:18:31+00:00,https://github.com/apache/airflow/pull/44529,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2509654227, 'issue_id': 2708839998, 'author': 'jscheffl', 'body': ""Okay, mypy checks again, I'll shortly wait until #44434 is merged, then these problems will be gone with a re-base"", 'created_at': datetime.datetime(2024, 12, 1, 9, 28, 3, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-01 09:28:03 UTC): Okay, mypy checks again, I'll shortly wait until #44434 is merged, then these problems will be gone with a re-base

"
2708833937,pull_request,closed,,Remove mypy errors from semantic merge problems due to Internal API removal,"I found more mypy errors on main due to parallel removal of AIP-44 internal API calls. This time (again) cause by me merging a PR that was checked in parallel and generated semantic check problems ... it was https://github.com/apache/airflow/pull/44330

Hope to get rid of this state when PR #44434 is merged, but this also was not building and is not fully reviewed.",jscheffl,2024-12-01 09:01:53+00:00,[],2024-12-01 12:32:53+00:00,2024-12-01 09:10:18+00:00,https://github.com/apache/airflow/pull/44528,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2509747144, 'issue_id': 2708833937, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 12, 1, 12, 32, 51, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-01 12:32:51 UTC): Nice!

"
2708758370,pull_request,closed,,"Revert ""Remove AIP-44 from airflow/sensors/base.py""",Reverts apache/airflow#44518,jscheffl,2024-12-01 08:17:20+00:00,[],2025-01-11 19:43:52+00:00,2024-12-01 08:47:41+00:00,https://github.com/apache/airflow/pull/44527,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2708434590,pull_request,closed,,Remove AIP-44 from edge_logs and edge_job,"related to https://github.com/apache/airflow/issues/44436

- [x]  ./providers/src/airflow/providers/edge/models/edge_logs.py: push_logs
- [x]  ./providers/src/airflow/providers/edge/models/edge_job.py: reserve_task
- [x]  ./providers/src/airflow/providers/edge/models/edge_job.py: set_state",rawwar,2024-12-01 04:03:15+00:00,[],2024-12-01 23:55:41+00:00,2024-12-01 23:55:41+00:00,https://github.com/apache/airflow/pull/44526,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2509558536, 'issue_id': 2708434590, 'author': 'rawwar', 'body': 'Once https://github.com/apache/airflow/pull/44510 is merged, I need to pull changes to fix failing tests', 'created_at': datetime.datetime(2024, 12, 1, 4, 3, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509653070, 'issue_id': 2708434590, 'author': 'jscheffl', 'body': 'The bindings you want to remove in this PR are actually cleaned in #44434 - hoping to have this merged... sooon.', 'created_at': datetime.datetime(2024, 12, 1, 9, 24, 49, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-12-01 04:03:45 UTC): Once https://github.com/apache/airflow/pull/44510 is merged, I need to pull changes to fix failing tests

jscheffl on (2024-12-01 09:24:49 UTC): The bindings you want to remove in this PR are actually cleaned in #44434 - hoping to have this merged... sooon.

"
2708355003,pull_request,closed,,Remove AIP-44 from models/variable,"related to https://github.com/apache/airflow/issues/44436

 

- [x] ./airflow/models/variable.py: _set
- [x]  ./airflow/models/variable.py: _update
- [x]  ./airflow/models/variable.py: _delete",rawwar,2024-12-01 02:53:17+00:00,[],2024-12-01 18:56:02+00:00,2024-12-01 18:56:01+00:00,https://github.com/apache/airflow/pull/44525,[],[],
2708309357,pull_request,closed,,[v2-10-test] Upgrading tomli to 2.2.1 as suggsested by CI (#44444),"(cherry picked from commit 5474e56f5cbaca7ec7b7045c71c078d448ebe7c8)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-01 01:03:57+00:00,[],2024-12-04 08:48:45+00:00,2024-12-01 19:37:42+00:00,https://github.com/apache/airflow/pull/44524,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2509748027, 'issue_id': 2708309357, 'author': 'potiuk', 'body': 'Merging - the other tests need to be handled differently (will do it shortly).', 'created_at': datetime.datetime(2024, 12, 1, 12, 35, 35, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-01 12:35:35 UTC): Merging - the other tests need to be handled differently (will do it shortly).

"
2708113539,pull_request,closed,,Remove AIP-44 from airflow/models/dagwarning.py,"related: https://github.com/apache/airflow/issues/44436

- [x]  ./airflow/models/dagwarning.py: purge_inactive_dag_warnings",jscheffl,2024-11-30 22:02:52+00:00,[],2024-12-01 12:48:14+00:00,2024-12-01 12:48:13+00:00,https://github.com/apache/airflow/pull/44523,[],[],
2708106833,pull_request,closed,,Pass cluster context into load_kube_config_from_dict,"The cluster_context passed into AsyncKubernetesHook is not passed through when load_kube_config_from_dict is called. This causes failures if you are running a KubernetesPodOperator task with deferrable=True and a cluster context that’s different to the default.

Ensuring the cluster_context is passed into the load_kube_config_from_dict method ensures the correct context is used for API calls
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",awdavidson,2024-11-30 21:52:41+00:00,[],2025-02-07 00:15:19+00:00,2025-02-07 00:15:18+00:00,https://github.com/apache/airflow/pull/44522,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2623222602, 'issue_id': 2708106833, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 30, 0, 14, 43, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-30 00:14:43 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2708013578,pull_request,closed,,Remove AIP-44 from airflow/cli/commands/task_command.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/cli/commands/task_command.py: _get_ti_db_access",jscheffl,2024-11-30 20:48:14+00:00,[],2024-11-30 21:55:27+00:00,2024-11-30 21:55:27+00:00,https://github.com/apache/airflow/pull/44521,"[('area:CLI', '')]",[],
2707991093,pull_request,closed,,Remove AIP-44 from airflow/utils/log/file_task_handler.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/utils/log/file_task_handler.py: _render_filename_db_access",jscheffl,2024-11-30 20:36:50+00:00,[],2024-11-30 21:53:24+00:00,2024-11-30 21:53:24+00:00,https://github.com/apache/airflow/pull/44520,"[('area:logging', '')]",[],
2707939750,pull_request,closed,,Remove AIP-44 from airflow/utils/cli_action_loggers.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/utils/cli_action_loggers.py: _default_action_log_internal",jscheffl,2024-11-30 20:26:28+00:00,[],2024-11-30 21:54:35+00:00,2024-11-30 21:54:35+00:00,https://github.com/apache/airflow/pull/44519,[],[],
2707933544,pull_request,closed,,Remove AIP-44 from airflow/sensors/base.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/sensors/base.py: _orig_start_date",jscheffl,2024-11-30 20:19:35+00:00,[],2024-12-01 08:17:06+00:00,2024-11-30 21:49:28+00:00,https://github.com/apache/airflow/pull/44518,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2707917277,pull_request,closed,,[v2-10-test] fix gantt flickering #42215 (#44488),"(cherry picked from commit 0c354e7f6a34ab05b4ce239ece77fd05bbffe9a5)

Co-authored-by: darkag <darkag@free.fr>",github-actions[bot],2024-11-30 19:56:57+00:00,[],2025-01-11 19:43:54+00:00,2024-11-30 21:07:26+00:00,https://github.com/apache/airflow/pull/44517,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2707903667,pull_request,open,,Add Advance Search Support and Integrate with Get Variables,"Add the filter variables support 

Request:
<img width=""1443"" alt=""image"" src=""https://github.com/user-attachments/assets/6e10f43d-c2e4-487c-9c1e-bb6ebdcfbb88"">

Response:
<img width=""1443"" alt=""image"" src=""https://github.com/user-attachments/assets/0fef47e0-de6c-40d6-9383-44bdfc2796a8"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-11-30 19:35:31+00:00,[],2025-01-01 00:04:05+00:00,,https://github.com/apache/airflow/pull/44516,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566760605, 'issue_id': 2707903667, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 4, 4, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-01 00:04:04 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

"
2707674221,pull_request,closed,,"[v2-10-test] Allow ""/"" in metrics validator (#42934)","* Allow ""/"" to avoid ERROR - Invalid stat name: dag_processing.processes,file_path=/mnt/c

* Add UT

* Reformat (cherry picked from commit 14b32eae6761075a9546647f47ba35705c9bac03)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-30 17:18:01+00:00,[],2024-12-04 08:49:22+00:00,2024-11-30 23:28:03+00:00,https://github.com/apache/airflow/pull/44515,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2509403571, 'issue_id': 2707674221, 'author': 'potiuk', 'body': 'Failure unrelated.', 'created_at': datetime.datetime(2024, 11, 30, 22, 24, 56, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-30 22:24:56 UTC): Failure unrelated.

"
2707644588,pull_request,closed,,Quarantine test_long_stalled_task_is_killed_by_listener_overtime_if_o…,"…l_timeout_long_enough

The #44513 track it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-30 16:49:20+00:00,[],2024-11-30 16:52:49+00:00,2024-11-30 16:52:48+00:00,https://github.com/apache/airflow/pull/44514,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2509039536, 'issue_id': 2707644588, 'author': 'potiuk', 'body': 'BTW. @mobuchowski -> I think you won the price for the longest test name :D', 'created_at': datetime.datetime(2024, 11, 30, 16, 52, 41, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-30 16:52:41 UTC): BTW. @mobuchowski -> I think you won the price for the longest test name :D

"
2707359189,pull_request,closed,,Remove AIP-44 from models/taskinstance,"related to https://github.com/apache/airflow/issues/44436

- [x] ./airflow/models/taskinstance.py: _merge_ti
- [x]  ./airflow/models/taskinstance.py: _add_log
- [x]  ./airflow/models/taskinstance.py: _update_ti_heartbeat
- [x]  ./airflow/models/taskinstance.py: _xcom_pull
- [x]  ./airflow/models/taskinstance.py: _get_template_context
- [x]  ./airflow/models/taskinstance.py: _handle_failure
- [x]  ./airflow/models/taskinstance.py: _record_task_map_for_downstreams
- [x]  ./airflow/models/taskinstance.py: _update_rtif
- [x]  ./airflow/models/taskinstance.py: _defer_task
- [x]  ./airflow/models/taskinstance.py: _handle_reschedule
- [x]  ./airflow/models/taskinstance.py: get_task_instance
- [x]  ./airflow/models/taskinstance.py: _clear_xcom_data
- [x]  ./airflow/models/taskinstance.py: _set_state
- [x]  ./airflow/models/taskinstance.py: _get_dagrun
- [x]  ./airflow/models/taskinstance.py: _check_and_change_state_before_execution
- [x]  ./airflow/models/taskinstance.py: _register_asset_changes_int
- [x]  ./airflow/models/taskinstance.py: save_to_db",rawwar,2024-11-30 13:17:20+00:00,[],2024-12-01 18:49:13+00:00,2024-12-01 18:49:12+00:00,https://github.com/apache/airflow/pull/44510,[],"[{'comment_id': 2508976862, 'issue_id': 2707359189, 'author': 'rawwar', 'body': 'Once https://github.com/apache/airflow/pull/44496 is merged, I need to pull changes and fix remaining failing tests', 'created_at': datetime.datetime(2024, 11, 30, 14, 20, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509016282, 'issue_id': 2707359189, 'author': 'potiuk', 'body': '> Once #44496 is merged, I need to pull changes and fix remaining failing tests\r\n\r\nMerged ! Go ahead!', 'created_at': datetime.datetime(2024, 11, 30, 15, 58, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510205368, 'issue_id': 2707359189, 'author': 'potiuk', 'body': 'Rebased and mered in #44540 .. Almost out-of the box after I rebased - and you are co-author @rawwar :)', 'created_at': datetime.datetime(2024, 12, 1, 18, 49, 12, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-30 14:20:49 UTC): Once https://github.com/apache/airflow/pull/44496 is merged, I need to pull changes and fix remaining failing tests

potiuk on (2024-11-30 15:58:59 UTC): Merged ! Go ahead!

potiuk on (2024-12-01 18:49:12 UTC): Rebased and mered in #44540 .. Almost out-of the box after I rebased - and you are co-author @rawwar :)

"
2707355583,pull_request,closed,,Remove Pydantic classes from models/dag,"related: https://github.com/apache/airflow/issues/44436#issuecomment-2508949883

A small patch for the last PR to remove AIP-44 from `models/dag`: https://github.com/apache/airflow/pull/44502. The previous PR did not remove the Pydantic classes.",jason810496,2024-11-30 13:11:33+00:00,[],2024-11-30 20:01:21+00:00,2024-11-30 20:01:21+00:00,https://github.com/apache/airflow/pull/44509,[],"[{'comment_id': 2509014989, 'issue_id': 2707355583, 'author': 'potiuk', 'body': 'MyPy does not agree with it :)', 'created_at': datetime.datetime(2024, 11, 30, 15, 54, 3, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-30 15:54:03 UTC): MyPy does not agree with it :)

"
2707201988,pull_request,closed,,Update trigger_timeout column in task_instance table to use UtcDateTime,"This PR addresses [comment](https://github.com/apache/airflow/blob/6f0d731350674bedc320f213d55694c2df43017c/airflow/models/taskinstance.py#L1774-L1778).

closes: https://github.com/apache/airflow/issues/44421


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-30 11:10:00+00:00,[],2024-12-12 11:34:30+00:00,2024-12-12 11:34:28+00:00,https://github.com/apache/airflow/pull/44507,"[('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2517146816, 'issue_id': 2707201988, 'author': 'vatsrahul1001', 'body': ""> Looks good, do we need to handle for mysql too?\r\n\r\nIn MySql, its stored as `DATETIME` only. I don't think so we need to handle in MySql"", 'created_at': datetime.datetime(2024, 12, 4, 12, 0, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531418455, 'issue_id': 2707201988, 'author': 'vatsrahul1001', 'body': '> LGTM +1 @kaxil?\r\n\r\nDoes this look good to you, @kaxil?', 'created_at': datetime.datetime(2024, 12, 10, 12, 1, 12, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-12-04 12:00:37 UTC): In MySql, its stored as `DATETIME` only. I don't think so we need to handle in MySql

vatsrahul1001 (Issue Creator) on (2024-12-10 12:01:12 UTC): Does this look good to you, @kaxil?

"
2706872995,pull_request,closed,,Fix tests badge in README.md,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
I was recently bothered by looking at the tests badge in the `README.md` and see that it always indicates failure.
It turns out that the badge's path has been changed a bit, and now depends on the [file's path](https://docs.github.com/en/actions/monitoring-and-troubleshooting-workflows/monitoring-workflows/adding-a-workflow-status-badge#using-the-workflow-file-name) within `.github/workflows` (`ci.yml`), rather than its name (`Tests`).

**Edit:** opened this PR on the main repo by mistake (used GitHub in-browser editing ability), I'll be more careful next time.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-30 07:20:10+00:00,[],2024-12-03 18:16:24+00:00,2024-12-03 00:21:51+00:00,https://github.com/apache/airflow/pull/44505,"[('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2508869152, 'issue_id': 2706872995, 'author': 'shahar1', 'body': 'When backporting, I guess that it would make more sense to add `?branch=v2-10-test` to the path :)', 'created_at': datetime.datetime(2024, 11, 30, 7, 22, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512163186, 'issue_id': 2706872995, 'author': 'gopidesupavan', 'body': '> When backporting, I guess that it would make more sense to add `?branch=v2-10-test` to the path :)\r\n\r\nI am okay, but one question do we run schedule runs in v2-10-test?', 'created_at': datetime.datetime(2024, 12, 2, 16, 59, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513249850, 'issue_id': 2706872995, 'author': 'potiuk', 'body': '> > When backporting, I guess that it would make more sense to add `?branch=v2-10-test` to the path :)\r\n> \r\n> I am okay, but one question do we run schedule runs in v2-10-test?\r\n\r\nNope. We do it only in main. There is no way to run scheduled runs on non-default branch https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#schedule', 'created_at': datetime.datetime(2024, 12, 3, 0, 21, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513250493, 'issue_id': 2706872995, 'author': 'potiuk', 'body': 'NICE ONE !', 'created_at': datetime.datetime(2024, 12, 3, 0, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513251419, 'issue_id': 2706872995, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44587""><img src=""https://img.shields.io/badge/PR-44587-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 3, 0, 22, 43, tzinfo=datetime.timezone.utc)}]","shahar1 (Issue Creator) on (2024-11-30 07:22:42 UTC): When backporting, I guess that it would make more sense to add `?branch=v2-10-test` to the path :)

gopidesupavan on (2024-12-02 16:59:46 UTC): I am okay, but one question do we run schedule runs in v2-10-test?

potiuk on (2024-12-03 00:21:30 UTC): Nope. We do it only in main. There is no way to run scheduled runs on non-default branch https://docs.github.com/en/actions/writing-workflows/choosing-when-your-workflow-runs/events-that-trigger-workflows#schedule

potiuk on (2024-12-03 00:22:00 UTC): NICE ONE !

github-actions[bot] on (2024-12-03 00:22:43 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44587""><img src=""https://img.shields.io/badge/PR-44587-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2706777381,pull_request,closed,,Remove AIP-44 from models/xcom.py,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/models/xcom.py: set
- [x] ./airflow/models/xcom.py: get_value
- [x] ./airflow/models/xcom.py: get_one
- [x] ./airflow/models/xcom.py: clear",jason810496,2024-11-30 06:39:01+00:00,[],2024-11-30 07:21:35+00:00,2024-11-30 07:21:35+00:00,https://github.com/apache/airflow/pull/44504,[],[],
2706769915,pull_request,closed,,Remove AIP-44 from models/skipmixin,"related: https://github.com/apache/airflow/issues/44436
- [x] ./airflow/models/skipmixin.py: _skip
- [x] ./airflow/models/skipmixin.py: _skip_all_except",jason810496,2024-11-30 06:33:12+00:00,[],2024-12-01 20:27:23+00:00,2024-12-01 20:27:23+00:00,https://github.com/apache/airflow/pull/44503,[],"[{'comment_id': 2510222933, 'issue_id': 2706769915, 'author': 'potiuk', 'body': 'Resolved conflicts :).', 'created_at': datetime.datetime(2024, 12, 1, 19, 41, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510223027, 'issue_id': 2706769915, 'author': 'potiuk', 'body': '(we are CLOSE) :)', 'created_at': datetime.datetime(2024, 12, 1, 19, 42, 18, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-01 19:41:58 UTC): Resolved conflicts :).

potiuk on (2024-12-01 19:42:18 UTC): (we are CLOSE) :)

"
2706757527,pull_request,closed,,Remove AIP-44 from models/dag,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/models/dag.py: fetch_callback
- [x] ./airflow/models/dag.py: fetch_dagrun
- [x] ./airflow/models/dag.py: get_current
- [x] ./airflow/models/dag.py: get_paused_dag_ids
- [x] ./airflow/models/dag.py: deactivate_deleted_dags",jason810496,2024-11-30 06:13:35+00:00,[],2024-11-30 07:00:30+00:00,2024-11-30 07:00:30+00:00,https://github.com/apache/airflow/pull/44502,[],[],
2706755768,pull_request,closed,,Remove AIP-44 from models/serialized_dag,"related: https://github.com/apache/airflow/issues/44436

- [x]  ./airflow/models/serialized_dag.py: get_serialized_dag
",jason810496,2024-11-30 06:08:52+00:00,[],2024-11-30 07:10:52+00:00,2024-11-30 07:10:52+00:00,https://github.com/apache/airflow/pull/44501,"[('area:serialization', '')]",[],
2706754243,pull_request,closed,,Remove AIP-44 from models/renderedtifields,"related: https://github.com/apache/airflow/issues/44436

- [x]  ./airflow/models/renderedtifields.py: _update_runtime_evaluated_template_fields",jason810496,2024-11-30 06:04:13+00:00,[],2024-12-01 20:29:10+00:00,2024-12-01 20:29:10+00:00,https://github.com/apache/airflow/pull/44500,[],"[{'comment_id': 2508866309, 'issue_id': 2706754243, 'author': 'jason810496', 'body': ""### Note\r\nI thinks this method is not the case that:\r\n> re-join back methods that were separated out from the main code - when methods start with `_`\r\n\r\nOnly Edge-Worker is depends on this `_update_runtime_evaluated_template_fields` method, and there isn't `update_runtime_evaluated_template_fields` public method."", 'created_at': datetime.datetime(2024, 11, 30, 7, 10, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509005943, 'issue_id': 2706754243, 'author': 'potiuk', 'body': '> ### Note\r\n> I thinks this method is not the case that:\r\n> \r\n> > re-join back methods that were separated out from the main code - when methods start with `_`\r\n> \r\n> Only Edge-Worker is depends on this `_update_runtime_evaluated_template_fields` method, and there isn\'t `update_runtime_evaluated_template_fields` public method.\r\n\r\nThis one needs a bit more effort I think. Actually this method seems to be nice idea to be renamed and added as ""legit"" method to use from this module. It\'s already used in `renderedtifields.py` and bash operator in standards provider (which is a bit problematic because bash operator should be backwards compatible - so it needs some compatibility code to make sure it also works for past Airflow versions when we rename it.\r\n\r\nAnd I think it\'s entirely worth it.', 'created_at': datetime.datetime(2024, 11, 30, 15, 23, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510238721, 'issue_id': 2706754243, 'author': 'potiuk', 'body': 'Fixed in #44546', 'created_at': datetime.datetime(2024, 12, 1, 20, 28, 53, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-11-30 07:10:13 UTC): ### Note
I thinks this method is not the case that:

Only Edge-Worker is depends on this `_update_runtime_evaluated_template_fields` method, and there isn't `update_runtime_evaluated_template_fields` public method.

potiuk on (2024-11-30 15:23:10 UTC): This one needs a bit more effort I think. Actually this method seems to be nice idea to be renamed and added as ""legit"" method to use from this module. It's already used in `renderedtifields.py` and bash operator in standards provider (which is a bit problematic because bash operator should be backwards compatible - so it needs some compatibility code to make sure it also works for past Airflow versions when we rename it.

And I think it's entirely worth it.

potiuk on (2024-12-01 20:28:53 UTC): Fixed in #44546

"
2706752418,pull_request,closed,,Remove AIP-44 from models/xcom_arg,"related: https://github.com/apache/airflow/issues/44436
 - [x] ./airflow/models/xcom_arg.py: _get_task_map_length

### Note

The Edge Worker also depends on the `_get_task_map_length` function, so I leave it starting with `_` instead of rejoining it with the `get_task_map_length` method.
",jason810496,2024-11-30 05:59:15+00:00,[],2024-12-01 20:30:22+00:00,2024-12-01 20:30:22+00:00,https://github.com/apache/airflow/pull/44499,[],"[{'comment_id': 2509007677, 'issue_id': 2706752418, 'author': 'potiuk', 'body': 'I think that one calls for ""joining"" - seems that `_get_task_map_length` is only used in `get_task_map_length` really - - so we should just remove the `_get_task_map_length` and move all the code to `get_task_map_length`', 'created_at': datetime.datetime(2024, 11, 30, 15, 25, 47, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-30 15:25:47 UTC): I think that one calls for ""joining"" - seems that `_get_task_map_length` is only used in `get_task_map_length` really - - so we should just remove the `_get_task_map_length` and move all the code to `get_task_map_length`

"
2706746962,pull_request,closed,,Remove AIP-44 from models/trigger,"related: https://github.com/apache/airflow/issues/44436

- [x] ./airflow/models/trigger.py: from_object
- [x] ./airflow/models/trigger.py: bulk_fetch
- [x] ./airflow/models/trigger.py: clean_unused
- [x] ./airflow/models/trigger.py: submit_event
- [x] ./airflow/models/trigger.py: submit_failure
- [x] ./airflow/models/trigger.py: ids_for_triggerer
- [x] ./airflow/models/trigger.py: assign_unassigned
",jason810496,2024-11-30 05:50:51+00:00,[],2024-11-30 06:18:19+00:00,2024-11-30 06:18:19+00:00,https://github.com/apache/airflow/pull/44498,"[('area:Triggerer', '')]",[],
2706674386,pull_request,closed,,AIP-72: Close sockets after sending start up msg,"We were closing `child_comms` socket before sending start-up msg which caused the startup msg to have fd of `-1` since it was closed. This resulted to the following to be `False` and hence there was no communication and it failed with `""NoneType' object has no attribute 'write""`.

https://github.com/apache/airflow/blob/55e419e95ab027d161cef95571300af9b2c81a0d/task_sdk/src/airflow/sdk/execution_time/task_runner.py#L95-L98

```
{'fd': -1, 'timestamp': datetime.datetime(2024, 11, 7, 12, 34, 56, 78901), 'logger': 'CommsDecoder', 'event': 'Received StartupDetails', 'level': 'info'},
```

Error was from following code block because `self.request_socket` was `None`:

https://github.com/apache/airflow/blob/55e419e95ab027d161cef95571300af9b2c81a0d/task_sdk/src/airflow/sdk/execution_time/task_runner.py#L101-L105

when sending it from

https://github.com/apache/airflow/blob/55e419e95ab027d161cef95571300af9b2c81a0d/task_sdk/src/airflow/sdk/execution_time/task_runner.py#L178
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-30 04:56:06+00:00,[],2024-11-30 11:55:27+00:00,2024-11-30 11:55:25+00:00,https://github.com/apache/airflow/pull/44497,"[('area:task-sdk', None)]",[],
2706597282,pull_request,closed,,Remove AIP-44 from models/dagrun,"related to #44436

 

- [x] ./airflow/models/dagrun.py: fetch_task_instances
- [x]  ./airflow/models/dagrun.py: _check_last_n_dagruns_failed
- [x]  ./airflow/models/dagrun.py: fetch_task_instance
- [x]  ./airflow/models/dagrun.py: get_previous_dagrun
- [x]  ./airflow/models/dagrun.py: get_previous_scheduled_dagrun
- [x]  ./airflow/models/dagrun.py: _get_log_template",rawwar,2024-11-30 03:54:46+00:00,[],2024-11-30 15:58:45+00:00,2024-11-30 15:58:18+00:00,https://github.com/apache/airflow/pull/44496,[],[],
2706423415,pull_request,closed,,Remove API-44 methods from method map,"The changes #44490, #44491, #44489 removed internal_api_call decorator from a few methods but did not remove them from method map.

This PR is a follow-up.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-30 00:05:12+00:00,[],2024-11-30 15:48:14+00:00,2024-11-30 00:17:25+00:00,https://github.com/apache/airflow/pull/44494,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2508895944, 'issue_id': 2706423415, 'author': 'jscheffl', 'body': 'Hi @potiuk While I like the cleanup and reversion of AIP-44 you are running faster than I can make the other PR to main to move EdgeExecutor off the AIP-44.\r\n\r\nThe method map is broken on main and for Airflow 3 can be completely removed. BUT we need it further for the backcompat case in Airflow 2.10. There I need to restore the state of Airflow 2.10, else it is both broken in Airflow 2.10 as well as in Airflow 3.\r\n\r\nWhile I accept it is temporarily broken in Airflow 3 (Still running behind trying to make EdgeExecutor working on main (again after the stone was hitting the glass) with the ongoing changes and merges to EdgeExecutor it is also throwing stones on the ability to further use it in Airflow 2.10.', 'created_at': datetime.datetime(2024, 11, 30, 9, 10, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509010130, 'issue_id': 2706423415, 'author': 'potiuk', 'body': '> While I accept it is temporarily broken in Airflow 3 (Still running behind trying to make EdgeExecutor working on main (again after the stone was hitting the glass) with the ongoing changes and merges to EdgeExecutor it is also throwing stones on the ability to further use it in Airflow 2.10.\r\n\r\nI think we should not hold back the changes for Airflow 2.10 compatibilty. This is the main thing we discussed before that it will have to end at some point of time - when it starts blocking our Airflow 3 development, And I think this is the time. \r\n\r\nI\'d say - if we need to have new features of `edge executor` to work for 2.10 (particularly in your installation - I doubt it is used by anyone else)  then maybe you should fork airflow right before we started to remove AIP-44 stuff, and continue to work on changes in standard executor that will be `2.10` compatible / backport there - and build it and use it internally.\r\n\r\nI think that was inevitable and there is no better way - there is no easy way same edge executor will work for both 2.10 and 3 becasue the APIs will be so vastly different (and AIP-44 completely removed in Airflow 3). \r\n\r\nI\'d say that this is the right moment to break the compatibility and let the burden on maintaining 2.10 variant of the edge executor to stay in the hands of Bosh, rather than keep us from cleaning and developing Airflow 3.\r\n\r\n@kaxil @ashb  - I guess the AIP-44 code is keeping you from AIP-72 progressing (it looked like from the discussions we had so far and the plans for next week to make PRs that are overlapping with the current AIP-44 cleanup. \r\n\r\nWe can raise it as a discussion at the devlist as well, but I think that was part of the agreement that we keep AIP-44 and Edge Executor happy with it for as long as we can - and I think ""as long as we can"" is ""NOW"".', 'created_at': datetime.datetime(2024, 11, 30, 15, 34, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509012064, 'issue_id': 2706423415, 'author': 'potiuk', 'body': 'Also technically speaking- when it comes to the mechanics of it. \r\n\r\n That should be of course a bit of a burden for you and your team - but this is completely no problem to fork Airflow and run `breeze prepare-proivders-package edge` from it - update versions there, test it etc. \r\n\r\nSo this is just a matter of backporting any changes in `main` edge executor to that fork to make it works with Airflow 2.10 / AIP-44. \r\n\r\nYou can also easily run the same  compatibility tests  in your CI - using your fork, so technically speaking you could do everything to release next ""2.10"" compatible edge worker on your own - without having to keep the compatibility in Airflow repo. \r\n\r\nSo all that is doable - the question is - should it slow down the current Airflow 3 development, or should it slow down Bosh\'s team runnning the 2.10 version of it.  i think that\'s basiclly the choice we are facing now.', 'created_at': datetime.datetime(2024, 11, 30, 15, 42, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509013447, 'issue_id': 2706423415, 'author': 'ashb', 'body': ""> @kaxil @ashb - I guess the AIP-44 code is keeping you from AIP-72 progressing\n\nNot especially, actually. It's very occasionally a mild inconvenience but not a blocker"", 'created_at': datetime.datetime(2024, 11, 30, 15, 48, 13, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-11-30 09:10:53 UTC): Hi @potiuk While I like the cleanup and reversion of AIP-44 you are running faster than I can make the other PR to main to move EdgeExecutor off the AIP-44.

The method map is broken on main and for Airflow 3 can be completely removed. BUT we need it further for the backcompat case in Airflow 2.10. There I need to restore the state of Airflow 2.10, else it is both broken in Airflow 2.10 as well as in Airflow 3.

While I accept it is temporarily broken in Airflow 3 (Still running behind trying to make EdgeExecutor working on main (again after the stone was hitting the glass) with the ongoing changes and merges to EdgeExecutor it is also throwing stones on the ability to further use it in Airflow 2.10.

potiuk (Issue Creator) on (2024-11-30 15:34:43 UTC): I think we should not hold back the changes for Airflow 2.10 compatibilty. This is the main thing we discussed before that it will have to end at some point of time - when it starts blocking our Airflow 3 development, And I think this is the time. 

I'd say - if we need to have new features of `edge executor` to work for 2.10 (particularly in your installation - I doubt it is used by anyone else)  then maybe you should fork airflow right before we started to remove AIP-44 stuff, and continue to work on changes in standard executor that will be `2.10` compatible / backport there - and build it and use it internally.

I think that was inevitable and there is no better way - there is no easy way same edge executor will work for both 2.10 and 3 becasue the APIs will be so vastly different (and AIP-44 completely removed in Airflow 3). 

I'd say that this is the right moment to break the compatibility and let the burden on maintaining 2.10 variant of the edge executor to stay in the hands of Bosh, rather than keep us from cleaning and developing Airflow 3.

@kaxil @ashb  - I guess the AIP-44 code is keeping you from AIP-72 progressing (it looked like from the discussions we had so far and the plans for next week to make PRs that are overlapping with the current AIP-44 cleanup. 

We can raise it as a discussion at the devlist as well, but I think that was part of the agreement that we keep AIP-44 and Edge Executor happy with it for as long as we can - and I think ""as long as we can"" is ""NOW"".

potiuk (Issue Creator) on (2024-11-30 15:42:35 UTC): Also technically speaking- when it comes to the mechanics of it. 

 That should be of course a bit of a burden for you and your team - but this is completely no problem to fork Airflow and run `breeze prepare-proivders-package edge` from it - update versions there, test it etc. 

So this is just a matter of backporting any changes in `main` edge executor to that fork to make it works with Airflow 2.10 / AIP-44. 

You can also easily run the same  compatibility tests  in your CI - using your fork, so technically speaking you could do everything to release next ""2.10"" compatible edge worker on your own - without having to keep the compatibility in Airflow repo. 

So all that is doable - the question is - should it slow down the current Airflow 3 development, or should it slow down Bosh's team runnning the 2.10 version of it.  i think that's basiclly the choice we are facing now.

ashb on (2024-11-30 15:48:13 UTC): Not especially, actually. It's very occasionally a mild inconvenience but not a blocker

"
2706419853,pull_request,closed,,Remove AIP-44 from Job,"Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-29 23:58:36+00:00,[],2024-11-30 02:19:32+00:00,2024-11-30 02:19:32+00:00,https://github.com/apache/airflow/pull/44493,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2508746083, 'issue_id': 2706419853, 'author': 'potiuk', 'body': 'For review - best is to  look at history of adding those removed methods here - from #34026', 'created_at': datetime.datetime(2024, 11, 30, 0, 9, 52, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-30 00:09:52 UTC): For review - best is to  look at history of adding those removed methods here - from #34026

"
2706386261,pull_request,closed,,Better description on how to build image for k8s,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-29 23:31:48+00:00,[],2024-11-30 14:30:01+00:00,2024-11-30 14:30:00+00:00,https://github.com/apache/airflow/pull/44492,"[('area:dev-tools', '')]","[{'comment_id': 2508733157, 'issue_id': 2706386261, 'author': 'potiuk', 'body': '<img width=""918"" alt=""Screenshot 2024-11-30 at 00 30 40"" src=""https://github.com/user-attachments/assets/7c969345-f0b4-4ef0-81a5-59a2136a250a"">', 'created_at': datetime.datetime(2024, 11, 29, 23, 32, 20, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-29 23:32:20 UTC): <img width=""918"" alt=""Screenshot 2024-11-30 at 00 30 40"" src=""https://github.com/user-attachments/assets/7c969345-f0b4-4ef0-81a5-59a2136a250a"">

"
2706176261,pull_request,closed,,Remove internal api call decorator from manager.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Part of #44436


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-29 21:28:05+00:00,[],2024-11-29 22:07:48+00:00,2024-11-29 22:07:47+00:00,https://github.com/apache/airflow/pull/44491,[],[],
2706167368,pull_request,closed,,Remove internal api call decorator from trigger_dag.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Part of #44436


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-29 21:21:08+00:00,[],2024-11-29 21:59:43+00:00,2024-11-29 21:59:43+00:00,https://github.com/apache/airflow/pull/44490,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2706145240,pull_request,closed,,Remove internal_api_call from airflow.secrets.metastore,"Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-29 20:57:42+00:00,[],2024-11-29 22:40:24+00:00,2024-11-29 22:40:15+00:00,https://github.com/apache/airflow/pull/44489,"[('area:secrets', '')]","[{'comment_id': 2508668495, 'issue_id': 2706145240, 'author': 'shahar1', 'body': 'Tests are 🔴', 'created_at': datetime.datetime(2024, 11, 29, 21, 12, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508671892, 'issue_id': 2706145240, 'author': 'potiuk', 'body': ""Ah... Our favorite:  `ImportError: cannot import name 'MetastoreBackend' from partially initialized module 'airflow.secrets.metastore' (most likely due to a circular import) (/opt/airflow/airflow/secrets/metastore.py)`"", 'created_at': datetime.datetime(2024, 11, 29, 21, 18, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508674064, 'issue_id': 2706145240, 'author': 'potiuk', 'body': 'One of those I want to get rid in airflow 3 by explicit rather than implicit initialization via ""airflow.__init__"".', 'created_at': datetime.datetime(2024, 11, 29, 21, 21, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508674290, 'issue_id': 2706145240, 'author': 'potiuk', 'body': 'Hopefully green now :)', 'created_at': datetime.datetime(2024, 11, 29, 21, 21, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508683233, 'issue_id': 2706145240, 'author': 'shahar1', 'body': '> Hopefully green now :)\r\n\r\nNot yet 😅 I was too optimistic', 'created_at': datetime.datetime(2024, 11, 29, 21, 38, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508697656, 'issue_id': 2706145240, 'author': 'potiuk', 'body': 'Variable too... I hate circular imports', 'created_at': datetime.datetime(2024, 11, 29, 22, 6, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508714744, 'issue_id': 2706145240, 'author': 'potiuk', 'body': 'Uff :)', 'created_at': datetime.datetime(2024, 11, 29, 22, 40, 22, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-11-29 21:12:45 UTC): Tests are 🔴

potiuk (Issue Creator) on (2024-11-29 21:18:43 UTC): Ah... Our favorite:  `ImportError: cannot import name 'MetastoreBackend' from partially initialized module 'airflow.secrets.metastore' (most likely due to a circular import) (/opt/airflow/airflow/secrets/metastore.py)`

potiuk (Issue Creator) on (2024-11-29 21:21:25 UTC): One of those I want to get rid in airflow 3 by explicit rather than implicit initialization via ""airflow.__init__"".

potiuk (Issue Creator) on (2024-11-29 21:21:55 UTC): Hopefully green now :)

shahar1 on (2024-11-29 21:38:27 UTC): Not yet 😅 I was too optimistic

potiuk (Issue Creator) on (2024-11-29 22:06:27 UTC): Variable too... I hate circular imports

potiuk (Issue Creator) on (2024-11-29 22:40:22 UTC): Uff :)

"
2706137326,pull_request,closed,,fix gantt flickering #42215,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

closes: #42215

Fix gantt flickering issue. if someone can label it to legacy ui
",darkag,2024-11-29 20:51:46+00:00,[],2024-11-30 19:58:00+00:00,2024-11-30 19:56:09+00:00,https://github.com/apache/airflow/pull/44488,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2508910357, 'issue_id': 2706137326, 'author': 'jscheffl', 'body': ""Before merge - for local testing - can you tell me a good example DAG/run such that I can test it locally? I am sure I have seen it myself flickering but I'd like to ensure I am looking at the right place... as I did not note down where..."", 'created_at': datetime.datetime(2024, 11, 30, 10, 10, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508997030, 'issue_id': 2706137326, 'author': 'darkag', 'body': 'Sure, here is step to reproduce the issue with the the following dag\r\n\r\n```python\r\nfrom __future__ import annotations\r\n\r\nimport pendulum\r\n\r\nfrom airflow.decorators import dag, task\r\nfrom airflow.operators.empty import EmptyOperator\r\n\r\n\r\n# [START dag_decorator_usage]\r\n@dag(\r\n    schedule=None,\r\n    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),\r\n    catchup=False,\r\n    tags=[""example""],\r\n    dag_display_name=""Sample DAG with Display Name"",\r\n)\r\ndef example_display_name():\r\n    sample_task_1 = EmptyOperator(\r\n        task_id=""sample_task_1"",\r\n        task_display_name=""Sample Task 1"",\r\n    )\r\n\r\n    @task(task_display_name=""Sample Task 2"")\r\n    def sample_task_2():\r\n        pass\r\n\r\n    sample_task_1 >> sample_task_2()\r\n\r\n\r\nexample_dag = example_display_name()\r\n```\r\ntrigger a dag run of this dag\r\nclear ""Sample task 2""\r\n\r\nwith the fix, the gantt gaph should look to something like this\r\n![image](https://github.com/user-attachments/assets/dee3d772-08fa-4e49-afae-2c204bc2182a)\r\n\r\nwithout it will result as something like this:\r\n![2024-11-30 16-10-10](https://github.com/user-attachments/assets/dc12a0c0-c747-457e-a12e-a466e24e2cfb)', 'created_at': datetime.datetime(2024, 11, 30, 15, 15, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509176445, 'issue_id': 2706137326, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44517""><img src=""https://img.shields.io/badge/PR-44517-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 11, 30, 19, 56, 59, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-11-30 10:10:19 UTC): Before merge - for local testing - can you tell me a good example DAG/run such that I can test it locally? I am sure I have seen it myself flickering but I'd like to ensure I am looking at the right place... as I did not note down where...

darkag (Issue Creator) on (2024-11-30 15:15:43 UTC): Sure, here is step to reproduce the issue with the the following dag

```python
from __future__ import annotations

import pendulum

from airflow.decorators import dag, task
from airflow.operators.empty import EmptyOperator


# [START dag_decorator_usage]
@dag(
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),
    catchup=False,
    tags=[""example""],
    dag_display_name=""Sample DAG with Display Name"",
)
def example_display_name():
    sample_task_1 = EmptyOperator(
        task_id=""sample_task_1"",
        task_display_name=""Sample Task 1"",
    )

    @task(task_display_name=""Sample Task 2"")
    def sample_task_2():
        pass

    sample_task_1 >> sample_task_2()


example_dag = example_display_name()
```
trigger a dag run of this dag
clear ""Sample task 2""

with the fix, the gantt gaph should look to something like this
![image](https://github.com/user-attachments/assets/dee3d772-08fa-4e49-afae-2c204bc2182a)

without it will result as something like this:
![2024-11-30 16-10-10](https://github.com/user-attachments/assets/dc12a0c0-c747-457e-a12e-a466e24e2cfb)

github-actions[bot] on (2024-11-30 19:56:59 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44517""><img src=""https://img.shields.io/badge/PR-44517-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2705804708,pull_request,closed,,[Mothership PR] Remove `internal_api_call` decorator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #44436

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-29 17:50:10+00:00,[],2024-12-06 22:51:09+00:00,2024-12-06 22:51:09+00:00,https://github.com/apache/airflow/pull/44486,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:logging', ''), ('area:serialization', ''), ('area:secrets', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:task-sdk', None), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2508213697, 'issue_id': 2705804708, 'author': 'vincbeck', 'body': 'As part of this task, #44436 mentions as well ""re-join back methods that were separated out from the main code - when methods start with _"". Are you planning to do it in this PR? I\'d advice to either do it as part of this PR or do the re-join before removing the decorator. Once the decorator is removed, it will be harder to look for methods that were used to be used for AIP-44 and needs to be re-joined', 'created_at': datetime.datetime(2024, 11, 29, 17, 57, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508235669, 'issue_id': 2705804708, 'author': 'shahar1', 'body': '> As part of this task, #44436 mentions as well ""re-join back methods that were separated out from the main code - when methods start with _"". Are you planning to do it in this PR? I\'d advice to either do it as part of this PR or do the re-join before removing the decorator. Once the decorator is removed, it will be harder to look for methods that were used to be used for AIP-44 and needs to be re-joined\r\n\r\nYes, that\'s why I just drafted it :)\r\nI\'ll take care of it, but just to make sure that I understand ""re-join"" correctly - everywhere where there\'s both `def fun()` and `def _fun()`, simply restore the logic from `_fun()` to `fun()`, or is it deeper than that.\r\nAlso: \r\n1. What should I do if `_fun()` is called more than once like `./airflow/dag_processing/processor.py: _execute_task_callbacks`? \r\n2. What should we do about these functions in `rcp_api.py`? Rename them to their original?\r\n\r\nIt\'s my first time in the API area, so I\'ll try not to break too many things :)', 'created_at': datetime.datetime(2024, 11, 29, 18, 13, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508289477, 'issue_id': 2705804708, 'author': 'vincbeck', 'body': '> Yes, that\'s why I just drafted it :)\r\n\r\nCool :) \r\n\r\n> I\'ll take care of it, but just to make sure that I understand ""re-join"" correctly - everywhere where there\'s both def fun() and def _fun(), simply restore the logic from _fun() to fun(), or is it deeper than that?\r\n\r\nYes you understood well what re-join means. When working on AIP-44, many methods were moved to private functions to make them ""callable"". You\'ll see many methods like:\r\n\r\n```\r\n@classmethod\r\n@internal_api_call\r\ndef function_name(self, ...)\r\n  return _function_name(...)\r\n```\r\n\r\nThe goal is to move back the implementation of `_function_name` into `function_name`.\r\n\r\n> Also, what should I do if _fun() is called more than once like ./airflow/dag_processing/processor.py: _execute_task_callbacks? (it\'s my first time in the API area)\r\n\r\nIn this case, (please @potiuk correct me if I am wrong) I dont think we should re-join this method. `_execute_task_callbacks` is called in different methods and the separation makes sense.\r\n\r\n> What should we do about these functions in rcp_api.py? Rename them to their original?\r\nAre you talking about `airflow/api_internal/endpoints/rpc_api_endpoint.py`? This file has been removed recently, so no need to take care of it\r\n\r\n> It\'s my first time in the API area, so I\'ll try not to break too many things :)\r\n\r\nNo worries! Thanks for doing it! We all have to start someday right?', 'created_at': datetime.datetime(2024, 11, 29, 18, 32, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508295954, 'issue_id': 2705804708, 'author': 'shahar1', 'body': '> > Yes, that\'s why I just drafted it :)\r\n> \r\n> Cool :)\r\n> \r\n> > I\'ll take care of it, but just to make sure that I understand ""re-join"" correctly - everywhere where there\'s both def fun() and def _fun(), simply restore the logic from _fun() to fun(), or is it deeper than that?\r\n> \r\n> Yes you understood well what re-join means. When working on AIP-44, many methods were moved to private functions to make them ""callable"". You\'ll see many methods like:\r\n> \r\n> ```\r\n> @classmethod\r\n> @internal_api_call\r\n> def function_name(self, ...)\r\n>   return _function_name(...)\r\n> ```\r\n> \r\n> The goal is to move back the implementation of `_function_name` into `function_name`.\r\n> \r\n> > Also, what should I do if _fun() is called more than once like ./airflow/dag_processing/processor.py: _execute_task_callbacks? (it\'s my first time in the API area)\r\n> \r\n> In this case, (please @potiuk correct me if I am wrong) I dont think we should re-join this method. `_execute_task_callbacks` is called in different methods and the separation makes sense.\r\n> \r\n> > What should we do about these functions in rcp_api.py? Rename them to their original?\r\n> > Are you talking about `airflow/api_internal/endpoints/rpc_api_endpoint.py`? This file has been removed recently, so no need to take care of it\r\n> \r\n> > It\'s my first time in the API area, so I\'ll try not to break too many things :)\r\n> \r\n> No worries! Thanks for doing it! We all have to start someday right?\r\n\r\nThanks for the deatiled response, I\'m on it!\r\nI\'m talking about `providers/src/airflow/providers/edge/worker_api/routes/rpc_api.py` (maybe @jscheffl could help with this one :) )', 'created_at': datetime.datetime(2024, 11, 29, 18, 34, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508397402, 'issue_id': 2705804708, 'author': 'potiuk', 'body': '> In this case, (please @potiuk correct me if I am wrong) I dont think we should re-join this method. _execute_task_callbacks is called in different methods and the separation makes sense.\r\n\r\nYes. We can maybe even nicely refactor it to make more sense and rename such methods, place them in the ""right"" place etc. This should be case-by-case decision and that\'s why in #44436  I extracted all the method lists so that we can do it in pieces - maybe not one-by-one, but maybe file-by-file, so that we could review the change in a meaningful way.\r\n\r\nThere are, for example, some cases where likely after re-joining we will be able to undo some of the changes made (for example there were few methods where we artifficially had to add  commit() where otherwise it was not needed - because the logic was split into ""client"" and ""server"" in a sequence of transctions.  By having smaller, focused commits ""per-file"" we can look at the historical changes to it and when we extracted it and decide what to do.\r\n\r\nAlso splitting it ""per-group"" might be easily distributed between different people in this case.', 'created_at': datetime.datetime(2024, 11, 29, 19, 9, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508402762, 'issue_id': 2705804708, 'author': 'potiuk', 'body': 'And yes. Cool you are looking at it @shahar1 -> i think a good idea will be by anyone who starts looking at removing the method from one of those files announce ""I am taking this part"" in #446436 in order to avoid duplication :)', 'created_at': datetime.datetime(2024, 11, 29, 19, 11, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508405075, 'issue_id': 2705804708, 'author': 'potiuk', 'body': 'Then - this one can be rebased gradually until we get to ""no change"" :D', 'created_at': datetime.datetime(2024, 11, 29, 19, 12, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508745199, 'issue_id': 2705804708, 'author': 'potiuk', 'body': 'I have realized that we forgot to remove method maps: https://github.com/apache/airflow/pull/44494\r\nAnd here is an example of ""joining"" back the methods that is more than just joining @shahar1 https://github.com/apache/airflow/pull/44493', 'created_at': datetime.datetime(2024, 11, 30, 0, 7, 43, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-11-29 17:57:09 UTC): As part of this task, #44436 mentions as well ""re-join back methods that were separated out from the main code - when methods start with _"". Are you planning to do it in this PR? I'd advice to either do it as part of this PR or do the re-join before removing the decorator. Once the decorator is removed, it will be harder to look for methods that were used to be used for AIP-44 and needs to be re-joined

shahar1 (Issue Creator) on (2024-11-29 18:13:32 UTC): Yes, that's why I just drafted it :)
I'll take care of it, but just to make sure that I understand ""re-join"" correctly - everywhere where there's both `def fun()` and `def _fun()`, simply restore the logic from `_fun()` to `fun()`, or is it deeper than that.
Also: 
1. What should I do if `_fun()` is called more than once like `./airflow/dag_processing/processor.py: _execute_task_callbacks`? 
2. What should we do about these functions in `rcp_api.py`? Rename them to their original?

It's my first time in the API area, so I'll try not to break too many things :)

vincbeck on (2024-11-29 18:32:21 UTC): Cool :) 


Yes you understood well what re-join means. When working on AIP-44, many methods were moved to private functions to make them ""callable"". You'll see many methods like:

```
@classmethod
@internal_api_call
def function_name(self, ...)
  return _function_name(...)
```

The goal is to move back the implementation of `_function_name` into `function_name`.


In this case, (please @potiuk correct me if I am wrong) I dont think we should re-join this method. `_execute_task_callbacks` is called in different methods and the separation makes sense.

Are you talking about `airflow/api_internal/endpoints/rpc_api_endpoint.py`? This file has been removed recently, so no need to take care of it


No worries! Thanks for doing it! We all have to start someday right?

shahar1 (Issue Creator) on (2024-11-29 18:34:41 UTC): Thanks for the deatiled response, I'm on it!
I'm talking about `providers/src/airflow/providers/edge/worker_api/routes/rpc_api.py` (maybe @jscheffl could help with this one :) )

potiuk on (2024-11-29 19:09:52 UTC): Yes. We can maybe even nicely refactor it to make more sense and rename such methods, place them in the ""right"" place etc. This should be case-by-case decision and that's why in #44436  I extracted all the method lists so that we can do it in pieces - maybe not one-by-one, but maybe file-by-file, so that we could review the change in a meaningful way.

There are, for example, some cases where likely after re-joining we will be able to undo some of the changes made (for example there were few methods where we artifficially had to add  commit() where otherwise it was not needed - because the logic was split into ""client"" and ""server"" in a sequence of transctions.  By having smaller, focused commits ""per-file"" we can look at the historical changes to it and when we extracted it and decide what to do.

Also splitting it ""per-group"" might be easily distributed between different people in this case.

potiuk on (2024-11-29 19:11:44 UTC): And yes. Cool you are looking at it @shahar1 -> i think a good idea will be by anyone who starts looking at removing the method from one of those files announce ""I am taking this part"" in #446436 in order to avoid duplication :)

potiuk on (2024-11-29 19:12:34 UTC): Then - this one can be rebased gradually until we get to ""no change"" :D

potiuk on (2024-11-30 00:07:43 UTC): I have realized that we forgot to remove method maps: https://github.com/apache/airflow/pull/44494
And here is an example of ""joining"" back the methods that is more than just joining @shahar1 https://github.com/apache/airflow/pull/44493

"
2705803923,pull_request,closed,,Remove more yoda conditions.,"Follow on from #44466 discovered via https://github.com/apache/airflow/pull/44484#discussion_r1863813546

Also I removed the redundant  `isinstance(hook.use_internal_ip, bool)` as `is
True` by defintion asserts that the result is a bool!
",ashb,2024-11-29 17:49:43+00:00,[],2024-11-29 18:45:50+00:00,2024-11-29 18:25:54+00:00,https://github.com/apache/airflow/pull/44485,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('provider:apache-druid', '')]","[{'comment_id': 2508327513, 'issue_id': 2705803923, 'author': 'potiuk', 'body': 'Nice it change is !', 'created_at': datetime.datetime(2024, 11, 29, 18, 45, 49, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-29 18:45:49 UTC): Nice it change is !

"
2705725549,pull_request,closed,,"Ensure that you can create a second DAG whilst another one is already ""active""","Why would you want to do this? Who knows, maybe you are calling a dag factory
from inside a `with DAG` block. Either way, this exposed a subtle bug in
`TaskGroup.create_root()`.

This is the other half of the fix for the flakey tests fixed in #44480, and
after much digging with @kaxil and @potiuk we've finally worked out why it was
flakey:

It was the ""Non-DB"" test job that were faling sometimes, and those tests use
xdist to parallelize the tests. Couple that with the fact that
`get_serialized_fields()` caches the answer on the class object, the test
would only fail when nothing else in the current test process had previously
called `DAG.get_serialized_fields()`.
",ashb,2024-11-29 17:23:55+00:00,[],2024-11-29 19:21:37+00:00,2024-11-29 18:44:22+00:00,https://github.com/apache/airflow/pull/44484,"[('area:task-sdk', None)]",[],
2705680085,pull_request,closed,,AIP-84 Rename Monitor Schema to DataModel,"""Schema"" is a remnant from marshmallow. Harmonized the data models name of the `monitor` module to be more consistent with other FastAPI data models naming convention.",pierrejeambrun,2024-11-29 16:55:05+00:00,['pierrejeambrun'],2024-11-29 23:16:12+00:00,2024-11-29 23:16:10+00:00,https://github.com/apache/airflow/pull/44483,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2705427198,pull_request,closed,,Fix flakey test in DAG serialization,"This behaviour is very odd, and is not in anyway clear _why_ it's happening,
but the fix is to not construct a DAG object, but to use attrs to tell us what
the fields are -- which is better behaviour anyway.

To reproduce the issue before this change:

1. `pytest tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_deserialization_with_dag_context` -> greeen
2. `pytest tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_deserialization_with_dag_context` -> boom

(So by dag objects existing in the DB it somehow ""poluted"" the
DagContextManager/TaskContextManager stack. I haven't dug into exactly how
that might be happening.)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-29 15:21:57+00:00,[],2024-11-29 15:48:43+00:00,2024-11-29 15:48:35+00:00,https://github.com/apache/airflow/pull/44480,"[('area:task-sdk', None)]",[],
2705268945,pull_request,closed,,Show prominent warning for deprecations in docs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/41532
continuation of https://github.com/apache/airflow/pull/43909

This PR aims to show prominent deprecation warnings consistently across all Airflow docs.
",omkar-foss,2024-11-29 14:28:55+00:00,['omkar-foss'],2024-12-02 06:45:50+00:00,2024-11-29 16:40:57+00:00,https://github.com/apache/airflow/pull/44479,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2508103121, 'issue_id': 2705268945, 'author': 'omkar-foss', 'body': '## Some screenshots for reference below.\r\n\r\n![after_1](https://github.com/user-attachments/assets/976e43ea-e23b-40cd-b918-7bffd0c63933)\r\n![after_2](https://github.com/user-attachments/assets/1cff9c56-9137-4aa7-a075-c7aa73fa298d)\r\n![after_3](https://github.com/user-attachments/assets/364edea0-5fb8-4110-904b-1996801a73f1)', 'created_at': datetime.datetime(2024, 11, 29, 16, 17, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508133016, 'issue_id': 2705268945, 'author': 'shahar1', 'body': 'Looks nice!', 'created_at': datetime.datetime(2024, 11, 29, 16, 41, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508375189, 'issue_id': 2705268945, 'author': 'potiuk', 'body': 'Indeed!', 'created_at': datetime.datetime(2024, 11, 29, 19, 2, 18, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-29 16:17:42 UTC): ## Some screenshots for reference below.

![after_1](https://github.com/user-attachments/assets/976e43ea-e23b-40cd-b918-7bffd0c63933)
![after_2](https://github.com/user-attachments/assets/1cff9c56-9137-4aa7-a075-c7aa73fa298d)
![after_3](https://github.com/user-attachments/assets/364edea0-5fb8-4110-904b-1996801a73f1)

shahar1 on (2024-11-29 16:41:15 UTC): Looks nice!

potiuk on (2024-11-29 19:02:18 UTC): Indeed!

"
2705221207,pull_request,closed,,feat: automatically inject OL info into spark job in DataprocSubmitJobOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR introduces a completely new feature to OpenLineage integration. **It will NOT impact users that are not using OpenLineage or have not explicitly enabled this feature (False by default).**

## TLDR; 
When explicitly enabled by the user for supported operators, we will automatically inject parent job information into the Spark job properties. For example, when submitting a Spark job using the DataprocSubmitJobOperator, we will include details about the Airflow task that triggered it so that the OpenLineage Spark integration can include them in parentRunFacet.

## Why ?

To enable full pipeline visibility and track dependencies between jobs in OpenLineage, we utilize the parentRunFacet. This facet stores the identifier of the parent job that triggered the current job. This approach works across various integrations, f.e. you can pass Airflow’s job identifier to a Spark application if it was triggered by an Airflow operator. Currently, this process requires manual configuration by the user, such as leveraging [macros](https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/macros.html):
```
DataprocSubmitJobOperator(
    task_id=""my_task"", 
    # ... 
    job={ 
        # ...
        ""spark.openlineage.parentJobNamespace"": ""{{ macros.OpenLineageProviderPlugin.lineage_job_namespace() }}"",
        ""spark.openlineage.parentJobName"": ""{{ macros.OpenLineageProviderPlugin.lineage_job_name(task_instance) }}"", 
        ""spark.openlineage.parentRunId"": ""{{ macros.OpenLineageProviderPlugin.lineage_run_id(task_instance) }}""
    } 
)

```
Understanding how various Airflow operators configure Spark allows us to automatically inject parent job information.

## Controlling the Behavior

We provide users with a flexible control mechanism to manage this injection, combining per-operator enablement with a global fallback configuration. This design is inspired by the `deferrable` argument in Airflow.

```python
ol_inject_parent_job_info: bool = conf.getboolean(
    ""openlineage"", ""spark_inject_parent_job_info"", fallback=False
)
```
Each supported operator will include an argument like `ol_inject_parent_job_info`, which defaults to the global configuration value of `openlineage.spark_inject_parent_job_info`. This approach allows users to:

1. Control behavior on a per-job basis by explicitly setting the argument.
2. Rely on a consistent default configuration for all jobs if the argument is not set.

This design ensures both flexibility and ease of use, enabling users to fine-tune their workflows while minimizing repetitive configuration. I am aware that adding an OpenLineage-related argument to the operator will affect all users, even those not using OpenLineage, but since it defaults to False and can be ignored, I hope this will not pose any issues.

## How?
The implementation is divided into three parts for better organization and clarity:

1. **Operator's Code (including the `execute` method):**  
   Contains minimal logic to avoid overwhelming users who are not actively working with OpenLineage.

2. **Google's Provider OpenLineage Utils File:**  
   Handles the logic for accessing Spark properties specific to a given operator or job.

3. **OpenLineage Provider's Utils:**  
   Responsible for creating / extracting all necessary information in a format compatible with the OpenLineage Spark integration. We are also performing modifications to the Spark properties here.

For some operators parts 1 and 2 may be in the operator's code. In general, the specific operator / provider will know how to get the spark properties and the OL will know what to inject and do the injection itself.

## Next steps
1. **Expand Operator Coverage:**  
   Increase support for additional operators by extending the parent job information injection to cover more cases.

2. **Automate Transport Configuration:**  
   Implement similar automation for transport configurations, starting with HTTP, to streamline the integration process.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-11-29 14:04:36+00:00,[],2024-12-19 13:01:12+00:00,2024-12-19 13:00:43+00:00,https://github.com/apache/airflow/pull/44477,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:openlineage', 'AIP-53'), ('provider:common-compat', '')]","[{'comment_id': 2517269215, 'issue_id': 2705221207, 'author': 'ahidalgob', 'body': 'Hi, are we planning on also emitting the lineage events from Airflow itself? I think we have other services that emit lineage (for example, BigQuery) where we also still emit this lineage from Airflow. For example, in Composer, we generate the events based on the SQL query of Hive, SparkSQL, Presto and Trino jobs.', 'created_at': datetime.datetime(2024, 12, 4, 12, 53, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517427061, 'issue_id': 2705221207, 'author': 'kacpermuda', 'body': ""Hey @ahidalgob, just to confirm I understand you correctly: are you asking if we plan to emit the lineage from the child job (in this case, Spark) directly from Airflow? As of now, there aren’t any plans for that that I'm aware of. In my opinion, it’s a bit more complex to implement compared to a SQL-based approach, where we can parse the SQL on the Airflow side and occasionally patch it with API calls to BigQuery or similar solutions. Extracting lineage from a Spark jar, which can do virtually anything, is more challenging. For now, I’m focusing on making it easier for users to configure Spark integration, without changing the entity responsible for emitting the events."", 'created_at': datetime.datetime(2024, 12, 4, 13, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517594409, 'issue_id': 2705221207, 'author': 'ahidalgob', 'body': ""Hi @kacpermuda , what I meant was exactly this you describe: parsing the SQL query on Airflow side and generating the inputs/outputs. Right now this PR only as you confirmed only configures how Spark generates the lineage events but doesn't generate from Airflow side, right?"", 'created_at': datetime.datetime(2024, 12, 4, 14, 26, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517639918, 'issue_id': 2705221207, 'author': 'kacpermuda', 'body': 'Correct, this feature is only about automatically passing some OpenLineage information from Airflow to Spark to automate the process of configuring the OpenLineage/Spark integration.', 'created_at': datetime.datetime(2024, 12, 4, 14, 43, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519832092, 'issue_id': 2705221207, 'author': 'ahidalgob', 'body': 'Thanks @kacpermuda, we would like to contribute the logic we used in Composer to generate the events from the SQL queries in other DataprocSubmitJob types. I think this PR and what we want to contribute are not incompatible, does it sound good to you? (also @mobuchowski )', 'created_at': datetime.datetime(2024, 12, 5, 10, 5, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519920387, 'issue_id': 2705221207, 'author': 'mobuchowski', 'body': ""@ahidalgob I don't think that's right, since you can submit JAR with arbitrary code rather than just SQL. Also, even for SQL jobs, rather than using parser (which is a best effort solution) we can use Spark integration that actually understands the uploaded jobs. Airflow events here can contribute proper hierarchy."", 'created_at': datetime.datetime(2024, 12, 5, 10, 33, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532232417, 'issue_id': 2705221207, 'author': 'kacpermuda', 'body': ""The failing trino test comes from changes made in #44717. Waiting for the fixing PR as it's on the way by the author."", 'created_at': datetime.datetime(2024, 12, 10, 16, 34, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541737829, 'issue_id': 2705221207, 'author': 'michalmodras', 'body': ""To make sure I understand the target state:\r\n- With Kacper's changes, some additional metadata about parent job (Airflow DAG / task in this case) will be passed to the Spark job, and emitted in an OpenLineage event to OpenLineage-supporting-catalog by the Spark job itself.\r\n- Regardless of that, OpenLineage event at the Airflow level can/will be emitted.\r\n\r\nI think it's fair for each layer of orchestration to emit metadata that it has access to, for example depending on the Spark job type/implementation, the low level information about Spark execution, or, in case of Airflow, information about DAG/task/Airflow deployment. \r\n\r\nFor Airflow itself, to construct such lineage event, Airflow needs to be aware of the input/output assets (as long as we cannot link lineage events only by process identifier). SQL parsing can be a way to get this information for SQL-like jobs, in case of other types of jobs (not necessarily Spark jobs) we can for example query the service the operator is integrated with (e.g. with BigQuery jobs - we could query BigQuery API to get that information and emit event linking input/output assets with BigQuery job id, and DAG/Task/Airflow deployment id)."", 'created_at': datetime.datetime(2024, 12, 13, 15, 47, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2544816446, 'issue_id': 2705221207, 'author': 'kacpermuda', 'body': ""> To make sure I understand the target state:\r\n> \r\n> With Kacper's changes, some additional metadata about parent job (Airflow DAG / task in this case) will be passed to the Spark job, and emitted in an OpenLineage event to OpenLineage-supporting-catalog by the Spark job itself.\r\nRegardless of that, OpenLineage event at the Airflow level can/will be emitted.\r\n\r\nCorrect, that is the target state in my opinion, Airflow events will still be emitted without any changes. For now we are simply automating the transfer of some additional information to Spark integration (but people have been doing this manually until now with OL provided macros)."", 'created_at': datetime.datetime(2024, 12, 16, 7, 40, 53, tzinfo=datetime.timezone.utc)}]","ahidalgob on (2024-12-04 12:53:47 UTC): Hi, are we planning on also emitting the lineage events from Airflow itself? I think we have other services that emit lineage (for example, BigQuery) where we also still emit this lineage from Airflow. For example, in Composer, we generate the events based on the SQL query of Hive, SparkSQL, Presto and Trino jobs.

kacpermuda (Issue Creator) on (2024-12-04 13:37:54 UTC): Hey @ahidalgob, just to confirm I understand you correctly: are you asking if we plan to emit the lineage from the child job (in this case, Spark) directly from Airflow? As of now, there aren’t any plans for that that I'm aware of. In my opinion, it’s a bit more complex to implement compared to a SQL-based approach, where we can parse the SQL on the Airflow side and occasionally patch it with API calls to BigQuery or similar solutions. Extracting lineage from a Spark jar, which can do virtually anything, is more challenging. For now, I’m focusing on making it easier for users to configure Spark integration, without changing the entity responsible for emitting the events.

ahidalgob on (2024-12-04 14:26:05 UTC): Hi @kacpermuda , what I meant was exactly this you describe: parsing the SQL query on Airflow side and generating the inputs/outputs. Right now this PR only as you confirmed only configures how Spark generates the lineage events but doesn't generate from Airflow side, right?

kacpermuda (Issue Creator) on (2024-12-04 14:43:57 UTC): Correct, this feature is only about automatically passing some OpenLineage information from Airflow to Spark to automate the process of configuring the OpenLineage/Spark integration.

ahidalgob on (2024-12-05 10:05:58 UTC): Thanks @kacpermuda, we would like to contribute the logic we used in Composer to generate the events from the SQL queries in other DataprocSubmitJob types. I think this PR and what we want to contribute are not incompatible, does it sound good to you? (also @mobuchowski )

mobuchowski on (2024-12-05 10:33:33 UTC): @ahidalgob I don't think that's right, since you can submit JAR with arbitrary code rather than just SQL. Also, even for SQL jobs, rather than using parser (which is a best effort solution) we can use Spark integration that actually understands the uploaded jobs. Airflow events here can contribute proper hierarchy.

kacpermuda (Issue Creator) on (2024-12-10 16:34:10 UTC): The failing trino test comes from changes made in #44717. Waiting for the fixing PR as it's on the way by the author.

michalmodras on (2024-12-13 15:47:02 UTC): To make sure I understand the target state:
- With Kacper's changes, some additional metadata about parent job (Airflow DAG / task in this case) will be passed to the Spark job, and emitted in an OpenLineage event to OpenLineage-supporting-catalog by the Spark job itself.
- Regardless of that, OpenLineage event at the Airflow level can/will be emitted.

I think it's fair for each layer of orchestration to emit metadata that it has access to, for example depending on the Spark job type/implementation, the low level information about Spark execution, or, in case of Airflow, information about DAG/task/Airflow deployment. 

For Airflow itself, to construct such lineage event, Airflow needs to be aware of the input/output assets (as long as we cannot link lineage events only by process identifier). SQL parsing can be a way to get this information for SQL-like jobs, in case of other types of jobs (not necessarily Spark jobs) we can for example query the service the operator is integrated with (e.g. with BigQuery jobs - we could query BigQuery API to get that information and emit event linking input/output assets with BigQuery job id, and DAG/Task/Airflow deployment id).

kacpermuda (Issue Creator) on (2024-12-16 07:40:53 UTC): Regardless of that, OpenLineage event at the Airflow level can/will be emitted.

Correct, that is the target state in my opinion, Airflow events will still be emitted without any changes. For now we are simply automating the transfer of some additional information to Spark integration (but people have been doing this manually until now with OL provided macros).

"
2704675090,pull_request,closed,,refactor(trigger_rule): remove deprecated NONE_FAILED_OR_SKIPPED,"## Why
as stated in https://github.com/apache/airflow/blob/b882246702ccb040243db803c08d2097d67283a5/RELEASE_NOTES.rst?plain=1#L4935, this should be removed

## What
remove deprecated `TriggerRule.NONE_FAILED_OR_SKIPPED`
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-29 10:35:17+00:00,['Lee-W'],2024-11-30 06:09:25+00:00,2024-11-30 06:09:25+00:00,https://github.com/apache/airflow/pull/44475,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2704136354,pull_request,closed,,AIP-72: Matching the test naming convention to execution API endpoint,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Cleanup to #44449 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-29 06:56:56+00:00,['amoghrajesh'],2024-11-29 09:07:28+00:00,2024-11-29 09:07:27+00:00,https://github.com/apache/airflow/pull/44471,[],[],
2704131497,pull_request,closed,,Fix gantt flickering (issue #42215),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #42215


How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

remove the startDate, endDate from events that causes a reset since it causes infinite refresh loop

closes: #42215


",darkag,2024-11-29 06:54:44+00:00,[],2024-11-29 18:55:32+00:00,2024-11-29 14:15:03+00:00,https://github.com/apache/airflow/pull/44470,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2507702350, 'issue_id': 2704131497, 'author': 'darkag', 'body': 'Since""Please ask maintainer to assign the \'legacy ui\' label to the PR in order to continue"" if someone can assign the label', 'created_at': datetime.datetime(2024, 11, 29, 12, 16, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507904221, 'issue_id': 2704131497, 'author': 'darkag', 'body': 'ok too complicated for me', 'created_at': datetime.datetime(2024, 11, 29, 14, 15, 3, tzinfo=datetime.timezone.utc)}]","darkag (Issue Creator) on (2024-11-29 12:16:28 UTC): Since""Please ask maintainer to assign the 'legacy ui' label to the PR in order to continue"" if someone can assign the label

darkag (Issue Creator) on (2024-11-29 14:15:03 UTC): ok too complicated for me

"
2704121356,pull_request,closed,,Handle downloading github raw files gracefully for 403 status code,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

@eladkal recently ran into an issue:
```
Downloading constraints for all Airflow versions for Python 3.9

Downloading https://raw.githubusercontent.com/apache/airflow/constraints-2.0.0/constraints-3.9.txt to /Users/eladkal/PycharmProjects/airflow/.build/constraints/constraints-2.0.0-python-3.9.txt
https://raw.githubusercontent.com/apache/airflow/constraints-2.0.0/constraints-3.9.txt could not be downloaded. Status code 403
Could not download constraints for Airflow 2.0.0 and Python 3.9
Downloading https://raw.githubusercontent.com/apache/airflow/constraints-2.0.1/constraints-3.9.txt to /Users/eladkal/PycharmProjects/airflow/.build/constraints/constraints-2.0.1-python-3.9.txt
https://raw.githubusercontent.com/apache/airflow/constraints-2.0.1/constraints-3.9.txt could not be downloaded. Status code 403
Could not download constraints for Airflow 2.0.1 and Python 3.9
Downloading https://raw.githubusercontent.com/apache/airflow/constraints-2.0.2/constraints-3.9.txt to /Users/eladkal/PycharmProjects/airflow/.build/constraints/constraints-2.0.2-python-3.9.txt
https://raw.githubusercontent.com/apache/airflow/constraints-2.0.2/constraints-3.9.txt could not be downloaded. Status code 403
Could not download constraints for Airflow 2.0.2 and Python 3.9
Downloading https://raw.githubusercontent.com/apache/airflow/constraints-2.1.0/constraints-3.9.txt to /Users/eladkal/PycharmProjects/airflow/.build/constraints/constraints-2.1.0-python-3.9.txt
https://raw.githubusercontent.com/apache/airflow/constraints-2.1.0/constraints-3.9.txt could not be downloaded. Status code 403
Could not download constraints for Airflow 2.1.0 and Python 3.9
....
```
Then

```
multiprocessing.pool.RemoteTraceback:
""""""
Traceback (most recent call last):
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.11.6/lib/python3.11/multiprocessing/pool.py"", line 125, in worker
    result = (True, func(*args, **kwds))
                    ^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.11.6/lib/python3.11/multiprocessing/pool.py"", line 48, in mapstar
    return list(map(*args))
           ^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/PycharmProjects/airflow/dev/breeze/src/airflow_breeze/utils/provider_dependencies.py"", line 83, in generate_providers_metadata_for_package
    if constraints[airflow_version].get(package_name) == provider_version:
       ~~~~~~~~~~~^^^^^^^^^^^^^^^^^
KeyError: '2.0.0'
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/eladkal/.local/bin/breeze"", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/rich_click/rich_command.py"", line 367, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/rich_click/rich_command.py"", line 152, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/PycharmProjects/airflow/dev/breeze/src/airflow_breeze/commands/release_management_commands.py"", line 2614, in generate_providers_metadata
    results = pool.map(
              ^^^^^^^^^
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.11.6/lib/python3.11/multiprocessing/pool.py"", line 367, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.11.6/lib/python3.11/multiprocessing/pool.py"", line 774, in get
    raise self._value
KeyError: '2.0.0'
```

On debugging we realised that its because of VPN! This revealed that we do not handle 403 well. This PR fixes that

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-29 06:52:23+00:00,[],2024-12-02 06:46:03+00:00,2024-12-02 06:46:03+00:00,https://github.com/apache/airflow/pull/44469,"[('area:dev-tools', '')]","[{'comment_id': 2509472199, 'issue_id': 2704121356, 'author': 'potiuk', 'body': 'Rebased to account for the workaround in `main`.', 'created_at': datetime.datetime(2024, 11, 30, 23, 8, 49, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-30 23:08:49 UTC): Rebased to account for the workaround in `main`.

"
2703819569,pull_request,closed,,fix(provider/edge): add back mising method map,"## Why
https://github.com/apache/airflow/pull/44462 seems to break the CI

e.g., https://github.com/apache/airflow/actions/runs/12076537283/job/33678186253?pr=44466

## What
Add back the methods defined previously


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-29 04:25:04+00:00,['Lee-W'],2024-11-29 10:32:39+00:00,2024-11-29 05:48:35+00:00,https://github.com/apache/airflow/pull/44468,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2507070204, 'issue_id': 2703819569, 'author': 'Lee-W', 'body': ""I'm not sure whether it's the correct fix, though. or should we just remove the `functions` variable?\r\n\r\n@potiuk"", 'created_at': datetime.datetime(2024, 11, 29, 4, 28, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507204435, 'issue_id': 2703819569, 'author': 'potiuk', 'body': '> (@potiuk was throwing the stone into the window :-D)\r\n\r\nIndeed. I was. Calling for glass-maker now', 'created_at': datetime.datetime(2024, 11, 29, 7, 3, 53, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-11-29 04:28:05 UTC): I'm not sure whether it's the correct fix, though. or should we just remove the `functions` variable?

@potiuk

potiuk on (2024-11-29 07:03:53 UTC): Indeed. I was. Calling for glass-maker now

"
2703461603,pull_request,closed,,Fix yoda-conditions,"Yoda conditions revert expected / checked values. We are adding ruff rule to avoid them.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-28 23:26:49+00:00,[],2024-11-29 07:54:30+00:00,2024-11-29 07:54:28+00:00,https://github.com/apache/airflow/pull/44466,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2507264188, 'issue_id': 2703461603, 'author': 'potiuk', 'body': 'Like it is ready to merge, looks,It, so I will do.', 'created_at': datetime.datetime(2024, 11, 29, 7, 54, 15, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-29 07:54:15 UTC): Like it is ready to merge, looks,It, so I will do.

"
2703344374,pull_request,closed,,AIP-72: Add escalation path for killing process in Supervisor,"Added logic to support escalation from SIGINT to SIGTERM and SIGKILL when killing a task process from the new Supervisor process. 

part of https://github.com/apache/airflow/issues/44356

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-28 22:01:45+00:00,[],2024-11-30 16:16:29+00:00,2024-11-30 16:16:26+00:00,https://github.com/apache/airflow/pull/44465,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2703328906,pull_request,closed,,AIP-79 Support Airflow 2.x plugins in fast api,"To support Airflow 2.x plugins in Airflow 3 the goal is to embed a minimal version of Airflow 2 in fast api using [WSGIMiddleware](https://fastapi.tiangolo.com/advanced/wsgi/). The Airflow 2.x plugins will run in this application as they are running today in Airflow 2. `WSGIMiddleware` allows running a WSGI in the fast api application. This Flask application will be accessible under the path `/pluginsv2`.

The plan is to:
1. (This PR) Copy files from core Airflow to Fab provider to create a minimal version of Airflow 2 in Fab provider. This minimal version of Airflow 2 should only contain core elements needed by the plugins to run. The goal is not to copy the entire Flask application but only a more simplified version of it. This minimal version of Airflow 2 in Fab provider should be self contained in Fab provider, they must not depend on Flask-related objects defined in core Airflow. The goal is, when the Flask application will be deleted from core Airflow, it should be possible because the mini Airflow 2 in Fab provider does not depend on it.
2. (This PR as well) Embed the mini Airflow 2 defined in Fab provider in the fast api application so that Airflow 2.x plugins will be available in Airflow 3
3. When the new Airflow 3 UI becomes the default UI and no fallback to the old UI is possible, remove the Flask application and all related resources (e.g. views) from core Airflow. 

The idea is, if you do not have any Airflow 2.x plugin defined in your environment, you should not have Flask as dependency. On the opposite, if you do have some Airflow 2.x plugins in your environment, fab provider will have to be installed and all the code needed to run the Flask application will be in this provider.

The experience for the user will not be ideal because these plugins use the Airflow 2 UI, therefore the UI experience will be inconsistent between the Airflow pages (Airflow 3 UI) and the plugins (Airflow 2 UI). A warning message will be added in the embedded Flask application to let the user knows about this weird experience but also to recommend them to migrate their plugins to Airflow 3 plugins.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-28 21:47:22+00:00,[],2024-12-06 18:42:29+00:00,2024-12-06 18:41:22+00:00,https://github.com/apache/airflow/pull/44464,"[('area:webserver', 'Webserver related Issues'), ('area:plugins', '')]","[{'comment_id': 2506783732, 'issue_id': 2703328906, 'author': 'vincbeck', 'body': '@jedcunningham', 'created_at': datetime.datetime(2024, 11, 28, 21, 47, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509166409, 'issue_id': 2703328906, 'author': 'jedcunningham', 'body': ""Instead of waiting for #2 to happen, let's just copy/trim whatever minimal FAB stuff we need into the FAB provider now - just leave it completely separate from the old UI. Then we aren't blocked at all."", 'created_at': datetime.datetime(2024, 11, 30, 19, 31, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511890607, 'issue_id': 2703328906, 'author': 'vincbeck', 'body': ""> Instead of waiting for #2 to happen, let's just copy/trim whatever minimal FAB stuff we need into the FAB provider now - just leave it completely separate from the old UI. Then we aren't blocked at all.\r\n\r\nThat sounds good to me. That's a good idea indeed, we can save some time by doing this. Should we do it in a separate PR though? This one sets up the mechanism to embed Airflow 2 in Airflow 3 and the other PR(s) would be copying over the Flask app to Fab provider"", 'created_at': datetime.datetime(2024, 12, 2, 15, 44, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511999535, 'issue_id': 2703328906, 'author': 'jedcunningham', 'body': 'I\'d kinda prefer we don\'t mount the ""whole"" AF2 app as-is in AF3, even if we do view it as temporary.', 'created_at': datetime.datetime(2024, 12, 2, 16, 16, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512158245, 'issue_id': 2703328906, 'author': 'vincbeck', 'body': '> I\'d kinda prefer we don\'t mount the ""whole"" AF2 app as-is in AF3, even if we do view it as temporary.\r\n\r\nAlright, I\'ll do it in this PR then', 'created_at': datetime.datetime(2024, 12, 2, 16, 57, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515494838, 'issue_id': 2703328906, 'author': 'vincbeck', 'body': 'This is a preview of the page when accessing a plugin.\r\n\r\nURL is `<fast_api_endpoint>/pluginsv2/`\r\n\r\n<img width=""1720"" alt=""Screenshot 2024-12-03 at 3 31 25\u202fPM"" src=""https://github.com/user-attachments/assets/8bc2be87-1f7d-49bb-af60-944fa1f23fe6"">', 'created_at': datetime.datetime(2024, 12, 3, 20, 32, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2520498376, 'issue_id': 2703328906, 'author': 'vincbeck', 'body': '> Can we also reuse that same application to do the flask auth server ? (When people are use FABAuthManager and we need to reach for the flask webserver) ?\r\n\r\nI was wondering the same and I think we should do that', 'created_at': datetime.datetime(2024, 12, 5, 14, 36, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2521377452, 'issue_id': 2703328906, 'author': 'vincbeck', 'body': 'Tests are passing, let me know if there are more comments/feedbacks', 'created_at': datetime.datetime(2024, 12, 5, 20, 50, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2523936089, 'issue_id': 2703328906, 'author': 'jedcunningham', 'body': 'Whoo! Nice!', 'created_at': datetime.datetime(2024, 12, 6, 18, 42, 29, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-11-28 21:47:57 UTC): @jedcunningham

jedcunningham on (2024-11-30 19:31:17 UTC): Instead of waiting for #2 to happen, let's just copy/trim whatever minimal FAB stuff we need into the FAB provider now - just leave it completely separate from the old UI. Then we aren't blocked at all.

vincbeck (Issue Creator) on (2024-12-02 15:44:53 UTC): That sounds good to me. That's a good idea indeed, we can save some time by doing this. Should we do it in a separate PR though? This one sets up the mechanism to embed Airflow 2 in Airflow 3 and the other PR(s) would be copying over the Flask app to Fab provider

jedcunningham on (2024-12-02 16:16:27 UTC): I'd kinda prefer we don't mount the ""whole"" AF2 app as-is in AF3, even if we do view it as temporary.

vincbeck (Issue Creator) on (2024-12-02 16:57:29 UTC): Alright, I'll do it in this PR then

vincbeck (Issue Creator) on (2024-12-03 20:32:41 UTC): This is a preview of the page when accessing a plugin.

URL is `<fast_api_endpoint>/pluginsv2/`

<img width=""1720"" alt=""Screenshot 2024-12-03 at 3 31 25 PM"" src=""https://github.com/user-attachments/assets/8bc2be87-1f7d-49bb-af60-944fa1f23fe6"">

vincbeck (Issue Creator) on (2024-12-05 14:36:42 UTC): I was wondering the same and I think we should do that

vincbeck (Issue Creator) on (2024-12-05 20:50:10 UTC): Tests are passing, let me know if there are more comments/feedbacks

jedcunningham on (2024-12-06 18:42:29 UTC): Whoo! Nice!

"
2703319925,pull_request,closed,,Swap internal RPC server for API server in the helm chart,"Previously the PRC server was possible to disable/enable, where as now the new
api-server is a required component in Airflow 3.0+

This also does a little bit of drive-by refactoring of the helper templates
for service account name generation

I'm not 100% sure what ""default"" version is the tests, so maybe me adding a parameterization for ""3.0.0"" is not right. I also don't know what version we set it the kube/helm tests we run against main etc. 

Part of https://github.com/apache/airflow/issues/44436 (and needed to fix main after #44427 was merged)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-28 21:38:50+00:00,[],2025-02-05 15:52:02+00:00,2024-11-29 17:49:18+00:00,https://github.com/apache/airflow/pull/44463,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2506797751, 'issue_id': 2703319925, 'author': 'ashb', 'body': ""Looks like I've got a lot more tests to fix up though!"", 'created_at': datetime.datetime(2024, 11, 28, 21, 59, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506802096, 'issue_id': 2703319925, 'author': 'potiuk', 'body': ""> Looks like I've got a lot more tests to fix up though!\r\n\r\nThe more he looked inside the more Piglet wasn’t there."", 'created_at': datetime.datetime(2024, 11, 28, 22, 6, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506824544, 'issue_id': 2703319925, 'author': 'ashb', 'body': '""Tests / Kubernetes tests / K8S System:LocalExecutor - false - v1.28.13 (pull_request)"" is still failing which is really unfortunate, I was hoping that would pass.', 'created_at': datetime.datetime(2024, 11, 28, 22, 36, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507188546, 'issue_id': 2703319925, 'author': 'amoghrajesh', 'body': ""This test needs fixing too:\r\n```\r\nFAILED helm_tests/security/test_rbac.py::TestRBAC::test_deployments_no_rbac_no_sa[3.0.0] - AssertionError: assert equals failed\r\n    (                                (                             \r\n      'Service',                       'Service',                  \r\n      'test-rbac-worker',              'test-rbac-worker',         \r\n    ),                               ),                            \r\n    (                                (                             \r\n                                       'ServiceAccount',           \r\n                                       'test-rbac-api-server',     \r\n                                     ),                            \r\n                                     (                             \r\n      'StatefulSet',                   'StatefulSet',              \r\n      'test-rbac-postgresql',          'test-rbac-postgresql',     \r\n    ),                               ),                            \r\n    (                                (                             \r\n      'StatefulSet',                   'StatefulSet',\r\n```"", 'created_at': datetime.datetime(2024, 11, 29, 6, 49, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507627248, 'issue_id': 2703319925, 'author': 'ashb', 'body': 'Okay, the ""Tests / Kubernetes tests / K8S System:LocalExecutor"" tests aren\'t passing because we aren\'t passing an `airflowVersion` in the values.', 'created_at': datetime.datetime(2024, 11, 29, 11, 31, 3, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-11-28 21:59:07 UTC): Looks like I've got a lot more tests to fix up though!

potiuk on (2024-11-28 22:06:23 UTC): The more he looked inside the more Piglet wasn’t there.

ashb (Issue Creator) on (2024-11-28 22:36:25 UTC): ""Tests / Kubernetes tests / K8S System:LocalExecutor - false - v1.28.13 (pull_request)"" is still failing which is really unfortunate, I was hoping that would pass.

amoghrajesh on (2024-11-29 06:49:07 UTC): This test needs fixing too:
```
FAILED helm_tests/security/test_rbac.py::TestRBAC::test_deployments_no_rbac_no_sa[3.0.0] - AssertionError: assert equals failed
    (                                (                             
      'Service',                       'Service',                  
      'test-rbac-worker',              'test-rbac-worker',         
    ),                               ),                            
    (                                (                             
                                       'ServiceAccount',           
                                       'test-rbac-api-server',     
                                     ),                            
                                     (                             
      'StatefulSet',                   'StatefulSet',              
      'test-rbac-postgresql',          'test-rbac-postgresql',     
    ),                               ),                            
    (                                (                             
      'StatefulSet',                   'StatefulSet',
```

ashb (Issue Creator) on (2024-11-29 11:31:03 UTC): Okay, the ""Tests / Kubernetes tests / K8S System:LocalExecutor"" tests aren't passing because we aren't passing an `airflowVersion` in the values.

"
2703263333,pull_request,closed,,Remove internal-api command,"This PR removes CLI and openapi specification for the API.

Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-28 21:23:13+00:00,[],2024-11-28 22:36:42+00:00,2024-11-28 22:36:40+00:00,https://github.com/apache/airflow/pull/44462,"[('area:CLI', ''), ('area:dev-tools', '')]",[],
2702918180,pull_request,closed,,AIP-84 Introduce SessionDep construct,Introduce `SessionDep` and `AsyncSessionDep` contructs to match the `TokenDep` that we have for the task_execution API. This is cleaner and more concise.,pierrejeambrun,2024-11-28 18:13:10+00:00,['pierrejeambrun'],2024-11-29 09:42:52+00:00,2024-11-29 09:42:50+00:00,https://github.com/apache/airflow/pull/44461,"[('area:dev-tools', ''), ('AIP-84', 'Modern Rest API')]",[],
2702910609,pull_request,closed,,Fix issues reported by ruff team before new ruff rules are out,"Ruff team is using Airflow as one of the ""ecosystem"" benchmarks for new rules they developed and reported the issues to us in the #44455 discussion. This PR addresses those issues that are still there (some of the reported tests were removed earlier today when we removed AIP-44 code in #44454

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-28 18:06:46+00:00,[],2024-11-28 19:17:13+00:00,2024-11-28 19:17:11+00:00,https://github.com/apache/airflow/pull/44460,"[('provider:google', 'Google (including GCP) related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API"")]",[],
2702878665,pull_request,closed,,AIP-84 Graph Data update datamodel,"Related to: https://github.com/apache/airflow/issues/42366

Subpart of: https://github.com/apache/airflow/issues/42367

Update the graph datamodel to comply with what is expected from https://github.com/apache/airflow/issues/42367

This does not yet introduce the new feature of `show_external_dependencies` to show connected datasets, dataset conditions, triggers and sensors. This will come in a follow up PR because it has enough complexity on it's own.",pierrejeambrun,2024-11-28 17:44:24+00:00,['pierrejeambrun'],2024-12-02 15:27:30+00:00,2024-12-02 15:27:28+00:00,https://github.com/apache/airflow/pull/44459,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('area:task-sdk', None)]",[],
2702684022,pull_request,closed,,Add backward compatibility check for StartTriggerArgs import in filesystem sensor,"Fixes the import issue reported in #44324 for `filesystem` sensor in `apache-airflow<2.10.0`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-11-28 16:34:27+00:00,[],2024-11-28 17:58:09+00:00,2024-11-28 17:58:09+00:00,https://github.com/apache/airflow/pull/44458,"[('area:providers', ''), ('provider:standard', '')]",[],
2702667226,pull_request,closed,,Fix wrong display of multiline messages in the log after filtering,"closes: #41265

### Issue Context
After research, the issue is caused by `airflow/www/static/js/dag/details/taskInstance/Logs/utils.ts`, the API just return the full raw logs.
Additionally, incorrect display behavior also occurs when filtering by file source.

### Main Fix Idea
The `currentLogLevel` and `currentFileSource` should remain same until a new `logLevel` or `fileSource` is encountered.

### Screenshot After Fix

**Without any filters**
<img width=""1401"" alt=""Without any filters"" src=""https://github.com/user-attachments/assets/6297f0ce-1337-4185-b0c5-8c4585b8fbc8"">
**Filter with level**
<img width=""1402"" alt=""Filter with level"" src=""https://github.com/user-attachments/assets/70458852-25d3-461f-b5c7-c8665907bb7f"">
**Filter with file source**
<img width=""1340"" alt=""Filter with file source"" src=""https://github.com/user-attachments/assets/06f7a866-9389-4a3c-9ed5-cc21b4aafc51"">
**Filter with level and file source**
<img width=""1380"" alt=""Filter with level and file source"" src=""https://github.com/user-attachments/assets/c158d48a-26a4-4d2f-98b6-102f3bd85e41"">


",jason810496,2024-11-28 16:24:43+00:00,[],2024-12-04 08:46:35+00:00,2024-12-03 13:35:19+00:00,https://github.com/apache/airflow/pull/44457,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2506476530, 'issue_id': 2702667226, 'author': 'jason810496', 'body': 'Hi @Lee-W, I think this issue should be back ported to `2.9.x`, `2.8.x`, and `2.7.x` and also fixed on the latest `main` branch once it is merged. Does that sound correct?', 'created_at': datetime.datetime(2024, 11, 28, 16, 30, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506484763, 'issue_id': 2702667226, 'author': 'pierrejeambrun', 'body': ""> Hi @Lee-W, I think this issue should be back ported to 2.9.x, 2.8.x, and 2.7.x\r\n\r\nWe do not backport to released versions. (unless critical security fixes but I haven't seen that happen before).\r\n\r\nThis will most likely be in the next patch release of `2.10.x`, people will have to upgrade to get it."", 'created_at': datetime.datetime(2024, 11, 28, 16, 35, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506988596, 'issue_id': 2702667226, 'author': 'Lee-W', 'body': 'Thanks @pierrejeambrun ! \r\n\r\n@jason810496 To create a ""backport"" PR to 2.10.x, you\'ll need to branch out from `v2-10-test`. In case you\'ve not yet tried it 🙂', 'created_at': datetime.datetime(2024, 11, 29, 2, 36, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507685349, 'issue_id': 2702667226, 'author': 'potiuk', 'body': '> @jason810496 To create a ""backport"" PR to 2.10.x, you\'ll need to branch out from `v2-10-test`. In case you\'ve not yet tried it 🙂\r\n\r\nActually we now have cherry-picker - and we marked it with ""backport"" label, so the backport PR should be created automatically and if it is not possible, instructions what to do will be posted automatically here as comment :D', 'created_at': datetime.datetime(2024, 11, 29, 12, 8, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507818749, 'issue_id': 2702667226, 'author': 'pierrejeambrun', 'body': ""Main is too different now and do not have this issue because of structured logs. (json)\r\n\r\nI noticed that the PR directly targets `v2-10-test`. I think it's fine in this case.\r\n\r\n@potiuk @Lee-W are we fine with that ?"", 'created_at': datetime.datetime(2024, 11, 29, 13, 26, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508355223, 'issue_id': 2702667226, 'author': 'potiuk', 'body': ""> I noticed that the PR directly targets v2-10-test. I think it's fine in this case.\r\n\r\nI think yes, but - we need to make sure this one will be forward-ported (for lack of a better word) or determined not to be needed in main :D"", 'created_at': datetime.datetime(2024, 11, 29, 18, 55, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508840984, 'issue_id': 2702667226, 'author': 'jason810496', 'body': 'Refactored the test cases to include error cases with traceback.\r\n\r\n> I think we should also consider applying the colors to those lines. (only certain lines appear red.)\r\n\r\nThis has been addressed. Screenshot:\r\n![截圖 2024-11-30 下午1 30 11](https://github.com/user-attachments/assets/221ea48a-c81a-4444-abd3-ba707d0265bb)', 'created_at': datetime.datetime(2024, 11, 30, 5, 33, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511875270, 'issue_id': 2702667226, 'author': 'jason810496', 'body': 'Rebased to the latest `v2-10-test`. Looking forward to any advice or feedback before merging. \r\ncc @Lee-W , @pierrejeambrun', 'created_at': datetime.datetime(2024, 12, 2, 15, 38, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512184067, 'issue_id': 2702667226, 'author': 'pierrejeambrun', 'body': ""Thanks for the update @jason810496 I was really busy today, I'll do a review tomorrow. (but last time I checked it was looking nice :))"", 'created_at': datetime.datetime(2024, 12, 2, 17, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514404243, 'issue_id': 2702667226, 'author': 'jason810496', 'body': '> Looks good thanks.\r\n> \r\n> Some of the questions of the previous review are left un answered. Just for my comprehension, if do you mind giving me a few hints.\r\n\r\nSure!\r\n\r\n1. The `mockExtraLog` in the previous version was just a variable to reuse in the regex instead of directly adding `----...` to the regex. In the refactored version, I removed the regex and matched the expected result with `.toContain`, which is more readable than handling multiple different matches in a single regex.\r\n\r\n2. There was an empty newline in the previous version of the test cases, causing an empty line in `parsedLogs`. This issue is resolved in the current version:\r\n   ```js\r\n   // Previous version with an empty line:\r\n   const mockLog = `line 1\r\n   line2\r\n   `;\r\n\r\n   // Current version without an empty line:\r\n   const mockLog = `line 1\r\n   line 2`;\r\n   ```\r\n\r\n3. Updated the comments for the new regex in the current version.', 'created_at': datetime.datetime(2024, 12, 3, 12, 16, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514575148, 'issue_id': 2702667226, 'author': 'pierrejeambrun', 'body': 'Great thanks @jason810496 for the details.', 'created_at': datetime.datetime(2024, 12, 3, 13, 35, 12, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-11-28 16:30:23 UTC): Hi @Lee-W, I think this issue should be back ported to `2.9.x`, `2.8.x`, and `2.7.x` and also fixed on the latest `main` branch once it is merged. Does that sound correct?

pierrejeambrun on (2024-11-28 16:35:58 UTC): We do not backport to released versions. (unless critical security fixes but I haven't seen that happen before).

This will most likely be in the next patch release of `2.10.x`, people will have to upgrade to get it.

Lee-W on (2024-11-29 02:36:40 UTC): Thanks @pierrejeambrun ! 

@jason810496 To create a ""backport"" PR to 2.10.x, you'll need to branch out from `v2-10-test`. In case you've not yet tried it 🙂

potiuk on (2024-11-29 12:08:07 UTC): Actually we now have cherry-picker - and we marked it with ""backport"" label, so the backport PR should be created automatically and if it is not possible, instructions what to do will be posted automatically here as comment :D

pierrejeambrun on (2024-11-29 13:26:34 UTC): Main is too different now and do not have this issue because of structured logs. (json)

I noticed that the PR directly targets `v2-10-test`. I think it's fine in this case.

@potiuk @Lee-W are we fine with that ?

potiuk on (2024-11-29 18:55:22 UTC): I think yes, but - we need to make sure this one will be forward-ported (for lack of a better word) or determined not to be needed in main :D

jason810496 (Issue Creator) on (2024-11-30 05:33:29 UTC): Refactored the test cases to include error cases with traceback.


This has been addressed. Screenshot:
![截圖 2024-11-30 下午1 30 11](https://github.com/user-attachments/assets/221ea48a-c81a-4444-abd3-ba707d0265bb)

jason810496 (Issue Creator) on (2024-12-02 15:38:22 UTC): Rebased to the latest `v2-10-test`. Looking forward to any advice or feedback before merging. 
cc @Lee-W , @pierrejeambrun

pierrejeambrun on (2024-12-02 17:07:00 UTC): Thanks for the update @jason810496 I was really busy today, I'll do a review tomorrow. (but last time I checked it was looking nice :))

jason810496 (Issue Creator) on (2024-12-03 12:16:41 UTC): Sure!

1. The `mockExtraLog` in the previous version was just a variable to reuse in the regex instead of directly adding `----...` to the regex. In the refactored version, I removed the regex and matched the expected result with `.toContain`, which is more readable than handling multiple different matches in a single regex.

2. There was an empty newline in the previous version of the test cases, causing an empty line in `parsedLogs`. This issue is resolved in the current version:
   ```js
   // Previous version with an empty line:
   const mockLog = `line 1
   line2
   `;

   // Current version without an empty line:
   const mockLog = `line 1
   line 2`;
   ```

3. Updated the comments for the new regex in the current version.

pierrejeambrun on (2024-12-03 13:35:12 UTC): Great thanks @jason810496 for the details.

"
2702514083,pull_request,closed,,AIP-82 Handle paused DAGs,"In #43826 I did not take into consideration paused and non active DAGs. This PR handles these now. I also added tests to cover these scenarios. These tests fail without the fix (changes in `airflow/dag_processing/collection.py`).

Triggers defined as part of a paused DAG (or non active DAG) should not be created neither update assets when they fire.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-28 15:28:51+00:00,[],2024-12-09 16:11:19+00:00,2024-12-06 18:43:37+00:00,https://github.com/apache/airflow/pull/44456,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2702286251,pull_request,closed,,Remove AIP-44 configuration from the code,"This change removes all configuration that controls AIP-44 behaviour. It does not yet remove all the related code, this will be a follow up but it removes all the controls that determine if AIP-44 is enabled or not and removes all the Traceback Session/Disabling of DB session modifications that were used in ""database isolation"" mode. The ""database isolation"" mode has been disabled in #44441 so there was no easy way to enable it anyoway - this change removes the capability to use database isolation mode completely.

Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-28 14:11:02+00:00,[],2024-11-30 20:43:05+00:00,2024-11-28 17:29:13+00:00,https://github.com/apache/airflow/pull/44454,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:celery', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('provider:standard', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2506556608, 'issue_id': 2702286251, 'author': 'potiuk', 'body': 'K8S tests failure unrelated (work in progress to fix them). Merging.', 'created_at': datetime.datetime(2024, 11, 28, 17, 28, 53, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-28 17:28:53 UTC): K8S tests failure unrelated (work in progress to fix them). Merging.

"
2701549116,pull_request,closed,,Get workflow information in codeql workflow,"followup from this pr #44448
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-28 09:47:59+00:00,[],2024-11-28 11:30:49+00:00,2024-11-28 10:00:28+00:00,https://github.com/apache/airflow/pull/44450,"[('area:dev-tools', '')]","[{'comment_id': 2505694244, 'issue_id': 2701549116, 'author': 'amoghrajesh', 'body': '@gopidesupavan the CI fails', 'created_at': datetime.datetime(2024, 11, 28, 9, 52, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505702283, 'issue_id': 2701549116, 'author': 'gopidesupavan', 'body': '> @gopidesupavan the CI fails\r\n\r\nfixed :)', 'created_at': datetime.datetime(2024, 11, 28, 9, 55, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505900254, 'issue_id': 2701549116, 'author': 'potiuk', 'body': 'Ah nice !', 'created_at': datetime.datetime(2024, 11, 28, 11, 30, 48, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2024-11-28 09:52:03 UTC): @gopidesupavan the CI fails

gopidesupavan (Issue Creator) on (2024-11-28 09:55:58 UTC): fixed :)

potiuk on (2024-11-28 11:30:48 UTC): Ah nice !

"
2701449289,pull_request,closed,,AIP-72: Adding PUT Variable Endpoint for execution API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/44446
Adding an API to the execution API for ""setting"" or ""creating"" a variable, later to be used by task SDK

Examples from legacy API and this one:

1. Getting one variable using Legacy API:
![image](https://github.com/user-attachments/assets/5ea8c239-ef76-48f6-94ca-0786cfead109)


2. Getting one variable using execution API:
![image](https://github.com/user-attachments/assets/4a582a2c-ecc6-43ea-8330-92728ba83020)


3. Setting a variable using legacy API:
![image](https://github.com/user-attachments/assets/f4f07e9d-f1cf-445b-9cb9-16ac7c1bbd21)


4. Setting a variable using execution API:
![image](https://github.com/user-attachments/assets/7d6c94a3-6c91-4fe5-97a1-dd3a4f68a638)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-28 09:25:36+00:00,['amoghrajesh'],2024-11-29 06:37:46+00:00,2024-11-29 06:37:45+00:00,https://github.com/apache/airflow/pull/44449,"[('area:API', ""Airflow's REST/HTTP API""), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2701435520,pull_request,closed,,Passing down PR labels to codeql analysis too,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

We need to pass down the env variable for PR labels to the codeql analysis running per PR too. 
Failure example: https://github.com/apache/airflow/actions/runs/12065619780/job/33644782061?pr=43774


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-28 09:19:14+00:00,[],2024-11-28 09:39:05+00:00,2024-11-28 09:22:49+00:00,https://github.com/apache/airflow/pull/44448,"[('area:dev-tools', '')]",[],
2701219539,pull_request,closed,,Edge worker connected state is sent to DB based on worker sate,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
In the edge worker the set_state() method always sends the worker state by statsd as 1. So in case of graceful shut down, the worker state will remain 1 (connected).

This PR modifies the set_metrics method, so the worker is sent as connected if the worker state is not offline or unknown

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-11-28 07:59:52+00:00,[],2024-11-28 13:16:17+00:00,2024-11-28 13:16:17+00:00,https://github.com/apache/airflow/pull/44447,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2701085476,pull_request,closed,,Add 'airflow assets details' subcommand,Next one for https://github.com/apache/airflow/issues/42317.,uranusjr,2024-11-28 07:13:39+00:00,[],2024-11-29 02:05:31+00:00,2024-11-29 02:05:30+00:00,https://github.com/apache/airflow/pull/44445,"[('area:CLI', '')]","[{'comment_id': 2505414924, 'issue_id': 2701085476, 'author': 'Lee-W', 'body': ""hmmm... now you're PR need manul approval to run the CI as well 🤔"", 'created_at': datetime.datetime(2024, 11, 28, 7, 19, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505424657, 'issue_id': 2701085476, 'author': 'uranusjr', 'body': 'It’s been this way for a while now. I think it only applies to a couple of jobs; the main jobs (tests) still run automatically.', 'created_at': datetime.datetime(2024, 11, 28, 7, 26, 33, tzinfo=datetime.timezone.utc)}]","Lee-W on (2024-11-28 07:19:21 UTC): hmmm... now you're PR need manul approval to run the CI as well 🤔

uranusjr (Issue Creator) on (2024-11-28 07:26:33 UTC): It’s been this way for a while now. I think it only applies to a couple of jobs; the main jobs (tests) still run automatically.

"
2700698051,pull_request,closed,,Upgrading tomli to 2.2.1 as suggsested by CI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fixing build, error: https://github.com/apache/airflow/actions/runs/12061193471/job/33632853840


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-28 04:17:37+00:00,[],2024-11-28 07:00:34+00:00,2024-11-28 07:00:34+00:00,https://github.com/apache/airflow/pull/44444,[],[],
2700604438,pull_request,closed,,[v2-10-test] Fix problem with inability to remove fields from Connection form (#40421),"(cherry picked from commit 14bfe39298a2361ae34eac840aebae84063306ee)

Co-authored-by: Maksim <maksimy@google.com>",github-actions[bot],2024-11-28 03:12:44+00:00,[],2024-12-04 09:00:15+00:00,2024-11-28 03:51:34+00:00,https://github.com/apache/airflow/pull/44442,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2700432551,pull_request,closed,,Get rid of database isolation option,"As part of removing AIP-44 we remove database isolation mode and remove pytest markers that skipped some tests.

Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-28 01:54:08+00:00,[],2024-11-28 12:34:34+00:00,2024-11-28 12:34:34+00:00,https://github.com/apache/airflow/pull/44441,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', ''), ('provider:airbyte', ''), ('provider:arangodb', ''), ('provider:asana', ''), ('provider:apache-druid', ''), ('provider:apache-livy', '')]","[{'comment_id': 2505194199, 'issue_id': 2700432551, 'author': 'potiuk', 'body': ""Seems it's green."", 'created_at': datetime.datetime(2024, 11, 28, 3, 28, 13, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-28 03:28:13 UTC): Seems it's green.

"
2700265643,pull_request,closed,,Add do_xcom_push documentation in EcsRunTaskOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

Adding documentation for the do_xcom_push parameter in the EcsRunTaskOperator. This parameter pushes the ECS task ARN into XCom, and if AWS CloudWatch logs are fetched, it also adds the last log message to XCom with the key 'return_value'

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",leonidasefrem,2024-11-28 00:00:47+00:00,[],2024-11-28 02:16:15+00:00,2024-11-28 02:16:11+00:00,https://github.com/apache/airflow/pull/44440,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2505020286, 'issue_id': 2700265643, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 28, 0, 0, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505132310, 'issue_id': 2700265643, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 28, 2, 16, 14, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-28 00:00:51 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-28 02:16:14 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2700136411,pull_request,closed,,Remove AIP-44 related CI configuration and workflows,"Part of #44436

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-27 23:04:50+00:00,[],2024-11-28 01:03:19+00:00,2024-11-28 01:03:17+00:00,https://github.com/apache/airflow/pull/44437,"[('area:dev-tools', '')]","[{'comment_id': 2504967470, 'issue_id': 2700136411, 'author': 'gopidesupavan', 'body': 'Should we remove this now https://github.com/apache/airflow/blob/main/scripts/docker/entrypoint_ci.sh#L341 ?', 'created_at': datetime.datetime(2024, 11, 27, 23, 19, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504973463, 'issue_id': 2700136411, 'author': 'potiuk', 'body': '> Should we remove this now https://github.com/apache/airflow/blob/main/scripts/docker/entrypoint_ci.sh#L341 ?\r\n\r\nNext step. I will add  `database_isolation` removal as a point in #44436', 'created_at': datetime.datetime(2024, 11, 27, 23, 27, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504974606, 'issue_id': 2700136411, 'author': 'gopidesupavan', 'body': '> > Should we remove this now https://github.com/apache/airflow/blob/main/scripts/docker/entrypoint_ci.sh#L341 ?\r\n> \r\n> Next step. I will add `database_isolation` removal as a point in #44436\r\n\r\nah ok fine :)', 'created_at': datetime.datetime(2024, 11, 27, 23, 29, 6, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-27 23:19:18 UTC): Should we remove this now https://github.com/apache/airflow/blob/main/scripts/docker/entrypoint_ci.sh#L341 ?

potiuk (Issue Creator) on (2024-11-27 23:27:27 UTC): Next step. I will add  `database_isolation` removal as a point in #44436

gopidesupavan on (2024-11-27 23:29:06 UTC): ah ok fine :)

"
2700120650,pull_request,closed,,Upgrade github/codeql-action/ to V3,"codeql-action v2 is scheduled to deprecate on December 5th, 2024. We can upgrade now to v3.

https://github.com/apache/airflow/actions/runs/12059007076/job/33626839039?pr=44432

https://github.blog/changelog/2024-01-12-code-scanning-deprecation-of-codeql-action-v2/


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-27 22:54:20+00:00,[],2024-11-27 23:17:17+00:00,2024-11-27 23:16:20+00:00,https://github.com/apache/airflow/pull/44435,"[('area:dev-tools', '')]","[{'comment_id': 2504965066, 'issue_id': 2700120650, 'author': 'potiuk', 'body': 'Nice', 'created_at': datetime.datetime(2024, 11, 27, 23, 16, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-27 23:16:16 UTC): Nice

"
2700118352,pull_request,closed,,Migrate Edge calls for Worker to FastAPI part 4 - Cleanup,"After PR https://github.com/apache/airflow/pull/44311, https://github.com/apache/airflow/pull/44330 and #44433 this PR is a cleanup and removes the old Internal API extensions.

For review: Only the last commit is relevant, the other 7 are from referenced base PRs",jscheffl,2024-11-27 22:53:08+00:00,[],2024-12-01 12:34:47+00:00,2024-12-01 11:50:06+00:00,https://github.com/apache/airflow/pull/44434,"[('area:providers', ''), ('kind:documentation', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2509704262, 'issue_id': 2700118352, 'author': 'jscheffl', 'body': ""> There is some devilish trickery with this one... Seems like it's no change at all:\r\n> But ... It looks good:\r\n\r\nNow after Part 3 is merged looks much better:\r\n\r\n![image](https://github.com/user-attachments/assets/a7026426-354b-4347-89cb-fe8e4dc3271f)"", 'created_at': datetime.datetime(2024, 12, 1, 11, 6, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509747746, 'issue_id': 2700118352, 'author': 'potiuk', 'body': '> Now after Part 3 is merged looks much better:\r\n\r\n\r\n:)', 'created_at': datetime.datetime(2024, 12, 1, 12, 34, 46, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-01 11:06:05 UTC): Now after Part 3 is merged looks much better:

![image](https://github.com/user-attachments/assets/a7026426-354b-4347-89cb-fe8e4dc3271f)

potiuk on (2024-12-01 12:34:46 UTC): :)

"
2700042703,pull_request,closed,,Migrate Edge calls for Worker to FastAPI part 3 - Jobs routes,"Follow-up PR as incremental part of https://github.com/apache/airflow/pull/44311 and #44330

Note: Only the last commit is the relevant change, the first 4 commits are from https://github.com/apache/airflow/pull/44311 and #44330

To prepare EdgeWorker to be independent of AIP-44 Internal API, this PR is the third step in adding/migrating to FastAPI. The calls to ""Jobs"" API to (1) fetch a job and (2) report job state are now real REST API calls, not using internal API.

I would separate the other internal API calls to follow-up PRs as this is already quite large. Especially cause for ongoing Airflow 2.10 Connexion API + Swagger manually need to be generated whereas the main workstream for Airflow 3 uses FastAPI.",jscheffl,2024-11-27 22:37:28+00:00,[],2024-12-01 12:59:13+00:00,2024-12-01 11:01:30+00:00,https://github.com/apache/airflow/pull/44433,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2507681738, 'issue_id': 2700042703, 'author': 'potiuk', 'body': 'I will wait for 1 and 2 to be merged :)', 'created_at': datetime.datetime(2024, 11, 29, 12, 5, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508280842, 'issue_id': 2700042703, 'author': 'jscheffl', 'body': '> I will wait for 1 and 2 to be merged :)\r\n\r\nAs internal API is now ""gone"" I will have a hard time getting #1+#2 merged. As there are some merge conflicts as well I\'ll focus on PR#3 + #4...\r\n\r\nBut anyway let me resolve the conflicts and integrate the feedback from Kaxil then it might be cleaner already.\r\n\r\nUPDATE: Okay now I realize that the internal API is gone but all the previous functions are moved to provider package... need to catch-up coming home...', 'created_at': datetime.datetime(2024, 11, 29, 18, 29, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508408909, 'issue_id': 2700042703, 'author': 'potiuk', 'body': '> UPDATE: Okay now I realize that the internal API is gone but all the previous functions are moved to provider package... need to catch-up coming home...\r\n\r\n:eyes:', 'created_at': datetime.datetime(2024, 11, 29, 19, 13, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509403396, 'issue_id': 2700042703, 'author': 'jscheffl', 'body': '> I will wait for 1 and 2 to be merged :)\r\n\r\nYou just merged 2 after I merged 1... so ""ball is in your field"" now :-D', 'created_at': datetime.datetime(2024, 11, 30, 22, 24, 6, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-29 12:05:51 UTC): I will wait for 1 and 2 to be merged :)

jscheffl (Issue Creator) on (2024-11-29 18:29:24 UTC): As internal API is now ""gone"" I will have a hard time getting #1+#2 merged. As there are some merge conflicts as well I'll focus on PR#3 + #4...

But anyway let me resolve the conflicts and integrate the feedback from Kaxil then it might be cleaner already.

UPDATE: Okay now I realize that the internal API is gone but all the previous functions are moved to provider package... need to catch-up coming home...

potiuk on (2024-11-29 19:13:58 UTC): :eyes:

jscheffl (Issue Creator) on (2024-11-30 22:24:06 UTC): You just merged 2 after I merged 1... so ""ball is in your field"" now :-D

"
2699998614,pull_request,closed,,Bump uv to 0.5.5,"https://github.com/astral-sh/uv/blob/main/CHANGELOG.md

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-27 22:13:10+00:00,[],2024-11-27 23:17:37+00:00,2024-11-27 23:15:34+00:00,https://github.com/apache/airflow/pull/44432,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2699676168,pull_request,closed,,[Snowflake] enable client_store_temporary_credential for snowflake provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR adds the support of a new parameter `client_store_temporary_credential` in the Snowflake hook connection. Snowflake hook supports both MFA and browser-based auth. 
1. MFA auth (`authenticator: username_password_mfa`): the cache config key is `client_request_mfa_token`, which was added by https://github.com/apache/airflow/pull/40394
2. browser-based auth (`authenticator: externalbrowser `): the cache config key is [`client_store_temporary_credential`](https://github.com/snowflakedb/snowflake-connector-python/blob/v3.12.3/src/snowflake/connector/connection.py#L224), which is introduced by this PR

More details are here: https://docs.snowflake.com/en/user-guide/admin-security-fed-auth-use#browser-based-sso


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",yzliao,2024-11-27 20:00:12+00:00,[],2024-12-14 00:30:53+00:00,2024-11-30 06:27:26+00:00,https://github.com/apache/airflow/pull/44431,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]","[{'comment_id': 2504682037, 'issue_id': 2699676168, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 27, 20, 0, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508852928, 'issue_id': 2699676168, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 30, 6, 27, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542574825, 'issue_id': 2699676168, 'author': 'haarismirza', 'body': 'Hi There, had a quick question why the variable `client_store_temporary_credential ` is not available in version 5.8.1 of the provider.', 'created_at': datetime.datetime(2024, 12, 14, 0, 11, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542577265, 'issue_id': 2699676168, 'author': 'yzliao', 'body': '> Hi There, had a quick question why the variable `client_store_temporary_credential ` is not available in version 5.8.1 of the provider.\r\n\r\n@haarismirza this PR was merged after 5.8.1 release. It may be included in the next release. I am not a release manager so I am not 100% sure.', 'created_at': datetime.datetime(2024, 12, 14, 0, 14, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542588421, 'issue_id': 2699676168, 'author': 'haarismirza', 'body': 'That makes total sense. Thanks for the reply @yzliao. Looks like @vatsrahul1001 last modified the provider change log - @vatsrahul1001 are you able to tell us when a new release for this provider will happen?', 'created_at': datetime.datetime(2024, 12, 14, 0, 30, 52, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-27 20:00:16 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-30 06:27:28 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

haarismirza on (2024-12-14 00:11:12 UTC): Hi There, had a quick question why the variable `client_store_temporary_credential ` is not available in version 5.8.1 of the provider.

yzliao (Issue Creator) on (2024-12-14 00:14:34 UTC): @haarismirza this PR was merged after 5.8.1 release. It may be included in the next release. I am not a release manager so I am not 100% sure.

haarismirza on (2024-12-14 00:30:52 UTC): That makes total sense. Thanks for the reply @yzliao. Looks like @vatsrahul1001 last modified the provider change log - @vatsrahul1001 are you able to tell us when a new release for this provider will happen?

"
2699286006,pull_request,closed,,minor FastAPI tests fixes,"I noticed a couple of minor issues in tests and this PR fixes them:

- Wrong param
- trailing slashes",rawwar,2024-11-27 17:32:16+00:00,[],2024-11-27 21:24:28+00:00,2024-11-27 21:24:28+00:00,https://github.com/apache/airflow/pull/44429,[],[],
2699256427,pull_request,closed,,support grouping of log lines for KubernetesPodOperator,"Support [grouping of log lines](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/logging-tasks.html#grouping-of-log-lines) for logs from KubernetesPodOperator.

Before:
![image](https://github.com/user-attachments/assets/ebb261e5-d543-4c9f-9682-0665a6b1b531)

After:
![image](https://github.com/user-attachments/assets/16565664-1a00-443d-a5ed-5687080a7128)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",karunpoudel,2024-11-27 17:16:05+00:00,[],2024-11-28 03:30:44+00:00,2024-11-28 03:30:44+00:00,https://github.com/apache/airflow/pull/44428,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2699246414,pull_request,closed,,Convert the LocalExecutor to run tasks using new Task SDK supervisor code,"This also lays the groundwork for a more general purpose ""workload"" execution
system, make a single interface for executors to run tasks and callbacks.

Also in this PR we set up the supervise function to send Task logs to a file,
and handle the task log template rendering in the scheduler before queueing
the workload.

Additionally we don't pass the activity directly to `supervise()` but instead
the properties/fields of it to reduce the coupling between SDK and Executor.
(More separation will appear in PRs over the next few weeks.)

The big change of note here is that rather than sending an airflow command
line to execute (`[""airflow"", ""tasks"", ""run"", ...]`) and going back in via the
CLI parser we go directly to a special purpose function. Much simpler.

It doesn't remove any of the old behaviour (CeleryExecutor still uses
LocalTaskJob via the CLI parser etc.), nor does anything currently send
callback requests via this new workload mechanism.

The `airflow.executors.workloads` module currently needs to be shared between
the Scheduler (or more specifically the Executor) and the ""worker"" side of
things. In the future these will be separate python dists and this module will
need to live somewhere else.

Right now we check the if `executor.queue_workload` is different from the
BaseExecutor version (which just raises an error right now) to see which
executors support this new version. That check will be removed as soon as all
the in-tree executors have been migrated.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-27 17:10:59+00:00,[],2024-11-28 12:45:37+00:00,2024-11-28 12:04:28+00:00,https://github.com/apache/airflow/pull/44427,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2504799325, 'issue_id': 2699246414, 'author': 'ashb', 'body': 'Yes, windows supports the socketpair etc (it\'s why I chose that API). This supervisor approach is what we do today with LocalTaskJob and the StandardRunner etc, this is just a simplified re-implementation of it.\r\n\r\nTo fully support windows we will need to have something other than `os.fork` based approach, the rest should be possible. Windows supports keeping open ""inheritable"" sockets open to launched processes, so it\'ll be slower because of launching a whole new python interpreter, but again, this is the current behaviour on Windows of StandardTask runner.', 'created_at': datetime.datetime(2024, 11, 27, 21, 31, 10, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-11-27 21:31:10 UTC): Yes, windows supports the socketpair etc (it's why I chose that API). This supervisor approach is what we do today with LocalTaskJob and the StandardRunner etc, this is just a simplified re-implementation of it.

To fully support windows we will need to have something other than `os.fork` based approach, the rest should be possible. Windows supports keeping open ""inheritable"" sockets open to launched processes, so it'll be slower because of launching a whole new python interpreter, but again, this is the current behaviour on Windows of StandardTask runner.

"
2699132832,pull_request,closed,,feat: add OpenLineage support for S3ToGCSOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for S3ToGCSOperator.

Also added an overlooked nit in tests for LocalFilesystemToGCSOperator.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-11-27 16:39:17+00:00,[],2024-11-28 19:43:28+00:00,2024-11-28 19:10:05+00:00,https://github.com/apache/airflow/pull/44426,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2699113904,pull_request,closed,,FIX make `CloudBatchSubmitJobOperator` fail when job fails,"Fixes : #43744

TODO:
-----

- [ ]  Improve unit test for `CloudBatchSunbmitJobOperator`",SuccessMoses,2024-11-27 16:30:20+00:00,[],2024-11-30 20:41:21+00:00,2024-11-30 15:51:55+00:00,https://github.com/apache/airflow/pull/44425,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2506229339, 'issue_id': 2699113904, 'author': 'potiuk', 'body': 'Yeah - as already planned - can you please add a unit test and get a better description in commit message @SuccessMoses ?', 'created_at': datetime.datetime(2024, 11, 28, 14, 17, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507437625, 'issue_id': 2699113904, 'author': 'SuccessMoses', 'body': '@potiuk I made a minor change to the test. Do you think more test is needed?', 'created_at': datetime.datetime(2024, 11, 29, 9, 43, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509014290, 'issue_id': 2699113904, 'author': 'potiuk', 'body': 'Yep. Nice work - the failing tests are also failing in `main` and we need to fix them separately, so this one is goood to go.', 'created_at': datetime.datetime(2024, 11, 30, 15, 51, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509157594, 'issue_id': 2699113904, 'author': 'SuccessMoses', 'body': ""@potiuk Thanks for merging. The failing test on `main`, is it something that is fixable? I won't like to give it a try too"", 'created_at': datetime.datetime(2024, 11, 30, 19, 26, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509223538, 'issue_id': 2699113904, 'author': 'potiuk', 'body': 'Workarounded already - and waits for a permanent fix here https://github.com/apache/airflow/issues/44513', 'created_at': datetime.datetime(2024, 11, 30, 20, 41, 19, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-28 14:17:40 UTC): Yeah - as already planned - can you please add a unit test and get a better description in commit message @SuccessMoses ?

SuccessMoses (Issue Creator) on (2024-11-29 09:43:17 UTC): @potiuk I made a minor change to the test. Do you think more test is needed?

potiuk on (2024-11-30 15:51:28 UTC): Yep. Nice work - the failing tests are also failing in `main` and we need to fix them separately, so this one is goood to go.

SuccessMoses (Issue Creator) on (2024-11-30 19:26:33 UTC): @potiuk Thanks for merging. The failing test on `main`, is it something that is fixable? I won't like to give it a try too

potiuk on (2024-11-30 20:41:19 UTC): Workarounded already - and waits for a permanent fix here https://github.com/apache/airflow/issues/44513

"
2699083014,pull_request,closed,,Add tests cases for multiple executors in chart,"related: https://github.com/apache/airflow/pull/43606/
adding examples to all files changed in the related PR to check validity for multiple executors and fix the errors.
with the tests, I found a problem in `chart/templates/rbac/pod-launcher-rolebinding.yaml` so I fix it here too.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-11-27 16:16:04+00:00,['romsharon98'],2025-01-07 09:26:06+00:00,2025-01-07 09:26:06+00:00,https://github.com/apache/airflow/pull/44424,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2698930235,pull_request,open,,Fix handle missing DAGs when clearing task instances to prevent failures.,"This PR handle missing DAGs when clearing task instances to prevent failures. When we delete DAG files and attempt to trigger them again, the process should access the DAGs and display an error indicating that the DAGs no longer exist, rather than causing the frontend to show an ""Oops"" error.

### Summary of Changes:
- Added warning logs for missing DAGs to prevent silent failures during task clearing.
- Improved error handling for downstream task clearing, including checks for partial_subset errors to handle cases where DAGs or downstream dependencies are unavailable.
- Updated the docstring for _clear_task_instances for better clarity and consistent style.
- Refined the grouping and handling of Task Instances by DAG and DAG Run to improve robustness and maintainability.

### Issue Reference:

Closes https://github.com/apache/airflow/issues/44274

^ Add meaningful description above
Read the [Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines) for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named {pr_number}.significant.rst or {issue_number}.significant.rst, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).",jieyao-MilestoneHub,2024-11-27 15:31:26+00:00,[],2025-01-29 09:50:27+00:00,,https://github.com/apache/airflow/pull/44423,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2504177957, 'issue_id': 2698930235, 'author': 'jieyao-MilestoneHub', 'body': '@pierrejeambrun @eladkal I sincerely apologize for the issues with the previous PR. As a result, I have created a new one. Moving forward, I will pay closer attention to the PR versions. Thank you for sharing your thoughts!', 'created_at': datetime.datetime(2024, 11, 27, 15, 34, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508820578, 'issue_id': 2698930235, 'author': 'jieyao-MilestoneHub', 'body': 'Hi @pierrejeambrun ,\r\n\r\nThanks for your feedback! I’ve updated the implementation to address the issue with missing DAGs causing partial success. Now, the process ensures clarity by stopping and raising an appropriate error if a DAG is missing.\r\n\r\nLet me know if this resolves your concern!', 'created_at': datetime.datetime(2024, 11, 30, 4, 10, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517270720, 'issue_id': 2698930235, 'author': 'utkarsharma2', 'body': '@pierrejeambrun Do we need this for 2.10.4?', 'created_at': datetime.datetime(2024, 12, 4, 12, 54, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518189409, 'issue_id': 2698930235, 'author': 'pierrejeambrun', 'body': ""It would be good to have this fix but I think we have been living with this for a long time, so I don't think it's critical.\r\n\r\nAlso the PR is not ready at this stage."", 'created_at': datetime.datetime(2024, 12, 4, 18, 13, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525424015, 'issue_id': 2698930235, 'author': 'jieyao-MilestoneHub', 'body': 'Hi @pierrejeambrun, I just wanted to let you know that I’ll need a bit more time to write the test as I’m still figuring out how Airflow defines its URLs. Thank you for your understanding!', 'created_at': datetime.datetime(2024, 12, 8, 5, 22, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620313931, 'issue_id': 2698930235, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 29, 0, 14, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2621157394, 'issue_id': 2698930235, 'author': 'pierrejeambrun', 'body': 'up', 'created_at': datetime.datetime(2025, 1, 29, 9, 50, 17, tzinfo=datetime.timezone.utc)}]","jieyao-MilestoneHub (Issue Creator) on (2024-11-27 15:34:31 UTC): @pierrejeambrun @eladkal I sincerely apologize for the issues with the previous PR. As a result, I have created a new one. Moving forward, I will pay closer attention to the PR versions. Thank you for sharing your thoughts!

jieyao-MilestoneHub (Issue Creator) on (2024-11-30 04:10:33 UTC): Hi @pierrejeambrun ,

Thanks for your feedback! I’ve updated the implementation to address the issue with missing DAGs causing partial success. Now, the process ensures clarity by stopping and raising an appropriate error if a DAG is missing.

Let me know if this resolves your concern!

utkarsharma2 on (2024-12-04 12:54:30 UTC): @pierrejeambrun Do we need this for 2.10.4?

pierrejeambrun on (2024-12-04 18:13:25 UTC): It would be good to have this fix but I think we have been living with this for a long time, so I don't think it's critical.

Also the PR is not ready at this stage.

jieyao-MilestoneHub (Issue Creator) on (2024-12-08 05:22:16 UTC): Hi @pierrejeambrun, I just wanted to let you know that I’ll need a bit more time to write the test as I’m still figuring out how Airflow defines its URLs. Thank you for your understanding!

github-actions[bot] on (2025-01-29 00:14:57 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

pierrejeambrun on (2025-01-29 09:50:17 UTC): up

"
2698882154,pull_request,closed,,Fix handle missing DAGs when clearing task instances to prevent failures.,"This PR handle missing DAGs when clearing task instances to prevent failures. When we delete DAG files and attempt to trigger them again, the process should access the DAGs and display an error indicating that the DAGs no longer exist, rather than causing the frontend to show an ""Oops"" error.

### Summary of Changes:
- Added warning logs for missing DAGs to prevent silent failures during task clearing.
- Improved error handling for downstream task clearing, including checks for partial_subset errors to handle cases where DAGs or downstream dependencies are unavailable.
- Updated the docstring for _clear_task_instances for better clarity and consistent style.
- Refined the grouping and handling of Task Instances by DAG and DAG Run to improve robustness and maintainability.


### Issue Reference:
Closes https://github.com/apache/airflow/issues/44274

^ Add meaningful description above
Read the [Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines) for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named {pr_number}.significant.rst or {issue_number}.significant.rst, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).",jieyao-MilestoneHub,2024-11-27 15:12:27+00:00,[],2024-11-27 15:24:55+00:00,2024-11-27 15:13:16+00:00,https://github.com/apache/airflow/pull/44422,[],[],
2698590184,pull_request,closed,,Fixing rendering of code block for newsfragment command,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

https://github.com/apache/airflow/pull/44378/files introduced newsfragment templating 👏🏽
However, github wasnt able to render the command due to a missing line.

Before:
![image](https://github.com/user-attachments/assets/28e0ca86-856d-44dc-b733-2474393cf568)

After:
![image](https://github.com/user-attachments/assets/cd6ec958-40cf-412e-a332-fc2c8357f667)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-27 13:37:43+00:00,[],2024-11-27 13:54:42+00:00,2024-11-27 13:54:42+00:00,https://github.com/apache/airflow/pull/44419,"[('area:dev-tools', '')]",[],
2698547447,pull_request,closed,,Update providers metadata 2024-11-27,,eladkal,2024-11-27 13:26:14+00:00,[],2024-11-27 19:10:56+00:00,2024-11-27 13:30:05+00:00,https://github.com/apache/airflow/pull/44418,[],[],
2698423391,pull_request,closed,,feat: add OpenLineage support for transfer operators between gcs and local,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for `GCSToLocalFilesystemOperator` and `LocalFilesystemToGCSOperator`, relies on #44410 that has already been merged.

Additionaly, it fixes a small bug in the translation of file to OL dataset, when using local filesystem, so that it conforms to naming convention.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-11-27 12:46:06+00:00,[],2024-11-27 13:32:12+00:00,2024-11-27 13:31:07+00:00,https://github.com/apache/airflow/pull/44417,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:common-io', '')]",[],
2698392548,pull_request,closed,,AIP-84: Migrate Dag Parsing endpoint to FastApi,"#### Related: [#42370](https://github.com/apache/airflow/issues/42370)

#### Testing:
API responses using legacy and fastAPI endpoints:
#### Legacy-API:
![image](https://github.com/user-attachments/assets/2db4d41d-e254-40dd-839a-b7fc650a645a)
last_parsed_time changed in airflow.dag:

![image](https://github.com/user-attachments/assets/b0f16829-cfb0-415c-8fce-0569f7052132)

#### FastAPI:
![image](https://github.com/user-attachments/assets/0214febd-e158-45f2-9f0f-97a5118a0513)
last_parsed_time changed in airflow.dag:

![image](https://github.com/user-attachments/assets/d0b695cd-5d6b-4c28-ac27-6c385c519ca5)
",prabhusneha,2024-11-27 12:32:33+00:00,[],2024-11-28 16:41:10+00:00,2024-11-28 16:41:07+00:00,https://github.com/apache/airflow/pull/44416,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2503829460, 'issue_id': 2698392548, 'author': 'rawwar', 'body': 'closed and reopened to run tests', 'created_at': datetime.datetime(2024, 11, 27, 13, 4, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505881689, 'issue_id': 2698392548, 'author': 'prabhusneha', 'body': 'Fixing the checks.', 'created_at': datetime.datetime(2024, 11, 28, 11, 20, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506257936, 'issue_id': 2698392548, 'author': 'prabhusneha', 'body': 'Rebased and all PR comments addressed.. FYI @pierrejeambrun', 'created_at': datetime.datetime(2024, 11, 28, 14, 31, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506492069, 'issue_id': 2698392548, 'author': 'pierrejeambrun', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 11, 28, 16, 41, 5, tzinfo=datetime.timezone.utc)}]","rawwar on (2024-11-27 13:04:53 UTC): closed and reopened to run tests

prabhusneha (Issue Creator) on (2024-11-28 11:20:59 UTC): Fixing the checks.

prabhusneha (Issue Creator) on (2024-11-28 14:31:50 UTC): Rebased and all PR comments addressed.. FYI @pierrejeambrun

pierrejeambrun on (2024-11-28 16:41:05 UTC): Thanks!

"
2698162017,pull_request,closed,,Add note about why we still have `black` config settings,"We mostly use ruff everywhere, but there is one use-case where black, or specifically `blacken-docs` is still needed.",ashb,2024-11-27 11:11:05+00:00,[],2024-11-27 13:51:17+00:00,2024-11-27 11:33:35+00:00,https://github.com/apache/airflow/pull/44415,[],"[{'comment_id': 2503931748, 'issue_id': 2698162017, 'author': 'potiuk', 'body': 'Nice', 'created_at': datetime.datetime(2024, 11, 27, 13, 51, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-27 13:51:15 UTC): Nice

"
2697961455,pull_request,closed,,"feat(dataset): allow ""airflow.dataset.metadata.Metadata"" import for backward compat","## Why
As we already have `airflow.dataset.Dataset` and `airflow.dataset.DatasetAlias` for backward compat, it makes sense to allow `airflow.dataset.metadata.Metadata` till airflow 3.2.

## What

allow importing `airflow.dataset.metadata.Metadata`

close: #44411

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-27 10:07:59+00:00,['Lee-W'],2024-12-02 13:12:32+00:00,2024-12-02 13:12:30+00:00,https://github.com/apache/airflow/pull/44413,[],[],
2697635701,pull_request,closed,,chore: unify handling of gcs paths in OpenLineage processes,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Each operator did the same GCS path processing to translate it to OpenLineage dataset name. This PR moves this logic to common utils function to make sure the lineage is consistent.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-11-27 08:36:44+00:00,[],2024-11-27 12:26:26+00:00,2024-11-27 11:48:27+00:00,https://github.com/apache/airflow/pull/44410,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2696768256,pull_request,closed,,AIP-72: Add support for fetching XComs in Supervisor,"Similar to https://github.com/apache/airflow/pull/44229 but for XComs

This commit adds support to handle XCom requests in the Supervisor process. The Task process could now send a request to the supervisor process to get a value of an XCom.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-27 02:47:43+00:00,[],2024-11-27 12:12:53+00:00,2024-11-27 12:12:50+00:00,https://github.com/apache/airflow/pull/44408,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2696682214,pull_request,closed,,AIP-72: Handle External update TI state in Supervisor,"- Updated logic to handle externally updated TI state in Supervisor. This states could have been externally changed via UI, CLI, API etc
- Replaced `FASTEST_HEARTBEAT_INTERVAL` and `SLOWEST_HEARTBEAT_INTERVAL` with `MIN_HEARTBEAT_INTERVAL` and `HEARTBEAT_THRESHOLD` for better clarity

This is part of my efforts to port LocalTaskJob tests to Supervisor: https://github.com/apache/airflow/issues/44356.

This ports over `TestLocalTaskJob.test_mark_{success,failure}_no_kill`.

This PR also allows retrying heartbeats:

- Added `_last_successful_heartbeat` and `_last_heartbeat_attempt` for better separation of tracking successful heartbeats and retries.
- `MIN_HEARTBEAT_INTERVAL` is now respected between heartbeat attempts, even after failures.
-  The num of retries is configurable via `MAX_FAILED_HEARTBEATS`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-27 01:47:31+00:00,[],2024-11-28 23:58:36+00:00,2024-11-28 23:58:35+00:00,https://github.com/apache/airflow/pull/44406,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2696660430,pull_request,closed,,AIP-72: Improve Supervisor and Task Instance State Validation,"This commit adds test that Supervisor prevents starting a Task Instance that is already running. Also updated `test_ti_update_state_conflict_if_not_queued` to use parameterized states, covering all non-queued Task Instance states.

This is part of my efforts to port LocalTaskJob tests to Supervisor: https://github.com/apache/airflow/issues/44356.

This ports over `TestLocalTaskJob.test_localtaskjob_double_trigger`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-27 01:35:39+00:00,[],2024-11-27 12:23:02+00:00,2024-11-27 12:13:45+00:00,https://github.com/apache/airflow/pull/44405,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2503740681, 'issue_id': 2696660430, 'author': 'ashb', 'body': ""Oh, it might be worth extending this to  check that the task code itself is never actually invoked? I'm not quite sure how we might do that across the subprocess though"", 'created_at': datetime.datetime(2024, 11, 27, 12, 23, 1, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-27 12:23:01 UTC): Oh, it might be worth extending this to  check that the task code itself is never actually invoked? I'm not quite sure how we might do that across the subprocess though

"
2696610172,pull_request,closed,,Add CodeQL security scanning on pull requests.,"Apparently we only run codeql on main, but we could run it on PRs as well. That's a good idea to test how it can look like.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-27 01:09:04+00:00,[],2024-11-27 14:23:10+00:00,2024-11-27 14:23:08+00:00,https://github.com/apache/airflow/pull/44404,"[('area:dev-tools', '')]","[{'comment_id': 2503665242, 'issue_id': 2696610172, 'author': 'potiuk', 'body': 'This seems to work well.', 'created_at': datetime.datetime(2024, 11, 27, 11, 45, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503739195, 'issue_id': 2696610172, 'author': 'potiuk', 'body': '> LGTM +1 Should we just mark 2-10* specifically?\r\n\r\nWe have the same pattern elsewhere - and we are going to have 2.11 in the future, so better to keep it this way I think.', 'created_at': datetime.datetime(2024, 11, 27, 12, 22, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503740124, 'issue_id': 2696610172, 'author': 'potiuk', 'body': 'And in the future we will have 3_0, 3_1 etc. ....', 'created_at': datetime.datetime(2024, 11, 27, 12, 22, 45, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-27 11:45:03 UTC): This seems to work well.

potiuk (Issue Creator) on (2024-11-27 12:22:17 UTC): We have the same pattern elsewhere - and we are going to have 2.11 in the future, so better to keep it this way I think.

potiuk (Issue Creator) on (2024-11-27 12:22:45 UTC): And in the future we will have 3_0, 3_1 etc. ....

"
2696251164,pull_request,closed,,Remove reference to hatch and add uv usage,Existing provider contribution guide reference hatch which is no longer used. Updated to refer to uv with simple usage example.,perry2of5,2024-11-26 22:16:45+00:00,[],2024-11-26 23:32:52+00:00,2024-11-26 23:27:56+00:00,https://github.com/apache/airflow/pull/44401,"[('area:dev-tools', '')]","[{'comment_id': 2502048095, 'issue_id': 2696251164, 'author': 'potiuk', 'body': 'Few small typoes and extra spaces to fix.', 'created_at': datetime.datetime(2024, 11, 26, 22, 20, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502050376, 'issue_id': 2696251164, 'author': 'perry2of5', 'body': ""I just fixed a few. Let me re-read and I'll push if I spot more. Sorry about that...."", 'created_at': datetime.datetime(2024, 11, 26, 22, 21, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502054466, 'issue_id': 2696251164, 'author': 'potiuk', 'body': 'No worries :)', 'created_at': datetime.datetime(2024, 11, 26, 22, 24, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502134698, 'issue_id': 2696251164, 'author': 'perry2of5', 'body': ""I think it is ready. I'm not going to rebase unless you ask me to (figure it just wastes CI resources)"", 'created_at': datetime.datetime(2024, 11, 26, 23, 1, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502176544, 'issue_id': 2696251164, 'author': 'vincbeck', 'body': 'All good! Thank you :)', 'created_at': datetime.datetime(2024, 11, 26, 23, 28, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-26 22:20:01 UTC): Few small typoes and extra spaces to fix.

perry2of5 (Issue Creator) on (2024-11-26 22:21:42 UTC): I just fixed a few. Let me re-read and I'll push if I spot more. Sorry about that....

potiuk on (2024-11-26 22:24:51 UTC): No worries :)

perry2of5 (Issue Creator) on (2024-11-26 23:01:42 UTC): I think it is ready. I'm not going to rebase unless you ask me to (figure it just wastes CI resources)

vincbeck on (2024-11-26 23:28:05 UTC): All good! Thank you :)

"
2696238556,pull_request,closed,,Remove Pydantic 2.10.0/2.10.1 workaround,"The Pydantic 2.10.0/2.10.1 workaround implemented in #44317 is not needed any more as it has been fixed in Pydantic 2.10.2 in the https://github.com/pydantic/pydantic/pull/10962

This PR removes the workaround and bumps min Pydantic version to 2.10.2.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-26 22:07:43+00:00,[],2024-11-26 22:39:24+00:00,2024-11-26 22:39:23+00:00,https://github.com/apache/airflow/pull/44400,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2502039205, 'issue_id': 2696238556, 'author': 'gopidesupavan', 'body': 'Require any full tests?', 'created_at': datetime.datetime(2024, 11, 26, 22, 13, 10, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-26 22:13:10 UTC): Require any full tests?

"
2696225553,pull_request,closed,,Fix failing ruff check on main,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-26 21:57:51+00:00,[],2024-11-26 21:59:18+00:00,2024-11-26 21:59:15+00:00,https://github.com/apache/airflow/pull/44399,[],[],
2696216902,pull_request,closed,,Fix so tests run in local docker for devcontainer,"Tests worked in github devcontainers, but not in local docker instances. This change ensures the expected /workspaces/airflow contains a link to the code so the tests can run. 

Possibly this is an X-Y problem where I fixed X, the test, but where really we should fix Y where Y is that the location is hardcoded to a place that isn't always populated.
",perry2of5,2024-11-26 21:52:41+00:00,[],2024-12-02 18:31:43+00:00,2024-12-02 18:31:39+00:00,https://github.com/apache/airflow/pull/44398,"[('area:dev-tools', '')]","[{'comment_id': 2502027444, 'issue_id': 2696216902, 'author': 'jscheffl', 'body': 'Do you have a hint how to locally test? VSCode and use DevContainers?', 'created_at': datetime.datetime(2024, 11, 26, 22, 4, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502046976, 'issue_id': 2696216902, 'author': 'perry2of5', 'body': 'Use vscode and local docker. I checked it out to my local file system and opened in vscode. vscode shows an option to open in devcontainers when you open the folder. The devcontainer will then start docker and vscode will connect to the devcontainer.', 'created_at': datetime.datetime(2024, 11, 26, 22, 19, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502366830, 'issue_id': 2696216902, 'author': 'potiuk', 'body': 'Running codespaces with this change leads to this:\r\n\r\n![image](https://github.com/user-attachments/assets/e96ef17d-7384-4ad4-9655-7465bef070cc)\r\n\r\nThe script exits with 0 and there is no terminal accessible. Yuo can see yourself by opening your own codespace:\r\n\r\n![image](https://github.com/user-attachments/assets/84933dfd-bc05-4ccd-8906-757ba9592e0c)', 'created_at': datetime.datetime(2024, 11, 27, 0, 55, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502406464, 'issue_id': 2696216902, 'author': 'perry2of5', 'body': 'Converting the PR to draft until I have time to address this.', 'created_at': datetime.datetime(2024, 11, 27, 1, 18, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512380361, 'issue_id': 2696216902, 'author': 'perry2of5', 'body': ""Was able to open in codespaces with no problem. An exit code of zero is success so I don't think that was the issue.\r\n\r\nProbably best to just let people update the AIRFLOW_SOURCES manually."", 'created_at': datetime.datetime(2024, 12, 2, 18, 31, 39, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-11-26 22:04:32 UTC): Do you have a hint how to locally test? VSCode and use DevContainers?

perry2of5 (Issue Creator) on (2024-11-26 22:19:07 UTC): Use vscode and local docker. I checked it out to my local file system and opened in vscode. vscode shows an option to open in devcontainers when you open the folder. The devcontainer will then start docker and vscode will connect to the devcontainer.

potiuk on (2024-11-27 00:55:01 UTC): Running codespaces with this change leads to this:

![image](https://github.com/user-attachments/assets/e96ef17d-7384-4ad4-9655-7465bef070cc)

The script exits with 0 and there is no terminal accessible. Yuo can see yourself by opening your own codespace:

![image](https://github.com/user-attachments/assets/84933dfd-bc05-4ccd-8906-757ba9592e0c)

perry2of5 (Issue Creator) on (2024-11-27 01:18:03 UTC): Converting the PR to draft until I have time to address this.

perry2of5 (Issue Creator) on (2024-12-02 18:31:39 UTC): Was able to open in codespaces with no problem. An exit code of zero is success so I don't think that was the issue.

Probably best to just let people update the AIRFLOW_SOURCES manually.

"
2696199380,pull_request,closed,,Delete `dag_version` table when downgrading the DB from the versioned Airflow,"In dagcode, fileloc_hash column was a primary key on the version before dag versioning. If dagcode is not deleted before downgrading, the fileloc_hash column, created when downgrading, would be a null column that can't be used for a primary key. A similar thing applies to serialized dag, which would have duplicates, and the primary key can't be determined. The solution is to delete the dag_version table data, which will delete the serdag and dagcode table data

",ephraimbuddy,2024-11-26 21:42:13+00:00,[],2024-11-27 06:47:24+00:00,2024-11-27 06:47:23+00:00,https://github.com/apache/airflow/pull/44397,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2695447317,pull_request,closed,,AIP-84 Migrate private graph_data endpoint,"Related to: https://github.com/apache/airflow/issues/42366

Subpart of: https://github.com/apache/airflow/issues/42367

Rough implementation of the `graph_data` in the FastAPI API. (same interface except that all fields are always returned, nothing is omitted like in the original implementation).

Then I will follow up with an update of the data model to return what is expected in https://github.com/apache/airflow/issues/42367

> Renaming to `Structure` will happen on the following PR.",pierrejeambrun,2024-11-26 17:02:39+00:00,['pierrejeambrun'],2024-11-28 15:11:15+00:00,2024-11-28 15:11:13+00:00,https://github.com/apache/airflow/pull/44394,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2695267826,pull_request,closed,,AIP-84 Fix default ordering when directly using SortParam,"This should fix the flakiness observed in main.

When no order is specified (i.e None), this should use the primary key as the default sorting. (Exactly what we do to fill the query parameter default value, but in some cases we use the SortParam outside of the FastAPI dependency system, bypassing the `dynamic_depends` function). ",pierrejeambrun,2024-11-26 16:20:52+00:00,['pierrejeambrun'],2024-11-26 18:47:33+00:00,2024-11-26 16:48:33+00:00,https://github.com/apache/airflow/pull/44393,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2501389030, 'issue_id': 2695267826, 'author': 'pierrejeambrun', 'body': 'Merged, @uranusjr feel free to rebase and report back if the issue persists.', 'created_at': datetime.datetime(2024, 11, 26, 16, 48, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501687424, 'issue_id': 2695267826, 'author': 'potiuk', 'body': 'nice!', 'created_at': datetime.datetime(2024, 11, 26, 18, 47, 33, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-11-26 16:48:30 UTC): Merged, @uranusjr feel free to rebase and report back if the issue persists.

potiuk on (2024-11-26 18:47:33 UTC): nice!

"
2695108669,pull_request,closed,,Fix formatting for backport failure message.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-26 15:37:50+00:00,[],2024-11-26 22:05:23+00:00,2024-11-26 22:05:00+00:00,https://github.com/apache/airflow/pull/44392,"[('area:dev-tools', '')]","[{'comment_id': 2501193246, 'issue_id': 2695108669, 'author': 'potiuk', 'body': 'Needed to produce a nicely formatted message - see https://github.com/apache/airflow/pull/44371#issuecomment-2501185577', 'created_at': datetime.datetime(2024, 11, 26, 15, 38, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502028571, 'issue_id': 2695108669, 'author': 'potiuk', 'body': 'The  failure fixed already in main.', 'created_at': datetime.datetime(2024, 11, 26, 22, 5, 21, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-26 15:38:53 UTC): Needed to produce a nicely formatted message - see https://github.com/apache/airflow/pull/44371#issuecomment-2501185577

potiuk (Issue Creator) on (2024-11-26 22:05:21 UTC): The  failure fixed already in main.

"
2695084970,pull_request,closed,,fix test_filters to use set to compare dag id's in dag run tests,"[CI](https://github.com/apache/airflow/actions/runs/12031755504)  failed for test_filters in test_dag_run.py(fastapi). 

This PR fixes it

Issue. Test should get all dag runs with ""success"" state. But, the order of these dag run's isn't relevant to this filter test. Hence, using a set instead of list.


EDIT: Looks like this is an issue across tests for list dag_run. I'll update this PR to fix all of its tests.",rawwar,2024-11-26 15:30:42+00:00,[],2024-11-27 00:52:27+00:00,2024-11-27 00:52:26+00:00,https://github.com/apache/airflow/pull/44391,[],"[{'comment_id': 2501249102, 'issue_id': 2695084970, 'author': 'potiuk', 'body': ""> I do not agree with that. Ordering of items returned by the API should be deterministic. Fixing the flakiness like this does not actually solve the problem I belive.\r\n\r\nI agree it's a better solution"", 'created_at': datetime.datetime(2024, 11, 26, 16, 1, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501354824, 'issue_id': 2695084970, 'author': 'uranusjr', 'body': 'I don’t know about the new implementation, but in the Connextion implementation, the result _is_ actually sorted, but it’s against a very weird default (`id`) that isn’t really deterministic in the tests because when you insert things through the ORM it’s not guaranteed the `id` would be the same as the order you insert them (due to both database and ORM implementation). So the tests will need fixing in any case unless we change the default.', 'created_at': datetime.datetime(2024, 11, 26, 16, 36, 27, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-26 16:01:27 UTC): I agree it's a better solution

uranusjr on (2024-11-26 16:36:27 UTC): I don’t know about the new implementation, but in the Connextion implementation, the result _is_ actually sorted, but it’s against a very weird default (`id`) that isn’t really deterministic in the tests because when you insert things through the ORM it’s not guaranteed the `id` would be the same as the order you insert them (due to both database and ORM implementation). So the tests will need fixing in any case unless we change the default.

"
2694825396,pull_request,closed,,Allow 'dag_version' table to be deleted by db clean command,"Deleting a dag would cascade delete dag_version table along with serialized_dag model and dagcode. However, we should be able to delete dag_version directly. I didn't add dag_code or serdag model because it won't make sense to have an existing dag_version without a corresponding dagcode and serdag

",ephraimbuddy,2024-11-26 14:16:43+00:00,[],2024-11-27 06:47:45+00:00,2024-11-27 06:47:42+00:00,https://github.com/apache/airflow/pull/44389,"[('AIP-65: DAG history in UI', '')]",[],
2694721532,pull_request,closed,,Also check NEW_SESSION imports in pre-commit,These three things are a set.,uranusjr,2024-11-26 13:38:03+00:00,[],2024-12-02 05:06:06+00:00,2024-11-27 01:15:32+00:00,https://github.com/apache/airflow/pull/44388,"[('area:dev-tools', '')]",[],
2694704790,pull_request,closed,,Add 'airflow assets list',"First one for #42317. The idea is pretty straightfoward.

Existing CLIs mostly use the Marshmallow models (from Connexion), but I opted to use the Pydantic models (for FastAPI) instead. I assume we’ll change those at some point anyway?

I also added the two fields added to Asset recently to the model. This would affect the endpoints, so we’ll see what happens…",uranusjr,2024-11-26 13:35:11+00:00,[],2024-11-27 03:01:07+00:00,2024-11-27 03:01:05+00:00,https://github.com/apache/airflow/pull/44387,"[('area:CLI', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2694420607,pull_request,closed,,Fix deferrable mode for BeamRunPythonPipelineOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have prepared a fix for an error in deferrable mode for `BeamRunPythonPipelineOperator`.

This error happens on a distributed system when the user has `trigger` and `worker` on different machines. `BeamRunPythonPipelineOperator` needs a local `py` file for starting a Job. Users can specify a path to the `py` file which is located in GCS bucket and then the operator will download this file to the local system. In the current deferrable mode implementation operator downloads `py` file before going to the deferrable mode. It means that on a distributed system the file is downloaded on the `worker` machine not on the `trigger` machine. And then when the operator tries to execute a Job on the `trigger` machine Airflow throws an error that the executable `py` file does not exist.

Fix for the same issue for the `BeamRunJavaPipelineOperator`: https://github.com/apache/airflow/pull/39371

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-11-26 11:59:38+00:00,[],2024-11-27 16:56:06+00:00,2024-11-27 16:56:06+00:00,https://github.com/apache/airflow/pull/44386,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:apache-beam', '')]","[{'comment_id': 2500649519, 'issue_id': 2694420607, 'author': 'eladkal', 'body': '> This error happens on a distributed system when the user has trigger and worker on different machines.\r\n\r\nDo we have a way to verify if other operators / other providers suffer from this problem? If so, lets open dedicated issues for them so we can keep track on it.', 'created_at': datetime.datetime(2024, 11, 26, 12, 19, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500815937, 'issue_id': 2694420607, 'author': 'MaksYermak', 'body': '> > This error happens on a distributed system when the user has trigger and worker on different machines.\r\n> \r\n> Do we have a way to verify if other operators / other providers suffer from this problem? If so, lets open dedicated issues for them so we can keep track on it.\r\n\r\nTo be honest I do not see any way how we can check the existence of this problem for other operators/providers.', 'created_at': datetime.datetime(2024, 11, 26, 13, 32, 57, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-26 12:19:45 UTC): Do we have a way to verify if other operators / other providers suffer from this problem? If so, lets open dedicated issues for them so we can keep track on it.

MaksYermak (Issue Creator) on (2024-11-26 13:32:57 UTC): To be honest I do not see any way how we can check the existence of this problem for other operators/providers.

"
2694290323,pull_request,closed,,Add DAG arguments to asset decorator,"I intentionally omitted some arguments e.g. start_date. We can figure out what to do with those later. I think these arguments are mostly considered reasonable and not something we wish we didn't add?

Close #44049.",uranusjr,2024-11-26 11:25:55+00:00,[],2024-11-27 01:26:03+00:00,2024-11-27 01:26:02+00:00,https://github.com/apache/airflow/pull/44384,"[('AIP-75', 'Asset-Centric Syntax'), ('area:task-sdk', None)]",[],
2694236768,pull_request,closed,,AIP84:  Check standalone_dag_processor config in get_airflow_health()  and update health endpoint,"closes: https://github.com/apache/airflow/issues/44253

### Motivation 
Right now the UI has to check the scheduler config for standalone_dag_processor in order to determine if the dag_processor health check should be rendered.

This PR does that check-in get_airflow_health() and also handles this inthe  ` public/health` endpoint.


### Testing
**Response with DAG Processor enabled**

<img width=""1458"" alt=""image"" src=""https://github.com/user-attachments/assets/0488152f-a59c-427d-9995-9b3cc15fb9b6"">


**Response with DAG Processor disabled**

<img width=""1398"" alt=""image"" src=""https://github.com/user-attachments/assets/af3f2666-c373-46e7-a303-4e5161d571e7"">


<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-26 11:03:21+00:00,[],2024-11-29 15:20:11+00:00,2024-11-29 15:20:08+00:00,https://github.com/apache/airflow/pull/44383,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2694027467,pull_request,closed,,AIP-84 Improve testing,"Improve a couple of test assertions on expected calls.


cc: @omkar-foss The issue was not with `mock.ANY` but with the `DAG` session object. The error message didn't show that but this is a known issue of pytest reporting errors. (pytest diff the `repr(...)` not the actual equality of objects, therefore `ANY` appears as a diff (while it's not), and the DAG session object does not (while they do not equally check))",pierrejeambrun,2024-11-26 10:10:52+00:00,['pierrejeambrun'],2024-11-26 17:40:33+00:00,2024-11-26 13:54:22+00:00,https://github.com/apache/airflow/pull/44381,[],"[{'comment_id': 2501563992, 'issue_id': 2694027467, 'author': 'omkar-foss', 'body': 'Thanks for looking into this @pierrejeambrun 👍🏽', 'created_at': datetime.datetime(2024, 11, 26, 17, 40, 32, tzinfo=datetime.timezone.utc)}]","omkar-foss on (2024-11-26 17:40:32 UTC): Thanks for looking into this @pierrejeambrun 👍🏽

"
2693981544,pull_request,closed,,refactor order by tests of GET Dag Runs endpoint,"this refactors order_by tests for GET Dag Runs endpoint. Also checks for reversed order.

Reference comment: https://github.com/apache/airflow/pull/44170#discussion_r1856749628",rawwar,2024-11-26 09:54:30+00:00,['rawwar'],2024-11-26 16:46:00+00:00,2024-11-26 16:45:59+00:00,https://github.com/apache/airflow/pull/44380,[],[],
2693865374,pull_request,closed,,docs(newsfragment): add template for significant newsfragments,"Closes: #44374

## Why
make updating https://github.com/apache/airflow/issues/41641 and https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+3+breaking+changes easier

## What
Add a template and a command line to generate a file based on the description to the doc

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-26 09:27:16+00:00,[],2024-11-27 07:48:22+00:00,2024-11-27 07:48:20+00:00,https://github.com/apache/airflow/pull/44378,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2500303506, 'issue_id': 2693865374, 'author': 'Lee-W', 'body': ""I've conducted some research into towncrier. It appears that there isn't a clever way to generate news fragments via templates, and it doesn't verify the content either. I'm not sure whether we should implement a script to check these sigificant files. The best we can do is probably check whether the checkboxes exist."", 'created_at': datetime.datetime(2024, 11, 26, 10, 58, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502954716, 'issue_id': 2693865374, 'author': 'Lee-W', 'body': ""I'll do some test on the script before merging it"", 'created_at': datetime.datetime(2024, 11, 27, 6, 0, 8, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-11-26 10:58:37 UTC): I've conducted some research into towncrier. It appears that there isn't a clever way to generate news fragments via templates, and it doesn't verify the content either. I'm not sure whether we should implement a script to check these sigificant files. The best we can do is probably check whether the checkboxes exist.

Lee-W (Issue Creator) on (2024-11-27 06:00:08 UTC): I'll do some test on the script before merging it

"
2692646311,pull_request,closed,,Move tests `bootstrap_dagbag` into test utils,"This is only used during testing, so I've moved into the testing utils.
The normal db utils aren't public, so this isn't a breaking change.

",jedcunningham,2024-11-25 23:48:47+00:00,[],2024-11-26 18:46:19+00:00,2024-11-26 08:01:42+00:00,https://github.com/apache/airflow/pull/44371,"[('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2499923578, 'issue_id': 2692646311, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12026244427\'> Run details </a>\r\n\r\n<table>\r\n            <tr>\r\n                <th>Status</th>\r\n                <th>Branch</th>\r\n                <th>Result</th>\r\n            </tr>\r\n            <tr>\r\n                <td>❌</td>\r\n                <td>v2-10-test</td>\r\n                <td><a href=""https://github.com/apache/airflow/commit/f0af1b3d23bd9a0adfe9642cae8a2725435e1ccf""><img src=\'https://img.shields.io/badge/Commit-f0af1b3-red\' alt=\'Commit Link\'></a></td>\r\n            </tr>\r\n        </table>\r\n\r\n        You can attempt to backport this manually by running:\r\n        \r\n        ```bash\r\n        cherry_picker f0af1b3 v2-10-test\r\n        ```\r\n        \r\n        This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\r\n        the files that need manual conflict resolution.\r\n        \r\n        After you have resolved the conflicts, you can continue the backport process by running:\r\n        \r\n        ```bash\r\n        cherry_picker --continue\r\n```', 'created_at': datetime.datetime(2024, 11, 26, 8, 2, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501181622, 'issue_id': 2692646311, 'author': 'potiuk', 'body': 'Ah... Bad formatting  in my PR ... needs to fix it :)', 'created_at': datetime.datetime(2024, 11, 26, 15, 34, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501185577, 'issue_id': 2692646311, 'author': 'potiuk', 'body': 'Much nicer now (manually corrected it):\r\n\r\nFrom:\r\n\r\n<img width=""868"" alt=""Screenshot 2024-11-26 at 16 39 27"" src=""https://github.com/user-attachments/assets/b693946a-7a4c-4d01-a5cc-f425d6adbfbc"">\r\n\r\nTo:\r\n\r\n<img width=""867"" alt=""Screenshot 2024-11-26 at 16 35 26"" src=""https://github.com/user-attachments/assets/5311b8b7-4b42-41bb-9b9d-63d8822d96bd"">', 'created_at': datetime.datetime(2024, 11, 26, 15, 35, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501685181, 'issue_id': 2692646311, 'author': 'gopidesupavan', 'body': '> Much nicer now (manually corrected it):\r\n> \r\n> From:\r\n> \r\n> <img alt=""Screenshot 2024-11-26 at 16 39 27"" width=""868"" src=""https://private-user-images.githubusercontent.com/595491/390023655-b693946a-7a4c-4d01-a5cc-f425d6adbfbc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzI2NDcwMjcsIm5iZiI6MTczMjY0NjcyNywicGF0aCI6Ii81OTU0OTEvMzkwMDIzNjU1LWI2OTM5NDZhLTdhNGMtNGQwMS1hNWNjLWY0MjVkNmFkYmZiYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMTI2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTEyNlQxODQ1MjdaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mMTE4Y2E5YzE0NjMyMWU4MWExZTRlM2RmM2I0MGFhODlmOTJmZmQ2ZTg3NGFjZjRiOTJjNmRjNDI5YWU2NmM1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.UIdrxqX5gdaxwYdpDUPeA2uXr52SslFEZotg6G0jM-Y"">\r\n> To:\r\n> \r\n> <img alt=""Screenshot 2024-11-26 at 16 35 26"" width=""867"" src=""https://private-user-images.githubusercontent.com/595491/390021767-5311b8b7-4b42-41bb-9b9d-63d8822d96bd.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzI2NDcwMjcsIm5iZiI6MTczMjY0NjcyNywicGF0aCI6Ii81OTU0OTEvMzkwMDIxNzY3LTUzMTFiOGI3LTRiNDItNDFiYi05YjlkLTYzZDg4MjJkOTZiZC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMTI2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTEyNlQxODQ1MjdaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05MzVjZDVlZTM1ZTY1ZGZhMTI2YTlkNTIwYWJhZTAyNWE4OWFlZDliOWJmNDQwOGExZDRlOGU4MzNjYWFiY2E2JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.oS8NM5_a7ZZ4nMUxQtnyRg__WCO9wohsoXqgClGDps0"">\r\n\r\nNice, manually verified , otherwise it may have to go multiple rounds :)', 'created_at': datetime.datetime(2024, 11, 26, 18, 46, 17, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-26 08:02:27 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12026244427'> Run details </a>

<table>
            <tr>
                <th>Status</th>
                <th>Branch</th>
                <th>Result</th>
            </tr>
            <tr>
                <td>❌</td>
                <td>v2-10-test</td>
                <td><a href=""https://github.com/apache/airflow/commit/f0af1b3d23bd9a0adfe9642cae8a2725435e1ccf""><img src='https://img.shields.io/badge/Commit-f0af1b3-red' alt='Commit Link'></a></td>
            </tr>
        </table>

        You can attempt to backport this manually by running:
        
        ```bash
        cherry_picker f0af1b3 v2-10-test
        ```
        
        This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
        the files that need manual conflict resolution.
        
        After you have resolved the conflicts, you can continue the backport process by running:
        
        ```bash
        cherry_picker --continue
```

potiuk on (2024-11-26 15:34:16 UTC): Ah... Bad formatting  in my PR ... needs to fix it :)

potiuk on (2024-11-26 15:35:47 UTC): Much nicer now (manually corrected it):

From:

<img width=""868"" alt=""Screenshot 2024-11-26 at 16 39 27"" src=""https://github.com/user-attachments/assets/b693946a-7a4c-4d01-a5cc-f425d6adbfbc"">

To:

<img width=""867"" alt=""Screenshot 2024-11-26 at 16 35 26"" src=""https://github.com/user-attachments/assets/5311b8b7-4b42-41bb-9b9d-63d8822d96bd"">

gopidesupavan on (2024-11-26 18:46:17 UTC): Nice, manually verified , otherwise it may have to go multiple rounds :)

"
2692430691,pull_request,closed,,Reset signals on exiting SchedulerJob loop,"Under normal use (i.e. running `airflow scheduler`) this doesn't matter as the
process is about to exit.

However this can come up in running tests -- for instance if you try to run
`pytest tests/jobs/test_scheduler_job.py tests/executors/` it will fail as the
signal handler from running the scheduler is still installed in the main
pytest process.

Since the fix is easy and doesn't significantly complicate anything it is
worth making the behaviour under pytest more ""correct"".

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-25 22:24:45+00:00,[],2024-11-26 08:23:29+00:00,2024-11-25 23:24:57+00:00,https://github.com/apache/airflow/pull/44370,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2692414419,pull_request,closed,,AIP-82 Send asset change event when trigger fires,"Resolves #42513 and #42514.

The purpose of this PR is to send events to assets when some watchers are associated to them. Example:

```
trigger = MyQueueTrigger(queue=""<my_queue>"")
asset = Asset(""test_asset"", watchers=[trigger])

with DAG(
    dag_id=""example"",
    schedule=[asset],
):
    task = EmptyOperator(task_id=""task"",)
```

As part of AIP-82, it is now possible to associate `watchers` to an asset. These watchers are triggers. By associating a trigger to an asset, whenever the trigger fires, the goal is to update the asset. This PR handles that part, when a trigger fires, it updates its associated triggers.

I also updated the logic behind how the triggers are cleaned up by the triggerer. These triggers that are associated to an assets long as long as the association between the trigger and the asset is defined in the DAG.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-25 22:14:22+00:00,[],2024-12-04 15:58:25+00:00,2024-12-04 15:58:23+00:00,https://github.com/apache/airflow/pull/44369,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Triggerer', '')]","[{'comment_id': 2501212903, 'issue_id': 2692414419, 'author': 'tirkarthi', 'body': 'On trigger restart or reassignment to another triggerer process the coroutine is cancelled and a check for `trigger_timeout` is done on `task_instance` where `task_instance` is None in this case and could be checked with sample patch as below to handle this.\r\n\r\nTraceback on trying this out locally with sample dag and ctrl+c to stop the triggerer\r\n\r\n```\r\n[2024-11-26T20:58:28.870+0530] {base_events.py:1744} ERROR - unhandled exception during asyncio.run() shutdown\r\ntask: <Task finished name=\'Task-3\' coro=<TriggerRunner.run_trigger() done, defined at /home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py:632> exception=AttributeError(""\'NoneType\' object has no attribute \'trigger_timeout\'"")>\r\nTraceback (most recent call last):\r\n  File ""/home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py"", line 639, in run_trigger\r\n    async for event in trigger.run():\r\n  File ""/home/karthikeyan/stuff/python/airflow/airflow/triggers/file.py"", line 87, in run\r\n    await asyncio.sleep(self.poke_interval)\r\n  File ""/usr/lib/python3.10/asyncio/tasks.py"", line 605, in sleep\r\n    return await future\r\nasyncio.exceptions.CancelledError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File ""/home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py"", line 644, in run_trigger\r\n    if timeout := trigger.task_instance.trigger_timeout:\r\nAttributeError: \'NoneType\' object has no attribute \'trigger_timeout\'\r\n```\r\n\r\nChecking for task_instance on trigger\r\n\r\n```patch\r\ndiff --git a/airflow/jobs/triggerer_job_runner.py b/airflow/jobs/triggerer_job_runner.py\r\nindex 8c226334f7..d7e5dbc6b1 100644\r\n--- a/airflow/jobs/triggerer_job_runner.py\r\n+++ b/airflow/jobs/triggerer_job_runner.py\r\n@@ -641,7 +641,7 @@ class TriggerRunner(threading.Thread, LoggingMixin):\r\n                 self.triggers[trigger_id][""events""] += 1\r\n                 self.events.append((trigger_id, event))\r\n         except asyncio.CancelledError:\r\n-            if timeout := trigger.task_instance.trigger_timeout:\r\n+            if timeout := (trigger.task_instance and trigger.task_instance.trigger_timeout):\r\n                 timeout = timeout.replace(tzinfo=timezone.utc) if not timeout.tzinfo else timeout\r\n                 if timeout < timezone.utcnow():\r\n                     self.log.error(""Trigger cancelled due to timeout"")\r\n```\r\n\r\nSample dag :\r\n\r\n```python\r\nfrom __future__ import annotations\r\n\r\nfrom datetime import datetime\r\n\r\nfrom airflow import DAG\r\nfrom airflow.operators.empty import EmptyOperator\r\nfrom airflow.triggers.file import FileTrigger\r\nfrom airflow.sdk.definitions.asset import Asset\r\n\r\ntrigger = FileTrigger(filepath=""/tmp/a"")\r\nasset = Asset(""test_asset_1"", watchers=[trigger])\r\n\r\nwith DAG(\r\n    dag_id=""file_trigger_timeout"",\r\n    start_date=datetime(2021, 1, 1),\r\n    catchup=False,\r\n    schedule=[asset],\r\n) as dag:\r\n    t1 = EmptyOperator(task_id=""t1"")\r\n\r\n    t1\r\n```', 'created_at': datetime.datetime(2024, 11, 26, 15, 46, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501227202, 'issue_id': 2692414419, 'author': 'tirkarthi', 'body': ""There are `cleanup` function implementations that expect `task_instance` to be always present like https://github.com/apache/airflow/pull/39442 and might fail to cleanup if they are used with asset based use cases though exceptions from cleanup are suppressed so just wondering if cleanup is semantically valid for triggers with assets scenario since it's not mentioned in the AIP.\r\n\r\nEdit : Just saw https://github.com/apache/airflow/issues/42514 to handle cleanup so my message might not be valid. Please ignore if not needed. Thanks."", 'created_at': datetime.datetime(2024, 11, 26, 15, 52, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501812675, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': ""> trigger_timeout\r\n\r\nNice! Thanks for the catch! I'll apply that"", 'created_at': datetime.datetime(2024, 11, 26, 20, 1, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501831157, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': ""> There are `cleanup` function implementations that expect `task_instance` to be always present like #39442 and might fail to cleanup if they are used with asset based use cases though exceptions from cleanup are suppressed so just wondering if cleanup is semantically valid for triggers with assets scenario since it's not mentioned in the AIP.\r\n> \r\n> Edit : Just saw #42514 to handle cleanup so my message might not be valid. Please ignore if not needed. Thanks.\r\n\r\nI think it is fine here because when I read the examples you provided, you cancel external job (external from Airflow) if the task instance is not in deferred state. All the logic here implemented is specific to deferrable operators and should not overlap with this feature. At first I thought the triggers were being cleaned up but here it is external jobs, I dont see it overlapping. Triggers would be another story. But thanks for heads-up! \r\n\r\n#42514 is being resolved as part of this PR, therefore the logic handling the trigger cleaned-up is done in that PR (at least on my perspective). So if you think something is missing or off, please call it out :)"", 'created_at': datetime.datetime(2024, 11, 26, 20, 13, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501840580, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': '> On trigger restart or reassignment to another triggerer process the coroutine is cancelled and a check for `trigger_timeout` is done on `task_instance` where `task_instance` is None in this case and could be checked with sample patch as below to handle this.\r\n> \r\n> Traceback on trying this out locally with sample dag and ctrl+c to stop the triggerer\r\n> \r\n> ```\r\n> [2024-11-26T20:58:28.870+0530] {base_events.py:1744} ERROR - unhandled exception during asyncio.run() shutdown\r\n> task: <Task finished name=\'Task-3\' coro=<TriggerRunner.run_trigger() done, defined at /home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py:632> exception=AttributeError(""\'NoneType\' object has no attribute \'trigger_timeout\'"")>\r\n> Traceback (most recent call last):\r\n>   File ""/home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py"", line 639, in run_trigger\r\n>     async for event in trigger.run():\r\n>   File ""/home/karthikeyan/stuff/python/airflow/airflow/triggers/file.py"", line 87, in run\r\n>     await asyncio.sleep(self.poke_interval)\r\n>   File ""/usr/lib/python3.10/asyncio/tasks.py"", line 605, in sleep\r\n>     return await future\r\n> asyncio.exceptions.CancelledError\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File ""/home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py"", line 644, in run_trigger\r\n>     if timeout := trigger.task_instance.trigger_timeout:\r\n> AttributeError: \'NoneType\' object has no attribute \'trigger_timeout\'\r\n> ```\r\n> \r\n> Checking for task_instance on trigger\r\n> \r\n> ```diff\r\n> diff --git a/airflow/jobs/triggerer_job_runner.py b/airflow/jobs/triggerer_job_runner.py\r\n> index 8c226334f7..d7e5dbc6b1 100644\r\n> --- a/airflow/jobs/triggerer_job_runner.py\r\n> +++ b/airflow/jobs/triggerer_job_runner.py\r\n> @@ -641,7 +641,7 @@ class TriggerRunner(threading.Thread, LoggingMixin):\r\n>                  self.triggers[trigger_id][""events""] += 1\r\n>                  self.events.append((trigger_id, event))\r\n>          except asyncio.CancelledError:\r\n> -            if timeout := trigger.task_instance.trigger_timeout:\r\n> +            if timeout := (trigger.task_instance and trigger.task_instance.trigger_timeout):\r\n>                  timeout = timeout.replace(tzinfo=timezone.utc) if not timeout.tzinfo else timeout\r\n>                  if timeout < timezone.utcnow():\r\n>                      self.log.error(""Trigger cancelled due to timeout"")\r\n> ```\r\n> \r\n> Sample dag :\r\n> \r\n> ```python\r\n> from __future__ import annotations\r\n> \r\n> from datetime import datetime\r\n> \r\n> from airflow import DAG\r\n> from airflow.operators.empty import EmptyOperator\r\n> from airflow.triggers.file import FileTrigger\r\n> from airflow.sdk.definitions.asset import Asset\r\n> \r\n> trigger = FileTrigger(filepath=""/tmp/a"")\r\n> asset = Asset(""test_asset_1"", watchers=[trigger])\r\n> \r\n> with DAG(\r\n>     dag_id=""file_trigger_timeout"",\r\n>     start_date=datetime(2021, 1, 1),\r\n>     catchup=False,\r\n>     schedule=[asset],\r\n> ) as dag:\r\n>     t1 = EmptyOperator(task_id=""t1"")\r\n> \r\n>     t1\r\n> ```\r\n\r\nIt should be fixed now', 'created_at': datetime.datetime(2024, 11, 26, 20, 19, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515658729, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': ""> Over all LGTM :)\r\n> \r\n> One question , do we have to re think triggers `default_capacity` config , with the new event driven it shares the triggers capacity config. so is it okay to have a single config for regular triggers and event driver triggers?\r\n\r\nI think so and to me it makes sense. The config `default_capacity` is on the triggerer level and set the maximum number of triggers one triggerer can run. The triggerer runs triggers from deferrable operators but from event driven scheduling as well, therefore, to me it makes sense `default_capacity` covers both use cases.\r\n\r\nThe only issue with this approach is, triggers from event driven scheduling can max out the triggerer (if many many triggers are used to update assets). Event driven scheduling would become a noisy neighbour for deferrable tasks. That'd mean that no deferrable task could run unless some of the triggers used to update the assets (all that defined in DAGs) are removed.\r\n\r\nKnowing that the default value of `default_capacity` is 1000, I dont know if this limit is hit often nor if we should treat them separately. What I can suggest is for now to have one common `default_capacity` config for all triggers. If some users, or someone with some data demonstrating we should have two `default_capacity` config (one for deferrable tasks and one for event driven scheduling), then we could do it."", 'created_at': datetime.datetime(2024, 12, 3, 22, 13, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516401969, 'issue_id': 2692414419, 'author': 'tirkarthi', 'body': ""There was a feature request and PR open to assign a specific queue to trigger and triggerer so that the specific triggerer instance listens to specific type of triggers but it's not active. Maybe the feature could be useful here once available to run asset related triggers in a separate triggerer instance and not to be part of the normal triggers.\r\n\r\nhttps://github.com/apache/airflow/issues/33818."", 'created_at': datetime.datetime(2024, 12, 4, 7, 28, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516407515, 'issue_id': 2692414419, 'author': 'tirkarthi', 'body': 'I tested this feature locally and will be useful at work once we upgrade for certain use cases. I am looking forward to how the ""infinite scheduling"" part is handled in future as noted in the AIP which will further improve usability for us. Thanks @vincbeck .', 'created_at': datetime.datetime(2024, 12, 4, 7, 31, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2516445588, 'issue_id': 2692414419, 'author': 'gopidesupavan', 'body': ""> > Over all LGTM :)\r\n> > One question , do we have to re think triggers `default_capacity` config , with the new event driven it shares the triggers capacity config. so is it okay to have a single config for regular triggers and event driver triggers?\r\n> \r\n> I think so and to me it makes sense. The config `default_capacity` is on the triggerer level and set the maximum number of triggers one triggerer can run. The triggerer runs triggers from deferrable operators but from event driven scheduling as well, therefore, to me it makes sense `default_capacity` covers both use cases.\r\n> \r\n> The only issue with this approach is, triggers from event driven scheduling can max out the triggerer (if many many triggers are used to update assets). Event driven scheduling would become a noisy neighbour for deferrable tasks. That'd mean that no deferrable task could run unless some of the triggers used to update the assets (all that defined in DAGs) are removed.\r\n> \r\n> Knowing that the default value of `default_capacity` is 1000, I dont know if this limit is hit often nor if we should treat them separately. What I can suggest is for now to have one common `default_capacity` config for all triggers. If some users, or someone with some data demonstrating we should have two `default_capacity` config (one for deferrable tasks and one for event driven scheduling), then we could do it.\r\n\r\nSure, that makes sense. I've heard from a couple of people two or three instances where they run thousands of triggers in their data pipelines,  and am sure these people will leverage this awesome event driven feature effectively once it up,  I just wanted to bring up that point here. :)"", 'created_at': datetime.datetime(2024, 12, 4, 7, 51, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517719866, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': ""> There was a feature request and PR open to assign a specific queue to trigger and triggerer so that the specific triggerer instance listens to specific type of triggers but it's not active. Maybe the feature could be useful here once available to run asset related triggers in a separate triggerer instance and not to be part of the normal triggers.\r\n> \r\n> #33818.\r\n\r\nI agree, that could be indeed useful for that feature. This is definitely something we can do later based on feedbacks/comments from users"", 'created_at': datetime.datetime(2024, 12, 4, 15, 12, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517721157, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': '> I tested this feature locally and will be useful at work once we upgrade for certain use cases. I am looking forward to how the ""infinite scheduling"" part is handled in future as noted in the AIP which will further improve usability for us. Thanks @vincbeck .\r\n\r\nThanks for testing it!!', 'created_at': datetime.datetime(2024, 12, 4, 15, 13, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517728465, 'issue_id': 2692414419, 'author': 'vincbeck', 'body': ""> > > Over all LGTM :)\r\n> > > One question , do we have to re think triggers `default_capacity` config , with the new event driven it shares the triggers capacity config. so is it okay to have a single config for regular triggers and event driver triggers?\r\n> > \r\n> > \r\n> > I think so and to me it makes sense. The config `default_capacity` is on the triggerer level and set the maximum number of triggers one triggerer can run. The triggerer runs triggers from deferrable operators but from event driven scheduling as well, therefore, to me it makes sense `default_capacity` covers both use cases.\r\n> > The only issue with this approach is, triggers from event driven scheduling can max out the triggerer (if many many triggers are used to update assets). Event driven scheduling would become a noisy neighbour for deferrable tasks. That'd mean that no deferrable task could run unless some of the triggers used to update the assets (all that defined in DAGs) are removed.\r\n> > Knowing that the default value of `default_capacity` is 1000, I dont know if this limit is hit often nor if we should treat them separately. What I can suggest is for now to have one common `default_capacity` config for all triggers. If some users, or someone with some data demonstrating we should have two `default_capacity` config (one for deferrable tasks and one for event driven scheduling), then we could do it.\r\n> \r\n> Sure, that makes sense. I've heard from a couple of people two or three instances where they run thousands of triggers in their data pipelines, and am sure these people will leverage this awesome event driven feature effectively once it up, I just wanted to bring up that point here. :)\r\n\r\nAnd thanks for doing it :) All these feedbacks/points are very useful when implementing features so thank you for doing it :)"", 'created_at': datetime.datetime(2024, 12, 4, 15, 15, 14, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-11-26 15:46:46 UTC): On trigger restart or reassignment to another triggerer process the coroutine is cancelled and a check for `trigger_timeout` is done on `task_instance` where `task_instance` is None in this case and could be checked with sample patch as below to handle this.

Traceback on trying this out locally with sample dag and ctrl+c to stop the triggerer

```
[2024-11-26T20:58:28.870+0530] {base_events.py:1744} ERROR - unhandled exception during asyncio.run() shutdown
task: <Task finished name='Task-3' coro=<TriggerRunner.run_trigger() done, defined at /home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py:632> exception=AttributeError(""'NoneType' object has no attribute 'trigger_timeout'"")>
Traceback (most recent call last):
  File ""/home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py"", line 639, in run_trigger
    async for event in trigger.run():
  File ""/home/karthikeyan/stuff/python/airflow/airflow/triggers/file.py"", line 87, in run
    await asyncio.sleep(self.poke_interval)
  File ""/usr/lib/python3.10/asyncio/tasks.py"", line 605, in sleep
    return await future
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/karthikeyan/stuff/python/airflow/airflow/jobs/triggerer_job_runner.py"", line 644, in run_trigger
    if timeout := trigger.task_instance.trigger_timeout:
AttributeError: 'NoneType' object has no attribute 'trigger_timeout'
```

Checking for task_instance on trigger

```patch
diff --git a/airflow/jobs/triggerer_job_runner.py b/airflow/jobs/triggerer_job_runner.py
index 8c226334f7..d7e5dbc6b1 100644
--- a/airflow/jobs/triggerer_job_runner.py
+++ b/airflow/jobs/triggerer_job_runner.py
@@ -641,7 +641,7 @@ class TriggerRunner(threading.Thread, LoggingMixin):
                 self.triggers[trigger_id][""events""] += 1
                 self.events.append((trigger_id, event))
         except asyncio.CancelledError:
-            if timeout := trigger.task_instance.trigger_timeout:
+            if timeout := (trigger.task_instance and trigger.task_instance.trigger_timeout):
                 timeout = timeout.replace(tzinfo=timezone.utc) if not timeout.tzinfo else timeout
                 if timeout < timezone.utcnow():
                     self.log.error(""Trigger cancelled due to timeout"")
```

Sample dag :

```python
from __future__ import annotations

from datetime import datetime

from airflow import DAG
from airflow.operators.empty import EmptyOperator
from airflow.triggers.file import FileTrigger
from airflow.sdk.definitions.asset import Asset

trigger = FileTrigger(filepath=""/tmp/a"")
asset = Asset(""test_asset_1"", watchers=[trigger])

with DAG(
    dag_id=""file_trigger_timeout"",
    start_date=datetime(2021, 1, 1),
    catchup=False,
    schedule=[asset],
) as dag:
    t1 = EmptyOperator(task_id=""t1"")

    t1
```

tirkarthi on (2024-11-26 15:52:42 UTC): There are `cleanup` function implementations that expect `task_instance` to be always present like https://github.com/apache/airflow/pull/39442 and might fail to cleanup if they are used with asset based use cases though exceptions from cleanup are suppressed so just wondering if cleanup is semantically valid for triggers with assets scenario since it's not mentioned in the AIP.

Edit : Just saw https://github.com/apache/airflow/issues/42514 to handle cleanup so my message might not be valid. Please ignore if not needed. Thanks.

vincbeck (Issue Creator) on (2024-11-26 20:01:46 UTC): Nice! Thanks for the catch! I'll apply that

vincbeck (Issue Creator) on (2024-11-26 20:13:17 UTC): I think it is fine here because when I read the examples you provided, you cancel external job (external from Airflow) if the task instance is not in deferred state. All the logic here implemented is specific to deferrable operators and should not overlap with this feature. At first I thought the triggers were being cleaned up but here it is external jobs, I dont see it overlapping. Triggers would be another story. But thanks for heads-up! 

#42514 is being resolved as part of this PR, therefore the logic handling the trigger cleaned-up is done in that PR (at least on my perspective). So if you think something is missing or off, please call it out :)

vincbeck (Issue Creator) on (2024-11-26 20:19:30 UTC): It should be fixed now

vincbeck (Issue Creator) on (2024-12-03 22:13:48 UTC): I think so and to me it makes sense. The config `default_capacity` is on the triggerer level and set the maximum number of triggers one triggerer can run. The triggerer runs triggers from deferrable operators but from event driven scheduling as well, therefore, to me it makes sense `default_capacity` covers both use cases.

The only issue with this approach is, triggers from event driven scheduling can max out the triggerer (if many many triggers are used to update assets). Event driven scheduling would become a noisy neighbour for deferrable tasks. That'd mean that no deferrable task could run unless some of the triggers used to update the assets (all that defined in DAGs) are removed.

Knowing that the default value of `default_capacity` is 1000, I dont know if this limit is hit often nor if we should treat them separately. What I can suggest is for now to have one common `default_capacity` config for all triggers. If some users, or someone with some data demonstrating we should have two `default_capacity` config (one for deferrable tasks and one for event driven scheduling), then we could do it.

tirkarthi on (2024-12-04 07:28:06 UTC): There was a feature request and PR open to assign a specific queue to trigger and triggerer so that the specific triggerer instance listens to specific type of triggers but it's not active. Maybe the feature could be useful here once available to run asset related triggers in a separate triggerer instance and not to be part of the normal triggers.

https://github.com/apache/airflow/issues/33818.

tirkarthi on (2024-12-04 07:31:02 UTC): I tested this feature locally and will be useful at work once we upgrade for certain use cases. I am looking forward to how the ""infinite scheduling"" part is handled in future as noted in the AIP which will further improve usability for us. Thanks @vincbeck .

gopidesupavan on (2024-12-04 07:51:55 UTC): Sure, that makes sense. I've heard from a couple of people two or three instances where they run thousands of triggers in their data pipelines,  and am sure these people will leverage this awesome event driven feature effectively once it up,  I just wanted to bring up that point here. :)

vincbeck (Issue Creator) on (2024-12-04 15:12:34 UTC): I agree, that could be indeed useful for that feature. This is definitely something we can do later based on feedbacks/comments from users

vincbeck (Issue Creator) on (2024-12-04 15:13:02 UTC): Thanks for testing it!!

vincbeck (Issue Creator) on (2024-12-04 15:15:14 UTC): And thanks for doing it :) All these feedbacks/points are very useful when implementing features so thank you for doing it :)

"
2692400020,pull_request,closed,,Update the system test `lib/system-tests/tests/example_comprehend_document_classifier.ts` to use example files from S3,"In the current implementation the system test downloads the file from Github and save it in S3. Since AWS team is running these system tests regularly, Github blocked us. Even though the system tests are not run that often (maximum every hour), it seems it is too much for Github. To avoid that, the files are now saved in S3 and used directly from there. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-25 22:05:08+00:00,[],2024-11-26 15:00:50+00:00,2024-11-26 08:47:27+00:00,https://github.com/apache/airflow/pull/44368,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2692107509,pull_request,closed,,Remove caching inside ExecutorLoader in favour of `job.executors` property,"The primary drivers of this are simplification, specifically:

1. It avoids global state -- which makes things easier to reason about. For
   instance this removes the use of `reload()` in our tests; a sure sign that
   things are overly complicated
2. It removes the wierd ""mixed"" source of truth inside SchedulerJob, where
   some places were still looking at `self.job.executors` while others were
   looking at ExecutorLoader.load_executor directly

`set_default_executor` was removed as nothing called it.

The comment about  ""Cache this executor by name here, so we can look it up
later if it is requested again, and not have to construct a new object"" is
moot as the SchedulerJob is the only thing that has persistent executor
objects, and `self.job.executors` is already that cache.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-25 20:24:30+00:00,[],2024-11-26 12:08:59+00:00,2024-11-26 12:08:55+00:00,https://github.com/apache/airflow/pull/44367,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2498968621, 'issue_id': 2692107509, 'author': 'ashb', 'body': ""I couldn't see any other uses of load executor that would break as a result of the removal of caching"", 'created_at': datetime.datetime(2024, 11, 25, 20, 28, 16, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-11-25 20:28:16 UTC): I couldn't see any other uses of load executor that would break as a result of the removal of caching

"
2691799969,pull_request,closed,,AIP-84 Migrate XCom get entries endpoint to Fastapi,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42980


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",michaeljs-c,2024-11-25 18:38:00+00:00,[],2024-11-26 20:21:09+00:00,2024-11-26 20:21:09+00:00,https://github.com/apache/airflow/pull/44366,"[('area:API', ""Airflow's REST/HTTP API""), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2500733151, 'issue_id': 2691799969, 'author': 'michaeljs-c', 'body': 'Looking into CI failures', 'created_at': datetime.datetime(2024, 11, 26, 12, 55, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500845202, 'issue_id': 2691799969, 'author': 'jason810496', 'body': '> Looking into CI failures\r\n\r\nHi @michaeljs-c, I think the current CI failure for static is cause by frontend generated code, which could be resolve by:\r\n```\r\npre-commit run ts-compile-format-lint-ui --all-files\r\n```\r\nrefer: https://github.com/apache/airflow/pull/43859#issuecomment-2488570257', 'created_at': datetime.datetime(2024, 11, 26, 13, 45, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501392106, 'issue_id': 2691799969, 'author': 'michaeljs-c', 'body': '> > Looking into CI failures\r\n> \r\n> Hi @michaeljs-c, I think the current CI failure for static is cause by frontend generated code, which could be resolve by:\r\n> \r\n> ```\r\n> pre-commit run ts-compile-format-lint-ui --all-files\r\n> ```\r\n> \r\n> refer: [#43859 (comment)](https://github.com/apache/airflow/pull/43859#issuecomment-2488570257)\r\n\r\nThanks! for some reason it got skipped during my initial pre-commit', 'created_at': datetime.datetime(2024, 11, 26, 16, 49, 16, tzinfo=datetime.timezone.utc)}]","michaeljs-c (Issue Creator) on (2024-11-26 12:55:31 UTC): Looking into CI failures

jason810496 on (2024-11-26 13:45:38 UTC): Hi @michaeljs-c, I think the current CI failure for static is cause by frontend generated code, which could be resolve by:
```
pre-commit run ts-compile-format-lint-ui --all-files
```
refer: https://github.com/apache/airflow/pull/43859#issuecomment-2488570257

michaeljs-c (Issue Creator) on (2024-11-26 16:49:16 UTC): Thanks! for some reason it got skipped during my initial pre-commit

"
2691734580,pull_request,closed,,add openblock labs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

OpenBlock is an enterprise-grade blockchain data and modeling platform for seamless protocol operations.",melotik,2024-11-25 18:06:17+00:00,[],2024-11-27 02:55:48+00:00,2024-11-27 02:55:45+00:00,https://github.com/apache/airflow/pull/44365,[],"[{'comment_id': 2498706345, 'issue_id': 2691734580, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 25, 18, 6, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502582848, 'issue_id': 2691734580, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 27, 2, 55, 47, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-25 18:06:21 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-27 02:55:47 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2691289314,pull_request,closed,,Use UI config,"Swap the UI to use the `ui/config` endpoint that will always be enabled and has better type checks.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-25 16:03:20+00:00,[],2024-11-25 17:14:25+00:00,2024-11-25 17:14:23+00:00,https://github.com/apache/airflow/pull/44364,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2691276326,pull_request,closed,,Fix ruff errors in routes public job,"https://github.com/apache/airflow/actions/runs/12013016097/job/33486044971?pr=44349#step:8:336

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-25 15:58:14+00:00,[],2024-11-25 16:20:08+00:00,2024-11-25 16:19:24+00:00,https://github.com/apache/airflow/pull/44363,[],"[{'comment_id': 2498448753, 'issue_id': 2691276326, 'author': 'pierrejeambrun', 'body': ""I'm surprised to see that the original build for the PR associated to it was successful. (Ruff didn't complain):\r\nhttps://github.com/apache/airflow/actions/runs/11983768727/job/33477766501?pr=43859"", 'created_at': datetime.datetime(2024, 11, 25, 16, 12, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498456650, 'issue_id': 2691276326, 'author': 'gopidesupavan', 'body': ""> I'm surprised to see that the original build for the PR associated to it was successful. (Ruff didn't complain): https://github.com/apache/airflow/actions/runs/11983768727/job/33477766501?pr=43859\r\n\r\nah might be due to recent upgrade to ruff version :)"", 'created_at': datetime.datetime(2024, 11, 25, 16, 15, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498464085, 'issue_id': 2691276326, 'author': 'gopidesupavan', 'body': ""> > I'm surprised to see that the original build for the PR associated to it was successful. (Ruff didn't complain): https://github.com/apache/airflow/actions/runs/11983768727/job/33477766501?pr=43859\r\n> \r\n> ah might be due to recent upgrade to ruff version :)\r\n\r\nhttps://github.com/apache/airflow/pull/44287"", 'created_at': datetime.datetime(2024, 11, 25, 16, 18, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498465788, 'issue_id': 2691276326, 'author': 'pierrejeambrun', 'body': 'Got it thanks.', 'created_at': datetime.datetime(2024, 11, 25, 16, 19, 24, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-25 16:12:41 UTC): I'm surprised to see that the original build for the PR associated to it was successful. (Ruff didn't complain):
https://github.com/apache/airflow/actions/runs/11983768727/job/33477766501?pr=43859

gopidesupavan (Issue Creator) on (2024-11-25 16:15:45 UTC): ah might be due to recent upgrade to ruff version :)

gopidesupavan (Issue Creator) on (2024-11-25 16:18:39 UTC): https://github.com/apache/airflow/pull/44287

pierrejeambrun on (2024-11-25 16:19:24 UTC): Got it thanks.

"
2691191080,pull_request,closed,,KubernetesPodOperator new callbacks and allow multiple callbacks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

I would like to have multiple callbacks in the kubernetes pod operator, and add two new callbacks.  `on_manifest_finalization` would allow the callback to make changes just before the manifest is turned into a pod.
`on_pod_wrapup` would happen after the calls to `on_pod_completion` but just before the pod is deleted.

Adding both of these plus allowing multiple callbacks would allow you to do things in the kubernetes pod operator akin to how it approaches XComs but in a modular way.  My use case here is I'm running DBT in kpo, and I want to do multiple things to the DBT artefacts after the DBT job has run, I could use `on_manifest_finalization` to insert an alpine sidecar with volumes mounted with the same intention as the XCom sidecar, where the sidecar keeps the volumes alive as files are extracted from it.  `on_pod_wrapup` would allow me to insert a single sidecar and have multiple callbacks run their `on_pod_completion` before `on_pod_wrapup` kills the sidecar.",johnhoran,2024-11-25 15:37:19+00:00,[],2025-01-27 11:55:06+00:00,2025-01-27 11:54:54+00:00,https://github.com/apache/airflow/pull/44357,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2614323269, 'issue_id': 2691191080, 'author': 'potiuk', 'body': 'Some static checks to solve after rebase', 'created_at': datetime.datetime(2025, 1, 26, 10, 52, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614329229, 'issue_id': 2691191080, 'author': 'potiuk', 'body': 'Note: We are in the process of moving all providers to a new structure - as part of https://github.com/apache/airflow/issues/46045 so if you would like to avoid having to resolve conflicts, speedy fix and rebase is something that you might want to do @johnhoran', 'created_at': datetime.datetime(2025, 1, 26, 11, 11, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614344896, 'issue_id': 2691191080, 'author': 'potiuk', 'body': 'See also devlist announcement: https://lists.apache.org/thread/dzbj5yx5kwpbwyr5yscp4wnlsp6p9v8l', 'created_at': datetime.datetime(2025, 1, 26, 11, 57, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614741727, 'issue_id': 2691191080, 'author': 'eladkal', 'body': 'I fixed the static checks but the PR has conflicts @johnhoran can you please revase and resolve them?', 'created_at': datetime.datetime(2025, 1, 27, 2, 28, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615553780, 'issue_id': 2691191080, 'author': 'eladkal', 'body': 'Failures are on papermill provider, not related to this PR', 'created_at': datetime.datetime(2025, 1, 27, 11, 52, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615558463, 'issue_id': 2691191080, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 27, 11, 54, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615558837, 'issue_id': 2691191080, 'author': 'potiuk', 'body': '> Failures are on papermill provider, not related to this PR\r\n\r\nYep. already fixed in main', 'created_at': datetime.datetime(2025, 1, 27, 11, 55, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-26 10:52:28 UTC): Some static checks to solve after rebase

potiuk on (2025-01-26 11:11:36 UTC): Note: We are in the process of moving all providers to a new structure - as part of https://github.com/apache/airflow/issues/46045 so if you would like to avoid having to resolve conflicts, speedy fix and rebase is something that you might want to do @johnhoran

potiuk on (2025-01-26 11:57:55 UTC): See also devlist announcement: https://lists.apache.org/thread/dzbj5yx5kwpbwyr5yscp4wnlsp6p9v8l

eladkal on (2025-01-27 02:28:33 UTC): I fixed the static checks but the PR has conflicts @johnhoran can you please revase and resolve them?

eladkal on (2025-01-27 11:52:48 UTC): Failures are on papermill provider, not related to this PR

boring-cyborg[bot] on (2025-01-27 11:54:56 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2025-01-27 11:55:05 UTC): Yep. already fixed in main

"
2691102702,pull_request,closed,,Bump uv version to 0.5.4,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-25 15:12:11+00:00,[],2024-11-25 16:21:43+00:00,2024-11-25 16:21:33+00:00,https://github.com/apache/airflow/pull/44349,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2498470398, 'issue_id': 2691102702, 'author': 'gopidesupavan', 'body': 'One pre-commit validation failed, fixed here https://github.com/apache/airflow/pull/44363. merging it now.', 'created_at': datetime.datetime(2024, 11, 25, 16, 21, 25, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-25 16:21:25 UTC): One pre-commit validation failed, fixed here https://github.com/apache/airflow/pull/44363. merging it now.

"
2690836410,pull_request,closed,,Fix handle missing DAGs when clearing task instances to prevent failures,"This PR handle missing DAGs when clearing task instances to prevent failures. When we delete DAG files and attempt to trigger them again, the process should access the DAGs and display an error indicating that the DAGs no longer exist, rather than causing the frontend to show an ""Oops"" error.

### Summary of Changes:
- Added warning logs for missing DAGs to prevent silent failures during task clearing.
- Improved error handling for downstream task clearing, including checks for partial_subset errors to handle cases where DAGs or downstream dependencies are unavailable.
- Updated the docstring for _clear_task_instances for better clarity and consistent style.
- Refined the grouping and handling of Task Instances by DAG and DAG Run to improve robustness and maintainability.

### Issue Reference:
Closes #44274

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jieyao-MilestoneHub,2024-11-25 13:54:25+00:00,[],2024-11-27 15:24:59+00:00,2024-11-27 15:13:12+00:00,https://github.com/apache/airflow/pull/44348,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('provider:http', '')]","[{'comment_id': 2498380426, 'issue_id': 2690836410, 'author': 'pierrejeambrun', 'body': ""Updating to 'bugfix'"", 'created_at': datetime.datetime(2024, 11, 25, 15, 46, 54, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-25 15:46:54 UTC): Updating to 'bugfix'

"
2690769625,pull_request,closed,,Clean up the pre-commit config,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jbampton,2024-11-25 13:33:47+00:00,[],2024-11-25 18:47:57+00:00,2024-11-25 18:37:00+00:00,https://github.com/apache/airflow/pull/44347,"[('area:dev-tools', '')]",[],
2690753265,pull_request,closed,,Don't set headers on the `OTLPSpanExporter`,"I'm trying to connect to [Logfire](https://logfire.pydantic.dev/docs/) without the need for an OTel collector, and this is getting in my way. Without the `headers` being set, I can do:

```bash
export OTEL_EXPORTER_OTLP_HEADERS='Authorization=...'
```

And I can connect to Logfire - ...but this also benefits any other OpenTelemetry backend.

> [!IMPORTANT]
> The `OTLPSpanExporter` sets the `Content-Type` to `application/x-protobuf` by default. This PR may break current users that depend on the `Content-Type` being checked.

As an alternative, the `OTLPSpanExporter` receives a `requests.Session`, which there we can pass the `content-type`.

I think the only way to not break current users but allow the OTel package to get the environment variables as expected is to create the `requests.Session`, but also create an `otel_content_type` setting with the default `application/json`. That said... I think it was just a mistake to add this header in the first place.",Kludex,2024-11-25 13:27:17+00:00,[],2024-11-26 15:00:16+00:00,2024-11-26 14:54:19+00:00,https://github.com/apache/airflow/pull/44346,[],"[{'comment_id': 2498147601, 'issue_id': 2690753265, 'author': 'ashb', 'body': ""Two questions, if you know/can work this out please.\r\n\r\n1. Does the breeze example with Jaeger still work: `breeze start-airflow --backend postgres --integration otel`\r\n2. How widely supported is protobuf in Otel collectors? Are there perhaps some that don't support otel and only work with JSON?"", 'created_at': datetime.datetime(2024, 11, 25, 14, 19, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498665811, 'issue_id': 2690753265, 'author': 'ferruzzi', 'body': 'Interesting.  I wonder if it might be safer to add some code which looks for that envvar and keeps json as the default, add a deprecation note that this will change in the future, and after the deprecation period remove the default and let the envvar and OTel default behavior do its thing.\r\n\r\nThat would let you get the functionality you need without breaking anyone else without notice.  But I also do not have any statistics on how many people might be affected either way so, it\'s hard to make a call if this is a ""bugfix"" we can fix immediately or a ""new breaking feature"" we need to warn about.', 'created_at': datetime.datetime(2024, 11, 25, 17, 47, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500596911, 'issue_id': 2690753265, 'author': 'Kludex', 'body': ""Okay... Sorry folks... New information... I didn't notice, but the exporter used overrides the headers anyway to use `Content-Type: application/x-protobuf`.\r\n\r\nIt really doesn't matter if you set `application/json`. That's just a not-needed, but also it prevents people to add more headers.\r\n\r\nRef.: \r\n- [OTLPMetricExporter](https://github.com/open-telemetry/opentelemetry-python/blob/6812da2787ef9265ed617f8bc89a9924981efb50/exporter/opentelemetry-exporter-otlp-proto-http/src/opentelemetry/exporter/otlp/proto/http/metric_exporter/__init__.py#L154-L156)\r\n- [OTLPSpanExporter](https://github.com/open-telemetry/opentelemetry-python/blob/6812da2787ef9265ed617f8bc89a9924981efb50/exporter/opentelemetry-exporter-otlp-proto-http/src/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py#L116)"", 'created_at': datetime.datetime(2024, 11, 26, 12, 12, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501027460, 'issue_id': 2690753265, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 26, 14, 54, 22, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-25 14:19:40 UTC): Two questions, if you know/can work this out please.

1. Does the breeze example with Jaeger still work: `breeze start-airflow --backend postgres --integration otel`
2. How widely supported is protobuf in Otel collectors? Are there perhaps some that don't support otel and only work with JSON?

ferruzzi on (2024-11-25 17:47:48 UTC): Interesting.  I wonder if it might be safer to add some code which looks for that envvar and keeps json as the default, add a deprecation note that this will change in the future, and after the deprecation period remove the default and let the envvar and OTel default behavior do its thing.

That would let you get the functionality you need without breaking anyone else without notice.  But I also do not have any statistics on how many people might be affected either way so, it's hard to make a call if this is a ""bugfix"" we can fix immediately or a ""new breaking feature"" we need to warn about.

Kludex (Issue Creator) on (2024-11-26 12:12:41 UTC): Okay... Sorry folks... New information... I didn't notice, but the exporter used overrides the headers anyway to use `Content-Type: application/x-protobuf`.

It really doesn't matter if you set `application/json`. That's just a not-needed, but also it prevents people to add more headers.

Ref.: 
- [OTLPMetricExporter](https://github.com/open-telemetry/opentelemetry-python/blob/6812da2787ef9265ed617f8bc89a9924981efb50/exporter/opentelemetry-exporter-otlp-proto-http/src/opentelemetry/exporter/otlp/proto/http/metric_exporter/__init__.py#L154-L156)
- [OTLPSpanExporter](https://github.com/open-telemetry/opentelemetry-python/blob/6812da2787ef9265ed617f8bc89a9924981efb50/exporter/opentelemetry-exporter-otlp-proto-http/src/opentelemetry/exporter/otlp/proto/http/trace_exporter/__init__.py#L116)

boring-cyborg[bot] on (2024-11-26 14:54:22 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2690571018,pull_request,closed,,AIP-84 Refactor SortParm,"Related: https://github.com/apache/airflow/pull/42959#issuecomment-2422749143  

### Refactor `SortParam`  

Leverage the `to_replace` functionality introduced in https://github.com/apache/airflow/pull/43793 and allow the `Column` type to be used in the `to_replace` dictionary.  
This change enables the complete removal of `attr_mapping` from `SortParam`, as most instances of `SortParam` do not require `attr_mapping`. 
",jason810496,2024-11-25 12:28:19+00:00,[],2024-11-27 10:25:50+00:00,2024-11-27 10:25:49+00:00,https://github.com/apache/airflow/pull/44345,[],"[{'comment_id': 2500113316, 'issue_id': 2690571018, 'author': 'pierrejeambrun', 'body': 'Need to resolve conflicts. Good to merge', 'created_at': datetime.datetime(2024, 11, 26, 9, 33, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500750641, 'issue_id': 2690571018, 'author': 'jason810496', 'body': 'Resolve conflict, wait for CI ⚙️', 'created_at': datetime.datetime(2024, 11, 26, 13, 3, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501397318, 'issue_id': 2690571018, 'author': 'jason810496', 'body': 'Just adapt https://github.com/apache/airflow/pull/44393 to this PR.', 'created_at': datetime.datetime(2024, 11, 26, 16, 50, 29, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-26 09:33:54 UTC): Need to resolve conflicts. Good to merge

jason810496 (Issue Creator) on (2024-11-26 13:03:53 UTC): Resolve conflict, wait for CI ⚙️

jason810496 (Issue Creator) on (2024-11-26 16:50:29 UTC): Just adapt https://github.com/apache/airflow/pull/44393 to this PR.

"
2690516839,pull_request,closed,,Simplify asset decorator implementation,"Since AssetDefinition subclasses Asset, we don't really need the to_asset() method, but can just pass self in.

I also moved some imports around to reduce module loading at import time.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",uranusjr,2024-11-25 12:05:40+00:00,[],2024-11-26 10:51:23+00:00,2024-11-26 10:51:21+00:00,https://github.com/apache/airflow/pull/44344,"[('area:task-sdk', None)]","[{'comment_id': 2499936550, 'issue_id': 2690516839, 'author': 'Lee-W', 'body': 'overall looks good, but look like we need to update some test cases 🤔', 'created_at': datetime.datetime(2024, 11, 26, 8, 9, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2499981903, 'issue_id': 2690516839, 'author': 'uranusjr', 'body': 'Actually that’s a bug in my implementation. Fixed.', 'created_at': datetime.datetime(2024, 11, 26, 8, 31, 8, tzinfo=datetime.timezone.utc)}]","Lee-W on (2024-11-26 08:09:47 UTC): overall looks good, but look like we need to update some test cases 🤔

uranusjr (Issue Creator) on (2024-11-26 08:31:08 UTC): Actually that’s a bug in my implementation. Fixed.

"
2690203934,pull_request,closed,,AIP-38 Fix 401 and 403 handling,"Small improvements:
- Redirection URL is changed to use the legacy `login` endpoint for now. At the moment the new API does not expose any `/login` route, and the current redirection will cause a plain `404`. (We can swap that back later when the new login endpoint is implemented)

- Do not handle 403. Permissions errors mean that the user is authenticated and recognized, he just does not have permission to do that. In that case redirecting him to `/login` does not serve any purpose as the user is already authenticated. We should instead handle the `403` and display an appropriate message to the User.",pierrejeambrun,2024-11-25 10:42:23+00:00,['pierrejeambrun'],2024-11-25 13:08:40+00:00,2024-11-25 13:08:37+00:00,https://github.com/apache/airflow/pull/44342,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2690168481,pull_request,closed,,Dont add extra deps for providers with same cross provider deps,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44195

After changes:
```
deps is ['apache-airflow-providers-common-sql']
extras is  {'amazon': ['apache-airflow-providers-amazon'], 'common.sql': ['apache-airflow-providers-common-sql'], 'openlineage': ['apache-airflow-providers-openlineage']}
EXTRAS ARE {'amazon': ['apache-airflow-providers-amazon>=2.6.0'], 'openlineage': ['apache-airflow-providers-openlineage']}

```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-25 10:31:33+00:00,[],2024-11-28 12:53:39+00:00,2024-11-28 11:37:14+00:00,https://github.com/apache/airflow/pull/44341,"[('area:dev-tools', '')]","[{'comment_id': 2500806881, 'issue_id': 2690168481, 'author': 'amoghrajesh', 'body': '@potiuk @eladkal @gopidesupavan can you take a look when you have some time?', 'created_at': datetime.datetime(2024, 11, 26, 13, 29, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503470076, 'issue_id': 2690168481, 'author': 'amoghrajesh', 'body': '@potiuk @gopidesupavan i handled it using the requirements parser, its much cleaner now!', 'created_at': datetime.datetime(2024, 11, 27, 10, 13, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503702548, 'issue_id': 2690168481, 'author': 'potiuk', 'body': 'Interesting error. The ""get_install_requiresments"" is probably not the best idea to use because it adds escaping to `""` which is needed to produce  ""pyproject.toml"". \r\n\r\n```\r\ndependencies = [\r\n{{- INSTALL_REQUIREMENTS }}\r\n]\r\n```\r\n\r\nInstead you should just use `PROVIDER_DEPENDENCIES.get(provider_id)[""deps""]` @amoghrajesh  - that one returns unescaped dependencies.\r\n\r\n(and we do not need to us version suffix - this one is merely used to filter out extras - so version suffix does not matter).', 'created_at': datetime.datetime(2024, 11, 27, 12, 4, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503704323, 'issue_id': 2690168481, 'author': 'potiuk', 'body': 'Maybe worth to add a comment in `get_install_requirements` that it escapes the dependencies :).', 'created_at': datetime.datetime(2024, 11, 27, 12, 4, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503813953, 'issue_id': 2690168481, 'author': 'amoghrajesh', 'body': '> Interesting error. The ""get_install_requiresments"" is probably not the best idea to use because it adds escaping to `""` which is needed to produce ""pyproject.toml"".\r\n> \r\n> ```\r\n> dependencies = [\r\n> {{- INSTALL_REQUIREMENTS }}\r\n> ]\r\n> ```\r\n> \r\n> Instead you should just use `PROVIDER_DEPENDENCIES.get(provider_id)[""deps""]` @amoghrajesh - that one returns unescaped dependencies.\r\n> \r\n> (and we do not need to us version suffix - this one is merely used to filter out extras - so version suffix does not matter).\r\n\r\nOh i see, let me correct that!', 'created_at': datetime.datetime(2024, 11, 27, 12, 57, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503883824, 'issue_id': 2690168481, 'author': 'amoghrajesh', 'body': '@potiuk the tests expect a version suffix, do we need it or not at all?', 'created_at': datetime.datetime(2024, 11, 27, 13, 29, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503928963, 'issue_id': 2690168481, 'author': 'amoghrajesh', 'body': '@potiuk i removed the `version_suffix` related changes. I will do it in a follow up', 'created_at': datetime.datetime(2024, 11, 27, 13, 50, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505268393, 'issue_id': 2690168481, 'author': 'amoghrajesh', 'body': 'Yep. Working on it. Looks like i did uv sync and precommit never ran to tell me this!', 'created_at': datetime.datetime(2024, 11, 28, 5, 3, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506055831, 'issue_id': 2690168481, 'author': 'potiuk', 'body': 'NICE!', 'created_at': datetime.datetime(2024, 11, 28, 12, 53, 38, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-26 13:29:11 UTC): @potiuk @eladkal @gopidesupavan can you take a look when you have some time?

amoghrajesh (Issue Creator) on (2024-11-27 10:13:11 UTC): @potiuk @gopidesupavan i handled it using the requirements parser, its much cleaner now!

potiuk on (2024-11-27 12:04:04 UTC): Interesting error. The ""get_install_requiresments"" is probably not the best idea to use because it adds escaping to `""` which is needed to produce  ""pyproject.toml"". 

```
dependencies = [
{{- INSTALL_REQUIREMENTS }}
]
```

Instead you should just use `PROVIDER_DEPENDENCIES.get(provider_id)[""deps""]` @amoghrajesh  - that one returns unescaped dependencies.

(and we do not need to us version suffix - this one is merely used to filter out extras - so version suffix does not matter).

potiuk on (2024-11-27 12:04:57 UTC): Maybe worth to add a comment in `get_install_requirements` that it escapes the dependencies :).

amoghrajesh (Issue Creator) on (2024-11-27 12:57:25 UTC): Oh i see, let me correct that!

amoghrajesh (Issue Creator) on (2024-11-27 13:29:52 UTC): @potiuk the tests expect a version suffix, do we need it or not at all?

amoghrajesh (Issue Creator) on (2024-11-27 13:50:04 UTC): @potiuk i removed the `version_suffix` related changes. I will do it in a follow up

amoghrajesh (Issue Creator) on (2024-11-28 05:03:41 UTC): Yep. Working on it. Looks like i did uv sync and precommit never ran to tell me this!

potiuk on (2024-11-28 12:53:38 UTC): NICE!

"
2690124324,pull_request,closed,,[DO NOT MERGE]: Just to check failing test,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ephraimbuddy,2024-11-25 10:15:38+00:00,[],2024-11-25 10:46:46+00:00,2024-11-25 10:46:26+00:00,https://github.com/apache/airflow/pull/44340,"[('full tests needed', 'We need to run full set of tests for this PR to merge')]",[],
2690038818,pull_request,closed,,[DO NOT MERGE] Test in-progres new pydantic version,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-25 09:47:37+00:00,[],2024-11-25 23:11:48+00:00,2024-11-25 23:11:48+00:00,https://github.com/apache/airflow/pull/44339,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2499221810, 'issue_id': 2690038818, 'author': 'potiuk', 'body': 'Closing as tests passed.', 'created_at': datetime.datetime(2024, 11, 25, 23, 11, 48, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-25 23:11:48 UTC): Closing as tests passed.

"
2689744681,pull_request,closed,,Add edge provider to boring-cyborg.yml,,eladkal,2024-11-25 08:30:51+00:00,[],2024-11-25 11:08:54+00:00,2024-11-25 09:36:03+00:00,https://github.com/apache/airflow/pull/44338,"[('area:dev-tools', '')]",[],
2689504095,pull_request,closed,,[Refactor] Move orderby type annotations of Assets endpoint to parameters,Move orderby type annotations to parameters,rawwar,2024-11-25 07:18:28+00:00,[],2025-01-29 00:14:59+00:00,2025-01-29 00:14:59+00:00,https://github.com/apache/airflow/pull/44335,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2498028871, 'issue_id': 2689504095, 'author': 'rawwar', 'body': ""> Why do we only move the `order_by` from assets into the `parameters` and not the others ?\r\n\r\nI did not want to do everything before confirming if this is a good idea. I'll update this PR to include all endpoints\r\n\r\n> The idea of `parameters.py` is for re-usable parameters, but those seem to be very specific to 1 route.\r\n> \r\n> Do we plan on re-using them ?\r\n\r\nwe might have to, if we plan to add more endpoints. It is similar to DagWarning filter or others. Not reusable right now. But, can be."", 'created_at': datetime.datetime(2024, 11, 25, 13, 29, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498056398, 'issue_id': 2689504095, 'author': 'pierrejeambrun', 'body': ""I don't think they will be reused actually. OrderBy are specific for each resource (dagrun, dag, asset, pool, variables, etc...).\r\n\r\nAnd for 1 specific resource, the only endpoint that leverage this ordering is the `get_resources` (listing the resources).\r\n\r\nDo we have any `order_by` that is re-used by at least 2 endpoints ?"", 'created_at': datetime.datetime(2024, 11, 25, 13, 42, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498122691, 'issue_id': 2689504095, 'author': 'rawwar', 'body': ""> I don't think they will be reused actually. OrderBy are specific for each resource (dagrun, dag, asset, pool, variables, etc...).\r\n> \r\n> And for 1 specific resource, the only endpoint that leverage this ordering is the `get_resources` (listing the resources).\r\n> \r\n> Do we have any `order_by` that is re-used by at least 2 endpoints ?\r\n\r\nYou are correct. I just checked. How about declaring sortable columns as constants and probably update SortParams to get these based on the Model?"", 'created_at': datetime.datetime(2024, 11, 25, 14, 9, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498404049, 'issue_id': 2689504095, 'author': 'pierrejeambrun', 'body': ""> You are correct. I just checked. How about declaring sortable columns as constants and probably update SortParams to get these based on the Model?\r\n\r\nI don't know, as long as these hardcoded array of string (sortable columns) are specified once, I don't feel the need to over factorize or simplify.\r\n\r\nWe cannot put the `sortable_columns` on the Model. Otherwise it introduce a dependency from the db layer to the webserver views/routes. That cannot be possible, the dependency should be the other way around, so the mapping between Models and sortable column has to leave somewhere else, probably in the webserver (FastAPI API). Then we end up with a mapping of constant arrays and SQLAlchemy Models ... and I find this messy too.\r\n\r\n\r\nBut maybe you have an idea on how to achieve a cleaner approach, I'd be glad to review a PR for that.\r\n\r\n\r\nMaybe another solution is instead of having 'strings' those could already be references to the actual column `DagRun.start_date`, etc... etc... benefiting from code completion, references, and removing hardcoded strings."", 'created_at': datetime.datetime(2024, 11, 25, 15, 55, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2584944467, 'issue_id': 2689504095, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 11, 0, 15, 21, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-25 13:29:42 UTC): I did not want to do everything before confirming if this is a good idea. I'll update this PR to include all endpoints


we might have to, if we plan to add more endpoints. It is similar to DagWarning filter or others. Not reusable right now. But, can be.

pierrejeambrun on (2024-11-25 13:42:11 UTC): I don't think they will be reused actually. OrderBy are specific for each resource (dagrun, dag, asset, pool, variables, etc...).

And for 1 specific resource, the only endpoint that leverage this ordering is the `get_resources` (listing the resources).

Do we have any `order_by` that is re-used by at least 2 endpoints ?

rawwar (Issue Creator) on (2024-11-25 14:09:20 UTC): You are correct. I just checked. How about declaring sortable columns as constants and probably update SortParams to get these based on the Model?

pierrejeambrun on (2024-11-25 15:55:33 UTC): I don't know, as long as these hardcoded array of string (sortable columns) are specified once, I don't feel the need to over factorize or simplify.

We cannot put the `sortable_columns` on the Model. Otherwise it introduce a dependency from the db layer to the webserver views/routes. That cannot be possible, the dependency should be the other way around, so the mapping between Models and sortable column has to leave somewhere else, probably in the webserver (FastAPI API). Then we end up with a mapping of constant arrays and SQLAlchemy Models ... and I find this messy too.


But maybe you have an idea on how to achieve a cleaner approach, I'd be glad to review a PR for that.


Maybe another solution is instead of having 'strings' those could already be references to the actual column `DagRun.start_date`, etc... etc... benefiting from code completion, references, and removing hardcoded strings.

github-actions[bot] on (2025-01-11 00:15:21 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2689274426,pull_request,closed,,dag_run table - replace column conf type - byte ( that store a python pickle ) by a JSON,closes #43933,rawwar,2024-11-25 05:46:46+00:00,[],2024-12-13 14:42:45+00:00,2024-12-13 14:42:45+00:00,https://github.com/apache/airflow/pull/44333,[],"[{'comment_id': 2505326973, 'issue_id': 2689274426, 'author': 'rawwar', 'body': '@kaxil , Should I be following what you did for XCOM value for DagRun.conf as well? \r\n\r\nYou mentioned following in the migration:\r\n\r\n```\r\n    # Summary of the change:\r\n    # 1. Create an archived table (`_xcom_archive`) to store the current ""pickled"" data in the xcom table\r\n    # 2. Extract and archive the pickled data using the condition\r\n    # 3. Delete the pickled data from the xcom table so that we can update the column type\r\n    # 4. Update the XCom.value column type to JSON from LargeBinary/LongBlob\r\n```', 'created_at': datetime.datetime(2024, 11, 28, 6, 5, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506079086, 'issue_id': 2689274426, 'author': 'kaxil', 'body': '> @kaxil , Should I be following what you did for XCOM value for DagRun.conf as well?\r\n> \r\n> You mentioned following in the migration:\r\n> \r\n> ```\r\n>     # Summary of the change:\r\n>     # 1. Create an archived table (`_xcom_archive`) to store the current ""pickled"" data in the xcom table\r\n>     # 2. Extract and archive the pickled data using the condition\r\n>     # 3. Delete the pickled data from the xcom table so that we can update the column type\r\n>     # 4. Update the XCom.value column type to JSON from LargeBinary/LongBlob\r\n> ```\r\n\r\nYeah, that\'s the only way I could think of to handle it without causing data loss', 'created_at': datetime.datetime(2024, 11, 28, 13, 4, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507585305, 'issue_id': 2689274426, 'author': 'rawwar', 'body': 'So, I\'m not sure why CI is all green. But, I tried to verify the alter table query and it isn\'t actually working. I tried to just select the data in conf data as below\r\n\r\n```\r\nselect conf, CAST(CONVERT_FROM(conf, \'UTF8\') AS JSONB) from dag_run\r\n```\r\n\r\nand its throwing \r\n\r\n`error: ERROR:  invalid byte sequence for encoding ""UTF8"": 0x80`', 'created_at': datetime.datetime(2024, 11, 29, 11, 5, 31, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-28 06:05:17 UTC): @kaxil , Should I be following what you did for XCOM value for DagRun.conf as well? 

You mentioned following in the migration:

```
    # Summary of the change:
    # 1. Create an archived table (`_xcom_archive`) to store the current ""pickled"" data in the xcom table
    # 2. Extract and archive the pickled data using the condition
    # 3. Delete the pickled data from the xcom table so that we can update the column type
    # 4. Update the XCom.value column type to JSON from LargeBinary/LongBlob
```

kaxil on (2024-11-28 13:04:35 UTC): Yeah, that's the only way I could think of to handle it without causing data loss

rawwar (Issue Creator) on (2024-11-29 11:05:31 UTC): So, I'm not sure why CI is all green. But, I tried to verify the alter table query and it isn't actually working. I tried to just select the data in conf data as below

```
select conf, CAST(CONVERT_FROM(conf, 'UTF8') AS JSONB) from dag_run
```

and its throwing 

`error: ERROR:  invalid byte sequence for encoding ""UTF8"": 0x80`

"
2688953613,pull_request,closed,,AIP-84 Migrate /object/grid_data from views to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42595

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-11-25 03:39:31+00:00,[],2024-12-23 14:58:09+00:00,2024-12-23 14:57:26+00:00,https://github.com/apache/airflow/pull/44332,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]","[{'comment_id': 2502510134, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': 'I addressed the comments. Thanks for the review! Some parts turned out to be more complex than I imagined. It still needs small touches and should be ready with unit tests soon. :sweat_smile:', 'created_at': datetime.datetime(2024, 11, 27, 2, 10, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509675556, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '@pierrejeambrun this is ready for review. I removed the WIP earlier but forgot to ping you again :sweat_smile: Please when you have time, thanks!', 'created_at': datetime.datetime(2024, 12, 1, 10, 25, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515046251, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': ""> Great.\r\n> \r\n> Looking good, just a few suggestions / improvement on the code, but nothing blocking.\r\n> \r\n> I'll also let Brent double check that the interface corresponds to the UI specifications.\r\n\r\nThat sounds amazing! Let me know if I have missed anything, and we can fix it at an early stage. \r\nI will review the comments and adjust the code accordingly in the coming hours. Many thanks for the review and the comments!"", 'created_at': datetime.datetime(2024, 12, 3, 16, 34, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515049790, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '> Great work! This will power so much of the new UI!\r\n> \r\n> In the old UI we also included the note for both dag runs and task instances. We should still include it for the new UI.\r\n\r\nI was writing my message and saw your review now :slightly_smiling_face:  Thanks for the review, Brent!', 'created_at': datetime.datetime(2024, 12, 3, 16, 36, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2519980071, 'issue_id': 2688953613, 'author': 'pierrejeambrun', 'body': 'Can you also plug the new common filters `include_upstream` and `include_downstream` in `structure_data` (`structure.py`)', 'created_at': datetime.datetime(2024, 12, 5, 10, 59, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526388783, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '> Can you also plug the new common filters `include_upstream` and `include_downstream` in `structure_data` (`structure.py`)\r\n\r\nI already included this in the previous commit, updating that endpoint params according to changes on those command `upstream|downstream` variables :)', 'created_at': datetime.datetime(2024, 12, 8, 21, 25, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529694214, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '> After more manual testing. It looks like we have a few issues.\r\n> \r\n> Using the `example_task_group` Dag:\r\n> \r\n> * `section_1` is correct if everything runs normally. But manually mark a child task as failed. Then the `states` dict is correct but overall_state was not updated\r\n> * `section_2` the `task_count` is correct at 2 if you assume its nested task group is a single task but the list of `states` shows 4 states which would be correct if you ignore task groups and only count the actual number of tasks no matter how nested they may be.\r\n\r\nThanks a lot for the review and additional tests! \r\nI have adjusted the code accordingly. Indeed it was missing recursive `task_groups` and `overall_state` calculation had problem with the order of the loops :sweat_smile:', 'created_at': datetime.datetime(2024, 12, 9, 22, 43, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536752788, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '> This is coming along well! Thanks for all your patience as I test this endpoint out more and more.\r\n\r\nMy pleasure! I am happy that we ensuring everything will run as expected before shipping this one. Thanks for having been testing multiple times throughout the PR! :) \r\nI will take a look at these soon. Thanks!', 'created_at': datetime.datetime(2024, 12, 11, 18, 13, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539838485, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '>We only want to count its immediate children and their states. So section_2, should only have a count of 2 and states of failed: 1, success: 1\r\n\r\nI misunderstood your earlier message from this one related to the representation of nested task groups. I have now included smaller steps to ensure the correct calculation.', 'created_at': datetime.datetime(2024, 12, 12, 19, 25, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539952587, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': ""I fixed the mypy check, I am surprised how my local pre-commit couldn't catch that. \r\nAdditionally, changed the `child_state`, I agree, it can reduce confusion"", 'created_at': datetime.datetime(2024, 12, 12, 20, 27, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541816275, 'issue_id': 2688953613, 'author': 'bbovenzi', 'body': 'Thanks so much. We are nearly there!\r\n\r\n1. Can you check that `limit` is actually being respected? In my manual testing, I was trying to only fetch 14 runs but I always got the default of 100. @pierrejeambrun would you have any ideas here?\r\n\r\n2. Can we add a test case for a triply nested dag group? Because it looks like we\'re only bubbling a failed state up twice.\r\n\r\nCurrent UI:\r\n<img width=""720"" alt=""Screenshot 2024-12-13 at 11 26 56\u202fAM"" src=""https://github.com/user-attachments/assets/ad7f79dd-3cf5-48e6-80b6-9e735ed67056"" />\r\n\r\nLegacy UI:\r\n<img width=""768"" alt=""Screenshot 2024-12-13 at 11 28 39\u202fAM"" src=""https://github.com/user-attachments/assets/0ba6b17b-0cbd-4417-97d5-ed7023acba6d"" />', 'created_at': datetime.datetime(2024, 12, 13, 16, 29, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2545723758, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': "">* Can you check that limit is actually being respected? In my manual testing, I was trying to only fetch 14 runs but I always got the default of 100. @pierrejeambrun would you have any ideas here?\r\n>* Can we add a test case for a triply nested dag group? Because it looks like we're only bubbling a failed state up twice.\r\n\r\nThanks for the comment! I will include test cases for more nested groups and test the limit accordingly. \r\n\r\n>A few things to adjust before we can merge. Also some part of the logic are re-implementation (state propagation bug mentioned by Brent), I would suggest to try to keep things similar to the legacy implementation that has proven to be correct for many edge cases. Unless some stuff need improving of course, but the legacy code seems cleaner to me at this point. Maybe just because i'm more used to it.\r\n\r\nThanks for the detailed review! \r\nI found the legacy implementation more complex to understand, to be honest :sweat_smile: For example, I couldn't easily grasp these edge cases (mostly for `Mapped` objects) which didn't included in couple of iterations (getting used to is the indication here :+1: ). We have covered most edge cases here too. Sorry if methods without comments made any confusion and took your time more while reviewing!\r\nI am not against converting the new logic to legacy implementation. If you think this could bring complexity, let's do that. Which area would you like to see the legacy implementation? I copied most of the logic from the legacy code to here other than building up the `task map` and decoupling the logic into multiple methods which was mostly populated under `dag_to_grid`. \r\n\r\nI will check these comments in detail today and start making the changes."", 'created_at': datetime.datetime(2024, 12, 16, 14, 7, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2545873207, 'issue_id': 2688953613, 'author': 'pierrejeambrun', 'body': ""> I found the legacy implementation more complex to understand\r\n\r\nI'm likely biased because i'm familiar with the old one. A fresh eye is always welcome and if you feel that way I'm sure others will find this new implementation easier to grasp, i'll just get used to it :).\r\n\r\nAs long as we have tests covering those edge cases we should be fine."", 'created_at': datetime.datetime(2024, 12, 16, 15, 6, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546737593, 'issue_id': 2688953613, 'author': 'bbovenzi', 'body': ""Honestly, I don't think I did a great job with `dag_to_grid` so it can definitely be improved. Either way, its a lot of complicated recursive logic so let's make sure we have tests to help us out."", 'created_at': datetime.datetime(2024, 12, 16, 20, 54, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2548912021, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': 'Amazing, thanks both of you for the open-minded approach and constructive feedback! :)\r\nI really appreciate the great work done here. Handling recursive logic like this isn’t easy. This work would take much longer without that logic already in place. I am focusing on adding the necessary tests and checking the areas you’ve highlighted. The PR will be updated soon.', 'created_at': datetime.datetime(2024, 12, 17, 16, 13, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557854580, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': "">Can you check that limit is actually being respected? In my manual testing, I was trying to only fetch 14 runs but I always got the default of 100. @pierrejeambrun would you have any ideas here?\r\n\r\nI have checked and it seems like it is working fine. I have included a test case for it.\r\n\r\n>Can we add a test case for a triply nested dag group? Because it looks like we're only bubbling a failed state up twice.\r\n\r\nIndeed, this needs to be recalculated since the entire parent state is updated accordingly. I have included that small calculation to cascade this to all recursive parent groups. I have also included test cases for nested loops. I have tested locally with a case that is exactly similar to the picture you sent with 3 depth. \r\n\r\n>As long as we have tests covering those edge cases we should be fine.\r\n\r\nI have included multiple test cases. I have also updated the code according to the comments. I will resolve them accordingly. \r\n\r\nOnly one specific thing to mention in general is I have included the `SortParam` `OR method`. Since the `value` won't be `null`, the only thing to compare is the generated way which falls to the primary key. This made me eliminate the unnecessary method and make or with `order_by | SortParam(...., <first_element_ordering>)`.  If you think this isn't generic enough to put on SortParam, I can move the OR logic to the grid method.\r\n\r\n---\r\n\r\nSorry for the delay! Many thanks for the tests and reviews!"", 'created_at': datetime.datetime(2024, 12, 20, 22, 53, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558002308, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': 'I double-checked the parameters created with `filter_param_factory`, and they weren’t working as expected. 😕 To address this, I needed to adjust the `run_types` and `run_states` parameter names to `run_type` and `state`, respectively. It seems that `filter_param_factory` requires the parameter names to match the column names to function correctly. \r\n\r\nAdditionally, I have included the remaining two filter tests to ensure full coverage. With this update, all filters have been tested.\r\n\r\nThanks!', 'created_at': datetime.datetime(2024, 12, 21, 5, 14, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559689679, 'issue_id': 2688953613, 'author': 'bugraoz93', 'body': '> Code and test cases look good, beside the couple of nits, ready to merge.\r\n\r\nAmazing news, just pushed the changes and resolved the threads. Thanks a lot for your detailed review!', 'created_at': datetime.datetime(2024, 12, 23, 13, 13, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559855816, 'issue_id': 2688953613, 'author': 'pierrejeambrun', 'body': 'cc: @bbovenzi just merged. Hoping this can enable further development for the front end side.', 'created_at': datetime.datetime(2024, 12, 23, 14, 58, 7, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-11-27 02:10:52 UTC): I addressed the comments. Thanks for the review! Some parts turned out to be more complex than I imagined. It still needs small touches and should be ready with unit tests soon. :sweat_smile:

bugraoz93 (Issue Creator) on (2024-12-01 10:25:30 UTC): @pierrejeambrun this is ready for review. I removed the WIP earlier but forgot to ping you again :sweat_smile: Please when you have time, thanks!

bugraoz93 (Issue Creator) on (2024-12-03 16:34:41 UTC): That sounds amazing! Let me know if I have missed anything, and we can fix it at an early stage. 
I will review the comments and adjust the code accordingly in the coming hours. Many thanks for the review and the comments!

bugraoz93 (Issue Creator) on (2024-12-03 16:36:16 UTC): I was writing my message and saw your review now :slightly_smiling_face:  Thanks for the review, Brent!

pierrejeambrun on (2024-12-05 10:59:57 UTC): Can you also plug the new common filters `include_upstream` and `include_downstream` in `structure_data` (`structure.py`)

bugraoz93 (Issue Creator) on (2024-12-08 21:25:20 UTC): I already included this in the previous commit, updating that endpoint params according to changes on those command `upstream|downstream` variables :)

bugraoz93 (Issue Creator) on (2024-12-09 22:43:35 UTC): Thanks a lot for the review and additional tests! 
I have adjusted the code accordingly. Indeed it was missing recursive `task_groups` and `overall_state` calculation had problem with the order of the loops :sweat_smile:

bugraoz93 (Issue Creator) on (2024-12-11 18:13:28 UTC): My pleasure! I am happy that we ensuring everything will run as expected before shipping this one. Thanks for having been testing multiple times throughout the PR! :) 
I will take a look at these soon. Thanks!

bugraoz93 (Issue Creator) on (2024-12-12 19:25:49 UTC): I misunderstood your earlier message from this one related to the representation of nested task groups. I have now included smaller steps to ensure the correct calculation.

bugraoz93 (Issue Creator) on (2024-12-12 20:27:13 UTC): I fixed the mypy check, I am surprised how my local pre-commit couldn't catch that. 
Additionally, changed the `child_state`, I agree, it can reduce confusion

bbovenzi on (2024-12-13 16:29:38 UTC): Thanks so much. We are nearly there!

1. Can you check that `limit` is actually being respected? In my manual testing, I was trying to only fetch 14 runs but I always got the default of 100. @pierrejeambrun would you have any ideas here?

2. Can we add a test case for a triply nested dag group? Because it looks like we're only bubbling a failed state up twice.

Current UI:
<img width=""720"" alt=""Screenshot 2024-12-13 at 11 26 56 AM"" src=""https://github.com/user-attachments/assets/ad7f79dd-3cf5-48e6-80b6-9e735ed67056"" />

Legacy UI:
<img width=""768"" alt=""Screenshot 2024-12-13 at 11 28 39 AM"" src=""https://github.com/user-attachments/assets/0ba6b17b-0cbd-4417-97d5-ed7023acba6d"" />

bugraoz93 (Issue Creator) on (2024-12-16 14:07:14 UTC): Thanks for the comment! I will include test cases for more nested groups and test the limit accordingly. 


Thanks for the detailed review! 
I found the legacy implementation more complex to understand, to be honest :sweat_smile: For example, I couldn't easily grasp these edge cases (mostly for `Mapped` objects) which didn't included in couple of iterations (getting used to is the indication here :+1: ). We have covered most edge cases here too. Sorry if methods without comments made any confusion and took your time more while reviewing!
I am not against converting the new logic to legacy implementation. If you think this could bring complexity, let's do that. Which area would you like to see the legacy implementation? I copied most of the logic from the legacy code to here other than building up the `task map` and decoupling the logic into multiple methods which was mostly populated under `dag_to_grid`. 

I will check these comments in detail today and start making the changes.

pierrejeambrun on (2024-12-16 15:06:34 UTC): I'm likely biased because i'm familiar with the old one. A fresh eye is always welcome and if you feel that way I'm sure others will find this new implementation easier to grasp, i'll just get used to it :).

As long as we have tests covering those edge cases we should be fine.

bbovenzi on (2024-12-16 20:54:47 UTC): Honestly, I don't think I did a great job with `dag_to_grid` so it can definitely be improved. Either way, its a lot of complicated recursive logic so let's make sure we have tests to help us out.

bugraoz93 (Issue Creator) on (2024-12-17 16:13:55 UTC): Amazing, thanks both of you for the open-minded approach and constructive feedback! :)
I really appreciate the great work done here. Handling recursive logic like this isn’t easy. This work would take much longer without that logic already in place. I am focusing on adding the necessary tests and checking the areas you’ve highlighted. The PR will be updated soon.

bugraoz93 (Issue Creator) on (2024-12-20 22:53:08 UTC): I have checked and it seems like it is working fine. I have included a test case for it.


Indeed, this needs to be recalculated since the entire parent state is updated accordingly. I have included that small calculation to cascade this to all recursive parent groups. I have also included test cases for nested loops. I have tested locally with a case that is exactly similar to the picture you sent with 3 depth. 


I have included multiple test cases. I have also updated the code according to the comments. I will resolve them accordingly. 

Only one specific thing to mention in general is I have included the `SortParam` `OR method`. Since the `value` won't be `null`, the only thing to compare is the generated way which falls to the primary key. This made me eliminate the unnecessary method and make or with `order_by | SortParam(...., <first_element_ordering>)`.  If you think this isn't generic enough to put on SortParam, I can move the OR logic to the grid method.

---

Sorry for the delay! Many thanks for the tests and reviews!

bugraoz93 (Issue Creator) on (2024-12-21 05:14:40 UTC): I double-checked the parameters created with `filter_param_factory`, and they weren’t working as expected. 😕 To address this, I needed to adjust the `run_types` and `run_states` parameter names to `run_type` and `state`, respectively. It seems that `filter_param_factory` requires the parameter names to match the column names to function correctly. 

Additionally, I have included the remaining two filter tests to ensure full coverage. With this update, all filters have been tested.

Thanks!

bugraoz93 (Issue Creator) on (2024-12-23 13:13:09 UTC): Amazing news, just pushed the changes and resolved the threads. Thanks a lot for your detailed review!

pierrejeambrun on (2024-12-23 14:58:07 UTC): cc: @bbovenzi just merged. Hoping this can enable further development for the front end side.

"
2688575776,pull_request,closed,,Bugfix/caplog flaky test in extra operator link test,"Alternative to #44329

Trying to fix https://github.com/apache/airflow/actions/runs/11998950574/job/33446424923#step:7:937

The error appearing in all of the builds mostly random job.",jscheffl,2024-11-24 23:06:31+00:00,[],2024-11-25 00:32:28+00:00,2024-11-24 23:25:12+00:00,https://github.com/apache/airflow/pull/44331,"[('area:serialization', '')]","[{'comment_id': 2496454420, 'issue_id': 2688575776, 'author': 'potiuk', 'body': 'nice', 'created_at': datetime.datetime(2024, 11, 25, 0, 32, 27, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-25 00:32:27 UTC): nice

"
2688550558,pull_request,closed,,Migrate Edge calls for Worker to FastAPI part 2 - Logs routes,"Follow-up PR as incremental part of #44311

Note: Only the last commit is the relevant change, the first commit is from #44311

To prepare EdgeWorker to be independent of AIP-44 Internal API, this PR is the third step in adding/migrating to FastAPI. The calls to ""Logs"" API to (1) get log path and (2) push log chunks are now real REST API calls, not using internal API.

I would separate the other internal API calls to follow-up PRs as this is already quite large. Especially cause for ongoing Airflow 2.10 Connexion API + Swagger manually need to be generated whereas the main workstream for Airflow 3 uses FastAPI.
",jscheffl,2024-11-24 22:40:56+00:00,[],2024-11-30 22:22:08+00:00,2024-11-30 22:20:26+00:00,https://github.com/apache/airflow/pull/44330,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2509397777, 'issue_id': 2688550558, 'author': 'potiuk', 'body': 'Re-reviewed... Looks good :)', 'created_at': datetime.datetime(2024, 11, 30, 22, 0, 28, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-30 22:00:28 UTC): Re-reviewed... Looks good :)

"
2688464558,pull_request,closed,,Fix caplog assertion in dag serialization,"Trying to fix https://github.com/apache/airflow/actions/runs/11998950574/job/33446424923#step:7:937

The error appearing in all of the builds mostly random job.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-24 21:52:07+00:00,[],2024-11-24 22:50:49+00:00,2024-11-24 22:50:19+00:00,https://github.com/apache/airflow/pull/44329,"[('area:serialization', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]",[],
2688284950,pull_request,closed,,Remove py38 as breeze's target,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-24 19:44:54+00:00,[],2024-11-24 20:43:35+00:00,2024-11-24 20:43:33+00:00,https://github.com/apache/airflow/pull/44328,"[('area:dev-tools', '')]","[{'comment_id': 2496203120, 'issue_id': 2688284950, 'author': 'potiuk', 'body': ""> Oh, another leftover that was in the source tree after my Python 3.8 removal... I was sooo certain that I catched all :-(\r\n> Thanks for cleaning behind!\r\n\r\nNo problem. this is what we do here - do not complain just fix what's been missed. Call it a teamwork :)."", 'created_at': datetime.datetime(2024, 11, 24, 19, 56, 42, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-24 19:56:42 UTC): No problem. this is what we do here - do not complain just fix what's been missed. Call it a teamwork :).

"
2687789461,pull_request,closed,,Move trigger_dagrun test file to Standard provider.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #43641

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Move `TriggerDagRunOperator` test file to Standard provider.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hardeybisey,2024-11-24 14:28:09+00:00,[],2024-11-24 15:39:58+00:00,2024-11-24 15:39:51+00:00,https://github.com/apache/airflow/pull/44327,"[('area:providers', ''), ('provider:standard', '')]",[],
2687671567,pull_request,closed,,Move OpenAPI tests to breeze container,"closes: #44020 

Running Open API client tests directly in the runner environment is fragile due to the need for manual installation of Airflow and providers, which can cause dependency conflicts and installation errors. Breeze offers a consistent, containerized setup.

Moving openapi tests run inside breeze container. Breeze uses a pre-configured container image, avoiding the need for manual installation of Airflow and providers in the runner


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-24 12:41:06+00:00,[],2024-11-27 13:31:29+00:00,2024-11-27 13:14:52+00:00,https://github.com/apache/airflow/pull/44326,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2496014130, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': 'Full tests not triggering , might be because of changes to workflows? @potiuk does this change need to come from the apache repo?', 'created_at': datetime.datetime(2024, 11, 24, 13, 51, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496067509, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': '<img width=""1701"" alt=""image"" src=""https://github.com/user-attachments/assets/1e4c1d3a-f18b-421a-8667-3efe2edda13c"">', 'created_at': datetime.datetime(2024, 11, 24, 15, 37, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496068752, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': 'ah it seems this one:\r\n\r\n<img width=""1459"" alt=""image"" src=""https://github.com/user-attachments/assets/a74a8b40-7e4f-4e51-86ac-0ecd6ccce3c2"">', 'created_at': datetime.datetime(2024, 11, 24, 15, 41, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496222810, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': '> ah it seems this one:\r\n> \r\n> <img alt=""image"" width=""1459"" src=""https://private-user-images.githubusercontent.com/31437079/389285779-a74a8b40-7e4f-4e51-86ac-0ecd6ccce3c2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzI0ODEzNzIsIm5iZiI6MTczMjQ4MTA3MiwicGF0aCI6Ii8zMTQzNzA3OS8zODkyODU3NzktYTc0YThiNDAtN2U0Zi00ZTUxLTg2YWMtMGVjZDZjY2NlM2MyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMjQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTI0VDIwNDQzMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTFmMjRkZGRlNWZhZGNhNTMzNDYyNGQ5NDkwOTc4ZGRjODdjZjcxYjdiZGUxMWM5MDA4MGNiMWY2NGY2OWE5MDImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.iJsao7qUG9nAj89IobSGOAcxowqEVQvJv6NVLsPlz8E"">\r\n\r\nThis looks like github actions have hard limit.', 'created_at': datetime.datetime(2024, 11, 24, 20, 45, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496293050, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': 'Alright one test failing but, its not related to this i believe. i will check that separate..', 'created_at': datetime.datetime(2024, 11, 24, 22, 43, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496322563, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': '> Full tests not triggering , might be because of changes to workflows? @potiuk does this change need to come from the apache repo?\r\n\r\nThis is fixed after removing openapi tests workflow :)', 'created_at': datetime.datetime(2024, 11, 24, 23, 26, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498835233, 'issue_id': 2687671567, 'author': 'jscheffl', 'body': ""> > Full tests not triggering , might be because of changes to workflows? @potiuk does this change need to come from the apache repo?\r\n> \r\n> This is fixed after removing openapi tests workflow :)\r\n\r\nYou don't need to worry with running a couple of attempts - I think this is usual when trying to experiment/model/integrate in Github. If you are afraid, just set the PR to Draft :-D\r\n\r\nOtherwise... really looking forward having this test :+1:"", 'created_at': datetime.datetime(2024, 11, 25, 19, 14, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498844148, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': ""> > > Full tests not triggering , might be because of changes to workflows? @potiuk does this change need to come from the apache repo?\r\n> > \r\n> > \r\n> > This is fixed after removing openapi tests workflow :)\r\n> \r\n> You don't need to worry with running a couple of attempts - I think this is usual when trying to experiment/model/integrate in Github. If you are afraid, just set the PR to Draft :-D\r\n> \r\n> Otherwise... really looking forward having this test 👍\r\n\r\nYes, this is fine now.. working as expected :)"", 'created_at': datetime.datetime(2024, 11, 25, 19, 19, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498845763, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': '<img width=""1461"" alt=""image"" src=""https://github.com/user-attachments/assets/65d94c1b-b3ba-42ce-b00c-80a5eb9ca153"">', 'created_at': datetime.datetime(2024, 11, 25, 19, 20, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502160510, 'issue_id': 2687671567, 'author': 'potiuk', 'body': 'Added some comments - it looks fantastic in general, but I found a few places where things might be improved. We could also use the opportunity to rename those tests to be ""python-api-client-tests"" across the board.', 'created_at': datetime.datetime(2024, 11, 26, 23, 16, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502165756, 'issue_id': 2687671567, 'author': 'gopidesupavan', 'body': '> Added some comments - it looks fantastic in general, but I found a few places where things might be improved. We could also use the opportunity to rename those tests to be ""python-api-client-tests"" across the board.\r\n\r\ncool, thanks those really great improvement suggestions let me have a updates on those :)', 'created_at': datetime.datetime(2024, 11, 26, 23, 20, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502165929, 'issue_id': 2687671567, 'author': 'potiuk', 'body': 'BTW. I really like how this `tests openapi-tests` (or whatever we name it eventually) is running all the tests of the client as well that gets generated :)\r\n\r\n\r\n![image](https://github.com/user-attachments/assets/f241de12-db8d-40ad-af8a-c6c5f3eab031)', 'created_at': datetime.datetime(2024, 11, 26, 23, 20, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503887101, 'issue_id': 2687671567, 'author': 'potiuk', 'body': 'Cool!', 'created_at': datetime.datetime(2024, 11, 27, 13, 31, 28, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-24 13:51:25 UTC): Full tests not triggering , might be because of changes to workflows? @potiuk does this change need to come from the apache repo?

gopidesupavan (Issue Creator) on (2024-11-24 15:37:37 UTC): <img width=""1701"" alt=""image"" src=""https://github.com/user-attachments/assets/1e4c1d3a-f18b-421a-8667-3efe2edda13c"">

gopidesupavan (Issue Creator) on (2024-11-24 15:41:14 UTC): ah it seems this one:

<img width=""1459"" alt=""image"" src=""https://github.com/user-attachments/assets/a74a8b40-7e4f-4e51-86ac-0ecd6ccce3c2"">

gopidesupavan (Issue Creator) on (2024-11-24 20:45:55 UTC): This looks like github actions have hard limit.

gopidesupavan (Issue Creator) on (2024-11-24 22:43:25 UTC): Alright one test failing but, its not related to this i believe. i will check that separate..

gopidesupavan (Issue Creator) on (2024-11-24 23:26:37 UTC): This is fixed after removing openapi tests workflow :)

jscheffl on (2024-11-25 19:14:19 UTC): You don't need to worry with running a couple of attempts - I think this is usual when trying to experiment/model/integrate in Github. If you are afraid, just set the PR to Draft :-D

Otherwise... really looking forward having this test :+1:

gopidesupavan (Issue Creator) on (2024-11-25 19:19:13 UTC): Yes, this is fine now.. working as expected :)

gopidesupavan (Issue Creator) on (2024-11-25 19:20:08 UTC): <img width=""1461"" alt=""image"" src=""https://github.com/user-attachments/assets/65d94c1b-b3ba-42ce-b00c-80a5eb9ca153"">

potiuk on (2024-11-26 23:16:37 UTC): Added some comments - it looks fantastic in general, but I found a few places where things might be improved. We could also use the opportunity to rename those tests to be ""python-api-client-tests"" across the board.

gopidesupavan (Issue Creator) on (2024-11-26 23:20:20 UTC): cool, thanks those really great improvement suggestions let me have a updates on those :)

potiuk on (2024-11-26 23:20:27 UTC): BTW. I really like how this `tests openapi-tests` (or whatever we name it eventually) is running all the tests of the client as well that gets generated :)


![image](https://github.com/user-attachments/assets/f241de12-db8d-40ad-af8a-c6c5f3eab031)

potiuk on (2024-11-27 13:31:28 UTC): Cool!

"
2687341689,pull_request,closed,,AIP-84 Refactor test cases with `datetime_zulu_format`,"related: https://github.com/apache/airflow/pull/43859#issuecomment-2493093935

Refactor test cases using the `datetime_zulu_format` utility instead of manual replacements.  
This change depends on https://github.com/apache/airflow/pull/43859 being merged.

### Refactored Test Cases  
- **In this PR**:  
  - `test_assets`  
  - `test_dag_run`  

- **In https://github.com/apache/airflow/pull/43859**:  
  - `test_event_logs`  
  - `test_import_error`  
",jason810496,2024-11-24 08:34:03+00:00,[],2024-11-27 13:42:47+00:00,2024-11-27 13:42:47+00:00,https://github.com/apache/airflow/pull/44323,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2500216232, 'issue_id': 2687341689, 'author': 'pierrejeambrun', 'body': 'Things have been merged in between, can you rebase and update the PR, then we can merge it before more changes come through.', 'created_at': datetime.datetime(2024, 11, 26, 10, 18, 13, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-26 10:18:13 UTC): Things have been merged in between, can you rebase and update the PR, then we can merge it before more changes come through.

"
2687247014,pull_request,closed,,AIP-84 Refactor Handling of Insert Duplicates,"related: https://github.com/apache/airflow/pull/44121#issuecomment-2493193823

It seems that only the Post Connection endpoint has an extra query to handle duplicate entries. Other `409_CONFLICT` cases don't handle inserting duplicate entries on unique constraint columns.  





",jason810496,2024-11-24 06:54:27+00:00,[],2024-12-16 12:50:55+00:00,2024-12-16 12:50:55+00:00,https://github.com/apache/airflow/pull/44322,[],"[{'comment_id': 2504194960, 'issue_id': 2687247014, 'author': 'jason810496', 'body': ""In summary, this PR will only add `orig` and `statement` to the response error details.\r\n  \r\n> Regexp can be not super reliable, also it will depends on the error message of the database (which can change between releases and versions).\r\n\r\nI will still explore the regex or string-matching approach in a follow-up PR.\r\nFrom my perspective, database error messages do not change frequently ( also we won't update the database driver version very often I think ). Even if the error message changes after upgrading the database driver, fixing it in one global handler would not be a significant issue."", 'created_at': datetime.datetime(2024, 11, 27, 15, 41, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525551172, 'issue_id': 2687247014, 'author': 'jason810496', 'body': 'Hi @pierrejeambrun, @ephraimbuddy,\r\n\r\nI’ve refactored the `_UniqueConstraintErrorHandler` to provide unified error details across all database dialects by parsing errors with `re2`. If the parsing fails, it defaults to returning the original database error.\r\n\r\nI’ve also added tests for the unique constraint handler, covering the following cases:\r\n- Inserting a duplicate entry for a single-column unique constraint (e.g., `Pool`, `Variable`).\r\n- Inserting a duplicate entry for a multi-column unique constraint (e.g., `dag_id` and `run_id` pair in `DagRun`).\r\n- Handling cases where parsing the database error message fails.\r\n\r\nLooking forward to your feedback and suggestions!', 'created_at': datetime.datetime(2024, 12, 8, 9, 9, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539416192, 'issue_id': 2687247014, 'author': 'jason810496', 'body': 'Rebase to latest main, looking forward to feedback.\r\ncc @pierrejeambrun , @ephraimbuddy', 'created_at': datetime.datetime(2024, 12, 12, 16, 20, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541552577, 'issue_id': 2687247014, 'author': 'kaxil', 'body': ""> I think there are a lot of hardcoded values, regexp and manual string manipulation etc. This code will likely break when the db version update the message or when a column name / values contains special character that we did not account for. The parsing could still fail.\r\n> \r\n> Also that's a lot of code to maintain, and it's not super welcoming.\r\n> \r\n> I'm not in favour of this change.\r\n> \r\n> I still think that at first just returning the plain `orig` and `statement` is enough for a user to understand. And for tests we just assert that those keys are present in the response.\r\n\r\nYup, I agree, it looks too brittle unfortunately."", 'created_at': datetime.datetime(2024, 12, 13, 14, 13, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542923427, 'issue_id': 2687247014, 'author': 'jason810496', 'body': 'Thank you for the feedback, @pierrejeambrun and @kaxil!\r\nI realize I overlooked the maintenance effort required for directly parsing errors from different dialects.\r\n( Hope we’ll see a PEP someday that standardizes the error details across various DBAPI drivers, then we could adopt the parsing solution. )\r\n\r\nJust refactored the implementation to include only the `statement` and `orig` in the error response.', 'created_at': datetime.datetime(2024, 12, 14, 7, 20, 5, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-11-27 15:41:33 UTC): In summary, this PR will only add `orig` and `statement` to the response error details.
  

I will still explore the regex or string-matching approach in a follow-up PR.
From my perspective, database error messages do not change frequently ( also we won't update the database driver version very often I think ). Even if the error message changes after upgrading the database driver, fixing it in one global handler would not be a significant issue.

jason810496 (Issue Creator) on (2024-12-08 09:09:55 UTC): Hi @pierrejeambrun, @ephraimbuddy,

I’ve refactored the `_UniqueConstraintErrorHandler` to provide unified error details across all database dialects by parsing errors with `re2`. If the parsing fails, it defaults to returning the original database error.

I’ve also added tests for the unique constraint handler, covering the following cases:
- Inserting a duplicate entry for a single-column unique constraint (e.g., `Pool`, `Variable`).
- Inserting a duplicate entry for a multi-column unique constraint (e.g., `dag_id` and `run_id` pair in `DagRun`).
- Handling cases where parsing the database error message fails.

Looking forward to your feedback and suggestions!

jason810496 (Issue Creator) on (2024-12-12 16:20:40 UTC): Rebase to latest main, looking forward to feedback.
cc @pierrejeambrun , @ephraimbuddy

kaxil on (2024-12-13 14:13:41 UTC): Yup, I agree, it looks too brittle unfortunately.

jason810496 (Issue Creator) on (2024-12-14 07:20:05 UTC): Thank you for the feedback, @pierrejeambrun and @kaxil!
I realize I overlooked the maintenance effort required for directly parsing errors from different dialects.
( Hope we’ll see a PEP someday that standardizes the error details across various DBAPI drivers, then we could adopt the parsing solution. )

Just refactored the implementation to include only the `statement` and `orig` in the error response.

"
2687193350,pull_request,closed,,Prepare docs for Nov 2nd wave of ad hoc providers,,eladkal,2024-11-24 06:36:01+00:00,[],2024-11-24 09:16:31+00:00,2024-11-24 09:16:28+00:00,https://github.com/apache/airflow/pull/44321,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', '')]",[],
2687038007,pull_request,closed,,Add fail_on_file_not_exist option to SFTPToS3Operator,"Fixes: https://github.com/apache/airflow/issues/40576

I added `fail_on_file_not_exist` param to `SFTPToS3Operator` so that user can configure the parameter and operator will not fail in case of sftp file not exist.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).

In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).

----

Here's the test result ran in my local environment.
<img width=""1718"" alt=""sftp_to_s3_test_local"" src=""https://github.com/user-attachments/assets/b10d30d8-7fd0-4a46-9697-3a2f1847ce8c"">
you can see the dag does not fail with `fail_on_file_not_exist` but still shows logs that the file does not exist.

sftp_to_s3_dag.py
```python
from airflow import DAG
from airflow.providers.amazon.aws.transfers.sftp_to_s3 import SFTPToS3Operator
from datetime import datetime, timedelta

default_args = {
    ""owner"": ""airflow"",
    ""retries"": 1,
    ""retry_delay"": timedelta(minutes=1),
}

with DAG(
    dag_id=""sftp_to_s3_example"",
    default_args=default_args,
    description=""Transfer a file from SFTP to S3"",
    schedule_interval=None,
    start_date=datetime(2023, 1, 1),
    catchup=False,
    tags=[""example"", ""sftp"", ""s3""],
) as dag:
    transfer_file = SFTPToS3Operator(
        task_id=""transfer_file"",
        sftp_conn_id=""sftp_default"",
        sftp_path=""/Users/john/test.mv.dba"", 
        s3_conn_id=""aws_conn"",
        s3_bucket=""airflow"",
        s3_key=""test/test.mv.db"",
        fail_on_file_not_exist=False,
    )
```
",Guaqamole,2024-11-24 04:14:19+00:00,[],2024-11-27 22:20:19+00:00,2024-11-27 22:20:16+00:00,https://github.com/apache/airflow/pull/44320,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2495794069, 'issue_id': 2687038007, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 24, 4, 14, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504893503, 'issue_id': 2687038007, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 27, 22, 20, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-24 04:14:24 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-27 22:20:18 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2686869023,pull_request,closed,,[v2-10-test] Avoid grouping task instance stats by try_number for dynamic mapped tasks (#44300),"(cherry picked from commit 5e52bd29abd690098ecf0701b8aab4792566eea3)

Co-authored-by: Shahar Epstein <60007259+shahar1@users.noreply.github.com>",github-actions[bot],2024-11-24 01:30:06+00:00,[],2024-12-04 08:51:34+00:00,2024-11-24 11:37:11+00:00,https://github.com/apache/airflow/pull/44319,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2495838817, 'issue_id': 2686869023, 'author': 'shahar1', 'body': ""1. The unit test fails, I'll take care of it.\r\n2. @potiuk What do you think that we should do with back-ported newsfragments?\r\nShould we keep them with the original PR id, or change it to the backport's? It could be automated as part of the cherry-picker, I wonder if it's worth the effort :)\r\n\r\n**Update:** I just checked and it seems that we don't have many back-ported news fragments."", 'created_at': datetime.datetime(2024, 11, 24, 6, 34, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495916204, 'issue_id': 2686869023, 'author': 'potiuk', 'body': '> Should we keep them with the original PR id, or change it to the backport\'s? It could be automated as part of the cherry-picker, I wonder if it\'s worth the effort :)\r\n\r\nShould be original PR.\r\n\r\n> Update: I just checked and it seems that we don\'t have many back-ported news fragments.\r\n\r\nYes - they are deleted after they are incorporated by release manager in release notes for 2.10.1* when they are relased - this is part of towncrier workflow. We should also then delete the newsfragment from `main` I guess (@jedcunningham ? @ephraimbuddy @utkarsharma2 ) because otherwise the newsfragment will appear in two releases. I **think** it is automated by our workflow and one reason why newsfragments should be committed in their corresponding PR because ""cherry-picking"" PR means also ""cherry-picking"" release notes.', 'created_at': datetime.datetime(2024, 11, 24, 10, 3, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495916496, 'issue_id': 2686869023, 'author': 'potiuk', 'body': 'So I am not sure if the rename was a good idea. :)', 'created_at': datetime.datetime(2024, 11, 24, 10, 4, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495923971, 'issue_id': 2686869023, 'author': 'shahar1', 'body': '> > Should we keep them with the original PR id, or change it to the backport\'s? It could be automated as part of the cherry-picker, I wonder if it\'s worth the effort :)\r\n> \r\n> Should be original PR.\r\n> \r\n> > Update: I just checked and it seems that we don\'t have many back-ported news fragments.\r\n> \r\n> Yes - they are deleted after they are incorporated by release manager in release notes for 2.10.1* when they are relased - this is part of towncrier workflow. We should also then delete the newsfragment from `main` I guess (@jedcunningham ? @ephraimbuddy @utkarsharma2 ) because otherwise the newsfragment will appear in two releases. I **think** it is automated by our workflow and one reason why newsfragments should be committed in their corresponding PR because ""cherry-picking"" PR means also ""cherry-picking"" release notes.\r\n\r\nThanks for the info :)\r\n\r\n\r\n\r\n> So I am not sure if the rename was a good idea. :)\r\n\r\nDropped last commit', 'created_at': datetime.datetime(2024, 11, 24, 10, 27, 13, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-11-24 06:34:35 UTC): 1. The unit test fails, I'll take care of it.
2. @potiuk What do you think that we should do with back-ported newsfragments?
Should we keep them with the original PR id, or change it to the backport's? It could be automated as part of the cherry-picker, I wonder if it's worth the effort :)

**Update:** I just checked and it seems that we don't have many back-ported news fragments.

potiuk on (2024-11-24 10:03:43 UTC): Should be original PR.


Yes - they are deleted after they are incorporated by release manager in release notes for 2.10.1* when they are relased - this is part of towncrier workflow. We should also then delete the newsfragment from `main` I guess (@jedcunningham ? @ephraimbuddy @utkarsharma2 ) because otherwise the newsfragment will appear in two releases. I **think** it is automated by our workflow and one reason why newsfragments should be committed in their corresponding PR because ""cherry-picking"" PR means also ""cherry-picking"" release notes.

potiuk on (2024-11-24 10:04:32 UTC): So I am not sure if the rename was a good idea. :)

shahar1 on (2024-11-24 10:27:13 UTC): Thanks for the info :)




Dropped last commit

"
2686862537,pull_request,closed,,Refactor package checks to be test and remove duplication,"Package checks are already ""tests"" not only checks since we introduced compatibility complete tests. This PR updates names of files and also removes duplication of wheel/sdist package build and verification and adding conditional steps.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-24 01:15:35+00:00,[],2024-11-24 11:34:20+00:00,2024-11-24 11:34:18+00:00,https://github.com/apache/airflow/pull/44318,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]",[],
2686838567,pull_request,closed,,Workaround Pydantic 2.10.0/2.10.1 for compatibility tests,"Our compatibility tests started to fail after Pydantic 2.10.0/2.10.1 have been released due to change in the way they are handling base classes for Pydantic classes and their protected members, when the base class uses PEP 563 ('from __future__ import annotations`) on Python 3.8 / 3.9.

This is tracked in https://github.com/pydantic/pydantic/issues/10958 and hopefully will be solved by adding eval-type-backport as required Pydantic 2.10.2+ dependency, but until it is released, manually installing `eval-type-backport` in compatibility tests should workaround the failing canary tests.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-24 00:06:39+00:00,[],2024-11-24 12:47:31+00:00,2024-11-24 09:35:13+00:00,https://github.com/apache/airflow/pull/44317,"[('area:dev-tools', '')]","[{'comment_id': 2495730481, 'issue_id': 2686838567, 'author': 'potiuk', 'body': 'Green!', 'created_at': datetime.datetime(2024, 11, 24, 1, 11, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495983167, 'issue_id': 2686838567, 'author': 'gopidesupavan', 'body': 'Nice :) think this solves the current ci failures related to pydantic.', 'created_at': datetime.datetime(2024, 11, 24, 12, 47, 30, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-24 01:11:04 UTC): Green!

gopidesupavan on (2024-11-24 12:47:30 UTC): Nice :) think this solves the current ci failures related to pydantic.

"
2686826939,pull_request,closed,,Add copy-pasteable cherry-picker command if it fails to cherry-pick,"When cherry-picker fails to backport a PR it adds a message to the PR explaining the failure and linking to the commit. This PR also adds a copy&pasteable cherry-picker command that the maintainer should run to retry it locally. It also explains what maintainer should do after solving the conflicts.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-23 23:52:35+00:00,[],2024-11-24 11:37:49+00:00,2024-11-24 01:10:44+00:00,https://github.com/apache/airflow/pull/44316,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2495954965, 'issue_id': 2686826939, 'author': 'gopidesupavan', 'body': 'Yeah, good one :)', 'created_at': datetime.datetime(2024, 11, 24, 11, 37, 47, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-24 11:37:47 UTC): Yeah, good one :)

"
2686818677,pull_request,closed,,[v2-10-test] Only install eval-type-backport for Python < 3.10 (#44294),"The `eval-type-backport` is a tool to replace some of the controversial new type hints added with `from future imoport __annotations__` to ""classic"" type hint (| and list - into `Union` and `List`).

This helps to battle some of the issues where Pydantic has troubles when they are used for classes that Pydantic uses.

The library was initially added in #42196 but it was added for all Python versions - this change limits it only to Python < 3.10 (cherry picked from commit 29483384be5245a12ae1eb80fab364ddcbe41481)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-23 23:40:51+00:00,[],2024-12-04 08:52:25+00:00,2024-11-24 09:37:31+00:00,https://github.com/apache/airflow/pull/44315,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2495693918, 'issue_id': 2686818677, 'author': 'potiuk', 'body': 'I am cherry-picking that one to 2-10-test - targetting for 2.10.4 - just in case https://github.com/pydantic/pydantic/issues/10958 will not be quickly resolved and Pydantic team will be reluctant to make `eval-type-backport` as required dependency for Pydantic (which IMHO is the best solution to the problem they introduced in Pydantic 2.10.*. This is not ideal as it only protects the 2.10.4 users on Python 3.8/3.9 but I want to have it handy.', 'created_at': datetime.datetime(2024, 11, 23, 23, 43, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495721077, 'issue_id': 2686818677, 'author': 'bugraoz93', 'body': 'I believe failed steps are not relevant to the changes. It seems like a couple of tests are still using old configuration.', 'created_at': datetime.datetime(2024, 11, 24, 0, 32, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495753083, 'issue_id': 2686818677, 'author': 'potiuk', 'body': '> I believe failed steps are not relevant to the changes. It seems like a couple of tests are still using old configuration.\r\n\r\nYeah, we need to fix it separately.', 'created_at': datetime.datetime(2024, 11, 24, 2, 7, 22, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-23 23:43:53 UTC): I am cherry-picking that one to 2-10-test - targetting for 2.10.4 - just in case https://github.com/pydantic/pydantic/issues/10958 will not be quickly resolved and Pydantic team will be reluctant to make `eval-type-backport` as required dependency for Pydantic (which IMHO is the best solution to the problem they introduced in Pydantic 2.10.*. This is not ideal as it only protects the 2.10.4 users on Python 3.8/3.9 but I want to have it handy.

bugraoz93 on (2024-11-24 00:32:18 UTC): I believe failed steps are not relevant to the changes. It seems like a couple of tests are still using old configuration.

potiuk (Issue Creator) on (2024-11-24 02:07:22 UTC): Yeah, we need to fix it separately.

"
2686587976,pull_request,closed,,Fix edge in rare conditions that task state can not be reported as cleaned in parallel,"With 0.6.1 a cleanup of orphan tasks has been added. I have seen a race in my testing that if the task is already acknowledged and the purging is running ... and in parallel the edge worker attempts to report state that the task/job is gone.
This small fix prevents the failure when the task is gone in the central table already,",jscheffl,2024-11-23 20:41:06+00:00,[],2024-11-26 05:15:44+00:00,2024-11-26 05:15:44+00:00,https://github.com/apache/airflow/pull/44314,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2686383050,pull_request,closed,,fix mypy failure due to termcolor upgrade,"[PR](https://github.com/apache/airflow/actions/runs/11989299333/job/33425681929?pr=44312) 
 static check failed with following error

```

airflow/cli/commands/standalone_command.py:151: error: Argument 2 to ""colored""
has incompatible type ""str""; expected
""Optional[Literal['black', 'grey', 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'light_grey', 'dark_grey', 'light_red', 'light_green', 'light_yellow', 'light_blue', 'light_magenta', 'light_cyan', 'white']]""
 [arg-type]
            colorised_name = colored(f""{name:10}"", color)
```

This fixes it",rawwar,2024-11-23 18:36:36+00:00,[],2024-11-24 00:07:20+00:00,2024-11-23 19:21:53+00:00,https://github.com/apache/airflow/pull/44313,"[('area:CLI', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2495710399, 'issue_id': 2686383050, 'author': 'kaxil', 'body': 'Thanks for fixing it 🙏', 'created_at': datetime.datetime(2024, 11, 24, 0, 7, 19, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-24 00:07:19 UTC): Thanks for fixing it 🙏

"
2686359727,pull_request,closed,,use __file__ for dag fileloc in test_dag,"When running test_dags.py locally using venv, it fails because, DAG's fileloc is hardcoded. airflow tests folder is assumed to be in `/opt/airflow`. This is not true when running tests on local using venv. Since, DAG's are created within the test file, we can just use `__file__` to get the source path


![image](https://github.com/user-attachments/assets/7d2a09fd-458b-4941-8363-e47c696b0e66)
",rawwar,2024-11-23 18:06:16+00:00,[],2024-11-24 02:56:09+00:00,2024-11-23 20:30:02+00:00,https://github.com/apache/airflow/pull/44312,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2495753873, 'issue_id': 2686359727, 'author': 'kaxil', 'body': ""fyi: I have started adding `changelogLskip` label for PRs that don't need to be in changelog like this one from few weeks"", 'created_at': datetime.datetime(2024, 11, 24, 2, 8, 31, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-24 02:08:31 UTC): fyi: I have started adding `changelogLskip` label for PRs that don't need to be in changelog like this one from few weeks

"
2686345321,pull_request,closed,,Migrate Edge calls for Worker to FastAPI part 1 - Worker routes,"To prepare EdgeWorker to be independent of AIP-44 Internal API, this PR is the second step in adding/migrating to FastAPI. The calls to ""Worker"" API to (1) register a worker and (2) set the state are now real REST API calls, not using internal API.

I would separate the other internal API calls to follow-up PRs as this is already quite large. Especially ecause for ongoing Airflow 2.10 Connexion API + Swagger manually need to be generated whereas the main workstram for Airflow 3 uses FastAPI.",jscheffl,2024-11-23 17:46:44+00:00,[],2024-11-30 21:48:09+00:00,2024-11-30 21:48:09+00:00,https://github.com/apache/airflow/pull/44311,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2508256913, 'issue_id': 2686345321, 'author': 'jscheffl', 'body': '> One ""bigger"" thing about revealing too much for auth errors.\r\n\r\nPoint taken. Thanks for the review. Actually it was a take-over from existing internal API. Would we need to harden this as well before we do a 2.10.4? See https://github.com/apache/airflow/blob/2.10.3/airflow/api_internal/endpoints/rpc_api_endpoint.py#L190 (now removed on main...)', 'created_at': datetime.datetime(2024, 11, 29, 18, 20, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508988335, 'issue_id': 2686345321, 'author': 'jscheffl', 'body': '@kaxil / @potiuk Thanks for the review! All things adjusted... but as AIP-44 needed to re-work a lot I needed to fully re-base and restore AIP-44 broken function. As Airflow 3 is now broken... after this PR v2.10 is working again.\r\n\r\nDo you want to have a second round or good to merge as is? (And follow-ups will be taken care...)', 'created_at': datetime.datetime(2024, 11, 30, 15, 2, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509025553, 'issue_id': 2686345321, 'author': 'potiuk', 'body': 'I had a quick look - I am good to go. I think we need to align on the near future strategy for breaking/non-breaking strategy for the edge worker - see https://github.com/apache/airflow/pull/44494#issuecomment-2509012064 but this one is good to go I think', 'created_at': datetime.datetime(2024, 11, 30, 16, 29, 31, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-11-29 18:20:55 UTC): Point taken. Thanks for the review. Actually it was a take-over from existing internal API. Would we need to harden this as well before we do a 2.10.4? See https://github.com/apache/airflow/blob/2.10.3/airflow/api_internal/endpoints/rpc_api_endpoint.py#L190 (now removed on main...)

jscheffl (Issue Creator) on (2024-11-30 15:02:24 UTC): @kaxil / @potiuk Thanks for the review! All things adjusted... but as AIP-44 needed to re-work a lot I needed to fully re-base and restore AIP-44 broken function. As Airflow 3 is now broken... after this PR v2.10 is working again.

Do you want to have a second round or good to merge as is? (And follow-ups will be taken care...)

potiuk on (2024-11-30 16:29:31 UTC): I had a quick look - I am good to go. I think we need to align on the near future strategy for breaking/non-breaking strategy for the edge worker - see https://github.com/apache/airflow/pull/44494#issuecomment-2509012064 but this one is good to go I think

"
2686107351,pull_request,closed,,Support connection extra parameters in MsSqlHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #43798 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-11-23 14:51:32+00:00,[],2024-11-26 07:47:17+00:00,2024-11-26 07:47:17+00:00,https://github.com/apache/airflow/pull/44310,"[('area:providers', ''), ('provider:microsoft-mssql', '')]","[{'comment_id': 2495504350, 'issue_id': 2686107351, 'author': 'jx2lee', 'body': ""Until test passed, I'm keeping Draft this. 🤣\r\n@shahar1"", 'created_at': datetime.datetime(2024, 11, 23, 14, 52, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496051112, 'issue_id': 2686107351, 'author': 'jx2lee', 'body': '@shahar1 when I moved Connection instance to test class, tests can pass!\r\nReview test code, please. 🙇🏽 \r\n\r\n(Thanks, @potiuk , for the hint)', 'created_at': datetime.datetime(2024, 11, 24, 15, 11, 12, tzinfo=datetime.timezone.utc)}]","jx2lee (Issue Creator) on (2024-11-23 14:52:53 UTC): Until test passed, I'm keeping Draft this. 🤣
@shahar1

jx2lee (Issue Creator) on (2024-11-24 15:11:12 UTC): @shahar1 when I moved Connection instance to test class, tests can pass!
Review test code, please. 🙇🏽 

(Thanks, @potiuk , for the hint)

"
2686048839,pull_request,closed,,Move `LatestOnlyOperator` operator to standard provider.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Moving latest_only operator to standard provider.

`airflow/operators/latest_only.py`  >> `providers/src/airflow/providers/standard/operators/latest_only.py`

related: #43641

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hardeybisey,2024-11-23 14:32:19+00:00,[],2024-11-30 15:55:01+00:00,2024-11-30 15:55:01+00:00,https://github.com/apache/airflow/pull/44309,"[('area:providers', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2507807396, 'issue_id': 2686048839, 'author': 'hardeybisey', 'body': '@potiuk Thanks for the review. I have made the test conditional based on the version it is running against.', 'created_at': datetime.datetime(2024, 11, 29, 13, 19, 24, tzinfo=datetime.timezone.utc)}]","hardeybisey (Issue Creator) on (2024-11-29 13:19:24 UTC): @potiuk Thanks for the review. I have made the test conditional based on the version it is running against.

"
2686046820,pull_request,closed,,[refactor] remove logical_date_field_name parametrization in TestPostDagRun.test_should_respond_200,"removing `logical_date_field_name` parametrization as `execution_date` has been removed and now, its just ""logical_date""",rawwar,2024-11-23 14:29:03+00:00,[],2024-11-24 02:55:38+00:00,2024-11-24 01:58:02+00:00,https://github.com/apache/airflow/pull/44308,"[('area:API', ""Airflow's REST/HTTP API""), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2686029020,pull_request,closed,,FIX add error_cb to `confluent.Consumer` config in `ConsumerFromTopic`,closes: #43569,SuccessMoses,2024-11-23 13:55:13+00:00,[],2024-12-08 22:22:44+00:00,2024-12-08 22:17:23+00:00,https://github.com/apache/airflow/pull/44307,"[('area:providers', ''), ('provider:apache-kafka', '')]","[{'comment_id': 2526410442, 'issue_id': 2686029020, 'author': 'SuccessMoses', 'body': 'Thanks for the review', 'created_at': datetime.datetime(2024, 12, 8, 22, 22, 43, tzinfo=datetime.timezone.utc)}]","SuccessMoses (Issue Creator) on (2024-12-08 22:22:43 UTC): Thanks for the review

"
2686012001,pull_request,closed,,forbid extra fields in BaseModel,"As of now, we allow any fields to be in the Data Models. This PR ensures that requests have the exact required fields.

As of now, if we pass the wrong fields, the data models simply ignore them.

@pierrejeambrun , do you think this is a good idea?",rawwar,2024-11-23 13:31:07+00:00,[],2025-01-30 14:13:37+00:00,2025-01-30 14:13:36+00:00,https://github.com/apache/airflow/pull/44306,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2498331210, 'issue_id': 2686012001, 'author': 'pierrejeambrun', 'body': 'Note: Add this to the breaking change of the API tracked here:\r\nhttps://github.com/apache/airflow/issues/43378\r\n\r\n(We do not create the newsfragments yet, format is not settled for those).', 'created_at': datetime.datetime(2024, 11, 25, 15, 27, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566760809, 'issue_id': 2686012001, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 4, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602003613, 'issue_id': 2686012001, 'author': 'pierrejeambrun', 'body': '@rawwar any progress on that one ? https://github.com/apache/airflow/pull/44986 also depends on that, I think it would be a great improvement for the API.\r\n\r\nLet me know if you need some help.', 'created_at': datetime.datetime(2025, 1, 20, 10, 21, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602008083, 'issue_id': 2686012001, 'author': 'rawwar', 'body': ""> @rawwar any progress on that one ? #44986 also depends on that, I think it would be a great improvement for the API.\r\n> \r\n> Let me know if you need some help.\r\n\r\nNo progress. I'll start working on this"", 'created_at': datetime.datetime(2025, 1, 20, 10, 23, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614417866, 'issue_id': 2686012001, 'author': 'rawwar', 'body': '@pierrejeambrun , while i was working on this, I noticed the following: \r\nhttps://github.com/apache/airflow/blob/f7a9a1581b58c296d8b6edfe71bb72efebb32943/airflow/api_fastapi/core_api/routes/public/connections.py#L206\r\n\r\nAs the models can have an alias, this `ConnectionBody(**patch_body.model_dump())` will fail when there are alias. Especially when few are validation/serialization alias. \r\n\r\n\r\nExample test: https://github.com/apache/airflow/blob/823ffde75de0f1b75ee12d82059099f504240f53/tests/api_fastapi/core_api/routes/public/test_connections.py#L316\r\n\r\nHere, it always fails when extra=forbit with following error:\r\n```\r\n\'{""detail"":[{""type"":""extra_forbidden"",""loc"":[""schema_""],""msg"":""Extra inputs are not permitted"",""input"":null,""url"":""https://errors.pydantic.dev/2.10/v/extra_forbidden""}]}\'\r\n```\r\n\r\nwe can\'t use `ConnectionBody(**patch_body.model_dump(by_alias=True))` because, `connection_id` is a required field. Its transformed to `conn_id` because of serialization_alias\r\n\r\n\r\nAlso, Do we even need to have this specific check? `ConnectionBody(**patch_body.model_dump())` feels redundant, given input is already validated during request.', 'created_at': datetime.datetime(2025, 1, 26, 13, 22, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615100949, 'issue_id': 2686012001, 'author': 'pierrejeambrun', 'body': '> Also, Do we even need to have this specific check? ConnectionBody(**patch_body.model_dump()) feels redundant, given input is already validated during request.\r\n\r\nThe idea behind this check is to ensure that the given payload is a fully formed entity before moving further and saving that to the DB. Why we do that is because the endpoint can accept partial updates, when we give a partial `PathBody` with a lot of None field and without specifying an update mask, we verify that this payload can be saved to the db.\r\n\r\nI would say that we need to keep that, but we still need to figure out the other problem that you are mentioning. `extra_forbidden` and `aliases` should play nicely together.', 'created_at': datetime.datetime(2025, 1, 27, 8, 22, 5, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-25 15:27:41 UTC): Note: Add this to the breaking change of the API tracked here:
https://github.com/apache/airflow/issues/43378

(We do not create the newsfragments yet, format is not settled for those).

jscheffl on (2025-01-01 00:04:29 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

pierrejeambrun on (2025-01-20 10:21:43 UTC): @rawwar any progress on that one ? https://github.com/apache/airflow/pull/44986 also depends on that, I think it would be a great improvement for the API.

Let me know if you need some help.

rawwar (Issue Creator) on (2025-01-20 10:23:35 UTC): No progress. I'll start working on this

rawwar (Issue Creator) on (2025-01-26 13:22:59 UTC): @pierrejeambrun , while i was working on this, I noticed the following: 
https://github.com/apache/airflow/blob/f7a9a1581b58c296d8b6edfe71bb72efebb32943/airflow/api_fastapi/core_api/routes/public/connections.py#L206

As the models can have an alias, this `ConnectionBody(**patch_body.model_dump())` will fail when there are alias. Especially when few are validation/serialization alias. 


Example test: https://github.com/apache/airflow/blob/823ffde75de0f1b75ee12d82059099f504240f53/tests/api_fastapi/core_api/routes/public/test_connections.py#L316

Here, it always fails when extra=forbit with following error:
```
'{""detail"":[{""type"":""extra_forbidden"",""loc"":[""schema_""],""msg"":""Extra inputs are not permitted"",""input"":null,""url"":""https://errors.pydantic.dev/2.10/v/extra_forbidden""}]}'
```

we can't use `ConnectionBody(**patch_body.model_dump(by_alias=True))` because, `connection_id` is a required field. Its transformed to `conn_id` because of serialization_alias


Also, Do we even need to have this specific check? `ConnectionBody(**patch_body.model_dump())` feels redundant, given input is already validated during request.

pierrejeambrun on (2025-01-27 08:22:05 UTC): The idea behind this check is to ensure that the given payload is a fully formed entity before moving further and saving that to the DB. Why we do that is because the endpoint can accept partial updates, when we give a partial `PathBody` with a lot of None field and without specifying an update mask, we verify that this payload can be saved to the db.

I would say that we need to keep that, but we still need to figure out the other problem that you are mentioning. `extra_forbidden` and `aliases` should play nicely together.

"
2686000996,pull_request,closed,,rename run_id to dag_run_id in DagRun response,"in my earlier [PR](https://github.com/apache/airflow/pull/42725/files#diff-a3a4378dfd0695c86020c63561b8d60020db031668608e8a644e272eaa5db047), I made a mistake by alias instead of validation_alias. which resulted in returning `run_id` instead of `dag_run_id` as per legacy implementation. This PR fixes it.",rawwar,2024-11-23 13:10:19+00:00,[],2024-11-23 14:07:23+00:00,2024-11-23 14:07:23+00:00,https://github.com/apache/airflow/pull/44305,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2685855619,pull_request,closed,,Update README_AIRFLOW3_DEV.md,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Applied some style and proofreading.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-23 11:20:31+00:00,[],2025-01-11 19:44:10+00:00,2024-11-24 01:34:18+00:00,https://github.com/apache/airflow/pull/44304,"[('area:dev-tools', '')]",[],
2685848835,pull_request,closed,,AIP-84 Get Mapped Task Instance Tries,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related to: https://github.com/apache/airflow/issues/42370

<!-- Please keep an empty line above the dashes. -->
---
",kandharvishnu,2024-11-23 11:02:47+00:00,[],2024-11-26 15:44:56+00:00,2024-11-26 15:44:56+00:00,https://github.com/apache/airflow/pull/44303,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2498581403, 'issue_id': 2685848835, 'author': 'pierrejeambrun', 'body': 'Need rebasing and conflict solving.', 'created_at': datetime.datetime(2024, 11, 25, 17, 9, 47, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-25 17:09:47 UTC): Need rebasing and conflict solving.

"
2685774229,pull_request,closed,,[Providers/HTTP] Add adapter parameter to HttpHook to allow custom requests adapters,"This PR adds an `adapter` parameter to the `HttpHook`, allowing users to mount custom adapters for HTTP request handling. This enhances flexibility and supports use cases like custom retries, timeouts, and SSL handling.

### Summary of Changes:
- Added `adapter` parameter to `HttpHook` to allow custom HTTP adapters.
- Modified `get_conn` to support mounting custom adapters or using TCPKeepAliveAdapter by default.
- Added comprehensive tests to validate the functionality of the `adapter` parameter and its integration with `get_conn`.
- Ensured all new tests pass and maintain compatibility with existing functionality.

### Issue Reference:
Closes #44285

### Testing and Validation:
- Added unit tests in `~/providers/tests/http/hooks/test_http.py` to validate:
  - Mounting custom adapters.
  - Default behavior when no adapter is provided.
  - Handling invalid adapter types.
- Ran `pytest providers/tests/http/hooks/test_http.py` using breeze.
- Pass `pre-commit run --files providers/src/airflow/providers/http/hooks/http.py providers/tests/http/hooks/test_http.py` using breeze.

### Backward Compatibility:
This change is backward-compatible. The new `adapter` parameter is optional and defaults to None, preserving existing behavior.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jieyao-MilestoneHub,2024-11-23 10:07:45+00:00,[],2024-12-03 18:22:38+00:00,2024-12-03 10:44:17+00:00,https://github.com/apache/airflow/pull/44302,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2495425712, 'issue_id': 2685774229, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 23, 10, 7, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495473186, 'issue_id': 2685774229, 'author': 'jieyao-MilestoneHub', 'body': 'Thank you, @shahar1, for your detailed review and valuable feedback! I’ve addressed your comments by:\r\n1. Adding a detailed docstring for the `__init__` method, including the missing `adapter` parameter.\r\n2. Removing the redundant instantiation of `TCPKeepAliveAdapter` in the `run` method.\r\n\r\nPlease let me know if there’s anything else I can improve. I really appreciate your time and support!', 'created_at': datetime.datetime(2024, 11, 23, 13, 3, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495512067, 'issue_id': 2685774229, 'author': 'shahar1', 'body': '> Thank you, @shahar1, for your detailed review and valuable feedback! I’ve addressed your comments by:\r\n> \r\n> 1. Adding a detailed docstring for the `__init__` method, including the missing `adapter` parameter.\r\n> 2. Removing the redundant instantiation of `TCPKeepAliveAdapter` in the `run` method.\r\n> \r\n> Please let me know if there’s anything else I can improve. I really appreciate your time and support!\r\n\r\nThanks :) Regarding the 2nd point - could you please explain why it makes sense to relocate the instanation of `TCPKeepAliveAdapter` to the `__init__`?', 'created_at': datetime.datetime(2024, 11, 23, 15, 20, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495766805, 'issue_id': 2685774229, 'author': 'jieyao-MilestoneHub', 'body': ""Thanks for the great suggestion! Moving the TCPKeepAliveAdapter to __init__ indeed streamlines the logic—keeps get_conn focused on session setup while ensuring TCP settings are ready upfront. A cleaner and more organized approach, much appreciated! 🙌\r\n\r\n\r\nIn response to the above, I've implemented two changes in this PR:\r\n\r\n1. Moved the instantiation of TCPKeepAliveAdapter to __init__ for better organization and to keep get_conn focused on session setup.\r\n2. Streamlined the handling of connection extras to make the session configuration more robust and easier to maintain."", 'created_at': datetime.datetime(2024, 11, 24, 2, 45, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495887393, 'issue_id': 2685774229, 'author': 'jieyao-MilestoneHub', 'body': ""Sure, let's have someone else take a look. Thank you for your suggestion!"", 'created_at': datetime.datetime(2024, 11, 24, 9, 22, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507614108, 'issue_id': 2685774229, 'author': 'shahar1', 'body': 'Tests currently seem to fail :(', 'created_at': datetime.datetime(2024, 11, 29, 11, 22, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2508812379, 'issue_id': 2685774229, 'author': 'jieyao-MilestoneHub', 'body': 'I need some time to figure out how to fix this issue.:)', 'created_at': datetime.datetime(2024, 11, 30, 3, 35, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511254028, 'issue_id': 2685774229, 'author': 'Lee-W', 'body': 'running `pre-commit run --all-files` locally can help you resolve issues earlier 🙂', 'created_at': datetime.datetime(2024, 12, 2, 11, 16, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512667471, 'issue_id': 2685774229, 'author': 'potiuk', 'body': '> running `pre-commit run --all-files` locally can help you resolve issues earlier 🙂\r\n\r\nOr `breeze static-checks --only-my-changes` which runs only on files you changed so it is way faster.', 'created_at': datetime.datetime(2024, 12, 2, 20, 3, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513430007, 'issue_id': 2685774229, 'author': 'jieyao-MilestoneHub', 'body': 'Thanks for your suggestion!', 'created_at': datetime.datetime(2024, 12, 3, 2, 48, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513892913, 'issue_id': 2685774229, 'author': 'Lee-W', 'body': ""Thanks @jieyao-MilestoneHub ! The PR looks LGTM! I'll keep it for one or two days for folks to check. Please ping me if I forget to get back to you and merge it."", 'created_at': datetime.datetime(2024, 12, 3, 8, 48, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513963191, 'issue_id': 2685774229, 'author': 'jieyao-MilestoneHub', 'body': 'Thank you all for taking the time to work on this together! 😊', 'created_at': datetime.datetime(2024, 12, 3, 9, 18, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514188597, 'issue_id': 2685774229, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 3, 10, 44, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515285992, 'issue_id': 2685774229, 'author': 'shahar1', 'body': '> Thank you all for taking the time to work on this together! 😊\r\n\r\nThank you for your great first contribution :)\r\nLooking forward!', 'created_at': datetime.datetime(2024, 12, 3, 18, 22, 36, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-23 10:07:49 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jieyao-MilestoneHub (Issue Creator) on (2024-11-23 13:03:50 UTC): Thank you, @shahar1, for your detailed review and valuable feedback! I’ve addressed your comments by:
1. Adding a detailed docstring for the `__init__` method, including the missing `adapter` parameter.
2. Removing the redundant instantiation of `TCPKeepAliveAdapter` in the `run` method.

Please let me know if there’s anything else I can improve. I really appreciate your time and support!

shahar1 on (2024-11-23 15:20:29 UTC): Thanks :) Regarding the 2nd point - could you please explain why it makes sense to relocate the instanation of `TCPKeepAliveAdapter` to the `__init__`?

jieyao-MilestoneHub (Issue Creator) on (2024-11-24 02:45:06 UTC): Thanks for the great suggestion! Moving the TCPKeepAliveAdapter to __init__ indeed streamlines the logic—keeps get_conn focused on session setup while ensuring TCP settings are ready upfront. A cleaner and more organized approach, much appreciated! 🙌


In response to the above, I've implemented two changes in this PR:

1. Moved the instantiation of TCPKeepAliveAdapter to __init__ for better organization and to keep get_conn focused on session setup.
2. Streamlined the handling of connection extras to make the session configuration more robust and easier to maintain.

jieyao-MilestoneHub (Issue Creator) on (2024-11-24 09:22:48 UTC): Sure, let's have someone else take a look. Thank you for your suggestion!

shahar1 on (2024-11-29 11:22:38 UTC): Tests currently seem to fail :(

jieyao-MilestoneHub (Issue Creator) on (2024-11-30 03:35:02 UTC): I need some time to figure out how to fix this issue.:)

Lee-W on (2024-12-02 11:16:21 UTC): running `pre-commit run --all-files` locally can help you resolve issues earlier 🙂

potiuk on (2024-12-02 20:03:48 UTC): Or `breeze static-checks --only-my-changes` which runs only on files you changed so it is way faster.

jieyao-MilestoneHub (Issue Creator) on (2024-12-03 02:48:17 UTC): Thanks for your suggestion!

Lee-W on (2024-12-03 08:48:34 UTC): Thanks @jieyao-MilestoneHub ! The PR looks LGTM! I'll keep it for one or two days for folks to check. Please ping me if I forget to get back to you and merge it.

jieyao-MilestoneHub (Issue Creator) on (2024-12-03 09:18:46 UTC): Thank you all for taking the time to work on this together! 😊

boring-cyborg[bot] on (2024-12-03 10:44:22 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

shahar1 on (2024-12-03 18:22:36 UTC): Thank you for your great first contribution :)
Looking forward!

"
2685679799,pull_request,closed,,AIP-84 Get Task Instance Tries,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related to: https://github.com/apache/airflow/issues/42370

<!-- Please keep an empty line above the dashes. -->
---
",kandharvishnu,2024-11-23 08:42:05+00:00,[],2024-11-25 17:09:22+00:00,2024-11-25 17:09:22+00:00,https://github.com/apache/airflow/pull/44301,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2498469759, 'issue_id': 2685679799, 'author': 'pierrejeambrun', 'body': 'Rebasing again, need latest main fix for the CI.', 'created_at': datetime.datetime(2024, 11, 25, 16, 21, 9, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-25 16:21:09 UTC): Rebasing again, need latest main fix for the CI.

"
2685631994,pull_request,closed,,Fix stats of dynamic mapped tasks after automatic retries of failed tasks,"closes: #44245

---

### Cause
The query for fetching the stats of task instances groups them by `task_id`, `run_id`, `state`, and `try_number`. However, using `try_number` for dynamic mapped tasks leads to incorrect results as individual tasks within the mapping might have different `try_number` values.

### Example
Let's say that within a dynamic mapped task there were 10 expansions - 4 of them failed in the first time and reran (i.e., `try_number = 2`).
![image](https://github.com/user-attachments/assets/184cd72f-fc0e-43f3-a0d1-a6429d16954f)

In this case, the API response will eventually show only statistics regarding the most recent `try_number`.

![image](https://github.com/user-attachments/assets/07a27c8a-af6c-4aef-8593-d5f18daf6473)

> [!NOTE]  
> Intermediate results might not exactly follow the latter pattern, as they also depend on the 
> `TaskInstance.state` parameter of the `group_by`. 


### Solution
In the query, avoid grouping by `try_number` only for dynamic mapped tasks (`map_index != -1`).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-23 08:28:31+00:00,[],2024-11-24 06:29:09+00:00,2024-11-24 01:29:20+00:00,https://github.com/apache/airflow/pull/44300,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:dynamic-task-mapping', 'AIP-42'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2495738193, 'issue_id': 2685631994, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44319""><img src=""https://img.shields.io/badge/PR-44319-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 11, 24, 1, 30, 8, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-24 01:30:08 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44319""><img src=""https://img.shields.io/badge/PR-44319-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2685616316,pull_request,closed,,Replace `breeze testing tests` command in a few places remaining,"Follow up after #43979 to remove a few remaining places where old `breeze testing tests` command was used.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-23 07:54:02+00:00,[],2024-11-23 23:30:01+00:00,2024-11-23 23:29:59+00:00,https://github.com/apache/airflow/pull/44299,"[('area:dev-tools', '')]","[{'comment_id': 2495389096, 'issue_id': 2685616316, 'author': 'potiuk', 'body': 'Thanks @ferruzzi for noticing :)', 'created_at': datetime.datetime(2024, 11, 23, 7, 54, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495689461, 'issue_id': 2685616316, 'author': 'potiuk', 'body': 'Unrelated errors. Merging', 'created_at': datetime.datetime(2024, 11, 23, 23, 29, 56, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-23 07:54:37 UTC): Thanks @ferruzzi for noticing :)

potiuk (Issue Creator) on (2024-11-23 23:29:56 UTC): Unrelated errors. Merging

"
2685223825,pull_request,closed,,Use Python 3.9 as target version for Ruff & Black rules,"Since we dropped support of Python 3.8 (after it reach EOL), we missed changing rules for black & ruff.

For reviewers: easier to just review [first commit](https://github.com/apache/airflow/pull/44298/commits/dfbbde809d5e07870b1e5f07bdc17803ac52c977), second commit is mostly  autogen code
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-23 03:26:13+00:00,[],2024-11-24 20:15:57+00:00,2024-11-24 04:51:43+00:00,https://github.com/apache/airflow/pull/44298,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:Triggerer', ''), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2495749633, 'issue_id': 2685223825, 'author': 'potiuk', 'body': 'Nice - but seems there are still some troubles with collection changes.\r\n\r\nBTW. I would like - before merge and when green re-run it locally and reapply ruff auto-changes - to see if I come up with small set of reviewable changes (aka - reproducibility check :)', 'created_at': datetime.datetime(2024, 11, 24, 1, 56, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495809436, 'issue_id': 2685223825, 'author': 'kaxil', 'body': '> Nice - but seems there are still some troubles with collection changes.\n> \n> \n> \n> BTW. I would like - before merge and when green re-run it locally and reapply ruff auto-changes - to see if I come up with small set of reviewable changes (aka - reproducibility check :)\n> \n> \n\nDone, rebased, ran ruff, force pushed locally', 'created_at': datetime.datetime(2024, 11, 24, 4, 51, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495810337, 'issue_id': 2685223825, 'author': 'kaxil', 'body': '> Interesting. How can it be that I over-looked the changes in the first commit when removing Python 3.9 support?\n\nYou already had to many changes to handle :)', 'created_at': datetime.datetime(2024, 11, 24, 4, 52, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496199713, 'issue_id': 2685223825, 'author': 'potiuk', 'body': 'And one more here @jscheffl ;) https://github.com/apache/airflow/pull/44328', 'created_at': datetime.datetime(2024, 11, 24, 19, 45, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496199953, 'issue_id': 2685223825, 'author': 'kaxil', 'body': '> And one more here @jscheffl ;) #44328\r\n\r\n:D', 'created_at': datetime.datetime(2024, 11, 24, 19, 46, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496200099, 'issue_id': 2685223825, 'author': 'kaxil', 'body': '> Interesting. How can it be that I over-looked the changes in the first commit when removing Python 3.9 support?\r\n\r\nAll good man', 'created_at': datetime.datetime(2024, 11, 24, 19, 46, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496200543, 'issue_id': 2685223825, 'author': 'jscheffl', 'body': '> And one more here @jscheffl ;) #44328\r\n\r\nHope this was the last one... or shall I go hunting again? :-D', 'created_at': datetime.datetime(2024, 11, 24, 19, 47, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496210999, 'issue_id': 2685223825, 'author': 'kaxil', 'body': ""> > And one more here @jscheffl ;) #44328\r\n> \r\n> Hope this was the last one... or shall I go hunting again? :-D\r\n\r\nIf you wouldn't be missing such things, I would consider you a bot 😄"", 'created_at': datetime.datetime(2024, 11, 24, 20, 15, 56, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-24 01:56:47 UTC): Nice - but seems there are still some troubles with collection changes.

BTW. I would like - before merge and when green re-run it locally and reapply ruff auto-changes - to see if I come up with small set of reviewable changes (aka - reproducibility check :)

kaxil (Issue Creator) on (2024-11-24 04:51:34 UTC): Done, rebased, ran ruff, force pushed locally

kaxil (Issue Creator) on (2024-11-24 04:52:09 UTC): You already had to many changes to handle :)

potiuk on (2024-11-24 19:45:21 UTC): And one more here @jscheffl ;) https://github.com/apache/airflow/pull/44328

kaxil (Issue Creator) on (2024-11-24 19:46:09 UTC): :D

kaxil (Issue Creator) on (2024-11-24 19:46:34 UTC): All good man

jscheffl on (2024-11-24 19:47:53 UTC): Hope this was the last one... or shall I go hunting again? :-D

kaxil (Issue Creator) on (2024-11-24 20:15:56 UTC): If you wouldn't be missing such things, I would consider you a bot 😄

"
2685113234,pull_request,closed,,Bump `google-cloud-translate` to `3.16`,"The changes added in https://github.com/apache/airflow/pull/44271 require 3.16 as `google.cloud.translate_v3.types.automl_translation` was added in 3.16 - https://github.com/googleapis/google-cloud-python/blob/main/packages/google-cloud-translate/CHANGELOG.md

Without this it causes failures on main such as https://github.com/apache/airflow/actions/runs/11982463149/job/33410779346?pr=44295#step:7:5367

```
  ==================================== ERRORS ====================================
  __ ERROR collecting providers/tests/google/cloud/operators/test_translate.py ___
  ImportError while importing test module '/opt/airflow/providers/tests/google/cloud/operators/test_translate.py'.
  Hint: make sure your test modules/packages have valid Python names.
  Traceback:
  /usr/local/lib/python3.11/importlib/__init__.py:126: in import_module
      return _bootstrap._gcd_import(name[level:], package, level)
  providers/tests/google/cloud/operators/test_translate.py:23: in <module>
      from google.cloud.translate_v3.types import automl_translation
  E   ImportError: cannot import name 'automl_translation' from 'google.cloud.translate_v3.types' (/usr/local/lib/python3.11/site-packages/google/cloud/translate_v3/types/__init__.py)
  ----- generated xml file: /files/test_result-providers_google-postgres.xml -----
  =========================== short test summary info ============================
  ERROR providers/tests/google/cloud/operators/test_translate.py
  !!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!
  ========================= 1 warning, 1 error in 39.33s =========================
  
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-23 02:14:18+00:00,[],2024-11-23 08:01:26+00:00,2024-11-23 03:42:11+00:00,https://github.com/apache/airflow/pull/44297,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2495390849, 'issue_id': 2685113234, 'author': 'potiuk', 'body': 'NICE!.. Our test harness seems to work well :)', 'created_at': datetime.datetime(2024, 11, 23, 8, 1, 24, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-23 08:01:24 UTC): NICE!.. Our test harness seems to work well :)

"
2685096504,pull_request,closed,,Remove unused code from `airflow/api/common/mark_tasks.py`,"PR title is self explanatory :)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-23 01:49:42+00:00,[],2024-11-23 14:01:45+00:00,2024-11-23 14:01:45+00:00,https://github.com/apache/airflow/pull/44296,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2685043094,pull_request,closed,,Bump `termcolor` to `2.5.0`,"https://pypi.org/project/termcolor/2.5.0/

This also allows us to remove `types-termcolor` as typing has been added to the package since 2.0: https://github.com/termcolor/termcolor/releases/tag/2.0.0

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-23 00:46:32+00:00,[],2024-11-23 15:01:45+00:00,2024-11-23 15:01:44+00:00,https://github.com/apache/airflow/pull/44295,"[('area:dev-tools', '')]",[],
2684903431,pull_request,closed,,Only install eval-type-backport for Python < 3.10,"The `eval-type-backport` is a tool to replace some of the controversial new type hints added with `from future imoport __annotations__` to ""classic"" type hint (| and list - into `Union` and `List`).

This helps to battle some of the issues where Pydantic has troubles when they are used for classes that Pydantic uses.

The library was initially added in #42196 but it was added for all Python versions - this change limits it only to Python < 3.10

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-22 23:22:01+00:00,[],2024-11-23 23:34:16+00:00,2024-11-23 23:28:58+00:00,https://github.com/apache/airflow/pull/44294,"[('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2495083151, 'issue_id': 2684903431, 'author': 'potiuk', 'body': 'Also see https://github.com/apache/airflow/pull/44249#issuecomment-2495077341 for context.', 'created_at': datetime.datetime(2024, 11, 22, 23, 22, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495688779, 'issue_id': 2684903431, 'author': 'potiuk', 'body': 'Issues unrelated. Merging.', 'created_at': datetime.datetime(2024, 11, 23, 23, 28, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495689241, 'issue_id': 2684903431, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/11991248507\'> Run details </a>\n\n<table>\n            <tr>\n                <th>Status</th>\n                <th>Branch</th>\n                <th>Result</th>\n            </tr>\n            <tr>\n                <td>❌</td>\n                <td>v2-10-test</td>\n                <td><a href=""https://github.com/apache/airflow/commit/29483384be5245a12ae1eb80fab364ddcbe41481""><img src=\'https://img.shields.io/badge/Commit-2948338-red\' alt=\'Commit Link\'></a></td>\n            </tr>\n        </table>', 'created_at': datetime.datetime(2024, 11, 23, 23, 29, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495691782, 'issue_id': 2684903431, 'author': 'potiuk', 'body': '> Backport failed to create: v2-10-test. View the failure log [ Run details](https://github.com/apache/airflow/actions/runs/11991248507)\r\n\r\nYeah - expected that. Will cherry pick manually.', 'created_at': datetime.datetime(2024, 11, 23, 23, 34, 14, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-22 23:22:27 UTC): Also see https://github.com/apache/airflow/pull/44249#issuecomment-2495077341 for context.

potiuk (Issue Creator) on (2024-11-23 23:28:48 UTC): Issues unrelated. Merging.

github-actions[bot] on (2024-11-23 23:29:44 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/11991248507'> Run details </a>

<table>
            <tr>
                <th>Status</th>
                <th>Branch</th>
                <th>Result</th>
            </tr>
            <tr>
                <td>❌</td>
                <td>v2-10-test</td>
                <td><a href=""https://github.com/apache/airflow/commit/29483384be5245a12ae1eb80fab364ddcbe41481""><img src='https://img.shields.io/badge/Commit-2948338-red' alt='Commit Link'></a></td>
            </tr>
        </table>

potiuk (Issue Creator) on (2024-11-23 23:34:14 UTC): Yeah - expected that. Will cherry pick manually.

"
2684695802,pull_request,closed,,Fix the Show Down text,"I needed to smile a bit when I was re-working the API and realized that the edge worker is involved in a ""show down"". Nice typo. But ""Shut down"" is correct.",jscheffl,2024-11-22 21:46:02+00:00,[],2024-11-23 00:27:00+00:00,2024-11-23 00:18:18+00:00,https://github.com/apache/airflow/pull/44292,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2495143156, 'issue_id': 2684695802, 'author': 'kaxil', 'body': ':D', 'created_at': datetime.datetime(2024, 11, 23, 0, 26, 59, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-23 00:26:59 UTC): :D

"
2684617426,pull_request,closed,,Allow dropping `_xcom_archive` table via CLI,"This tables was created to not cause data loss (in https://github.com/apache/airflow/pull/44166) when upgrading from AF 2 to AF 3 if a user had pickled values in XCom table.

- Introduced `ARCHIVED_TABLES_FROM_DB_MIGRATIONS` to track tables created during database migrations, such as `_xcom_archive`.
- Added `_xcom_archive` to the db cleanup `config_list` for handling its records based on `timestamp`.
- Add support in `airflow db drop-archived` to drop `_xcom_archive`.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-22 21:27:56+00:00,[],2024-11-22 22:53:11+00:00,2024-11-22 22:53:09+00:00,https://github.com/apache/airflow/pull/44291,[],[],
2684434020,pull_request,closed,,Use `JSONB` type for `XCom.value` column in PostgreSQL,"`JSONB` is more efficient, we already use that in migration, this makes it consistent when DB tables are created from ORM.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-22 20:12:41+00:00,[],2024-11-22 20:42:23+00:00,2024-11-22 20:42:04+00:00,https://github.com/apache/airflow/pull/44290,[],"[{'comment_id': 2494762355, 'issue_id': 2684434020, 'author': 'kaxil', 'body': 'The failure is unrelated:\r\n\r\n```\r\n=========================== short test summary info ============================\r\nFAILED tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_extra_operator_links_logs_error_for_non_registered_extra_links - assert ""Operator Link class \'tests.serialization.test_dag_serialization.TaskStateLink\' not registered"" in \'\'\r\n +  where \'\' = <_pytest.logging.LogCaptureFixture object at 0x7f1454367730>.text\r\n= 1 failed, 1709 passed, 5698 skipped, 2 xfailed, 5 warnings in 116.71s (0:01:56) =\r\n\r\n```', 'created_at': datetime.datetime(2024, 11, 22, 20, 42, 22, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-22 20:42:22 UTC): The failure is unrelated:

```
=========================== short test summary info ============================
FAILED tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_extra_operator_links_logs_error_for_non_registered_extra_links - assert ""Operator Link class 'tests.serialization.test_dag_serialization.TaskStateLink' not registered"" in ''
 +  where '' = <_pytest.logging.LogCaptureFixture object at 0x7f1454367730>.text
= 1 failed, 1709 passed, 5698 skipped, 2 xfailed, 5 warnings in 116.71s (0:01:56) =

```

"
2683445648,pull_request,closed,,Move external task sensor to standard provider,"Relates to #43641

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-11-22 14:45:14+00:00,[],2024-11-27 11:30:49+00:00,2024-11-27 11:30:49+00:00,https://github.com/apache/airflow/pull/44288,"[('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:system-tests', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2503044970, 'issue_id': 2683445648, 'author': 'kunaljubce', 'body': '> Nice - just one small thing to fix with the modified release notes.\r\n\r\nThanks for pointing this @potiuk, I have reverted the release notes changes.', 'created_at': datetime.datetime(2024, 11, 27, 6, 52, 44, tzinfo=datetime.timezone.utc)}]","kunaljubce (Issue Creator) on (2024-11-27 06:52:44 UTC): Thanks for pointing this @potiuk, I have reverted the release notes changes.

"
2683269324,pull_request,closed,,Bump Ruff to 0.8.0,"[pypi.org/project/ruff/0.8.0](https://pypi.org/project/ruff/0.8.0/)

Hi! I just released Ruff 0.8.0. This release removes a few rules that had been deprecated for a few releases, so Ruff 0.8.0 would have started emitting warnings when linting trio due to the fact that you have some of these now-removed rules explicitly ignored in your Ruff config.

This PR gets rid of the removed rules from your Ruff config. There's also some additional changes made here; let me know if any of them are undesirable, and I can revert them:
- The `flake8-type-checking` rules have been recoded from `TCH` to `TC`; I updated `noqa` comments and configuration settings related to these so that they use the new error codes
- `dev/breeze/src/airflow_breeze/utils/console.py` was changed slightly due to autofix for UP015, which has been improved in the latest release

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",AlexWaygood,2024-11-22 13:46:04+00:00,[],2024-11-23 00:13:57+00:00,2024-11-22 21:20:36+00:00,https://github.com/apache/airflow/pull/44287,"[('area:dev-tools', ''), ('area:serialization', ''), ('area:task-sdk', None)]","[{'comment_id': 2493806532, 'issue_id': 2683269324, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 22, 13, 46, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494835527, 'issue_id': 2683269324, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 22, 21, 20, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494837701, 'issue_id': 2683269324, 'author': 'jedcunningham', 'body': 'Thanks @AlexWaygood! Appreciate you coming over and doing the update for us. Congrats on your first Airflow commit 🎉', 'created_at': datetime.datetime(2024, 11, 22, 21, 21, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494927205, 'issue_id': 2683269324, 'author': 'AlexWaygood', 'body': 'No problem, glad I could help!', 'created_at': datetime.datetime(2024, 11, 22, 21, 51, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495132197, 'issue_id': 2683269324, 'author': 'potiuk', 'body': ""REALLLY NICE @AlexWaygood ... \r\n\r\nBTW. Question - out of curiosity - was it some tool or Ai used to generate those 8 PRs you opened to all the repositories ? Or was it purely manually done?\r\n\r\nI am not complaining of course, quite the opposite, but trying to figure out various automation patterns in tooling and devex. This is actually a cool idea I've been exploring with Alpha Omega Fund I work - to be able to build some kind of (automated) network of OSS projects that depend on other projects and run some checks, verifications, and eventually like you did, automated PRs to fix problems found in other projects - and this seems like a cool idea if we could help various libraries to help their users to be upgraded quicker and more automatically. I'd be courious to talk about it if you'd be interested - shoot me a message at my email from GitHub profile if you'd be interested."", 'created_at': datetime.datetime(2024, 11, 23, 0, 13, 28, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-22 13:46:09 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-22 21:20:39 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

jedcunningham on (2024-11-22 21:21:34 UTC): Thanks @AlexWaygood! Appreciate you coming over and doing the update for us. Congrats on your first Airflow commit 🎉

AlexWaygood (Issue Creator) on (2024-11-22 21:51:37 UTC): No problem, glad I could help!

potiuk on (2024-11-23 00:13:28 UTC): REALLLY NICE @AlexWaygood ... 

BTW. Question - out of curiosity - was it some tool or Ai used to generate those 8 PRs you opened to all the repositories ? Or was it purely manually done?

I am not complaining of course, quite the opposite, but trying to figure out various automation patterns in tooling and devex. This is actually a cool idea I've been exploring with Alpha Omega Fund I work - to be able to build some kind of (automated) network of OSS projects that depend on other projects and run some checks, verifications, and eventually like you did, automated PRs to fix problems found in other projects - and this seems like a cool idea if we could help various libraries to help their users to be upgraded quicker and more automatically. I'd be courious to talk about it if you'd be interested - shoot me a message at my email from GitHub profile if you'd be interested.

"
2682631511,pull_request,closed,,Lower-bind pydantic to 2.10.1,"The new pydantic 2.10 release produces different output for the OpenAPI specification for the same classes. In order to stabilize it, we should make sure Pydantic is not less than 2.10.1.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-22 09:40:08+00:00,[],2024-11-22 11:28:27+00:00,2024-11-22 11:28:26+00:00,https://github.com/apache/airflow/pull/44284,"[('area:providers', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2493344466, 'issue_id': 2682631511, 'author': 'potiuk', 'body': 'The whole issue is not solved yet BTW.\r\n\r\nSee: \r\n* https://github.com/pydantic/pydantic/issues/10924#issuecomment-2493313194\r\n* https://github.com/pydantic/pydantic/issues/10910\r\n* https://github.com/databricks/dbt-databricks/pull/843\r\n* https://github.com/apache/airflow/pull/44249#issuecomment-2491919741', 'created_at': datetime.datetime(2024, 11, 22, 9, 44, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493392298, 'issue_id': 2682631511, 'author': 'gopidesupavan', 'body': 'Is full tests require?', 'created_at': datetime.datetime(2024, 11, 22, 10, 9, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493394538, 'issue_id': 2682631511, 'author': 'gopidesupavan', 'body': 'Ah I see it has changed to dependency file, so it should trigger full tests :) ?', 'created_at': datetime.datetime(2024, 11, 22, 10, 10, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493536473, 'issue_id': 2682631511, 'author': 'potiuk', 'body': 'The failing tests are ""dataplex"" - unrelated fixed in https://github.com/apache/airflow/pull/44281', 'created_at': datetime.datetime(2024, 11, 22, 11, 28, 20, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-22 09:44:32 UTC): The whole issue is not solved yet BTW.

See: 
* https://github.com/pydantic/pydantic/issues/10924#issuecomment-2493313194
* https://github.com/pydantic/pydantic/issues/10910
* https://github.com/databricks/dbt-databricks/pull/843
* https://github.com/apache/airflow/pull/44249#issuecomment-2491919741

gopidesupavan on (2024-11-22 10:09:09 UTC): Is full tests require?

gopidesupavan on (2024-11-22 10:10:20 UTC): Ah I see it has changed to dependency file, so it should trigger full tests :) ?

potiuk (Issue Creator) on (2024-11-22 11:28:20 UTC): The failing tests are ""dataplex"" - unrelated fixed in https://github.com/apache/airflow/pull/44281

"
2682443886,pull_request,open,,Add logical_date to models using execution_date,Airflow 3 renames all database columns from 'execution_date' to 'logical_date'. This backports the new name to 2.x so users can change their code accessing those fields to use the new name before upgrading to Airflow 3.,uranusjr,2024-11-22 08:49:44+00:00,[],2025-01-20 07:47:04+00:00,,https://github.com/apache/airflow/pull/44283,"[('area:dev-tools', '')]",[],
2682352621,pull_request,open,,Rename CLI flag that specifies execution date,"The 'airflow dags trigger' command takes -e and --exec-date referring to the legacy ""execution date"" name. New -l and --logical-date flags have been added to refer to the new ""logical date"" name.

A custom argument action is implemented to emit a deprecation message when either -e or --exec-date is used instead of the new flags. Note that we do not use warnings.warn() here, but emit a message directly to stderr, because this is intended to be fired by a CLI call, which does not want the call stack provided by warnings.warn(). This is also what argparse does when you use the new 'deprecated' option on an argument (new in Python 3.13).",uranusjr,2024-11-22 08:35:40+00:00,[],2025-01-13 13:30:28+00:00,,https://github.com/apache/airflow/pull/44282,"[('area:CLI', '')]","[{'comment_id': 2493485561, 'issue_id': 2682352621, 'author': 'uranusjr', 'body': 'Actually, we might want to remove this argument entirely instead, and prefer data interval fields. Converting this to draft for now.', 'created_at': datetime.datetime(2024, 11, 22, 11, 0, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581488674, 'issue_id': 2682352621, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 10, 0, 15, 46, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-11-22 11:00:42 UTC): Actually, we might want to remove this argument entirely instead, and prefer data interval fields. Converting this to draft for now.

github-actions[bot] on (2025-01-10 00:15:46 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2682288387,pull_request,closed,,fix google datacatalog operator tests,"GCP has released new version of google-cloud-datacatalog, it seems added extra attributes.

https://github.com/apache/airflow/actions/runs/11965065908/job/33364323283#step:11:5147
https://cloud.google.com/python/docs/reference/datacatalog/latest/changelog

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-22 08:13:56+00:00,[],2024-11-22 15:51:23+00:00,2024-11-22 09:58:23+00:00,https://github.com/apache/airflow/pull/44281,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2493208241, 'issue_id': 2682288387, 'author': 'gopidesupavan', 'body': 'This seems version bump is required. in canary its installing latest version.', 'created_at': datetime.datetime(2024, 11, 22, 8, 46, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493370723, 'issue_id': 2682288387, 'author': 'gopidesupavan', 'body': 'merging this one now, failures are not related to this change :)', 'created_at': datetime.datetime(2024, 11, 22, 9, 58, 18, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-22 08:46:33 UTC): This seems version bump is required. in canary its installing latest version.

gopidesupavan (Issue Creator) on (2024-11-22 09:58:18 UTC): merging this one now, failures are not related to this change :)

"
2682263117,pull_request,closed,,[edge] Clean up of dead tasks in edge_jobs table ,"# Description

This PR fixes the issue with dead edge jobs stay in edge_job table. If worker died or was not able to update the state of a job, the task will stay forever in the table. To fix this the job last_update will be checked with the SCHEDULER_ZOMBIE_TASK_THRESHOLD time to detect zombie task and state will be set to REMOVED. A job in state REMOVED will be deleted after job_fail_purge time archived

# Details about changes
* Detect orphaned tasks after SCHEDULER_ZOMBIE_TASK_THRESHOLD 
* Add REMOVED  job state
* Remove REMOVED state jobs after job_fail_purge  time.
* Adapt unit test",AutomationDev85,2024-11-22 08:05:08+00:00,[],2024-11-22 20:02:47+00:00,2024-11-22 20:02:47+00:00,https://github.com/apache/airflow/pull/44280,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2682177415,pull_request,closed,,BigQueryInsertJobOperator: log transient error and check job state before marking task as success,"
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pankajastro,2024-11-22 07:34:24+00:00,[],2024-12-01 09:50:03+00:00,2024-12-01 09:49:38+00:00,https://github.com/apache/airflow/pull/44279,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2493124169, 'issue_id': 2682177415, 'author': 'rawwar', 'body': ""There's another active PR: https://github.com/apache/airflow/pull/40863"", 'created_at': datetime.datetime(2024, 11, 22, 8, 8, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493499113, 'issue_id': 2682177415, 'author': 'kandharvishnu', 'body': 'Closes this issue - https://github.com/apache/airflow/issues/40839', 'created_at': datetime.datetime(2024, 11, 22, 11, 6, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493675054, 'issue_id': 2682177415, 'author': 'pankajastro', 'body': ""> There's another active PR: #40863\r\n\r\nYeah, but it has some open discussions, and it's also a pretty old PR. so I thought maybe a new PR would easy."", 'created_at': datetime.datetime(2024, 11, 22, 12, 42, 40, tzinfo=datetime.timezone.utc)}]","rawwar on (2024-11-22 08:08:20 UTC): There's another active PR: https://github.com/apache/airflow/pull/40863

kandharvishnu on (2024-11-22 11:06:52 UTC): Closes this issue - https://github.com/apache/airflow/issues/40839

pankajastro (Issue Creator) on (2024-11-22 12:42:40 UTC): Yeah, but it has some open discussions, and it's also a pretty old PR. so I thought maybe a new PR would easy.

"
2681936053,pull_request,closed,,feat(asset): pass dag kwargs to asset decorator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-22 06:04:42+00:00,[],2024-11-27 01:25:51+00:00,2024-11-27 01:25:50+00:00,https://github.com/apache/airflow/pull/44278,"[('area:task-sdk', None)]","[{'comment_id': 2502415419, 'issue_id': 2681936053, 'author': 'Lee-W', 'body': 'close in favor of https://github.com/apache/airflow/pull/44384', 'created_at': datetime.datetime(2024, 11, 27, 1, 25, 50, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-11-27 01:25:50 UTC): close in favor of https://github.com/apache/airflow/pull/44384

"
2681809707,pull_request,closed,,AIP-84: Migrate Extra Links endpoint to fastapi,"#### Related: #42370

#### Testing:
API responses using legacy and fastAPI endpoints:
#### Legacy-API:
![image](https://github.com/user-attachments/assets/e3f54ea3-edc4-4eee-bb6d-20a459972f0e)



#### FastAPI:
![image](https://github.com/user-attachments/assets/5395e060-4c69-4663-b5d2-7fadacfaa91d)




<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",prabhusneha,2024-11-22 05:00:44+00:00,[],2024-11-25 16:54:00+00:00,2024-11-25 16:53:57+00:00,https://github.com/apache/airflow/pull/44277,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2498543127, 'issue_id': 2681809707, 'author': 'prabhusneha', 'body': '> Great thanks.\r\n> \r\n> Looking good overall, a few suggestions, and should be ready to merge once other comments are resolved.\r\n\r\nRebased and resolved all comments.', 'created_at': datetime.datetime(2024, 11, 25, 16, 53, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498545025, 'issue_id': 2681809707, 'author': 'pierrejeambrun', 'body': 'Thanks 👍', 'created_at': datetime.datetime(2024, 11, 25, 16, 53, 53, tzinfo=datetime.timezone.utc)}]","prabhusneha (Issue Creator) on (2024-11-25 16:53:01 UTC): Rebased and resolved all comments.

pierrejeambrun on (2024-11-25 16:53:53 UTC): Thanks 👍

"
2681480449,pull_request,closed,,Handle XCom value errors in FAB's XCom list view,"This commit improved handling of JSON columns in FAB. While we are removing FAB for 3.0, this error was bothering me in breeze :)

- Added code to correctly identify JSON columns to not add FAB filter for it.
- Excluded the `value` column from add/edit operations in `XComModelView` as XCom values are not meant to be modified directly via the UI.

Errors:

```
root@b16e4907c2ca:/opt/airflow# airflow webserver
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
Running the Gunicorn Server with:
Workers: 4 sync
Host: 0.0.0.0:8080
Timeout: 120
Logfiles: - -
Access Logformat:
=================================================================
/usr/local/lib/python3.9/site-packages/flask_limiter/extension.py:333 UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.
[2024-11-22T01:22:43.225+0000] {filters.py:117} WARNING - Filter type not supported for column: value
[2024-11-22T01:22:43.225+0000] {filters.py:117} WARNING - Filter type not supported for column: value
[2024-11-22T01:22:43.226+0000] {filters.py:117} WARNING - Filter type not supported for column: value
[2024-11-22T01:22:43.226+0000] {filters.py:117} WARNING - Filter type not supported for column: value
[2024-11-22T01:22:43.226+0000] {forms.py:107} ERROR - Column value Type not supported
[2024-11-22T01:22:43.226+0000] {forms.py:107} ERROR - Column value Type not supported
[2024-11-22T01:22:43.226+0000] {forms.py:107} ERROR - Column value Type not supported
[2024-11-22T01:22:43.226+0000] {forms.py:107} ERROR - Column value Type not supported
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-22 01:23:26+00:00,[],2024-11-22 11:43:21+00:00,2024-11-22 11:43:18+00:00,https://github.com/apache/airflow/pull/44275,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2681393671,pull_request,closed,,Specify workspaceFolder so devcontainer will start in local docker w/ vscode,"Current files on main fail with ""Workspace folder not specified in devcontainer.json"" for postgres and mysql backends. This fixes it.

I found these issue on MacOS 15.1.1 using Docker Desktop.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",perry2of5,2024-11-22 00:18:57+00:00,[],2024-11-22 18:12:48+00:00,2024-11-22 17:35:24+00:00,https://github.com/apache/airflow/pull/44273,[],[],
2681274078,pull_request,closed,,Add EmptyOperator and decorator to decorators/empty.py,"# Add EmptyOperator with @task.empty decorator

## Objective
This PR introduces a new operator called `EmptyOperator` with support for the `@task.empty` decorator. This operator serves as a placeholder for tasks in DAGs that do not have any execution logic but are useful for defining the structure of the workflow.

## Key Changes
- Created `airflow/decorators/empty.py` with the implementation of `EmptyOperator` and the `@task.empty` decorator.
- Modified `airflow/decorators/__init__.pyi` to expose the new `empty` decorator.
- Added functionality to capture `args/kwargs` and log custom messages when executing tasks decorated with `@task.empty`.

## Example Usage
```python
from airflow.decorators import dag, task
from airflow.utils.dates import days_ago

@dag(schedule_interval=None, start_date=days_ago(1), catchup=False)
def my_empty_dag():
    @task.empty
    def start_task():
        print(""This is a placeholder start task."")

    @task.empty
    def end_task():
        print(""This is a placeholder end task."")

    start_task() >> end_task()

dag = my_empty_dag()
",AlefRP,2024-11-21 23:23:37+00:00,[],2024-11-25 10:06:09+00:00,2024-11-25 10:06:08+00:00,https://github.com/apache/airflow/pull/44272,[],"[{'comment_id': 2492554569, 'issue_id': 2681274078, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 21, 23, 23, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492925682, 'issue_id': 2681274078, 'author': 'eladkal', 'body': ""Given that we plan to move decorators to standard provider https://github.com/apache/airflow/pull/44027 it's best to add new decorators to the standard provider directly rather than to the old path"", 'created_at': datetime.datetime(2024, 11, 22, 5, 52, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494977035, 'issue_id': 2681274078, 'author': 'potiuk', 'body': 'I think it\'s also not a good idea. The whole idea of an EmptyOperator is that it is empty. so decorating a method with it makes no sense - because it will never have a callable. The whole idea of an empty operator is that it is there, serviing as a placeholder but it is also skipped when scheduling. Enttirely skipped in scheduler without even attempting to run anything - without even considering running anything.\r\n\r\nAs far as I understand it now - when it decorates a funtion, it\'s essentially the same as `@task` - the only difference is that it wraps around EmptyOperator, but - unless I understand it wrongly and please correct me if I am wrong - it will actually attempt to execute the ""execute()"" method (unlike when you use EmptyOperator in your DAG directly). This is also why you have logs at execution time.\r\n\r\nSo basically it\'s no different to write:\r\n\r\n```python\r\n@task.empty()\r\ndef empty_task_a():\r\n     pass\r\n```\r\n\r\nthan\r\n\r\n```python\r\n@task\r\ndef empty_task_a():\r\n     pass\r\n```\r\n\r\nIMHO - they will behave exactly the same.\r\n\r\nOr am I wrong @AlefRP ?', 'created_at': datetime.datetime(2024, 11, 22, 22, 28, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-21 23:23:41 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-11-22 05:52:21 UTC): Given that we plan to move decorators to standard provider https://github.com/apache/airflow/pull/44027 it's best to add new decorators to the standard provider directly rather than to the old path

potiuk on (2024-11-22 22:28:18 UTC): I think it's also not a good idea. The whole idea of an EmptyOperator is that it is empty. so decorating a method with it makes no sense - because it will never have a callable. The whole idea of an empty operator is that it is there, serviing as a placeholder but it is also skipped when scheduling. Enttirely skipped in scheduler without even attempting to run anything - without even considering running anything.

As far as I understand it now - when it decorates a funtion, it's essentially the same as `@task` - the only difference is that it wraps around EmptyOperator, but - unless I understand it wrongly and please correct me if I am wrong - it will actually attempt to execute the ""execute()"" method (unlike when you use EmptyOperator in your DAG directly). This is also why you have logs at execution time.

So basically it's no different to write:

```python
@task.empty()
def empty_task_a():
     pass
```

than

```python
@task
def empty_task_a():
     pass
```

IMHO - they will behave exactly the same.

Or am I wrong @AlefRP ?

"
2681271884,pull_request,closed,,Introduce gcp advance (V3) API translate native datasets operators,"- Add support for native datasets for Cloud Translation API.

- The datasets created via automl API are considered legacy, as they keep been supported, all new enhancements
will be avaliable for native datasets(reccomended), created by Cloud Translate API, see more: https://cloud.google.com/translate/docs/advanced/automl-upgrade.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-11-21 23:21:25+00:00,[],2024-11-23 02:01:48+00:00,2024-11-22 21:59:31+00:00,https://github.com/apache/airflow/pull/44271,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2681208785,pull_request,closed,,"Replace var names `select`, `base_select`, `base_query` with `query`","Previosly it was `base_select` then recently renamed to `select`.  `select` is not a great choice because it collides with the sqlalchemy function.  Query is a better name.

Also best to remove the ""base"" part of it because we tend to mutate it, making it not a ""base"" of anything.
",dstandish,2024-11-21 22:40:33+00:00,[],2024-11-25 21:49:34+00:00,2024-11-25 21:49:33+00:00,https://github.com/apache/airflow/pull/44270,[],"[{'comment_id': 2498609637, 'issue_id': 2681208785, 'author': 'pierrejeambrun', 'body': 'statement is fine by me too :)', 'created_at': datetime.datetime(2024, 11, 25, 17, 22, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-25 17:22:00 UTC): statement is fine by me too :)

"
2681120429,pull_request,closed,,Add Dag Runs list to new UI,"Use list dag run and get dag run to render a list of dag runs, initialize a dag run page, and add an Overview button to see failed runs.

Also:
- moved TaskCountChart to its own component
- use chakra's Status component
- remove 8 hours option in time range selector. 12 is good

<img width=""730"" alt=""Screenshot 2024-11-21 at 5 08 46 PM"" src=""https://github.com/user-attachments/assets/633cfee5-afb4-44b2-8544-ff5f224065b6"">
<img width=""837"" alt=""Screenshot 2024-11-21 at 5 08 41 PM"" src=""https://github.com/user-attachments/assets/89b64dce-27f3-40f2-aa78-550d15683997"">
<img width=""1334"" alt=""Screenshot 2024-11-21 at 5 08 35 PM"" src=""https://github.com/user-attachments/assets/aafe9400-cdb2-4ae0-bc09-877de2ca11c5"">



---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-21 22:11:38+00:00,[],2024-12-04 14:24:34+00:00,2024-12-04 14:24:32+00:00,https://github.com/apache/airflow/pull/44269,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2493178752, 'issue_id': 2681120429, 'author': 'tirkarthi', 'body': 'Since `try_number` is present in the task_instance probably a filter to get `task_instance.try_number > 1` could be added to the API to fill retried tasks section. Something like below but the color palette needs a fix since up_for_retry has gold color which is not compatible with Chakra.\r\n\r\n```patch\r\ndiff --git a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\r\nindex 2f74f22689..5238ad1f91 100644\r\n--- a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\r\n+++ b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml\r\n@@ -3894,6 +3894,22 @@ paths:\r\n           - type: number\r\n           - type: \'null\'\r\n           title: Duration Lte\r\n+      - name: try_number_gte\r\n+        in: query\r\n+        required: false\r\n+        schema:\r\n+          anyOf:\r\n+          - type: number\r\n+          - type: \'null\'\r\n+          title: Try Number Gte\r\n+      - name: try_number_lte\r\n+        in: query\r\n+        required: false\r\n+        schema:\r\n+          anyOf:\r\n+          - type: number\r\n+          - type: \'null\'\r\n+          title: Try Number Lte\r\n       - name: state\r\n         in: query\r\n         required: false\r\ndiff --git a/airflow/api_fastapi/core_api/routes/public/task_instances.py b/airflow/api_fastapi/core_api/routes/public/task_instances.py\r\nindex 6d5b427abb..9278ed16cb 100644\r\n--- a/airflow/api_fastapi/core_api/routes/public/task_instances.py\r\n+++ b/airflow/api_fastapi/core_api/routes/public/task_instances.py\r\n@@ -277,6 +277,7 @@ def get_task_instances(\r\n     end_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(""end_date"", TI))],\r\n     update_at_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(""updated_at"", TI))],\r\n     duration_range: Annotated[RangeFilter, Depends(float_range_filter_factory(""duration"", TI))],\r\n+    try_number: Annotated[RangeFilter, Depends(float_range_filter_factory(""try_number"", TI))],\r\n     state: QueryTIStateFilter,\r\n     pool: QueryTIPoolFilter,\r\n     queue: QueryTIQueueFilter,\r\n@@ -325,6 +326,7 @@ def get_task_instances(\r\n             end_date_range,\r\n             update_at_range,\r\n             duration_range,\r\n+            try_number,\r\n             state,\r\n             pool,\r\n             queue,\r\ndiff --git a/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx b/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx\r\nindex 1a891cf8a7..d803b89eb3 100644\r\n--- a/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx\r\n+++ b/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx\r\n@@ -49,6 +49,16 @@ export const Overview = () => {\r\n       state: [""failed""],\r\n     });\r\n \r\n+  const { data: retriedTasks, isLoading: isLoadingRetriedTasks } =\r\n+    useTaskInstanceServiceGetTaskInstances({\r\n+      dagId: dagId ?? """",\r\n+      dagRunId: ""~"",\r\n+      logicalDateGte: startDate,\r\n+      logicalDateLte: endDate,\r\n+      state: [""failed""],\r\n+      tryNumberGte: 1,\r\n+    });\r\n+\r\n   const { data: failedRuns, isLoading: isLoadingRuns } =\r\n     useDagRunServiceGetDagRuns({\r\n       dagId: dagId ?? """",\r\n@@ -77,7 +87,7 @@ export const Overview = () => {\r\n           events={(failedTasks?.task_instances ?? []).map((ti) => ({\r\n             timestamp: ti.start_date ?? ti.logical_date,\r\n           }))}\r\n-          isLoading={isLoading}\r\n+          isLoading={isLoadingRetriedTasks}\r\n           label=""Failed Task""\r\n           route={`${location.pathname}/tasks`}\r\n           startDate={startDate}\r\n@@ -97,6 +107,18 @@ export const Overview = () => {\r\n           }}\r\n           startDate={startDate}\r\n         />\r\n+        <TrendCountButton\r\n+          colorPalette={stateColor.up_for_retry}\r\n+          count={retriedTasks?.total_entries ?? 0}\r\n+          endDate={endDate}\r\n+          events={(retriedTasks?.task_instances ?? []).map((ti) => ({\r\n+            timestamp: ti.start_date ?? ti.logical_date,\r\n+          }))}\r\n+          isLoading={isLoading}\r\n+          label=""Retried Task""\r\n+          route={`${location.pathname}/tasks`}\r\n+          startDate={startDate}\r\n+        />\r\n       </HStack>\r\n     </Box>\r\n   );\r\n```', 'created_at': datetime.datetime(2024, 11, 22, 8, 34, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493831162, 'issue_id': 2681120429, 'author': 'bbovenzi', 'body': '> Since `try_number` is present in the task_instance probably a filter to get `task_instance.try_number > 1` could be added to the API to fill retried tasks section. Something like below but the color palette needs a fix since up_for_retry has gold color which is not compatible with Chakra.\r\n\r\nNice! Do you want to make a pull request with that after this is merged?', 'created_at': datetime.datetime(2024, 11, 22, 13, 58, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493907448, 'issue_id': 2681120429, 'author': 'tirkarthi', 'body': 'Sure @bbovenzi', 'created_at': datetime.datetime(2024, 11, 22, 14, 36, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515478570, 'issue_id': 2681120429, 'author': 'bbovenzi', 'body': ""Fixed the params link issue by removing Chakra's tabs and making our Dag Tabs component just a list of NavLinks instead."", 'created_at': datetime.datetime(2024, 12, 3, 20, 23, 54, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-11-22 08:34:35 UTC): Since `try_number` is present in the task_instance probably a filter to get `task_instance.try_number > 1` could be added to the API to fill retried tasks section. Something like below but the color palette needs a fix since up_for_retry has gold color which is not compatible with Chakra.

```patch
diff --git a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml
index 2f74f22689..5238ad1f91 100644
--- a/airflow/api_fastapi/core_api/openapi/v1-generated.yaml
+++ b/airflow/api_fastapi/core_api/openapi/v1-generated.yaml
@@ -3894,6 +3894,22 @@ paths:
           - type: number
           - type: 'null'
           title: Duration Lte
+      - name: try_number_gte
+        in: query
+        required: false
+        schema:
+          anyOf:
+          - type: number
+          - type: 'null'
+          title: Try Number Gte
+      - name: try_number_lte
+        in: query
+        required: false
+        schema:
+          anyOf:
+          - type: number
+          - type: 'null'
+          title: Try Number Lte
       - name: state
         in: query
         required: false
diff --git a/airflow/api_fastapi/core_api/routes/public/task_instances.py b/airflow/api_fastapi/core_api/routes/public/task_instances.py
index 6d5b427abb..9278ed16cb 100644
--- a/airflow/api_fastapi/core_api/routes/public/task_instances.py
+++ b/airflow/api_fastapi/core_api/routes/public/task_instances.py
@@ -277,6 +277,7 @@ def get_task_instances(
     end_date_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(""end_date"", TI))],
     update_at_range: Annotated[RangeFilter, Depends(datetime_range_filter_factory(""updated_at"", TI))],
     duration_range: Annotated[RangeFilter, Depends(float_range_filter_factory(""duration"", TI))],
+    try_number: Annotated[RangeFilter, Depends(float_range_filter_factory(""try_number"", TI))],
     state: QueryTIStateFilter,
     pool: QueryTIPoolFilter,
     queue: QueryTIQueueFilter,
@@ -325,6 +326,7 @@ def get_task_instances(
             end_date_range,
             update_at_range,
             duration_range,
+            try_number,
             state,
             pool,
             queue,
diff --git a/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx b/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx
index 1a891cf8a7..d803b89eb3 100644
--- a/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx
+++ b/airflow/ui/src/pages/DagsList/Dag/Overview/Overview.tsx
@@ -49,6 +49,16 @@ export const Overview = () => {
       state: [""failed""],
     });
 
+  const { data: retriedTasks, isLoading: isLoadingRetriedTasks } =
+    useTaskInstanceServiceGetTaskInstances({
+      dagId: dagId ?? """",
+      dagRunId: ""~"",
+      logicalDateGte: startDate,
+      logicalDateLte: endDate,
+      state: [""failed""],
+      tryNumberGte: 1,
+    });
+
   const { data: failedRuns, isLoading: isLoadingRuns } =
     useDagRunServiceGetDagRuns({
       dagId: dagId ?? """",
@@ -77,7 +87,7 @@ export const Overview = () => {
           events={(failedTasks?.task_instances ?? []).map((ti) => ({
             timestamp: ti.start_date ?? ti.logical_date,
           }))}
-          isLoading={isLoading}
+          isLoading={isLoadingRetriedTasks}
           label=""Failed Task""
           route={`${location.pathname}/tasks`}
           startDate={startDate}
@@ -97,6 +107,18 @@ export const Overview = () => {
           }}
           startDate={startDate}
         />
+        <TrendCountButton
+          colorPalette={stateColor.up_for_retry}
+          count={retriedTasks?.total_entries ?? 0}
+          endDate={endDate}
+          events={(retriedTasks?.task_instances ?? []).map((ti) => ({
+            timestamp: ti.start_date ?? ti.logical_date,
+          }))}
+          isLoading={isLoading}
+          label=""Retried Task""
+          route={`${location.pathname}/tasks`}
+          startDate={startDate}
+        />
       </HStack>
     </Box>
   );
```

bbovenzi (Issue Creator) on (2024-11-22 13:58:21 UTC): Nice! Do you want to make a pull request with that after this is merged?

tirkarthi on (2024-11-22 14:36:34 UTC): Sure @bbovenzi

bbovenzi (Issue Creator) on (2024-12-03 20:23:54 UTC): Fixed the params link issue by removing Chakra's tabs and making our Dag Tabs component just a list of NavLinks instead.

"
2681078654,pull_request,closed,,implement singleton _otel_logger_instance,"#41822  wip

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dannyl1u,2024-11-21 21:46:30+00:00,[],2025-01-12 00:17:20+00:00,2025-01-12 00:17:19+00:00,https://github.com/apache/airflow/pull/44268,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2571807407, 'issue_id': 2681078654, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 6, 0, 16, 23, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-06 00:16:23 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2680998887,pull_request,closed,,Add base model for rest api; set from_attributes=True,"Add base model for rest api; set from_attributes=True

This enables us to have simpler API code, since we don't need to call `model_validate` as much.",dstandish,2024-11-21 21:26:47+00:00,[],2024-11-22 16:39:51+00:00,2024-11-22 16:39:49+00:00,https://github.com/apache/airflow/pull/44267,[],[],
2680894692,pull_request,closed,,Update newsfragment text for clarification for #41808,As discussed in https://github.com/apache/airflow/pull/41808#issuecomment-2489829891,jscheffl,2024-11-21 20:44:01+00:00,[],2024-11-21 21:04:17+00:00,2024-11-21 21:04:16+00:00,https://github.com/apache/airflow/pull/44266,[],[],
2680765740,pull_request,closed,,AIP84: UI endpoint for config,"**closes**: https://github.com/apache/airflow/issues/43166

### Description
In the old UI, we passed a lot of variables via global variables in FAB templates. This PR replaces that with `ui/config` so that UI can use it.


Response json

```
{
    ""navbar_color"": ""#fff"",
    ""navbar_text_color"": ""#51504f"",
    ""navbar_hover_color"": ""#eee"",
    ""navbar_text_hover_color"": ""#51504f"",
    ""navbar_logo_text_color"": ""#51504f"",
    ""page_size"": 100,
    ""auto_refresh_interval"": 3,
    ""default_ui_timezone"": ""UTC"",
    ""hide_paused_dags_by_default"": false,
    ""instance_name"": ""Airflow"",
    ""instance_name_has_markup"": false,
    ""enable_swagger_ui"": true,
    ""require_confirmation_dag_change"": false,
    ""default_wrap"": false,
    ""warn_deployment_exposure"": true,
    ""audit_view_excluded_events"": """",
    ""audit_view_included_events"": """",
    ""is_k8s"": false,
    ""test_connection"": ""Disabled"",
    ""state_color_mapping"": {
        ""deferred"": ""mediumpurple"",
        ""failed"": ""red"",
        ""queued"": ""gray"",
        ""removed"": ""lightgrey"",
        ""restarting"": ""violet"",
        ""running"": ""lime"",
        ""scheduled"": ""tan"",
        ""skipped"": ""hotpink"",
        ""success"": ""green"",
        ""up_for_reschedule"": ""turquoise"",
        ""up_for_retry"": ""gold"",
        ""upstream_failed"": ""orange""
    }
}
```

### Testing

<img width=""1323"" alt=""image"" src=""https://github.com/user-attachments/assets/ea3db4dc-0784-41ea-b821-9b9c6cb93321"">

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-21 20:13:20+00:00,[],2024-11-22 14:08:32+00:00,2024-11-22 14:08:29+00:00,https://github.com/apache/airflow/pull/44265,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2493368659, 'issue_id': 2680765740, 'author': 'vatsrahul1001', 'body': '> Looking good.\r\n> \r\n> Just a few suggestions/questions.\r\n> \r\n> Are we missing the `standalone_dag_processor` ?\r\n\r\nAs per below inline from Brent we have to do this in [issue](https://github.com/apache/airflow/issues/44253)\r\n\r\n```\r\nOther config:\r\nstandalone_dag_processor [This should be checked in API, not the UI](https://github.com/apache/airflow/issues/44253)\r\n```', 'created_at': datetime.datetime(2024, 11, 22, 9, 57, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493528447, 'issue_id': 2680765740, 'author': 'pierrejeambrun', 'body': '> Are we missing the standalone_dag_processor ?\r\n\r\nAt first glance, it feels like we just need to add an extra field to `additional_config` with `conf.getboolean(""scheduler"", ""standalone_dag_processor"")` ?\r\n\r\nMaybe i\'m missing something though.', 'created_at': datetime.datetime(2024, 11, 22, 11, 23, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493649265, 'issue_id': 2680765740, 'author': 'vatsrahul1001', 'body': '> > Are we missing the standalone_dag_processor ?\r\n> \r\n> At first glance, it feels like we just need to add an extra field to `additional_config` with `conf.getboolean(""scheduler"", ""standalone_dag_processor"")` ?\r\n> \r\n> Maybe i\'m missing something though.\r\n\r\n@bbovenzi can you confirm on this?', 'created_at': datetime.datetime(2024, 11, 22, 12, 29, 5, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-11-22 09:57:13 UTC): As per below inline from Brent we have to do this in [issue](https://github.com/apache/airflow/issues/44253)

```
Other config:
standalone_dag_processor [This should be checked in API, not the UI](https://github.com/apache/airflow/issues/44253)
```

pierrejeambrun on (2024-11-22 11:23:39 UTC): At first glance, it feels like we just need to add an extra field to `additional_config` with `conf.getboolean(""scheduler"", ""standalone_dag_processor"")` ?

Maybe i'm missing something though.

vatsrahul1001 (Issue Creator) on (2024-11-22 12:29:05 UTC): @bbovenzi can you confirm on this?

"
2680434604,pull_request,closed,,Allow `json_result_force_utf8_encoding` specification in `providers.snowflake.hooks.SnowflakeHook` extra dict,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

**Motivation/Justification**:

Snowflake's Python connector recommends using `json_result_force_utf8_decoding` to `True`, but preserves it as `False`/no-op for [legacy reasons](https://docs.snowflake.com/en/release-notes/clients-drivers/snowsql-2023#id7). I've come across cases at work where not setting this returns unexpected results, whereas setting it to True (via a workaround) returns the expected results.

Therefore, I think there is a valid case for allowing this to be passed via connection arguments (via `extra`).

[Relevant 'upstream' Snowflake connector code](https://github.com/snowflakedb/snowflake-connector-python/blob/main/src/snowflake/connector/connection.py#L370)

<!-- Please keep an empty line above the dashes. -->
---

- [x] Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ttzhou,2024-11-21 18:17:43+00:00,[],2024-11-28 03:50:22+00:00,2024-11-28 03:50:18+00:00,https://github.com/apache/airflow/pull/44264,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]","[{'comment_id': 2491952781, 'issue_id': 2680434604, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 21, 18, 17, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505210857, 'issue_id': 2680434604, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 28, 3, 50, 21, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-21 18:17:48 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-28 03:50:21 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2680432557,pull_request,closed,,Ensure that Task SDK supervisor closes all its subprocess handles correctly.,"If we keep any copies of the handles open then the selector loop in monitor
process will get stuck waiting on a read loop on a socket that never closes
(because its open in the same process still!).

Sadly I wasn't able to reproduce this behaviour in unit tests, but only when
running this code for real. (The main fix here is to pass `child_stderr` to
_close_unused_sockets too, the rest are drive-by tidy ups)

Since we never access `proc.stdout` or stderr on the class (they are closed
over in the callbacks only) I removed those properties as they aren't needed
and shouldn't be accessed directly as it would lead to garbled output.

Also add tests (and re-fix) the last-chance exception handling
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-21 18:16:34+00:00,[],2024-11-22 13:39:39+00:00,2024-11-22 10:15:47+00:00,https://github.com/apache/airflow/pull/44263,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2680416039,pull_request,closed,,Fix Dataplex Data Quality partial update,"Fix a failure when trying to do a partial update of Dataplex Data Quality Task and always getting AirflowException because mandatory fields are missing.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amirmor1,2024-11-21 18:07:46+00:00,[],2024-11-22 23:01:15+00:00,2024-11-22 23:01:15+00:00,https://github.com/apache/airflow/pull/44262,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2680259241,pull_request,closed,,Fix Dataplex Data Quality partial update,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

Fix a failure when trying to do a partial update of Dataplex Data Quality Task and always getting AirflowException because mandatory fields are missing.



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amirmor1,2024-11-21 17:14:10+00:00,[],2024-11-21 17:14:37+00:00,2024-11-21 17:14:36+00:00,https://github.com/apache/airflow/pull/44261,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2680217528,pull_request,closed,,Attempt to build with main version of pydantic,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-21 16:57:29+00:00,[],2024-11-22 22:01:50+00:00,2024-11-22 22:01:50+00:00,https://github.com/apache/airflow/pull/44260,[],"[{'comment_id': 2492661949, 'issue_id': 2680217528, 'author': 'sydney-runkle', 'body': 'You can try against v2.10.1 now :)', 'created_at': datetime.datetime(2024, 11, 22, 1, 4, 15, tzinfo=datetime.timezone.utc)}]","sydney-runkle on (2024-11-22 01:04:15 UTC): You can try against v2.10.1 now :)

"
2680096013,pull_request,closed,,Add `otel_headers` to OTel logic,"Does anyone know why just doing `export OTEL_EXPORTER_OTLP_HEADERS='Authorization=your-write-token'` on the terminal, before running airflow isn't enough? Airflow ignores environment variables?",Kludex,2024-11-21 16:26:30+00:00,[],2024-11-27 09:15:03+00:00,2024-11-27 09:15:00+00:00,https://github.com/apache/airflow/pull/44258,[],"[{'comment_id': 2491702602, 'issue_id': 2680096013, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 21, 16, 26, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493391717, 'issue_id': 2680096013, 'author': 'Kludex', 'body': ""I see an analogous PR that didn't have any tests: https://github.com/apache/airflow/pull/42441/\r\n\r\nCan someone help me to move this forward? Also, the question no one is answering me: https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1732208803722989 😅"", 'created_at': datetime.datetime(2024, 11, 22, 10, 8, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503330968, 'issue_id': 2680096013, 'author': 'Kludex', 'body': ""Since https://github.com/apache/airflow/pull/44346 was merged, we don't need this."", 'created_at': datetime.datetime(2024, 11, 27, 9, 15, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-21 16:26:34 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

Kludex (Issue Creator) on (2024-11-22 10:08:51 UTC): I see an analogous PR that didn't have any tests: https://github.com/apache/airflow/pull/42441/

Can someone help me to move this forward? Also, the question no one is answering me: https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1732208803722989 😅

Kludex (Issue Creator) on (2024-11-27 09:15:00 UTC): Since https://github.com/apache/airflow/pull/44346 was merged, we don't need this.

"
2679813941,pull_request,closed,,Use airflow config in new UI,"Use the new public/config api endpoint to make sure the UI uses config values. The public endpoint can we switched off. So later on we should migrate this to a dedicated `ui/config` endpoint.

Also, I didn't get around to `show_trigger_form_if_no_params` since we may also need API changes to make that work.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-21 14:57:07+00:00,[],2024-11-21 18:15:39+00:00,2024-11-21 18:15:36+00:00,https://github.com/apache/airflow/pull/44252,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2679693333,pull_request,closed,,"Revert ""Remove `/webapp` prefix from new UI (#44227)""","This reverts commit 82e0157c7c252ad298d2018990d378def07d0077.

From #44227 - failing tests",jedcunningham,2024-11-21 14:36:26+00:00,[],2024-11-21 14:50:21+00:00,2024-11-21 14:47:58+00:00,https://github.com/apache/airflow/pull/44251,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2491436675, 'issue_id': 2679693333, 'author': 'bbovenzi', 'body': 'Oh my bad for merging too fast!', 'created_at': datetime.datetime(2024, 11, 21, 14, 50, 19, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-11-21 14:50:19 UTC): Oh my bad for merging too fast!

"
2679665507,pull_request,closed,,Restrict pydantic 2.10.0,"Recent pydantic 2.10.0 release causing failures in CI.
It seems there is ticket already opened here. https://github.com/pydantic/pydantic/issues/10910

Failing tests in CI https://github.com/apache/airflow/actions/runs/11954326679/job/33324739597#step:7:12365

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-21 14:26:40+00:00,[],2024-11-23 01:23:28+00:00,2024-11-22 00:34:22+00:00,https://github.com/apache/airflow/pull/44249,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2491397416, 'issue_id': 2679665507, 'author': 'sydney-runkle', 'body': ""We should have a patch release out this afternoon with a fix for the issues you're encountering :)"", 'created_at': datetime.datetime(2024, 11, 21, 14, 36, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491431197, 'issue_id': 2679665507, 'author': 'ashb', 'body': ""@sydney-runkle Do you plan on yanking the 2.10.0 release? (I don't mind either way, just need to know what we do)\r\n\r\nIf 2.10.0 gets yanked then we don't need to keep this/can revert it, otherwise we probably should keep the exclusion rule"", 'created_at': datetime.datetime(2024, 11, 21, 14, 48, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491724895, 'issue_id': 2679665507, 'author': 'sydney-runkle', 'body': ""We're not going to yank v2.10.0, will just release a v2.10.1 patch soon!"", 'created_at': datetime.datetime(2024, 11, 21, 16, 35, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491726425, 'issue_id': 2679665507, 'author': 'sydney-runkle', 'body': 'Perhaps you all could test against our `main` branch before we do our patch release to confirm that all is working as expected on your end?', 'created_at': datetime.datetime(2024, 11, 21, 16, 36, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491741605, 'issue_id': 2679665507, 'author': 'potiuk', 'body': '> Perhaps you all could test against our `main` branch before we do our patch release to confirm that all is working as expected on your end?\r\n\r\nIt would be easier if you have an rc or beta/alpha released in PyPI - because I am not sure if we can trigger the whole test suite against Github-installed version. Can it be done @sydney-runkle ?', 'created_at': datetime.datetime(2024, 11, 21, 16, 41, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491756113, 'issue_id': 2679665507, 'author': 'sydney-runkle', 'body': 'You can try with `pydantic==git+https://github.com/pydantic/pydantic@main`', 'created_at': datetime.datetime(2024, 11, 21, 16, 47, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491765857, 'issue_id': 2679665507, 'author': 'potiuk', 'body': ""> You can try with `pydantic==git+https://github.com/pydantic/pydantic@main`\r\n\r\nIt might be that we expect version in our CI for that, so I am not sure if it's going to work . I can try, but I have a feeling it will fail in one of the steps."", 'created_at': datetime.datetime(2024, 11, 21, 16, 52, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491784564, 'issue_id': 2679665507, 'author': 'gopidesupavan', 'body': ""> > You can try with `pydantic==git+https://github.com/pydantic/pydantic@main`\r\n> \r\n> It might be that we expect version in our CI for that, so I am not sure if it's going to work . I can try, but I have a feeling it will fail in one of the steps.\r\n\r\nyeah i think it might fail at constraints ?"", 'created_at': datetime.datetime(2024, 11, 21, 17, 0, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491784934, 'issue_id': 2679665507, 'author': 'potiuk', 'body': ""> > You can try with `pydantic==git+https://github.com/pydantic/pydantic@main`\r\n> \r\n> It might be that we expect version in our CI for that, so I am not sure if it's going to work . I can try, but I have a feeling it will fail in one of the steps.\r\n\r\nTrying it here @sydney-runkle https://github.com/apache/airflow/pull/44260"", 'created_at': datetime.datetime(2024, 11, 21, 17, 0, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491789913, 'issue_id': 2679665507, 'author': 'potiuk', 'body': ""> > > You can try with `pydantic==git+https://github.com/pydantic/pydantic@main`\r\n> > \r\n> > \r\n> > It might be that we expect version in our CI for that, so I am not sure if it's going to work . I can try, but I have a feeling it will fail in one of the steps.\r\n> \r\n> Trying it here @sydney-runkle #44260\r\n\r\nYeah... some tests are already failing here as I suspected. But those are auxiliary ones, maybe the main part of the tests that actually failed before will be ok:\r\n\r\n```\r\n  Preparing metadata (pyproject.toml): finished with status 'done'\r\nERROR: Requested apache-airflow==3.0.0.dev0 from file:///home/runner/work/airflow/airflow has invalid metadata: Expected end or semicolon (after name and no valid version specifier)\r\n    pydantic==git+https://github.com/pydantic/pydantic@main\r\n```"", 'created_at': datetime.datetime(2024, 11, 21, 17, 1, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491919741, 'issue_id': 2679665507, 'author': 'Viicos', 'body': ""We're going to release 2.10.1 any minute now.\r\n\r\nWe got [a report](https://github.com/pydantic/pydantic/issues/10924) today of an issue happening on Python <3.10. The [`TaskInstancePydantic`](https://github.com/apache/airflow/blob/1307e37bc6338c43aa5099752d012e244f8494ba/airflow/serialization/pydantic/taskinstance.py#L84) class is subclassing [`LoggingMixin`](https://github.com/apache/airflow/blob/main/airflow/utils/log/logging_mixin.py#L68). This class has an annotation for `_log` using the new 3.10+ union syntax. While Pydantic has always evaluated _all_ type annotations of models including their bases, we were not using the correct globals and locals to so. Meaning with the following example:\r\n\r\n*a.py*\r\n\r\n```python\r\nfrom logging import Logger\r\n\r\nclass Base:\r\n    _log: 'Logger | None'\r\n```\r\n\r\n*b.py*\r\n\r\n```python\r\nfrom a import Base\r\n\r\nfrom pydantic import BaseModel\r\n\r\nclass Model(BaseModel, Base):\r\n    pass\r\n```\r\n\r\nEvalutating the annotation for `_log` would have resulted in a `NameError`, because `Logger` is imported in `a.py`, and we only used the globals of the `b.py` module until now. `NameError`'s are ignored to allow for types to be defined later on. However, on 2.10, this now raises a `TypeError` because `'Logger | None'` successfully evaluates (read: `Logger` can be resolved), but the union syntax is not supported on Python 3.9.\r\n\r\nWhat's probably best is to make sure you're using the old syntax for every class that is going to be used in the context of a Pydantic model."", 'created_at': datetime.datetime(2024, 11, 21, 18, 1, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492661627, 'issue_id': 2679665507, 'author': 'sydney-runkle', 'body': 'Just released v2.10.1 with fixes for the issues you folks reported :)', 'created_at': datetime.datetime(2024, 11, 22, 1, 3, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493355454, 'issue_id': 2679665507, 'author': 'potiuk', 'body': '> What\'s probably best is to make sure you\'re using the old syntax for every class that is going to be used in the context of a Pydantic model.\r\n\r\nAs discussed in https://github.com/pydantic/pydantic/issues/10924#issuecomment-2493313194 - I think this change is breaking far too much of an existing code base and you are facing the reality that this will cause even more people to limit their Pydantic version to < 2 (it looks like the `dbt` team asked `dbt-databricks` maintainer to do so). While we might likely implement some fix to that (maybe limiting Pydantic to <2.10) in Airflow 2.10.4, this is not a good solution because Pydantic is so popular and used in many, many dependencies, and it\'s simply not reasonable to expect that existing released code will be updated. It might help if new versions of software are updated but I have a feeling even recent version of released software will start failing with similar issues. So I would seriously reconsider that ""fix"" and revert it or workaround it in 2.10.2 (at least that\'s what I\'d do as a maintainer of such popular library).', 'created_at': datetime.datetime(2024, 11, 22, 9, 50, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493386351, 'issue_id': 2679665507, 'author': 'Viicos', 'body': '> I think this change is breaking far too much of an existing code base\r\n\r\nSince the release of 2.10, we only had one report (https://github.com/pydantic/pydantic/issues/10924) related to evaluation of forward annotations.\r\n\r\n> Pydantic is so popular and used in many, many dependencies\r\n\r\nWe are aware of that, it is, in some cases, extremely challenging for us to make changes/cleanups, especially because in the field of forward annotations evaluation.\r\n\r\nThe standard library utilities are far from perfect, so we had to implement our own logic to support edge cases that unfortunately led to a messy implementation, accepting invalid annotations to evaluate (this can be dangerous as names in forward annotations could resolve to the wrong type) [^1].\r\n\r\n> it\'s simply not reasonable to expect that existing released code will be updated\r\n\r\nHonestly, this requires a one line change on your end:\r\n\r\nhttps://github.com/apache/airflow/blob/f33166a612218a10cee0e42cde36bc43fc184222/airflow/utils/log/logging_mixin.py#L68-L78\r\n\r\nYour usage of type annotations is inconsistent here, as you are mixing the new union syntax with `Optional`. Note that if this class were to be defined in the same module as [`TaskInstancePydantic`](https://github.com/apache/airflow/blob/1307e37bc6338c43aa5099752d012e244f8494ba/airflow/serialization/pydantic/taskinstance.py#L84), the issue would have appeared already.\r\n\r\n> So I would seriously reconsider that ""fix"" and revert it or workaround it in 2.10.2\r\n\r\nThe ""fix"" is not actually a fix, but a complete refactor of our forward annotations evaluation. It\'s unfortunately not possible for us to ""revert"" it. The current implementation is vastly more accurate, and as I said above will avoid dangerous issues when forward annotations are silently _not_ resolved to the correct type. \r\n\r\nIf we do get more reports, depending on their validity, we will then consider tweaking the current logic. \r\n\r\n[^1]: Read more [here](https://docs.pydantic.dev/latest/internals/resolving_annotations/#the-challenges-of-runtime-evaluation).', 'created_at': datetime.datetime(2024, 11, 22, 10, 6, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493449727, 'issue_id': 2679665507, 'author': 'Viicos', 'body': ""For instance: https://github.com/langchain-ai/langchain-google/issues/610 is an example of a forward annotation evaluation that resolved to the wrong type in <2.10 (I'm in the process of writing up what's happening)."", 'created_at': datetime.datetime(2024, 11, 22, 10, 40, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493487589, 'issue_id': 2679665507, 'author': 'pierrejeambrun', 'body': ""> What's probably best is to make sure you're using the old syntax for every class that is going to be used in the context of a Pydantic model.\r\n\r\nIndeed this is not great. We have all the codebase updated to the new style type annotation. (`|`, `list`, etc...) and having to use the old one everywhere pydantic is involved is not great. (maybe I didn't understand correctly what you are suggesting).\r\n\r\n> but the union syntax is not supported on Python 3.9.\r\n\r\nWe use `from future import __annotation__` in conjunction with `eval-type-backport` and has been working nicely for us to solve pydantic new style annotation + forward evaluation in python 3.9. Is that expected or will we still face an issue with the new release ?"", 'created_at': datetime.datetime(2024, 11, 22, 11, 1, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493571703, 'issue_id': 2679665507, 'author': 'potiuk', 'body': '> If we do get more reports, depending on their validity, we will then consider tweaking the current logic.\r\n\r\nSure. It is indeed up to you. We are pretty well protected - we have ""constraint mechanism"" and we can restric airlfow 2.10.4 - and we are rather happy to adjust future versions of airflow, I was just merely suggesting that this change might have more consequences for you - so It was more of a friendly advice than complaint.\r\n\r\nBut yes - I agree my assesment might be wrong.\r\n\r\n> Your usage of type annotations is inconsistent here, as you are mixing the new union syntax with Optional. Note that if this class were to be defined in the same module as [TaskInstancePydantic](https://github.com/apache/airflow/blob/1307e37bc6338c43aa5099752d012e244f8494ba/airflow/serialization/pydantic/taskinstance.py#L84), the issue would have appeared already.\r\n\r\nYes -  but to be perfectly honest it\'s because of Pydantic. We have a rule in our pre-commit that enforces using new style type annotations. Because of inability of pydantic to handle it, we specifically converted our Pydantic classes to not use `from future import __annotations__` and we even had to add exeption to our rule: \r\n\r\nhttps://github.com/apache/airflow/blob/main/pyproject.toml#L326\r\n\r\nSo our ""inconistent use"" is exclusively because of Pydantic. And our use is perfectly fine according to current state of type annotations - both style of annotations can be inter-mixed and `from __future__ import annoutattion` as defined in https://peps.python.org/pep-0563/ . And while I know there are a lot of controversies around that PEP and the way how it works will likely change in the future, this is the current state of affairs, and we are following the accepted PEPs (while Pydantic does not really handle them properly and we had to introduce inconsistency in order to workaround it).\r\n\r\nSo technically speaking it\'s because of Pydantic we are inconsistent. \r\n\r\nAnd I am not complaining and not trying to heat it up, I am just stating the fact - explaining that well, it\'s Pydantic who is the root cause of that inconsistency, not Airflow.\r\n\r\nSo really - @Viicos - please treat it as a friendly advice, that maybe it\'s a good idea to consider supporting that case. While we will handle it ourselves (luckily our constraint mechanism we introduce many years ago and educate our users to use them will prevent a lot of our users from being affected). It\'s really a maintainer-to-maintainer friendly suggestion that this might hit you back.', 'created_at': datetime.datetime(2024, 11, 22, 11, 47, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493889097, 'issue_id': 2679665507, 'author': 'Viicos', 'body': '> Indeed this is not great. We have all the codebase updated to the new style type annotation. (`|`, `list`, etc...) and having to use the old one everywhere pydantic is involved is not great. (maybe I didn\'t understand correctly what you are suggesting).\r\n\r\nYes sorry what I meant is precisely on the `LoggingMixin` class, where two annotations are using the old syntax, while the `_log` field is using the new one.\r\n\r\nBut as you mentioned, nothing related to this should be an issue if the `eval-type-backport` backport is used. What\'s interesting however, is that the [initial report](https://github.com/pydantic/pydantic/issues/10924) should not happen if the backport is indeed installed.\r\n\r\nTurns out, the backport was added in https://github.com/apache/airflow/commit/7d5f2bad082425d0457e3f94e6119f739f3e9892, and the user is still on `2.9.0`, released prior to the addition of the dependency. Sorry for the confusion.\r\n\r\n---\r\n\r\n> so It was more of a friendly advice than complaint.\r\n\r\nSorry if I did not understand it that way. I think we both know how annoying unexpected breaking changes can be. In this case, the intent was to fix actual invalid cases (such as [this one](https://github.com/langchain-ai/langchain-google/issues/610)) and I would find it very unfortunate to consider Pydantic in the same state as other well established libraries (e.g. `requests`) where no change is possible because of https://xkcd.com/1172/.\r\n\r\nRegarding the ""inconsistent use"" we are talking about, as I answered at the top of this comment, it was in fact due to the reporting user not using the latest airfow version which included the evaluation backport.\r\n\r\n> while Pydantic does not really handle them properly\r\n\r\nPydantic is not really to blame here. There are some PEP 563 use cases that are _theoretically impossible_ to support (e.g. referencing locals in a function) (and we had/will have to wait for PEP 649 to resolve most of these cases). And compared to the other dataclass-like libraries performing validation, I\'m not afraid to say Pydantic is by far the most accurate when it comes to handling forward annotations, including the `eval-type-backport` library (which solves most of the discussion here :smile:).\r\n\r\nThanks again, I\'ll close the original issue by suggesting upgrading to the latest airflow version. Please let us know if you encounter more issues with 2.10.1.', 'created_at': datetime.datetime(2024, 11, 22, 14, 27, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493893952, 'issue_id': 2679665507, 'author': 'Viicos', 'body': ""Sidenote:\r\n\r\nPrior to the final 2.10 release, I was looking at libraries making extensive use of Pydantic. I tested on some, but wasn't aware airflow was using it, along with `vertexai`/`langchain-google` etc. We will definitely try to test future beta releases on these ones."", 'created_at': datetime.datetime(2024, 11, 22, 14, 29, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494264226, 'issue_id': 2679665507, 'author': 'pierrejeambrun', 'body': ""> Prior to the final 2.10 release, I was looking at libraries making extensive use of Pydantic. I tested on some, but wasn't aware airflow was using it, along with vertexai/langchain-google etc. We will definitely try to test future beta releases on these ones.\r\n\r\nGreat to hear! Yes the usage in airflow started small but it's becoming more and more central in our datamodel.\r\n\r\n> But as you mentioned, nothing related to this should be an issue if the eval-type-backport backport is used. What's interesting however, is that the https://github.com/pydantic/pydantic/issues/10924 should not happen if the backport is indeed installed.\r\n\r\nThanks for the details 👍"", 'created_at': datetime.datetime(2024, 11, 22, 16, 53, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495077341, 'issue_id': 2679665507, 'author': 'potiuk', 'body': ""Yes. thanks for all details. Again, it was not blaming or complaint (and I know how difficult it is to pass emotions and intents via GitHub issues.\r\n\r\nAnd yes - i know, and quote https://xkcd.com/1172/ more often than not. Also what gets handy in such case is https://www.hyrumslaw.com/ (which BTW also has the reference to the XKCD in question) :) . \r\n\r\n\r\nNow all is clear. I've also learned about `eval-type-backport` now - it's been part of the much bigger https://github.com/apache/airflow/pull/42196/files#diff-d56d1b58c0ca28bdddd10c2cee2ab3cb4312766ea5de51f210dbc15a0fea42faR427 - and I even did not know that it existed.\r\n\r\nFYI @Viicos - that one was added only in main and is going to be added as a requirement in Airflow 3.0.  But as far as I understand, just installing it should generally solve the problem that the use had with databricks-dbt. So @pierrejeambrun -> maybe this is the right fix that we should add to 2.10.4 - simply add `eval-type-backport` to 2.10.4 to preven similar errors for users who install newer Pydantic versions ?"", 'created_at': datetime.datetime(2024, 11, 22, 23, 15, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495086593, 'issue_id': 2679665507, 'author': 'potiuk', 'body': ""@pierrejeambrun Created https://github.com/apache/airflow/pull/44294 -> I noticed that the `eval-type-backport` has been added for all python versions (and we really need it for < 3.10) - so I corrected it in #44294 - and we can backport it to 2.10.4 becuse #42196 was not cherry-pickable (learning for the future those kind of changes should be raher split from the main change - seems that eval-type-backport dependency deserved it's own PR."", 'created_at': datetime.datetime(2024, 11, 22, 23, 25, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495184341, 'issue_id': 2679665507, 'author': 'pierrejeambrun', 'body': 'Sounds great thanks Jarek. \r\n\r\nYes indeed when I first introduced it, I really didn’t know it would be all that important and have to be cherry picked.\r\n\r\nIt was really just to fix issues I was facing with initial development of the FastAPI API. Now looking back, indeed a PR of its own would have been nice 😄', 'created_at': datetime.datetime(2024, 11, 23, 1, 23, 27, tzinfo=datetime.timezone.utc)}]","sydney-runkle on (2024-11-21 14:36:08 UTC): We should have a patch release out this afternoon with a fix for the issues you're encountering :)

ashb on (2024-11-21 14:48:19 UTC): @sydney-runkle Do you plan on yanking the 2.10.0 release? (I don't mind either way, just need to know what we do)

If 2.10.0 gets yanked then we don't need to keep this/can revert it, otherwise we probably should keep the exclusion rule

sydney-runkle on (2024-11-21 16:35:36 UTC): We're not going to yank v2.10.0, will just release a v2.10.1 patch soon!

sydney-runkle on (2024-11-21 16:36:14 UTC): Perhaps you all could test against our `main` branch before we do our patch release to confirm that all is working as expected on your end?

potiuk on (2024-11-21 16:41:55 UTC): It would be easier if you have an rc or beta/alpha released in PyPI - because I am not sure if we can trigger the whole test suite against Github-installed version. Can it be done @sydney-runkle ?

sydney-runkle on (2024-11-21 16:47:50 UTC): You can try with `pydantic==git+https://github.com/pydantic/pydantic@main`

potiuk on (2024-11-21 16:52:01 UTC): It might be that we expect version in our CI for that, so I am not sure if it's going to work . I can try, but I have a feeling it will fail in one of the steps.

gopidesupavan (Issue Creator) on (2024-11-21 17:00:24 UTC): yeah i think it might fail at constraints ?

potiuk on (2024-11-21 17:00:33 UTC): Trying it here @sydney-runkle https://github.com/apache/airflow/pull/44260

potiuk on (2024-11-21 17:01:59 UTC): Yeah... some tests are already failing here as I suspected. But those are auxiliary ones, maybe the main part of the tests that actually failed before will be ok:

```
  Preparing metadata (pyproject.toml): finished with status 'done'
ERROR: Requested apache-airflow==3.0.0.dev0 from file:///home/runner/work/airflow/airflow has invalid metadata: Expected end or semicolon (after name and no valid version specifier)
    pydantic==git+https://github.com/pydantic/pydantic@main
```

Viicos on (2024-11-21 18:01:25 UTC): We're going to release 2.10.1 any minute now.

We got [a report](https://github.com/pydantic/pydantic/issues/10924) today of an issue happening on Python <3.10. The [`TaskInstancePydantic`](https://github.com/apache/airflow/blob/1307e37bc6338c43aa5099752d012e244f8494ba/airflow/serialization/pydantic/taskinstance.py#L84) class is subclassing [`LoggingMixin`](https://github.com/apache/airflow/blob/main/airflow/utils/log/logging_mixin.py#L68). This class has an annotation for `_log` using the new 3.10+ union syntax. While Pydantic has always evaluated _all_ type annotations of models including their bases, we were not using the correct globals and locals to so. Meaning with the following example:

*a.py*

```python
from logging import Logger

class Base:
    _log: 'Logger | None'
```

*b.py*

```python
from a import Base

from pydantic import BaseModel

class Model(BaseModel, Base):
    pass
```

Evalutating the annotation for `_log` would have resulted in a `NameError`, because `Logger` is imported in `a.py`, and we only used the globals of the `b.py` module until now. `NameError`'s are ignored to allow for types to be defined later on. However, on 2.10, this now raises a `TypeError` because `'Logger | None'` successfully evaluates (read: `Logger` can be resolved), but the union syntax is not supported on Python 3.9.

What's probably best is to make sure you're using the old syntax for every class that is going to be used in the context of a Pydantic model.

sydney-runkle on (2024-11-22 01:03:56 UTC): Just released v2.10.1 with fixes for the issues you folks reported :)

potiuk on (2024-11-22 09:50:18 UTC): As discussed in https://github.com/pydantic/pydantic/issues/10924#issuecomment-2493313194 - I think this change is breaking far too much of an existing code base and you are facing the reality that this will cause even more people to limit their Pydantic version to < 2 (it looks like the `dbt` team asked `dbt-databricks` maintainer to do so). While we might likely implement some fix to that (maybe limiting Pydantic to <2.10) in Airflow 2.10.4, this is not a good solution because Pydantic is so popular and used in many, many dependencies, and it's simply not reasonable to expect that existing released code will be updated. It might help if new versions of software are updated but I have a feeling even recent version of released software will start failing with similar issues. So I would seriously reconsider that ""fix"" and revert it or workaround it in 2.10.2 (at least that's what I'd do as a maintainer of such popular library).

Viicos on (2024-11-22 10:06:16 UTC): Since the release of 2.10, we only had one report (https://github.com/pydantic/pydantic/issues/10924) related to evaluation of forward annotations.


We are aware of that, it is, in some cases, extremely challenging for us to make changes/cleanups, especially because in the field of forward annotations evaluation.

The standard library utilities are far from perfect, so we had to implement our own logic to support edge cases that unfortunately led to a messy implementation, accepting invalid annotations to evaluate (this can be dangerous as names in forward annotations could resolve to the wrong type) [^1].


Honestly, this requires a one line change on your end:

https://github.com/apache/airflow/blob/f33166a612218a10cee0e42cde36bc43fc184222/airflow/utils/log/logging_mixin.py#L68-L78

Your usage of type annotations is inconsistent here, as you are mixing the new union syntax with `Optional`. Note that if this class were to be defined in the same module as [`TaskInstancePydantic`](https://github.com/apache/airflow/blob/1307e37bc6338c43aa5099752d012e244f8494ba/airflow/serialization/pydantic/taskinstance.py#L84), the issue would have appeared already.


The ""fix"" is not actually a fix, but a complete refactor of our forward annotations evaluation. It's unfortunately not possible for us to ""revert"" it. The current implementation is vastly more accurate, and as I said above will avoid dangerous issues when forward annotations are silently _not_ resolved to the correct type. 

If we do get more reports, depending on their validity, we will then consider tweaking the current logic. 

[^1]: Read more [here](https://docs.pydantic.dev/latest/internals/resolving_annotations/#the-challenges-of-runtime-evaluation).

Viicos on (2024-11-22 10:40:36 UTC): For instance: https://github.com/langchain-ai/langchain-google/issues/610 is an example of a forward annotation evaluation that resolved to the wrong type in <2.10 (I'm in the process of writing up what's happening).

pierrejeambrun on (2024-11-22 11:01:49 UTC): Indeed this is not great. We have all the codebase updated to the new style type annotation. (`|`, `list`, etc...) and having to use the old one everywhere pydantic is involved is not great. (maybe I didn't understand correctly what you are suggesting).


We use `from future import __annotation__` in conjunction with `eval-type-backport` and has been working nicely for us to solve pydantic new style annotation + forward evaluation in python 3.9. Is that expected or will we still face an issue with the new release ?

potiuk on (2024-11-22 11:47:09 UTC): Sure. It is indeed up to you. We are pretty well protected - we have ""constraint mechanism"" and we can restric airlfow 2.10.4 - and we are rather happy to adjust future versions of airflow, I was just merely suggesting that this change might have more consequences for you - so It was more of a friendly advice than complaint.

But yes - I agree my assesment might be wrong.


Yes -  but to be perfectly honest it's because of Pydantic. We have a rule in our pre-commit that enforces using new style type annotations. Because of inability of pydantic to handle it, we specifically converted our Pydantic classes to not use `from future import __annotations__` and we even had to add exeption to our rule: 

https://github.com/apache/airflow/blob/main/pyproject.toml#L326

So our ""inconistent use"" is exclusively because of Pydantic. And our use is perfectly fine according to current state of type annotations - both style of annotations can be inter-mixed and `from __future__ import annoutattion` as defined in https://peps.python.org/pep-0563/ . And while I know there are a lot of controversies around that PEP and the way how it works will likely change in the future, this is the current state of affairs, and we are following the accepted PEPs (while Pydantic does not really handle them properly and we had to introduce inconsistency in order to workaround it).

So technically speaking it's because of Pydantic we are inconsistent. 

And I am not complaining and not trying to heat it up, I am just stating the fact - explaining that well, it's Pydantic who is the root cause of that inconsistency, not Airflow.

So really - @Viicos - please treat it as a friendly advice, that maybe it's a good idea to consider supporting that case. While we will handle it ourselves (luckily our constraint mechanism we introduce many years ago and educate our users to use them will prevent a lot of our users from being affected). It's really a maintainer-to-maintainer friendly suggestion that this might hit you back.

Viicos on (2024-11-22 14:27:34 UTC): Yes sorry what I meant is precisely on the `LoggingMixin` class, where two annotations are using the old syntax, while the `_log` field is using the new one.

But as you mentioned, nothing related to this should be an issue if the `eval-type-backport` backport is used. What's interesting however, is that the [initial report](https://github.com/pydantic/pydantic/issues/10924) should not happen if the backport is indeed installed.

Turns out, the backport was added in https://github.com/apache/airflow/commit/7d5f2bad082425d0457e3f94e6119f739f3e9892, and the user is still on `2.9.0`, released prior to the addition of the dependency. Sorry for the confusion.

---


Sorry if I did not understand it that way. I think we both know how annoying unexpected breaking changes can be. In this case, the intent was to fix actual invalid cases (such as [this one](https://github.com/langchain-ai/langchain-google/issues/610)) and I would find it very unfortunate to consider Pydantic in the same state as other well established libraries (e.g. `requests`) where no change is possible because of https://xkcd.com/1172/.

Regarding the ""inconsistent use"" we are talking about, as I answered at the top of this comment, it was in fact due to the reporting user not using the latest airfow version which included the evaluation backport.


Pydantic is not really to blame here. There are some PEP 563 use cases that are _theoretically impossible_ to support (e.g. referencing locals in a function) (and we had/will have to wait for PEP 649 to resolve most of these cases). And compared to the other dataclass-like libraries performing validation, I'm not afraid to say Pydantic is by far the most accurate when it comes to handling forward annotations, including the `eval-type-backport` library (which solves most of the discussion here :smile:).

Thanks again, I'll close the original issue by suggesting upgrading to the latest airflow version. Please let us know if you encounter more issues with 2.10.1.

Viicos on (2024-11-22 14:29:58 UTC): Sidenote:

Prior to the final 2.10 release, I was looking at libraries making extensive use of Pydantic. I tested on some, but wasn't aware airflow was using it, along with `vertexai`/`langchain-google` etc. We will definitely try to test future beta releases on these ones.

pierrejeambrun on (2024-11-22 16:53:04 UTC): Great to hear! Yes the usage in airflow started small but it's becoming more and more central in our datamodel.


Thanks for the details 👍

potiuk on (2024-11-22 23:15:41 UTC): Yes. thanks for all details. Again, it was not blaming or complaint (and I know how difficult it is to pass emotions and intents via GitHub issues.

And yes - i know, and quote https://xkcd.com/1172/ more often than not. Also what gets handy in such case is https://www.hyrumslaw.com/ (which BTW also has the reference to the XKCD in question) :) . 


Now all is clear. I've also learned about `eval-type-backport` now - it's been part of the much bigger https://github.com/apache/airflow/pull/42196/files#diff-d56d1b58c0ca28bdddd10c2cee2ab3cb4312766ea5de51f210dbc15a0fea42faR427 - and I even did not know that it existed.

FYI @Viicos - that one was added only in main and is going to be added as a requirement in Airflow 3.0.  But as far as I understand, just installing it should generally solve the problem that the use had with databricks-dbt. So @pierrejeambrun -> maybe this is the right fix that we should add to 2.10.4 - simply add `eval-type-backport` to 2.10.4 to preven similar errors for users who install newer Pydantic versions ?

potiuk on (2024-11-22 23:25:14 UTC): @pierrejeambrun Created https://github.com/apache/airflow/pull/44294 -> I noticed that the `eval-type-backport` has been added for all python versions (and we really need it for < 3.10) - so I corrected it in #44294 - and we can backport it to 2.10.4 becuse #42196 was not cherry-pickable (learning for the future those kind of changes should be raher split from the main change - seems that eval-type-backport dependency deserved it's own PR.

pierrejeambrun on (2024-11-23 01:23:27 UTC): Sounds great thanks Jarek. 

Yes indeed when I first introduced it, I really didn’t know it would be all that important and have to be cherry picked.

It was really just to fix issues I was facing with initial development of the FastAPI API. Now looking back, indeed a PR of its own would have been nice 😄

"
2679471224,pull_request,closed,,Add OpenLineage method in BigQueryToBigQueryOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Add OpenLineage method (get_openlineage_facets_on_complete) in BigQueryToBigQueryOperator. 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",spapi17,2024-11-21 13:23:48+00:00,[],2024-11-26 14:47:40+00:00,2024-11-26 14:47:40+00:00,https://github.com/apache/airflow/pull/44248,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2491140383, 'issue_id': 2679471224, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 21, 13, 23, 53, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-21 13:23:53 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2679437362,pull_request,closed,,Also allow passing buffer instead of path for retrieve_file and store_file methods in SFTPHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In the FTPSHook it's also possible to pass a buffer (like StringIO/BytesIO) instead of a path, I've refactored the retrieve_file and store_file methods in SFTPHook so those also support those types.  This avoids the need to create a file to be able to download a file to FTP, you can directly download it into a buffer and vice versa if you need to upload content to an FTP server you don't need to create a file locally to be able to upload it.  I just delegate this to the underlying paramiko getfo and putfo methods, nothing fancy had to be done to achieve this as the paramiko library already supported this.  This shortcoming was described as a pitfall for the SFTPHook.

Also using our in-house StreamOperator which allows executing an operator in a multi-threaded way within the same worker (similar to expand but then distributing the work over multiple threads within the same worker instead of multiple workers), we discovered that when using the SFTPHook in a PythonOperator to retrieve a file, the connections don't get closed, which seems probable as each thread has to instantiate a new SFTPHook as the underlying library paramiko isn't thread-safe.  When you look at the source code you'll notice that each operation within the SFTPHook get's a connection but actually never closes it as you have to call the close_conn method manually.

```
    def retrieve_file(self, remote_full_path: str, local_full_path: str, prefetch: bool = True) -> None:
        """"""
        Transfer the remote file to a local location.

        If local_full_path is a string path, the file will be put
        at that location.

        :param remote_full_path: full path to the remote file
        :param local_full_path: full path to the local file or a file-like buffer
        :param prefetch: controls whether prefetch is performed (default: True)
        """"""
        conn = self.get_conn()
        if isinstance(local_full_path, BytesIO):
            conn.getfo(remote_full_path, local_full_path, prefetch=prefetch)
        else:
            conn.get(remote_full_path, local_full_path, prefetch=prefetch)
```

In the past we didn't use the SFTPHook but used directly the paramiko library like this and didn't have any issues:

```
    def get_file(remote_full_path: str) -> str:
        buffer = BytesIO()
        conn = get_connection(conn_id=sftp_conn)
        with Transport((conn.host, conn.port)) as transport:
            transport.connect(username=conn.login, password=conn.password)
            with SFTPClient.from_transport(transport) as sftp:
                sftp.retrieve_file(remote_full_path, buffer)  # Download file to buffer
        return buffer.getvalue().decode(""utf-8"")
```

So I think we should refactor the SFTP hook so it always release the sftp connection after each operator to avoid connection leaks:

```
    def retrieve_file(self, remote_full_path: str, local_full_path: str, prefetch: bool = True) -> None:
        """"""
        Transfer the remote file to a local location.

        If local_full_path is a string path, the file will be put
        at that location.

        :param remote_full_path: full path to the remote file
        :param local_full_path: full path to the local file or a file-like buffer
        :param prefetch: controls whether prefetch is performed (default: True)
        """"""
        with self.get_sftp_conn() as conn:
            if isinstance(local_full_path, BytesIO):
                conn.getfo(remote_full_path, local_full_path, prefetch=prefetch)
            else:
                conn.get(remote_full_path, local_full_path, prefetch=prefetch)
```

Otherwise we would need to call it like this, in the above you don't need to worry about the connection:

```
    def retrieve_file(self, remote_full_path: str, local_full_path: str, prefetch: bool = True) -> None:
        """"""
        Transfer the remote file to a local location.

        If local_full_path is a string path, the file will be put
        at that location.

        :param remote_full_path: full path to the remote file
        :param local_full_path: full path to the local file or a file-like buffer
        :param prefetch: controls whether prefetch is performed (default: True)
        """"""
        try:
            conn = self.get_sftp_conn():
            if isinstance(local_full_path, BytesIO):
                conn.getfo(remote_full_path, local_full_path, prefetch=prefetch)
            else:
                conn.get(remote_full_path, local_full_path, prefetch=prefetch)```
        finally:
            conn.close()
```

I've added a test case for both changes.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-21 13:18:56+00:00,[],2025-02-05 19:45:04+00:00,2025-02-05 19:45:04+00:00,https://github.com/apache/airflow/pull/44247,"[('area:providers', ''), ('provider:sftp', '')]","[{'comment_id': 2636391816, 'issue_id': 2679437362, 'author': 'eladkal', 'body': ""Tests fail\r\n\r\n```\r\n=========================== short test summary info ============================\r\nFAILED providers/sftp/tests/provider_tests/sftp/hooks/test_sftp.py::TestSFTPHook::test_sftp_hook_with_proxy_command - AssertionError: Expected 'ProxyCommand' to be called once. Called 0 times.\r\n```"", 'created_at': datetime.datetime(2025, 2, 5, 10, 52, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2636552741, 'issue_id': 2679437362, 'author': 'dabla', 'body': ""> Tests fail\r\n> \r\n> ```\r\n> =========================== short test summary info ============================\r\n> FAILED providers/sftp/tests/provider_tests/sftp/hooks/test_sftp.py::TestSFTPHook::test_sftp_hook_with_proxy_command - AssertionError: Expected 'ProxyCommand' to be called once. Called 0 times.\r\n> ```\r\n\r\nfixed"", 'created_at': datetime.datetime(2025, 2, 5, 12, 8, 32, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-02-05 10:52:18 UTC): Tests fail

```
=========================== short test summary info ============================
FAILED providers/sftp/tests/provider_tests/sftp/hooks/test_sftp.py::TestSFTPHook::test_sftp_hook_with_proxy_command - AssertionError: Expected 'ProxyCommand' to be called once. Called 0 times.
```

dabla (Issue Creator) on (2025-02-05 12:08:32 UTC): fixed

"
2679386067,pull_request,closed,,Migrate public endpoint Set Task Instances State to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/43752
related: https://github.com/apache/airflow/issues/42370

This migrates the Set Task Instances State API from `api_connexion` to `api_fastapi`.",omkar-foss,2024-11-21 13:07:47+00:00,['omkar-foss'],2024-11-21 22:22:00+00:00,2024-11-21 22:04:15+00:00,https://github.com/apache/airflow/pull/44246,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2491967937, 'issue_id': 2679386067, 'author': 'bbovenzi', 'body': 'I think we should only merge one of this and https://github.com/apache/airflow/pull/44223 and include setting a note and all the `include_*` filters to update other task instance states at the same time.', 'created_at': datetime.datetime(2024, 11, 21, 18, 25, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492434085, 'issue_id': 2679386067, 'author': 'omkar-foss', 'body': 'Closed this PR as this functionality is handled by Patch Task Instance API in https://github.com/apache/airflow/pull/44223 using `update_mask = [""new_state""]`.', 'created_at': datetime.datetime(2024, 11, 21, 22, 6, 20, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-11-21 18:25:06 UTC): I think we should only merge one of this and https://github.com/apache/airflow/pull/44223 and include setting a note and all the `include_*` filters to update other task instance states at the same time.

omkar-foss (Issue Creator) on (2024-11-21 22:06:20 UTC): Closed this PR as this functionality is handled by Patch Task Instance API in https://github.com/apache/airflow/pull/44223 using `update_mask = [""new_state""]`.

"
