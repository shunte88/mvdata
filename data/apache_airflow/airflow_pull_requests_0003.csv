id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2765728706,pull_request,closed,,AIP-72: Gracefully handle 'not-found' XCOMs in task sdk API client,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45341 

### Testing results
DAG used:
```
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator

def push_to_xcom(**kwargs):
    value = ""Hello, XCom!""
    return value


def pull_from_xcom(**kwargs):
    ti = kwargs['ti']
    xcom_value = ti.xcom_pull(task_ids='invalid_id')
    print(f""Retrieved XCom Value: {xcom_value}"")


with DAG(
    'xcom_example',
    schedule=None,
    catchup=False,
) as dag:

    push_xcom_task = PythonOperator(
        task_id='push_xcom_task',
        python_callable=push_to_xcom,
    )

    pull_xcom_task = PythonOperator(
        task_id='pull_xcom_task',
        python_callable=pull_from_xcom,
    )

    push_xcom_task >> pull_xcom_task
```

#### Legacy
Task 1 XCom pushed:
<img width=""1727"" alt=""image"" src=""https://github.com/user-attachments/assets/b4ab2d7a-72e4-4e13-ba0d-2b3faa7aee7f"" />

Task 2 XCom consumed as None when absent:
<img width=""1727"" alt=""image"" src=""https://github.com/user-attachments/assets/461744d5-6c77-4630-b98f-87d7d0942b67"" />



#### Task SDK
Task 1 XCom pushed:
<img width=""1727"" alt=""image"" src=""https://github.com/user-attachments/assets/c3967e43-8c56-4779-ab00-c724c2d18ab3"" />

Task 2 XCom consumed as None when absent:
<img width=""1727"" alt=""image"" src=""https://github.com/user-attachments/assets/1a3c30ca-e0e8-47d4-a555-c4311b4ca094"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-02 09:49:52+00:00,[],2025-01-03 09:11:46+00:00,2025-01-03 09:11:44+00:00,https://github.com/apache/airflow/pull/45344,"[('area:task-sdk', None)]","[{'comment_id': 2567694580, 'issue_id': 2765728706, 'author': 'potiuk', 'body': '@amoghrajesh - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.', 'created_at': datetime.datetime(2025, 1, 2, 12, 21, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567697724, 'issue_id': 2765728706, 'author': 'amoghrajesh', 'body': '> @amoghrajesh - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in #45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.\r\n\r\nOh ok, let me rebase this one', 'created_at': datetime.datetime(2025, 1, 2, 12, 24, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568675277, 'issue_id': 2765728706, 'author': 'amoghrajesh', 'body': 'Hi @uranusjr are you ok with the reply on this comment? https://github.com/apache/airflow/pull/45344#discussion_r1900781515', 'created_at': datetime.datetime(2025, 1, 3, 4, 20, 2, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:21:50 UTC): @amoghrajesh - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.

amoghrajesh (Issue Creator) on (2025-01-02 12:24:23 UTC): Oh ok, let me rebase this one

amoghrajesh (Issue Creator) on (2025-01-03 04:20:02 UTC): Hi @uranusjr are you ok with the reply on this comment? https://github.com/apache/airflow/pull/45344#discussion_r1900781515

"
2765718786,pull_request,closed,,change doc for reinitFrequency in chart,"according to [this](https://github.com/apache/airflow/blob/main/airflow/security/kerberos.py#L78) code line where this parameter send to kerberos cli we add `m` after it means consider it as minutes.



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2025-01-02 09:42:53+00:00,[],2025-01-03 02:22:01+00:00,2025-01-03 02:22:00+00:00,https://github.com/apache/airflow/pull/45343,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2567698472, 'issue_id': 2765718786, 'author': 'potiuk', 'body': '@romsharon98  - I rebased this one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 25, 8, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:25:08 UTC): @romsharon98  - I rebased this one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

"
2765490110,pull_request,closed,,Cleanup some useless mocks/fixture in manager tests,"This fixture was, in theory, able to reproduce the bug fixed in #30243, but I was unable to now. So, let's toss it.

cc @uranusjr @blinkseb, not sure if either of you might know why?",jedcunningham,2025-01-02 06:05:55+00:00,[],2025-01-07 15:18:01+00:00,2025-01-07 15:17:55+00:00,https://github.com/apache/airflow/pull/45340,[],"[{'comment_id': 2567338066, 'issue_id': 2765490110, 'author': 'uranusjr', 'body': 'I donâ€™t remember the details, but from the things mocked, it looks like we changed when we filter files/folders from a scan to check whether a file actually contains a DAG later in the manager, making the mocks now useless (because they are no longer called at this part of the code). All of the mocks simply forces the manager to treat a Python file as one containing a DAG and not drop it prematurely.', 'created_at': datetime.datetime(2025, 1, 2, 6, 40, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567702515, 'issue_id': 2765490110, 'author': 'potiuk', 'body': '@jedcunningham  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.', 'created_at': datetime.datetime(2025, 1, 2, 12, 28, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567869736, 'issue_id': 2765490110, 'author': 'jedcunningham', 'body': ""@uranusjr, sorry, to clarify I meant the `change_platform_timezone` fixture - removing the code fix from #30243 didn't cause the tests to fail for me."", 'created_at': datetime.datetime(2025, 1, 2, 14, 35, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568112440, 'issue_id': 2765490110, 'author': 'jedcunningham', 'body': 'Messed with this a bit more, still not able to get the tests to fail. I say we go ahead with removing it.', 'created_at': datetime.datetime(2025, 1, 2, 17, 20, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568471391, 'issue_id': 2765490110, 'author': 'blinkseb', 'body': ""Hi! I don't remember the full details, but as mentioned in #30243, it's normal that the tests don't fail when removing the fixture since the bug was fixed. The fixture was there to ensure there would be no regression (past or future) by assuming that the system timezone is not the same as the configured user timezone."", 'created_at': datetime.datetime(2025, 1, 2, 22, 42, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568733015, 'issue_id': 2765490110, 'author': 'jedcunningham', 'body': ""I left the fixture, I undid the bugfix. I also verified the timestamp didn't match the UTC timestamp, but still the tests are passing. Something else must have changed since that PR landed, but unfortunately that fixture doesn't seem to be preventing a regression any longer."", 'created_at': datetime.datetime(2025, 1, 3, 6, 6, 4, tzinfo=datetime.timezone.utc)}]","uranusjr on (2025-01-02 06:40:10 UTC): I donâ€™t remember the details, but from the things mocked, it looks like we changed when we filter files/folders from a scan to check whether a file actually contains a DAG later in the manager, making the mocks now useless (because they are no longer called at this part of the code). All of the mocks simply forces the manager to treat a Python file as one containing a DAG and not drop it prematurely.

potiuk on (2025-01-02 12:28:34 UTC): @jedcunningham  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.

jedcunningham (Issue Creator) on (2025-01-02 14:35:41 UTC): @uranusjr, sorry, to clarify I meant the `change_platform_timezone` fixture - removing the code fix from #30243 didn't cause the tests to fail for me.

jedcunningham (Issue Creator) on (2025-01-02 17:20:49 UTC): Messed with this a bit more, still not able to get the tests to fail. I say we go ahead with removing it.

blinkseb on (2025-01-02 22:42:57 UTC): Hi! I don't remember the full details, but as mentioned in #30243, it's normal that the tests don't fail when removing the fixture since the bug was fixed. The fixture was there to ensure there would be no regression (past or future) by assuming that the system timezone is not the same as the configured user timezone.

jedcunningham (Issue Creator) on (2025-01-03 06:06:04 UTC): I left the fixture, I undid the bugfix. I also verified the timestamp didn't match the UTC timestamp, but still the tests are passing. Something else must have changed since that PR landed, but unfortunately that fixture doesn't seem to be preventing a regression any longer.

"
2765440290,pull_request,closed,,Add a couple DAG bundle related helpers,"This is broken out of the larger changes adding DAG bundle parsing, to make reviewing that (eventual) PR a bit easier.",jedcunningham,2025-01-02 04:49:29+00:00,[],2025-01-15 03:33:34+00:00,2025-01-15 02:58:03+00:00,https://github.com/apache/airflow/pull/45339,"[('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2567703026, 'issue_id': 2765440290, 'author': 'potiuk', 'body': '@jedcunningham  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.', 'created_at': datetime.datetime(2025, 1, 2, 12, 29, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:29:00 UTC): @jedcunningham  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.

"
2765436110,pull_request,closed,,Unifying the action name within quotes,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-02 04:41:31+00:00,[],2025-01-02 09:49:00+00:00,2025-01-02 07:47:27+00:00,https://github.com/apache/airflow/pull/45338,"[('area:dev-tools', '')]",[],
2765427922,pull_request,closed,,Temporarily remove support for `dags reserialize` command,"As we work toward getting bundle parsing support in main (#42289), it'll be easier for reviewers to review the new `dags reserialize` command separate from the rest of the parsing changes (that PR will be rather large already). But in the meantime, simply using DagBag on a single directory won't continue working.

Tracking issue to add it back: #45336",jedcunningham,2025-01-02 04:25:30+00:00,[],2025-01-02 10:03:34+00:00,2025-01-02 10:03:34+00:00,https://github.com/apache/airflow/pull/45337,"[('area:CLI', ''), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2765360559,pull_request,closed,,Cleanup some (old) tasks UI tests,"These tests don't need to use a dedicated DAG, plus this is the only use of DAGs from the tests dag dir, which means we can later switch to only parsing the example DAGs.

This also removes a couple leftover DAG code related tests that aren't needed anymore - all DAG code comes from the db, and we parse/store example DAGs all over the place, so no extra value with these tests.

Why am I touching old UI stuff? My parsing changes for DAG bundles breaks a bunch of these tests, and we aren't quite ready to remove the old UI...
",jedcunningham,2025-01-02 02:01:33+00:00,[],2025-01-02 14:21:49+00:00,2025-01-02 10:06:57+00:00,https://github.com/apache/airflow/pull/45335,"[('area:webserver', 'Webserver related Issues'), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2567776464, 'issue_id': 2765360559, 'author': 'potiuk', 'body': 'Hey @jedcunningham -> the bug in main image upload (fixed by #45347) masked test failures in that one  - I just reverted it, so you will have to re-do it', 'created_at': datetime.datetime(2025, 1, 2, 13, 28, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567849841, 'issue_id': 2765360559, 'author': 'jedcunningham', 'body': 'Hmm, not sure those failures are related? Or am I looking in the wrong spot?\r\n\r\nhttps://github.com/apache/airflow/actions/runs/12579028168/job/35066133378', 'created_at': datetime.datetime(2025, 1, 2, 14, 21, 47, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 13:28:24 UTC): Hey @jedcunningham -> the bug in main image upload (fixed by #45347) masked test failures in that one  - I just reverted it, so you will have to re-do it

jedcunningham (Issue Creator) on (2025-01-02 14:21:47 UTC): Hmm, not sure those failures are related? Or am I looking in the wrong spot?

https://github.com/apache/airflow/actions/runs/12579028168/job/35066133378

"
2765345348,pull_request,open,,Fix databricks job link,"# Fix Databricks Extra Link to See Job Run with Custom S3 Backend

## Problem Addressed
Closes: #45240 
This PR addresses the issue described in [#45240](https://github.com/apache/airflow/issues/45240), where the Databricks Extra Link for ""See Job Run"" does not work when using a custom XCom backend that writes to S3. Specifically:

- The link directs to the S3 path of the XCom JSON file instead of the Databricks workspace job run URL.
- This behavior makes the feature unusable in setups with custom XCom backends, such as those storing XCom values entirely in S3.

## Proposed Changes

- Refactored the `DatabricksJobRunLink` implementation to reliably fetch the Databricks job run URL from XCom using `XCom.get_value`.
- Ensured compatibility with custom XCom backends, decoupling the link generation logic from specific backend implementations.
- Improved error handling to ensure the system fails gracefully if the required XCom value is missing or malformed.
- Enhanced maintainability with detailed comments and a cleaner structure.

## Key Benefits

- Resolves the issue of broken links when using custom XCom backends.
- Ensures compatibility across a wide range of backend configurations, including setups where all XCom values are stored in S3.
- Improves user experience by providing accurate links to Databricks job run details.

## Testing

- Validated the new implementation using a local Airflow environment with a custom XCom backend.
- Confirmed that the generated links now correctly point to Databricks job run URLs, regardless of the XCom storage location.

## Issue Link

Closes [#45240](https://github.com/apache/airflow/issues/45240).

## Checklist

- [x] All unit tests pass.
- [x] Code is formatted according to Airflowâ€™s standards.
- [x] Changes are backward compatible and do not break existing functionality.
- [x] adding unit test 

## Code of Conduct

I agree to follow this project's Code of Conduct.",mohamedmeqlad99,2025-01-02 01:18:01+00:00,[],2025-01-02 15:07:01+00:00,,https://github.com/apache/airflow/pull/45334,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2567707922, 'issue_id': 2765345348, 'author': 'potiuk', 'body': 'I rebased it @mohamedmeqlad99  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 33, 14, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:33:14 UTC): I rebased it @mohamedmeqlad99  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

"
2765308766,pull_request,closed,,Updated year in NOTICE,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",esivakumar26,2025-01-01 23:30:23+00:00,[],2025-01-02 10:03:56+00:00,2025-01-02 10:03:56+00:00,https://github.com/apache/airflow/pull/45333,[],[],
2765260884,pull_request,closed,,update outdated hyperlinks referencing provider package files,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

Seems like provider packages directory structure was updated recently. 
This PR updates all the references to files in the folder.

hyperlinks updated - 
https://github.com/search?q=repo%3Aapache%2Fairflow%20github.com%2Fapache%2Fairflow%2Fblob%2Fmain%2Fairflow%2Fproviders&type=code



**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rahul-madaan,2025-01-01 21:10:09+00:00,[],2025-01-01 23:25:54+00:00,2025-01-01 23:25:54+00:00,https://github.com/apache/airflow/pull/45332,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:openlineage', 'AIP-53'), ('provider:apache-beam', '')]",[],
2765161801,pull_request,closed,,Fix manual refresh images script,"The script can be used to manually refresh ARM images until we complete ARC migration. For now what is important is the refresh of the CI image not PROD image - and that works after small adjustment. For now we are commenting out the PROD part - as this is not necessarily needed and it need a bit more adjustment and thinking how to do it properly after separation of task_sdk so we comment it for now.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-01 16:48:17+00:00,[],2025-01-01 18:52:32+00:00,2025-01-01 18:52:32+00:00,https://github.com/apache/airflow/pull/45331,"[('area:dev-tools', '')]",[],
2765158963,pull_request,closed,,Fix Variable Page header on scroll,"https://github.com/user-attachments/assets/9b33b7b1-82f4-4562-8b5e-24fd49097102


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-01 16:41:20+00:00,[],2025-01-01 17:24:25+00:00,2025-01-01 17:04:21+00:00,https://github.com/apache/airflow/pull/45330,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2567080086, 'issue_id': 2765158963, 'author': 'potiuk', 'body': 'Not that I am sure what it does - but it looks good :)', 'created_at': datetime.datetime(2025, 1, 1, 17, 4, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567080935, 'issue_id': 2765158963, 'author': 'shubhamraj-git', 'body': '@potiuk  So, basically before the fix, The search bar, add and import button were not fix and that gets disappeared when table is scrolled. This fix it by setting overflow.', 'created_at': datetime.datetime(2025, 1, 1, 17, 7, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567085844, 'issue_id': 2765158963, 'author': 'potiuk', 'body': '> @potiuk So, basically before the fix, The search bar, add and import button were not fix and that gets disappeared when table is scrolled. This fix it by setting overflow.\r\n\r\nYep. Got it :)', 'created_at': datetime.datetime(2025, 1, 1, 17, 24, 24, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-01 17:04:17 UTC): Not that I am sure what it does - but it looks good :)

shubhamraj-git (Issue Creator) on (2025-01-01 17:07:06 UTC): @potiuk  So, basically before the fix, The search bar, add and import button were not fix and that gets disappeared when table is scrolled. This fix it by setting overflow.

potiuk on (2025-01-01 17:24:24 UTC): Yep. Got it :)

"
2765133444,pull_request,closed,,fix(databricks): update DatabricksJobRunLink for improved XCom handlin,"# Fix Databricks Extra Link to See Job Run with Custom S3 Backend

## Problem Addressed

This PR addresses the issue described in [#45240](https://github.com/apache/airflow/issues/45240), where the Databricks Extra Link for ""See Job Run"" does not work when using a custom XCom backend that writes to S3. Specifically:

- The link directs to the S3 path of the XCom JSON file instead of the Databricks workspace job run URL.
- This behavior makes the feature unusable in setups with custom XCom backends, such as those storing XCom values entirely in S3.

## Proposed Changes

- Refactored the `DatabricksJobRunLink` implementation to reliably fetch the Databricks job run URL from XCom using `XCom.get_value`.
- Ensured compatibility with custom XCom backends, decoupling the link generation logic from specific backend implementations.
- Improved error handling to ensure the system fails gracefully if the required XCom value is missing or malformed.
- Enhanced maintainability with detailed comments and a cleaner structure.

## Key Benefits

- Resolves the issue of broken links when using custom XCom backends.
- Ensures compatibility across a wide range of backend configurations, including setups where all XCom values are stored in S3.
- Improves user experience by providing accurate links to Databricks job run details.

## Testing

- Validated the new implementation using a local Airflow environment with a custom XCom backend.
- Confirmed that the generated links now correctly point to Databricks job run URLs, regardless of the XCom storage location.

## Issue Link

Closes [#45240](https://github.com/apache/airflow/issues/45240).

## Checklist

- [x] All unit tests pass.
- [x] Code is formatted according to Airflowâ€™s standards.
- [x] Changes are backward compatible and do not break existing functionality.

## Code of Conduct

I agree to follow this project's Code of Conduct.
",mohamedmeqlad99,2025-01-01 15:41:40+00:00,[],2025-01-02 01:14:14+00:00,2025-01-02 01:14:14+00:00,https://github.com/apache/airflow/pull/45328,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2567054839, 'issue_id': 2765133444, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 1, 15, 41, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567060213, 'issue_id': 2765133444, 'author': 'potiuk', 'body': 'You need to add unit tests exhibiting and testing the new behaviour', 'created_at': datetime.datetime(2025, 1, 1, 15, 58, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567069169, 'issue_id': 2765133444, 'author': 'mohamedmeqlad99', 'body': ""@potiuk i don't understand can u explain more how can I do this and what I need to edit"", 'created_at': datetime.datetime(2025, 1, 1, 16, 25, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567079679, 'issue_id': 2765133444, 'author': 'potiuk', 'body': 'Add unit tests: Look at our [Contributing docs](https://github.com/apache/airflow/blob/main/contributing-docs/README.rst) - particularly [testing](https://github.com/apache/airflow/blob/main/contributing-docs/09_testing.rst) - you can also look at other PRs for reference. We practically never accept PRs that have no accompanying unit tests and you need to learn how to write and run them if you want to contribute. \r\n\r\nOur contribution guides have quick-starts for various IDEs and when you follow them you can have working development environment where you can run unit tests in less than 10 minutes.', 'created_at': datetime.datetime(2025, 1, 1, 17, 2, 49, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-01 15:41:44 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2025-01-01 15:58:25 UTC): You need to add unit tests exhibiting and testing the new behaviour

mohamedmeqlad99 (Issue Creator) on (2025-01-01 16:25:21 UTC): @potiuk i don't understand can u explain more how can I do this and what I need to edit

potiuk on (2025-01-01 17:02:49 UTC): Add unit tests: Look at our [Contributing docs](https://github.com/apache/airflow/blob/main/contributing-docs/README.rst) - particularly [testing](https://github.com/apache/airflow/blob/main/contributing-docs/09_testing.rst) - you can also look at other PRs for reference. We practically never accept PRs that have no accompanying unit tests and you need to learn how to write and run them if you want to contribute. 

Our contribution guides have quick-starts for various IDEs and when you follow them you can have working development environment where you can run unit tests in less than 10 minutes.

"
2765090382,pull_request,closed,,Rename fail stop dag property to fail fast,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


closes: #45229 
This PR renames fail_stop DAG property to fail_fast, the changes made to relevant files

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hprassad,2025-01-01 14:05:41+00:00,[],2025-01-21 05:06:34+00:00,2025-01-21 02:04:41+00:00,https://github.com/apache/airflow/pull/45327,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('area:task-sdk', None)]","[{'comment_id': 2567023363, 'issue_id': 2765090382, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 1, 14, 5, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567287702, 'issue_id': 2765090382, 'author': 'amoghrajesh', 'body': '@hprassad FYI, I updated your PR description to link the issue.', 'created_at': datetime.datetime(2025, 1, 2, 4, 59, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567359541, 'issue_id': 2765090382, 'author': 'amoghrajesh', 'body': '@Lee-W do we have to add this one into migration rules too?', 'created_at': datetime.datetime(2025, 1, 2, 7, 12, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567507251, 'issue_id': 2765090382, 'author': 'Lee-W', 'body': '> @Lee-W do we have to add this one into migration rules too?\n\nYes, this can be easily detected. Iâ€™ll create a PR for this later', 'created_at': datetime.datetime(2025, 1, 2, 9, 47, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567713095, 'issue_id': 2765090382, 'author': 'potiuk', 'body': '@hprassad  - I rebased it  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 37, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569633094, 'issue_id': 2765090382, 'author': 'hprassad', 'body': '@amoghrajesh & @Lee-W , I have added file in newsfragments folder for the PR', 'created_at': datetime.datetime(2025, 1, 3, 18, 14, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597382414, 'issue_id': 2765090382, 'author': 'amoghrajesh', 'body': '@hprassad Few checks are failing. Can you please take a look and fix it?', 'created_at': datetime.datetime(2025, 1, 17, 3, 57, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601409027, 'issue_id': 2765090382, 'author': 'amoghrajesh', 'body': '@hprassad gentle ping. Could you please handle the review comments and rebase this Pull Request? We are waiting on this one for https://github.com/apache/airflow/issues/44951', 'created_at': datetime.datetime(2025, 1, 20, 5, 34, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601926484, 'issue_id': 2765090382, 'author': 'Lee-W', 'body': ""@amoghrajesh I just updated it. Please take a final look. Once this is merged, I'll create a ruff PR for migration rule. Thanks!"", 'created_at': datetime.datetime(2025, 1, 20, 9, 50, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603479158, 'issue_id': 2765090382, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 21, 2, 4, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603666358, 'issue_id': 2765090382, 'author': 'amoghrajesh', 'body': '@hprassad congratulations on your first PR merge! ðŸ¥‡', 'created_at': datetime.datetime(2025, 1, 21, 5, 6, 32, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-01 14:05:45 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

amoghrajesh on (2025-01-02 04:59:38 UTC): @hprassad FYI, I updated your PR description to link the issue.

amoghrajesh on (2025-01-02 07:12:04 UTC): @Lee-W do we have to add this one into migration rules too?

Lee-W on (2025-01-02 09:47:35 UTC): Yes, this can be easily detected. Iâ€™ll create a PR for this later

potiuk on (2025-01-02 12:37:25 UTC): @hprassad  - I rebased it  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

hprassad (Issue Creator) on (2025-01-03 18:14:57 UTC): @amoghrajesh & @Lee-W , I have added file in newsfragments folder for the PR

amoghrajesh on (2025-01-17 03:57:46 UTC): @hprassad Few checks are failing. Can you please take a look and fix it?

amoghrajesh on (2025-01-20 05:34:24 UTC): @hprassad gentle ping. Could you please handle the review comments and rebase this Pull Request? We are waiting on this one for https://github.com/apache/airflow/issues/44951

Lee-W on (2025-01-20 09:50:57 UTC): @amoghrajesh I just updated it. Please take a final look. Once this is merged, I'll create a ruff PR for migration rule. Thanks!

boring-cyborg[bot] on (2025-01-21 02:04:44 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

amoghrajesh on (2025-01-21 05:06:32 UTC): @hprassad congratulations on your first PR merge! ðŸ¥‡

"
2765076946,pull_request,closed,,feat: automatically inject OL transport info into spark jobs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Similar to #44477 , this PR introduces a new feature to OpenLineage integration. **It will NOT impact users that are not using OpenLineage or have not explicitly enabled this feature (False by default).**

## TLDR; 
When explicitly enabled by the user for supported operators, we will automatically inject transport information into the Spark job properties. For example, when submitting a Spark job using the DataprocSubmitJobOperator, we will configure  Spark/OpenLineage integration to use the same transport configuration that Airflow integration uses.

## Why ?

Currently, this process requires manual configuration by the user, as described [here](https://openlineage.io/docs/integrations/spark/configuration/airflow/). E.g.:
```
DataprocSubmitJobOperator(
    task_id=""my_task"", 
    # ... 
    job={ 
        # ...
        ""spark.openlineage.transport.type"": ""http"",
        ""spark.openlineage.transport.url"": openlineage_url,
        ""spark.openlineage.transport.compression"": ""gzip"",
        ""spark.openlineage.transport.auth.apiKey"": api_key,
        ""spark.openlineage.transport.auth.type"": ""apiKey"",
    } 
)

```
Understanding how various Airflow operators configure Spark allows us to automatically inject transport information.

## Controlling the Behavior

We provide users with a flexible control mechanism to manage this injection, combining per-operator enablement with a global fallback configuration. This design is inspired by the `deferrable` argument in Airflow.

```python
ol_inject_transport_info: bool = conf.getboolean(
    ""openlineage"", ""spark_inject_transport_info"", fallback=False
)
```
Each supported operator will include an argument like `ol_inject_transport_info`, which defaults to the global configuration value of `openlineage.spark_inject_transport_info`. This approach allows users to:

1. Control behavior on a per-job basis by explicitly setting the argument.
2. Rely on a consistent default configuration for all jobs if the argument is not set.

This design ensures both flexibility and ease of use, enabling users to fine-tune their workflows while minimizing repetitive configuration. I am aware that adding an OpenLineage-related argument to the operator will affect all users, even those not using OpenLineage, but since it defaults to False and can be ignored, I hope this will not pose any issues.

## How?
The implementation is divided into three parts for better organization and clarity:

1. **Operator's Code (including the `execute` method):**  
   Contains minimal logic to avoid overwhelming users who are not actively working with OpenLineage.

2. **Google's Provider OpenLineage Utils File:**  
   Handles the logic for accessing Spark properties specific to a given operator or job.

3. **OpenLineage Provider's Utils:**  
   Responsible for creating / extracting all necessary information in a format compatible with the OpenLineage Spark integration. We are also performing modifications to the Spark properties here.

For some operators parts 1 and 2 may be in the operator's code. In general, the specific operator / provider will know how to get the spark properties and the OL will know what to inject and do the injection itself.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-01 13:38:12+00:00,[],2025-01-09 19:06:47+00:00,2025-01-09 18:49:44+00:00,https://github.com/apache/airflow/pull/45326,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:openlineage', 'AIP-53'), ('provider:common-compat', '')]","[{'comment_id': 2567689211, 'issue_id': 2765076946, 'author': 'potiuk', 'body': 'Hey @kacpermuda -> I rebased your PR -> we found and issue with @jscheffl with the new caching scheme - fixed in #45347 that would run ""main"" version of the tests-> so I am rebasing all PRs affected :)', 'created_at': datetime.datetime(2025, 1, 2, 12, 17, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:17:16 UTC): Hey @kacpermuda -> I rebased your PR -> we found and issue with @jscheffl with the new caching scheme - fixed in #45347 that would run ""main"" version of the tests-> so I am rebasing all PRs affected :)

"
2765012719,pull_request,closed,,Use free_up_disk_space after checkout,"small fix :) 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-01 11:27:26+00:00,[],2025-01-01 11:36:40+00:00,2025-01-01 11:36:01+00:00,https://github.com/apache/airflow/pull/45325,"[('area:dev-tools', '')]",[],
2765002361,pull_request,closed,,Fix --from-job parameter to be --from-run and update dev CI docs,"I proposed `--from-job` parameter name and it was a mistake, it should be `--from-run` because we are reffering to a GitHub run not job within the run. I realized that when I wanted to review and update documentation about reproducing CI job locally - so this is done together.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-01 11:04:56+00:00,[],2025-01-01 11:24:32+00:00,2025-01-01 11:24:31+00:00,https://github.com/apache/airflow/pull/45324,"[('area:dev-tools', '')]",[],
2764982066,pull_request,closed,,Download only test-warnings-* artifacts for finalize step,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-01 10:25:16+00:00,[],2025-01-01 10:27:16+00:00,2025-01-01 10:27:15+00:00,https://github.com/apache/airflow/pull/45323,"[('area:dev-tools', '')]",[],
2764975230,pull_request,closed,,Add disk space cleanup script to CI,"Seems we are hitting disk space issue in finalize summary step. 
https://github.com/apache/airflow/actions/runs/12568439772/job/35037031243

Adding shell script to remove folders that are not required for us.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-01 10:10:31+00:00,[],2025-01-01 10:25:38+00:00,2025-01-01 10:20:59+00:00,https://github.com/apache/airflow/pull/45322,"[('area:dev-tools', '')]","[{'comment_id': 2566944206, 'issue_id': 2764975230, 'author': 'gopidesupavan', 'body': 'I think we are downloading all the artifacts, https://github.com/apache/airflow/blob/main/.github/workflows/finalize-tests.yml#L190 that includes CI images aswell. thats why we are hitting space issue.\r\n\r\nmay be we can filter download part', 'created_at': datetime.datetime(2025, 1, 1, 10, 19, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566944817, 'issue_id': 2764975230, 'author': 'potiuk', 'body': 'Oh yeah.. And possibly we should not download all of them now ?', 'created_at': datetime.datetime(2025, 1, 1, 10, 20, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566946506, 'issue_id': 2764975230, 'author': 'potiuk', 'body': 'https://github.com/apache/airflow/pull/45323', 'created_at': datetime.datetime(2025, 1, 1, 10, 25, 37, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2025-01-01 10:19:01 UTC): I think we are downloading all the artifacts, https://github.com/apache/airflow/blob/main/.github/workflows/finalize-tests.yml#L190 that includes CI images aswell. thats why we are hitting space issue.

may be we can filter download part

potiuk on (2025-01-01 10:20:53 UTC): Oh yeah.. And possibly we should not download all of them now ?

potiuk on (2025-01-01 10:25:37 UTC): https://github.com/apache/airflow/pull/45323

"
2764960716,pull_request,closed,,"Add extra explanation on how to use ""--from-pr"" and ""--from-job""","We have the nice feature of being able to reproduce the exact environment most of the tests are run in our CI, but it needs a bit more explanation on how to use it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-01 09:39:59+00:00,[],2025-01-01 10:22:03+00:00,2025-01-01 10:22:01+00:00,https://github.com/apache/airflow/pull/45321,"[('area:dev-tools', '')]",[],
2764934503,pull_request,closed,,Re-add conditional prod image build,"Prod image build sometimes (quite often) is not needed. When removing `pull_request_target` in #45266 `wait-for=prod-images` had the condition that prevented it from running (and the `build-prod-images` step depended on it) - but this condition is gone now.

Instead of preventing the whole composite workflow from running, we are adding it to ""build-prod-packages"" so that the whole workflow can complete as prerequisite to ""finalize-tests"" which should be executed regardless from `prod-image-build` being executed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-01 08:41:58+00:00,[],2025-01-01 09:10:04+00:00,2025-01-01 09:10:02+00:00,https://github.com/apache/airflow/pull/45320,"[('area:dev-tools', '')]","[{'comment_id': 2566911868, 'issue_id': 2764934503, 'author': 'potiuk', 'body': 'Realized that after #45319', 'created_at': datetime.datetime(2025, 1, 1, 8, 44, 17, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-01 08:44:17 UTC): Realized that after #45319

"
2764752568,pull_request,closed,,Add dependency between finalize tests and building prod images,"When finalizing tests we are using packages generated in prod image build step and generally we should not finalize the tests until PROD images are successfully built.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-01 00:43:17+00:00,[],2025-01-01 03:56:13+00:00,2025-01-01 03:56:13+00:00,https://github.com/apache/airflow/pull/45319,"[('area:dev-tools', '')]","[{'comment_id': 2566778033, 'issue_id': 2764752568, 'author': 'potiuk', 'body': 'Should prevent cases like https://github.com/apache/airflow/actions/runs/12563255232/job/35028354787', 'created_at': datetime.datetime(2025, 1, 1, 0, 47, 3, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-01 00:47:03 UTC): Should prevent cases like https://github.com/apache/airflow/actions/runs/12563255232/job/35028354787

"
2764718387,pull_request,closed,,Switch to single key for bundle config,Changes to have all bundle configs under one key.  Later we can move more bundle-related configs to this section.,dstandish,2024-12-31 23:09:32+00:00,[],2025-01-16 20:18:38+00:00,2025-01-06 23:45:33+00:00,https://github.com/apache/airflow/pull/45318,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2764653893,pull_request,closed,,Use global pre-commit exclude for vendor folder,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jbampton,2024-12-31 20:18:02+00:00,[],2025-01-02 14:00:42+00:00,2025-01-02 10:29:53+00:00,https://github.com/apache/airflow/pull/45316,"[('area:dev-tools', '')]","[{'comment_id': 2567558655, 'issue_id': 2764653893, 'author': 'potiuk', 'body': 'Nice. Thanks @jbampton !', 'created_at': datetime.datetime(2025, 1, 2, 10, 29, 50, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 10:29:50 UTC): Nice. Thanks @jbampton !

"
2764643822,pull_request,closed,,[v2-10-test] Fix update issues for object and advanced-arrays fields when empty default (#45313),"(cherry picked from commit 6eab1f24c2fe070b6d68a1435eadaccd807ed1c0)

Co-authored-by: Jens Scheffler <95105677+jscheffl@users.noreply.github.com>",github-actions[bot],2024-12-31 19:56:53+00:00,[],2025-01-11 19:42:54+00:00,2024-12-31 20:13:53+00:00,https://github.com/apache/airflow/pull/45315,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566686304, 'issue_id': 2764643822, 'author': 'jscheffl', 'body': 'Re-open to force a build...', 'created_at': datetime.datetime(2024, 12, 31, 19, 59, 11, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-31 19:59:11 UTC): Re-open to force a build...

"
2764560609,pull_request,closed,,Speed up image building in CI by exporting and importing mount cache,"During the build, cache of ``uv`` and ``pip`` is stored in a separate ""cache mount"" volum that is mounted during the build. This cache mount volume is preserved between builds and can be exported and imported to speed up the build process in CI - where cache is stored as artifact and can be imported in the next build.

This PR implements it:

* export and import commands are added to breeze to export/import cache mount content

* the cache mount content is stashed as artifact in the build after image is built and it is restored before the image is built

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-31 17:24:01+00:00,[],2025-01-01 02:56:29+00:00,2025-01-01 02:56:28+00:00,https://github.com/apache/airflow/pull/45314,"[('area:dev-tools', '')]","[{'comment_id': 2566609965, 'issue_id': 2764560609, 'author': 'potiuk', 'body': 'And here is caching of the ""cache-mount"" as well cc: @gopidesupavan', 'created_at': datetime.datetime(2024, 12, 31, 17, 25, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566610770, 'issue_id': 2764560609, 'author': 'potiuk', 'body': 'First tests show that we can go down to < 2 minutes from ~6 minutes to build the image', 'created_at': datetime.datetime(2024, 12, 31, 17, 26, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566635133, 'issue_id': 2764560609, 'author': 'gopidesupavan', 'body': '> First tests show that we can go down to < 2 minutes from ~6 minutes to build the image\r\n\r\nNice improvement :)', 'created_at': datetime.datetime(2024, 12, 31, 18, 10, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566794813, 'issue_id': 2764560609, 'author': 'potiuk', 'body': 'Finally: 3m30 s.  to build the image instead of 5m47. Not as fast as the fastest ""registry"" build we had (1m20s or so ) but ""fast enough""', 'created_at': datetime.datetime(2025, 1, 1, 1, 39, 46, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-31 17:25:11 UTC): And here is caching of the ""cache-mount"" as well cc: @gopidesupavan

potiuk (Issue Creator) on (2024-12-31 17:26:23 UTC): First tests show that we can go down to < 2 minutes from ~6 minutes to build the image

gopidesupavan on (2024-12-31 18:10:31 UTC): Nice improvement :)

potiuk (Issue Creator) on (2025-01-01 01:39:46 UTC): Finally: 3m30 s.  to build the image instead of 5m47. Not as fast as the fastest ""registry"" build we had (1m20s or so ) but ""fast enough""

"
2764505279,pull_request,closed,,Fix update issues for object and advanced-arrays fields when empty default,"As reported in #45032 the CodeMirror entry boxes are not working.

This is caused by how CodeMirror implements the entry: It is shadowing the original `<textarea>` fields in HTML. Unfortunately only via JavaScript the content of CodeMirror and HTML is in sync.
...and unfortunately my hand-written JavaScript checked for NULL/empty value _before_ getting to the fields from CodeMirror. So if an object or advanced array was initialized with an empty value, it never reached the onBlur() update action.
Moved the check for empty _after_ the CodeMirror field check.

Alongside figured out that the same as reported for advancedArray was also happening for object, just that the object field was never correctly initialized on empty value. Fixed this as well if a field is `type=[""object"", ""null""]`.

closes: #45032
",jscheffl,2024-12-31 16:04:03+00:00,[],2024-12-31 19:56:57+00:00,2024-12-31 19:56:09+00:00,https://github.com/apache/airflow/pull/45313,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2566685335, 'issue_id': 2764505279, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45315""><img src=""https://img.shields.io/badge/PR-45315-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 31, 19, 56, 55, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-31 19:56:55 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45315""><img src=""https://img.shields.io/badge/PR-45315-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2764400327,pull_request,closed,,Change UI source formatting to 110 chars,"(Note: I know this PR fails in pre-commit checks but wanted to raise it anyway... based on discussion I'd make it clean)

I noticed that in pre-commit we format all text to 110 chars... for Python code and tooling. Also there was a bit of discussion on the devlist about to change it for smaller screens.

NOTE: The big diff is mainly the re-formatting of all UI source. The impact is caused by the one line change in https://github.com/apache/airflow/pull/45312/files#diff-14e4a70ab8ce4057d209267e534689fe0c3f48658095289169b396cd0c37be51R8

Nevertheless I was wondering why we format the (new) UI code to 80 chars? Is there a reason for this? I'd propose (with this PR) to make it common with the test of the codebase.",jscheffl,2024-12-31 13:52:30+00:00,[],2025-01-01 00:00:42+00:00,2025-01-01 00:00:42+00:00,https://github.com/apache/airflow/pull/45312,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566483370, 'issue_id': 2764400327, 'author': 'potiuk', 'body': 'Applied full tests needed to trigger full static checks', 'created_at': datetime.datetime(2024, 12, 31, 14, 9, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566527090, 'issue_id': 2764400327, 'author': 'bbovenzi', 'body': ""That was just the default value for prettier. I'm happy to have it match our rules for python."", 'created_at': datetime.datetime(2024, 12, 31, 15, 15, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566758795, 'issue_id': 2764400327, 'author': 'jscheffl', 'body': 'No short term objection... as not too much activity LGTM (and beat me up if this was too fast)', 'created_at': datetime.datetime(2024, 12, 31, 23, 58, 27, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-31 14:09:29 UTC): Applied full tests needed to trigger full static checks

bbovenzi on (2024-12-31 15:15:35 UTC): That was just the default value for prettier. I'm happy to have it match our rules for python.

jscheffl (Issue Creator) on (2024-12-31 23:58:27 UTC): No short term objection... as not too much activity LGTM (and beat me up if this was too fast)

"
2764234173,pull_request,closed,,[docs openlineage] updated outdated hyperlink to GcsToGcsOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR updates the hyperlink to GcsToGcsOperator.
Doc updated - https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/guides/developer.html#example

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rahul-madaan,2024-12-31 10:45:32+00:00,[],2024-12-31 12:42:05+00:00,2024-12-31 12:33:31+00:00,https://github.com/apache/airflow/pull/45311,"[('area:providers', ''), ('kind:documentation', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2566418106, 'issue_id': 2764234173, 'author': 'rahul-madaan', 'body': 'I found out that there are more places where the similar change is required. \r\n\r\nhttps://github.com/search?q=repo%3Aapache%2Fairflow%20github.com%2Fapache%2Fairflow%2Fblob%2Fmain%2Fairflow%2Fproviders&type=code\r\n\r\nAs this PR is now merged, I will be raising another PR for the same.', 'created_at': datetime.datetime(2024, 12, 31, 12, 42, 4, tzinfo=datetime.timezone.utc)}]","rahul-madaan (Issue Creator) on (2024-12-31 12:42:04 UTC): I found out that there are more places where the similar change is required. 

https://github.com/search?q=repo%3Aapache%2Fairflow%20github.com%2Fapache%2Fairflow%2Fblob%2Fmain%2Fairflow%2Fproviders&type=code

As this PR is now merged, I will be raising another PR for the same.

"
2764094927,pull_request,closed,,AIP-72: Handling `execution_timeout` for tasks in task SDK,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45307

### Testing results

DAG:
```
from time import sleep

from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from datetime import datetime, timedelta


def print_hello():
    print(""Going to sleep 100 seconds"")
    sleep(100)

with DAG(
    dag_id=""tasktimeout"",
    schedule=None,
    catchup=False,
) as dag:
    hello_task = PythonOperator(
        task_id=""ttimemout"",
        execution_timeout=timedelta(seconds=10),
        python_callable=print_hello,
    )

```

#### Legacy
1. No retries
![image (14)](https://github.com/user-attachments/assets/6b5e5a6b-a1d0-44a6-aebc-7dcf5cbbc00e)

2. With timeouts
![image (15)](https://github.com/user-attachments/assets/0099249d-0d31-4051-8686-73f94d29ea11)

#### Task sdk
1. No retries
<img width=""1725"" alt=""image"" src=""https://github.com/user-attachments/assets/7c319262-1729-4777-9d03-6cef0843618a"" />

2. With retries
<img width=""1725"" alt=""image"" src=""https://github.com/user-attachments/assets/92908ae2-8a72-4563-9d92-7438797ea0fb"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-31 08:15:52+00:00,['amoghrajesh'],2025-01-01 05:09:07+00:00,2025-01-01 05:09:05+00:00,https://github.com/apache/airflow/pull/45310,"[('area:task-sdk', None)]","[{'comment_id': 2566850977, 'issue_id': 2764094927, 'author': 'amoghrajesh', 'body': 'Will merge this PR with one approval as it is functional. Can handle any issues or shortcomings, if any, in follow ups.', 'created_at': datetime.datetime(2025, 1, 1, 5, 8, 11, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-01 05:08:11 UTC): Will merge this PR with one approval as it is functional. Can handle any issues or shortcomings, if any, in follow ups.

"
2764068595,pull_request,closed,,Import Variable button and modal on variables list page,"Modal : 
<img width=""943"" alt=""image"" src=""https://github.com/user-attachments/assets/931fee52-c6e0-40ee-8fc0-eece6ed3602d"" />

View : 
<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/b0904b84-514b-4220-a028-91e19f50ca24"" />


related: #43709


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-31 07:43:41+00:00,[],2024-12-31 15:35:32+00:00,2024-12-31 15:35:32+00:00,https://github.com/apache/airflow/pull/45309,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2764052373,pull_request,closed,,AIP-72: Handling AirflowException in task sdk,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


PR: https://github.com/apache/airflow/pull/45106 provides a machinery to handle ""failure"" / ""retry"" states in the execution API server itself.

This PR handles the AirflowException if thrown by tasks.

### Testing results
DAG:
```
from airflow import DAG
from airflow.exceptions import AirflowException
from airflow.providers.standard.operators.python import PythonOperator


def print_hello():
    raise AirflowException(""hi i am AirflowException!"")

with DAG(
    dag_id=""afexception"",
    schedule=None,
    catchup=False,
) as dag:
    hello_task = PythonOperator(
        task_id=""afexception_task"",
        retries=2,
        python_callable=print_hello,
    )

```

#### Legacy

1. With retries
![image (12)](https://github.com/user-attachments/assets/88251c7a-ef2d-444b-9592-e88f538983d2)

2. Without retries
![image (13)](https://github.com/user-attachments/assets/b77b93b8-7443-4e7a-b3a8-6b65fdb67690)



#### Task SDK
1. With retries
<img width=""1725"" alt=""image"" src=""https://github.com/user-attachments/assets/d4c2fed8-340a-4609-b806-7640539ebee3"" />

2. Without retries
<img width=""1725"" alt=""image"" src=""https://github.com/user-attachments/assets/303c8e39-e1b2-4a54-85b7-df72d43ac0ca"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-31 07:23:19+00:00,['amoghrajesh'],2024-12-31 16:34:02+00:00,2024-12-31 16:34:00+00:00,https://github.com/apache/airflow/pull/45308,"[('area:task-sdk', None)]","[{'comment_id': 2566572287, 'issue_id': 2764052373, 'author': 'amoghrajesh', 'body': '@jscheffl this is a simple one, would like an approval if you are around.', 'created_at': datetime.datetime(2024, 12, 31, 16, 23, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566577351, 'issue_id': 2764052373, 'author': 'amoghrajesh', 'body': '> I am around... and I _thought_ I had viewed and approved? Anyway... here you are!\n\nThanks Jens. Had to check, cos holiday season :)', 'created_at': datetime.datetime(2024, 12, 31, 16, 32, 16, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-31 16:23:36 UTC): @jscheffl this is a simple one, would like an approval if you are around.

amoghrajesh (Issue Creator) on (2024-12-31 16:32:16 UTC): Thanks Jens. Had to check, cos holiday season :)

"
2763954981,pull_request,closed,,Small changes to provider_issue_TEMPLATE.md.jinja2,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-31 04:59:20+00:00,[],2024-12-31 12:25:38+00:00,2024-12-31 12:25:38+00:00,https://github.com/apache/airflow/pull/45306,"[('area:dev-tools', '')]",[],
2763717707,pull_request,closed,,fix deserializing callbacks to proper types,"Without this fix, the callback requests are deserialized as a base class `CallbackRequest` and are not executed - they are silently failing through this check.

```
def _execute_callbacks(
    dagbag: DagBag, callback_requests: list[CallbackRequest], log: FilteringBoundLogger
) -> None:
    for request in callback_requests:
        log.debug(""Processing Callback Request"", request=request.to_json())
        if isinstance(request, TaskCallbackRequest):
            raise NotImplementedError(
                ""Haven't coded Task callback yet - https://github.com/apache/airflow/issues/44354!""
            )
            # _execute_task_callbacks(dagbag, request)
        elif isinstance(request, DagCallbackRequest):
            _execute_dag_callbacks(dagbag, request, log)
```",mobuchowski,2024-12-30 21:30:59+00:00,[],2025-01-08 11:46:39+00:00,2025-01-07 16:21:49+00:00,https://github.com/apache/airflow/pull/45305,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2566238872, 'issue_id': 2763717707, 'author': 'mobuchowski', 'body': '@amoghrajesh dag ones (DagCallbackRequest) should work, and are mostly implemented in some form. This PR makes basic ones work. There are missing things - like the context is empty dict - but neverthless is improving the situation.\r\n\r\nMy main motivation is unblocking ticket https://github.com/apache/airflow/pull/44547 that has been really hard to get to get merged.', 'created_at': datetime.datetime(2024, 12, 31, 8, 30, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576225020, 'issue_id': 2763717707, 'author': 'jscheffl', 'body': 'I assume this PR broke main, failed tests are with https://github.com/apache/airflow/actions/runs/12657999447\r\n\r\nSomeone able to fix this or shall we revert to fix canary again?', 'created_at': datetime.datetime(2025, 1, 7, 21, 9, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577476407, 'issue_id': 2763717707, 'author': 'kaxil', 'body': '> I assume this PR broke main, failed tests are with https://github.com/apache/airflow/actions/runs/12657999447\r\n> \r\n> Someone able to fix this or shall we revert to fix canary again?\r\n\r\nFixed in https://github.com/apache/airflow/pull/45482', 'created_at': datetime.datetime(2025, 1, 8, 11, 46, 38, tzinfo=datetime.timezone.utc)}]","mobuchowski (Issue Creator) on (2024-12-31 08:30:55 UTC): @amoghrajesh dag ones (DagCallbackRequest) should work, and are mostly implemented in some form. This PR makes basic ones work. There are missing things - like the context is empty dict - but neverthless is improving the situation.

My main motivation is unblocking ticket https://github.com/apache/airflow/pull/44547 that has been really hard to get to get merged.

jscheffl on (2025-01-07 21:09:48 UTC): I assume this PR broke main, failed tests are with https://github.com/apache/airflow/actions/runs/12657999447

Someone able to fix this or shall we revert to fix canary again?

kaxil on (2025-01-08 11:46:38 UTC): Fixed in https://github.com/apache/airflow/pull/45482

"
2763680569,pull_request,open,,AIP-81 Central API Communication Mechanism for CLI and Connection Command Integration,"closes: #42561 and discarding dynamic generation of requests: #42562

**Summary**
This PR introduces a central API communication mechanism for the CLI and adopts one of the broadest endpoint ranges in the API, focusing on connection commands. After several iterations to automate API call generation and handle edge cases, I couldn't achieve a fully dynamic request generation process. Instead, I landed on a structure similar to TaskSDK <-> ExecutionAPI. This approach simplifies reviews, maintains consistency across clients, and opens the door for better automation in future iterations, possibly in 3.1 or 3.2.

**Implementation Details**

- Added a central API communication mechanism for the CLI.
- Integrated connection_command.py with unit tests.
- Implemented most of the necessary CLI operations.
- Data model generation from RestAPI to CLI is handled using uv.
- Added decorators to cascade generic processes to operations.
- Created a testing framework for CLI testing, with an example implementation for connection command.
- Pending Work
- Some minor features related to the connection command are still in progress and will be added in follow-up updates before 3.0.

**Note:** There are two missing functionalities in this PR for the connection command. Those will be included with follow-up tasks.
* #45302 (Create Default Connections)
* #45303 (Overwrite the Bulk Insert Connections when Flag is passed)

**Notes on task_command**
While working on this, I realized that task_command behaves more like a local_command than a remote_command. This needs further discussion, especially regarding its integration with TaskSDK. From the CLI perspective, depending on TaskSDK seems cleaner than directly calling ExecutionAPI, it avoids duplication and keeps the structure consistent. Even if the CLI calls TaskSDK, the two-hop process to reach the ExecutionAPI feels a bit redundant. What do you think, @ashb (to all, please jump into discussion, I tagged Ash to follow up the previous discussion started on this in Slack)?

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-12-30 20:46:54+00:00,[],2025-02-07 00:07:53+00:00,,https://github.com/apache/airflow/pull/45300,"[('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566759853, 'issue_id': 2763680569, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 1, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578837385, 'issue_id': 2763680569, 'author': 'bugraoz93', 'body': '**Note Update:** The missing parts are included in the PR. \r\n\r\n- Create default connections in connection_command\r\n- Include overwrite functionality for file import operations for connections and pool endpoint\r\n- Include overwrite functionality to connection_command\r\n\r\nThanks @jason810496 for your contributions!', 'created_at': datetime.datetime(2025, 1, 8, 22, 57, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2641435763, 'issue_id': 2763680569, 'author': 'bugraoz93', 'body': ""Thanks a lot for your time and your comments! I will address them and adjust the code accordingly soon. \n\n> Next time would be better to cut PRs in smaller chunks not to scare reviewers away by number of LoC :-D\n\nIndeed, that's on me making it big. I thought most parts were repeated on the operations while making the integration easier for contributers and went for it. I agree, that's on me, I will definitely split next time :D"", 'created_at': datetime.datetime(2025, 2, 7, 0, 7, 52, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-01 00:01:59 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

bugraoz93 (Issue Creator) on (2025-01-08 22:57:13 UTC): **Note Update:** The missing parts are included in the PR. 

- Create default connections in connection_command
- Include overwrite functionality for file import operations for connections and pool endpoint
- Include overwrite functionality to connection_command

Thanks @jason810496 for your contributions!

bugraoz93 (Issue Creator) on (2025-02-07 00:07:52 UTC): Thanks a lot for your time and your comments! I will address them and adjust the code accordingly soon. 


Indeed, that's on me making it big. I thought most parts were repeated on the operations while making the integration easier for contributers and went for it. I agree, that's on me, I will definitely split next time :D

"
2763643083,pull_request,closed,,Add GFM support for markdown rendering,"Working on the new Trigger UI Form I noticed that the Markdown rendering is by default a bit limited.

This PR adds full GFM style support to markdown on the UI when rendered.

See also https://github.com/remarkjs/remark-gfm",jscheffl,2024-12-30 20:02:10+00:00,[],2024-12-31 15:31:26+00:00,2024-12-31 15:31:26+00:00,https://github.com/apache/airflow/pull/45299,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2763560437,pull_request,closed,,Move create topic to hook in Azure Service Bus provider,This is a minor refactor to push the logic to create a topic down into the hook rather than calling the Azure Service Bus SDK create_topic method in the operator.,perry2of5,2024-12-30 18:31:50+00:00,[],2025-01-02 23:31:13+00:00,2025-01-01 07:08:27+00:00,https://github.com/apache/airflow/pull/45297,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2763550579,pull_request,closed,,Extend --from-job and --from-pr to PROD images as well,"Building on top of #45287 we also add the same capability for PROD images. Additionally:

* the token is required so it is passed as obligatory --github-token option (with GITHUB_TOKEN env var as source of it). Help contains link to generate the token so that it can be easily generated.

* error messages contain message text on top of error code

* the --github-repository is used to determine the right github repo to use when calling the API.

* PROD image platform escaping used `-` instead of `-` which make it impossible to find the artifact when looking for it. This has been fixed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-30 18:21:28+00:00,[],2024-12-30 20:25:47+00:00,2024-12-30 20:25:46+00:00,https://github.com/apache/airflow/pull/45296,"[('area:dev-tools', '')]","[{'comment_id': 2565789917, 'issue_id': 2763550579, 'author': 'potiuk', 'body': 'I tried to get PROD image and realized it was not implemented :). So I added it, found a typo in PROD load/save and improved a bit github_token/  github_repository behaviour : @gopidesupavan :D', 'created_at': datetime.datetime(2024, 12, 30, 18, 23, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565794736, 'issue_id': 2763550579, 'author': 'potiuk', 'body': 'BTW. Side effect of the #45266 is that PR workflow sshould not work almost as well (minus caching speed from registry) for PRs internaly done in a different repository - without having to setup GitHub registry - which was huge limitation of the ""pull_retquest_target"" workflow. This means that it should be entirely possible for anyone to test their PR locally using their own github runners - in their own repository in-repo PR and it should **just work** - including storing the image artifacts - that\'s why it is important to use `--github-repository` flag whenever possible :)', 'created_at': datetime.datetime(2024, 12, 30, 18, 29, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565804827, 'issue_id': 2763550579, 'author': 'gopidesupavan', 'body': '> I tried to get PROD image and realized it was not implemented :). So I added it, found a typo in PROD load/save and improved a bit github_token/ github_repository behaviour : @gopidesupavan :D\r\n\r\nYeah good catch :) thank you', 'created_at': datetime.datetime(2024, 12, 30, 18, 41, 25, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-30 18:23:19 UTC): I tried to get PROD image and realized it was not implemented :). So I added it, found a typo in PROD load/save and improved a bit github_token/  github_repository behaviour : @gopidesupavan :D

potiuk (Issue Creator) on (2024-12-30 18:29:05 UTC): BTW. Side effect of the #45266 is that PR workflow sshould not work almost as well (minus caching speed from registry) for PRs internaly done in a different repository - without having to setup GitHub registry - which was huge limitation of the ""pull_retquest_target"" workflow. This means that it should be entirely possible for anyone to test their PR locally using their own github runners - in their own repository in-repo PR and it should **just work** - including storing the image artifacts - that's why it is important to use `--github-repository` flag whenever possible :)

gopidesupavan on (2024-12-30 18:41:25 UTC): Yeah good catch :) thank you

"
2763485575,pull_request,open,,"AIP-72: Task SDK support for on_task_instance_* listeners, make OpenLineage compatible","With AIP-72, there is no access to the database session from the worker process, and the runtime objects have some differences to the db models. This PR contains three commits that deal with that situation:

- First commit adjusts `on_task_instance_*` listeners interface to AIP-72: drops `session` argument and makes `task_instance` argument an instance of `RuntimeTaskInstance` class, not database model
- Second commit adds basic support for calling listeners in Task SDK, additionally adding some context fields that allow OL and other listeners not use DB.
- Third commit adjusts OpenLineage integration to work with new interface and Task SDK.

Some followup work: 
- wrap listener calls into `Activity` to make logging better visible from UI, and distinct from task logs
- add separate interface for API to capture manual/API task changes. Impossible to reuse current interface since object would be a different type (not `RuntimeTaskInstance`) 
- add support for more types of listeners, more in task https://github.com/apache/airflow/issues/45491

closes https://github.com/apache/airflow/issues/45423",mobuchowski,2024-12-30 17:14:58+00:00,[],2025-02-07 20:49:49+00:00,,https://github.com/apache/airflow/pull/45294,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:providers', ''), ('provider:openlineage', 'AIP-53'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('area:task-sdk', None)]","[{'comment_id': 2567699171, 'issue_id': 2763485575, 'author': 'potiuk', 'body': '@mobuchowski  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.', 'created_at': datetime.datetime(2025, 1, 2, 12, 25, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567699957, 'issue_id': 2763485575, 'author': 'potiuk', 'body': 'Actually - I rebased it now.', 'created_at': datetime.datetime(2025, 1, 2, 12, 26, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567701656, 'issue_id': 2763485575, 'author': 'mobuchowski', 'body': ""I will rebase very soon as I'm working on some of the test failures anyway ðŸ™‚"", 'created_at': datetime.datetime(2025, 1, 2, 12, 27, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2643456814, 'issue_id': 2763485575, 'author': 'vikramkoka', 'body': '@mobuchowski \r\nHope all is well. Just checking in how this is coming along? \r\n\r\nYou had also mentioned that you would be raising another PR once https://github.com/apache/airflow/pull/45732 was merged. Since that is already merged, is that follow-up PR already in progress. \r\n\r\nThank you!', 'created_at': datetime.datetime(2025, 2, 7, 16, 48, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2644101721, 'issue_id': 2763485575, 'author': 'mobuchowski', 'body': ""Hey @vikramkoka - rebased this PR and fixed conflicts, it should be good to merge.\r\n\r\nHaven't started on followup to https://github.com/apache/airflow/pull/45732 but will try to find some time next week. I don't think we need to hold up this PR for that, especially since rebasing 2000 lines PR on fast moving target takes significant amount of time."", 'created_at': datetime.datetime(2025, 2, 7, 20, 49, 48, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:25:42 UTC): @mobuchowski  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.

potiuk on (2025-01-02 12:26:25 UTC): Actually - I rebased it now.

mobuchowski (Issue Creator) on (2025-01-02 12:27:49 UTC): I will rebase very soon as I'm working on some of the test failures anyway ðŸ™‚

vikramkoka on (2025-02-07 16:48:23 UTC): @mobuchowski 
Hope all is well. Just checking in how this is coming along? 

You had also mentioned that you would be raising another PR once https://github.com/apache/airflow/pull/45732 was merged. Since that is already merged, is that follow-up PR already in progress. 

Thank you!

mobuchowski (Issue Creator) on (2025-02-07 20:49:48 UTC): Hey @vikramkoka - rebased this PR and fixed conflicts, it should be good to merge.

Haven't started on followup to https://github.com/apache/airflow/pull/45732 but will try to find some time next week. I don't think we need to hold up this PR for that, especially since rebasing 2000 lines PR on fast moving target takes significant amount of time.

"
2763201215,pull_request,closed,,AIP-72: Semantically correct the TI state handling in supervisor,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

We transition states to a terminal state in supervisor under `wait()`. We do it when the task has finished running and has reached a ""non direct"" state. Direct states are ones which need some information to transition into. For example, the reschedule state needs ""reschedule date"".

Code that handles this: https://github.com/apache/airflow/blob/main/task_sdk/src/airflow/sdk/execution_time/supervisor.py#L524-L527

However, a more semantically correct way to transition into a terminal state would be to check if ""hey, have we already transitioned our TI into some state, if not, let me do it - to success or failed or something like that.""

This PR corrects some of these things semantically so that it reflects the intent.
Checks for `if self.final_state not in STATES_SENT_DIRECTLY`

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-30 13:18:34+00:00,[],2025-01-07 17:47:27+00:00,2025-01-07 17:47:23+00:00,https://github.com/apache/airflow/pull/45291,"[('area:task-sdk', None)]",[],
2763084936,pull_request,closed,,Improve caching strategy across the board of CI workflow,"We are using various caches in our build and so far - due to the way how ""standard"" caching works, PRs from forks could not effectively use the cache from main Airflow repository - because caches are not shared with other repositories - so the PRs builds could only use cache effectively when they were rebased and continued running from the same fork.

This PR improves caching strategy using ""stash"" action from the ASF. Unlike `cache` - the action uses artifacts to store cache, and that makes it possible for the stash action to use such cache uploaded from `main` canary builds in PRs coming from the fork.

As part of this change all the places where setup-python was used and breeze installed afterwards were reviewed and updated to use only breeze installation action (it already installs python) and this action has been improved to use UV caching effectively.

Overall this PR should decrease setup overhead for many jobs across the CI workflow.

Follow-up after #45266

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-30 11:43:32+00:00,[],2025-01-01 01:29:38+00:00,2025-01-01 01:29:36+00:00,https://github.com/apache/airflow/pull/45289,"[('area:dev-tools', '')]","[{'comment_id': 2565429618, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'Looks like the stash action does not work exactly as advertised :)', 'created_at': datetime.datetime(2024, 12, 30, 12, 35, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565432944, 'issue_id': 2763084936, 'author': 'gopidesupavan', 'body': '> Looks like the stash action does not work exactly as advertised :)\r\n\r\nthink we need to set env variable name `head_name` https://github.com/apache/infrastructure-actions/blob/main/stash/restore/action.yml#L108', 'created_at': datetime.datetime(2024, 12, 30, 12, 38, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565440590, 'issue_id': 2763084936, 'author': 'gopidesupavan', 'body': '> > Looks like the stash action does not work exactly as advertised :)\r\n> \r\n> think we need to set env variable name `head_name` https://github.com/apache/infrastructure-actions/blob/main/stash/restore/action.yml#L108\r\n\r\nah head_name is derived from github ref.', 'created_at': datetime.datetime(2024, 12, 30, 12, 46, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565546644, 'issue_id': 2763084936, 'author': 'potiuk', 'body': ""Yeah - it seems that the action likely gets into a race condition, or does not work as advertised:\r\n\r\nFrom: https://github.com/apache/infrastructure-actions/tree/main/stash#usage\r\n\r\n> Using the save action again in the same workflow run will overwrite the existing cache with the same key. This does apply to each invocation in a matrix job as well! If you want to keep the old cache, you can use a different key or set overwrite to false.\r\n\r\nIt seems that we have error 409 conflict not handled (I tried with both override 'false' - there it fails obviously) and default `true` - and there it **should** work - but I think there is a race condition that when multiple jobs are trying to upload the same artifact - which is happening in our case - they get 409 conflict:\r\n\r\n> Root directory input is valid!\r\nError: Failed to CreateArtifact: Received non-retryable error: Failed request: (409) Conflict: an artifact with this name already exists on the workflow run\r\n\r\nCC: @assignUser - is the right guess ?"", 'created_at': datetime.datetime(2024, 12, 30, 14, 22, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565548617, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'Evidently it tries with ""overwite: true"":\r\n\r\n![image](https://github.com/user-attachments/assets/2936fedb-7c01-4e42-9fff-131b7aa1da29)', 'created_at': datetime.datetime(2024, 12, 30, 14, 24, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565551877, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'If that\'s the right guess, then we might try to handle it somehow - since we don\'t care which uploaded artifact will be uploaded - we can actually even ignore 409 when it happens - without retrying it because it means that someone else managed to upload the artifact in parallel and they ""won"".', 'created_at': datetime.datetime(2024, 12, 30, 14, 27, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565552865, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'cc: @assignUser - seems we are stressing your action to the limit :)', 'created_at': datetime.datetime(2024, 12, 30, 14, 27, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565602157, 'issue_id': 2763084936, 'author': 'assignUser', 'body': ""Wow that's wild, haven't seen that before :D But that's an issue with the artifact backend, nothing really I can change in the action itself."", 'created_at': datetime.datetime(2024, 12, 30, 15, 9, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565855217, 'issue_id': 2763084936, 'author': 'potiuk', 'body': ""> Wow that's wild, haven't seen that before :D But that's an issue with the artifact backend, nothing really I can change in the action itself.\r\n\r\nLet's see... PRs might be coming :)"", 'created_at': datetime.datetime(2024, 12, 30, 19, 44, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565964463, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'FYI. @assignUser and @gopidesupavan -> seems that this is a well known ""feature"" of the `@v4` action that caused a number of users a problems when migrating to `@v4`. The proposed `solution` (which IMHO is just a workaround) is to upload each artifact with a different key and use ""merge-multiple"" feature and glob pattern to download and merge all such uploaded artifacts (!??!!#$@#%!%!$%!#%!)....\r\n\r\nThis is even explained here: https://github.com/actions/download-artifact/blob/main/docs/MIGRATION.md#multiple-uploads-to-the-same-named-artifact as solution.\r\n\r\nhttps://github.com/actions/upload-artifact/issues/478\r\n\r\nExample solution:  https://github.com/actions/upload-artifact/issues/478#issuecomment-1885470013\r\n\r\nBut stash does not use the download-artitact action and ""merge-multiple"" ... And I really do not like the ""solution"". .. So we wil have to come up with a different approach.', 'created_at': datetime.datetime(2024, 12, 30, 22, 15, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565985028, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'OK. @assignUser and @gopidesupavan -> I think I found a solution (and actually this is a better one in general for performance, but slightly more ""distributed"" among the .yml files.\r\n\r\nInstead of heaving a clear save/restore around installation, I only do:\r\n\r\n* restore\r\n* installl\r\n\r\nAnd I make sure to have one separate job that is prerequisite of all other jobs (`build-info` which was already there as a single job that kicks-off the rest - for uv cache and `install-pre-commit` that is added as ""needs"" for all jobs that need the cache and those ""needs"" job are the only ones that upload the artifact. \r\n\r\nThis way we get a little longer bootstrap, but then all the other jobs should use the cache uploaded by the prerequisite job. Plus the bootstrap will also use the artifact from previous runs (or target branch) if corresponding pyproject.toml / pre-commit config files did not change.', 'created_at': datetime.datetime(2024, 12, 30, 22, 52, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566025919, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'Ha. TIL....\r\n\r\nFirst of all It turns out that `uv` is DAMN FAST. I\r\n\r\nInstalling breeze with uv from scratch = 6s, just downloading breeze cache is 5s \r\n\r\n<img width=""826"" alt=""Screenshot 2024-12-31 at 00 42 24"" src=""https://github.com/user-attachments/assets/036c15a9-4789-432f-953c-a7f1d146cdb7"" />\r\n\r\nNot mentioning upload delay.... So using cache for breeze makes no sense..\r\n\r\nI expected a bit different numbers for ""pre-commit"" ... but... \r\n\r\nInstalling all our pre-commits with uv from scratch = 1m45 s, uploading the resulting cache = 1m56 s (!) \r\n\r\n<img width=""774"" alt=""Screenshot 2024-12-31 at 00 31 14"" src=""https://github.com/user-attachments/assets/bc64adb9-94a3-4f18-b019-c2f14eeef4ec"" />\r\n\r\nDownloading the artifact cache and installing pre-commit is ..... 2 m (!)\r\n\r\n<img width=""761"" alt=""Screenshot 2024-12-31 at 00 33 01"" src=""https://github.com/user-attachments/assets/7ce9c3c5-90d6-4be2-b126-6ec78017e204"" />\r\n\r\nBut I think there is something wrong with cache restoration - not sure what though (yet):\r\n\r\nThe cache is downloaded in 30 seconds:\r\n\r\n<img width=""1313"" alt=""Screenshot 2024-12-31 at 00 47 47"" src=""https://github.com/user-attachments/assets/ba523821-be1b-4ff1-bf86-0e6b35952682"" />\r\n\r\nBut then it takes almost as much time to install all pre-commits. Which I think is because we neeed both `uv` and  `pre-commit` cache. which means that I need to upload whole `~/.cache/` folder.... But... the problem is that this is a hidden file - and the stash action does not allow to pass `include-hidden-files` :( Need to contribute it..', 'created_at': datetime.datetime(2024, 12, 31, 0, 13, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566037385, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'https://github.com/apache/infrastructure-actions/pull/81', 'created_at': datetime.datetime(2024, 12, 31, 0, 35, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566037530, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'Also https://github.com/apache/infrastructure-actions/pull/82', 'created_at': datetime.datetime(2024, 12, 31, 0, 35, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566058919, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'Ok. @assignUser @gopidesupavan -> I believe I also found out why caching did not speed up pre-commit. The problem was that `stash/restore` action (unlike download-artifact) did not expand `~` to home directory of the user - and this is where our cache is stored. \r\n\r\nEffectively the cache was restored to `~/.cache/` directory inside the checked out repository (with actual `~` as directory name) :( .. Took me a bit of time to figure it out.\r\n\r\n\r\nFix in https://github.com/apache/infrastructure-actions/pull/84', 'created_at': datetime.datetime(2024, 12, 31, 1, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566094221, 'issue_id': 2763084936, 'author': 'gopidesupavan', 'body': '> FYI. @assignUser and @gopidesupavan -> seems that this is a well known ""feature"" of the `@v4` action that caused a number of users a problems when migrating to `@v4`. The proposed `solution` (which IMHO is just a workaround) is to upload each artifact with a different key and use ""merge-multiple"" feature and glob pattern to download and merge all such uploaded artifacts (!??!!#$@#%!%!$%!#%!)....\r\n> \r\n> This is even explained here: https://github.com/actions/download-artifact/blob/main/docs/MIGRATION.md#multiple-uploads-to-the-same-named-artifact as solution.\r\n> \r\n> [actions/upload-artifact#478](https://github.com/actions/upload-artifact/issues/478)\r\n> \r\n> Example solution: [actions/upload-artifact#478 (comment)](https://github.com/actions/upload-artifact/issues/478#issuecomment-1885470013)\r\n> \r\n> But stash does not use the download-artitact action and ""merge-multiple"" ... And I really do not like the ""solution"". .. So we wil have to come up with a different approach.\r\n\r\nOh yeah this is new breaking change they released with v4, actually i got to know this, when try different patterns for our trusted publisher faced this while upload files to artifact', 'created_at': datetime.datetime(2024, 12, 31, 3, 6, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566094564, 'issue_id': 2763084936, 'author': 'gopidesupavan', 'body': '> OK. @assignUser and @gopidesupavan -> I think I found a solution (and actually this is a better one in general for performance, but slightly more ""distributed"" among the .yml files.\r\n> \r\n> Instead of heaving a clear save/restore around installation, I only do:\r\n> \r\n> * restore\r\n> * installl\r\n> \r\n> And I make sure to have one separate job that is prerequisite of all other jobs (`build-info` which was already there as a single job that kicks-off the rest - for uv cache and `install-pre-commit` that is added as ""needs"" for all jobs that need the cache and those ""needs"" job are the only ones that upload the artifact.\r\n> \r\n> This way we get a little longer bootstrap, but then all the other jobs should use the cache uploaded by the prerequisite job. Plus the bootstrap will also use the artifact from previous runs (or target branch) if corresponding pyproject.toml / pre-commit config files did not change.\r\n\r\ngood point make sense :)', 'created_at': datetime.datetime(2024, 12, 31, 3, 7, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566095238, 'issue_id': 2763084936, 'author': 'gopidesupavan', 'body': '> Ha. TIL....\r\n> \r\n> First of all It turns out that `uv` is DAMN FAST. I\r\n> \r\n> Installing breeze with uv from scratch = 6s, just downloading breeze cache is 5s\r\n> \r\n> <img alt=""Screenshot 2024-12-31 at 00 42 24"" width=""826"" src=""https://private-user-images.githubusercontent.com/595491/399386334-036c15a9-4789-432f-953c-a7f1d146cdb7.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU2MTQ1ODAsIm5iZiI6MTczNTYxNDI4MCwicGF0aCI6Ii81OTU0OTEvMzk5Mzg2MzM0LTAzNmMxNWE5LTQ3ODktNDMyZi05NTNjLWE3ZjFkMTQ2Y2RiNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjMxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIzMVQwMzA0NDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YmFhZTEzZDViM2RiMTViODdjYzliMWI1MWY5MmIyMDFlMTU1OWZmZDBlOTBjZTUzMWI4NmI5OTgzNGZhNzdhJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.R5sjOUSawYLdSi0vvgc5AvdmGxShQDdmhULC7DAE3DA"">\r\n> Not mentioning upload delay.... So using cache for breeze makes no sense..\r\n> \r\n> I expected a bit different numbers for ""pre-commit"" ... but...\r\n> \r\n> Installing all our pre-commits with uv from scratch = 1m45 s, uploading the resulting cache = 1m56 s (!)\r\n> \r\n> <img alt=""Screenshot 2024-12-31 at 00 31 14"" width=""774"" src=""https://private-user-images.githubusercontent.com/595491/399385418-bc64adb9-94a3-4f18-b019-c2f14eeef4ec.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU2MTQ1ODAsIm5iZiI6MTczNTYxNDI4MCwicGF0aCI6Ii81OTU0OTEvMzk5Mzg1NDE4LWJjNjRhZGI5LTk0YTMtNGYxOC1iMDE5LWMyZjE0ZWVlZjRlYy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjMxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIzMVQwMzA0NDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iYjk0NGViYzg2OTBiYTY4NWUwNDJiZTgwMTgwZWJkNmFhODUzMWZjYWQ2MGRkYjcwOTVjZTIzN2Y5ZjAxNzA3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.4MBPMfnmMFbvJ1QRZ3NuAXg4xefR_TKZZ6pgOpB4QVw"">\r\n> Downloading the artifact cache and installing pre-commit is ..... 2 m (!)\r\n> \r\n> <img alt=""Screenshot 2024-12-31 at 00 33 01"" width=""761"" src=""https://private-user-images.githubusercontent.com/595491/399385698-7ce9c3c5-90d6-4be2-b126-6ec78017e204.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU2MTQ1ODAsIm5iZiI6MTczNTYxNDI4MCwicGF0aCI6Ii81OTU0OTEvMzk5Mzg1Njk4LTdjZTljM2M1LTkwZDYtNGJlMi1iMTI2LTZlYzc4MDE3ZTIwNC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjMxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIzMVQwMzA0NDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lOWY4MDA5YjkxNGYzMDQ0Mjk5NmY1Mzg4MWJkOWQ2M2ZjODNjNzIzOTg2Nzk1MmVhMjAzZWJlYzIwNThjN2NhJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.hE_kQn7yAHb4cP86ykrLhHj018f8hR5i_HcFidr5mJ8"">\r\n> But I think there is something wrong with cache restoration - not sure what though (yet):\r\n> \r\n> The cache is downloaded in 30 seconds:\r\n> \r\n> <img alt=""Screenshot 2024-12-31 at 00 47 47"" width=""1313"" src=""https://private-user-images.githubusercontent.com/595491/399386703-ba523821-be1b-4ff1-bf86-0e6b35952682.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU2MTQ1ODAsIm5iZiI6MTczNTYxNDI4MCwicGF0aCI6Ii81OTU0OTEvMzk5Mzg2NzAzLWJhNTIzODIxLWJlMWItNGZmMS1iZjg2LTBlNmIzNTk1MjY4Mi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMjMxJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTIzMVQwMzA0NDBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOGY4Mjk0NDAwOTE2NGFiMTY0Y2Y3OWY5YWQzOTgxZWQ2NTYyZjg2NDgwYmQ1NTNkYzk1MTBiNDg4NzdmZjdiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ZX9MZbDvHCQiP6nPYjUxIxXiz9AyBxmHGuqVkwM9o24"">\r\n> But then it takes almost as much time to install all pre-commits. Which I think is because we neeed both `uv` and `pre-commit` cache. which means that I need to upload whole `~/.cache/` folder.... But... the problem is that this is a hidden file - and the stash action does not allow to pass `include-hidden-files` :( Need to contribute it..\r\n\r\ninteresting ... Yes absolutely UV is super fast , like they release new versions super fast ðŸ˜„', 'created_at': datetime.datetime(2024, 12, 31, 3, 9, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566097552, 'issue_id': 2763084936, 'author': 'gopidesupavan', 'body': '> Ok. @assignUser @gopidesupavan -> I believe I also found out why caching did not speed up pre-commit. The problem was that `stash/restore` action (unlike download-artifact) did not expand `~` to home directory of the user - and this is where our cache is stored.\r\n> \r\n> Effectively the cache was restored to `~/.cache/` directory inside the checked out repository (with actual `~` as directory name) :( .. Took me a bit of time to figure it out.\r\n> \r\n> Fix in [apache/infrastructure-actions#84](https://github.com/apache/infrastructure-actions/pull/84)\r\n\r\nah gotcha good find :)  and we always point `~/.cache/` so that path becomes after download `{github_workspace}~/.cache/`', 'created_at': datetime.datetime(2024, 12, 31, 3, 16, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566554693, 'issue_id': 2763084936, 'author': 'potiuk', 'body': ""OK. I think i Implemented all workarounds to not have to wait for any of the `stash` action PRs I created, let's see what will be the savings now"", 'created_at': datetime.datetime(2024, 12, 31, 15, 56, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566601905, 'issue_id': 2763084936, 'author': 'potiuk', 'body': ""There is one more error with tar ... Pre-commit is currently stored with `/hom/runner` prefix, that's why it had no impact on the timing. \r\n\r\nBut K8S is already hugely impactful -> instaling the venv + all the tools is ~ 1 minute. Savingit is 30 seconds, restoring 10 seconds - since we have many k8S jobs, this will be huge improvement"", 'created_at': datetime.datetime(2024, 12, 31, 17, 13, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566688958, 'issue_id': 2763084936, 'author': 'potiuk', 'body': 'Nice. 1m35 s -> 30s  for pre-commit environment.', 'created_at': datetime.datetime(2024, 12, 31, 20, 5, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-30 12:35:33 UTC): Looks like the stash action does not work exactly as advertised :)

gopidesupavan on (2024-12-30 12:38:33 UTC): think we need to set env variable name `head_name` https://github.com/apache/infrastructure-actions/blob/main/stash/restore/action.yml#L108

gopidesupavan on (2024-12-30 12:46:04 UTC): ah head_name is derived from github ref.

potiuk (Issue Creator) on (2024-12-30 14:22:28 UTC): Yeah - it seems that the action likely gets into a race condition, or does not work as advertised:

From: https://github.com/apache/infrastructure-actions/tree/main/stash#usage


It seems that we have error 409 conflict not handled (I tried with both override 'false' - there it fails obviously) and default `true` - and there it **should** work - but I think there is a race condition that when multiple jobs are trying to upload the same artifact - which is happening in our case - they get 409 conflict:

Error: Failed to CreateArtifact: Received non-retryable error: Failed request: (409) Conflict: an artifact with this name already exists on the workflow run

CC: @assignUser - is the right guess ?

potiuk (Issue Creator) on (2024-12-30 14:24:16 UTC): Evidently it tries with ""overwite: true"":

![image](https://github.com/user-attachments/assets/2936fedb-7c01-4e42-9fff-131b7aa1da29)

potiuk (Issue Creator) on (2024-12-30 14:27:08 UTC): If that's the right guess, then we might try to handle it somehow - since we don't care which uploaded artifact will be uploaded - we can actually even ignore 409 when it happens - without retrying it because it means that someone else managed to upload the artifact in parallel and they ""won"".

potiuk (Issue Creator) on (2024-12-30 14:27:59 UTC): cc: @assignUser - seems we are stressing your action to the limit :)

assignUser on (2024-12-30 15:09:35 UTC): Wow that's wild, haven't seen that before :D But that's an issue with the artifact backend, nothing really I can change in the action itself.

potiuk (Issue Creator) on (2024-12-30 19:44:24 UTC): Let's see... PRs might be coming :)

potiuk (Issue Creator) on (2024-12-30 22:15:47 UTC): FYI. @assignUser and @gopidesupavan -> seems that this is a well known ""feature"" of the `@v4` action that caused a number of users a problems when migrating to `@v4`. The proposed `solution` (which IMHO is just a workaround) is to upload each artifact with a different key and use ""merge-multiple"" feature and glob pattern to download and merge all such uploaded artifacts (!??!!#$@#%!%!$%!#%!)....

This is even explained here: https://github.com/actions/download-artifact/blob/main/docs/MIGRATION.md#multiple-uploads-to-the-same-named-artifact as solution.

https://github.com/actions/upload-artifact/issues/478

Example solution:  https://github.com/actions/upload-artifact/issues/478#issuecomment-1885470013

But stash does not use the download-artitact action and ""merge-multiple"" ... And I really do not like the ""solution"". .. So we wil have to come up with a different approach.

potiuk (Issue Creator) on (2024-12-30 22:52:06 UTC): OK. @assignUser and @gopidesupavan -> I think I found a solution (and actually this is a better one in general for performance, but slightly more ""distributed"" among the .yml files.

Instead of heaving a clear save/restore around installation, I only do:

* restore
* installl

And I make sure to have one separate job that is prerequisite of all other jobs (`build-info` which was already there as a single job that kicks-off the rest - for uv cache and `install-pre-commit` that is added as ""needs"" for all jobs that need the cache and those ""needs"" job are the only ones that upload the artifact. 

This way we get a little longer bootstrap, but then all the other jobs should use the cache uploaded by the prerequisite job. Plus the bootstrap will also use the artifact from previous runs (or target branch) if corresponding pyproject.toml / pre-commit config files did not change.

potiuk (Issue Creator) on (2024-12-31 00:13:01 UTC): Ha. TIL....

First of all It turns out that `uv` is DAMN FAST. I

Installing breeze with uv from scratch = 6s, just downloading breeze cache is 5s 

<img width=""826"" alt=""Screenshot 2024-12-31 at 00 42 24"" src=""https://github.com/user-attachments/assets/036c15a9-4789-432f-953c-a7f1d146cdb7"" />

Not mentioning upload delay.... So using cache for breeze makes no sense..

I expected a bit different numbers for ""pre-commit"" ... but... 

Installing all our pre-commits with uv from scratch = 1m45 s, uploading the resulting cache = 1m56 s (!) 

<img width=""774"" alt=""Screenshot 2024-12-31 at 00 31 14"" src=""https://github.com/user-attachments/assets/bc64adb9-94a3-4f18-b019-c2f14eeef4ec"" />

Downloading the artifact cache and installing pre-commit is ..... 2 m (!)

<img width=""761"" alt=""Screenshot 2024-12-31 at 00 33 01"" src=""https://github.com/user-attachments/assets/7ce9c3c5-90d6-4be2-b126-6ec78017e204"" />

But I think there is something wrong with cache restoration - not sure what though (yet):

The cache is downloaded in 30 seconds:

<img width=""1313"" alt=""Screenshot 2024-12-31 at 00 47 47"" src=""https://github.com/user-attachments/assets/ba523821-be1b-4ff1-bf86-0e6b35952682"" />

But then it takes almost as much time to install all pre-commits. Which I think is because we neeed both `uv` and  `pre-commit` cache. which means that I need to upload whole `~/.cache/` folder.... But... the problem is that this is a hidden file - and the stash action does not allow to pass `include-hidden-files` :( Need to contribute it..

potiuk (Issue Creator) on (2024-12-31 00:35:34 UTC): https://github.com/apache/infrastructure-actions/pull/81

potiuk (Issue Creator) on (2024-12-31 00:35:58 UTC): Also https://github.com/apache/infrastructure-actions/pull/82

potiuk (Issue Creator) on (2024-12-31 01:32:00 UTC): Ok. @assignUser @gopidesupavan -> I believe I also found out why caching did not speed up pre-commit. The problem was that `stash/restore` action (unlike download-artifact) did not expand `~` to home directory of the user - and this is where our cache is stored. 

Effectively the cache was restored to `~/.cache/` directory inside the checked out repository (with actual `~` as directory name) :( .. Took me a bit of time to figure it out.


Fix in https://github.com/apache/infrastructure-actions/pull/84

gopidesupavan on (2024-12-31 03:06:40 UTC): Oh yeah this is new breaking change they released with v4, actually i got to know this, when try different patterns for our trusted publisher faced this while upload files to artifact

gopidesupavan on (2024-12-31 03:07:32 UTC): good point make sense :)

gopidesupavan on (2024-12-31 03:09:26 UTC): interesting ... Yes absolutely UV is super fast , like they release new versions super fast ðŸ˜„

gopidesupavan on (2024-12-31 03:16:02 UTC): ah gotcha good find :)  and we always point `~/.cache/` so that path becomes after download `{github_workspace}~/.cache/`

potiuk (Issue Creator) on (2024-12-31 15:56:28 UTC): OK. I think i Implemented all workarounds to not have to wait for any of the `stash` action PRs I created, let's see what will be the savings now

potiuk (Issue Creator) on (2024-12-31 17:13:04 UTC): There is one more error with tar ... Pre-commit is currently stored with `/hom/runner` prefix, that's why it had no impact on the timing. 

But K8S is already hugely impactful -> instaling the venv + all the tools is ~ 1 minute. Savingit is 30 seconds, restoring 10 seconds - since we have many k8S jobs, this will be huge improvement

potiuk (Issue Creator) on (2024-12-31 20:05:31 UTC): Nice. 1m35 s -> 30s  for pre-commit environment.

"
2763053234,pull_request,closed,,Fix HTTP 500 error on updating same task instance state via FastAPI PATCH taskinstance/{task} endpoint,"During AIP-84 testing, we noticed an HTTP 500 error when providing the same task state for the FastAPI PATCH taskinstance/{task} endpoint.

In comparison, the legacy API does not exhibit this issue. Upon investigation, the failure occurs on this [line](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/core_api/routes/public/task_instances.py#L707). When the same state is provided, the [tis_altered](https://github.com/apache/airflow/blob/main/airflow/api/common/mark_tasks.py#L102) variable returns None, which results in [tis](https://github.com/apache/airflow/blob/main/airflow/api/common/mark_tasks.py#L102) also being None.

Further inspection revealed that [ti](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/core_api/routes/public/task_instances.py#L705) should actually be tis. Additionally, since HTTP 404 is already handled [here](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/core_api/routes/public/task_instances.py#L705), it would be more appropriate to raise an HTTP 409 error in this case.


<img width=""1159"" alt=""image"" src=""https://github.com/user-attachments/assets/c38161ac-2d18-4983-acc9-4423959d73d8"" />
<img width=""519"" alt=""image"" src=""https://github.com/user-attachments/assets/22bcd822-277d-4851-aca0-875b13c74974"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-30 11:16:25+00:00,[],2025-01-06 05:13:35+00:00,2025-01-06 05:13:33+00:00,https://github.com/apache/airflow/pull/45288,[],[],
2763048004,pull_request,closed,,Add from-job and from-pr option to breeze ci-image load,"closes: #45269 

follow up from #45266
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-30 11:12:27+00:00,[],2024-12-30 13:29:47+00:00,2024-12-30 13:29:40+00:00,https://github.com/apache/airflow/pull/45287,"[('area:dev-tools', '')]","[{'comment_id': 2565414262, 'issue_id': 2763048004, 'author': 'potiuk', 'body': 'Nice! One small nit', 'created_at': datetime.datetime(2024, 12, 30, 12, 20, 51, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-30 12:20:51 UTC): Nice! One small nit

"
2762964270,pull_request,closed,,Use existing mock_supervisor_comms fixture for tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

#45245 added a fixture and I missed while rebasing it with main. Adding it here.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-30 10:06:02+00:00,[],2024-12-30 12:56:07+00:00,2024-12-30 12:56:05+00:00,https://github.com/apache/airflow/pull/45284,"[('area:task-sdk', None)]",[],
2762958636,pull_request,closed,,Slight caching improvement in image building,"Packaging tools (uv and pip) do not have to use mounted cache as they are always reinstalled when their versions got updated in the Dockerfile, and changing sources of airflow does not invalidate the installation step (COPY . is made after the installation).

This will add two more layers being cached in github registry when the image is built.

Follow-up after #45266

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-30 10:01:22+00:00,[],2024-12-30 11:48:20+00:00,2024-12-30 11:48:19+00:00,https://github.com/apache/airflow/pull/45283,"[('area:dev-tools', '')]",[],
2762941519,pull_request,closed,,AIP-72: Handling SystemExit from task sdk,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


PR: #45106 provides a machinery to handle ""failure"" / ""retry"" states in the execution API server itself.

The aim of this PR is to extend to the ""SystemExit"" exception if thrown by tasks.


## Testing results

### DAG used (with and without retries):
```
import sys
from time import sleep

from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator


def print_hello():
    sleep(10)
    print(""exiting with code 10"")
    exit(10)

with DAG(
    dag_id=""exitcode"",
    schedule=None,
    catchup=False,
    tags=[""demo""],
) as dag:
    hello_task = PythonOperator(
        task_id=""exitcode-task"",
        retries=2,
        python_callable=print_hello,
    )
```

### Behaviour in legacy (non task sdk):

With retries configured
![image (8)](https://github.com/user-attachments/assets/ca7c1e6f-a1bc-479a-a1dd-3acaba3ead4d)
![image (9)](https://github.com/user-attachments/assets/3646f612-4410-47fe-a690-2ea2613ed5f8)

Without retries configured
<img width=""1719"" alt=""image"" src=""https://github.com/user-attachments/assets/76657e18-a3ec-47ef-b32f-eca351f8b7a3"" />
<img width=""1719"" alt=""image"" src=""https://github.com/user-attachments/assets/e66d4cb9-dbf0-468f-98cd-584128bd72ab"" />


### Behaviour in task sdk:

With retries configured
![image (10)](https://github.com/user-attachments/assets/15f98a5a-1d11-40fd-981f-e2f8876acc18)
![image (11)](https://github.com/user-attachments/assets/e58ef04e-ab53-4769-9507-47cffaf4efb7)

Without retries configured
<img width=""1719"" alt=""image"" src=""https://github.com/user-attachments/assets/b94be24e-75c4-4cbc-8aab-f020a4dc0a45"" />
<img width=""1719"" alt=""image"" src=""https://github.com/user-attachments/assets/00797a5a-5954-418b-b6b4-dcc5f9f61ff0"" />





<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-30 09:47:12+00:00,['amoghrajesh'],2024-12-30 16:00:04+00:00,2024-12-30 16:00:02+00:00,https://github.com/apache/airflow/pull/45282,"[('area:dev-tools', ''), ('area:task-sdk', None)]","[{'comment_id': 2565658200, 'issue_id': 2762941519, 'author': 'amoghrajesh', 'body': 'Merging this, its a simple one', 'created_at': datetime.datetime(2024, 12, 30, 15, 59, 58, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-30 15:59:58 UTC): Merging this, its a simple one

"
2762933093,pull_request,closed,,Skip building CI image when change does not touch python code,"In very simple changes we should skip building ci image altogether. This had been missing condition in one of the earlier refactors.

Follow-up after #45266

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-30 09:40:12+00:00,[],2024-12-30 10:01:37+00:00,2024-12-30 10:01:35+00:00,https://github.com/apache/airflow/pull/45281,"[('area:dev-tools', '')]","[{'comment_id': 2565247339, 'issue_id': 2762933093, 'author': 'potiuk', 'body': 'This will make things like https://github.com/apache/airflow/actions/runs/12544405502 build in seconds.', 'created_at': datetime.datetime(2024, 12, 30, 9, 42, 1, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-30 09:42:01 UTC): This will make things like https://github.com/apache/airflow/actions/runs/12544405502 build in seconds.

"
2762886074,pull_request,closed,,Fixing CI static checks due to #45278,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-30 09:00:53+00:00,[],2024-12-30 09:05:54+00:00,2024-12-30 09:05:54+00:00,https://github.com/apache/airflow/pull/45280,"[('area:dev-tools', '')]",[],
2762841094,pull_request,closed,,Extending task sdk loggers to handle non ascii characters,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

If we run a dag that emits non ascii characters in the task logs, the logger in task sdk runs into an exception that looks like this:
```
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-27T06:56:12.072210"",""event"":"""",""level"":""info""}
{""chan"":""stderr"",""event"":""--- Logging error ---"",""timestamp"":""2024-12-27T06:56:12.072312Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Traceback (most recent call last):"",""timestamp"":""2024-12-27T06:56:12.073263Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.12/site-packages/airflow/sdk/log.py\"", line 111, in emit"",""timestamp"":""2024-12-27T06:56:12.074470Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    msg = self.format(record)"",""timestamp"":""2024-12-27T06:56:12.074516Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""          ^^^^^^^^^^^^^^^^^^^"",""timestamp"":""2024-12-27T06:56:12.074527Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.12/logging/__init__.py\"", line 999, in format"",""timestamp"":""2024-12-27T06:56:12.074535Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return fmt.format(record)"",""timestamp"":""2024-12-27T06:56:12.074542Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""           ^^^^^^^^^^^^^^^^^^"",""timestamp"":""2024-12-27T06:56:12.074549Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.12/site-packages/structlog/stdlib.py\"", line 1098, in format"",""timestamp"":""2024-12-27T06:56:12.074555Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    ed = p(logger, meth_name, cast(EventDict, ed))"",""timestamp"":""2024-12-27T06:56:12.074562Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"",""timestamp"":""2024-12-27T06:56:12.074577Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.12/site-packages/airflow/sdk/log.py\"", line 205, in json_processor"",""timestamp"":""2024-12-27T06:56:12.074584Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return encoder.encode(event_dict).decode(\""ascii\"")"",""timestamp"":""2024-12-27T06:56:12.074590Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"",""timestamp"":""2024-12-27T06:56:12.074596Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 10: ordinal not in range(128)"",""timestamp"":""2024-12-27T06:56:12.074601Z"",""level"":""error"",""logger"":""task""}
```

### Internals:
- We use the `msgspec.json.Encoder()` encoder internally for task sdk log encoding.
```
In [5]: x
Out[5]: 'â†’ Get DAGs'
```

```
In [7]: encoder = msgspec.json.Encoder()

In [8]: encoder.encode(x)
Out[8]: b'""\xe2\x86\x92 Get DAGs""'
```

So, we just instead update the decode to `utf-8`.

### Testing:
Example DAG:
```
from airflow import DAG
from airflow.providers.standard.operators.bash import BashOperator

with DAG(
    ""unicode_logging_test"",
    schedule=None,
    catchup=False,
    tags=[""test"", ""unicode"", ""logging""],
) as dag:

    generate_unicode_logs = BashOperator(
        task_id=""generate_unicode_logs"",
        bash_command='echo ""This is a test log with non-ASCII characters: Ã©, Ã¼, æ¼¢å­—, ðŸ˜Š""',
    )

    generate_unicode_logs

```

Without changes, logs:
```
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2024-12-30T08:29:01.614531"",""event"":""Filling up the DagBag from /files/dags/non-ascii.py"",""level"":""info""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2024-12-30T08:29:01.615191"",""event"":""Importing /files/dags/non-ascii.py"",""level"":""debug""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2024-12-30T08:29:01.624665"",""event"":""Loaded DAG <DAG: unicode_logging_test>"",""level"":""debug""}
{""file"":""/files/dags/non-ascii.py"",""timestamp"":""2024-12-30T08:29:01.624924"",""logger"":""task"",""event"":""DAG file parsed"",""level"":""debug""}
{""json"":""{\""rendered_fields\"":{\""bash_command\"":\""echo \\\""This is a test log with non-ASCII characters: Ã©, Ã¼, æ¼¢å­—, ðŸ˜Š\\\""\"",\""env\"":null,\""cwd\"":null},\""type\"":\""SetRenderedFields\""}\n"",""timestamp"":""2024-12-30T08:29:01.625635"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""logger"":""airflow.task.operators.airflow.providers.standard.operators.bash.BashOperator"",""timestamp"":""2024-12-30T08:29:01.656412"",""event"":""BashOperator.execute cannot be called outside TaskInstance!"",""level"":""warning""}
{""logger"":""airflow.task.operators.airflow.providers.standard.operators.bash.BashOperator"",""timestamp"":""2024-12-30T08:29:01.656968"",""event"":""Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='unicode_logging_test' AIRFLOW_CTX_TASK_ID='generate_unicode_logs' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-30T08:29:01.038634+00:00'"",""level"":""debug""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:29:01.657464"",""event"":""Tmp dir root location: /tmp"",""level"":""info""}
{""chan"":""stderr"",""event"":""--- Logging error ---"",""timestamp"":""2024-12-30T08:29:01.657838Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Traceback (most recent call last):"",""timestamp"":""2024-12-30T08:29:01.658815Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/log.py\"", line 111, in emit"",""timestamp"":""2024-12-30T08:29:01.658911Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    msg = self.format(record)"",""timestamp"":""2024-12-30T08:29:01.658965Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 927, in format"",""timestamp"":""2024-12-30T08:29:01.659051Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return fmt.format(record)"",""timestamp"":""2024-12-30T08:29:01.659112Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/site-packages/structlog/stdlib.py\"", line 1098, in format"",""timestamp"":""2024-12-30T08:29:01.659217Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    ed = p(logger, meth_name, cast(EventDict, ed))"",""timestamp"":""2024-12-30T08:29:01.659314Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/log.py\"", line 205, in json_processor"",""timestamp"":""2024-12-30T08:29:01.659344Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return encoder.encode(event_dict).decode(\""ascii\"")"",""timestamp"":""2024-12-30T08:29:01.659403Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 105: ordinal not in range(128)"",""timestamp"":""2024-12-30T08:29:01.659473Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Call stack:"",""timestamp"":""2024-12-30T08:29:01.659534Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/bin/airflow\"", line 8, in <module>"",""timestamp"":""2024-12-30T08:29:01.663849Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    sys.exit(main())"",""timestamp"":""2024-12-30T08:29:01.663979Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/__main__.py\"", line 58, in main"",""timestamp"":""2024-12-30T08:29:01.664052Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    args.func(args)"",""timestamp"":""2024-12-30T08:29:01.664108Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/cli_config.py\"", line 49, in command"",""timestamp"":""2024-12-30T08:29:01.664234Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(*args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.664305Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/utils/cli.py\"", line 111, in wrapper"",""timestamp"":""2024-12-30T08:29:01.664366Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return f(*args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.664432Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/utils/providers_configuration_loader.py\"", line 55, in wrapped_function"",""timestamp"":""2024-12-30T08:29:01.664496Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(*args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.664557Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/scheduler_command.py\"", line 56, in scheduler"",""timestamp"":""2024-12-30T08:29:01.664623Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    run_command_with_daemon_option("",""timestamp"":""2024-12-30T08:29:01.664682Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/daemon_utils.py\"", line 86, in run_command_with_daemon_option"",""timestamp"":""2024-12-30T08:29:01.664747Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    callback()"",""timestamp"":""2024-12-30T08:29:01.664800Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/scheduler_command.py\"", line 59, in <lambda>"",""timestamp"":""2024-12-30T08:29:01.664883Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    callback=lambda: _run_scheduler_job(args),"",""timestamp"":""2024-12-30T08:29:01.664934Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/scheduler_command.py\"", line 45, in _run_scheduler_job"",""timestamp"":""2024-12-30T08:29:01.664972Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    run_job(job=job_runner.job, execute_callable=job_runner._execute)"",""timestamp"":""2024-12-30T08:29:01.665047Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/utils/session.py\"", line 101, in wrapper"",""timestamp"":""2024-12-30T08:29:01.665151Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(*args, session=session, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.665205Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/job.py\"", line 342, in run_job"",""timestamp"":""2024-12-30T08:29:01.665244Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return execute_job(job, execute_callable=execute_callable)"",""timestamp"":""2024-12-30T08:29:01.665325Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/job.py\"", line 371, in execute_job"",""timestamp"":""2024-12-30T08:29:01.665388Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    ret = execute_callable()"",""timestamp"":""2024-12-30T08:29:01.665415Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 953, in _execute"",""timestamp"":""2024-12-30T08:29:01.665449Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._run_scheduler_loop()"",""timestamp"":""2024-12-30T08:29:01.665524Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 1093, in _run_scheduler_loop"",""timestamp"":""2024-12-30T08:29:01.665588Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    num_queued_tis = self._do_scheduling(session)"",""timestamp"":""2024-12-30T08:29:01.665638Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 1241, in _do_scheduling"",""timestamp"":""2024-12-30T08:29:01.665685Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    num_queued_tis = self._critical_section_enqueue_task_instances(session=session)"",""timestamp"":""2024-12-30T08:29:01.665808Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 724, in _critical_section_enqueue_task_instances"",""timestamp"":""2024-12-30T08:29:01.665884Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._enqueue_task_instances_with_queued_state(queued_tis_per_executor, executor, session=session)"",""timestamp"":""2024-12-30T08:29:01.665934Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 653, in _enqueue_task_instances_with_queued_state"",""timestamp"":""2024-12-30T08:29:01.665968Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    executor.queue_workload(workload)"",""timestamp"":""2024-12-30T08:29:01.666038Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 246, in queue_workload"",""timestamp"":""2024-12-30T08:29:01.666109Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._check_workers()"",""timestamp"":""2024-12-30T08:29:01.666148Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 185, in _check_workers"",""timestamp"":""2024-12-30T08:29:01.666195Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._spawn_worker()"",""timestamp"":""2024-12-30T08:29:01.666275Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 197, in _spawn_worker"",""timestamp"":""2024-12-30T08:29:01.666364Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    p.start()"",""timestamp"":""2024-12-30T08:29:01.666406Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/process.py\"", line 121, in start"",""timestamp"":""2024-12-30T08:29:01.666440Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._popen = self._Popen(self)"",""timestamp"":""2024-12-30T08:29:01.666509Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/context.py\"", line 224, in _Popen"",""timestamp"":""2024-12-30T08:29:01.666596Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return _default_context.get_context().Process._Popen(process_obj)"",""timestamp"":""2024-12-30T08:29:01.666646Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/context.py\"", line 277, in _Popen"",""timestamp"":""2024-12-30T08:29:01.666675Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return Popen(process_obj)"",""timestamp"":""2024-12-30T08:29:01.666704Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/popen_fork.py\"", line 19, in __init__"",""timestamp"":""2024-12-30T08:29:01.666755Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._launch(process_obj)"",""timestamp"":""2024-12-30T08:29:01.666855Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/popen_fork.py\"", line 71, in _launch"",""timestamp"":""2024-12-30T08:29:01.666902Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    code = process_obj._bootstrap(parent_sentinel=child_r)"",""timestamp"":""2024-12-30T08:29:01.666957Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/process.py\"", line 315, in _bootstrap"",""timestamp"":""2024-12-30T08:29:01.667024Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.run()"",""timestamp"":""2024-12-30T08:29:01.667090Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/process.py\"", line 108, in run"",""timestamp"":""2024-12-30T08:29:01.667152Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._target(*self._args, **self._kwargs)"",""timestamp"":""2024-12-30T08:29:01.667303Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 92, in _run_worker"",""timestamp"":""2024-12-30T08:29:01.667380Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    _execute_work(log, workload)"",""timestamp"":""2024-12-30T08:29:01.667428Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 113, in _execute_work"",""timestamp"":""2024-12-30T08:29:01.667471Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    supervise("",""timestamp"":""2024-12-30T08:29:01.667552Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py\"", line 896, in supervise"",""timestamp"":""2024-12-30T08:29:01.667638Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    process = WatchedSubprocess.start(dag_path, ti, client=client, logger=logger)"",""timestamp"":""2024-12-30T08:29:01.667675Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py\"", line 345, in start"",""timestamp"":""2024-12-30T08:29:01.667721Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    _fork_main(child_stdin, child_stdout, child_stderr, child_logs.fileno(), target)"",""timestamp"":""2024-12-30T08:29:01.667787Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py\"", line 252, in _fork_main"",""timestamp"":""2024-12-30T08:29:01.667919Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    target()"",""timestamp"":""2024-12-30T08:29:01.667981Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py\"", line 134, in _subprocess_main"",""timestamp"":""2024-12-30T08:29:01.668052Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    main()"",""timestamp"":""2024-12-30T08:29:01.668120Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py\"", line 490, in main"",""timestamp"":""2024-12-30T08:29:01.668165Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    run(ti, log)"",""timestamp"":""2024-12-30T08:29:01.668194Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py\"", line 393, in run"",""timestamp"":""2024-12-30T08:29:01.668227Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    result = ti.task.execute(context)  # type: ignore[attr-defined]"",""timestamp"":""2024-12-30T08:29:01.668284Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/models/baseoperator.py\"", line 377, in wrapper"",""timestamp"":""2024-12-30T08:29:01.668354Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(self, *args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.668404Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/providers/src/airflow/providers/standard/operators/bash.py\"", line 265, in execute"",""timestamp"":""2024-12-30T08:29:01.668430Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    result = self._run_inline_command(bash_path=bash_path, env=env)"",""timestamp"":""2024-12-30T08:29:01.668464Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/providers/src/airflow/providers/standard/operators/bash.py\"", line 280, in _run_inline_command"",""timestamp"":""2024-12-30T08:29:01.668514Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return self.subprocess_hook.run_command("",""timestamp"":""2024-12-30T08:29:01.668581Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/providers/src/airflow/providers/standard/hooks/subprocess.py\"", line 88, in run_command"",""timestamp"":""2024-12-30T08:29:01.668627Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.log.info(\""Running command: %s\"", command)"",""timestamp"":""2024-12-30T08:29:01.668693Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 1446, in info"",""timestamp"":""2024-12-30T08:29:01.668739Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._log(INFO, msg, args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.668852Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 1589, in _log"",""timestamp"":""2024-12-30T08:29:01.668903Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.handle(record)"",""timestamp"":""2024-12-30T08:29:01.668934Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 1599, in handle"",""timestamp"":""2024-12-30T08:29:01.668969Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.callHandlers(record)"",""timestamp"":""2024-12-30T08:29:01.669020Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 1661, in callHandlers"",""timestamp"":""2024-12-30T08:29:01.669124Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    hdlr.handle(record)"",""timestamp"":""2024-12-30T08:29:01.669180Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 952, in handle"",""timestamp"":""2024-12-30T08:29:01.669223Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.emit(record)"",""timestamp"":""2024-12-30T08:29:01.669302Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/log.py\"", line 122, in emit"",""timestamp"":""2024-12-30T08:29:01.669371Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.handleError(record)"",""timestamp"":""2024-12-30T08:29:01.669418Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Message: 'Running command: %s'"",""timestamp"":""2024-12-30T08:29:01.669445Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Arguments: (['/usr/bin/bash', '-c', 'echo \""This is a test log with non-ASCII characters: Ã©, Ã¼, æ¼¢å­—, ðŸ˜Š\""'],)"",""timestamp"":""2024-12-30T08:29:01.669481Z"",""level"":""error"",""logger"":""task""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:29:01.670357"",""event"":""Output:"",""level"":""info""}
{""chan"":""stderr"",""event"":""--- Logging error ---"",""timestamp"":""2024-12-30T08:29:01.672321Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Traceback (most recent call last):"",""timestamp"":""2024-12-30T08:29:01.672481Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/log.py\"", line 111, in emit"",""timestamp"":""2024-12-30T08:29:01.672544Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    msg = self.format(record)"",""timestamp"":""2024-12-30T08:29:01.672597Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/logging/__init__.py\"", line 927, in format"",""timestamp"":""2024-12-30T08:29:01.672670Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return fmt.format(record)"",""timestamp"":""2024-12-30T08:29:01.672744Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/site-packages/structlog/stdlib.py\"", line 1098, in format"",""timestamp"":""2024-12-30T08:29:01.672791Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    ed = p(logger, meth_name, cast(EventDict, ed))"",""timestamp"":""2024-12-30T08:29:01.672838Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/log.py\"", line 205, in json_processor"",""timestamp"":""2024-12-30T08:29:01.672897Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return encoder.encode(event_dict).decode(\""ascii\"")"",""timestamp"":""2024-12-30T08:29:01.673016Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 56: ordinal not in range(128)"",""timestamp"":""2024-12-30T08:29:01.673073Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""Call stack:"",""timestamp"":""2024-12-30T08:29:01.673128Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/bin/airflow\"", line 8, in <module>"",""timestamp"":""2024-12-30T08:29:01.673205Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    sys.exit(main())"",""timestamp"":""2024-12-30T08:29:01.673293Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/__main__.py\"", line 58, in main"",""timestamp"":""2024-12-30T08:29:01.673478Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    args.func(args)"",""timestamp"":""2024-12-30T08:29:01.673818Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/cli_config.py\"", line 49, in command"",""timestamp"":""2024-12-30T08:29:01.674222Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(*args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.674334Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/utils/cli.py\"", line 111, in wrapper"",""timestamp"":""2024-12-30T08:29:01.674514Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return f(*args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.674679Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/utils/providers_configuration_loader.py\"", line 55, in wrapped_function"",""timestamp"":""2024-12-30T08:29:01.674918Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(*args, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.674972Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/scheduler_command.py\"", line 56, in scheduler"",""timestamp"":""2024-12-30T08:29:01.675059Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    run_command_with_daemon_option("",""timestamp"":""2024-12-30T08:29:01.675459Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/daemon_utils.py\"", line 86, in run_command_with_daemon_option"",""timestamp"":""2024-12-30T08:29:01.675508Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    callback()"",""timestamp"":""2024-12-30T08:29:01.675645Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/scheduler_command.py\"", line 59, in <lambda>"",""timestamp"":""2024-12-30T08:29:01.675680Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    callback=lambda: _run_scheduler_job(args),"",""timestamp"":""2024-12-30T08:29:01.675720Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/cli/commands/local_commands/scheduler_command.py\"", line 45, in _run_scheduler_job"",""timestamp"":""2024-12-30T08:29:01.675842Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    run_job(job=job_runner.job, execute_callable=job_runner._execute)"",""timestamp"":""2024-12-30T08:29:01.675907Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/utils/session.py\"", line 101, in wrapper"",""timestamp"":""2024-12-30T08:29:01.675972Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return func(*args, session=session, **kwargs)"",""timestamp"":""2024-12-30T08:29:01.676137Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/job.py\"", line 342, in run_job"",""timestamp"":""2024-12-30T08:29:01.676246Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return execute_job(job, execute_callable=execute_callable)"",""timestamp"":""2024-12-30T08:29:01.676371Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/job.py\"", line 371, in execute_job"",""timestamp"":""2024-12-30T08:29:01.676424Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    ret = execute_callable()"",""timestamp"":""2024-12-30T08:29:01.676507Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 953, in _execute"",""timestamp"":""2024-12-30T08:29:01.676574Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._run_scheduler_loop()"",""timestamp"":""2024-12-30T08:29:01.676663Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 1093, in _run_scheduler_loop"",""timestamp"":""2024-12-30T08:29:01.676708Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    num_queued_tis = self._do_scheduling(session)"",""timestamp"":""2024-12-30T08:29:01.676748Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 1241, in _do_scheduling"",""timestamp"":""2024-12-30T08:29:01.676813Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    num_queued_tis = self._critical_section_enqueue_task_instances(session=session)"",""timestamp"":""2024-12-30T08:29:01.676886Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 724, in _critical_section_enqueue_task_instances"",""timestamp"":""2024-12-30T08:29:01.676928Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._enqueue_task_instances_with_queued_state(queued_tis_per_executor, executor, session=session)"",""timestamp"":""2024-12-30T08:29:01.676958Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/jobs/scheduler_job_runner.py\"", line 653, in _enqueue_task_instances_with_queued_state"",""timestamp"":""2024-12-30T08:29:01.677029Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    executor.queue_workload(workload)"",""timestamp"":""2024-12-30T08:29:01.677093Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 246, in queue_workload"",""timestamp"":""2024-12-30T08:29:01.677131Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._check_workers()"",""timestamp"":""2024-12-30T08:29:01.677180Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 185, in _check_workers"",""timestamp"":""2024-12-30T08:29:01.677255Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._spawn_worker()"",""timestamp"":""2024-12-30T08:29:01.677424Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 197, in _spawn_worker"",""timestamp"":""2024-12-30T08:29:01.677494Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    p.start()"",""timestamp"":""2024-12-30T08:29:01.677553Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/process.py\"", line 121, in start"",""timestamp"":""2024-12-30T08:29:01.677596Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._popen = self._Popen(self)"",""timestamp"":""2024-12-30T08:29:01.677652Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/context.py\"", line 224, in _Popen"",""timestamp"":""2024-12-30T08:29:01.677737Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return _default_context.get_context().Process._Popen(process_obj)"",""timestamp"":""2024-12-30T08:29:01.677779Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/context.py\"", line 277, in _Popen"",""timestamp"":""2024-12-30T08:29:01.677824Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    return Popen(process_obj)"",""timestamp"":""2024-12-30T08:29:01.677892Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/popen_fork.py\"", line 19, in __init__"",""timestamp"":""2024-12-30T08:29:01.677965Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._launch(process_obj)"",""timestamp"":""2024-12-30T08:29:01.678050Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/popen_fork.py\"", line 71, in _launch"",""timestamp"":""2024-12-30T08:29:01.678129Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    code = process_obj._bootstrap(parent_sentinel=child_r)"",""timestamp"":""2024-12-30T08:29:01.678238Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/process.py\"", line 315, in _bootstrap"",""timestamp"":""2024-12-30T08:29:01.678345Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self.run()"",""timestamp"":""2024-12-30T08:29:01.678389Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/usr/local/lib/python3.9/multiprocessing/process.py\"", line 108, in run"",""timestamp"":""2024-12-30T08:29:01.678462Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    self._target(*self._args, **self._kwargs)"",""timestamp"":""2024-12-30T08:29:01.678535Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 92, in _run_worker"",""timestamp"":""2024-12-30T08:29:01.678572Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    _execute_work(log, workload)"",""timestamp"":""2024-12-30T08:29:01.678625Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/airflow/executors/local_executor.py\"", line 113, in _execute_work"",""timestamp"":""2024-12-30T08:29:01.678693Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    supervise("",""timestamp"":""2024-12-30T08:29:01.678776Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py\"", line 896, in supervise"",""timestamp"":""2024-12-30T08:29:01.678830Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""    process = WatchedSubprocess.start(dag_path, ti, client=client, logger=logger)"",""timestamp"":""2024-12-30T08:29:01.678874Z"",""level"":""error"",""logger"":""task""}
{""chan"":""stderr"",""event"":""  File \""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py\"", line 345, in start"",""timestamp"":""2024-12-30T08:29:01.678947Z"",""level"":""error"",""logger"":""task""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:29:01.673033"",""event"":""Command exited with return code 0"",""level"":""info""}
{""json"":""{\""key\"":\""return_value\"",\""value\"":\""\\\""This is a test log with non-ASCII characters: \\\\u00e9, \\\\u00fc, \\\\u6f22\\\\u5b57, \\\\ud83d\\\\ude0a\\\""\"",\""dag_id\"":\""unicode_logging_test\"",\""run_id\"":\""manual__2024-12-30T08:29:01.038634+00:00\"",\""task_id\"":\""generate_unicode_logs\"",\""map_index\"":null,\""type\"":\""SetXCom\""}\n"",""timestamp"":""2024-12-30T08:29:01.673960"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""json"":""{\""state\"":\""success\"",\""end_date\"":\""2024-12-30T08:29:01.674161Z\"",\""type\"":\""TaskState\""}\n"",""timestamp"":""2024-12-30T08:29:01.674351"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```

With changes, logs:
```
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2024-12-30T08:26:02.798717"",""event"":""Filling up the DagBag from /files/dags/non-ascii.py"",""level"":""info""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2024-12-30T08:26:02.799734"",""event"":""Importing /files/dags/non-ascii.py"",""level"":""debug""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2024-12-30T08:26:02.815459"",""event"":""Loaded DAG <DAG: unicode_logging_test>"",""level"":""debug""}
{""file"":""/files/dags/non-ascii.py"",""timestamp"":""2024-12-30T08:26:02.815916"",""logger"":""task"",""event"":""DAG file parsed"",""level"":""debug""}
{""json"":""{\""rendered_fields\"":{\""bash_command\"":\""echo \\\""This is a test log with non-ASCII characters: Ã©, Ã¼, æ¼¢å­—, ðŸ˜Š\\\""\"",\""env\"":null,\""cwd\"":null},\""type\"":\""SetRenderedFields\""}\n"",""timestamp"":""2024-12-30T08:26:02.816578"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""logger"":""airflow.task.operators.airflow.providers.standard.operators.bash.BashOperator"",""timestamp"":""2024-12-30T08:26:02.841691"",""event"":""BashOperator.execute cannot be called outside TaskInstance!"",""level"":""warning""}
{""logger"":""airflow.task.operators.airflow.providers.standard.operators.bash.BashOperator"",""timestamp"":""2024-12-30T08:26:02.842139"",""event"":""Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='unicode_logging_test' AIRFLOW_CTX_TASK_ID='generate_unicode_logs' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-30T08:25:13.497632+00:00'"",""level"":""debug""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:26:02.842428"",""event"":""Tmp dir root location: /tmp"",""level"":""info""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:26:02.842670"",""event"":""Running command: ['/usr/bin/bash', '-c', 'echo \""This is a test log with non-ASCII characters: Ã©, Ã¼, æ¼¢å­—, ðŸ˜Š\""']"",""level"":""info""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:26:02.848839"",""event"":""Output:"",""level"":""info""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:26:02.849667"",""event"":""This is a test log with non-ASCII characters: Ã©, Ã¼, æ¼¢å­—, ðŸ˜Š"",""level"":""info""}
{""logger"":""airflow.task.hooks.airflow.providers.standard.hooks.subprocess.SubprocessHook"",""timestamp"":""2024-12-30T08:26:02.849786"",""event"":""Command exited with return code 0"",""level"":""info""}
{""json"":""{\""key\"":\""return_value\"",\""value\"":\""\\\""This is a test log with non-ASCII characters: \\\\u00e9, \\\\u00fc, \\\\u6f22\\\\u5b57, \\\\ud83d\\\\ude0a\\\""\"",\""dag_id\"":\""unicode_logging_test\"",\""run_id\"":\""manual__2024-12-30T08:25:13.497632+00:00\"",\""task_id\"":\""generate_unicode_logs\"",\""map_index\"":null,\""type\"":\""SetXCom\""}\n"",""timestamp"":""2024-12-30T08:26:02.850431"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""json"":""{\""state\"":\""success\"",\""end_date\"":\""2024-12-30T08:26:02.850521Z\"",\""type\"":\""TaskState\""}\n"",""timestamp"":""2024-12-30T08:26:02.850626"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-30 08:29:25+00:00,['amoghrajesh'],2024-12-30 10:14:00+00:00,2024-12-30 10:13:59+00:00,https://github.com/apache/airflow/pull/45279,"[('area:task-sdk', None)]",[],
2762802497,pull_request,closed,,Re-enable cache for scheduiled builds,"The scheduled builds had cache set to ""disabled"". This PR restores the cache back to use regular cache for them. Historically scheduled builds were using cache but they were not uploading it - this has changed, but cache remained disabled for them. This has been somewhat masked by the UV speed but also caused unnecessary rebuilds of local docker images.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-30 07:51:23+00:00,[],2024-12-30 08:05:11+00:00,2024-12-30 08:05:10+00:00,https://github.com/apache/airflow/pull/45278,"[('area:dev-tools', '')]","[{'comment_id': 2565135961, 'issue_id': 2762802497, 'author': 'potiuk', 'body': 'Follow up after #45266', 'created_at': datetime.datetime(2024, 12, 30, 7, 52, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-30 07:52:31 UTC): Follow up after #45266

"
2762703279,pull_request,closed,,Fixing some nits in 01_ci_environment.md,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fixing my own nits on https://github.com/apache/airflow/pull/45266

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-30 06:14:04+00:00,[],2024-12-30 07:57:39+00:00,2024-12-30 07:57:39+00:00,https://github.com/apache/airflow/pull/45277,"[('area:dev-tools', '')]",[],
2762563785,pull_request,closed,,Add task instance details for each run,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:



How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #44668

<img width=""722"" alt=""Screenshot 2024-12-29 at 8 16 46â€¯PM"" src=""https://github.com/user-attachments/assets/de9c6de1-c1d7-43aa-9ae6-186ecb2fae38"" />

<img width=""722"" alt=""Screenshot 2024-12-29 at 8 16 49â€¯PM"" src=""https://github.com/user-attachments/assets/2599d4e1-a31a-4651-9e36-2ded389200a4"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dauinh,2024-12-30 02:26:41+00:00,[],2025-01-03 18:16:08+00:00,2025-01-03 10:05:30+00:00,https://github.com/apache/airflow/pull/45273,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566759919, 'issue_id': 2762563785, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 2, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568533078, 'issue_id': 2762563785, 'author': 'dauinh', 'body': 'I have rebased, made changes and run pre-commit checks as request, thank you!', 'created_at': datetime.datetime(2025, 1, 2, 23, 54, 35, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-01 00:02:10 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

dauinh (Issue Creator) on (2025-01-02 23:54:35 UTC): I have rebased, made changes and run pre-commit checks as request, thank you!

"
2762391736,pull_request,closed,,Bump uv to 0.5.11 (#45105),cherry-pick of https://github.com/apache/airflow/pull/45105,raphaelauv,2024-12-29 20:15:35+00:00,[],2024-12-29 22:22:14+00:00,2024-12-29 20:55:19+00:00,https://github.com/apache/airflow/pull/45272,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2762314765,pull_request,closed,,Migrate trigger form params to new UI,"After @shubhamraj-git has added the trigger form to the new React UI, this PR now adds the flexible trigger form - Based on the logic of the former AIP-50 implementation - using DAG ParamsDict to render form fields based on field definitions.

Note that the form rendering was made as a component by intent as it will be re-used in Connection Forms in future to render connection extra fields.

To test the form rendering the following DAGs might be good candidates:
- `example_bash_decorator` - has no params so should not display a specific form 
![image](https://github.com/user-attachments/assets/1ffb9ffc-f2a5-4152-8ba1-f9375892e233)

- `example_bash_operator` - has one basic parameter w/o any special thing. Simple as it can be 
![image](https://github.com/user-attachments/assets/afa627b9-3bcd-4599-b1ce-343c11dcc67c)

- `example_params_trigger_ui` - has 4 parameters, still basic 
![image](https://github.com/user-attachments/assets/428bf971-0d09-408a-94c1-6bbc812852f1)
 ... and with advanced section un-folded: 
![image](https://github.com/user-attachments/assets/489a7c46-4651-45c5-be79-9607ca027854)

- `example_params_ui_tutorial` - this is the most complex beast as it has all features as a demo that shall be supported. 
![image](https://github.com/user-attachments/assets/8a462ee1-c081-4d87-924b-5c00d370b4f1)
![image](https://github.com/user-attachments/assets/aab56f59-e694-4c4c-a3da-37acd71fc85d)
...and the lower section un-folded: 
![image](https://github.com/user-attachments/assets/b30d8da5-263b-4b9d-9b8e-f1c298992e67)


Scope of the PR is the UI layout and logic to render. What is missing and will be a follow-up PR is the binding and sync of the form field content with the JSON dict that is used to trigger the DAG in the ""Advanced Options"" section.",jscheffl,2024-12-29 16:16:15+00:00,[],2025-01-27 12:48:29+00:00,2025-01-16 15:51:34+00:00,https://github.com/apache/airflow/pull/45270,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-50', 'Trigger DAG UI user Form')]","[{'comment_id': 2565833235, 'issue_id': 2762314765, 'author': 'shubhamraj-git', 'body': ""Thanks @jscheffl for working on this.\r\nHad the first look. Looks great. The base is almost ready.\r\n\r\nAs mentioned in TODO, we will support the accordion and not flat.\r\n\r\nSome points which i noticed, just writing it down incase we don't miss.\r\n1. There is no live changes to conf json onBlur\r\n2. Should have a validation for integer inputs.\r\n3. Dropdown not working for select values\r\n4. we should have a time picker.\r\n5. Length check not working\r\n~6. JSON inputs should have a code view? (Just a opinion)~\r\n7. List should have multi lines\r\n\r\nOverall this is going in right direction.\r\n\r\nShould we have inbuilt scroll for the dynamic form? since the modal seems very long.\r\n\r\nEDIT: Just saw a todo for point 6 (json code view) and most of the above issues as todo."", 'created_at': datetime.datetime(2024, 12, 30, 19, 16, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567986116, 'issue_id': 2762314765, 'author': 'jscheffl', 'body': '> Thanks @jscheffl for working on this. Had the first look. Looks great. The base is almost ready.\r\n> \r\n> As mentioned in TODO, we will support the accordion and not flat.\r\n> \r\n> Some points which i noticed, just writing it down incase we don\'t miss.\r\n> \r\n>     1. There is no live changes to conf json onBlur\r\n>     2. Should have a validation for integer inputs.\r\n>     3. Dropdown not working for select values\r\n>     4. we should have a time picker.\r\n>     5. Length check not working\r\n>        ~6. JSON inputs should have a code view? (Just a opinion)~\r\n>     6. List should have multi lines\r\n> \r\n> \r\n> Overall this is going in right direction.\r\n> \r\n> Should we have inbuilt scroll for the dynamic form? since the modal seems very long.\r\n> \r\n> EDIT: Just saw a todo for point 6 (json code view) and most of the above issues as todo.\r\n\r\n(1) I recommend to make into a separate PR - as also discussed 1:1\r\n(2,3,5,6) fixed.\r\n(4) would need a component fix in react for Chrome... and a workaround for Firefox. Firfox time picking is ""just broken"" - would make this to a separate PR as well.\r\n\r\nSo... for the Layout part I\'d say... ready for review!', 'created_at': datetime.datetime(2025, 1, 2, 15, 52, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585391171, 'issue_id': 2762314765, 'author': 'jscheffl', 'body': 'Had a few ""sleeps"" over the discussion I had in Slack with @shubhamraj-git about Accordion.. and after Pierre also assigned it to the Note for Clear tasks... I am somewhat open and ajusted... as forms can get long. All is not (last commit) in one accordion group. Looks like this and parts are nicely folding:\r\n\r\n![image](https://github.com/user-attachments/assets/f39c2a4d-94bc-4591-9dc8-3fa3a3a5d857)\r\n\r\nChanging to Advanced options:\r\n\r\n![image](https://github.com/user-attachments/assets/c56f7ee1-7af2-49a1-8d14-0b11595e686d)\r\n\r\nWDYT?', 'created_at': datetime.datetime(2025, 1, 11, 19, 58, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585742519, 'issue_id': 2762314765, 'author': 'jscheffl', 'body': 'Hi @bbovenzi I aligned in Slack with @shubhamraj-git that he would take the ""wire-up"" of reset-button and sync of form fields <-> Advanced Options JSON in a follow up PR the next days. So this PR is mainly the general component start and layout, function coming in the next PR.\r\n\r\nWould it be OK frmo point of code/layout/structure mo merge? Then would need your review/approval.', 'created_at': datetime.datetime(2025, 1, 12, 13, 48, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591265505, 'issue_id': 2762314765, 'author': 'jscheffl', 'body': ""> Sorry this took me a bit to review.\r\n> \r\n> Now I see how sections work with the accordions so ignore my previous comment.\r\n> \r\n> It is a bit of a nitpick, but coudl we rename the field components? Along the lines of `NumberInput` instead of `FieldNumber`?\r\n> \r\n> I'm excited we're finally able to migrate all of this to react! Great work!\r\n\r\nUff, this was a very good review! Learned something new. I assume now it needs a second iteration review from the rework...\r\nHad some challenges with the `flex-basis` - which is much cleaner in your proposal... but somehow not working. Any idea why?"", 'created_at': datetime.datetime(2025, 1, 14, 22, 48, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594123650, 'issue_id': 2762314765, 'author': 'jscheffl', 'body': '> Found two things with the datetime field.\r\n> \r\n> Also, did you see my comment on renaming the Fields and NormalRow?\r\n\r\nNext round of reviews applied.\r\nSaw the request to rename ""NormalRow"" ... renamed it to proposed ""FieldRow"" - is this OK?\r\nThe other comment about renaming the Fields... I did not understand. Can you help me what you wanted me to rename to?', 'created_at': datetime.datetime(2025, 1, 15, 23, 11, 46, tzinfo=datetime.timezone.utc)}]","shubhamraj-git on (2024-12-30 19:16:13 UTC): Thanks @jscheffl for working on this.
Had the first look. Looks great. The base is almost ready.

As mentioned in TODO, we will support the accordion and not flat.

Some points which i noticed, just writing it down incase we don't miss.
1. There is no live changes to conf json onBlur
2. Should have a validation for integer inputs.
3. Dropdown not working for select values
4. we should have a time picker.
5. Length check not working
~6. JSON inputs should have a code view? (Just a opinion)~
7. List should have multi lines

Overall this is going in right direction.

Should we have inbuilt scroll for the dynamic form? since the modal seems very long.

EDIT: Just saw a todo for point 6 (json code view) and most of the above issues as todo.

jscheffl (Issue Creator) on (2025-01-02 15:52:10 UTC): (1) I recommend to make into a separate PR - as also discussed 1:1
(2,3,5,6) fixed.
(4) would need a component fix in react for Chrome... and a workaround for Firefox. Firfox time picking is ""just broken"" - would make this to a separate PR as well.

So... for the Layout part I'd say... ready for review!

jscheffl (Issue Creator) on (2025-01-11 19:58:30 UTC): Had a few ""sleeps"" over the discussion I had in Slack with @shubhamraj-git about Accordion.. and after Pierre also assigned it to the Note for Clear tasks... I am somewhat open and ajusted... as forms can get long. All is not (last commit) in one accordion group. Looks like this and parts are nicely folding:

![image](https://github.com/user-attachments/assets/f39c2a4d-94bc-4591-9dc8-3fa3a3a5d857)

Changing to Advanced options:

![image](https://github.com/user-attachments/assets/c56f7ee1-7af2-49a1-8d14-0b11595e686d)

WDYT?

jscheffl (Issue Creator) on (2025-01-12 13:48:31 UTC): Hi @bbovenzi I aligned in Slack with @shubhamraj-git that he would take the ""wire-up"" of reset-button and sync of form fields <-> Advanced Options JSON in a follow up PR the next days. So this PR is mainly the general component start and layout, function coming in the next PR.

Would it be OK frmo point of code/layout/structure mo merge? Then would need your review/approval.

jscheffl (Issue Creator) on (2025-01-14 22:48:31 UTC): Uff, this was a very good review! Learned something new. I assume now it needs a second iteration review from the rework...
Had some challenges with the `flex-basis` - which is much cleaner in your proposal... but somehow not working. Any idea why?

jscheffl (Issue Creator) on (2025-01-15 23:11:46 UTC): Next round of reviews applied.
Saw the request to rename ""NormalRow"" ... renamed it to proposed ""FieldRow"" - is this OK?
The other comment about renaming the Fields... I did not understand. Can you help me what you wanted me to rename to?

"
2762255219,pull_request,closed,,Update Cohere to 5.13.4 v2 API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Relates to: #38465
closes: #38349
closes: #45271

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",okirialbert,2024-12-29 13:36:10+00:00,[],2024-12-30 01:45:22+00:00,2024-12-29 20:44:01+00:00,https://github.com/apache/airflow/pull/45267,"[('area:providers', ''), ('provider:cohere', '')]",[],
2762218891,pull_request,closed,,Simplify caching mechanisms for CI and PROD images (canary),"For a long time we had used a sophisticated mechanism to speed up our CI jobs by building the images in ""pull_request_target"" workflow and pushing them to GitHub registry. That however had several drawbacks:

* CI image was complex when it comes to layer setup (we had to pre- cache installed dependencies by installing them from branch tip

* The pull_request_target is a very dangerous workflow, we had a number of security problems with it (and it's difficult to debug)

* Caching of `pip` and `uv` was not used because it increased size of the image significantly

This PR significantly improves the caching mechanisms for the images building of several advacements that were not possible before:

* The upload-artifacts@v4 action and improved stash action developed by @assignUser and published in ""apache/infrastructure-actions"" allows us to store all images (8GB per run) in artifacts rather than in registry - so we can do the image build once and share it with all the jobs.

* The uv speed is ""enough"" to allow occasional installation of Airlfow locally. This allows to utilize cache-mount and locally build uv cache, rather than rely on ""remote"" cache when we are building local images for breeze. The first time you build local breeze image it will take 2-5 more minutes (depending on your network speed, but because we can utilise cache mounts, every subsequent build should be very fast - even if all dependencies change. Using uv also allows to ""always"" reinstall airflow when you build the image even if single source file changed, because with cache it takes sub-seconds to reinstall airflow and all dependencies.

* the cache mounts are not included in the image size, and since we can export and import images in CI in artifacts and we do not need to rebuild them, the images shared as compressed artifacts are relatively small (2GB) - cache of `uv` is around 4GB on top of that so sharing image built in the ""build image"" job with other jobs in the same workflow is fast.

* we are still using registry cache for the ""non-python"" parts of the image - both CI and breeze image build speed benefit from using the image cache for system dependencies, database clients etc.

* documentation has been updated to reflect the new CI setup. The  diagrams showing the workflows of ours are no longer needed as the workflows are quite straightforward when they are looked at.

Fixes: #42999
Fixes: #43268

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-29 11:51:53+00:00,[],2025-01-11 19:41:22+00:00,2024-12-29 21:58:27+00:00,https://github.com/apache/airflow/pull/45266,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('canary', 'When set on PR running from apache repo - behave as canary run'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2564767939, 'issue_id': 2762218891, 'author': 'potiuk', 'body': 'I still have some tests to fix, but this one should be generally ready to review. There is a corresponding #45261 ""regular PR"" (this is canary build equivalent).\r\n\r\nIt should be **HUGE** simplificaiton of our CI workflows and Dockerfile -> and huge improvement in security - as we are getting rid of the `pull_request_target` workflow.\r\n\r\nI am planning to backport that one to `v2-10-test` and `providers-fab/v1-5` so that we will be able to get rid of the `pull_request_target` workflows altogether.', 'created_at': datetime.datetime(2024, 12, 29, 16, 3, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564769349, 'issue_id': 2762218891, 'author': 'potiuk', 'body': 'I added comments/conversations explainining some detailed reasoning for the changes. The change is huge (of course) - and sorry for that size, but I could not really make it smaller. I separated two folow-ups that do not need to be added now in this PR:\r\n\r\n* https://github.com/apache/airflow/issues/45268\r\n* https://github.com/apache/airflow/issues/45269\r\n\r\nbut all the rest is essentially ""needed"" as single PR.', 'created_at': datetime.datetime(2024, 12, 29, 16, 7, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564790472, 'issue_id': 2762218891, 'author': 'jscheffl', 'body': 'Oh, this is BIG. How much time do you give me/us to review? Are we in a hurry?', 'created_at': datetime.datetime(2024, 12, 29, 17, 29, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564802583, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> Oh, this is BIG. How much time do you give me/us to review? Are we in a hurry?\r\n\r\nNot THAT big - most of it is generated images/hashes and removal of some parts of the workflow that are not used any more. There is no ""huge"" hurry with merging it but this one will all also fix some of the current caching issues (i.e. fixing #42999 ) -> so also local breeze dev env should be quite a bit snappier to rebuild images locally. So the sooner - the better :)', 'created_at': datetime.datetime(2024, 12, 29, 18, 10, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564804750, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> One question-> does the PR workflow build uses cache? from where it uses is it from github registry?\r\n\r\nPRs are using cache from the artifacts. If you look at the `ci-image-build.xml`, we are attempting to download the cached artifact image and load it to the registry (the load command will only run when ""stash/restore"" command will have a cache hit:\r\n\r\n```yaml\r\n      - name: ""Restore CI docker image ${{ inputs.platform }}:${{ env.PYTHON_MAJOR_MINOR_VERSION }}""\r\n        uses: apache/infrastructure-actions/stash/restore@c94b890bbedc2fc61466d28e6bd9966bc6c6643c\r\n        with:\r\n          key: ""ci-image-save-${{ inputs.platform }}-${{ env.PYTHON_MAJOR_MINOR_VERSION }}""\r\n          path: ""/tmp/""\r\n        id: restore-ci-image\r\n      - name: ""Load CI image ${{ inputs.platform }}:${{ env.PYTHON_MAJOR_MINOR_VERSION }}""\r\n        run: breeze ci-image load --platform ${{ inputs.platform }}\r\n        shell: bash\r\n        if: steps.restore-ci-image.stash-hit == \'true\'\r\n```\r\n\r\nThis is the nice thing with using `stash` action - because it will download artifacts ""up"" the hierarchy when it finds it (see https://github.com/apache/infrastructure-actions/tree/main/stash#features) \r\n\r\n1) It will try to attempt to find cache in current workflow  (it will not find any because we have not built an image yet)\r\n2) It will look for cache in previous action runs of the current branch (which means that even if you modify Dockerfile or other scripts, the cached image uploaded in previous run of your PR will be used subsequent runs of the same PR within 2 days should be faster\r\n3) If it does not find it (first time you run your PR) - it will look for the same artifact in the target branch (`main` or `v-*-test`)   - which will be the last ""canary"" built image\r\n\r\nWhich is EXACTLY what we need.', 'created_at': datetime.datetime(2024, 12, 29, 18, 20, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564814190, 'issue_id': 2762218891, 'author': 'gopidesupavan', 'body': '> > One question-> does the PR workflow build uses cache? from where it uses is it from github registry?\r\n> \r\n> PRs are using cache from the artifacts. If you look at the `ci-image-build.xml`, we are attempting to download the cached artifact image and load it to the registry (the load command will only run when ""stash/restore"" command will have a cache hit:\r\n> \r\n> ```yaml\r\n>       - name: ""Restore CI docker image ${{ inputs.platform }}:${{ env.PYTHON_MAJOR_MINOR_VERSION }}""\r\n>         uses: apache/infrastructure-actions/stash/restore@c94b890bbedc2fc61466d28e6bd9966bc6c6643c\r\n>         with:\r\n>           key: ""ci-image-save-${{ inputs.platform }}-${{ env.PYTHON_MAJOR_MINOR_VERSION }}""\r\n>           path: ""/tmp/""\r\n>         id: restore-ci-image\r\n>       - name: ""Load CI image ${{ inputs.platform }}:${{ env.PYTHON_MAJOR_MINOR_VERSION }}""\r\n>         run: breeze ci-image load --platform ${{ inputs.platform }}\r\n>         shell: bash\r\n>         if: steps.restore-ci-image.stash-hit == \'true\'\r\n> ```\r\n> \r\n> This is the nice thing with using `stash` action - because it will download artifacts ""up"" the hierarchy when it finds it (see https://github.com/apache/infrastructure-actions/tree/main/stash#features)\r\n> \r\n> 1. It will try to attempt to find cache in current workflow  (it will not find any because we have not built an image yet)\r\n> 2. It will look for cache in previous action runs of the current branch (which means that even if you modify Dockerfile or other scripts, the cached image uploaded in previous run of your PR will be used subsequent runs of the same PR within 2 days should be faster\r\n> 3. If it does not find it (first time you run your PR) - it will look for the same artifact in the target branch (`main` or `v-*-test`)   - which will be the last ""canary"" built image\r\n> \r\n> Which is EXACTLY what we need.\r\n\r\nUnderstood, Acutally i have replicated this scenario, uploading image as artifact and restoring and rebuilding, but its not used any cache from the restored artifact, instead it built all the layers. as per my understand the docker image load will not load the image into buildx, this is slightly bit behaving different. \r\n\r\nThere is issue also i think for this https://github.com/docker/buildx/issues/847 ?\r\n\r\nThis is the reason i tried slight different, instead of upload image artifact, upload cache file into artifact and restored this cache and used as `type=local,src=/tmp/local-cache` with buildx. and worked fine', 'created_at': datetime.datetime(2024, 12, 29, 19, 3, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564815948, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> This is the reason i tried slight different, instead of upload image artifact, upload cache file into artifact and restored this cache and used as type=local,src=/tmp/local-cache with buildx. and worked fine\r\n\r\nAh. Indeed. I have not yet **looked** at this - I was going to look at it after we merge it. BUT there is an easy solution - we need to stop using buildx for CI image building - and revert to default builder.', 'created_at': datetime.datetime(2024, 12, 29, 19, 11, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564816354, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> This is the reason i tried slight different, instead of upload image artifact, upload cache file into artifact and restored this cache and used as type=local,src=/tmp/local-cache with buildx. and worked fine\r\n\r\nI also tried it but this has problematic effect  - the cache also contains whole `uv` cache which is additional 10 GB  or so (!) and downloading that much of an artifact is actually **slower** than `uv` recreating the cache in CI :D', 'created_at': datetime.datetime(2024, 12, 29, 19, 13, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564816954, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> Ah. Indeed. I have not yet looked at this - I was going to look at it after we merge it. BUT there is an easy solution - we need to stop using buildx for CI image building - and revert to default builder. \r\n\r\nI removed the `--builder` and pushed all the changes now.', 'created_at': datetime.datetime(2024, 12, 29, 19, 16, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564817313, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> I removed the `--builder` and pushed all the changes now.\r\n\r\nI believe in this case it will use the `docker` builder - so it should also use the loaded images.\r\n\r\n> Buildx supports the following build drivers:\r\n> docker: uses the BuildKit library bundled into the Docker daemon.', 'created_at': datetime.datetime(2024, 12, 29, 19, 18, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564819282, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> I believe in this case it will use the docker builder - so it should also use the loaded images.\r\n\r\nOr not... I will have to take a closer look :). Seems indeed the loaded images from the previous run are not used as cache  .... `cache invalidation is the most difficult thing in computer science` and yeah - I had a fair share of similar issues with it in the past :).', 'created_at': datetime.datetime(2024, 12, 29, 19, 29, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564820877, 'issue_id': 2762218891, 'author': 'potiuk', 'body': '> Or not... I will have to take a closer look :). Seems indeed the loaded images from the previous run are not used as cache .... cache invalidation is the most difficult thing in computer science and yeah - I had a fair share of similar issues with it in the past :).\r\n\r\nOK. So we will have to revert back to `--cache-from` for CI image building. That\'s simplest (and it works - you can see it win ""early cache"" build). Fixup is coming.', 'created_at': datetime.datetime(2024, 12, 29, 19, 36, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564822161, 'issue_id': 2762218891, 'author': 'gopidesupavan', 'body': '> > I believe in this case it will use the docker builder - so it should also use the loaded images.\r\n> \r\n> Or not... I will have to take a closer look :). Seems indeed the loaded images from the previous run are not used as cache .... `cache invalidation is the most difficult thing in computer science` and yeah - I had a fair share of similar issues with it in the past :).\r\n\r\nYeah indeed ðŸ˜„', 'created_at': datetime.datetime(2024, 12, 29, 19, 43, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564827166, 'issue_id': 2762218891, 'author': 'potiuk', 'body': ""Pushed... Let's see. We will observe it only after cache gets updated, so we might not see the whole effect of it until we merge."", 'created_at': datetime.datetime(2024, 12, 29, 20, 6, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564828047, 'issue_id': 2762218891, 'author': 'gopidesupavan', 'body': ""> Pushed... Let's see. We will observe it only after cache gets updated, so we might not see the whole effect of it until we merge.\r\n\r\nYeah agree, we can monitor next builds after this merge :)"", 'created_at': datetime.datetime(2024, 12, 29, 20, 11, 4, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-29 16:03:23 UTC): I still have some tests to fix, but this one should be generally ready to review. There is a corresponding #45261 ""regular PR"" (this is canary build equivalent).

It should be **HUGE** simplificaiton of our CI workflows and Dockerfile -> and huge improvement in security - as we are getting rid of the `pull_request_target` workflow.

I am planning to backport that one to `v2-10-test` and `providers-fab/v1-5` so that we will be able to get rid of the `pull_request_target` workflows altogether.

potiuk (Issue Creator) on (2024-12-29 16:07:47 UTC): I added comments/conversations explainining some detailed reasoning for the changes. The change is huge (of course) - and sorry for that size, but I could not really make it smaller. I separated two folow-ups that do not need to be added now in this PR:

* https://github.com/apache/airflow/issues/45268
* https://github.com/apache/airflow/issues/45269

but all the rest is essentially ""needed"" as single PR.

jscheffl on (2024-12-29 17:29:24 UTC): Oh, this is BIG. How much time do you give me/us to review? Are we in a hurry?

potiuk (Issue Creator) on (2024-12-29 18:10:42 UTC): Not THAT big - most of it is generated images/hashes and removal of some parts of the workflow that are not used any more. There is no ""huge"" hurry with merging it but this one will all also fix some of the current caching issues (i.e. fixing #42999 ) -> so also local breeze dev env should be quite a bit snappier to rebuild images locally. So the sooner - the better :)

potiuk (Issue Creator) on (2024-12-29 18:20:18 UTC): PRs are using cache from the artifacts. If you look at the `ci-image-build.xml`, we are attempting to download the cached artifact image and load it to the registry (the load command will only run when ""stash/restore"" command will have a cache hit:

```yaml
      - name: ""Restore CI docker image ${{ inputs.platform }}:${{ env.PYTHON_MAJOR_MINOR_VERSION }}""
        uses: apache/infrastructure-actions/stash/restore@c94b890bbedc2fc61466d28e6bd9966bc6c6643c
        with:
          key: ""ci-image-save-${{ inputs.platform }}-${{ env.PYTHON_MAJOR_MINOR_VERSION }}""
          path: ""/tmp/""
        id: restore-ci-image
      - name: ""Load CI image ${{ inputs.platform }}:${{ env.PYTHON_MAJOR_MINOR_VERSION }}""
        run: breeze ci-image load --platform ${{ inputs.platform }}
        shell: bash
        if: steps.restore-ci-image.stash-hit == 'true'
```

This is the nice thing with using `stash` action - because it will download artifacts ""up"" the hierarchy when it finds it (see https://github.com/apache/infrastructure-actions/tree/main/stash#features) 

1) It will try to attempt to find cache in current workflow  (it will not find any because we have not built an image yet)
2) It will look for cache in previous action runs of the current branch (which means that even if you modify Dockerfile or other scripts, the cached image uploaded in previous run of your PR will be used subsequent runs of the same PR within 2 days should be faster
3) If it does not find it (first time you run your PR) - it will look for the same artifact in the target branch (`main` or `v-*-test`)   - which will be the last ""canary"" built image

Which is EXACTLY what we need.

gopidesupavan on (2024-12-29 19:03:30 UTC): Understood, Acutally i have replicated this scenario, uploading image as artifact and restoring and rebuilding, but its not used any cache from the restored artifact, instead it built all the layers. as per my understand the docker image load will not load the image into buildx, this is slightly bit behaving different. 

There is issue also i think for this https://github.com/docker/buildx/issues/847 ?

This is the reason i tried slight different, instead of upload image artifact, upload cache file into artifact and restored this cache and used as `type=local,src=/tmp/local-cache` with buildx. and worked fine

potiuk (Issue Creator) on (2024-12-29 19:11:49 UTC): Ah. Indeed. I have not yet **looked** at this - I was going to look at it after we merge it. BUT there is an easy solution - we need to stop using buildx for CI image building - and revert to default builder.

potiuk (Issue Creator) on (2024-12-29 19:13:58 UTC): I also tried it but this has problematic effect  - the cache also contains whole `uv` cache which is additional 10 GB  or so (!) and downloading that much of an artifact is actually **slower** than `uv` recreating the cache in CI :D

potiuk (Issue Creator) on (2024-12-29 19:16:38 UTC): I removed the `--builder` and pushed all the changes now.

potiuk (Issue Creator) on (2024-12-29 19:18:28 UTC): I believe in this case it will use the `docker` builder - so it should also use the loaded images.

potiuk (Issue Creator) on (2024-12-29 19:29:08 UTC): Or not... I will have to take a closer look :). Seems indeed the loaded images from the previous run are not used as cache  .... `cache invalidation is the most difficult thing in computer science` and yeah - I had a fair share of similar issues with it in the past :).

potiuk (Issue Creator) on (2024-12-29 19:36:32 UTC): OK. So we will have to revert back to `--cache-from` for CI image building. That's simplest (and it works - you can see it win ""early cache"" build). Fixup is coming.

gopidesupavan on (2024-12-29 19:43:01 UTC): Yeah indeed ðŸ˜„

potiuk (Issue Creator) on (2024-12-29 20:06:44 UTC): Pushed... Let's see. We will observe it only after cache gets updated, so we might not see the whole effect of it until we merge.

gopidesupavan on (2024-12-29 20:11:04 UTC): Yeah agree, we can monitor next builds after this merge :)

"
2762204663,pull_request,closed,,Import Variable API ,"<img width=""1433"" alt=""image"" src=""https://github.com/user-attachments/assets/4948b84a-0073-4c4a-8cb8-9b44c4700701"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-29 11:08:05+00:00,[],2024-12-29 17:33:14+00:00,2024-12-29 17:33:14+00:00,https://github.com/apache/airflow/pull/45265,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2564742955, 'issue_id': 2762204663, 'author': 'shubhamraj-git', 'body': '@jscheffl \r\n\r\nYaa, In starting I thought to add this as private endpoint for UI.\r\nBut we have a option to do it from CLI.\r\nSo, thought to be consistent and add public API.\r\n\r\nAlso, regarding the static checks, I tried running it locally. It suggesting me to change the name of `ImportVariableBody` to `Body_import_variables`, Not sure, why there is constraint to change it.', 'created_at': datetime.datetime(2024, 12, 29, 14, 31, 42, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2024-12-29 14:31:42 UTC): @jscheffl 

Yaa, In starting I thought to add this as private endpoint for UI.
But we have a option to do it from CLI.
So, thought to be consistent and add public API.

Also, regarding the static checks, I tried running it locally. It suggesting me to change the name of `ImportVariableBody` to `Body_import_variables`, Not sure, why there is constraint to change it.

"
2761795276,pull_request,closed,,Add `group_display_name` attribute to allow specifying a custom display name in the UI for TaskGroup,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:


related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #44569

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hardeybisey,2024-12-28 16:39:51+00:00,[],2025-01-04 16:07:13+00:00,2025-01-04 16:07:13+00:00,https://github.com/apache/airflow/pull/45264,"[('area:serialization', ''), ('type:new-feature', 'Changelog: New Features'), ('area:task-sdk', None)]","[{'comment_id': 2571263496, 'issue_id': 2761795276, 'author': 'hardeybisey', 'body': '> Thanks for the contribution! I always wanted to make this but the big shift to Airflow 3 distracted me from making this...\r\n> \r\n> Once check that we need to discuss on attribute model...\r\n> \r\n> ... and besides this, would it make sense to consider adding UI changes in the same PR as well? Else the group display name would have no effect other than just adding an attribute.\r\n\r\nThank you for taking the time to review this and for your thoughtful feedback!\r\n\r\nTo clarify, when you mention the display name having no effect, are you suggesting it doesnâ€™t currently reflect in the UI? In this implementation, when the group display name is provided, it is displayed in the UI as expected as shown below.\r\n\r\n<img width=""1018"" alt=""image"" src=""https://github.com/user-attachments/assets/137b9d4b-e8c7-4f5f-af3a-c76638036ad1"" />\r\n\r\n\r\n\r\n\r\n\r\nRegarding the UI changes, Iâ€™d be happy to extend this PR to also include a new Group Display Name key as part of the task group details on this page if that is what you are suggesting. \r\n<img width=""840"" alt=""image"" src=""https://github.com/user-attachments/assets/2372e01a-7d6b-4449-b782-1853753965bb"" />\r\n\r\n\r\nPlease let me know the direction youâ€™d like me to proceed. Thank you!', 'created_at': datetime.datetime(2025, 1, 4, 11, 42, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571306906, 'issue_id': 2761795276, 'author': 'jscheffl', 'body': '> > Thanks for the contribution! I always wanted to make this but the big shift to Airflow 3 distracted me from making this...\r\n> > Once check that we need to discuss on attribute model...\r\n> > ... and besides this, would it make sense to consider adding UI changes in the same PR as well? Else the group display name would have no effect other than just adding an attribute.\r\n> \r\n> Thank you for taking the time to review this and for your thoughtful feedback!\r\n> \r\n> To clarify, when you mention the display name having no effect, are you suggesting it doesnâ€™t currently reflect in the UI? In this implementation, when the group display name is provided, it is displayed in the UI as expected as shown below.\r\n> <img alt=""image"" width=""1018"" src=""https://private-user-images.githubusercontent.com/104902482/400136461-137b9d4b-e8c7-4f5f-af3a-c76638036ad1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5OTc4ODEsIm5iZiI6MTczNTk5NzU4MSwicGF0aCI6Ii8xMDQ5MDI0ODIvNDAwMTM2NDYxLTEzN2I5ZDRiLWU4YzctNGY1Zi1hZjNhLWM3NjYzODAzNmFkMS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTA0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEwNFQxMzMzMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05ZmVjNWZjN2Y5NDlkZDA0ODIyYmM2ZmIzYjMzOTVhZjRmNzg2ZjQyMWNkZWExODU5YTUzOGUyYWE0OWFkYmM3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.2yVDKByjc3ZS0nUGb1objoQ0ZireZ3jfkHq254u3yi0"">\r\n> \r\n> Regarding the UI changes, Iâ€™d be happy to extend this PR to also include a new Group Display Name key as part of the task group details on this page if that is what you are suggesting. <img alt=""image"" width=""840"" src=""https://private-user-images.githubusercontent.com/104902482/400136149-2372e01a-7d6b-4449-b782-1853753965bb.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5OTc4ODEsIm5iZiI6MTczNTk5NzU4MSwicGF0aCI6Ii8xMDQ5MDI0ODIvNDAwMTM2MTQ5LTIzNzJlMDFhLTdkNmItNDQ0OS1iNzgyLTE4NTM3NTM5NjViYi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTA0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEwNFQxMzMzMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wOGE0ZWJkOWFiMzk5MTM2NGEzYjJmYWE0YWI3ZDEzYTk3NTViOGZjMDk5MTc4MDAzMTU0NGY3MDJmMTUwMDZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.CWqrbEQTc-s7083D8RZYn_nXnMwbfNuGGLh3AvdCaJQ"">\r\n> \r\n> Please let me know the direction youâ€™d like me to proceed. Thank you!\r\n\r\nOh, did not notice that UI changed w/o touching the code. Cool.\r\nI assume on current (legacy) UI no changes are needed. But if you like... the ""new"" UI is under construction and if you want to contribute there... any contribution is welcome! https://github.com/orgs/apache/projects/400', 'created_at': datetime.datetime(2025, 1, 4, 13, 35, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571323704, 'issue_id': 2761795276, 'author': 'hardeybisey', 'body': '> > > Thanks for the contribution! I always wanted to make this but the big shift to Airflow 3 distracted me from making this...\r\n> > > Once check that we need to discuss on attribute model...\r\n> > > ... and besides this, would it make sense to consider adding UI changes in the same PR as well? Else the group display name would have no effect other than just adding an attribute.\r\n> > \r\n> > \r\n> > Thank you for taking the time to review this and for your thoughtful feedback!\r\n> > To clarify, when you mention the display name having no effect, are you suggesting it doesnâ€™t currently reflect in the UI? In this implementation, when the group display name is provided, it is displayed in the UI as expected as shown below.\r\n> > <img alt=""image"" width=""1018"" src=""https://private-user-images.githubusercontent.com/104902482/400136461-137b9d4b-e8c7-4f5f-af3a-c76638036ad1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5OTc4ODEsIm5iZiI6MTczNTk5NzU4MSwicGF0aCI6Ii8xMDQ5MDI0ODIvNDAwMTM2NDYxLTEzN2I5ZDRiLWU4YzctNGY1Zi1hZjNhLWM3NjYzODAzNmFkMS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTA0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEwNFQxMzMzMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05ZmVjNWZjN2Y5NDlkZDA0ODIyYmM2ZmIzYjMzOTVhZjRmNzg2ZjQyMWNkZWExODU5YTUzOGUyYWE0OWFkYmM3JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.2yVDKByjc3ZS0nUGb1objoQ0ZireZ3jfkHq254u3yi0"">\r\n> > Regarding the UI changes, Iâ€™d be happy to extend this PR to also include a new Group Display Name key as part of the task group details on this page if that is what you are suggesting. <img alt=""image"" width=""840"" src=""https://private-user-images.githubusercontent.com/104902482/400136149-2372e01a-7d6b-4449-b782-1853753965bb.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzU5OTc4ODEsIm5iZiI6MTczNTk5NzU4MSwicGF0aCI6Ii8xMDQ5MDI0ODIvNDAwMTM2MTQ5LTIzNzJlMDFhLTdkNmItNDQ0OS1iNzgyLTE4NTM3NTM5NjViYi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTA0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDEwNFQxMzMzMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0wOGE0ZWJkOWFiMzk5MTM2NGEzYjJmYWE0YWI3ZDEzYTk3NTViOGZjMDk5MTc4MDAzMTU0NGY3MDJmMTUwMDZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.CWqrbEQTc-s7083D8RZYn_nXnMwbfNuGGLh3AvdCaJQ"">\r\n> > Please let me know the direction youâ€™d like me to proceed. Thank you!\r\n> \r\n> Oh, did not notice that UI changed w/o touching the code. Cool. I assume on current (legacy) UI no changes are needed. But if you like... the ""new"" UI is under construction and if you want to contribute there... any contribution is welcome! https://github.com/orgs/apache/projects/400\r\n\r\nThanks for the feedback! Just to confirm, does this mean the PR is ready to go and meets the current requirements?\r\n\r\nAlso, Iâ€™m happy to contribute to other areas that are not UI-related, as Iâ€™m not an expert with frontend libraries or code :smile:', 'created_at': datetime.datetime(2025, 1, 4, 14, 46, 21, tzinfo=datetime.timezone.utc)}]","hardeybisey (Issue Creator) on (2025-01-04 11:42:40 UTC): Thank you for taking the time to review this and for your thoughtful feedback!

To clarify, when you mention the display name having no effect, are you suggesting it doesnâ€™t currently reflect in the UI? In this implementation, when the group display name is provided, it is displayed in the UI as expected as shown below.

<img width=""1018"" alt=""image"" src=""https://github.com/user-attachments/assets/137b9d4b-e8c7-4f5f-af3a-c76638036ad1"" />





Regarding the UI changes, Iâ€™d be happy to extend this PR to also include a new Group Display Name key as part of the task group details on this page if that is what you are suggesting. 
<img width=""840"" alt=""image"" src=""https://github.com/user-attachments/assets/2372e01a-7d6b-4449-b782-1853753965bb"" />


Please let me know the direction youâ€™d like me to proceed. Thank you!

jscheffl on (2025-01-04 13:35:13 UTC): Oh, did not notice that UI changed w/o touching the code. Cool.
I assume on current (legacy) UI no changes are needed. But if you like... the ""new"" UI is under construction and if you want to contribute there... any contribution is welcome! https://github.com/orgs/apache/projects/400

hardeybisey (Issue Creator) on (2025-01-04 14:46:21 UTC): Thanks for the feedback! Just to confirm, does this mean the PR is ready to go and meets the current requirements?

Also, Iâ€™m happy to contribute to other areas that are not UI-related, as Iâ€™m not an expert with frontend libraries or code :smile:

"
2761759302,pull_request,closed,,Update docs for passing any valid parameters to Elasticsearch client,"related: https://github.com/apache/airflow/issues/44724#issuecomment-2551328540
Closes: #44724




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-28 15:03:41+00:00,[],2024-12-29 23:16:29+00:00,2024-12-29 23:16:29+00:00,https://github.com/apache/airflow/pull/45263,"[('area:providers', ''), ('kind:documentation', ''), ('provider:elasticsearch', '')]",[],
2761712671,pull_request,closed,,Loop scheduler before running dag in docker tests,"Sometimes docker compose tests are failing due to dag not available. 
https://github.com/apache/airflow/actions/runs/12519916344/job/34925347645#step:8:1714

Might be worth running some loops before calling dags endpoint.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-28 13:02:50+00:00,[],2024-12-28 22:45:43+00:00,2024-12-28 13:13:30+00:00,https://github.com/apache/airflow/pull/45262,"[('area:production-image', 'Production image improvements and fixes')]",[],
2761636972,pull_request,closed,,Simplify caching mechanisms for CI and PROD images (regular PR),"For a long time we had used a sophisticated mechanism to speed up our CI jobs by building the images in ""pull_request_target"" workflow and pushing them to GitHub registry. That however had several drawbacks:

* CI image was complex when it comes to layer setup (we had to pre- cache installed dependencies by installing them from branch tip

* The pull_request_target is a very dangerous workflow, we had a number of security problems with it (and it's difficult to debug)

* Caching of `pip` and `uv` was not used because it increased size of the image significantly

This PR significantly improves the caching mechanisms for the images building of several advacements that were not possible before:

* The upload-artifacts@v4 action and improved stash action developed by @assignUser and published in ""apache/infrastructure-actions"" allows us to store all images (8GB per run) in artifacts rather than in registry - so we can do the image build once and share it with all the jobs.

* The uv speed is ""enough"" to allow occasional installation of Airlfow locally. This allows to utilize cache-mount and locally build uv cache, rather than rely on ""remote"" cache when we are building local images for breeze. The first time you build local breeze image it will take 2-5 more minutes (depending on your network speed, but because we can utilise cache mounts, every subsequent build should be very fast - even if all dependencies change. Using uv also allows to ""always"" reinstall airflow when you build the image even if single source file changed, because with cache it takes sub-seconds to reinstall airflow and all dependencies.

* the cache mounts are not included in the image size, and since we can export and import images in CI in artifacts and we do not need to rebuild them, the images shared as compressed artifacts are relatively small (2GB) - cache of `uv` is around 4GB on top of that so sharing image built in the ""build image"" job with other jobs in the same workflow is fast.

* we are still using registry cache for the ""non-python"" parts of the image - both CI and breeze image build speed benefit from using the image cache for system dependencies, database clients etc.

* documentation has been updated to reflect the new CI setup. The  diagrams showing the workflows of ours are no longer needed as the workflows are quite straightforward when they are looked at.

Fixes: #42999
Fixes: #43268

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-28 08:56:53+00:00,[],2024-12-29 21:58:52+00:00,2024-12-29 21:58:52+00:00,https://github.com/apache/airflow/pull/45261,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2564325510, 'issue_id': 2761636972, 'author': 'gopidesupavan', 'body': 'Nice looking forward for this :)', 'created_at': datetime.datetime(2024, 12, 28, 13, 26, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564699951, 'issue_id': 2761636972, 'author': 'potiuk', 'body': 'Also opened a ""canary"" build from ""apache"" repo to check how caching will work #45266\r\n\r\nI will eventually close that one and will mark ""ready for review"" the other one, as we cannot get this one to be green due to pull_request_target workflow failing.', 'created_at': datetime.datetime(2024, 12, 29, 11, 53, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564848394, 'issue_id': 2761636972, 'author': 'potiuk', 'body': 'Merged in https://github.com/apache/airflow/pull/45266', 'created_at': datetime.datetime(2024, 12, 29, 21, 58, 52, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-12-28 13:26:10 UTC): Nice looking forward for this :)

potiuk (Issue Creator) on (2024-12-29 11:53:38 UTC): Also opened a ""canary"" build from ""apache"" repo to check how caching will work #45266

I will eventually close that one and will mark ""ready for review"" the other one, as we cannot get this one to be green due to pull_request_target workflow failing.

potiuk (Issue Creator) on (2024-12-29 21:58:52 UTC): Merged in https://github.com/apache/airflow/pull/45266

"
2761586991,pull_request,closed,,Remove old lineage stuff,"
closes: #44983 



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-28 07:33:45+00:00,[],2025-01-27 12:51:49+00:00,2025-01-25 03:42:47+00:00,https://github.com/apache/airflow/pull/45260,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:lineage', '')]","[{'comment_id': 2564284850, 'issue_id': 2761586991, 'author': 'jason810496', 'body': 'When attempting to remove the lineage logic from the core module, I noticed that it causes failures in tests related to **OpenLineage listener capturing hook-level lineage** (https://github.com/apache/airflow/pull/41482).  \r\n\r\nFor example, removing `apply_lineage` and `prepare_lineage` from `BaseOperator`:  \r\nhttps://github.com/apache/airflow/blob/0efd9e6a2fa8bde0f6c14e88951b44badca063a2/airflow/models/baseoperator.py#L705-L739  \r\n\r\nResults in the following test failure:  \r\n```\r\nFAILED providers/tests/openlineage/extractors/test_manager.py::test_extractor_manager_gets_data_from_pythonoperator - assert 0 == 1\r\n +  where 0 = len([])\r\n +    where [] = HookLineage(inputs=[], outputs=[]).outputs\r\n```\r\nhttps://github.com/apache/airflow/blob/0efd9e6a2fa8bde0f6c14e88951b44badca063a2/providers/tests/openlineage/extractors/test_manager.py#L301  \r\n\r\nIt seems OpenLineage is still coupled with the lineage module and might need to be moved to `compact.lineage` for now (or to the OpenLineage module in a future PR ).  \r\n\r\nAfter some experimentation, implementing an `on_load` callback in the `OpenLineageProviderPlugin` to monkey-patch the core module at runtime prevents the OpenLineage test failures, even with the lineage module removed from the core. \r\n> Based on https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/plugins.html#interface\r\n\r\nIâ€™m not sure if this is a suitable long-term solution for maintaining OpenLineage compatibility while cleaning up the lineage module ?\r\n\r\ncc @Lee-W @uranusjr', 'created_at': datetime.datetime(2024, 12, 28, 9, 57, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567315195, 'issue_id': 2761586991, 'author': 'jason810496', 'body': 'The CI failure is caused by a flaky K8s test (#45145) and a breaking change in the compatibility tests for providers 2.9.3 and 2.10.4 .  \r\n\r\nShould we fix the tests to pass the compatibility checks, or is it acceptable to ignore the compatibility tests since all tests for 3.0 have passed ?', 'created_at': datetime.datetime(2025, 1, 2, 6, 1, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567323698, 'issue_id': 2761586991, 'author': 'Lee-W', 'body': ""> The CI failure is caused by a flaky K8s test (#45145) and a breaking change in the compatibility tests for providers 2.3.9 and 2.3.10.  \n> \n> \n> \n> Should we fix the tests to pass the compatibility checks, or is it acceptable to ignore the compatibility tests since all tests for 3.0 have passed ?\n\n2.9.3 or 2.3.9. If it's 2.9.3, then we'll need to fix it as providers will still support airflow 2 for some time"", 'created_at': datetime.datetime(2025, 1, 2, 6, 14, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567337940, 'issue_id': 2761586991, 'author': 'jason810496', 'body': ""> 2.9.3 or 2.3.9. If it's 2.9.3, then we'll need to fix it as providers will still support airflow 2 for some time\r\n\r\nSorry for the typo, I mean 2.9.3 and 2.10.4 . Thanks for reply, if then I will fix the test."", 'created_at': datetime.datetime(2025, 1, 2, 6, 39, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567341419, 'issue_id': 2761586991, 'author': 'uranusjr', 'body': 'We should not remove the entire lineage mechanism. The issue is only meant to remove the old lineage constructs in `airflow.lineage.entities`. The rest of the mechanism integrates modern Airflow assets with OpenLineage, and they should be kept.', 'created_at': datetime.datetime(2025, 1, 2, 6, 45, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567404322, 'issue_id': 2761586991, 'author': 'mobuchowski', 'body': 'Just as TP said. Removing [airflow/lineage/hook.py](https://github.com/apache/airflow/pull/45260/files#diff-da82ad12f9efa71b6de517375641691e1b83a69f66eb79fa4887b197b15c4147) is wrong', 'created_at': datetime.datetime(2025, 1, 2, 8, 8, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567710194, 'issue_id': 2761586991, 'author': 'potiuk', 'body': '@jason810496  I rebased it -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 35, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2570319488, 'issue_id': 2761586991, 'author': 'jason810496', 'body': 'Fixed: I only moved `airflow.lineage.entities` to `airflow.providers.common.compat.lineage.entities`.  \r\nThe CI failure is unrelated, as no relevant frontend tests failed.  \r\n\r\nOne small question: Does this PR need to be backported to 2.10 ?', 'created_at': datetime.datetime(2025, 1, 4, 6, 39, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2588811851, 'issue_id': 2761586991, 'author': 'Lee-W', 'body': 'Hi @jason810496, I just found the PR we discussed yesterday. https://github.com/apache/airflow/pull/44720 I think this one would be useful for this PR.', 'created_at': datetime.datetime(2025, 1, 14, 3, 1, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589178774, 'issue_id': 2761586991, 'author': 'uranusjr', 'body': '> One small question: Does this PR need to be backported to 2.10?\r\n\r\nNo since you only moved the classes. The providers are always released from main, and itâ€™s OK for those classes to be available in two places in 2.10.', 'created_at': datetime.datetime(2025, 1, 14, 7, 8, 1, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-12-28 09:57:19 UTC): When attempting to remove the lineage logic from the core module, I noticed that it causes failures in tests related to **OpenLineage listener capturing hook-level lineage** (https://github.com/apache/airflow/pull/41482).  

For example, removing `apply_lineage` and `prepare_lineage` from `BaseOperator`:  
https://github.com/apache/airflow/blob/0efd9e6a2fa8bde0f6c14e88951b44badca063a2/airflow/models/baseoperator.py#L705-L739  

Results in the following test failure:  
```
FAILED providers/tests/openlineage/extractors/test_manager.py::test_extractor_manager_gets_data_from_pythonoperator - assert 0 == 1
 +  where 0 = len([])
 +    where [] = HookLineage(inputs=[], outputs=[]).outputs
```
https://github.com/apache/airflow/blob/0efd9e6a2fa8bde0f6c14e88951b44badca063a2/providers/tests/openlineage/extractors/test_manager.py#L301  

It seems OpenLineage is still coupled with the lineage module and might need to be moved to `compact.lineage` for now (or to the OpenLineage module in a future PR ).  

After some experimentation, implementing an `on_load` callback in the `OpenLineageProviderPlugin` to monkey-patch the core module at runtime prevents the OpenLineage test failures, even with the lineage module removed from the core. 

Iâ€™m not sure if this is a suitable long-term solution for maintaining OpenLineage compatibility while cleaning up the lineage module ?

cc @Lee-W @uranusjr

jason810496 (Issue Creator) on (2025-01-02 06:01:21 UTC): The CI failure is caused by a flaky K8s test (#45145) and a breaking change in the compatibility tests for providers 2.9.3 and 2.10.4 .  

Should we fix the tests to pass the compatibility checks, or is it acceptable to ignore the compatibility tests since all tests for 3.0 have passed ?

Lee-W on (2025-01-02 06:14:52 UTC): 2.9.3 or 2.3.9. If it's 2.9.3, then we'll need to fix it as providers will still support airflow 2 for some time

jason810496 (Issue Creator) on (2025-01-02 06:39:58 UTC): Sorry for the typo, I mean 2.9.3 and 2.10.4 . Thanks for reply, if then I will fix the test.

uranusjr on (2025-01-02 06:45:29 UTC): We should not remove the entire lineage mechanism. The issue is only meant to remove the old lineage constructs in `airflow.lineage.entities`. The rest of the mechanism integrates modern Airflow assets with OpenLineage, and they should be kept.

mobuchowski on (2025-01-02 08:08:54 UTC): Just as TP said. Removing [airflow/lineage/hook.py](https://github.com/apache/airflow/pull/45260/files#diff-da82ad12f9efa71b6de517375641691e1b83a69f66eb79fa4887b197b15c4147) is wrong

potiuk on (2025-01-02 12:35:07 UTC): @jason810496  I rebased it -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

jason810496 (Issue Creator) on (2025-01-04 06:39:48 UTC): Fixed: I only moved `airflow.lineage.entities` to `airflow.providers.common.compat.lineage.entities`.  
The CI failure is unrelated, as no relevant frontend tests failed.  

One small question: Does this PR need to be backported to 2.10 ?

Lee-W on (2025-01-14 03:01:04 UTC): Hi @jason810496, I just found the PR we discussed yesterday. https://github.com/apache/airflow/pull/44720 I think this one would be useful for this PR.

uranusjr on (2025-01-14 07:08:01 UTC): No since you only moved the classes. The providers are always released from main, and itâ€™s OK for those classes to be available in two places in 2.10.

"
2761393377,pull_request,closed,,Move first provider (airbyte) to a separate project,"This is the first step to move providers to separate projects inside our monorepo.

Airbyte is a first provider that is separated out to a project under ""providers/<PROVIDER_ID>"" directory. This has the nice property that all files belonging to the same provider are under a single directory that is part of the Airflow workspace. For now the code is more complex because we are handling providers being in either ""old"" or ""new"" structure, but once we move old providers to the new structure, a lot of code could be removed and simplified.

The new structure for provider code is:

```
providers
        |- PROVIDER_ID
        |            |- src
        |            |    |-airflow
        |            |            |- providers
        |            |                       |- PROVIDER_ID
        |            |- tests
        |            |      |- providers
        |            |                 |- PROVIDER_ID
        |            |- docs
        |            |     |- .latest-doc-only-changes.txt
        |            |- pyproject.toml
        |            |- CHANGELOG.rst
        |            |- provider.yaml
        |            |- README.rst
        |- PROVIDER_ID2
        ...

```

Part of #44511

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-28 01:58:01+00:00,[],2025-01-18 20:12:17+00:00,2025-01-14 06:42:23+00:00,https://github.com/apache/airflow/pull/45259,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2564247959, 'issue_id': 2761393377, 'author': 'potiuk', 'body': 'This is not yet complete, and I also extract some things out of that to separate PR to make it smaller/simpler. Just wanted to test the image build process.', 'created_at': datetime.datetime(2024, 12, 28, 7, 38, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567384208, 'issue_id': 2761393377, 'author': 'uranusjr', 'body': 'Once we sort out what needs to be done to move one provider, an automated script to move each one is maybe possible.', 'created_at': datetime.datetime(2025, 1, 2, 7, 45, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567539071, 'issue_id': 2761393377, 'author': 'potiuk', 'body': '> Once we sort out what needs to be done to move one provider, an automated script to move each one is maybe possible.\r\n\r\nThat\'s exactly the plan (and that\'s how I\'ve done it in very old POC. But only after 3 or 4 selected proividers that exhibit different ""variants"" - for example one common provider and one provider with auth manager etc. I have not yet chosen the next providers. There will be **some** problems uncovered only after we do such three different providers.\r\n\r\nAnd then we will incrementally move one-provider-by-one-provider with the aid of that script (ideally by a number of different people so that they can also learn about the structure, consequences, packaging and solve smaller problems along the way)\r\n\r\nMy plan how to do this is described in detail (including the automation and incremental move) in https://github.com/apache/airflow/issues/44511#issue-2707381976 - see the end where I even linked to the old POC of the script that was used in the past.', 'created_at': datetime.datetime(2025, 1, 2, 10, 13, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572263862, 'issue_id': 2761393377, 'author': 'eladkal', 'body': 'What about system tests? Is it going to stay cenerlized or per provider?', 'created_at': datetime.datetime(2025, 1, 6, 4, 41, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572315952, 'issue_id': 2761393377, 'author': 'potiuk', 'body': '> What about system tests? Is it going to stay cenerlized or per provider?\r\n\r\nThey are under ""tests/system"" in  the provider.', 'created_at': datetime.datetime(2025, 1, 6, 5, 39, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572427916, 'issue_id': 2761393377, 'author': 'potiuk', 'body': 'Indeed - worth to describe the proposal how tests should work - this is one of the changes that is not yet ""final"" setup but more of a step in the right direction. \r\n\r\nIt\'s not obvious and worth mentioning what\'s the setup I propose now (and how it can slightly evolve).\r\n\r\nI propose that we move all the provider tests in the ""tests"" folder or ""tests/system"" folder as `providers.<PROVIDER>`. Main reason is so that we can mark ""tests"" as the root for all tests similarly as ""src"" is root for all sources.\r\n\r\nThis will allow to avoid problems like ""from email import something"" failing which was often the problem that we had when we wanted to treat ""tests"" as PYTHONPATh entry - because it was clashing with built-in email package (for example - there were more packages like that).\r\n\r\nSo Inside provider folders we  (I use google as an example with sytem tests) will have this:\r\n\r\n```\r\ntests\r\n     |- conftest.py -> here we import common plugins for both ""tests"" and system tests""\r\n\r\ntests/providers/google/ \r\n                      |-  -> all google tests are here\r\n\r\ntests/system/providers/google\r\n            |- conftest.py -> here we have common stuff for system tests of google provider\r\n```\r\n\r\nThis should help with making nice separation between regular and ""system"" tests - but also allow to have unambiguous imports:\r\n\r\n```python\r\nfrom email import ....\r\nfrom providers.email import test_whatever\r\n```\r\n\r\nBut at the same time, even if someone will have ""tests"" added to PYTHONPATH (some IDEs will do it automatically) we will avoid this to be interpreted as ""from tests.email import"" (which happened to a number of people in the past - and it\'s pretty confusing).\r\n\r\n```python\r\nfrom email \r\n```\r\n\r\nWe will still have to figure out what to do with ""tests_common"" - currently we use plugins in the common conftest.py:\r\n\r\n```python\r\npytest_plugins = ""tests_common.pytest_plugin""\r\n```\r\n\r\nThis allows to run provider tests from the root of breeze, and where we also install airflow:  `pip install -e.[]`  (or by default when you run `uv sync` and have `.venv` environment created. This **just works**:\r\n\r\n```bash\r\npytest providers/airbyte/tests/providers/airbyte/test_something.py\r\n```\r\n\r\nBut after we complete the provider split we have the possibility of moving ""airflow"" to subfolder of the main repo - we have not decided yet, but that would make sense - and in this case we will be able to refactor slightly the way how tests_common is imported. One problem with the proposal now is that you cannot run easily tests when you create venv directly in the ""provider"" folder. \r\n\r\nThis does **NOT** work yet (you really need to run provider tests in context of Airflow venv):\r\n\r\n```\r\ncd providers/airbyte\r\nuv sync\r\nuv run pytest tests/providers/airfbyte/test_something.py \r\n```\r\n\r\nBut when we move airflow out and make ""test_common"" a ""referrable"" uv-workspae project, we should be able to make it possible to make it ""common"" project that will be imported by all projects: airflow, task_sdk, each of the provider etc. I did not want to make those changes now - that would require a number of import changes in tests , so I want to do it as a separte refactor after all providers have been moved. \r\n\r\nThis will also make each ""provider"" project ""truly"" standalone - i.e. you will be able to easily run tests there without even creating a venv in ""."" top-level project - and essentially work on provider project separately. \r\n\r\nAt the same time (thanks to workspaces) we will allow to have all - task_sdk + providers + test_common installed together and run and test them togetther as well. This is the promise of workspaces - that you can work separately on each project but you can also install everything together and implemnt - at the same time - changes in all the projects (which was so far the only way we could develop airflow).', 'created_at': datetime.datetime(2025, 1, 6, 7, 2, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582276299, 'issue_id': 2761393377, 'author': 'potiuk', 'body': '> Looks good! Our sphinx friend is angry though :)\r\n\r\nYeah. And as usual speaking riddles, so I have to somehow walk around the beast.', 'created_at': datetime.datetime(2025, 1, 10, 10, 10, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2588500262, 'issue_id': 2761393377, 'author': 'potiuk', 'body': 'OK. Sphinx riddles and resulting Drachenfutter continued ....\r\n\r\nI **think** I got it right now.  I had to make some ""dirty"" solution to speed it up for docs building. There are far too many moving parts now to fix it for docs building individually ""per-package"" now, so for now I am  just dynamically copying the docs to ""docs/apache-airflow-providers-*/ and build docs from there. (those new providers are gitignored and by default the  generated files are deleted after building to avoid the docs to show up in your IDE in two places normally (you can add `--skip-deletion` flag to leave the copied docs in place).\r\n\r\nEventually, I think we shoudl be able to generate docs separately for each provider - in each provider on it\'s own. But that would require quite a bit more heavy sphinx scripts refactoring (or rather generally writing them from the scratch in much simpler form).\r\n\r\nBut for now I think it should be ""good enough"". Let\'s see.', 'created_at': datetime.datetime(2025, 1, 14, 0, 32, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589157319, 'issue_id': 2761393377, 'author': 'gopidesupavan', 'body': 'Woohoo nice Jarek :)', 'created_at': datetime.datetime(2025, 1, 14, 6, 49, 35, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-28 07:38:56 UTC): This is not yet complete, and I also extract some things out of that to separate PR to make it smaller/simpler. Just wanted to test the image build process.

uranusjr on (2025-01-02 07:45:05 UTC): Once we sort out what needs to be done to move one provider, an automated script to move each one is maybe possible.

potiuk (Issue Creator) on (2025-01-02 10:13:53 UTC): That's exactly the plan (and that's how I've done it in very old POC. But only after 3 or 4 selected proividers that exhibit different ""variants"" - for example one common provider and one provider with auth manager etc. I have not yet chosen the next providers. There will be **some** problems uncovered only after we do such three different providers.

And then we will incrementally move one-provider-by-one-provider with the aid of that script (ideally by a number of different people so that they can also learn about the structure, consequences, packaging and solve smaller problems along the way)

My plan how to do this is described in detail (including the automation and incremental move) in https://github.com/apache/airflow/issues/44511#issue-2707381976 - see the end where I even linked to the old POC of the script that was used in the past.

eladkal on (2025-01-06 04:41:31 UTC): What about system tests? Is it going to stay cenerlized or per provider?

potiuk (Issue Creator) on (2025-01-06 05:39:49 UTC): They are under ""tests/system"" in  the provider.

potiuk (Issue Creator) on (2025-01-06 07:02:26 UTC): Indeed - worth to describe the proposal how tests should work - this is one of the changes that is not yet ""final"" setup but more of a step in the right direction. 

It's not obvious and worth mentioning what's the setup I propose now (and how it can slightly evolve).

I propose that we move all the provider tests in the ""tests"" folder or ""tests/system"" folder as `providers.<PROVIDER>`. Main reason is so that we can mark ""tests"" as the root for all tests similarly as ""src"" is root for all sources.

This will allow to avoid problems like ""from email import something"" failing which was often the problem that we had when we wanted to treat ""tests"" as PYTHONPATh entry - because it was clashing with built-in email package (for example - there were more packages like that).

So Inside provider folders we  (I use google as an example with sytem tests) will have this:

```
tests
     |- conftest.py -> here we import common plugins for both ""tests"" and system tests""

tests/providers/google/ 
                      |-  -> all google tests are here

tests/system/providers/google
            |- conftest.py -> here we have common stuff for system tests of google provider
```

This should help with making nice separation between regular and ""system"" tests - but also allow to have unambiguous imports:

```python
from email import ....
from providers.email import test_whatever
```

But at the same time, even if someone will have ""tests"" added to PYTHONPATH (some IDEs will do it automatically) we will avoid this to be interpreted as ""from tests.email import"" (which happened to a number of people in the past - and it's pretty confusing).

```python
from email 
```

We will still have to figure out what to do with ""tests_common"" - currently we use plugins in the common conftest.py:

```python
pytest_plugins = ""tests_common.pytest_plugin""
```

This allows to run provider tests from the root of breeze, and where we also install airflow:  `pip install -e.[]`  (or by default when you run `uv sync` and have `.venv` environment created. This **just works**:

```bash
pytest providers/airbyte/tests/providers/airbyte/test_something.py
```

But after we complete the provider split we have the possibility of moving ""airflow"" to subfolder of the main repo - we have not decided yet, but that would make sense - and in this case we will be able to refactor slightly the way how tests_common is imported. One problem with the proposal now is that you cannot run easily tests when you create venv directly in the ""provider"" folder. 

This does **NOT** work yet (you really need to run provider tests in context of Airflow venv):

```
cd providers/airbyte
uv sync
uv run pytest tests/providers/airfbyte/test_something.py 
```

But when we move airflow out and make ""test_common"" a ""referrable"" uv-workspae project, we should be able to make it possible to make it ""common"" project that will be imported by all projects: airflow, task_sdk, each of the provider etc. I did not want to make those changes now - that would require a number of import changes in tests , so I want to do it as a separte refactor after all providers have been moved. 

This will also make each ""provider"" project ""truly"" standalone - i.e. you will be able to easily run tests there without even creating a venv in ""."" top-level project - and essentially work on provider project separately. 

At the same time (thanks to workspaces) we will allow to have all - task_sdk + providers + test_common installed together and run and test them togetther as well. This is the promise of workspaces - that you can work separately on each project but you can also install everything together and implemnt - at the same time - changes in all the projects (which was so far the only way we could develop airflow).

potiuk (Issue Creator) on (2025-01-10 10:10:57 UTC): Yeah. And as usual speaking riddles, so I have to somehow walk around the beast.

potiuk (Issue Creator) on (2025-01-14 00:32:09 UTC): OK. Sphinx riddles and resulting Drachenfutter continued ....

I **think** I got it right now.  I had to make some ""dirty"" solution to speed it up for docs building. There are far too many moving parts now to fix it for docs building individually ""per-package"" now, so for now I am  just dynamically copying the docs to ""docs/apache-airflow-providers-*/ and build docs from there. (those new providers are gitignored and by default the  generated files are deleted after building to avoid the docs to show up in your IDE in two places normally (you can add `--skip-deletion` flag to leave the copied docs in place).

Eventually, I think we shoudl be able to generate docs separately for each provider - in each provider on it's own. But that would require quite a bit more heavy sphinx scripts refactoring (or rather generally writing them from the scratch in much simpler form).

But for now I think it should be ""good enough"". Let's see.

gopidesupavan on (2025-01-14 06:49:35 UTC): Woohoo nice Jarek :)

"
2761385344,pull_request,closed,,Upgrade to latest Helm version,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-28 01:28:15+00:00,[],2024-12-28 07:13:10+00:00,2024-12-28 07:13:09+00:00,https://github.com/apache/airflow/pull/45258,"[('area:dev-tools', '')]",[],
2761297082,pull_request,open,,[OpenLineage] Added Openlineage support for DatabricksCopyIntoOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

This PR adds support for DatabricksCopyIntoOperator (/providers/databricks/operators/databricks_sql.py)
Taking reference from CopyFromExternalStageToSnowflakeOperator which already has OL support.

<details>
<summary>tested using this DAG - click to open</summary>

```python

""""""
Example DAG demonstrating the usage of DatabricksCopyIntoOperator with OpenLineage support.
""""""

import logging
logging.getLogger('databricks.sql').setLevel(logging.DEBUG)

from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.databricks.operators.databricks_sql import DatabricksCopyIntoOperator

default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    'databricks_copy_into_example',
    default_args=default_args,
    description='Example DAG for DatabricksCopyIntoOperator with OpenLineage',
    schedule_interval=None,
    schedule=None,
    start_date=datetime(2024, 12, 13),
    catchup=False,
    tags=['example', 'databricks', 'openlineage'],
) as dag:

    # Example with S3
    copy_from_s3 = DatabricksCopyIntoOperator(
        task_id='copy_from_s3',
        databricks_conn_id='databricks_default',
        table_name='wide_world_importers.astronomer_assets.sample',
        file_location='s3a://kreative360/yoyo/sample.csv',
        file_format='CSV',
        format_options={
            ""header"": ""true"",
            ""inferSchema"": ""true"",
            ""delimiter"": "",""
        },
        copy_options={
            ""force"": ""true"",
            ""mergeSchema"": ""true""
        },
        http_path='/sql/1.0/warehouses/ca43e87568a0b22e',
        credential={
            ""AWS_ACCESS_KEY"": ""<redacted>"",
            ""AWS_SECRET_KEY"": ""<redacted>"",
            ""AWS_SESSION_TOKEN"": ""<redacted>"",
            ""AWS_REGION"": ""ap-south-1""
        }
    )

    # Example with Azure Blob Storage using wasbs protocol
    copy_from_azure = DatabricksCopyIntoOperator(
        task_id='copy_from_azure',
        databricks_conn_id='databricks_default',  
        table_name='wide_world_importers.astronomer_assets.sample',
        file_location='wasbs://rahul-container@openlineagecustom.blob.core.windows.net/sample.csv',
        file_format='CSV',
        # Using Azure storage credential
        credential={
            ""AZURE_SAS_TOKEN"": ""<redacted>"", # Replace with actual SAS token
        },
        format_options={
            ""header"": ""true"",
            ""inferSchema"": ""true""
        },
        copy_options={
            ""force"": ""true"",
            ""mergeSchema"": ""true""
        },
        http_path='/sql/1.0/warehouses/ca43e87568a0b22e'
    )

    # Example with GCS
    copy_from_gcs = DatabricksCopyIntoOperator(
        task_id='copy_from_gcs',
        databricks_conn_id='databricks_default',
        table_name='wide_world_importers.astronomer_assets.sample',
        file_location='gs://kreative360/yoyo/sample.csv',
        file_format='CSV',
        format_options={
            ""header"": ""true"",
            ""inferSchema"": ""true"",
            ""delimiter"": "",""
        },
        copy_options={
            ""force"": ""true"",
            ""mergeSchema"": ""true""
        },
        http_path='/sql/1.0/warehouses/ca43e87568a0b22e',
    )

    [copy_from_s3, copy_from_azure, copy_from_gcs]


```
</details>

note - tests have been performed using s3 object on aws only, other cloud providers (azure and gcs) have been tested only using FAIL events. 

OL events:
- aws(s3) - [aws.json](https://github.com/user-attachments/files/18263924/aws.json)
- azure -  [azure.json](https://github.com/user-attachments/files/18263927/azure.json)
- gcs - [gcs.json](https://github.com/user-attachments/files/18263929/gcs.json)


**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rahul-madaan,2024-12-27 21:48:59+00:00,[],2025-01-31 15:45:05+00:00,,https://github.com/apache/airflow/pull/45257,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2564271610, 'issue_id': 2761297082, 'author': 'rahul-madaan', 'body': '@kacpermuda @potiuk could you please take a look at the PR and approve?', 'created_at': datetime.datetime(2024, 12, 28, 8, 47, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567701976, 'issue_id': 2761297082, 'author': 'potiuk', 'body': '@rahul-madaan  -> I rebased it. we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 28, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572817109, 'issue_id': 2761297082, 'author': 'rahul-madaan', 'body': '@kacpermuda @potiuk A gentle reminder, please review the PR whenever you find some time this week.', 'created_at': datetime.datetime(2025, 1, 6, 10, 27, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572897340, 'issue_id': 2761297082, 'author': 'kacpermuda', 'body': ""@rahul-madaan Can you please rebase and make sure all the CI is green? I'll try to review the PR this week :)"", 'created_at': datetime.datetime(2025, 1, 6, 11, 15, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573936622, 'issue_id': 2761297082, 'author': 'rahul-madaan', 'body': 'errors are not getting resolved even after rebasing. It somehow started coming after Jarek rebased it. Should I reset the branch and  cherrypick my commits to resolve this?', 'created_at': datetime.datetime(2025, 1, 6, 21, 13, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574036726, 'issue_id': 2761297082, 'author': 'jscheffl', 'body': '> errors are not getting resolved even after rebasing. It somehow started coming after Jarek rebased it. Should I reset the branch and cherrypick my commits to resolve this?\r\n\r\nUsually not needed - but I agree it seems the errors are unrelated to your changes... on first view.', 'created_at': datetime.datetime(2025, 1, 6, 22, 28, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614077090, 'issue_id': 2761297082, 'author': 'rahul-madaan', 'body': '@kacpermuda I have addressed all the comments, please take a look. I have tested it on s3 and it is working perfectly.', 'created_at': datetime.datetime(2025, 1, 25, 19, 38, 25, tzinfo=datetime.timezone.utc)}]","rahul-madaan (Issue Creator) on (2024-12-28 08:47:36 UTC): @kacpermuda @potiuk could you please take a look at the PR and approve?

potiuk on (2025-01-02 12:28:06 UTC): @rahul-madaan  -> I rebased it. we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

rahul-madaan (Issue Creator) on (2025-01-06 10:27:34 UTC): @kacpermuda @potiuk A gentle reminder, please review the PR whenever you find some time this week.

kacpermuda on (2025-01-06 11:15:17 UTC): @rahul-madaan Can you please rebase and make sure all the CI is green? I'll try to review the PR this week :)

rahul-madaan (Issue Creator) on (2025-01-06 21:13:02 UTC): errors are not getting resolved even after rebasing. It somehow started coming after Jarek rebased it. Should I reset the branch and  cherrypick my commits to resolve this?

jscheffl on (2025-01-06 22:28:12 UTC): Usually not needed - but I agree it seems the errors are unrelated to your changes... on first view.

rahul-madaan (Issue Creator) on (2025-01-25 19:38:25 UTC): @kacpermuda I have addressed all the comments, please take a look. I have tested it on s3 and it is working perfectly.

"
2761277760,pull_request,closed,,Fix Version Check for CLI Imports in Providers,"closes: https://github.com/apache/airflow/pull/44538#issuecomment-2563910508
While testing the changes (here #45148, I missed that we are releasing the providers from the main branch but actual versions not from the main branch. So I have only tested the changes on the main, my bad :facepalm: 

The imports for the older versions were adjusted accordingly.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-12-27 21:14:09+00:00,[],2024-12-30 19:19:55+00:00,2024-12-30 19:19:55+00:00,https://github.com/apache/airflow/pull/45255,"[('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('provider:celery', ''), ('provider:fab', '')]","[{'comment_id': 2564049386, 'issue_id': 2761277760, 'author': 'potiuk', 'body': 'Hmm. Interesting it was not caught by the compatibility tests', 'created_at': datetime.datetime(2024, 12, 27, 21, 41, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564049498, 'issue_id': 2761277760, 'author': 'potiuk', 'body': 'And some tests still need fixing.', 'created_at': datetime.datetime(2024, 12, 27, 21, 41, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564060208, 'issue_id': 2761277760, 'author': 'bugraoz93', 'body': '>Hmm. Interesting it was not caught by the compatibility tests\r\n\r\nYeah, I would expect some tests to fail.\r\n> And some tests still need fixing.\r\n\r\nYes, I am fixing them now. Thanks for the quick review!', 'created_at': datetime.datetime(2024, 12, 27, 22, 6, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564090268, 'issue_id': 2761277760, 'author': 'bugraoz93', 'body': ""My local pre-commit didn't fix the exact issue even with `--all-files`. Suspecting from old image, rebuilding and trying again now"", 'created_at': datetime.datetime(2024, 12, 27, 23, 26, 48, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-27 21:41:19 UTC): Hmm. Interesting it was not caught by the compatibility tests

potiuk on (2024-12-27 21:41:29 UTC): And some tests still need fixing.

bugraoz93 (Issue Creator) on (2024-12-27 22:06:19 UTC): Yeah, I would expect some tests to fail.

Yes, I am fixing them now. Thanks for the quick review!

bugraoz93 (Issue Creator) on (2024-12-27 23:26:48 UTC): My local pre-commit didn't fix the exact issue even with `--all-files`. Suspecting from old image, rebuilding and trying again now

"
2761252711,pull_request,closed,,Fix XCom value deserialization in Task SDK,"Fixing this so main works with most of the XCom example. But proper fix will be part of https://github.com/apache/airflow/issues/45231

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-27 20:33:29+00:00,[],2024-12-27 20:44:52+00:00,2024-12-27 20:44:50+00:00,https://github.com/apache/airflow/pull/45254,"[('area:task-sdk', None)]",[],
2761212968,pull_request,closed,,Fixed Issue #45116,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45116
related: #40470

<!-- Please keep an empty line above the dashes. -->

The fix adds a ""Logout"" button to the navbar_menu and uses supporting JavaScript to send a POST request to the ```/logout``` endpoint. Additionally, it also fixes a duplicate text of ""login"" associated with the login button.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Spaarsh,2024-12-27 19:36:09+00:00,[],2024-12-29 20:49:54+00:00,2024-12-28 22:04:12+00:00,https://github.com/apache/airflow/pull/45253,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2563977661, 'issue_id': 2761212968, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 27, 19, 36, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563982758, 'issue_id': 2761212968, 'author': 'Spaarsh', 'body': 'This how the logout button shall look in the GUI:\r\n### GUI with the new Logout button:\r\n<video src=""https://github.com/user-attachments/assets/049f129a-dbc1-4abb-96f7-df7810d6962e"" width=""320"" height=""240"" controls></video>\r\n\r\n### GUI after removing additional ""login"" text:\r\n<video src=""https://github.com/user-attachments/assets/1c149afe-c0d3-4630-b30c-842d1d24881a"" width=""320"" height=""240"" controls></video>', 'created_at': datetime.datetime(2024, 12, 27, 19, 44, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564002436, 'issue_id': 2761212968, 'author': 'Spaarsh', 'body': 'The current fix is not a clean one. I did go through the code to make a cleaner fix which would involve including the ""logout"" in one of the functions in \r\n[base_auth_manager.py](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/airflow/auth/managers/base_auth_manager.py#L398C1-L423C1):\r\n```\r\n    def filter_permitted_menu_items(self, menu_items: list[MenuItem]) -> list[MenuItem]:\r\n        """"""\r\n        Filter menu items based on user permissions.\r\n\r\n\r\n        :param menu_items: list of all menu items\r\n        """"""\r\n        items = filter(\r\n            lambda item: self.security_manager.has_access(ACTION_CAN_ACCESS_MENU, item.name), menu_items\r\n        )\r\n        accessible_items = []\r\n        for menu_item in items:\r\n            menu_item_copy = MenuItem(\r\n                **{\r\n                    **menu_item.__dict__,\r\n                    ""childs"": [],\r\n                }\r\n            )\r\n            if menu_item.childs:\r\n                accessible_children = []\r\n                for child in menu_item.childs:\r\n                    if self.security_manager.has_access(ACTION_CAN_ACCESS_MENU, child.name):\r\n                        accessible_children.append(child)\r\n                menu_item_copy.childs = accessible_children\r\n            accessible_items.append(menu_item_copy)\r\n        return accessible_items\r\n```\r\nThe reason being that this menu list is called in the [```navbar_menu.html```](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/airflow/www/templates/appbuilder/navbar_menu.html#L36C1-L60C13)\r\n\r\nEnabling these changes further requires changes in the [security_manager.py](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/airflow/www/security_manager.py#L119C4-L140C68). Is this the correct approach? I did attempt to implement these but that just lead to the need for more changes.\r\n\r\nAlso, I think that the version checking condition in the [override.py](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/providers/src/airflow/providers/fab/auth_manager/security_manager/override.py#L135C1-L140C24) can now be removed if it had been implemented solely due to the GET request at /logout endpoint.', 'created_at': datetime.datetime(2024, 12, 27, 20, 13, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564080648, 'issue_id': 2761212968, 'author': 'jscheffl', 'body': 'From the screencast I see that you have not properly compiled www-assets before running the UI. This has side effects of missing scripts.\r\n\r\nWhat I do not understand is the fix you are attempting to contribute. There IS already a logout menu entry behind the profile:\r\n![image](https://github.com/user-attachments/assets/e1c2e133-1ce1-4150-a850-710becd6738f)\r\nWhy do you plan to add another in this PR?', 'created_at': datetime.datetime(2024, 12, 27, 23, 2, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564462491, 'issue_id': 2761212968, 'author': 'Spaarsh', 'body': '@jscheffl @shahar1 my sincere apologies for this mishap. I have compiled the www-assets (sorry for this mistake). In my previous comment under the issue, I had presumed that the person who opened the issue tried to go to the /logout/ endpoint in the browser to logout. I should have asked them how exactly was the error occurring. The only instance of 405 error I got was when I tried to enter the /logout/ in the browser. Hence my assumption. \r\n\r\nAgain, my apologies for this bad PR. I will make a comment under the issue to understand how to recreate the error. Should I close my PR until then?', 'created_at': datetime.datetime(2024, 12, 28, 20, 59, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564488156, 'issue_id': 2761212968, 'author': 'shahar1', 'body': ""> @jscheffl @shahar1 my sincere apologies for this mishap. I have compiled the www-assets (sorry for this mistake). In my previous comment under the issue, I had presumed that the person who opened the issue tried to go to the /logout/ endpoint in the browser to logout. I should have asked them how exactly was the error occurring. The only instance of 405 error I got was when I tried to enter the /logout/ in the browser. Hence my assumption. \n> \n> Again, my apologies for this bad PR. I will make a comment under the issue to understand how to recreate the error. Should I close my PR until then?\n\nTry to take it easy. Nothing bad happened :)\nYou could close this PR for now - try to figure out if you can reproduce the issue. If you can, you may create a new PR to fix it - otherwise, there's plenty of other issues that you could tackle."", 'created_at': datetime.datetime(2024, 12, 28, 21, 41, 38, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-27 19:36:14 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

Spaarsh (Issue Creator) on (2024-12-27 19:44:57 UTC): This how the logout button shall look in the GUI:
### GUI with the new Logout button:
<video src=""https://github.com/user-attachments/assets/049f129a-dbc1-4abb-96f7-df7810d6962e"" width=""320"" height=""240"" controls></video>

### GUI after removing additional ""login"" text:
<video src=""https://github.com/user-attachments/assets/1c149afe-c0d3-4630-b30c-842d1d24881a"" width=""320"" height=""240"" controls></video>

Spaarsh (Issue Creator) on (2024-12-27 20:13:02 UTC): The current fix is not a clean one. I did go through the code to make a cleaner fix which would involve including the ""logout"" in one of the functions in 
[base_auth_manager.py](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/airflow/auth/managers/base_auth_manager.py#L398C1-L423C1):
```
    def filter_permitted_menu_items(self, menu_items: list[MenuItem]) -> list[MenuItem]:
        """"""
        Filter menu items based on user permissions.


        :param menu_items: list of all menu items
        """"""
        items = filter(
            lambda item: self.security_manager.has_access(ACTION_CAN_ACCESS_MENU, item.name), menu_items
        )
        accessible_items = []
        for menu_item in items:
            menu_item_copy = MenuItem(
                **{
                    **menu_item.__dict__,
                    ""childs"": [],
                }
            )
            if menu_item.childs:
                accessible_children = []
                for child in menu_item.childs:
                    if self.security_manager.has_access(ACTION_CAN_ACCESS_MENU, child.name):
                        accessible_children.append(child)
                menu_item_copy.childs = accessible_children
            accessible_items.append(menu_item_copy)
        return accessible_items
```
The reason being that this menu list is called in the [```navbar_menu.html```](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/airflow/www/templates/appbuilder/navbar_menu.html#L36C1-L60C13)

Enabling these changes further requires changes in the [security_manager.py](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/airflow/www/security_manager.py#L119C4-L140C68). Is this the correct approach? I did attempt to implement these but that just lead to the need for more changes.

Also, I think that the version checking condition in the [override.py](https://github.com/apache/airflow/blob/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019/providers/src/airflow/providers/fab/auth_manager/security_manager/override.py#L135C1-L140C24) can now be removed if it had been implemented solely due to the GET request at /logout endpoint.

jscheffl on (2024-12-27 23:02:28 UTC): From the screencast I see that you have not properly compiled www-assets before running the UI. This has side effects of missing scripts.

What I do not understand is the fix you are attempting to contribute. There IS already a logout menu entry behind the profile:
![image](https://github.com/user-attachments/assets/e1c2e133-1ce1-4150-a850-710becd6738f)
Why do you plan to add another in this PR?

Spaarsh (Issue Creator) on (2024-12-28 20:59:57 UTC): @jscheffl @shahar1 my sincere apologies for this mishap. I have compiled the www-assets (sorry for this mistake). In my previous comment under the issue, I had presumed that the person who opened the issue tried to go to the /logout/ endpoint in the browser to logout. I should have asked them how exactly was the error occurring. The only instance of 405 error I got was when I tried to enter the /logout/ in the browser. Hence my assumption. 

Again, my apologies for this bad PR. I will make a comment under the issue to understand how to recreate the error. Should I close my PR until then?

shahar1 on (2024-12-28 21:41:38 UTC): Try to take it easy. Nothing bad happened :)
You could close this PR for now - try to figure out if you can reproduce the issue. If you can, you may create a new PR to fix it - otherwise, there's plenty of other issues that you could tackle.

"
2761208560,pull_request,closed,,Remove Python <3.9 code from main,"Fixed the test to include typing.Dict and removed the old skipif check.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-27 19:29:42+00:00,[],2024-12-27 20:24:18+00:00,2024-12-27 20:24:16+00:00,https://github.com/apache/airflow/pull/45252,[],[],
2761195515,pull_request,closed,,Edit variable button on variable list page,"related: https://github.com/apache/airflow/issues/43709

Note:
This needs to rebase on https://github.com/apache/airflow/pull/45238, once that is merged.

<img width=""943"" alt=""image"" src=""https://github.com/user-attachments/assets/561e3dd6-9599-42a5-acc2-f14a232248b8"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-27 19:10:36+00:00,[],2024-12-29 19:23:22+00:00,2024-12-29 19:23:22+00:00,https://github.com/apache/airflow/pull/45251,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2563983465, 'issue_id': 2761195515, 'author': 'shubhamraj-git', 'body': '@pierrejeambrun @jscheffl @bbovenzi \r\n\r\nI can see that the patch variable api have a check \r\n```\r\nif patch_body.key != variable_key:\r\n        raise HTTPException(\r\n            status.HTTP_400_BAD_REQUEST, ""Invalid body, key from request body doesn\'t match uri parameter""\r\n        )\r\n    non_update_fields = {""key""}\r\n```\r\n\r\nIs this introduced new that we can\'t edit the variable key?\r\nI checked in the legacy UI and I was able to edit it.', 'created_at': datetime.datetime(2024, 12, 27, 19, 46, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564378237, 'issue_id': 2761195515, 'author': 'shubhamraj-git', 'body': '@jscheffl I am open to suggestion on this, if we have something better.\r\nMy only take on this was, we are going to have import vars, export var, delete multiple, action bars soon. So, it will contain lot of files, so just made the proper CRUD under a folder.', 'created_at': datetime.datetime(2024, 12, 28, 16, 48, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564378607, 'issue_id': 2761195515, 'author': 'jscheffl', 'body': '> @pierrejeambrun @jscheffl @bbovenzi\r\n> \r\n> I can see that the patch variable api have a check\r\n> \r\n> ```\r\n> if patch_body.key != variable_key:\r\n>         raise HTTPException(\r\n>             status.HTTP_400_BAD_REQUEST, ""Invalid body, key from request body doesn\'t match uri parameter""\r\n>         )\r\n>     non_update_fields = {""key""}\r\n> ```\r\n> \r\n> Is this introduced new that we can\'t edit the variable key? I checked in the legacy UI and I was able to edit it.\r\n\r\nI believe that this is an artefact from the migration of public API from Connexion to Fast API, this validation was converted 1:1.\r\nThe legacy UI was _not_ using the public API but was directly writing to DB.\r\n\r\nSo technically we have two options:\r\n1. Restrict changing the key in UI, make the key field read-only when editing\r\n2. Remove the validation in Rest API\r\n3. Add a UI specific API just for this\r\n\r\nFrom UI Perspective dis-allowing to change the key does not make sense. So I\'d propose to remove the validation in REST API. For option 1 I see no reason. And Option 3 is too much overhead just because of a cross-validation in API\r\n\r\nAny other opinions?', 'created_at': datetime.datetime(2024, 12, 28, 16, 50, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564378654, 'issue_id': 2761195515, 'author': 'shubhamraj-git', 'body': '> @pierrejeambrun @jscheffl @bbovenzi\r\n> \r\n> I can see that the patch variable api have a check\r\n> \r\n> ```\r\n> if patch_body.key != variable_key:\r\n>         raise HTTPException(\r\n>             status.HTTP_400_BAD_REQUEST, ""Invalid body, key from request body doesn\'t match uri parameter""\r\n>         )\r\n>     non_update_fields = {""key""}\r\n> ```\r\n> \r\n> Is this introduced new that we can\'t edit the variable key? I checked in the legacy UI and I was able to edit it.\r\n\r\nAlso regrading this issue.\r\n\r\nIf we plan to implement this.\r\n1. I can have a PR where I will disable the key edit.\r\n2. But if we chose to remove this check from backend, I can have a PR to do that.', 'created_at': datetime.datetime(2024, 12, 28, 16, 50, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564386485, 'issue_id': 2761195515, 'author': 'shubhamraj-git', 'body': ""> I believe that this is an artefact from the migration of public API from Connexion to Fast API, this validation was converted 1:1. The legacy UI was _not_ using the public API but was directly writing to DB.\r\n> \r\n> So technically we have two options:\r\n> \r\n> 1. Restrict changing the key in UI, make the key field read-only when editing\r\n> 2. Remove the validation in Rest API\r\n> 3. Add a UI specific API just for this\r\n> \r\n> From UI Perspective dis-allowing to change the key does not make sense. So I'd propose to remove the validation in REST API. For option 1 I see no reason. And Option 3 is too much overhead just because of a cross-validation in API\r\n> \r\n> Any other opinions?\r\n\r\nRegarding option 1)\r\nIf we change the key itself, I think we actually created a new variable itself, Isn't this contradicting to edit behaviour? Like users will need to actual change the references too in that case.\r\n\r\nI think this can have a discussion and can be fixed later in other PR, what say?"", 'created_at': datetime.datetime(2024, 12, 28, 17, 30, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564799615, 'issue_id': 2761195515, 'author': 'shubhamraj-git', 'body': '@potiuk @pierrejeambrun @jscheffl \r\nBased upon the discussion, https://apache-airflow.slack.com/archives/C07813CNKA8/p1735405229925579\r\nI have disabled the variable key edit from UI side.', 'created_at': datetime.datetime(2024, 12, 29, 17, 59, 17, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2024-12-27 19:46:03 UTC): @pierrejeambrun @jscheffl @bbovenzi 

I can see that the patch variable api have a check 
```
if patch_body.key != variable_key:
        raise HTTPException(
            status.HTTP_400_BAD_REQUEST, ""Invalid body, key from request body doesn't match uri parameter""
        )
    non_update_fields = {""key""}
```

Is this introduced new that we can't edit the variable key?
I checked in the legacy UI and I was able to edit it.

shubhamraj-git (Issue Creator) on (2024-12-28 16:48:21 UTC): @jscheffl I am open to suggestion on this, if we have something better.
My only take on this was, we are going to have import vars, export var, delete multiple, action bars soon. So, it will contain lot of files, so just made the proper CRUD under a folder.

jscheffl on (2024-12-28 16:50:17 UTC): I believe that this is an artefact from the migration of public API from Connexion to Fast API, this validation was converted 1:1.
The legacy UI was _not_ using the public API but was directly writing to DB.

So technically we have two options:
1. Restrict changing the key in UI, make the key field read-only when editing
2. Remove the validation in Rest API
3. Add a UI specific API just for this

From UI Perspective dis-allowing to change the key does not make sense. So I'd propose to remove the validation in REST API. For option 1 I see no reason. And Option 3 is too much overhead just because of a cross-validation in API

Any other opinions?

shubhamraj-git (Issue Creator) on (2024-12-28 16:50:36 UTC): Also regrading this issue.

If we plan to implement this.
1. I can have a PR where I will disable the key edit.
2. But if we chose to remove this check from backend, I can have a PR to do that.

shubhamraj-git (Issue Creator) on (2024-12-28 17:30:42 UTC): Regarding option 1)
If we change the key itself, I think we actually created a new variable itself, Isn't this contradicting to edit behaviour? Like users will need to actual change the references too in that case.

I think this can have a discussion and can be fixed later in other PR, what say?

shubhamraj-git (Issue Creator) on (2024-12-29 17:59:17 UTC): @potiuk @pierrejeambrun @jscheffl 
Based upon the discussion, https://apache-airflow.slack.com/archives/C07813CNKA8/p1735405229925579
I have disabled the variable key edit from UI side.

"
2761172953,pull_request,closed,,[v2-10-test] Fixed the endless reschedule (#45224),"(cherry picked from commit 7f2b8ef5acf95b7fb8faa38a10caf94c043f5019)

See #45224 - Note - needed to alter the patch due to internal-API

FYI @morooshka ",jscheffl,2024-12-27 18:38:54+00:00,[],2024-12-27 22:50:57+00:00,2024-12-27 22:50:57+00:00,https://github.com/apache/airflow/pull/45250,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2761129391,pull_request,closed,,Fix test collection for Connection and Variables for non-db tests,"When Tests were collected for microsoft provider alone for non-db tests, Connection were used in ""parametrized"" to perameterize the tests. This was only working accidentally so far because all ORM models were loaded before in other tests - including Triggers -and then the connection objects did not trigger any DB operations. But when microsoft provider tests were run first (and in separation), the Triggers were not imported and Connection creation caused error:

> When initializing mapper mapped class AssetModel->asset, expression
  'Trigger' failed to locate a name ('Trigger') # Please enter the commit
  message for your changes. Lines starting

This can be mitigated (as already advised in unit tests documentation) by replacing Connections with MagicMock.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-27 17:42:25+00:00,[],2024-12-27 20:23:05+00:00,2024-12-27 20:23:03+00:00,https://github.com/apache/airflow/pull/45249,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('area:dev-tools', '')]","[{'comment_id': 2563905999, 'issue_id': 2761129391, 'author': 'potiuk', 'body': 'Discovered when looking why https://github.com/apache/airflow/pull/45249 has been failing - very interesting side-effect in our tests', 'created_at': datetime.datetime(2024, 12, 27, 17, 45, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563910580, 'issue_id': 2761129391, 'author': 'potiuk', 'body': '> Interesting one :)\r\n\r\nIndeed - we should likely improve some of the diagnostics there and fail ""earlier"" and with ""clearer"" message - but for now this one should be ""good enough""', 'created_at': datetime.datetime(2024, 12, 27, 17, 52, 34, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-27 17:45:37 UTC): Discovered when looking why https://github.com/apache/airflow/pull/45249 has been failing - very interesting side-effect in our tests

potiuk (Issue Creator) on (2024-12-27 17:52:34 UTC): Indeed - we should likely improve some of the diagnostics there and fail ""earlier"" and with ""clearer"" message - but for now this one should be ""good enough""

"
2761118632,pull_request,closed,,More controls for pgbouncer secrets configuration,"closes: #45171

Allow to disable adding default secret mounts for pgbouncer configs as well as metrics exported database url env variable. This can be useful for cases, where the value is retrieved other way, e.g. secrets provider class.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",andrii-korotkov-verkada,2024-12-27 17:28:33+00:00,[],2025-01-12 08:19:31+00:00,2025-01-12 08:19:28+00:00,https://github.com/apache/airflow/pull/45248,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2564581730, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': ""I've refined the functionality and added the tests."", 'created_at': datetime.datetime(2024, 12, 29, 1, 52, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564581895, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': 'Also, if this gets merged, how can I release a new chart version?', 'created_at': datetime.datetime(2024, 12, 29, 1, 54, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564628297, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': ""How do I trigger tests for Helm etc.? Are they automatically triggered after some time or just don't update the checks summary at first?"", 'created_at': datetime.datetime(2024, 12, 29, 6, 27, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564836967, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': '![Screenshot 2024-12-29 at 12 58 32\u202fPM](https://github.com/user-attachments/assets/23bd5bde-e4c9-4fe8-b35a-6a242c8fee89)\r\n\r\nI see, it has to be maintainer-approved. Curious if at least some tests can be made to run by default. That can greatly speed up the iteration.', 'created_at': datetime.datetime(2024, 12, 29, 20, 59, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564838370, 'issue_id': 2761118632, 'author': 'potiuk', 'body': ""> I see, it has to be maintainer-approved. Curious if at least some tests can be made to run by default. That can greatly speed up the iteration.\r\n\r\nNot until your first PR gets merged. This is protection against bots mining bitcoins and roque PRs trying to exploit weaknesses in Github Actions, and it's mandated by the Infra and security team of The ASF."", 'created_at': datetime.datetime(2024, 12, 29, 21, 5, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564838730, 'issue_id': 2761118632, 'author': 'potiuk', 'body': 'But you can run exactly the same tests locally -> All tests that are run in CI are runnable locally - that is basic assumptions for our CI system https://github.com/apache/airflow/tree/main/contributing-docs/testing -> you can see more details about all the types of tests we have and how to reproduce them locally 1:1', 'created_at': datetime.datetime(2024, 12, 29, 21, 7, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564852291, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': ""> Not until your first PR gets merged. This is protection against bots mining bitcoins and roque PRs trying to exploit weaknesses in Github Actions, and it's mandated by the Infra and security team of The ASF.\r\n\r\nAh, I see, that makes sense.\r\n\r\n> But you can run exactly the same tests locally -> All tests that are run in CI are runnable locally - that is basic assumptions for our CI system https://github.com/apache/airflow/tree/main/contributing-docs/testing -> you can see more details about all the types of tests we have and how to reproduce them locally 1:1\r\n\r\nThanks for the hints, I've naively tried to just run pytest with no args :)"", 'created_at': datetime.datetime(2024, 12, 29, 22, 18, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564853878, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': 'Tho I might be running into some incompatibility issues with pytest\r\n```\r\nERROR: while parsing the following warning configuration:\r\n\r\n  error::pytest.PytestReturnNotNoneWarning\r\n\r\nThis error occurred:\r\n\r\nTraceback (most recent call last):\r\n  File ""/Users/andrii.korotkov/.pyenv/versions/3.10.12/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1638, in parse_warning_filter\r\n    category: Type[Warning] = _resolve_warning_category(category_)\r\n  File ""/Users/andrii.korotkov/.pyenv/versions/3.10.12/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1677, in _resolve_warning_category\r\n    cat = getattr(m, klass)\r\n  File ""/Users/andrii.korotkov/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pytest/__init__.py"", line 165, in __getattr__\r\n    raise AttributeError(f""module {__name__} has no attribute {name}"")\r\nAttributeError: module pytest has no attribute PytestReturnNotNoneWarning\r\n```', 'created_at': datetime.datetime(2024, 12, 29, 22, 26, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564853900, 'issue_id': 2761118632, 'author': 'potiuk', 'body': '> Thanks for the hints, I\'ve naively tried to just run pytest :)\r\n\r\nIt works as long as you have the same environment. \r\n\r\nThose instructions on running tests are explaining how to get the SAME environment to run your pytest command in - in general.  To avoid ""works for me"" (or rather ""does not work for me""). \r\n\r\nAirflow has 700+ dependencies, 3 different databases in 8 versions, 10 integrations, kubernetes and a number of other variations - recreating it all by **just** running pytest is a nice dream (and our vision in the future with testcontainers and other things) - but so far adding tools to make things running in reproducible way is a bit more efficient (as long as you follow it).', 'created_at': datetime.datetime(2024, 12, 29, 22, 27, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564854346, 'issue_id': 2761118632, 'author': 'potiuk', 'body': '> Tho I might be running into some incompatibility issues with pytest\r\n\r\nJust follow the docs.  Breeze is best to reproduce the env. You can also use `uv` for local venv. But the docs are complete and explain what to do.', 'created_at': datetime.datetime(2024, 12, 29, 22, 29, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564874289, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': ""I've got non-db unit tests, helm tests and k8s tests to pass when running with breeze."", 'created_at': datetime.datetime(2024, 12, 30, 0, 6, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566454261, 'issue_id': 2761118632, 'author': 'potiuk', 'body': ""> I've got non-db unit tests, helm tests and k8s tests to pass when running with breeze.\r\n\r\n![image](https://github.com/user-attachments/assets/90d87a62-6460-4dd8-9e50-5be7d5b9a939)\r\n\r\n\r\nAlways Be Rebased."", 'created_at': datetime.datetime(2024, 12, 31, 13, 25, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580696816, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': ""Do you know why this error might happen?\r\n```\r\nError: Failed to CreateArtifact: Received non-retryable error: Failed request: (409) Conflict: an artifact with this name already exists on the workflow run\r\n```\r\nI don't think I control artifact names in the PR, at least not directly..."", 'created_at': datetime.datetime(2025, 1, 9, 16, 15, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585119317, 'issue_id': 2761118632, 'author': 'andrii-korotkov-verkada', 'body': ""I've used it in a live environment and it works well."", 'created_at': datetime.datetime(2025, 1, 11, 6, 36, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585637256, 'issue_id': 2761118632, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 12, 8, 19, 30, tzinfo=datetime.timezone.utc)}]","andrii-korotkov-verkada (Issue Creator) on (2024-12-29 01:52:57 UTC): I've refined the functionality and added the tests.

andrii-korotkov-verkada (Issue Creator) on (2024-12-29 01:54:01 UTC): Also, if this gets merged, how can I release a new chart version?

andrii-korotkov-verkada (Issue Creator) on (2024-12-29 06:27:37 UTC): How do I trigger tests for Helm etc.? Are they automatically triggered after some time or just don't update the checks summary at first?

andrii-korotkov-verkada (Issue Creator) on (2024-12-29 20:59:36 UTC): ![Screenshot 2024-12-29 at 12 58 32â€¯PM](https://github.com/user-attachments/assets/23bd5bde-e4c9-4fe8-b35a-6a242c8fee89)

I see, it has to be maintainer-approved. Curious if at least some tests can be made to run by default. That can greatly speed up the iteration.

potiuk on (2024-12-29 21:05:52 UTC): Not until your first PR gets merged. This is protection against bots mining bitcoins and roque PRs trying to exploit weaknesses in Github Actions, and it's mandated by the Infra and security team of The ASF.

potiuk on (2024-12-29 21:07:17 UTC): But you can run exactly the same tests locally -> All tests that are run in CI are runnable locally - that is basic assumptions for our CI system https://github.com/apache/airflow/tree/main/contributing-docs/testing -> you can see more details about all the types of tests we have and how to reproduce them locally 1:1

andrii-korotkov-verkada (Issue Creator) on (2024-12-29 22:18:17 UTC): Ah, I see, that makes sense.


Thanks for the hints, I've naively tried to just run pytest with no args :)

andrii-korotkov-verkada (Issue Creator) on (2024-12-29 22:26:53 UTC): Tho I might be running into some incompatibility issues with pytest
```
ERROR: while parsing the following warning configuration:

  error::pytest.PytestReturnNotNoneWarning

This error occurred:

Traceback (most recent call last):
  File ""/Users/andrii.korotkov/.pyenv/versions/3.10.12/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1638, in parse_warning_filter
    category: Type[Warning] = _resolve_warning_category(category_)
  File ""/Users/andrii.korotkov/.pyenv/versions/3.10.12/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 1677, in _resolve_warning_category
    cat = getattr(m, klass)
  File ""/Users/andrii.korotkov/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pytest/__init__.py"", line 165, in __getattr__
    raise AttributeError(f""module {__name__} has no attribute {name}"")
AttributeError: module pytest has no attribute PytestReturnNotNoneWarning
```

potiuk on (2024-12-29 22:27:03 UTC): It works as long as you have the same environment. 

Those instructions on running tests are explaining how to get the SAME environment to run your pytest command in - in general.  To avoid ""works for me"" (or rather ""does not work for me""). 

Airflow has 700+ dependencies, 3 different databases in 8 versions, 10 integrations, kubernetes and a number of other variations - recreating it all by **just** running pytest is a nice dream (and our vision in the future with testcontainers and other things) - but so far adding tools to make things running in reproducible way is a bit more efficient (as long as you follow it).

potiuk on (2024-12-29 22:29:04 UTC): Just follow the docs.  Breeze is best to reproduce the env. You can also use `uv` for local venv. But the docs are complete and explain what to do.

andrii-korotkov-verkada (Issue Creator) on (2024-12-30 00:06:35 UTC): I've got non-db unit tests, helm tests and k8s tests to pass when running with breeze.

potiuk on (2024-12-31 13:25:50 UTC): ![image](https://github.com/user-attachments/assets/90d87a62-6460-4dd8-9e50-5be7d5b9a939)


Always Be Rebased.

andrii-korotkov-verkada (Issue Creator) on (2025-01-09 16:15:14 UTC): Do you know why this error might happen?
```
Error: Failed to CreateArtifact: Received non-retryable error: Failed request: (409) Conflict: an artifact with this name already exists on the workflow run
```
I don't think I control artifact names in the PR, at least not directly...

andrii-korotkov-verkada (Issue Creator) on (2025-01-11 06:36:08 UTC): I've used it in a live environment and it works well.

boring-cyborg[bot] on (2025-01-12 08:19:30 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2760981132,pull_request,closed,,AIP-72: Push XCom on Task Return,"closes https://github.com/apache/airflow/issues/45230

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-27 15:00:10+00:00,[],2024-12-27 17:57:54+00:00,2024-12-27 17:57:52+00:00,https://github.com/apache/airflow/pull/45245,"[('area:task-sdk', None)]",[],
2760885719,pull_request,closed,,Import missing modules when importing all DB models,"Importing all modules did not include importing trigger module, and this caused strange errors when running tests that never imported Trigger separately.

Similaarly Xcom and Variables have not been imported

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-27 13:27:46+00:00,[],2024-12-27 15:28:19+00:00,2024-12-27 15:28:19+00:00,https://github.com/apache/airflow/pull/45244,[],"[{'comment_id': 2563704018, 'issue_id': 2760885719, 'author': 'potiuk', 'body': ""Example errors appearing in xdist tests here: \r\n\r\nhttps://github.com/apache/airflow/actions/runs/12515046642/job/34913595134?pr=44126#step:7:3627\r\n\r\n\r\n```\r\nFAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_multiple_function_definition - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\nFAILED providers/tests/microsoft/azure/triggers/test_msgraph.py::TestMSGraphTrigger::test_run_when_response_is_bytes - AssertionError: assert equals failed\r\n  'failure'  'success'\r\nFAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_duplicate_facet_keys - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\nFAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_invalid_function_definition - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\nFAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_wrong_return_type_function - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\nFAILED providers/tests/microsoft/azure/triggers/test_msgraph.py::TestMSGraphTrigger::test_serialize - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\nFAILED providers/tests/microsoft/azure/triggers/test_powerbi.py::TestPowerBITrigger::test_powerbi_trigger_serialization - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\nFAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_exception - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.\r\n```"", 'created_at': datetime.datetime(2024, 12, 27, 13, 29, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563710255, 'issue_id': 2760885719, 'author': 'potiuk', 'body': 'lso it is likely that this one was impacting some other ways Airflow DB is initialized: https://github.com/apache/airflow/discussions/45236', 'created_at': datetime.datetime(2024, 12, 27, 13, 37, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563712622, 'issue_id': 2760885719, 'author': 'potiuk', 'body': 'I am not sure if we are missing other models here, but generally, depending on what sequence imports happened our DB scripts could ""forget"" to create certain tables, and our tests were failing with missing associations if referred DB models were not imported in earlier tests.\r\n\r\nThis is somewhat a weakness of our ""imports"" doing a lot of work implicitly (and sometimes forgetting to do it).', 'created_at': datetime.datetime(2024, 12, 27, 13, 40, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563722772, 'issue_id': 2760885719, 'author': 'potiuk', 'body': 'Though @uranusjr @ashb -> I am not sure if this is right - I also saw that there are those __getrr_ calls for all lazy imports, so I am not at all sure if this is the right approach what I am doing - this mechanism of sometimes lazy, sometimes not importing of modules is .... complex ... and I am not sure what the intentions were to have some of the modules lazy and some not... So I am not all sure if what I am doing here is fine.', 'created_at': datetime.datetime(2024, 12, 27, 13, 52, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563802153, 'issue_id': 2760885719, 'author': 'potiuk', 'body': 'Nope. It does not help;', 'created_at': datetime.datetime(2024, 12, 27, 15, 28, 19, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-27 13:29:50 UTC): Example errors appearing in xdist tests here: 

https://github.com/apache/airflow/actions/runs/12515046642/job/34913595134?pr=44126#step:7:3627


```
FAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_multiple_function_definition - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
FAILED providers/tests/microsoft/azure/triggers/test_msgraph.py::TestMSGraphTrigger::test_run_when_response_is_bytes - AssertionError: assert equals failed
  'failure'  'success'
FAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_duplicate_facet_keys - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
FAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_invalid_function_definition - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
FAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_wrong_return_type_function - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
FAILED providers/tests/microsoft/azure/triggers/test_msgraph.py::TestMSGraphTrigger::test_serialize - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
FAILED providers/tests/microsoft/azure/triggers/test_powerbi.py::TestPowerBITrigger::test_powerbi_trigger_serialization - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
FAILED providers/tests/openlineage/utils/test_utils.py::test_get_user_provided_run_facets_with_exception - sqlalchemy.exc.InvalidRequestError: One or more mappers failed to initialize - can't proceed with initialization of other mappers. Triggering mapper: 'mapped class AssetModel->asset'. Original exception was: When initializing mapper mapped class AssetModel->asset, expression 'Trigger' failed to locate a name ('Trigger'). If this is a class name, consider adding this relationship() to the <class 'airflow.models.asset.AssetModel'> class after both dependent classes have been defined.
```

potiuk (Issue Creator) on (2024-12-27 13:37:30 UTC): lso it is likely that this one was impacting some other ways Airflow DB is initialized: https://github.com/apache/airflow/discussions/45236

potiuk (Issue Creator) on (2024-12-27 13:40:19 UTC): I am not sure if we are missing other models here, but generally, depending on what sequence imports happened our DB scripts could ""forget"" to create certain tables, and our tests were failing with missing associations if referred DB models were not imported in earlier tests.

This is somewhat a weakness of our ""imports"" doing a lot of work implicitly (and sometimes forgetting to do it).

potiuk (Issue Creator) on (2024-12-27 13:52:28 UTC): Though @uranusjr @ashb -> I am not sure if this is right - I also saw that there are those __getrr_ calls for all lazy imports, so I am not at all sure if this is the right approach what I am doing - this mechanism of sometimes lazy, sometimes not importing of modules is .... complex ... and I am not sure what the intentions were to have some of the modules lazy and some not... So I am not all sure if what I am doing here is fine.

potiuk (Issue Creator) on (2024-12-27 15:28:19 UTC): Nope. It does not help;

"
2760763577,pull_request,closed,,feat: Add OpenLineage support for some SQL to GCS operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for some SQL to GCS operators. The logic is very similar (almost the same) as in SQLExecuteQueryOperator where we take advantage of DB hooks being instrumented.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-27 11:24:30+00:00,[],2025-01-08 18:38:41+00:00,2025-01-08 18:02:59+00:00,https://github.com/apache/airflow/pull/45242,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2760762061,pull_request,closed,,Implement AlloyDB create/update/delete instance operators,"- Implemented new AlloyDB operators: create/update/delete instance
- Slightly refactored  cluster operators",moiseenkov,2024-12-27 11:23:00+00:00,[],2024-12-27 11:46:34+00:00,2024-12-27 11:46:33+00:00,https://github.com/apache/airflow/pull/45241,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2760715883,pull_request,closed,,Deprecate page_size parameter for Google Ads API v17 and later versions,"This PR is for deprecating the page_size parameter for Google Ads API.
This is a follow-up PR for https://github.com/apache/airflow/pull/43515.
The page_size parameter is deprecated for v17 and later versions.
Currently Google Ads API supports the version v16 and v16.1. However support for these versions will end at the end of February. Hence we need to deprecate this parameter first and remove it after February.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",molcay,2024-12-27 10:37:10+00:00,[],2025-01-08 09:39:36+00:00,2025-01-07 13:09:42+00:00,https://github.com/apache/airflow/pull/45239,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2574970274, 'issue_id': 2760715883, 'author': 'MaksYermak', 'body': '@potiuk could you please check this PR?', 'created_at': datetime.datetime(2025, 1, 7, 10, 46, 54, tzinfo=datetime.timezone.utc)}]","MaksYermak on (2025-01-07 10:46:54 UTC): @potiuk could you please check this PR?

"
2760682569,pull_request,closed,,Delete variable button on variable list page,"related: https://github.com/apache/airflow/issues/43709

<img width=""943"" alt=""image"" src=""https://github.com/user-attachments/assets/8076fb34-e191-4ad2-93a5-295d66b34b10"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-27 10:10:50+00:00,[],2024-12-28 09:10:18+00:00,2024-12-28 09:10:18+00:00,https://github.com/apache/airflow/pull/45238,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2760541565,pull_request,closed,,Deferrable support for HttpOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Enabling deferrable for HttpOperator causes an error.
The minimum test case is as follows
```
import datetime

from airflow import DAG
from airflow.operators.empty import EmptyOperator
from airflow.providers.http.operators.http import HttpOperator

with DAG(
    dag_id=""my_dag_name"",
    catchup=False,
) as dag:

    test = HttpOperator(
        task_id=""test"",
        method=""GET"",
        http_conn_id=""google_http_default"",
        endpoint=""search?q=airflow"",
        log_response=True,
        deferrable=True,
    )

    EmptyOperator(task_id=""start"") >> test >> EmptyOperator(task_id=""end"")
```

For connections, set Connection Id to â€œgoogle_http_defaultâ€, Connection Type to â€œHTTPâ€ and HOST to â€œhttps://www.google.comâ€.

If you place it in airflow/files/dags/ and run it you will get the following error

```
[2024-12-27, 01:53:21 UTC] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 1814, in resume_execution
    return execute_callable(context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/providers/http/operators/http.py"", line 261, in execute_complete
    raise AirflowException(f""Unexpected error in the operation: {event['message']}"")
airflow.exceptions.AirflowException: Unexpected error in the operation: Connection closed.
```

Causes:.

https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/triggers/http .py#L97
A session object is created by the above caller.

It is at the following link
https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/hooks/http.py #L413

The following is then called.
https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/triggers/http .py#L103

https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/triggers/http .py#L117
It is expected that the ClientSession is alive at this point, but it is already out of scope and disconnected.

To properly correct this, we changed the configuration to the following Previously, the opposite was the case, which caused the bug.

Correct.
ClientSession scope {
  ClientResponse scope{
    response.read
  }
}

Incorrect
ClientResponse scope {
  ClientSession scope {
  }
  response.read expect session living (error)
}

With the interface changes, we modified the required tests, re-ran the required tests, and verified that they completed successfully. I would be happy to check and review! Best regards.

Takayuki Tanabe

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",TakayukiTanabeSS,2024-12-27 07:51:36+00:00,[],2025-01-17 04:48:40+00:00,2025-01-17 04:48:37+00:00,https://github.com/apache/airflow/pull/45228,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2563426694, 'issue_id': 2760541565, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 27, 7, 51, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569461337, 'issue_id': 2760541565, 'author': 'TakayukiTanabeSS', 'body': '@Lee-W Thank you for reviewing! I will resume work on this matter from January 6th, so please wait for two days.', 'created_at': datetime.datetime(2025, 1, 3, 16, 0, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572451688, 'issue_id': 2760541565, 'author': 'TakayukiTanabeSS', 'body': ""@Lee-W I've made modifications according to your review! Please check again."", 'created_at': datetime.datetime(2025, 1, 6, 7, 22, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2588795294, 'issue_id': 2760541565, 'author': 'Lee-W', 'body': 'The CI seems weird ðŸ¤”  let me rebase and see how it works', 'created_at': datetime.datetime(2025, 1, 14, 2, 52, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589015408, 'issue_id': 2760541565, 'author': 'TakayukiTanabeSS', 'body': 'Thank you!\r\nIt was a great experience working with you.', 'created_at': datetime.datetime(2025, 1, 14, 5, 9, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591458301, 'issue_id': 2760541565, 'author': 'Lee-W', 'body': ""> Thank you! It was a great experience working with you.\r\n\r\nOpps, I notice there's a static check error. Should be a quick fix. ðŸ™‚"", 'created_at': datetime.datetime(2025, 1, 15, 1, 42, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594729698, 'issue_id': 2760541565, 'author': 'TakayukiTanabeSS', 'body': 'i did rebase and work on the quick fix!', 'created_at': datetime.datetime(2025, 1, 16, 7, 37, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594903806, 'issue_id': 2760541565, 'author': 'TakayukiTanabeSS', 'body': '@Lee-W Corrections have been made concerning the linter! Please check.', 'created_at': datetime.datetime(2025, 1, 16, 8, 47, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597428642, 'issue_id': 2760541565, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 17, 4, 48, 39, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-27 07:51:40 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

TakayukiTanabeSS (Issue Creator) on (2025-01-03 16:00:18 UTC): @Lee-W Thank you for reviewing! I will resume work on this matter from January 6th, so please wait for two days.

TakayukiTanabeSS (Issue Creator) on (2025-01-06 07:22:47 UTC): @Lee-W I've made modifications according to your review! Please check again.

Lee-W on (2025-01-14 02:52:25 UTC): The CI seems weird ðŸ¤”  let me rebase and see how it works

TakayukiTanabeSS (Issue Creator) on (2025-01-14 05:09:20 UTC): Thank you!
It was a great experience working with you.

Lee-W on (2025-01-15 01:42:21 UTC): Opps, I notice there's a static check error. Should be a quick fix. ðŸ™‚

TakayukiTanabeSS (Issue Creator) on (2025-01-16 07:37:52 UTC): i did rebase and work on the quick fix!

TakayukiTanabeSS (Issue Creator) on (2025-01-16 08:47:53 UTC): @Lee-W Corrections have been made concerning the linter! Please check.

boring-cyborg[bot] on (2025-01-17 04:48:39 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2760487907,pull_request,closed,,Deferrable support for HttpOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Enabling deferrable for HttpOperator causes an error.
The minimum test case is as follows
```
import datetime

from airflow import DAG
from airflow.operators.empty import EmptyOperator
from airflow.providers.http.operators.http import HttpOperator

with DAG(
    dag_id=""my_dag_name"",
    catchup=False,
) as dag:

    test = HttpOperator(
        task_id=""test"",
        method=""GET"",
        http_conn_id=""google_http_default"",
        endpoint=""search?q=airflow"",
        log_response=True,
        deferrable=True,
    )

    EmptyOperator(task_id=""start"") >> test >> EmptyOperator(task_id=""end"")
```

For connections, set Connection Id to â€œgoogle_http_defaultâ€, Connection Type to â€œHTTPâ€ and HOST to â€œhttps://www.google.comâ€.

If you place it in airflow/files/dags/ and run it you will get the following error

```
[2024-12-27, 01:53:21 UTC] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 1814, in resume_execution
    return execute_callable(context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/providers/http/operators/http.py"", line 261, in execute_complete
    raise AirflowException(f""Unexpected error in the operation: {event['message']}"")
airflow.exceptions.AirflowException: Unexpected error in the operation: Connection closed.
```

Causes:.

https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/triggers/http .py#L97
A session object is created by the above caller.

It is at the following link
https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/hooks/http.py #L413

The following is then called.
https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/triggers/http .py#L103

https://github.com/apache/airflow/blob/9178f8f0b1ffd80b8eacf4d02b732528fde218e5/providers/src/airflow/providers/http/triggers/http .py#L117
It is expected that the ClientSession is alive at this point, but it is already out of scope and disconnected.

To properly correct this, I changed the configuration to the following Previously, the opposite was the case, which caused the bug.

Correct.
ClientSession scope {
  ClientResponse scope{
    response.read
  }
}

Incorrect
ClientResponse scope {
  ClientSession scope {
  }
  response.read expect session living (error)
}

With the interface changes, I modified the required tests, re-ran the required tests, and verified that they completed successfully. I would be happy to check and review! Best regards.

Takayuki Tanabe

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).",thawk105,2024-12-27 06:55:02+00:00,[],2024-12-27 07:12:57+00:00,2024-12-27 07:12:07+00:00,https://github.com/apache/airflow/pull/45225,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2563388048, 'issue_id': 2760487907, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 27, 6, 55, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563389648, 'issue_id': 2760487907, 'author': 'thawk105', 'body': 'I have added three new commits from the following commitments.\r\n\r\ncommit ef012cf4bb1af675cd09c5f0f21d26df45901214 (origin/v2-10-test, v2-10-test)\r\n\r\nPlease let me know if there are any corrections needed!', 'created_at': datetime.datetime(2024, 12, 27, 6, 57, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563399809, 'issue_id': 2760487907, 'author': 'thawk105', 'body': 'I will cut back from the main branch and re-submit a PR.', 'created_at': datetime.datetime(2024, 12, 27, 7, 12, 56, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-27 06:55:07 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

thawk105 (Issue Creator) on (2024-12-27 06:57:40 UTC): I have added three new commits from the following commitments.

commit ef012cf4bb1af675cd09c5f0f21d26df45901214 (origin/v2-10-test, v2-10-test)

Please let me know if there are any corrections needed!

thawk105 (Issue Creator) on (2024-12-27 07:12:56 UTC): I will cut back from the main branch and re-submit a PR.

"
2760180649,pull_request,closed,,Fixed the endless sensor reschedule,"Fixed the endless sensor reschedule

Rescheduling mode. In case of unhandled exception occurred during the sensor's first try run the rescheduling attempt is not saved into DB because of the full transaction rollback. the ""first try"" here can be also the first one after clearing the task. In that case the start moment for calculating the task running duration should be taken as:
 - In case of first retry after exception: current system time
 - The first successfully saved to DB rescheduled tries reschedule date for the following  rescheduled runs

closes: #45050 


<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

---

",morooshka,2024-12-26 22:09:42+00:00,[],2024-12-27 18:38:42+00:00,2024-12-27 18:17:22+00:00,https://github.com/apache/airflow/pull/45224,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2563929611, 'issue_id': 2760180649, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12519300669\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>âŒ</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019""><img src=\'https://img.shields.io/badge/Commit-7f2b8ef-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 7f2b8ef v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 27, 18, 18, 12, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-27 18:18:12 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12519300669'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>âŒ</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/7f2b8ef5acf95b7fb8faa38a10caf94c043f5019""><img src='https://img.shields.io/badge/Commit-7f2b8ef-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 7f2b8ef v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2760092132,pull_request,closed,,Data Interval Date validation of trigger Dag form ,"Note:

Instead of overwriting the date to bring it in valid range, let's throw the error so that user know the value is not supported.

Incase of one is defined and another not
<img width=""884"" alt=""image"" src=""https://github.com/user-attachments/assets/937f4f69-96c3-44cb-8854-d723a3776b2c"" />

Incase start > end date
<img width=""884"" alt=""image"" src=""https://github.com/user-attachments/assets/987a944b-5bcf-4ecf-93be-0c59f96baca2"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-26 19:47:53+00:00,[],2024-12-26 22:18:04+00:00,2024-12-26 22:18:04+00:00,https://github.com/apache/airflow/pull/45223,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2760001911,pull_request,closed,,[main] Add BigQuery job link (#45020),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
ports: #45020

kudos for GIT for changing the path automatically without extra effort :D

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-26 17:48:09+00:00,[],2025-01-11 19:43:03+00:00,2024-12-26 18:45:52+00:00,https://github.com/apache/airflow/pull/45222,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2759945897,pull_request,closed,,Refactor the Dag trigger form ,"Note:

This PR refactors the TriggerDAGForm component for some bugs and code refactors.
1. Reset was not removing the error until the values are filled again. 
2. We have used field now instead of using the text.
3. Used the inbuilt field error.
4. Set the date validation check alert under ErrorAlert component.
5. Close the form on once the query has been invalidated.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-26 16:36:15+00:00,[],2024-12-26 18:02:22+00:00,2024-12-26 18:02:22+00:00,https://github.com/apache/airflow/pull/45220,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2759783452,pull_request,closed,,Prepare fab ad-hoc release December 2024,"Generated with :
`breeze release-management prepare-provider-documentation fab  --base-branch providers-fab/v1-5`",eladkal,2024-12-26 13:33:33+00:00,[],2024-12-29 18:14:47+00:00,2024-12-29 16:55:44+00:00,https://github.com/apache/airflow/pull/45218,"[('area:providers', ''), ('kind:documentation', ''), ('provider:fab', '')]","[{'comment_id': 2564783866, 'issue_id': 2759783452, 'author': 'potiuk', 'body': 'Do you want me to ""forward-port"" it to main - or will you do it @eladkal  ?', 'created_at': datetime.datetime(2024, 12, 29, 17, 6, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564796699, 'issue_id': 2759783452, 'author': 'eladkal', 'body': '> Do you want me to ""forward-port"" it to main - or will you do it @eladkal ?\r\n\r\nIt\'s just moving the log entry I can do it but there are troubles with doc build', 'created_at': datetime.datetime(2024, 12, 29, 17, 49, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564801773, 'issue_id': 2759783452, 'author': 'potiuk', 'body': ""> It's just moving the log entry I can do it but there are troubles with doc build\r\n\r\nThere should not be, I think - what troubles?"", 'created_at': datetime.datetime(2024, 12, 29, 18, 7, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564803368, 'issue_id': 2759783452, 'author': 'eladkal', 'body': ""> > It's just moving the log entry I can do it but there are troubles with doc build\r\n> \r\n> There should not be, I think - what troubles?\r\n\r\nPublished traceback on release manager channel."", 'created_at': datetime.datetime(2024, 12, 29, 18, 14, 46, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-29 17:06:07 UTC): Do you want me to ""forward-port"" it to main - or will you do it @eladkal  ?

eladkal (Issue Creator) on (2024-12-29 17:49:34 UTC): It's just moving the log entry I can do it but there are troubles with doc build

potiuk on (2024-12-29 18:07:21 UTC): There should not be, I think - what troubles?

eladkal (Issue Creator) on (2024-12-29 18:14:46 UTC): Published traceback on release manager channel.

"
2759543291,pull_request,closed,,Update providers metadata 2024-12-26,,eladkal,2024-12-26 09:40:28+00:00,[],2024-12-26 10:39:13+00:00,2024-12-26 10:39:10+00:00,https://github.com/apache/airflow/pull/45217,[],[],
2759441763,pull_request,closed,,Add task instance state and name filter to task instances tab in a dagrun,"A dagrun might have a lot of task instances that are paginated. This PR adds filters to filter by state e.g. failed task instances which is similar to the filter in dagrun page now. I have also added search by task_id or task_display_name so that users can quickly get to the required task instance in a paginated setting. Slightly related issues for grid view to search by name #32239 . This also updates the URLs so that it's shareable.

Notes for reviewer and self : 

* I reused the `searchBar` component but doesn't need advanced search as of now as it's not implemented and not useful here where search by task name is only needed. This can be added in future and the `hideAdvanced` part can be removed.

Screenshot : 

![image](https://github.com/user-attachments/assets/c35e0c24-3174-48cd-b26c-eed942b2d3e3)
",tirkarthi,2024-12-26 08:07:50+00:00,[],2025-01-20 10:20:08+00:00,2025-01-20 10:20:08+00:00,https://github.com/apache/airflow/pull/45215,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566760017, 'issue_id': 2759441763, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 2, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591241871, 'issue_id': 2759441763, 'author': 'bbovenzi', 'body': 'Lgmt looks like we need to rebase though', 'created_at': datetime.datetime(2025, 1, 14, 22, 31, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591677180, 'issue_id': 2759441763, 'author': 'tirkarthi', 'body': '@bbovenzi Thanks, rebased and fixed conflicts.', 'created_at': datetime.datetime(2025, 1, 15, 5, 22, 31, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-01 00:02:24 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

bbovenzi on (2025-01-14 22:31:13 UTC): Lgmt looks like we need to rebase though

tirkarthi (Issue Creator) on (2025-01-15 05:22:31 UTC): @bbovenzi Thanks, rebased and fixed conflicts.

"
2759398585,pull_request,closed,," feat(cli): add ""core.task_runner"" and ""core.enable_xcom_pickling"" to unsupported config check to command ""airflow config lint""","## Why
Config `core.task_runner` and `core.enable_xcom_pickling` are removed and will no longer exist in airflow 3.0

## What
Add lint rules to check these 2 configs

Closes: #45213

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-26 07:25:45+00:00,[],2024-12-31 12:28:46+00:00,2024-12-31 12:28:46+00:00,https://github.com/apache/airflow/pull/45214,"[('area:CLI', '')]",[],
2759330125,pull_request,closed,,Introducing get_run_data_interval on LazyDeserializedDAG,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

`get_run_data_interval` was not present on the `LazyDeserializedDAG` object leading to issues in Airflow scheduler while running dags with a schedule which looked like this:
```
AttributeError: 'LazyDeserializedDAG' object has no attribute 'get_run_data_interval'
```

This PR intends to fix that by porting over `get_run_data_interval`. 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-26 06:12:53+00:00,[],2024-12-27 14:10:12+00:00,2024-12-27 14:10:11+00:00,https://github.com/apache/airflow/pull/45211,"[('area:serialization', '')]","[{'comment_id': 2563064908, 'issue_id': 2759330125, 'author': 'ashb', 'body': '@amoghrajesh It probably needs some unit tests adding though :)', 'created_at': datetime.datetime(2024, 12, 26, 20, 0, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563386468, 'issue_id': 2759330125, 'author': 'amoghrajesh', 'body': '@ashb I have added UT coverage for this, the UT added makes sure that we hit the get_run_data_interval flow and we validate if certain fields have been set or not.', 'created_at': datetime.datetime(2024, 12, 27, 6, 52, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563712720, 'issue_id': 2759330125, 'author': 'ashb', 'body': ""@amoghrajesh Lets merge this as it is, but let's ping TP and we can revisit the timetable bit if we have to."", 'created_at': datetime.datetime(2024, 12, 27, 13, 40, 26, tzinfo=datetime.timezone.utc)}]","ashb on (2024-12-26 20:00:29 UTC): @amoghrajesh It probably needs some unit tests adding though :)

amoghrajesh (Issue Creator) on (2024-12-27 06:52:37 UTC): @ashb I have added UT coverage for this, the UT added makes sure that we hit the get_run_data_interval flow and we validate if certain fields have been set or not.

ashb on (2024-12-27 13:40:26 UTC): @amoghrajesh Lets merge this as it is, but let's ping TP and we can revisit the timetable bit if we have to.

"
2759075027,pull_request,closed,,Include driver classpath in --jars cmd docstring in spark-submit hook and operator,"Like it can be read in the [official Spark docs](https://spark.apache.org/docs/3.5.3/submitting-applications.html#advanced-dependency-management), when using the `--jars` option, the jars provided will be included in both the driver and the executor classpaths.

The driver classpath is excluded in the `docstring`. This PR changes that.",IlaiGigi,2024-12-25 19:56:33+00:00,[],2024-12-25 20:42:55+00:00,2024-12-25 20:42:55+00:00,https://github.com/apache/airflow/pull/45210,"[('area:providers', ''), ('provider:apache-spark', '')]","[{'comment_id': 2561988988, 'issue_id': 2759075027, 'author': 'IlaiGigi', 'body': ""I seem unable to request a review through the UI like described [here](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/requesting-a-pull-request-review#requesting-reviews-from-collaborators-and-organization-members),  perhaps it is locked behind a certain amount of contributions or I'm just doing something wrong.\r\n\r\n@romsharon98, may I get a review?"", 'created_at': datetime.datetime(2024, 12, 25, 20, 3, 3, tzinfo=datetime.timezone.utc)}]","IlaiGigi (Issue Creator) on (2024-12-25 20:03:03 UTC): I seem unable to request a review through the UI like described [here](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/requesting-a-pull-request-review#requesting-reviews-from-collaborators-and-organization-members),  perhaps it is locked behind a certain amount of contributions or I'm just doing something wrong.

@romsharon98, may I get a review?

"
2759071024,pull_request,closed,,Add encryption column for variables,"<img width=""1647"" alt=""image"" src=""https://github.com/user-attachments/assets/81ca3806-ece8-422b-84a5-9356a840526e"" />

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-25 19:41:18+00:00,[],2024-12-25 21:21:04+00:00,2024-12-25 21:21:04+00:00,https://github.com/apache/airflow/pull/45209,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2758900654,pull_request,closed,,Bump keyring from 25.5.0 to 25.6.0,"Bumps [keyring](https://github.com/jaraco/keyring) from 25.5.0 to 25.6.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/jaraco/keyring/blob/main/NEWS.rst"">keyring's changelog</a>.</em></p>
<blockquote>
<h1>v25.6.0</h1>
<h2>Features</h2>
<ul>
<li>Avoid logging a warning when config does not specify a backend. (<a href=""https://redirect.github.com/jaraco/keyring/issues/682"">#682</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/jaraco/keyring/commit/a9a7624b5d7eda87257d2da082abc5f195eae50f""><code>a9a7624</code></a> Finalize</li>
<li><a href=""https://github.com/jaraco/keyring/commit/21680c682c35032a0131104f00d2f9e2d13a301f""><code>21680c6</code></a> Merge pull request <a href=""https://redirect.github.com/jaraco/keyring/issues/702"">#702</a> from jfly/issue-682</li>
<li><a href=""https://github.com/jaraco/keyring/commit/bf80b69eeefdd41c8ccfc545a61d48f8e18aea20""><code>bf80b69</code></a> Add news fragment.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/1526c17f38538491d6ceee3b03015047ae49a92f""><code>1526c17</code></a> Don't log a warning when the <code>backend</code> config section is missing</li>
<li><a href=""https://github.com/jaraco/keyring/commit/edaa964d4b1a90ba564ddafd2471523f12cd8e8c""><code>edaa964</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>
<li><a href=""https://github.com/jaraco/keyring/commit/5c34e69568f23a524af4fa9dad3f5e80f22ec3e6""><code>5c34e69</code></a> Use extend for proper workaround.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/1119d7b6c7cc69ef42101f26f9d7a3a62a2e0373""><code>1119d7b</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>
<li><a href=""https://github.com/jaraco/keyring/commit/750a1891ec4a1c0602050e3463e9593a8c13aa14""><code>750a189</code></a> Require Python 3.9 or later now that Python 3.8 is EOL.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/e61a9df7cdc9c8d1b56c30b7b3f94a7cdac14414""><code>e61a9df</code></a> Include pyproject.toml in ruff.toml.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/db4dfc495552aca8d6f05ed58441fa65fdc2ed9c""><code>db4dfc4</code></a><code>jaraco/skeleton#151</code></li>
<li>See full diff in <a href=""https://github.com/jaraco/keyring/compare/v25.5.0...v25.6.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyring&package-manager=pip&previous-version=25.5.0&new-version=25.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-12-25 17:08:20+00:00,[],2024-12-26 08:55:04+00:00,2024-12-26 08:54:56+00:00,https://github.com/apache/airflow/pull/45208,"[('area:dev-tools', ''), ('area:dependencies', 'Issues related to dependencies problems')]",[],
2758858570,pull_request,closed,,Fix tries disappearing when first try is selected out of multiple tries.,"Check for taskInstance.try_number to show tries instead of current selected tryNumber that makes other tries to disappear on selection of first try.

To reproduce : 

1. Go to a task instance with multiple tries.
2. Select the first try and the tries component disappears.",tirkarthi,2024-12-25 15:16:45+00:00,[],2024-12-25 21:32:52+00:00,2024-12-25 21:32:51+00:00,https://github.com/apache/airflow/pull/45206,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2758836569,pull_request,closed,,Action button setup for variables list,"<img width=""1647"" alt=""image"" src=""https://github.com/user-attachments/assets/23d0a4b4-95bc-4e51-8f2d-8aedbee1df6a"" />

Note:

This PR is raised to give the base support to all actions, to avoid dependency, having this will allow to track upcoming PRs for add and delete separately.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-25 14:26:48+00:00,[],2024-12-26 12:55:54+00:00,2024-12-26 12:55:53+00:00,https://github.com/apache/airflow/pull/45205,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2561953457, 'issue_id': 2758836569, 'author': 'shubhamraj-git', 'body': '@pierrejeambrun Also regarding the placement of this button? do we need to follow the leagcy? It was in starting of the row, Should i add there?\r\nBut if we want consistency throughout all pages, it should be at end.', 'created_at': datetime.datetime(2024, 12, 25, 17, 4, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562006464, 'issue_id': 2758836569, 'author': 'pierrejeambrun', 'body': '> @pierrejeambrun Also regarding the placement of this button? do we need to follow the leagcy? It was in starting of the row, Should i add there?\r\nBut if we want consistency throughout all pages, it should be at end.\r\n\r\nActions at the end of the row seems fine by me.', 'created_at': datetime.datetime(2024, 12, 25, 21, 47, 29, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2024-12-25 17:04:42 UTC): @pierrejeambrun Also regarding the placement of this button? do we need to follow the leagcy? It was in starting of the row, Should i add there?
But if we want consistency throughout all pages, it should be at end.

pierrejeambrun on (2024-12-25 21:47:29 UTC): But if we want consistency throughout all pages, it should be at end.

Actions at the end of the row seems fine by me.

"
2758813697,pull_request,closed,,feat: ansible operator,"related: #45203

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",liuzheng,2024-12-25 13:37:43+00:00,[],2024-12-30 01:36:10+00:00,2024-12-30 01:36:10+00:00,https://github.com/apache/airflow/pull/45204,"[('area:providers', '')]","[{'comment_id': 2561895170, 'issue_id': 2758813697, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 25, 13, 37, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562522356, 'issue_id': 2758813697, 'author': 'potiuk', 'body': 'Before any more progress on that - please read and follow https://github.com/apache/airflow/blob/main/PROVIDERS.rst#accepting-new-community-providers on discussing, proposing and accepting new providers . PR is not enough to propose new provider. You will find some example past discussions there as well and that should guide you on how you should approach proposing a new provider', 'created_at': datetime.datetime(2024, 12, 26, 11, 36, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564939253, 'issue_id': 2758813697, 'author': 'liuzheng', 'body': 'I will try the third-party-airflow-plugins-and-providers.\r\nCLOSE now', 'created_at': datetime.datetime(2024, 12, 30, 1, 36, 10, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-25 13:37:47 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-26 11:36:11 UTC): Before any more progress on that - please read and follow https://github.com/apache/airflow/blob/main/PROVIDERS.rst#accepting-new-community-providers on discussing, proposing and accepting new providers . PR is not enough to propose new provider. You will find some example past discussions there as well and that should guide you on how you should approach proposing a new provider

liuzheng (Issue Creator) on (2024-12-30 01:36:10 UTC): I will try the third-party-airflow-plugins-and-providers.
CLOSE now

"
2758554406,pull_request,closed,,Update serializers.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Bluefox9x5,2024-12-25 06:49:22+00:00,[],2024-12-26 18:00:12+00:00,2024-12-26 18:00:09+00:00,https://github.com/apache/airflow/pull/45202,"[('kind:documentation', '')]","[{'comment_id': 2561661262, 'issue_id': 2758554406, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 25, 6, 49, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562992866, 'issue_id': 2758554406, 'author': 'shahar1', 'body': '> **^ Add meaningful description above** Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information. In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed. In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x). In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).\r\n\r\nWelcome to Apache Airflow and thanks for your contribution! \r\nEvery good journey starts with removing a letter (my first PR was like that as well :D ) - feel free to challenge yourself a bit more with any of the [good first issues](https://github.com/apache/airflow/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22).', 'created_at': datetime.datetime(2024, 12, 26, 17, 59, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562993071, 'issue_id': 2758554406, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 26, 18, 0, 11, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-25 06:49:26 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

shahar1 on (2024-12-26 17:59:51 UTC): Welcome to Apache Airflow and thanks for your contribution! 
Every good journey starts with removing a letter (my first PR was like that as well :D ) - feel free to challenge yourself a bit more with any of the [good first issues](https://github.com/apache/airflow/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22).

boring-cyborg[bot] on (2024-12-26 18:00:11 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2758510652,pull_request,closed,,Remove tuple_in_condition helpers,"These were introduced when not all databases support the tuple expression. Now that sqlalchemy.tuple_ is supported in all database backends Airflow officially support, they are not needed anymore.

We actually already use the tuple_ expression directly in a lot of code right now.

The not_in variant is removed outright. The in_ variant is kept for now since it was used in the standard provider. It is therefore kept for now (but not used anywhere), and will be removed in a future release.",uranusjr,2024-12-25 05:32:23+00:00,[],2024-12-26 03:04:02+00:00,2024-12-26 03:04:00+00:00,https://github.com/apache/airflow/pull/45201,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('provider:standard', '')]",[],
2758159650,pull_request,closed,,Add dags search widget to navbar for quick search,"Closes #33210 

There are workflows where users need to quickly switch between dags. Returning to home page to search takes time and also loads dags list data and makes other queries which are not needed. Add a search widget in the top navbar so that users can search and results are returned like legacy home page search. Then users can click on the result to switch to the relevant dag page. The component uses `AsyncSelect` to fetch options on type and uses debounce to limit queries. The results are limited to 10 so that the queries are faster and uses existing dags endpoint used by home page search without recent runs data. 

Notes to reviewer and self

* debounce-promise is needed since use-debounce doesn't work with promises . Ref : https://github.com/JedWatson/react-select/issues/3075#issuecomment-450194917
* `staleTime` is set as zero so that queries are not cached and results are live to search for dags added recently after a search for the term.
* There are autocomplete components for Chakra but they are not compatible with Chakra 3 . Ref : https://github.com/anubra266/choc-autocomplete/issues/272 
* There could be a custom endpoint with just `dag_id` and `dag_display_name` but with 10 entries the size is low at 2kB compressed and 8-9kB uncompressed and doesn't seem to be worth it to have a separate endpoint. Probably if needed can be taken as an enhancement in another PR.

![dags_search_modal](https://github.com/user-attachments/assets/7eba4960-7322-4975-8990-86d6601033e3)

",tirkarthi,2024-12-24 17:38:13+00:00,[],2025-01-08 18:47:04+00:00,2025-01-08 18:47:04+00:00,https://github.com/apache/airflow/pull/45198,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2561928807, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': '@shubhamraj-git  The search is substring search like the legacy view. Legacy view has limit of 10 entries and I am fine with increasing the limit here. Thanks.\r\n\r\nhttps://github.com/apache/airflow/blob/b13ed892b1fcc98b1bc9896dd4b2273a21121705/airflow/www/views.py#L5522', 'created_at': datetime.datetime(2024, 12, 25, 15, 27, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561929641, 'issue_id': 2758159650, 'author': 'shubhamraj-git', 'body': '> @shubhamraj-git The search is substring search like the legacy view. Legacy view has limit of 10 entries and I am fine with increasing the limit here. Thanks.\r\n> \r\n> https://github.com/apache/airflow/blob/b13ed892b1fcc98b1bc9896dd4b2273a21121705/airflow/www/views.py#L5522\r\n\r\nActually yes, I saw in the legacy. Hence removed the comment, since i got my answer. Yes, maybe increasing to 10 will be good.', 'created_at': datetime.datetime(2024, 12, 25, 15, 30, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562301134, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': 'Thanks, increased it to 10 and also increased width to view longer names.', 'created_at': datetime.datetime(2024, 12, 26, 8, 20, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566760100, 'issue_id': 2758159650, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 2, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569373766, 'issue_id': 2758159650, 'author': 'bbovenzi', 'body': 'I think we should style this as a universal search like how the Chakra 3 docs work:\r\n\r\n<img width=""1412"" alt=""Screenshot 2025-01-03 at 10 04 54\u202fAM"" src=""https://github.com/user-attachments/assets/14ee9d8e-4e4c-4409-b5a3-b7750b300e97"" />', 'created_at': datetime.datetime(2025, 1, 3, 15, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571626089, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': ""@bbovenzi I don't find any docs in Chakra for search. Is it just making the dropdown component display in modal and make the modal open on clicking on search?"", 'created_at': datetime.datetime(2025, 1, 5, 13, 24, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571675678, 'issue_id': 2758159650, 'author': 'Kysluss', 'body': ""Hello,\r\n\r\n[choc-autocomplete](https://github.com/anubra266/choc-autocomplete) just put out an alpha release that adds v3 support.  Feel free to use it and submit any feedback, issues, and PRs.  I'm one of the maintainers of the project and we're trying to get it stable as quick as possible.\r\n\r\n**Edit** Official v6 is out and stable that adds support for Chakra v3"", 'created_at': datetime.datetime(2025, 1, 5, 16, 11, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576007948, 'issue_id': 2758159650, 'author': 'bbovenzi', 'body': ""> @bbovenzi I don't find any docs in Chakra for search. Is it just making the dropdown component display in modal and make the modal open on clicking on search?\r\n\r\nYeah, its not a specific component. but built using the first Searchbar as a button and then opening a dropdown in a modal. Although we'll need it to be a typeahead search and not a set dropdown."", 'created_at': datetime.datetime(2025, 1, 7, 18, 53, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576894899, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': 'Thanks @bbovenzi , updated the PR so that ""search dags"" at top right of the header is a button and it opens the modal with the search implementation. Updated screenshot in the PR description.', 'created_at': datetime.datetime(2025, 1, 8, 7, 6, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576896908, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': 'Chakra search is also triggered by ""ctrl+k"" . I guess there needs to be a tracking ticket to track porting keyboard shortcuts in legacy UI to new UI too.', 'created_at': datetime.datetime(2025, 1, 8, 7, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576934088, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': ""> Hello,\r\n> \r\n> [choc-autocomplete](https://github.com/anubra266/choc-autocomplete) just put out an alpha release that adds v3 support. Feel free to use it and submit any feedback, issues, and PRs. I'm one of the maintainers of the project and we're trying to get it stable as quick as possible.\r\n> \r\n> **Edit** Official v6 is out and stable that adds support for Chakra v3\r\n\r\nThanks @Kysluss , will check it out."", 'created_at': datetime.datetime(2025, 1, 8, 7, 33, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578251429, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': ""> 1. Let's add a similar keyboard command. Maybe we maintain a single json file of keyboard commands that components need to import so we can maintain a single source of truth.\r\n\r\nI have not worked on keyboard shortcuts in the legacy UI and need to understand this. From the initial understanding it seems the keypress is captured and an event is dispatched which gets handled by a reducer. I would like to have it as a separate issue since it looks like lot of work that would need it's own ticket.\r\n\r\n>     2. We should have a default list of dags ready with the dropdown already open when the user opens the dialog. That can either be just whatever 10 dags the API returns or later we can have it be the recently viewed dags.\r\n\r\nThanks @bbovenzi for the suggestion. react-select library provides an option to just set defaulOptions with list of options or to pass defaultOptions that calls the API. In this case I took the later approach where dag_display_pattern will be empty and the first 10 dags are returned.\r\n\r\nhttps://react-select.com/async#defaultoptions"", 'created_at': datetime.datetime(2025, 1, 8, 17, 39, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578310955, 'issue_id': 2758159650, 'author': 'tirkarthi', 'body': 'Thanks, refactored to `SearchDags` folder exporting only `SearchDagsButton` in index.ts . I have also set `menuIsOpen` so that default dags are always shown on modal open and not just on clicking the select input.', 'created_at': datetime.datetime(2025, 1, 8, 18, 7, 43, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-12-25 15:27:02 UTC): @shubhamraj-git  The search is substring search like the legacy view. Legacy view has limit of 10 entries and I am fine with increasing the limit here. Thanks.

https://github.com/apache/airflow/blob/b13ed892b1fcc98b1bc9896dd4b2273a21121705/airflow/www/views.py#L5522

shubhamraj-git on (2024-12-25 15:30:08 UTC): Actually yes, I saw in the legacy. Hence removed the comment, since i got my answer. Yes, maybe increasing to 10 will be good.

tirkarthi (Issue Creator) on (2024-12-26 08:20:04 UTC): Thanks, increased it to 10 and also increased width to view longer names.

jscheffl on (2025-01-01 00:02:38 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

bbovenzi on (2025-01-03 15:09:38 UTC): I think we should style this as a universal search like how the Chakra 3 docs work:

<img width=""1412"" alt=""Screenshot 2025-01-03 at 10 04 54â€¯AM"" src=""https://github.com/user-attachments/assets/14ee9d8e-4e4c-4409-b5a3-b7750b300e97"" />

tirkarthi (Issue Creator) on (2025-01-05 13:24:43 UTC): @bbovenzi I don't find any docs in Chakra for search. Is it just making the dropdown component display in modal and make the modal open on clicking on search?

Kysluss on (2025-01-05 16:11:32 UTC): Hello,

[choc-autocomplete](https://github.com/anubra266/choc-autocomplete) just put out an alpha release that adds v3 support.  Feel free to use it and submit any feedback, issues, and PRs.  I'm one of the maintainers of the project and we're trying to get it stable as quick as possible.

**Edit** Official v6 is out and stable that adds support for Chakra v3

bbovenzi on (2025-01-07 18:53:36 UTC): Yeah, its not a specific component. but built using the first Searchbar as a button and then opening a dropdown in a modal. Although we'll need it to be a typeahead search and not a set dropdown.

tirkarthi (Issue Creator) on (2025-01-08 07:06:35 UTC): Thanks @bbovenzi , updated the PR so that ""search dags"" at top right of the header is a button and it opens the modal with the search implementation. Updated screenshot in the PR description.

tirkarthi (Issue Creator) on (2025-01-08 07:08:00 UTC): Chakra search is also triggered by ""ctrl+k"" . I guess there needs to be a tracking ticket to track porting keyboard shortcuts in legacy UI to new UI too.

tirkarthi (Issue Creator) on (2025-01-08 07:33:08 UTC): Thanks @Kysluss , will check it out.

tirkarthi (Issue Creator) on (2025-01-08 17:39:50 UTC): I have not worked on keyboard shortcuts in the legacy UI and need to understand this. From the initial understanding it seems the keypress is captured and an event is dispatched which gets handled by a reducer. I would like to have it as a separate issue since it looks like lot of work that would need it's own ticket.


Thanks @bbovenzi for the suggestion. react-select library provides an option to just set defaulOptions with list of options or to pass defaultOptions that calls the API. In this case I took the later approach where dag_display_pattern will be empty and the first 10 dags are returned.

https://react-select.com/async#defaultoptions

tirkarthi (Issue Creator) on (2025-01-08 18:07:43 UTC): Thanks, refactored to `SearchDags` folder exporting only `SearchDagsButton` in index.ts . I have also set `menuIsOpen` so that default dags are always shown on modal open and not just on clicking the select input.

"
2758096439,pull_request,closed,,Implement AlloyDB create/update/delete instance operators,"- Implemented new AlloyDB operators: create/update/delete instance
- Slightly refactored  cluster operators",moiseenkov,2024-12-24 16:12:34+00:00,[],2024-12-24 16:12:41+00:00,2024-12-24 16:12:41+00:00,https://github.com/apache/airflow/pull/45197,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2758094621,pull_request,closed,,Fix potential race on modifying __init__.py for providers,"Two things:

* limit number of __init__.py files that might trigger the update
* make the updates serial

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-24 16:10:31+00:00,[],2024-12-24 16:41:19+00:00,2024-12-24 16:41:18+00:00,https://github.com/apache/airflow/pull/45196,"[('area:dev-tools', '')]",[],
2757891788,pull_request,closed,,Support AES256 encryption of sensitive params,"Implements support for `_ENCRYPTED` versions of env variables and `_encrypted` versions of config params. Those would be encrypted using a parameter `params_encryption_aes256_key` (which can be retrieved from a secret for example). The params encryption key itself doesn't support encrypted suffix, or it'd create an infinite recursion.

closes: #45194

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",andrii-korotkov-verkada,2024-12-24 14:47:55+00:00,[],2024-12-26 18:53:11+00:00,2024-12-26 18:53:11+00:00,https://github.com/apache/airflow/pull/45195,[],"[{'comment_id': 2561201300, 'issue_id': 2757891788, 'author': 'andrii-korotkov-verkada', 'body': 'Starting with a draft with a POC. Please, let me know if this is a good direction.', 'created_at': datetime.datetime(2024, 12, 24, 14, 48, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561230348, 'issue_id': 2757891788, 'author': 'potiuk', 'body': 'Before we go any deeper. I would like to dicuss the reasoning of doing it\r\n\r\nI simply think it does not achieve any ""more"" security than we currently have. Both parameters and decryption key are necesarlly in the same environment and you neeed to have access to both - if you don\'t, then you cannot decrypt them.\r\n\r\nWe already have encryption using fernet key (symmetric) but there we use it to encrypt the database values, becuase then for example if you have only access to database backups/dumps or database itself, you are not able to decrypt it without access to the configuraiton of Airlfow - where the fernet key is stored. So here values and keys are kept in two separate ""spaces"" / ""security scopes/perimeters"".\r\n\r\nWe also already support `_CMD` pattern - where the actual sensitive values are retrieved by running a script that can (for example) use workload identity to retrieve sensitive values from somewhere else (say secrets manager) - so that it is not stored in the configuration at all.\r\n\r\nIn this case and your proposal, seemlngly both encrypted values and the key are supposed to be stored in the same ""space"" - so if you have access to one, you have access to other, and you can use the key to decrypt the values, so at best it\'s security-by-obscurity.\r\n\r\nDo you see any scenario where someone could get hold of the values but not the key  - where it could be helpful? What kind of attacks and which actor behaviours it would prevent ?\r\n\r\nIt might be you have some concrete use cases in mind that I don\'t know.', 'created_at': datetime.datetime(2024, 12, 24, 15, 24, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561251188, 'issue_id': 2757891788, 'author': 'andrii-korotkov-verkada', 'body': ""Sure. I think of this as more of a convenience feature rather than a feature that heightens a security.\r\nArgoCD is used to manage manifests, as well as there are multiple shards (i.e. AWS accounts and clusters), where each needs to have some configuration, ideally with as little overhead as possible. Some secret values can be based on large things, e.g. pgbouncer.ini config, so automated way for managing them would be very helpful.\r\nHere are several options I've considered:\r\n* Storing generated manifests in the repo, even for secrets. That's a hard no from a security perspective.\r\n* Generate and apply secrets to the cluster directly without committing them to the repo. This makes secrets not very durable, e.g. if fernet key is removed for some reason, the encrypted data is effectively lost. This would require duplicating the key in some password manager, which would make management a bit clunkier.\r\n* Use secrets manager backend to store secrets. This helps with durability and overall seems like a good option, however adding secrets to the manager and rotating them would be clunky, since it's not integrated with helm templating.\r\n* Using _CMD env variables. This can work, but has a few downsides in my case, like aws cli not being pre-installed in the default image (at least I didn't see it in constraints) and cmd code needs to be repeated for each parameter.\r\n* Use AES256 encryption to store encrypted versions of secrets. This solves durability, auditing, security and convenience. Since helm templating supports aes256 encryption natively, I can just generate all manifests with it with all secrets needed for all shards, which is especially convenient given some secrets like `connection` are based on multiple helm inputs (e.g. host, username, password). This way, I reduce the number of secrets to manage with external means (like cluster secret or secrets manager) to just one.\r\n\r\nI'd have to think separately on how to work with secret things mounted as files, e.g. `pgbouncer.ini`. Though probably a similar approach with having a key like `pgbouncer.ini.encrypted` and using the same key to decrypt would work.\r\n\r\nPlease, let me know if these arguments make sense. Happy to discuss further."", 'created_at': datetime.datetime(2024, 12, 24, 15, 54, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562897575, 'issue_id': 2757891788, 'author': 'andrii-korotkov-verkada', 'body': ""Here's an example when there's a secret value in a config where it doesn't seem to be possible to hide it https://airflow.apache.org/docs/apache-airflow/1.10.8/security.html#github-enterprise-ghe-authentication."", 'created_at': datetime.datetime(2024, 12, 26, 15, 42, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562963602, 'issue_id': 2757891788, 'author': 'potiuk', 'body': 'Just to note - not that I am against it totally, but I want you to think and come up with proposal how to tell the user to maintain ""secret"" status of such values?\r\n\r\nIf you are keeping both - secret values and private key in the same configuration place (secure perimeter), then you can use the key to decrypt the values. What your advise should be for the users who are going to use that feature, how they should keep the key and what exactly will the encryption will be protecting against?\r\n\r\nIf we are going to accept some form of it, we need have detailed documentation describing the users what kind of security they can expect and how they should protect (and against what) - the thing is that often when people see some ""Encrypted"" values, they **think** they are generally protected against the values leaking (but they don\'t realise for example that storing the key to decrypt the values in the same security perimeter/storage gives them false sense of security).\r\n\r\nWhat your ""user documentation"" for that feature and user recommendation would look ilike for it?\r\n\r\nBTW:\r\n\r\n> Using _CMD env variables. This can work, but has a few downsides in my case, like aws cli not being pre-installed in the default image (at least I didn\'t see it in constraints) and cmd code needs to be repeated for each parameter.\r\n\r\nNot really. You can have a single command that is used there and pass the parameter to that command indicating which secret you want to retrieve - `...SQL_CON_CMD=/opt/airflow/bin/get_secret_value.sh SQL_CONN` etc. That\'s what it was designed for.', 'created_at': datetime.datetime(2024, 12, 26, 17, 14, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562968855, 'issue_id': 2757891788, 'author': 'potiuk', 'body': 'Also. I think it needs an explanation on why you cannot use ""k8s secrets"" (if you are talking about k8s) - and why is it problematic to deploy them separately and mount as config files.', 'created_at': datetime.datetime(2024, 12, 26, 17, 22, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562987050, 'issue_id': 2757891788, 'author': 'andrii-korotkov-verkada', 'body': ""I think the problem I'm trying to solve is that the secrets are in different places in different formats. While some of them can be handled with _CMD params (thanks for pointing that a single script can be used!), in some cases this option is not offered, for example:\r\n* Pgbouncer configs such as `pgbouncer.ini` (not sure why this one is secret) and `users.txt` (contains some username and passwords). Those are read from a secret and mounted as files.\r\n* Auth-related secrets (e.g. for GHE) which seem to be just put in the `airflow.cfg` which is mounted as a config map, not a secret.\r\n* Secrets that might need to be specified as a part of server init Python file (e.g. Okta client secret), though these probably can be passed as env variables reading values from k8s secrets.\r\n\r\nMy proposal offers an option to replace these secrets with one, still probably a k8s secret, to simplify management while offering the same amount of security (e.g. reading one k8s secret in a namespace requires pretty much the same amount of permissions and effort as reading multiple). I'll set users' expectations that they are getting the same amount of security and still need to keep their k8s secret with encrypted key safe, but that this way would simplify managing a configuration."", 'created_at': datetime.datetime(2024, 12, 26, 17, 51, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563000726, 'issue_id': 2757891788, 'author': 'andrii-korotkov-verkada', 'body': 'One alternative to the `_encrypted` suffix is to have encrypted values start with some prefix, e.g.\r\n```\r\nclient_secret: aes256encrypted:<base64-encoded-ciphertext>\r\n```', 'created_at': datetime.datetime(2024, 12, 26, 18, 11, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563014480, 'issue_id': 2757891788, 'author': 'potiuk', 'body': 'Why not having it all configured through env variables? All airflow configurations can be configured via ENV variables  in one place - same source for every secret value https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables \r\n\r\nThe thing is that we tend to avoid having to add ""features"" to Airflow where they can be provided via ""external"" means in this case deployment that might be responsible to keep all secrets (i.e. env variables) that are providing all secret values from a single ""secret"" that can even be backed by a secret manager. \r\n\r\nGenerally we are now more in the mode (for Airlfow 3) to search what  non core issues we can remove from Airflow rather than what we can add to it. Similalry as your other issue  (now discussion) https://github.com/apache/airflow/discussions/45221 - we are very, very, very cautious about adding things to Airflow that  could be done ""externally"" - we are good at scheduling workfloads, we are not good in keeping secret configurations (K8S is way better for that) and authentication (KeyCloak is way better in this). You have to remember, that whatever we approve as contributions to Airlfow, we also have to maintain it - and if there are other ways to achieve it - for example via deployment features - we tend to be very hesitant about accepting those.\r\n\r\nYou seem to be very focused on K8S / ArgoCD environment, so my question is - why ""standard"" feature where all the configurationsecrets can be configured in one place and exposed as env variables are not ""good"" for you ?', 'created_at': datetime.datetime(2024, 12, 26, 18, 35, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563025248, 'issue_id': 2757891788, 'author': 'andrii-korotkov-verkada', 'body': ""Thanks for detailed replies. After more thinking I concede - marginal wins in maintenance of configs across shards are not worth the complexity of adding a new feature. I understand the complexity of maintaining open source. I can probably achieve my goals with some customized manifests overlays + a custom script to render the helm templates (which we have anyways). That said, I'm still looking to contribute something, maybe that KeyCloak auth manager."", 'created_at': datetime.datetime(2024, 12, 26, 18, 53, 6, tzinfo=datetime.timezone.utc)}]","andrii-korotkov-verkada (Issue Creator) on (2024-12-24 14:48:23 UTC): Starting with a draft with a POC. Please, let me know if this is a good direction.

potiuk on (2024-12-24 15:24:51 UTC): Before we go any deeper. I would like to dicuss the reasoning of doing it

I simply think it does not achieve any ""more"" security than we currently have. Both parameters and decryption key are necesarlly in the same environment and you neeed to have access to both - if you don't, then you cannot decrypt them.

We already have encryption using fernet key (symmetric) but there we use it to encrypt the database values, becuase then for example if you have only access to database backups/dumps or database itself, you are not able to decrypt it without access to the configuraiton of Airlfow - where the fernet key is stored. So here values and keys are kept in two separate ""spaces"" / ""security scopes/perimeters"".

We also already support `_CMD` pattern - where the actual sensitive values are retrieved by running a script that can (for example) use workload identity to retrieve sensitive values from somewhere else (say secrets manager) - so that it is not stored in the configuration at all.

In this case and your proposal, seemlngly both encrypted values and the key are supposed to be stored in the same ""space"" - so if you have access to one, you have access to other, and you can use the key to decrypt the values, so at best it's security-by-obscurity.

Do you see any scenario where someone could get hold of the values but not the key  - where it could be helpful? What kind of attacks and which actor behaviours it would prevent ?

It might be you have some concrete use cases in mind that I don't know.

andrii-korotkov-verkada (Issue Creator) on (2024-12-24 15:54:12 UTC): Sure. I think of this as more of a convenience feature rather than a feature that heightens a security.
ArgoCD is used to manage manifests, as well as there are multiple shards (i.e. AWS accounts and clusters), where each needs to have some configuration, ideally with as little overhead as possible. Some secret values can be based on large things, e.g. pgbouncer.ini config, so automated way for managing them would be very helpful.
Here are several options I've considered:
* Storing generated manifests in the repo, even for secrets. That's a hard no from a security perspective.
* Generate and apply secrets to the cluster directly without committing them to the repo. This makes secrets not very durable, e.g. if fernet key is removed for some reason, the encrypted data is effectively lost. This would require duplicating the key in some password manager, which would make management a bit clunkier.
* Use secrets manager backend to store secrets. This helps with durability and overall seems like a good option, however adding secrets to the manager and rotating them would be clunky, since it's not integrated with helm templating.
* Using _CMD env variables. This can work, but has a few downsides in my case, like aws cli not being pre-installed in the default image (at least I didn't see it in constraints) and cmd code needs to be repeated for each parameter.
* Use AES256 encryption to store encrypted versions of secrets. This solves durability, auditing, security and convenience. Since helm templating supports aes256 encryption natively, I can just generate all manifests with it with all secrets needed for all shards, which is especially convenient given some secrets like `connection` are based on multiple helm inputs (e.g. host, username, password). This way, I reduce the number of secrets to manage with external means (like cluster secret or secrets manager) to just one.

I'd have to think separately on how to work with secret things mounted as files, e.g. `pgbouncer.ini`. Though probably a similar approach with having a key like `pgbouncer.ini.encrypted` and using the same key to decrypt would work.

Please, let me know if these arguments make sense. Happy to discuss further.

andrii-korotkov-verkada (Issue Creator) on (2024-12-26 15:42:30 UTC): Here's an example when there's a secret value in a config where it doesn't seem to be possible to hide it https://airflow.apache.org/docs/apache-airflow/1.10.8/security.html#github-enterprise-ghe-authentication.

potiuk on (2024-12-26 17:14:30 UTC): Just to note - not that I am against it totally, but I want you to think and come up with proposal how to tell the user to maintain ""secret"" status of such values?

If you are keeping both - secret values and private key in the same configuration place (secure perimeter), then you can use the key to decrypt the values. What your advise should be for the users who are going to use that feature, how they should keep the key and what exactly will the encryption will be protecting against?

If we are going to accept some form of it, we need have detailed documentation describing the users what kind of security they can expect and how they should protect (and against what) - the thing is that often when people see some ""Encrypted"" values, they **think** they are generally protected against the values leaking (but they don't realise for example that storing the key to decrypt the values in the same security perimeter/storage gives them false sense of security).

What your ""user documentation"" for that feature and user recommendation would look ilike for it?

BTW:


Not really. You can have a single command that is used there and pass the parameter to that command indicating which secret you want to retrieve - `...SQL_CON_CMD=/opt/airflow/bin/get_secret_value.sh SQL_CONN` etc. That's what it was designed for.

potiuk on (2024-12-26 17:22:52 UTC): Also. I think it needs an explanation on why you cannot use ""k8s secrets"" (if you are talking about k8s) - and why is it problematic to deploy them separately and mount as config files.

andrii-korotkov-verkada (Issue Creator) on (2024-12-26 17:51:19 UTC): I think the problem I'm trying to solve is that the secrets are in different places in different formats. While some of them can be handled with _CMD params (thanks for pointing that a single script can be used!), in some cases this option is not offered, for example:
* Pgbouncer configs such as `pgbouncer.ini` (not sure why this one is secret) and `users.txt` (contains some username and passwords). Those are read from a secret and mounted as files.
* Auth-related secrets (e.g. for GHE) which seem to be just put in the `airflow.cfg` which is mounted as a config map, not a secret.
* Secrets that might need to be specified as a part of server init Python file (e.g. Okta client secret), though these probably can be passed as env variables reading values from k8s secrets.

My proposal offers an option to replace these secrets with one, still probably a k8s secret, to simplify management while offering the same amount of security (e.g. reading one k8s secret in a namespace requires pretty much the same amount of permissions and effort as reading multiple). I'll set users' expectations that they are getting the same amount of security and still need to keep their k8s secret with encrypted key safe, but that this way would simplify managing a configuration.

andrii-korotkov-verkada (Issue Creator) on (2024-12-26 18:11:55 UTC): One alternative to the `_encrypted` suffix is to have encrypted values start with some prefix, e.g.
```
client_secret: aes256encrypted:<base64-encoded-ciphertext>
```

potiuk on (2024-12-26 18:35:13 UTC): Why not having it all configured through env variables? All airflow configurations can be configured via ENV variables  in one place - same source for every secret value https://kubernetes.io/docs/tasks/inject-data-application/distribute-credentials-secure/#configure-all-key-value-pairs-in-a-secret-as-container-environment-variables 

The thing is that we tend to avoid having to add ""features"" to Airflow where they can be provided via ""external"" means in this case deployment that might be responsible to keep all secrets (i.e. env variables) that are providing all secret values from a single ""secret"" that can even be backed by a secret manager. 

Generally we are now more in the mode (for Airlfow 3) to search what  non core issues we can remove from Airflow rather than what we can add to it. Similalry as your other issue  (now discussion) https://github.com/apache/airflow/discussions/45221 - we are very, very, very cautious about adding things to Airflow that  could be done ""externally"" - we are good at scheduling workfloads, we are not good in keeping secret configurations (K8S is way better for that) and authentication (KeyCloak is way better in this). You have to remember, that whatever we approve as contributions to Airlfow, we also have to maintain it - and if there are other ways to achieve it - for example via deployment features - we tend to be very hesitant about accepting those.

You seem to be very focused on K8S / ArgoCD environment, so my question is - why ""standard"" feature where all the configurationsecrets can be configured in one place and exposed as env variables are not ""good"" for you ?

andrii-korotkov-verkada (Issue Creator) on (2024-12-26 18:53:06 UTC): Thanks for detailed replies. After more thinking I concede - marginal wins in maintenance of configs across shards are not worth the complexity of adding a new feature. I understand the complexity of maintaining open source. I can probably achieve my goals with some customized manifests overlays + a custom script to render the helm templates (which we have anyways). That said, I'm still looking to contribute something, maybe that KeyCloak auth manager.

"
2757656785,pull_request,closed,,Remove redundant check for positional arguments,"This was missed in the refactor: https://github.com/apache/airflow/pull/19965 -- since the `task_decorator_factory` enforces keyword-only parameters for via the `*` in its signature.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-24 11:41:23+00:00,[],2024-12-25 06:09:56+00:00,2024-12-25 06:09:56+00:00,https://github.com/apache/airflow/pull/45193,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2757102854,pull_request,closed,,Fix CI failure dict assertion with deepdiff,"https://github.com/apache/airflow/actions/runs/12471950302/job/34810119013#step:7:2722

Hope order is not important? 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-24 03:28:14+00:00,[],2024-12-24 08:21:31+00:00,2024-12-24 04:44:51+00:00,https://github.com/apache/airflow/pull/45191,[],"[{'comment_id': 2560802101, 'issue_id': 2757102854, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 12, 24, 8, 1, 3, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-24 08:01:03 UTC): Nice!

"
2756816079,pull_request,open,,issue 45114: Allow SMTP user and password to be set from airflow.cfg,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).

Closes: #45114 ",Mamiololo01,2024-12-23 22:49:30+00:00,[],2025-02-08 00:14:52+00:00,,https://github.com/apache/airflow/pull/45189,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2560399332, 'issue_id': 2756816079, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 23, 22, 49, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2644360031, 'issue_id': 2756816079, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 8, 0, 14, 50, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-23 22:49:34 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2025-02-08 00:14:50 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2756742460,pull_request,closed,,Add support for serverless job in Databricks operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #45138 

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45138 

This PR enables running Databricks jobs as a serverless mode. It relaxes the check for the presence of both job_cluster_key and existing_cluster_id (as for serverless, both settings should not be present). It also added a named parameter for databricks environment
Also added relevant unit test cases and updated the documentation.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",HariGS-DB,2024-12-23 21:33:45+00:00,[],2025-02-05 05:51:53+00:00,2025-01-28 12:06:46+00:00,https://github.com/apache/airflow/pull/45188,"[('area:providers', ''), ('kind:documentation', ''), ('provider:databricks', '')]","[{'comment_id': 2560321426, 'issue_id': 2756742460, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 23, 21, 33, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560325703, 'issue_id': 2756742460, 'author': 'HariGS-DB', 'body': '@alexott Please could you give your review comments when possible.', 'created_at': datetime.datetime(2024, 12, 23, 21, 38, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595715484, 'issue_id': 2756742460, 'author': 'HariGS-DB', 'body': '> Thanks for the great addition @HariGS-DB . I have few minor suggestions. Happy to take another pass once you add your thoughts or have addressed the comments.\r\n> \r\n> Thanks @eladkal for requesting review here\r\n\r\nHi @pankajkoti I have incorporated your review comments. I had to close and reopen the PR due to some merge conflicts which I have resolved. Please could you check and give me your new feedback', 'created_at': datetime.datetime(2025, 1, 16, 13, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597562792, 'issue_id': 2756742460, 'author': 'pankajkoti', 'body': ""@HariGS-DB some checks are failing in the CI. Could you please take care of that? And then we're good to merge I guess"", 'created_at': datetime.datetime(2025, 1, 17, 6, 59, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614513769, 'issue_id': 2756742460, 'author': 'HariGS-DB', 'body': ""> @HariGS-DB some checks are failing in the CI. Could you please take care of that? And then we're good to merge I guess\r\n\r\nI have addressed some of the issues. Could you please re-check? I think it needs your approval before the complete tests are run."", 'created_at': datetime.datetime(2025, 1, 26, 17, 19, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616108920, 'issue_id': 2756742460, 'author': 'HariGS-DB', 'body': '@pankajkoti I have resolved the issues and the error check in the test and docs. But I am still getting a mypy error in the CI for code which I have not even touched. I might need some advice on how should I resolve them', 'created_at': datetime.datetime(2025, 1, 27, 15, 43, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618661991, 'issue_id': 2756742460, 'author': 'HariGS-DB', 'body': '@pankajkoti I see you have pushed a new change which seem to have fixed the CI pipelines. Is there anything else need to be done for merging this. Please let me know', 'created_at': datetime.datetime(2025, 1, 28, 10, 57, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618820125, 'issue_id': 2756742460, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 28, 12, 6, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618823762, 'issue_id': 2756742460, 'author': 'pankajkoti', 'body': 'Thanks, @HariGS-DB, for the fantastic contribution! Iâ€™ve merged the PR.\r\n\r\nSince this was your first contribution, the CI pipeline required maintainer approval to run. Going forward, for your subsequent PRs, the CI pipelines will run automatically without needing approval. ðŸŽ‰', 'created_at': datetime.datetime(2025, 1, 28, 12, 8, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634927921, 'issue_id': 2756742460, 'author': 'HariGS-DB', 'body': '@pankajkoti Do you know when this PR will be released in the next airflow version? I will need to add another PR to introduce a validation for serverless (check for presence of environment_key  in the json payload when submitting it for serverless ). I will submit this PR this week, is it possible to hold this PR in the next release until then?', 'created_at': datetime.datetime(2025, 2, 4, 19, 53, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2635762360, 'issue_id': 2756742460, 'author': 'pankajkoti', 'body': 'Hi @HariGS-DB,\r\n\r\nProviders are typically released on a bi-weekly cycle, as outlined here: https://github.com/apache/airflow/blob/main/PROVIDERS.rst#community-providers-release-process. While itâ€™s not possible to delay a release for a single PR or skip a PR from the release candidate, you can cast a negative vote if the provider release includes this PR and it introduces a breaking change. Release managers initiate a voting thread once the provider release candidates are created. If youâ€™re not already subscribed to the dev list (https://airflow.apache.org/community/#mailing-list), I recommend doing so to stay informed about upcoming releases, allowing you to test and vote accordingly.\r\n\r\nIn this case, it looks like the change is an addition rather than a regression, so proceeding with the release seems reasonable. Additional validation can be incorporated in the next release if needed, without delaying the current one. Does that sound good to you?', 'created_at': datetime.datetime(2025, 2, 5, 5, 51, 25, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-23 21:33:50 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

HariGS-DB (Issue Creator) on (2024-12-23 21:38:58 UTC): @alexott Please could you give your review comments when possible.

HariGS-DB (Issue Creator) on (2025-01-16 13:37:00 UTC): Hi @pankajkoti I have incorporated your review comments. I had to close and reopen the PR due to some merge conflicts which I have resolved. Please could you check and give me your new feedback

pankajkoti on (2025-01-17 06:59:22 UTC): @HariGS-DB some checks are failing in the CI. Could you please take care of that? And then we're good to merge I guess

HariGS-DB (Issue Creator) on (2025-01-26 17:19:37 UTC): I have addressed some of the issues. Could you please re-check? I think it needs your approval before the complete tests are run.

HariGS-DB (Issue Creator) on (2025-01-27 15:43:09 UTC): @pankajkoti I have resolved the issues and the error check in the test and docs. But I am still getting a mypy error in the CI for code which I have not even touched. I might need some advice on how should I resolve them

HariGS-DB (Issue Creator) on (2025-01-28 10:57:01 UTC): @pankajkoti I see you have pushed a new change which seem to have fixed the CI pipelines. Is there anything else need to be done for merging this. Please let me know

boring-cyborg[bot] on (2025-01-28 12:06:49 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

pankajkoti on (2025-01-28 12:08:29 UTC): Thanks, @HariGS-DB, for the fantastic contribution! Iâ€™ve merged the PR.

Since this was your first contribution, the CI pipeline required maintainer approval to run. Going forward, for your subsequent PRs, the CI pipelines will run automatically without needing approval. ðŸŽ‰

HariGS-DB (Issue Creator) on (2025-02-04 19:53:58 UTC): @pankajkoti Do you know when this PR will be released in the next airflow version? I will need to add another PR to introduce a validation for serverless (check for presence of environment_key  in the json payload when submitting it for serverless ). I will submit this PR this week, is it possible to hold this PR in the next release until then?

pankajkoti on (2025-02-05 05:51:25 UTC): Hi @HariGS-DB,

Providers are typically released on a bi-weekly cycle, as outlined here: https://github.com/apache/airflow/blob/main/PROVIDERS.rst#community-providers-release-process. While itâ€™s not possible to delay a release for a single PR or skip a PR from the release candidate, you can cast a negative vote if the provider release includes this PR and it introduces a breaking change. Release managers initiate a voting thread once the provider release candidates are created. If youâ€™re not already subscribed to the dev list (https://airflow.apache.org/community/#mailing-list), I recommend doing so to stay informed about upcoming releases, allowing you to test and vote accordingly.

In this case, it looks like the change is an addition rather than a regression, so proceeding with the release seems reasonable. Additional validation can be incorporated in the next release if needed, without delaying the current one. Does that sound good to you?

"
2756446063,pull_request,closed,,[providers-fab/v1-5] Invalidate user session on password reset (#45139),"session expire on pass change

fix statis checks

add tests (cherry picked from commit https://github.com/apache/airflow/commit/cf401c48bb6d06f1b30fef59d2a07afab22118bc)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-23 17:12:15+00:00,[],2025-01-11 19:41:30+00:00,2024-12-24 08:11:37+00:00,https://github.com/apache/airflow/pull/45185,"[('provider:google', 'Google (including GCP) related issues'), ('provider:microsoft-azure', 'Azure-related issues'), ('area:CLI', ''), ('area:providers', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('provider:fab', '')]","[{'comment_id': 2560054067, 'issue_id': 2756446063, 'author': 'potiuk', 'body': 'Same as https://github.com/apache/airflow/pull/45164 but opened from the ""apache/airlfow"" repository so that after approval I can just push the `providers-fab/v1-5` branch to the tip of the approved PR - to keep commit history.', 'created_at': datetime.datetime(2024, 12, 23, 17, 16, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560813136, 'issue_id': 2756446063, 'author': 'potiuk', 'body': 'I had to rebase it one-more time to make it `fast-forward` one.', 'created_at': datetime.datetime(2024, 12, 24, 8, 11, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560817518, 'issue_id': 2756446063, 'author': 'potiuk', 'body': ""All right @eladkal -> the `providers-fab/v1-5` branch tip now contains the back-ported changes and you should be able to chec out that branch and follow the regular process for `1.5.2` released of the `fab` provider (and only that provider) from that branch.\r\n\r\nIt's generally smooth and relatively simple - so far (even if I had to backport few changes).\r\n\r\nWe can indeed think of some improvements there. I will create an issue for it -> one idea I had is that we could have some code in`breeze` that we could modify Provider's selective checks to only run tests for selected providers, not for all of them"", 'created_at': datetime.datetime(2024, 12, 24, 8, 15, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560827472, 'issue_id': 2756446063, 'author': 'potiuk', 'body': 'I created an issue https://github.com/apache/airflow/issues/45192 in our CI/DEV ENV project that describes how we can make future cases like that simpler to handle backporting.', 'created_at': datetime.datetime(2024, 12, 24, 8, 25, 18, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-23 17:16:17 UTC): Same as https://github.com/apache/airflow/pull/45164 but opened from the ""apache/airlfow"" repository so that after approval I can just push the `providers-fab/v1-5` branch to the tip of the approved PR - to keep commit history.

potiuk (Issue Creator) on (2024-12-24 08:11:01 UTC): I had to rebase it one-more time to make it `fast-forward` one.

potiuk (Issue Creator) on (2024-12-24 08:15:27 UTC): All right @eladkal -> the `providers-fab/v1-5` branch tip now contains the back-ported changes and you should be able to chec out that branch and follow the regular process for `1.5.2` released of the `fab` provider (and only that provider) from that branch.

It's generally smooth and relatively simple - so far (even if I had to backport few changes).

We can indeed think of some improvements there. I will create an issue for it -> one idea I had is that we could have some code in`breeze` that we could modify Provider's selective checks to only run tests for selected providers, not for all of them

potiuk (Issue Creator) on (2024-12-24 08:25:18 UTC): I created an issue https://github.com/apache/airflow/issues/45192 in our CI/DEV ENV project that describes how we can make future cases like that simpler to handle backporting.

"
2756445920,pull_request,closed,,Allow internal retries when pending k8s pod is deleted,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
On Airflow instances with the Kubernetes executor, a task will immediately fail if its worker pod is deleted/ evicted in the pending state. A new worker pod is not spun up to replace it, and the task fails with the below error message. 
```
{task_context_logger.py:104} ERROR - Executor reports task instance <TaskInstance: dag_id.task_id scheduled__2024-10-20T02:00:00+00:00 [queued]> finished (failed) although the task says it's queued. (Info: None) Was the task killed externally?
```
This failure is triggered by [this line in the source code](https://github.com/apache/airflow/blob/43d7c1c5b6a83694c9c526ab9bc29cc1a87c4ef3/providers/src/airflow/providers/cncf/kubernetes/executors/kubernetes_executor_utils.py#L237). 

If the task is not failed upon worker pod deletion, it will remain in the queued state until it reaches `task_queued_timeout`. Once this timeout is reached, internal retries will be allowed due to [PR #43520](https://github.com/apache/airflow/pull/43520) and a new worker pod will be spun up for the task. Therefore, if the first worker pod was deleted or evicted due to a temporary issue, the task will be able to run on the newly spun up worker pod.   

In this PR, I have removed the code that fails the task when its pending worker pod is deleted. This will prevent task failures from temporary issues with pending worker pods.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",karenbraganz,2024-12-23 17:12:08+00:00,[],2025-01-27 12:54:20+00:00,2025-01-24 17:15:09+00:00,https://github.com/apache/airflow/pull/45184,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2756377278,pull_request,closed,,Add full screen view for logs,"Related https://github.com/apache/airflow/issues/44663#issuecomment-2520512667

It will be useful to have logs open in full screen view to read the logs. Currently the tab and task details are still present on scroll taking more space. Legacy logs page had more screen space which was useful for our users internally. The implementation is simple that uses dialog to display the same code block with wrap and other styles applied in full screen mode.

Notes for reviewer and self : 

* I would opt for removing Dialog.Header section too to get more space or replace log with some other useful information.
* Using an IconButton but can change to button with text ""Full Screen"" for uniformity.

![image](https://github.com/user-attachments/assets/c0185a9e-3b13-44b6-bea6-43ffdcdba444)

Full screen

![image](https://github.com/user-attachments/assets/5ccf6ed9-09b0-457a-b6a1-b0dfae5d458c)


",tirkarthi,2024-12-23 16:27:40+00:00,[],2025-01-08 14:27:28+00:00,2025-01-08 14:20:50+00:00,https://github.com/apache/airflow/pull/45183,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2566760185, 'issue_id': 2756377278, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 2, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577806752, 'issue_id': 2756377278, 'author': 'tirkarthi', 'body': 'Thanks @pierrejeambrun and @bbovenzi', 'created_at': datetime.datetime(2025, 1, 8, 14, 27, 26, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-01 00:02:53 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

tirkarthi (Issue Creator) on (2025-01-08 14:27:26 UTC): Thanks @pierrejeambrun and @bbovenzi

"
2756318746,pull_request,closed,,feat: Add OpenLineage support for CloudSQLExecuteQueryOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for CloudSQLExecuteQueryOperator. The logic is very similar (almost the same) as in SQLExecuteQueryOperator where we take advantage of DB hooks being instrumented.

Adding OL required changing sql proxy in the operator to a context manager, probably a nit change.

I've run some manual tests and all looks good.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-23 15:50:06+00:00,[],2025-01-27 13:06:31+00:00,2025-01-22 15:11:17+00:00,https://github.com/apache/airflow/pull/45182,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2573146636, 'issue_id': 2756318746, 'author': 'kacpermuda', 'body': ""@ahidalgob @michalmodras As an addition to my manual tests I've done I wanted to run system tests for CloudSQLExecuteQueryOperator, but they seem to fail even on current main (breeze testing system-tests providers/tests/system/google/cloud/cloud_sql/example_cloud_sql_query.py). Also, the [system test dashboard](https://storage.googleapis.com/providers-dashboard-html/dashboard.html) provided by Google is not available, so I can't verify if those system tests fails only for me. Would appreciate any help in running those tests"", 'created_at': datetime.datetime(2025, 1, 6, 13, 47, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577326536, 'issue_id': 2756318746, 'author': 'michalmodras', 'body': '@fdemiane is currently working on some fixes in the Google system tests dashboard; @fdemiane can you please help @kacpermuda ?', 'created_at': datetime.datetime(2025, 1, 8, 10, 27, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578169009, 'issue_id': 2756318746, 'author': 'mobuchowski', 'body': '@kacpermuda should we draft this PR until you verify if it works?', 'created_at': datetime.datetime(2025, 1, 8, 16, 58, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578364800, 'issue_id': 2756318746, 'author': 'kacpermuda', 'body': ""Yeah, we can do that. I've tested it manually but if we can run the system tests as well it would be better."", 'created_at': datetime.datetime(2025, 1, 8, 18, 38, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2592636496, 'issue_id': 2756318746, 'author': 'fdemiane', 'body': ""Hello @kacpermuda,\r\nIndeed the Google Providers Dashboard is down for maintenance. The example_cloud_sql_query.py system test was also failing on main since a long time, and I wasn't able to run it either. This needs investigation and most probably changes to the system test code.\r\nIn the light of the above, I can recommend sticking to manually testing the operator, or maybe try to manually replicate in some way what the system test is doing for greater coverage"", 'created_at': datetime.datetime(2025, 1, 15, 12, 15, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604186792, 'issue_id': 2756318746, 'author': 'kacpermuda', 'body': ""Thanks for the information. I've run some more manual tests, I think I even managed to run a system test with proxy (that was my main concern, if the proxy still works fine). I think it can be merged now, and once the dashboard is live again I'll check again if all works well."", 'created_at': datetime.datetime(2025, 1, 21, 9, 44, 5, tzinfo=datetime.timezone.utc)}]","kacpermuda (Issue Creator) on (2025-01-06 13:47:07 UTC): @ahidalgob @michalmodras As an addition to my manual tests I've done I wanted to run system tests for CloudSQLExecuteQueryOperator, but they seem to fail even on current main (breeze testing system-tests providers/tests/system/google/cloud/cloud_sql/example_cloud_sql_query.py). Also, the [system test dashboard](https://storage.googleapis.com/providers-dashboard-html/dashboard.html) provided by Google is not available, so I can't verify if those system tests fails only for me. Would appreciate any help in running those tests

michalmodras on (2025-01-08 10:27:45 UTC): @fdemiane is currently working on some fixes in the Google system tests dashboard; @fdemiane can you please help @kacpermuda ?

mobuchowski on (2025-01-08 16:58:25 UTC): @kacpermuda should we draft this PR until you verify if it works?

kacpermuda (Issue Creator) on (2025-01-08 18:38:23 UTC): Yeah, we can do that. I've tested it manually but if we can run the system tests as well it would be better.

fdemiane on (2025-01-15 12:15:52 UTC): Hello @kacpermuda,
Indeed the Google Providers Dashboard is down for maintenance. The example_cloud_sql_query.py system test was also failing on main since a long time, and I wasn't able to run it either. This needs investigation and most probably changes to the system test code.
In the light of the above, I can recommend sticking to manually testing the operator, or maybe try to manually replicate in some way what the system test is doing for greater coverage

kacpermuda (Issue Creator) on (2025-01-21 09:44:05 UTC): Thanks for the information. I've run some more manual tests, I think I even managed to run a system test with proxy (that was my main concern, if the proxy still works fine). I think it can be merged now, and once the dashboard is live again I'll check again if all works well.

"
2756318427,pull_request,closed,,fix GCSToGCSOperator bug when copy single object with replace to False,"This PR aims to fix a small bug in GCSToGCSOperator when copy single object with replace to False.

Currently, when replace set to False, the set operation is used to check replacing file(s).
It works well except in line 412 of _copy_source_without_wildcard function that check `objects` is a single object. An error occurred while this if statement tries to get element by index from set object.
`if len(objects) == 1 and objects[0][-1] != ""/"":`
I simply convert back to a list. It will not affect other downstream because other `objects` are a list too.

I also attached an error log that I found this bug last month.
![IMG_5918](https://github.com/user-attachments/assets/0bf28f86-6d0b-428d-949c-d912d1bae48a)


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",NatchapolLaow,2024-12-23 15:49:53+00:00,[],2024-12-26 12:57:49+00:00,2024-12-26 12:57:46+00:00,https://github.com/apache/airflow/pull/45181,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2559936472, 'issue_id': 2756318427, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 23, 15, 49, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562672408, 'issue_id': 2756318427, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 26, 12, 57, 48, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-23 15:49:57 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-12-26 12:57:48 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2756269664,pull_request,closed,,Add lower bound for alloydb,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-23 15:20:27+00:00,[],2024-12-24 09:30:20+00:00,2024-12-24 09:30:18+00:00,https://github.com/apache/airflow/pull/45180,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2559893049, 'issue_id': 2756269664, 'author': 'potiuk', 'body': 'This should remove warning when `uv` performs resolution.', 'created_at': datetime.datetime(2024, 12, 23, 15, 21, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-23 15:21:00 UTC): This should remove warning when `uv` performs resolution.

"
2756148308,pull_request,closed,,[v2-10-test] Update min version of click also in airflow to 8.1.8 (#45177),"Click introduced breaking change for breeze opts behaviour
fixed in #45156 however it did not force breeze image to upgrade
click to newer version and it could have caused out-dated
images to use older click version even if the image has been
rebuilt.

This PR also updates click version in the breeze image.
(cherry picked from commit a2b18d8181fa0d27956e2fd3669d5c50cd121846)

Co-authored-by: Jarek Potiuk <jarek@potiuk.com>",github-actions[bot],2024-12-23 14:10:05+00:00,[],2025-01-12 13:13:32+00:00,2025-01-12 13:13:18+00:00,https://github.com/apache/airflow/pull/45179,[],"[{'comment_id': 2585730019, 'issue_id': 2756148308, 'author': 'potiuk', 'body': 'Not needed any more.', 'created_at': datetime.datetime(2025, 1, 12, 13, 13, 18, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-12 13:13:18 UTC): Not needed any more.

"
2756142723,pull_request,closed,,Correctly import isabs from os.path,"The #45139 imported isabs from ""airflow.www.app"" - but isabs has been added there fairly recently and it is anyhow stdlib's os.path isabs - so it should be imported from there.

This breaks fab 1.5.2 backport compatibility tests, so we need to cherry-pick it there alongside #45139

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-23 14:06:42+00:00,[],2024-12-23 14:24:42+00:00,2024-12-23 14:24:40+00:00,https://github.com/apache/airflow/pull/45178,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2559775307, 'issue_id': 2756142723, 'author': 'potiuk', 'body': 'cc: @shubhamraj-git -> small thing I found out when backporting - isabs should be imported from os.path :)', 'created_at': datetime.datetime(2024, 12, 23, 14, 7, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559776932, 'issue_id': 2756142723, 'author': 'potiuk', 'body': 'I am so glad we have compatibility tests :)', 'created_at': datetime.datetime(2024, 12, 23, 14, 8, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559782956, 'issue_id': 2756142723, 'author': 'shubhamraj-git', 'body': ""@potiuk Ohh yeah! Sorry for this.\r\nJust saw, need to be careful while choosing the 'quick fix' in VS code. :)"", 'created_at': datetime.datetime(2024, 12, 23, 14, 12, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559800770, 'issue_id': 2756142723, 'author': 'potiuk', 'body': '> +1, nice catch.\r\n\r\nIt were the tests that caught it - not me :)', 'created_at': datetime.datetime(2024, 12, 23, 14, 24, 10, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-23 14:07:27 UTC): cc: @shubhamraj-git -> small thing I found out when backporting - isabs should be imported from os.path :)

potiuk (Issue Creator) on (2024-12-23 14:08:36 UTC): I am so glad we have compatibility tests :)

shubhamraj-git on (2024-12-23 14:12:50 UTC): @potiuk Ohh yeah! Sorry for this.
Just saw, need to be careful while choosing the 'quick fix' in VS code. :)

potiuk (Issue Creator) on (2024-12-23 14:24:10 UTC): It were the tests that caught it - not me :)

"
2756113189,pull_request,closed,,Update min version of click also in airflow to 8.1.8,"Click introduced breaking change for breeze opts behaviour fixed in #45156 however it did not force breeze image to upgrade click to newer version and it could have caused out-dated images to use older click version even if the image has been rebuilt.

This PR also updates click version in the breeze image.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-23 13:50:23+00:00,[],2024-12-23 14:10:09+00:00,2024-12-23 14:09:20+00:00,https://github.com/apache/airflow/pull/45177,"[('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2559751223, 'issue_id': 2756113189, 'author': 'potiuk', 'body': ""cc: @raphaelauv -> that's why your hash generated in #45149 was different."", 'created_at': datetime.datetime(2024, 12, 23, 13, 53, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559779087, 'issue_id': 2756113189, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45179""><img src=""https://img.shields.io/badge/PR-45179-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 23, 14, 10, 7, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-23 13:53:25 UTC): cc: @raphaelauv -> that's why your hash generated in #45149 was different.

github-actions[bot] on (2024-12-23 14:10:07 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45179""><img src=""https://img.shields.io/badge/PR-45179-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2756007982,pull_request,closed,,Chart: add info that storageClassName can be templated,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

It is possible to template `storageClassName` parameter, but for some reason it is not mentioned at https://airflow.apache.org/docs/helm-chart/stable/parameters-ref.html as it is for other parameters that support templating. This small PR fixes it.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Aakcht,2024-12-23 12:47:22+00:00,[],2025-02-05 15:52:03+00:00,2025-01-09 13:52:53+00:00,https://github.com/apache/airflow/pull/45176,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2755886271,pull_request,open,,Fix ContinuousTimetable false triggering when last run ends in future,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45081 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-12-23 11:40:50+00:00,[],2025-02-08 04:32:00+00:00,,https://github.com/apache/airflow/pull/45175,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2755576862,pull_request,closed,,Add checkbox snippet,"

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-23 09:08:03+00:00,[],2024-12-23 09:46:21+00:00,2024-12-23 09:44:10+00:00,https://github.com/apache/airflow/pull/45174,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2559309032, 'issue_id': 2755576862, 'author': 'jscheffl', 'body': 'Where is the checkbox to be used  in future? Or any ticket associated to the demand creating it?', 'created_at': datetime.datetime(2024, 12, 23, 9, 39, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559312118, 'issue_id': 2755576862, 'author': 'shubhamraj-git', 'body': ""> Where is the checkbox to be used in future? Or any ticket associated to the demand creating it?\r\n\r\nYes @jscheffl , This will be used in variables list or list page, where the rows need to be selected. I didn't raise any PR thats why couldn't link any issues towards it."", 'created_at': datetime.datetime(2024, 12, 23, 9, 41, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559319767, 'issue_id': 2755576862, 'author': 'shubhamraj-git', 'body': 'Yaa, actually I have started working on it, faced the issue, thought might rebase it, that PR will take longer to be raised.  But will keep this in mind from next time.', 'created_at': datetime.datetime(2024, 12, 23, 9, 46, 20, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-23 09:39:41 UTC): Where is the checkbox to be used  in future? Or any ticket associated to the demand creating it?

shubhamraj-git (Issue Creator) on (2024-12-23 09:41:37 UTC): Yes @jscheffl , This will be used in variables list or list page, where the rows need to be selected. I didn't raise any PR thats why couldn't link any issues towards it.

shubhamraj-git (Issue Creator) on (2024-12-23 09:46:20 UTC): Yaa, actually I have started working on it, faced the issue, thought might rebase it, that PR will take longer to be raised.  But will keep this in mind from next time.

"
2755533708,pull_request,closed,,Moving test that updates TI state to right class,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

`test_ti_update_state_to_failed_table_check` doesn't belong under the class `TestTIHealthEndpoint`. Moving it into: `TestTIUpdateState`


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-23 08:43:09+00:00,[],2024-12-23 12:37:06+00:00,2024-12-23 12:37:06+00:00,https://github.com/apache/airflow/pull/45173,[],[],
2754929951,pull_request,open,,fetches data but fails to display them,"# Description

I implemented data fetching for pool slots using React Query. The data is successfully retrieved but I need help with displaying it in the required format.

Closes: https://github.com/apache/airflow/issues/43328

## Current Status
- âœ… Successfully fetching pool slots data using React Query
- âœ… Basic data transformation implemented
- âš ï¸ Display format needs adjustment to match design requirements

## Implementation Details
- Added usePoolServiceGetPools hook for data fetching
- Implemented data reduction to calculate total slots by type:
  - running
  - queued
  - deferred
  - scheduled
  - open

## Questions/Help Needed
- Need guidance on transforming the display to match the horizontal stacked bar design
- Looking for feedback on the current data transformation approach
",LefterisXefteris,2024-12-23 00:28:38+00:00,[],2025-01-07 14:17:16+00:00,,https://github.com/apache/airflow/pull/45170,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2559966906, 'issue_id': 2754929951, 'author': 'tirkarthi', 'body': 'Related issue https://github.com/apache/airflow/issues/43328', 'created_at': datetime.datetime(2024, 12, 23, 16, 12, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566760329, 'issue_id': 2754929951, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 3, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575396919, 'issue_id': 2754929951, 'author': 'pierrejeambrun', 'body': 'I think some rebase went wrong. Can you fix the branch and resolve possible conflicts to facilitate the review please.', 'created_at': datetime.datetime(2025, 1, 7, 14, 16, 8, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-12-23 16:12:40 UTC): Related issue https://github.com/apache/airflow/issues/43328

jscheffl on (2025-01-01 00:03:16 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

pierrejeambrun on (2025-01-07 14:16:08 UTC): I think some rebase went wrong. Can you fix the branch and resolve possible conflicts to facilitate the review please.

"
2754862086,pull_request,closed,,"[providers-fab/v1-5] Sort ""opts"" element in click option dictionary before hashing (#45156)","Some impleemntation details of click 8.1.8 caused instability in configuration directories that are produced by click config - the instability is in sequence of generated ""opts"" list - the sequence of options in it is random.

While it can be likely fixed in later versions, better is to protect from it and sort the opts list before hashing the dict.

(cherry picked from commit 1796c40c82b621dba68b33bb1a43db8185e3a858)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 21:56:36+00:00,[],2024-12-22 22:08:23+00:00,2024-12-22 22:08:22+00:00,https://github.com/apache/airflow/pull/45169,"[('area:dev-tools', '')]","[{'comment_id': 2558616798, 'issue_id': 2754862086, 'author': 'potiuk', 'body': ""Need to cherry-pick that one to FAB provider's branch"", 'created_at': datetime.datetime(2024, 12, 22, 21, 57, 30, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 21:57:30 UTC): Need to cherry-pick that one to FAB provider's branch

"
2754851615,pull_request,closed,,[providers-fab/v1-5] Add build-images workflow triggering for provideâ€¦,"â€¦r branches (#45167)

(cherry picked from commit 351ac28c7c4dde3a611e4260bbb0f01c7618f261)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 21:26:40+00:00,[],2024-12-22 21:28:02+00:00,2024-12-22 21:28:01+00:00,https://github.com/apache/airflow/pull/45168,"[('area:dev-tools', '')]","[{'comment_id': 2558606594, 'issue_id': 2754851615, 'author': 'potiuk', 'body': ""Not sure if 100% needed, but let's merge it first."", 'created_at': datetime.datetime(2024, 12, 22, 21, 27, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 21:27:31 UTC): Not sure if 100% needed, but let's merge it first.

"
2754843557,pull_request,closed,,Add build-images workflow triggering for provider branches,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 21:04:52+00:00,[],2024-12-22 21:25:42+00:00,2024-12-22 21:25:40+00:00,https://github.com/apache/airflow/pull/45167,"[('area:dev-tools', '')]","[{'comment_id': 2558599870, 'issue_id': 2754843557, 'author': 'potiuk', 'body': 'One more thing needed - pull_request_target needs to be configured for `provider-*` branches too :)', 'created_at': datetime.datetime(2024, 12, 22, 21, 6, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 21:06:31 UTC): One more thing needed - pull_request_target needs to be configured for `provider-*` branches too :)

"
2754832219,pull_request,closed,,Fix branch filter pattens for provider branches in ci workflow (#45162),"I **hope** this time it will be ok:

https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#filter-pattern-cheat-sheet (cherry picked from commit 2535f4edc19e5da3d021de6afb3bb16616bbdf9e)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 20:33:16+00:00,[],2024-12-22 20:49:57+00:00,2024-12-22 20:49:55+00:00,https://github.com/apache/airflow/pull/45166,"[('area:dev-tools', '')]","[{'comment_id': 2558590091, 'issue_id': 2754832219, 'author': 'potiuk', 'body': 'I think I need to merge this one to `providers-fab/v1-5` to make it works', 'created_at': datetime.datetime(2024, 12, 22, 20, 34, 26, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 20:34:26 UTC): I think I need to merge this one to `providers-fab/v1-5` to make it works

"
2754829310,pull_request,closed,,Fix check_files.py tool if tooo many providers released and switch to UV,"Providers release 12-2024 has soooo many providers that the `check_files.py` fails due to too many docker layers with `ERROR: failed to solve: failed to prepare w9ub7ctzfn39slk4xzv2uur10 as 2972unzauyu1g5fcm6iozhw1b: max depth exceeded`

This PR puts all PIP installs into a single layer plus switches to UV, so it is now SUPER fast and works. Also if the script is only used by noob PMC members :-D ",jscheffl,2024-12-22 20:25:31+00:00,[],2024-12-22 21:08:20+00:00,2024-12-22 21:08:20+00:00,https://github.com/apache/airflow/pull/45165,"[('area:dev-tools', '')]","[{'comment_id': 2558590644, 'issue_id': 2754829310, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 12, 22, 20, 36, 12, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-22 20:36:12 UTC): Nice!

"
2754828092,pull_request,closed,,[providers-fab/v1-5] Invalidate user session on password reset (#45139),"* session expire on pass change

* fix statis checks

* add tests (cherry picked from commit cf401c48bb6d06f1b30fef59d2a07afab22118bc)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 20:22:19+00:00,[],2024-12-23 17:14:06+00:00,2024-12-23 17:14:06+00:00,https://github.com/apache/airflow/pull/45164,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2558585942, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'Hmm. Still something wrong :(', 'created_at': datetime.datetime(2024, 12, 22, 20, 23, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558607130, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'All right ! Now all workflows seems to be triggering !', 'created_at': datetime.datetime(2024, 12, 22, 21, 29, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558607384, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'cc: @shubhamraj-git', 'created_at': datetime.datetime(2024, 12, 22, 21, 29, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558614899, 'issue_id': 2754828092, 'author': 'potiuk', 'body': '> Do we need any change log update?\r\n\r\nIt will be generated automatically - following the usual release provider process.', 'created_at': datetime.datetime(2024, 12, 22, 21, 51, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558615276, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'Ah... I need to backport the click changes too :)', 'created_at': datetime.datetime(2024, 12, 22, 21, 52, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558639898, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'And some more :)', 'created_at': datetime.datetime(2024, 12, 22, 23, 8, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559734445, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'I had to backport few fixes since that branch was relased - so it was a ""bit"" more involved - but all of them applied cleanly', 'created_at': datetime.datetime(2024, 12, 23, 13, 42, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560051378, 'issue_id': 2754828092, 'author': 'potiuk', 'body': 'Everything is green here, so cool. But I want to keep history of the commits, so I had to redo it from the ""apache/airflow"" repository and will merge it by pushing the `providers-fab/v1-5` branch once approved there.\r\n\r\nhttps://github.com/apache/airflow/pull/45185', 'created_at': datetime.datetime(2024, 12, 23, 17, 14, 6, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 20:23:17 UTC): Hmm. Still something wrong :(

potiuk (Issue Creator) on (2024-12-22 21:29:02 UTC): All right ! Now all workflows seems to be triggering !

potiuk (Issue Creator) on (2024-12-22 21:29:50 UTC): cc: @shubhamraj-git

potiuk (Issue Creator) on (2024-12-22 21:51:51 UTC): It will be generated automatically - following the usual release provider process.

potiuk (Issue Creator) on (2024-12-22 21:52:56 UTC): Ah... I need to backport the click changes too :)

potiuk (Issue Creator) on (2024-12-22 23:08:47 UTC): And some more :)

potiuk (Issue Creator) on (2024-12-23 13:42:37 UTC): I had to backport few fixes since that branch was relased - so it was a ""bit"" more involved - but all of them applied cleanly

potiuk (Issue Creator) on (2024-12-23 17:14:06 UTC): Everything is green here, so cool. But I want to keep history of the commits, so I had to redo it from the ""apache/airflow"" repository and will merge it by pushing the `providers-fab/v1-5` branch once approved there.

https://github.com/apache/airflow/pull/45185

"
2754816518,pull_request,closed,,Fix the error alert component,"Before:
<img width=""882"" alt=""Screenshot 2024-12-23 at 1 15 12â€¯AM"" src=""https://github.com/user-attachments/assets/f278e62d-d072-4ebb-b6ab-2ee945d296e6"" />

After:
<img width=""882"" alt=""Screenshot 2024-12-23 at 1 13 22â€¯AM"" src=""https://github.com/user-attachments/assets/0155d581-c3c9-4a63-a244-49d98c6cac6d"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-22 19:51:44+00:00,[],2024-12-22 20:43:37+00:00,2024-12-22 20:43:37+00:00,https://github.com/apache/airflow/pull/45163,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2754804618,pull_request,closed,,Fix branch filter pattens for provider branches in ci workflow,"I **hope** this time it will be ok:

https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#filter-pattern-cheat-sheet

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 19:19:27+00:00,[],2024-12-22 20:47:17+00:00,2024-12-22 20:19:04+00:00,https://github.com/apache/airflow/pull/45162,"[('area:dev-tools', '')]","[{'comment_id': 2558583515, 'issue_id': 2754804618, 'author': 'gopidesupavan', 'body': 'Tested here, yes hope it works this time :)\r\n\r\n<img width=""699"" alt=""image"" src=""https://github.com/user-attachments/assets/eca7cb14-99de-48c1-b44d-04c655cb9d87"" />\r\n\r\nhttps://regextester.github.io/', 'created_at': datetime.datetime(2024, 12, 22, 20, 15, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558584104, 'issue_id': 2754804618, 'author': 'potiuk', 'body': ""> Tested here, yes hope it works this time :)\r\n> \r\n\r\nThe problem is ... it's not regexp. It's not glob either. It's something GitHub speciific https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#filter-pattern-cheat-sheet\r\n\r\nFor example they only support select ranges lile `[a-z]` ..."", 'created_at': datetime.datetime(2024, 12, 22, 20, 17, 8, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-12-22 20:15:26 UTC): Tested here, yes hope it works this time :)

<img width=""699"" alt=""image"" src=""https://github.com/user-attachments/assets/eca7cb14-99de-48c1-b44d-04c655cb9d87"" />

https://regextester.github.io/

potiuk (Issue Creator) on (2024-12-22 20:17:08 UTC): The problem is ... it's not regexp. It's not glob either. It's something GitHub speciific https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#filter-pattern-cheat-sheet

For example they only support select ranges lile `[a-z]` ...

"
2754780689,pull_request,closed,,"[v2-10-test] Sort ""opts"" element in click option dictionary before haâ€¦","â€¦shing (#45156)

Some impleemntation details of click 8.1.8 caused instability in configuration directories that are produced by click config - the instability is in sequence of generated ""opts"" list - the sequence of options in it is random.

While it can be likely fixed in later versions, better is to protect from it and sort the opts list before hashing the dict. (cherry picked from commit 1796c40c82b621dba68b33bb1a43db8185e3a858)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 18:18:04+00:00,[],2024-12-22 20:37:03+00:00,2024-12-22 20:37:01+00:00,https://github.com/apache/airflow/pull/45161,"[('area:dev-tools', '')]",[],
2754771656,pull_request,closed,,Apply changes on a new branch from arorasachin9:feature/airflow-45037,Attempt to re-produce errors from https://github.com/apache/airflow/pull/45038/files,jscheffl,2024-12-22 17:56:09+00:00,[],2024-12-23 09:42:20+00:00,2024-12-23 09:42:19+00:00,https://github.com/apache/airflow/pull/45160,"[('area:providers', ''), ('provider:celery', '')]","[{'comment_id': 2559313240, 'issue_id': 2754771656, 'author': 'jscheffl', 'body': 'Continue on other PR...', 'created_at': datetime.datetime(2024, 12, 23, 9, 42, 19, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-23 09:42:19 UTC): Continue on other PR...

"
2754767929,pull_request,closed,,Add triggering PR and Push workflows for provider branches,"With FAB 1.5.2 we have the first case where we need to build and release providers for old version. That requires `pull_request` and `push` workflows to start when they are targetted against `providers-*/v[VERSION]` branches.

The .asf.yaml is updated to make providers-fab/v1-5 protected and documentation of provider's lifecycle is updated to explain how we work with releasing past versions of providers.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 17:46:54+00:00,[],2024-12-22 19:02:34+00:00,2024-12-22 19:02:33+00:00,https://github.com/apache/airflow/pull/45159,"[('area:providers', ''), ('area:dev-tools', '')]","[{'comment_id': 2558535099, 'issue_id': 2754767929, 'author': 'potiuk', 'body': 'cc: @shubhamraj-git', 'created_at': datetime.datetime(2024, 12, 22, 17, 47, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558538218, 'issue_id': 2754767929, 'author': 'potiuk', 'body': ""> Oooh, I feared this when the breaking chnges for FAB came in... let complexity get started :-D\r\n\r\nIt's actually very straightforward :). And I am glad we can finally try it."", 'created_at': datetime.datetime(2024, 12, 22, 17, 57, 27, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 17:47:17 UTC): cc: @shubhamraj-git

potiuk (Issue Creator) on (2024-12-22 17:57:27 UTC): It's actually very straightforward :). And I am glad we can finally try it.

"
2754765637,pull_request,open,,Fix: Added example of _push_xcoms_if_necessary to deferring.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
### What is the purpose of this PR?

This PR updates the `deferring.rst` documentation to include an example of the `_push_xcoms_if_necessary` method, as suggested in issue #44759.

The new content provides guidance on:
- Pushing XComs when deferred tasks exit directly from triggers.
- How to integrate `_push_xcoms_if_necessary` with custom triggers.

### Related Issues

Closes #44759.

### Changes Made
- Added a new section under **Exiting deferred task from Triggers** in `deferring.rst` to describe the `_push_xcoms_if_necessary` method and its usage.
- Included example code snippets to illustrate the implementation.

### Checklist

- [x] Documentation updated.
- [x] Code quality checks passed (pre-commit hooks run).

### Reviewers
Please suggest any further refinements or additional examples if required.


**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",avyuktsoni0731,2024-12-22 17:41:17+00:00,[],2025-02-07 00:15:14+00:00,,https://github.com/apache/airflow/pull/45158,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('kind:documentation', '')]","[{'comment_id': 2558533086, 'issue_id': 2754765637, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 22, 17, 41, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558579641, 'issue_id': 2754765637, 'author': 'potiuk', 'body': '@tirkarthi @eladkal -> I think you were more involved in https://github.com/apache/airflow/issues/44759 - that one looks nice and good I will have a few nits.', 'created_at': datetime.datetime(2024, 12, 22, 20, 3, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558620595, 'issue_id': 2754765637, 'author': 'tirkarthi', 'body': ""I don't think this is the right approach. My comment was that you can set `self.xcoms` which is a dictionary and then the triggerer pushes it to xcom once the event is emitted. There is no need to reimplement `_push_xcoms_if_necessary` or even mention it as a public interface. The example would be to set `self.xcoms` and explain to users that triggerer does the job of pushing them to xcom.\r\n\r\nhttps://github.com/apache/airflow/issues/44759#issuecomment-2528268226"", 'created_at': datetime.datetime(2024, 12, 22, 22, 9, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559056767, 'issue_id': 2754765637, 'author': 'avyuktsoni0731', 'body': ""@potiuk @tirkarthi I've created a PR with the changes, please do look into it, and let me know if I'm still not able to understand it properly, will make the required changes if needed."", 'created_at': datetime.datetime(2024, 12, 23, 7, 19, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2641465665, 'issue_id': 2754765637, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 7, 0, 15, 12, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-22 17:41:21 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-22 20:03:19 UTC): @tirkarthi @eladkal -> I think you were more involved in https://github.com/apache/airflow/issues/44759 - that one looks nice and good I will have a few nits.

tirkarthi on (2024-12-22 22:09:14 UTC): I don't think this is the right approach. My comment was that you can set `self.xcoms` which is a dictionary and then the triggerer pushes it to xcom once the event is emitted. There is no need to reimplement `_push_xcoms_if_necessary` or even mention it as a public interface. The example would be to set `self.xcoms` and explain to users that triggerer does the job of pushing them to xcom.

https://github.com/apache/airflow/issues/44759#issuecomment-2528268226

avyuktsoni0731 (Issue Creator) on (2024-12-23 07:19:52 UTC): @potiuk @tirkarthi I've created a PR with the changes, please do look into it, and let me know if I'm still not able to understand it properly, will make the required changes if needed.

github-actions[bot] on (2025-02-07 00:15:12 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2754761790,pull_request,closed,,[providers-fab/v1-5] Invalidate user session on password reset (#45139),"* session expire on pass change

* fix statis checks

* add tests (cherry picked from commit cf401c48bb6d06f1b30fef59d2a07afab22118bc)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 17:32:07+00:00,[],2024-12-22 20:20:47+00:00,2024-12-22 20:20:47+00:00,https://github.com/apache/airflow/pull/45157,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2558530245, 'issue_id': 2754761790, 'author': 'potiuk', 'body': 'cc: @shubhamraj-git', 'created_at': datetime.datetime(2024, 12, 22, 17, 32, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558560967, 'issue_id': 2754761790, 'author': 'potiuk', 'body': 'Re-opened to trigger (hopefully) the build.', 'created_at': datetime.datetime(2024, 12, 22, 19, 5, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558561720, 'issue_id': 2754761790, 'author': 'potiuk', 'body': 'Hmmmmmm', 'created_at': datetime.datetime(2024, 12, 22, 19, 7, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558585160, 'issue_id': 2754761790, 'author': 'potiuk', 'body': 'Hmm. I think I need to close that PR and open a new one.', 'created_at': datetime.datetime(2024, 12, 22, 20, 20, 47, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 17:32:30 UTC): cc: @shubhamraj-git

potiuk (Issue Creator) on (2024-12-22 19:05:43 UTC): Re-opened to trigger (hopefully) the build.

potiuk (Issue Creator) on (2024-12-22 19:07:41 UTC): Hmmmmmm

potiuk (Issue Creator) on (2024-12-22 20:20:47 UTC): Hmm. I think I need to close that PR and open a new one.

"
2754743879,pull_request,closed,,"Sort ""opts"" element in click option dictionary before hashing","Some impleemntation details of click 8.1.8 caused instability in configuration directories that are produced by click config - the instability is in sequence of generated ""opts"" list - the sequence of options in it is random.

While it can be likely fixed in later versions, better is to protect from it and sort the opts list before hashing the dict.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 16:50:15+00:00,[],2024-12-22 17:28:29+00:00,2024-12-22 17:27:39+00:00,https://github.com/apache/airflow/pull/45156,"[('area:dev-tools', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2558528527, 'issue_id': 2754743879, 'author': 'potiuk', 'body': 'The failing test is intermittent', 'created_at': datetime.datetime(2024, 12, 22, 17, 27, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558528861, 'issue_id': 2754743879, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12456292585\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>âŒ</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/1796c40c82b621dba68b33bb1a43db8185e3a858""><img src=\'https://img.shields.io/badge/Commit-1796c40-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 1796c40 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 22, 17, 28, 27, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 17:27:25 UTC): The failing test is intermittent

github-actions[bot] on (2024-12-22 17:28:27 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12456292585'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>âŒ</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/1796c40c82b621dba68b33bb1a43db8185e3a858""><img src='https://img.shields.io/badge/Commit-1796c40-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 1796c40 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2754714298,pull_request,closed,,"Fix breeze command hashes to ""Linux"" version.","When calculating command hashes, after click 1.8.1 the hash calculated is different for Linux than for Mac.

Until we fix it, setting it to Linux hashes is good for CI to not fail

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 15:37:22+00:00,[],2024-12-22 16:51:16+00:00,2024-12-22 15:43:40+00:00,https://github.com/apache/airflow/pull/45155,"[('area:dev-tools', '')]","[{'comment_id': 2558495968, 'issue_id': 2754714298, 'author': 'potiuk', 'body': 'I will take a close look what has changed eventually but evidently on Mac the hash is different :)', 'created_at': datetime.datetime(2024, 12, 22, 15, 38, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558496124, 'issue_id': 2754714298, 'author': 'potiuk', 'body': '(or at least it looks like - it also might be that there is other factor that makes it flip-flop).', 'created_at': datetime.datetime(2024, 12, 22, 15, 38, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558498614, 'issue_id': 2754714298, 'author': 'gopidesupavan', 'body': 'I got it i think its the ubuntu upgrade that github release recently ? ubuntu-24.04. might it is default now in our repo', 'created_at': datetime.datetime(2024, 12, 22, 15, 47, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558498999, 'issue_id': 2754714298, 'author': 'gopidesupavan', 'body': 'Our CI using now the latest version ubuntu-24.04, https://github.com/apache/airflow/actions/runs/12454695812/job/34766359224#step:1:4', 'created_at': datetime.datetime(2024, 12, 22, 15, 49, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558499153, 'issue_id': 2754714298, 'author': 'potiuk', 'body': ""> I got it i think its the ubuntu upgrade that github release recently ? ubuntu-24.04. might it is default now in our repo\r\n\r\nNaa. Something else - I see a very weird behaviour on my Mac - the hash is changing between runs, so that's something different."", 'created_at': datetime.datetime(2024, 12, 22, 15, 49, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558499813, 'issue_id': 2754714298, 'author': 'potiuk', 'body': ""It looks like it's just NOT STABLE - but I haven't figured out yet what triggers the unstability."", 'created_at': datetime.datetime(2024, 12, 22, 15, 52, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558499830, 'issue_id': 2754714298, 'author': 'gopidesupavan', 'body': ""> > I got it i think its the ubuntu upgrade that github release recently ? ubuntu-24.04. might it is default now in our repo\r\n> \r\n> Naa. Something else - I see a very weird behaviour on my Mac - the hash is changing between runs, so that's something different.\r\n\r\noh okay.."", 'created_at': datetime.datetime(2024, 12, 22, 15, 52, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558500191, 'issue_id': 2754714298, 'author': 'potiuk', 'body': 'Yeah... It flip-flops randomly so we will keep on seing it... very interesting :)', 'created_at': datetime.datetime(2024, 12, 22, 15, 53, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558501995, 'issue_id': 2754714298, 'author': 'potiuk', 'body': 'Ok. Found it - new click does not keep stable sequence of options:\r\n\r\n<img width=""1807"" alt=""Screenshot 2024-12-22 at 16 59 21"" src=""https://github.com/user-attachments/assets/69e1fb97-e4a5-4619-9dec-0921ba6790ed"" />', 'created_at': datetime.datetime(2024, 12, 22, 16, 0, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558516875, 'issue_id': 2754714298, 'author': 'potiuk', 'body': 'Fix here: https://github.com/apache/airflow/pull/45156', 'created_at': datetime.datetime(2024, 12, 22, 16, 51, 15, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 15:38:25 UTC): I will take a close look what has changed eventually but evidently on Mac the hash is different :)

potiuk (Issue Creator) on (2024-12-22 15:38:57 UTC): (or at least it looks like - it also might be that there is other factor that makes it flip-flop).

gopidesupavan on (2024-12-22 15:47:48 UTC): I got it i think its the ubuntu upgrade that github release recently ? ubuntu-24.04. might it is default now in our repo

gopidesupavan on (2024-12-22 15:49:17 UTC): Our CI using now the latest version ubuntu-24.04, https://github.com/apache/airflow/actions/runs/12454695812/job/34766359224#step:1:4

potiuk (Issue Creator) on (2024-12-22 15:49:52 UTC): Naa. Something else - I see a very weird behaviour on my Mac - the hash is changing between runs, so that's something different.

potiuk (Issue Creator) on (2024-12-22 15:52:15 UTC): It looks like it's just NOT STABLE - but I haven't figured out yet what triggers the unstability.

gopidesupavan on (2024-12-22 15:52:18 UTC): oh okay..

potiuk (Issue Creator) on (2024-12-22 15:53:42 UTC): Yeah... It flip-flops randomly so we will keep on seing it... very interesting :)

potiuk (Issue Creator) on (2024-12-22 16:00:11 UTC): Ok. Found it - new click does not keep stable sequence of options:

<img width=""1807"" alt=""Screenshot 2024-12-22 at 16 59 21"" src=""https://github.com/user-attachments/assets/69e1fb97-e4a5-4619-9dec-0921ba6790ed"" />

potiuk (Issue Creator) on (2024-12-22 16:51:15 UTC): Fix here: https://github.com/apache/airflow/pull/45156

"
2754705322,pull_request,closed,,Adding doc section in changelog for providers,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Core release changelogs have support for ""doc-only"" changes which looks like so:
```
doc-only
~~~~~~~~

* ``Update DAG example links in multiple providers documents (#44034)``

```


But for provider releases, for some reason, we push the ""doc"" marked ones to ""skipped"". This isn;t correct.
![Screenshot 2024-12-18 at 14 56 08](https://github.com/user-attachments/assets/2bc04941-8971-478f-b95f-92cada415741)
![Screenshot 2024-12-18 at 14 55 40](https://github.com/user-attachments/assets/756e3a3e-f213-4cad-947f-ea2d3027b88a)



Adding support to mark it in docs-only section for provider release too.

Tested with airbyte:
![image](https://github.com/user-attachments/assets/86812a20-5057-4762-9447-c941233010b0)

Result
![image](https://github.com/user-attachments/assets/e936be74-1368-41e5-8a6f-567f72e2b418)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-22 15:15:42+00:00,[],2024-12-23 05:40:42+00:00,2024-12-23 05:40:23+00:00,https://github.com/apache/airflow/pull/45154,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2558493286, 'issue_id': 2754705322, 'author': 'eladkal', 'body': 'Nice! Thank you for this one', 'created_at': datetime.datetime(2024, 12, 22, 15, 29, 17, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-12-22 15:29:17 UTC): Nice! Thank you for this one

"
2754680306,pull_request,closed,,Update link to provider life cycle doc,,eladkal,2024-12-22 14:17:22+00:00,[],2024-12-22 15:04:45+00:00,2024-12-22 14:50:49+00:00,https://github.com/apache/airflow/pull/45153,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2754652639,pull_request,closed,,More options for elasticsearch secret creation,"Sometimes you don't want to include secret data in Git manifest for security reasons, e.g. when storing manifests in Git and deploying with ArgoCD.

However, you may still want to generate a secret itself and then edit it's data section later, e.g. manually with kubectl.

Provide more options of generating the secret while keeping backwards compatibility.

related: #45140

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",andrii-korotkov-verkada,2024-12-22 13:10:12+00:00,[],2024-12-23 02:16:36+00:00,2024-12-23 02:16:26+00:00,https://github.com/apache/airflow/pull/45152,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2558451849, 'issue_id': 2754652639, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 22, 13, 10, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558452402, 'issue_id': 2754652639, 'author': 'andrii-korotkov-verkada', 'body': ""Please, let me know if this kind of approach is good. If so, I'll follow-up with PRs updating other secrets generation logic."", 'created_at': datetime.datetime(2024, 12, 22, 13, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558769296, 'issue_id': 2754652639, 'author': 'andrii-korotkov-verkada', 'body': ""I've realized there's probably not much sense in generating a secret with empty data, since it'd cause issues during bootstrap. I know that a part of problems is from trying to use ArgoCD instead of installing using Helm. So if not using pre-existing secret, it always makes sense to generate a full one and apply via Helm or Kubectl and not commit to the repo, and use ArgoCD to manage non-secrets only. One more option in my case is to use AWS secrets manager, fetching secrets in `airflowLocalSettings` and overriding env variables."", 'created_at': datetime.datetime(2024, 12, 23, 2, 16, 23, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-22 13:10:17 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

andrii-korotkov-verkada (Issue Creator) on (2024-12-22 13:12:00 UTC): Please, let me know if this kind of approach is good. If so, I'll follow-up with PRs updating other secrets generation logic.

andrii-korotkov-verkada (Issue Creator) on (2024-12-23 02:16:23 UTC): I've realized there's probably not much sense in generating a secret with empty data, since it'd cause issues during bootstrap. I know that a part of problems is from trying to use ArgoCD instead of installing using Helm. So if not using pre-existing secret, it always makes sense to generate a full one and apply via Helm or Kubectl and not commit to the repo, and use ArgoCD to manage non-secrets only. One more option in my case is to use AWS secrets manager, fetching secrets in `airflowLocalSettings` and overriding env variables.

"
2754634823,pull_request,closed,,[v2-10-test] Mark failing db isolation test in v2-10-test as skipped,"This test should be skipped for DB isolation mode.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 12:27:43+00:00,[],2024-12-22 12:42:06+00:00,2024-12-22 12:42:05+00:00,https://github.com/apache/airflow/pull/45151,[],"[{'comment_id': 2558439623, 'issue_id': 2754634823, 'author': 'potiuk', 'body': 'Should move v2-10-test PRs and canary builds back to the ""green"" zone.', 'created_at': datetime.datetime(2024, 12, 22, 12, 28, 40, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 12:28:40 UTC): Should move v2-10-test PRs and canary builds back to the ""green"" zone.

"
2754624219,pull_request,closed,,Update doc build timeout,"To avoid error on Amazon provider doc build:

```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 125, in worker
    result = (True, func(*args, **kwds))
  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 48, in mapstar
    return list(map(*args))
  File ""/opt/airflow/docs/build_docs.py"", line 200, in perform_docs_build_for_single_package
    errors=builder.build_sphinx_docs(
  File ""/opt/airflow/docs/exts/docs_build/docs_builder.py"", line 222, in build_sphinx_docs
    completed_proc = run(
  File ""/usr/local/lib/python3.9/subprocess.py"", line 507, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File ""/usr/local/lib/python3.9/subprocess.py"", line 1134, in communicate
    stdout, stderr = self._communicate(input, endtime, timeout)
  File ""/usr/local/lib/python3.9/subprocess.py"", line 2021, in _communicate
    self.wait(timeout=self._remaining_time(endtime))
  File ""/usr/local/lib/python3.9/subprocess.py"", line 1189, in wait
    return self._wait(timeout=timeout)
  File ""/usr/local/lib/python3.9/subprocess.py"", line 1925, in _wait
    raise TimeoutExpired(self.args, timeout)
subprocess.TimeoutExpired: Command '['sphinx-build', '-T', '--color', '-b', 'html', '-d', '/opt/airflow/docs/_doctrees/docs/apache-airflow-providers-amazon', '-c', '/opt/airflow/docs', '-w', '/opt/airflow/docs/_build/docs/apache-airflow-providers-amazon/stable/warning-build-apache-airflow-providers-amazon.log', '/opt/airflow/docs/apache-airflow-providers-amazon', '/opt/airflow/docs/_build/docs/apache-airflow-providers-amazon/stable']' timed out after 899.9998589580064 seconds
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/lib/python3.9/runpy.py"", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/usr/local/lib/python3.9/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/opt/airflow/docs/build_docs.py"", line 622, in <module>
    main()
  File ""/opt/airflow/docs/build_docs.py"", line 502, in main
    package_build_errors, package_spelling_errors = build_docs_for_packages(
  File ""/opt/airflow/docs/build_docs.py"", line 241, in build_docs_for_packages
    run_in_parallel(
  File ""/opt/airflow/docs/build_docs.py"", line 309, in run_in_parallel
    run_docs_build_in_parallel(
  File ""/opt/airflow/docs/build_docs.py"", line 355, in run_docs_build_in_parallel
    result_list = pool.map(perform_docs_build_for_single_package, doc_build_specifications)
  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 364, in map
    return self._map_async(func, iterable, mapstar, chunksize).get()
  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 771, in get
    raise self._value
subprocess.TimeoutExpired: Command '['sphinx-build', '-T', '--color', '-b', 'html', '-d', '/opt/airflow/docs/_doctrees/docs/apache-airflow-providers-amazon', '-c', '/opt/airflow/docs', '-w', '/opt/airflow/docs/_build/docs/apache-airflow-providers-amazon/stable/warning-build-apache-airflow-providers-amazon.log', '/opt/airflow/docs/apache-airflow-providers-amazon', '/opt/airflow/docs/_build/docs/apache-airflow-providers-amazon/stable']' timed out after 899.9998589580064 seconds
```",eladkal,2024-12-22 12:02:28+00:00,[],2024-12-22 13:24:06+00:00,2024-12-22 12:55:01+00:00,https://github.com/apache/airflow/pull/45150,"[('kind:documentation', '')]",[],
2754622629,pull_request,closed,,feat: K8S 1.32 support,,raphaelauv,2024-12-22 11:58:35+00:00,[],2024-12-23 13:53:29+00:00,2024-12-23 13:52:32+00:00,https://github.com/apache/airflow/pull/45149,"[('area:dev-tools', '')]","[{'comment_id': 2558523696, 'issue_id': 2754622629, 'author': 'raphaelauv', 'body': ""I can't reproduce with `pre-commit run --all-files` the error of the CI `Update breeze docs`"", 'created_at': datetime.datetime(2024, 12, 22, 17, 12, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558539570, 'issue_id': 2754622629, 'author': 'potiuk', 'body': ""Rebase. It's already been fixed in `main` in #45156 - that was instability in sequence of options in click config dictionary in click 8.1.8 which caused random hash calculation."", 'created_at': datetime.datetime(2024, 12, 22, 18, 1, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558572024, 'issue_id': 2754622629, 'author': 'raphaelauv', 'body': 'Thanks for your help , I rebased and it still failing, any idea ?', 'created_at': datetime.datetime(2024, 12, 22, 19, 38, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558582652, 'issue_id': 2754622629, 'author': 'potiuk', 'body': 'Yeah. You need to run `breeze static-checks --last-commit` and it should fix itself.', 'created_at': datetime.datetime(2024, 12, 22, 20, 12, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558582891, 'issue_id': 2754622629, 'author': 'potiuk', 'body': '(or so I think)', 'created_at': datetime.datetime(2024, 12, 22, 20, 13, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559513562, 'issue_id': 2754622629, 'author': 'raphaelauv', 'body': 'yes I tried `breeze static-checks --last-commit` after the rebase , no effect', 'created_at': datetime.datetime(2024, 12, 23, 11, 30, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559637294, 'issue_id': 2754622629, 'author': 'potiuk', 'body': 'Try  `breeze ci-image build --python 3.9` and repeat it.', 'created_at': datetime.datetime(2024, 12, 23, 12, 41, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559668203, 'issue_id': 2754622629, 'author': 'raphaelauv', 'body': 'yes I already tried to rebuild my breeze context , no effect', 'created_at': datetime.datetime(2024, 12, 23, 13, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559691249, 'issue_id': 2754622629, 'author': 'potiuk', 'body': 'You can also (though it should happen automatically) remove and re-install breeze `uv tool remove airflow_breeze` followed by `uv tool install --editable ./dev/breeze`.  Maybe also you did the rebuild before constraints were updated - then `breeze ci-image build --upgrade-to-newer-dependencies` might help.', 'created_at': datetime.datetime(2024, 12, 23, 13, 14, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559691800, 'issue_id': 2754622629, 'author': 'potiuk', 'body': 'I re-run it locally and those hashes were properly calculated - I pushed a fixup.', 'created_at': datetime.datetime(2024, 12, 23, 13, 14, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559697606, 'issue_id': 2754622629, 'author': 'raphaelauv', 'body': '`breeze ci-image build --upgrade-to-newer-dependencies` fixed it :+1: \r\n\r\nthanks', 'created_at': datetime.datetime(2024, 12, 23, 13, 18, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559748540, 'issue_id': 2754622629, 'author': 'potiuk', 'body': '> `breeze ci-image build --upgrade-to-newer-dependencies` fixed it ðŸ‘\r\n> \r\n> thanks\r\n\r\nAh. I found out the root cause - we should also upgrade minimum version of click in ""airflow"" so that `breeze ci-image build` will upgrade it as well - I missed that in https://github.com/apache/airflow/pull/45156. \r\n\r\nThis should be fixed now for everyone else via: https://github.com/apache/airflow/pull/45177', 'created_at': datetime.datetime(2024, 12, 23, 13, 51, 49, tzinfo=datetime.timezone.utc)}]","raphaelauv (Issue Creator) on (2024-12-22 17:12:45 UTC): I can't reproduce with `pre-commit run --all-files` the error of the CI `Update breeze docs`

potiuk on (2024-12-22 18:01:33 UTC): Rebase. It's already been fixed in `main` in #45156 - that was instability in sequence of options in click config dictionary in click 8.1.8 which caused random hash calculation.

raphaelauv (Issue Creator) on (2024-12-22 19:38:04 UTC): Thanks for your help , I rebased and it still failing, any idea ?

potiuk on (2024-12-22 20:12:31 UTC): Yeah. You need to run `breeze static-checks --last-commit` and it should fix itself.

potiuk on (2024-12-22 20:13:20 UTC): (or so I think)

raphaelauv (Issue Creator) on (2024-12-23 11:30:57 UTC): yes I tried `breeze static-checks --last-commit` after the rebase , no effect

potiuk on (2024-12-23 12:41:10 UTC): Try  `breeze ci-image build --python 3.9` and repeat it.

raphaelauv (Issue Creator) on (2024-12-23 13:01:00 UTC): yes I already tried to rebuild my breeze context , no effect

potiuk on (2024-12-23 13:14:18 UTC): You can also (though it should happen automatically) remove and re-install breeze `uv tool remove airflow_breeze` followed by `uv tool install --editable ./dev/breeze`.  Maybe also you did the rebuild before constraints were updated - then `breeze ci-image build --upgrade-to-newer-dependencies` might help.

potiuk on (2024-12-23 13:14:41 UTC): I re-run it locally and those hashes were properly calculated - I pushed a fixup.

raphaelauv (Issue Creator) on (2024-12-23 13:18:35 UTC): `breeze ci-image build --upgrade-to-newer-dependencies` fixed it :+1: 

thanks

potiuk on (2024-12-23 13:51:49 UTC): Ah. I found out the root cause - we should also upgrade minimum version of click in ""airflow"" so that `breeze ci-image build` will upgrade it as well - I missed that in https://github.com/apache/airflow/pull/45156. 

This should be fixed now for everyone else via: https://github.com/apache/airflow/pull/45177

"
2754616289,pull_request,closed,,[v2-10-test] Fix breeze output static checks failure (#45142),"The new click 8.1.8 makes the dictionary of options used to calculate hash of commands different for setup command. by bumping it to minimum 8.1.8 version we make the hash the same for both CI and locally installed breeze (click 8.1.8 change in pyproject.toml of breeze will force reinstallation of breeze for everyone locally).

(cherry picked from commit 4ab4707a81a103adfa0d9a5bdb90eba23e428b73)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 11:41:00+00:00,[],2024-12-22 12:42:18+00:00,2024-12-22 12:42:16+00:00,https://github.com/apache/airflow/pull/45147,"[('area:dev-tools', '')]",[],
2754555052,pull_request,closed,,Small fix to asset compilation retry,"Try num printed is now more human, and capture_output is added - it was missing in the original #45143

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 08:45:52+00:00,[],2024-12-22 10:28:15+00:00,2024-12-22 10:27:57+00:00,https://github.com/apache/airflow/pull/45144,"[('area:dev-tools', '')]","[{'comment_id': 2558380419, 'issue_id': 2754555052, 'author': 'potiuk', 'body': 'Small fix :)', 'created_at': datetime.datetime(2024, 12, 22, 8, 46, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558407607, 'issue_id': 2754555052, 'author': 'potiuk', 'body': '> Oh oops. The zero indexing error!!\r\n\r\noff-by-one :)', 'created_at': datetime.datetime(2024, 12, 22, 10, 28, 14, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-22 08:46:18 UTC): Small fix :)

potiuk (Issue Creator) on (2024-12-22 10:28:14 UTC): off-by-one :)

"
2754529567,pull_request,closed,,Prevent occasional 500 errors when installing npm dependencies,"When we are installing npm dependencies, occasionally in CI we get 500 Internal Error. This change adds max 3 tries of such installations - retrying when 500 internal error is detected.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 07:30:11+00:00,[],2024-12-22 10:09:16+00:00,2024-12-22 08:30:13+00:00,https://github.com/apache/airflow/pull/45143,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2558402722, 'issue_id': 2754529567, 'author': 'gopidesupavan', 'body': 'Cool :) retries always helps..', 'created_at': datetime.datetime(2024, 12, 22, 10, 9, 15, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-12-22 10:09:15 UTC): Cool :) retries always helps..

"
2754523325,pull_request,closed,,Fix breeze output static checks failure,"The new click 8.1.8 makes the dictionary of options used to calculate hash of commands different for setup command. by bumping it to minimum 8.1.8 version we make the hash the same for both CI and locally installed breeze (click 8.1.8 change in pyproject.toml of breeze will force reinstallation of breeze for everyone locally).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-22 07:08:44+00:00,[],2024-12-22 11:41:34+00:00,2024-12-22 07:35:59+00:00,https://github.com/apache/airflow/pull/45142,"[('area:dev-tools', '')]","[{'comment_id': 2558403528, 'issue_id': 2754523325, 'author': 'gopidesupavan', 'body': 'oh nice good to know , due to the click version difference it produced different hashes :)', 'created_at': datetime.datetime(2024, 12, 22, 10, 12, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558408764, 'issue_id': 2754523325, 'author': 'potiuk', 'body': '> oh nice good to know , due to the click version difference it produced different hashes :)\r\n\r\nYeah. We are hashing dictionaries of command information that click produces, I think the difference is that we have a `""""` as default value and click 8.1.8 implemented a fix for that.\r\n\r\n```python\r\noption_chicken_egg_providers = click.option(\r\n    ""--chicken-egg-providers"",\r\n    default="""",\r\n    help=""List of chicken-egg provider packages - ""\r\n    ""those that have airflow_version >= current_version and should ""\r\n    ""be installed in CI from locally built packages with >= current_version.dev0 "",\r\n    envvar=""CHICKEN_EGG_PROVIDERS"",\r\n)\r\n```\r\n\r\nRelease notes: https://github.com/pallets/click/releases/tag/8.1.8\r\nIssue: https://github.com/pallets/click/issues/2500\r\nFix: https://github.com/pallets/click/pull/2724', 'created_at': datetime.datetime(2024, 12, 22, 10, 32, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558410202, 'issue_id': 2754523325, 'author': 'potiuk', 'body': 'Actually it is something else - because it was only setup :)... But .... It works, so no need to dig-in', 'created_at': datetime.datetime(2024, 12, 22, 10, 38, 31, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-12-22 10:12:28 UTC): oh nice good to know , due to the click version difference it produced different hashes :)

potiuk (Issue Creator) on (2024-12-22 10:32:30 UTC): Yeah. We are hashing dictionaries of command information that click produces, I think the difference is that we have a `""""` as default value and click 8.1.8 implemented a fix for that.

```python
option_chicken_egg_providers = click.option(
    ""--chicken-egg-providers"",
    default="""",
    help=""List of chicken-egg provider packages - ""
    ""those that have airflow_version >= current_version and should ""
    ""be installed in CI from locally built packages with >= current_version.dev0 "",
    envvar=""CHICKEN_EGG_PROVIDERS"",
)
```

Release notes: https://github.com/pallets/click/releases/tag/8.1.8
Issue: https://github.com/pallets/click/issues/2500
Fix: https://github.com/pallets/click/pull/2724

potiuk (Issue Creator) on (2024-12-22 10:38:31 UTC): Actually it is something else - because it was only setup :)... But .... It works, so no need to dig-in

"
2754374094,pull_request,closed,,Fix static checks in canary on 2024-12-21,"Static checks are complaining about breeze docs in https://github.com/apache/airflow/actions/runs/12447881419/job/34753093437

This PR fixes the static checks.",jscheffl,2024-12-21 21:42:14+00:00,[],2024-12-22 10:31:54+00:00,2024-12-22 10:31:49+00:00,https://github.com/apache/airflow/pull/45141,"[('area:dev-tools', '')]","[{'comment_id': 2558356563, 'issue_id': 2754374094, 'author': 'potiuk', 'body': 'Complete fix in #45142', 'created_at': datetime.datetime(2024, 12, 22, 7, 9, 33, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-22 07:09:33 UTC): Complete fix in #45142

"
2754348664,pull_request,closed,,Invalidate user session on password reset,"Session expire on pass change

The key difference is automatic transaction handling in the UI vs the manual control required in CLI operations. In the CLI, it does not automatically commit the session unless you explicitly tell it to, while the UI framework does this at the end of a successful request. So, session.commit() is added.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-21 20:22:31+00:00,[],2024-12-22 17:24:15+00:00,2024-12-22 17:24:15+00:00,https://github.com/apache/airflow/pull/45139,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2558237084, 'issue_id': 2754348664, 'author': 'potiuk', 'body': 'Just a static check failure :)', 'created_at': datetime.datetime(2024, 12, 21, 20, 48, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558450729, 'issue_id': 2754348664, 'author': 'potiuk', 'body': 'This is provider-only change - so we do not need to backport it.', 'created_at': datetime.datetime(2024, 12, 22, 13, 6, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558470388, 'issue_id': 2754348664, 'author': 'eladkal', 'body': '> This is provider-only change - so we do not need to backport it.\r\n\r\nNot so simple. It was decided that fab provider next release is breaking change and compatible with Airflow 3 only.\r\nhttps://github.com/eladkal/airflow/blob/c8c5756530b95de7f53b1f4cfc296d04627c7b25/providers/src/airflow/providers/fab/provider.yaml#L53\r\n\r\nto release this change to fab provider that is compatible with Airflow 2.9 we need to create a branch from fab tag 1.5.1 and follow on:\r\nhttps://github.com/apache/airflow/blob/main/PROVIDERS.rst#mixed-governance-model-for-3rd-party-related-community-providers', 'created_at': datetime.datetime(2024, 12, 22, 14, 13, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558487523, 'issue_id': 2754348664, 'author': 'potiuk', 'body': '> > This is provider-only change - so we do not need to backport it.\r\n> \r\n> Not so simple. It was decided that fab provider next release is breaking change and compatible with Airflow 3 only. https://github.com/eladkal/airflow/blob/c8c5756530b95de7f53b1f4cfc296d04627c7b25/providers/src/airflow/providers/fab/provider.yaml#L53\r\n> \r\n> to release this change to fab provider that is compatible with Airflow 2.9 we need to create a branch from fab tag 1.5.1 and follow on: https://github.com/apache/airflow/blob/main/PROVIDERS.rst#mixed-governance-model-for-3rd-party-related-community-providers\r\n\r\nIndeed. First time!. So wiil simply need to create a branch from FAB and use cherry-picker to cherry-pick it there after merging. Probably manual `cherry_picker` command. I can do it once this one is merged.', 'created_at': datetime.datetime(2024, 12, 22, 15, 10, 49, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-21 20:48:14 UTC): Just a static check failure :)

potiuk on (2024-12-22 13:06:58 UTC): This is provider-only change - so we do not need to backport it.

eladkal on (2024-12-22 14:13:53 UTC): Not so simple. It was decided that fab provider next release is breaking change and compatible with Airflow 3 only.
https://github.com/eladkal/airflow/blob/c8c5756530b95de7f53b1f4cfc296d04627c7b25/providers/src/airflow/providers/fab/provider.yaml#L53

to release this change to fab provider that is compatible with Airflow 2.9 we need to create a branch from fab tag 1.5.1 and follow on:
https://github.com/apache/airflow/blob/main/PROVIDERS.rst#mixed-governance-model-for-3rd-party-related-community-providers

potiuk on (2024-12-22 15:10:49 UTC): Indeed. First time!. So wiil simply need to create a branch from FAB and use cherry-picker to cherry-pick it there after merging. Probably manual `cherry_picker` command. I can do it once this one is merged.

"
2754288338,pull_request,closed,,[v2-10-test] Allow fetching XCom with forward slash from the API and escape it in the UI (#45134),"(cherry picked from commit 9316ed6df85234ba7f36437152329d9b1a27424d)

Co-authored-by: Shahar Epstein <60007259+shahar1@users.noreply.github.com>",github-actions[bot],2024-12-21 17:42:03+00:00,[],2025-01-28 12:10:17+00:00,2024-12-21 18:10:06+00:00,https://github.com/apache/airflow/pull/45137,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2754226945,pull_request,closed,,typo: Update mixins.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


typo
<!-- Please keep an empty line above the dashes. -->
---
",WrRan,2024-12-21 16:42:24+00:00,[],2025-01-05 05:09:04+00:00,2025-01-05 05:09:04+00:00,https://github.com/apache/airflow/pull/45136,"[('area:task-sdk', None)]","[{'comment_id': 2571504028, 'issue_id': 2754226945, 'author': 'WrRan', 'body': 'no one review. it goes to close.', 'created_at': datetime.datetime(2025, 1, 5, 5, 9, 4, tzinfo=datetime.timezone.utc)}]","WrRan (Issue Creator) on (2025-01-05 05:09:04 UTC): no one review. it goes to close.

"
2754197284,pull_request,closed,,Allow fetching XCom with forward slash from the API and escape it in the UI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #41598


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-21 16:14:19+00:00,[],2025-01-28 12:10:02+00:00,2024-12-21 17:41:17+00:00,https://github.com/apache/airflow/pull/45134,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2558184162, 'issue_id': 2754197284, 'author': 'potiuk', 'body': ""> Backport to v2-10-test as well?\r\n\r\nIt's already marked to be backported :)"", 'created_at': datetime.datetime(2024, 12, 21, 17, 40, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558184289, 'issue_id': 2754197284, 'author': 'potiuk', 'body': '(but yes milestone was missing).', 'created_at': datetime.datetime(2024, 12, 21, 17, 41, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558184552, 'issue_id': 2754197284, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45137""><img src=""https://img.shields.io/badge/PR-45137-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 21, 17, 42, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-21 17:40:40 UTC): It's already marked to be backported :)

potiuk on (2024-12-21 17:41:06 UTC): (but yes milestone was missing).

github-actions[bot] on (2024-12-21 17:42:05 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45137""><img src=""https://img.shields.io/badge/PR-45137-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2754130753,pull_request,closed,,Update contributors quick start guide,"This PR focuses on updating and formatting the contributors quick start guide.

As a new experimenting contributor, I had some troubles when I worked with the quick start guide, some commands that didn't work because of outdated packages, some instructions were unclear etc.

Addressing major changes I did:
1. Moving down the installation of the `docker compose plugin`: If we already have a section that is dedicated to the installation of docker compose, then commands that are relevant to its installation should be there, and not in a section that is dedicated to the installation of purely docker.
2. Sqlite -> sqlite3: according to the [Ubuntu package repository](https://packages.ubuntu.com/search?keywords=sqlite), the package `sqlite` is available only on `focal` and `jammy` Ubuntu distribution codenames. This means that the command `sudo apt install sqlite` will not work with any distributions beyond other than these two (like oracular, noble etc.). As I see it, these are the options:
a. Move to `sqlite3`. This would require performing tests, which I have - ran all the tests under the ./tests directory, which is probably not sufficient.
b. Add a note excluding distributions other than focal and jammy to use sqlite3 instead. This means developing on machines with distributions other than these may lead to inconsistencies as a result of breaking changes between the versions unless compatibility checks are done. 
This is very likely larger than my PR, and the best course of action for now is probably to delay this change until a decision is made, I made the changes only to raise awareness.
3. Removing section describing pre-commit with uv (lines 466-479): this content was just duplicated with the few lines below it. There are more examples of this behavior, but they are less aggressive so I decided to leave them be.

The other changes I made are mostly cosmetic.",IlaiGigi,2024-12-21 15:10:33+00:00,[],2024-12-24 13:46:00+00:00,2024-12-24 13:43:56+00:00,https://github.com/apache/airflow/pull/45133,"[('area:dev-tools', '')]","[{'comment_id': 2558147491, 'issue_id': 2754130753, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 21, 15, 10, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559797210, 'issue_id': 2754130753, 'author': 'potiuk', 'body': ""Very nice!  Thanks @IlaiGigi !\r\n\r\nBTW. Sqlite -> sqlite3 is not a problem (and we should change it to sqlite3 as you did). Sqlite3 was what we've always been using and `sqlite1 is just old name of the package installed, but I believe it was still sqlite3 even if it was named `sqlite`"", 'created_at': datetime.datetime(2024, 12, 23, 14, 21, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561145521, 'issue_id': 2754130753, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 24, 13, 43, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561145771, 'issue_id': 2754130753, 'author': 'potiuk', 'body': 'Ho Ho Ho ! Nice present for contributors ðŸŽ…', 'created_at': datetime.datetime(2024, 12, 24, 13, 44, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561147418, 'issue_id': 2754130753, 'author': 'IlaiGigi', 'body': 'Thank you, I also plan to do the same for the other contributing docs when I find the time. :santa:', 'created_at': datetime.datetime(2024, 12, 24, 13, 45, 59, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-21 15:10:38 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-23 14:21:59 UTC): Very nice!  Thanks @IlaiGigi !

BTW. Sqlite -> sqlite3 is not a problem (and we should change it to sqlite3 as you did). Sqlite3 was what we've always been using and `sqlite1 is just old name of the package installed, but I believe it was still sqlite3 even if it was named `sqlite`

boring-cyborg[bot] on (2024-12-24 13:43:58 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-12-24 13:44:16 UTC): Ho Ho Ho ! Nice present for contributors ðŸŽ…

IlaiGigi (Issue Creator) on (2024-12-24 13:45:59 UTC): Thank you, I also plan to do the same for the other contributing docs when I find the time. :santa:

"
2753878311,pull_request,closed,,Refactor Broken cli_parser Unit Tests,"Description:
<!-- Please keep an empty line above the dashes. -->
---
In the current version, the `COMMAND` definitions related to the CLI have been moved to `cli_config`. This change caused the existing unit tests for `cli_parser` to become outdated and ineffective.

This PR addresses the issue by updating and refactoring the affected unit tests to align with the new cli_config structure, ensuring proper functionality and coverage.",WrRan,2024-12-21 10:20:03+00:00,[],2025-01-05 05:08:47+00:00,2025-01-05 05:08:46+00:00,https://github.com/apache/airflow/pull/45132,"[('area:CLI', '')]","[{'comment_id': 2571503977, 'issue_id': 2753878311, 'author': 'WrRan', 'body': 'no one review. it goes to close.', 'created_at': datetime.datetime(2025, 1, 5, 5, 8, 46, tzinfo=datetime.timezone.utc)}]","WrRan (Issue Creator) on (2025-01-05 05:08:46 UTC): no one review. it goes to close.

"
2753838727,pull_request,closed,,Fix selective tests checks when system tests are modified,"When providers system tests were modified in provider tests were modified, selective checks had two bugs that compounded led to provider tests being skipped.

1) Modification of system tests lead to ""all providers affected""
   condition (wrongly) - because ""TESTS"" were checked as root path
   before ""SYSTEM TESTS"" - and since system tests were subfolder
   of tests, the code that checked if system tests path belongs
   to provider never found it.

2) ""All Providers affected"" in such case (when it was not caused by
   another condition lead to ""skip-provider-tests"" set to true due
   to missing ""else"" in one of the conditions.

This PR fixes both cases and simplifies the conditions so that they are easier to understand and modify. Those conditions will be further simplified when we separate providers to separate projects #44511 because there we will not have to check separately several sub-folders of airflow, but for now it's good enough.

Some of those conditions are simplified as well because we are in Python 3.9+ and ""is_relative_to"" is now available in Path.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-21 08:16:21+00:00,[],2024-12-21 15:09:38+00:00,2024-12-21 15:09:36+00:00,https://github.com/apache/airflow/pull/45131,"[('area:dev-tools', '')]","[{'comment_id': 2558061822, 'issue_id': 2753838727, 'author': 'potiuk', 'body': '> It seems there are might be some pr\'s until now went out without providers tests. and good thing we have schedule run to spot out these like the one recent :)\r\n\r\nWell. I think it was quite rare - It\'s only when system tests were modified and NO provider.yaml was modified - that would trigger another path I think, and this is a rare case where system tests are modified together with regular tests and code. When you add new classes with system tests you also usually modify the provider.yaml to add those hooks/operators you added.\r\n\r\nBut yes. ""canary"" builds are necessary and they are running all tests by-design to catch such cases. That was an important and deliberate design decision.', 'created_at': datetime.datetime(2024, 12, 21, 9, 23, 32, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-21 09:23:32 UTC): Well. I think it was quite rare - It's only when system tests were modified and NO provider.yaml was modified - that would trigger another path I think, and this is a rare case where system tests are modified together with regular tests and code. When you add new classes with system tests you also usually modify the provider.yaml to add those hooks/operators you added.

But yes. ""canary"" builds are necessary and they are running all tests by-design to catch such cases. That was an important and deliberate design decision.

"
2753820992,pull_request,open,,add jsonschema,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

WIP #42850 ",dannyl1u,2024-12-21 07:23:04+00:00,[],2025-02-06 00:15:22+00:00,,https://github.com/apache/airflow/pull/45130,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2638320894, 'issue_id': 2753820992, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 6, 0, 15, 21, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-02-06 00:15:21 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2753812292,pull_request,open,,[Resolve OOM When Reading Large Logs in Webserver] Refactor to Use K-Way Merge for Log Streams Instead of Sorting Entire Log Records,"
related: #45079 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-21 06:58:14+00:00,[],2025-02-08 12:08:01+00:00,,https://github.com/apache/airflow/pull/45129,"[('area:logging', ''), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2558049857, 'issue_id': 2753812292, 'author': 'potiuk', 'body': 'Rebased after we fixed main issue', 'created_at': datetime.datetime(2024, 12, 21, 8, 32, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559653452, 'issue_id': 2753812292, 'author': 'jason810496', 'body': ""CI is failing due to: `Please ask the maintainer to assign the 'legacy api' label to the PR in order to continue.`  \r\n\r\nSince the `get_log` endpoint in both the legacy API and FastAPI uses the `read_log_chunks` method, itâ€™s necessary to fix the endpoints and their corresponding tests."", 'created_at': datetime.datetime(2024, 12, 23, 12, 51, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559677285, 'issue_id': 2753812292, 'author': 'potiuk', 'body': 'Applied and closed/reopened to trigger the build', 'created_at': datetime.datetime(2024, 12, 23, 13, 6, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561601807, 'issue_id': 2753812292, 'author': 'jason810496', 'body': 'Fix the provider tests that explicitly use the `read` or `_read` methods.', 'created_at': datetime.datetime(2024, 12, 25, 4, 29, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562218329, 'issue_id': 2753812292, 'author': 'jason810496', 'body': ""Finally fixed the tests!  \r\n\r\nThis is the first (and likely the largest) PR for resolving OOM issues when reading large logs in the webserver.\r\nFurther PRs will only focus on refactoring each provider, as listed in the TODO tasks in #45079.  \r\n\r\nEven though the providers haven't yet been refactored to support stream-based log reading, the compatibility utility will transform the old `read` log method (which returns the entire list of logs) into a stream-based approach. Once all providers are refactored to use stream-based reading, the compatibility utility can be removed.  \r\n\r\nFor the testing part:  \r\nSince the CI will run provider compatibility tests for versions 2.9.3 and 2.10.3, my approach is to copy the old test cases related to log reading into new stream-based tests. Iâ€™ve added the `mark_test_for_old_read_log_method` and `mark_test_for_stream_based_read_log_method` pytest decorators to selectively skip the corresponding test runs.\r\nFrom my perspective, this approach is simpler and minimizes changes to the original test logic. Additionally, tests marked with `mark_test_for_old_read_log_method` can be safely removed once all providers migrate to stream-based reading."", 'created_at': datetime.datetime(2024, 12, 26, 6, 43, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567061787, 'issue_id': 2753812292, 'author': 'jason810496', 'body': 'Rebase to latest main, wait for review.', 'created_at': datetime.datetime(2025, 1, 1, 16, 2, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567711760, 'issue_id': 2753812292, 'author': 'potiuk', 'body': '@jason810496  I rebased it  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 36, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571537145, 'issue_id': 2753812292, 'author': 'jason810496', 'body': ""Hi @dstandish,  \r\n\r\nHope you're doing well, and Happy New Year! Would you mind taking a look at this PR when you have a moment? Thanks!"", 'created_at': datetime.datetime(2025, 1, 5, 7, 55, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2586837129, 'issue_id': 2753812292, 'author': 'jason810496', 'body': 'Just rebase to latest main, nothing update.', 'created_at': datetime.datetime(2025, 1, 13, 11, 20, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614106600, 'issue_id': 2753812292, 'author': 'potiuk', 'body': '@dstandish @ashb - can we merge it ? That one seems like a good cnadidate for 2.10.5 ?', 'created_at': datetime.datetime(2025, 1, 25, 21, 32, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614106757, 'issue_id': 2753812292, 'author': 'potiuk', 'body': 'It only really waits for your review/approval and it solves real issue.', 'created_at': datetime.datetime(2025, 1, 25, 21, 33, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2645266948, 'issue_id': 2753812292, 'author': 'jason810496', 'body': 'Hi @potiuk, may I ask whether this PR is considered a refactor for 3.0 or 2.10? I saw the 3.0 feature freeze mentioned in the dev list, so Iâ€™m not sure which version this PR will be counted for.\r\n\r\nHere is the related discussion on Slack: https://apache-airflow.slack.com/archives/CCZRF2U5A/p1736767159693839', 'created_at': datetime.datetime(2025, 2, 8, 12, 8, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-21 08:32:27 UTC): Rebased after we fixed main issue

jason810496 (Issue Creator) on (2024-12-23 12:51:26 UTC): CI is failing due to: `Please ask the maintainer to assign the 'legacy api' label to the PR in order to continue.`  

Since the `get_log` endpoint in both the legacy API and FastAPI uses the `read_log_chunks` method, itâ€™s necessary to fix the endpoints and their corresponding tests.

potiuk on (2024-12-23 13:06:50 UTC): Applied and closed/reopened to trigger the build

jason810496 (Issue Creator) on (2024-12-25 04:29:48 UTC): Fix the provider tests that explicitly use the `read` or `_read` methods.

jason810496 (Issue Creator) on (2024-12-26 06:43:54 UTC): Finally fixed the tests!  

This is the first (and likely the largest) PR for resolving OOM issues when reading large logs in the webserver.
Further PRs will only focus on refactoring each provider, as listed in the TODO tasks in #45079.  

Even though the providers haven't yet been refactored to support stream-based log reading, the compatibility utility will transform the old `read` log method (which returns the entire list of logs) into a stream-based approach. Once all providers are refactored to use stream-based reading, the compatibility utility can be removed.  

For the testing part:  
Since the CI will run provider compatibility tests for versions 2.9.3 and 2.10.3, my approach is to copy the old test cases related to log reading into new stream-based tests. Iâ€™ve added the `mark_test_for_old_read_log_method` and `mark_test_for_stream_based_read_log_method` pytest decorators to selectively skip the corresponding test runs.
From my perspective, this approach is simpler and minimizes changes to the original test logic. Additionally, tests marked with `mark_test_for_old_read_log_method` can be safely removed once all providers migrate to stream-based reading.

jason810496 (Issue Creator) on (2025-01-01 16:02:52 UTC): Rebase to latest main, wait for review.

potiuk on (2025-01-02 12:36:12 UTC): @jason810496  I rebased it  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

jason810496 (Issue Creator) on (2025-01-05 07:55:51 UTC): Hi @dstandish,  

Hope you're doing well, and Happy New Year! Would you mind taking a look at this PR when you have a moment? Thanks!

jason810496 (Issue Creator) on (2025-01-13 11:20:24 UTC): Just rebase to latest main, nothing update.

potiuk on (2025-01-25 21:32:49 UTC): @dstandish @ashb - can we merge it ? That one seems like a good cnadidate for 2.10.5 ?

potiuk on (2025-01-25 21:33:37 UTC): It only really waits for your review/approval and it solves real issue.

jason810496 (Issue Creator) on (2025-02-08 12:08:00 UTC): Hi @potiuk, may I ask whether this PR is considered a refactor for 3.0 or 2.10? I saw the 3.0 feature freeze mentioned in the dev list, so Iâ€™m not sure which version this PR will be counted for.

Here is the related discussion on Slack: https://apache-airflow.slack.com/archives/CCZRF2U5A/p1736767159693839

"
2753787681,pull_request,closed,,"Ignore deprecations in gcp automl, translate","https://github.com/apache/airflow/actions/runs/12441141635/job/34737776458

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-21 06:03:11+00:00,[],2024-12-21 16:00:43+00:00,2024-12-21 07:09:55+00:00,https://github.com/apache/airflow/pull/45128,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2558015411, 'issue_id': 2753787681, 'author': 'gopidesupavan', 'body': 'Do we really need to ignore these deprecations? or we should remove those deprecated classes? it looks like they have date mentioned target around sept 2025.', 'created_at': datetime.datetime(2024, 12, 21, 6, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558030449, 'issue_id': 2753787681, 'author': 'potiuk', 'body': ""It's ok - it's September 2025 - so they are fine. My question is more why in the original PR the tests did not fail. I am looking into it."", 'created_at': datetime.datetime(2024, 12, 21, 7, 10, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558032686, 'issue_id': 2753787681, 'author': 'gopidesupavan', 'body': ""> It's ok - it's September 2025 - so they are fine. My question is more why in the original PR the tests did not fail. I am looking into it.\r\n\r\nah i see it looks like providers tests not triggered in original pr https://github.com/apache/airflow/actions/runs/12431426634/job/34709142003"", 'created_at': datetime.datetime(2024, 12, 21, 7, 19, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558039291, 'issue_id': 2753787681, 'author': 'gopidesupavan', 'body': 'looks like selective checks ignoring some of the file checks conditions. trying to look more..', 'created_at': datetime.datetime(2024, 12, 21, 7, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558046363, 'issue_id': 2753787681, 'author': 'potiuk', 'body': 'Fix here #45131', 'created_at': datetime.datetime(2024, 12, 21, 8, 17, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558046771, 'issue_id': 2753787681, 'author': 'potiuk', 'body': ""It was a very subtle combination of two bugs - and it's mostly a by-product of having several different folders where provider files come from. Will be simplified in the future when we implement [#44511](https://github.com/apache/airflow/issues/44511) (I am working on it already - first PRs are coming shortly on that one)."", 'created_at': datetime.datetime(2024, 12, 21, 8, 19, 10, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-12-21 06:07:00 UTC): Do we really need to ignore these deprecations? or we should remove those deprecated classes? it looks like they have date mentioned target around sept 2025.

potiuk on (2024-12-21 07:10:36 UTC): It's ok - it's September 2025 - so they are fine. My question is more why in the original PR the tests did not fail. I am looking into it.

gopidesupavan (Issue Creator) on (2024-12-21 07:19:48 UTC): ah i see it looks like providers tests not triggered in original pr https://github.com/apache/airflow/actions/runs/12431426634/job/34709142003

gopidesupavan (Issue Creator) on (2024-12-21 07:48:50 UTC): looks like selective checks ignoring some of the file checks conditions. trying to look more..

potiuk on (2024-12-21 08:17:24 UTC): Fix here #45131

potiuk on (2024-12-21 08:19:10 UTC): It was a very subtle combination of two bugs - and it's mostly a by-product of having several different folders where provider files come from. Will be simplified in the future when we implement [#44511](https://github.com/apache/airflow/issues/44511) (I am working on it already - first PRs are coming shortly on that one).

"
2753639062,pull_request,closed,,Fix incorrect CHANGELOG.rst update,"Regarding the discussion on
https://github.com/apache/airflow/pull/45084.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-12-20 23:44:45+00:00,[],2024-12-21 07:45:26+00:00,2024-12-21 07:45:26+00:00,https://github.com/apache/airflow/pull/45127,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2558038485, 'issue_id': 2753639062, 'author': 'eladkal', 'body': 'I fixed the records during release so no need to change anything', 'created_at': datetime.datetime(2024, 12, 21, 7, 45, 24, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-12-21 07:45:24 UTC): I fixed the records during release so no need to change anything

"
2753538092,pull_request,closed,,Add view_url for DagBundles,"This PR adds view_url to Dagbundles to enable viewing the bundle's version

",ephraimbuddy,2024-12-20 22:01:17+00:00,['ephraimbuddy'],2025-01-08 18:50:28+00:00,2025-01-08 18:50:26+00:00,https://github.com/apache/airflow/pull/45126,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2753533089,pull_request,closed,,Refactor Azure Service Bus: move create_subscription to hook,"This commit refactors the logic to create a subscription into the hook. The operators should not be accessing the connection to Azure Service Bus directly. This code belongs in the hook to promote reuse.

In addition, it allows the caller to pass a RuleFilter to apply to the subscription to limit which messages are sent to the subscription.

@dabla: this addresses part of your comments on PR 44675",perry2of5,2024-12-20 21:55:50+00:00,[],2024-12-30 17:46:29+00:00,2024-12-21 14:27:25+00:00,https://github.com/apache/airflow/pull/45125,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2557944744, 'issue_id': 2753533089, 'author': 'perry2of5', 'body': 'The build failure appears unrelated to my re-wording of the comment :)', 'created_at': datetime.datetime(2024, 12, 21, 1, 46, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558048582, 'issue_id': 2753533089, 'author': 'potiuk', 'body': 'Yeah. Fixed in main (including #45131 fixing selective checks that caused broken main). Rebased it now.', 'created_at': datetime.datetime(2024, 12, 21, 8, 27, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558323963, 'issue_id': 2753533089, 'author': 'perry2of5', 'body': 'Thank you to both of you!', 'created_at': datetime.datetime(2024, 12, 22, 4, 12, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558363785, 'issue_id': 2753533089, 'author': 'dabla', 'body': '> Thank you to both of you!\r\n\r\nNicely done, good work!', 'created_at': datetime.datetime(2024, 12, 22, 7, 42, 5, tzinfo=datetime.timezone.utc)}]","perry2of5 (Issue Creator) on (2024-12-21 01:46:25 UTC): The build failure appears unrelated to my re-wording of the comment :)

potiuk on (2024-12-21 08:27:04 UTC): Yeah. Fixed in main (including #45131 fixing selective checks that caused broken main). Rebased it now.

perry2of5 (Issue Creator) on (2024-12-22 04:12:16 UTC): Thank you to both of you!

dabla on (2024-12-22 07:42:05 UTC): Nicely done, good work!

"
2753452786,pull_request,open,,skip setproctitle in `task_runner` on Mac OS,"On some newer versions of Mac OS setproctitle can cause segfault https://github.com/benoitc/gunicorn/issues/3021

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jaketf,2024-12-20 20:37:40+00:00,[],2025-01-08 10:18:39+00:00,,https://github.com/apache/airflow/pull/45124,"[('area:task-sdk', None)]",[],
2753442949,pull_request,closed,,Allow Dynamic Tasks to be Searchable Using map_index_template (#45109),"Automated backport of #45109 failed, so here a manual PR for backport...",jscheffl,2024-12-20 20:28:46+00:00,[],2025-01-28 12:12:57+00:00,2024-12-20 20:50:59+00:00,https://github.com/apache/airflow/pull/45122,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:dynamic-task-mapping', 'AIP-42')]",[],
2753420596,pull_request,closed,,Add HTTP retry handling into task SDK api.client,"closes: #44355

Add HTTP retry handling to Task SDK.",jscheffl,2024-12-20 20:10:17+00:00,[],2024-12-27 22:51:46+00:00,2024-12-27 22:51:46+00:00,https://github.com/apache/airflow/pull/45121,"[('area:task-sdk', None)]","[{'comment_id': 2564077103, 'issue_id': 2753420596, 'author': 'jscheffl', 'body': 'Merging as (still) no response from Kaxil/Ash... let me know ""post mortem"" if some polishing is needed.', 'created_at': datetime.datetime(2024, 12, 27, 22, 51, 41, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-27 22:51:41 UTC): Merging as (still) no response from Kaxil/Ash... let me know ""post mortem"" if some polishing is needed.

"
2753307978,pull_request,closed,,[v2-10-test] Evaluate none in extended json type decorator,"backports: #45119

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-20 18:59:22+00:00,[],2025-01-28 12:10:59+00:00,2024-12-20 21:15:57+00:00,https://github.com/apache/airflow/pull/45120,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2753295518,pull_request,closed,,Evaluate None in SQLAlchemy's extended JSON type decorator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #22245

As of today, at least in mapped operators for `map_index > 0`, the `next_kwargs` column is saved as the string `null` in the DB, instead of a real `<null>`. That is unlike mapped operators with indeces `-1` or `0`, as well as unmapped operators.
As far as I'm concerned, this inconsistency doesn't affect any logic that depends on it, since it is still deserialized as Python's `None` - but it will be nice to save a few bytes and ensure consistency.
While I haven't figured out *why* it happens only in that case - I've found that applying the flag `should_evaluate_none = True` seems to solve it. I didn't find a proper way to test it, since it is always deserialized as Python's `None`.

Mapped operators are yet to be implemented in the `main` with the new task sdk, but if tests won't indicate that it breaks anything - I think that it will be ok to merge.



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-20 18:53:21+00:00,[],2025-01-28 12:10:52+00:00,2024-12-21 17:38:23+00:00,https://github.com/apache/airflow/pull/45119,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2558165903, 'issue_id': 2753295518, 'author': 'shahar1', 'body': '@potiuk are we ok with merging this PR on `main`? \r\nYou approved and merged the backport, just wondered if you just missed this one or is it on purpose :)', 'created_at': datetime.datetime(2024, 12, 21, 16, 24, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558183614, 'issue_id': 2753295518, 'author': 'potiuk', 'body': 'Ups', 'created_at': datetime.datetime(2024, 12, 21, 17, 38, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558183684, 'issue_id': 2753295518, 'author': 'potiuk', 'body': 'Thanks ðŸ˜“ .... Not sure how I missed it :)', 'created_at': datetime.datetime(2024, 12, 21, 17, 38, 46, tzinfo=datetime.timezone.utc)}]","shahar1 (Issue Creator) on (2024-12-21 16:24:33 UTC): @potiuk are we ok with merging this PR on `main`? 
You approved and merged the backport, just wondered if you just missed this one or is it on purpose :)

potiuk on (2024-12-21 17:38:28 UTC): Ups

potiuk on (2024-12-21 17:38:46 UTC): Thanks ðŸ˜“ .... Not sure how I missed it :)

"
2753128325,pull_request,closed,,Bump openlineage-airflow from 1.25.0 to 1.26.0,"Bumps openlineage-airflow from 1.25.0 to 1.26.0.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=openlineage-airflow&package-manager=pip&previous-version=1.25.0&new-version=1.26.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-12-20 17:06:50+00:00,[],2024-12-20 21:16:43+00:00,2024-12-20 21:16:35+00:00,https://github.com/apache/airflow/pull/45118,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2752971500,pull_request,closed,,Update task try selector dropdown,"Reverse order of options in the Task Try selector so that the latest try is always at the top. Also, add the state in text and not just a colored circle.

<img width=""300"" alt=""Screenshot 2024-12-20 at 10 32 47â€¯AM"" src=""https://github.com/user-attachments/assets/197defe9-f5be-4162-a369-1f70455db09a"" />

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-20 15:35:04+00:00,[],2024-12-20 15:50:11+00:00,2024-12-20 15:50:09+00:00,https://github.com/apache/airflow/pull/45117,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2752883762,pull_request,closed,,[v2-10-test] Update cli_config.py (#45110),"(cherry picked from commit b7e81f56aa5dd029fbb1a3ef6962bdca56b7c9d0)

Co-authored-by: Wang Ran (æ±ªç„¶) <wangr@smail.nju.edu.cn>",github-actions[bot],2024-12-20 14:45:27+00:00,[],2025-01-28 12:13:25+00:00,2024-12-20 20:42:03+00:00,https://github.com/apache/airflow/pull/45115,"[('area:CLI', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2752688563,pull_request,closed,,AIP-72: Fix recursion bug with `XComArg`,"It fixes the following bug

```python
{""timestamp"":""2024-12-20T10:38:56.890735"",""logger"":""task"",""error_detail"":
[{""exc_type"":""RecursionError"",""exc_value"":""maximum recursion depth exceeded in comparison"",""syntax_error"":null,""is_cause"":false,""frames"":
[
	{""filename"":""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py"",""lineno"":382,""name"":""main""},
	{""filename"":""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py"",""lineno"":317,""name"":""run""},
	{""filename"":""/opt/airflow/airflow/models/baseoperator.py"",""lineno"":378,""name"":""wrapper""},
	{""filename"":""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"",""lineno"":182,""name"":""execute""},
	{""filename"":""/opt/airflow/task_sdk/src/airflow/sdk/definitions/baseoperator.py"",""lineno"":660,""name"":""__setattr__""},
	{""filename"":""/opt/airflow/task_sdk/src/airflow/sdk/definitions/baseoperator.py"",""lineno"":1126,""name"":""_set_xcomargs_dependency""},
	{""filename"":""/opt/airflow/airflow/models/xcom_arg.py"",""lineno"":132,""name"":""apply_upstream_relationship""},
	{""filename"":""/opt/airflow/airflow/models/xcom_arg.py"",""lineno"":118,""name"":""iter_xcom_references""},
	{""filename"":""/opt/airflow/airflow/models/xcom_arg.py"",""lineno"":121,""name"":""iter_xcom_references""},
	{""filename"":""/opt/airflow/airflow/models/xcom_arg.py"",""lineno"":118,""name"":""iter_xcom_references""},
	...
```

To reproduce just run `tutorial_dag` or the following minimal dag:

```python
import pendulum

from airflow.models.dag import DAG
from airflow.providers.standard.operators.python import PythonOperator

with DAG(
    ""sdk_tutorial_dag"",
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),
    catchup=False,
    tags=[""example""],
) as dag:
    dag.doc_md = __doc__

    def extract(**kwargs):
        ti = kwargs[""ti""]
        data_string = '{""1001"": 301.27, ""1002"": 433.21, ""1003"": 502.22}'
        ti.xcom_push(""order_data"", data_string)

    extract_task = PythonOperator(
        task_id=""extract"",
        python_callable=extract,
    )

    extract_task
```

I need this fix for https://github.com/apache/airflow/pull/45075 (part of the getting [Task Context working with AIP-72](https://github.com/apache/airflow/issues/44481))

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-20 12:55:36+00:00,[],2024-12-20 15:54:50+00:00,2024-12-20 15:54:48+00:00,https://github.com/apache/airflow/pull/45112,"[('area:task-sdk', None)]",[],
2752679190,pull_request,closed,,[typo] Update configuration.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

a typo",WrRan,2024-12-20 12:50:02+00:00,[],2024-12-21 08:31:58+00:00,2024-12-21 08:31:58+00:00,https://github.com/apache/airflow/pull/45111,[],[],
2752618322,pull_request,closed,,[typo] Update cli_config.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
just a typo.",WrRan,2024-12-20 12:13:22+00:00,[],2025-01-28 12:13:31+00:00,2024-12-20 14:44:37+00:00,https://github.com/apache/airflow/pull/45110,"[('area:CLI', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2556890199, 'issue_id': 2752618322, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 20, 12, 13, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557147070, 'issue_id': 2752618322, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 20, 14, 44, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557148454, 'issue_id': 2752618322, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45115""><img src=""https://img.shields.io/badge/PR-45115-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 20, 14, 45, 30, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-20 12:13:26 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-12-20 14:44:40 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

github-actions[bot] on (2024-12-20 14:45:30 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45115""><img src=""https://img.shields.io/badge/PR-45115-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2752588486,pull_request,closed,,Allow Dynamic Tasks to be Searchable Using map_index_template,"I know we should not add ""new features"" to the legacy UI - but just took a look and realized that this request is actually a single-line change. So I propose to ""just make it"". Also I see this quite useful in my daily life.

closes: #45100",jscheffl,2024-12-20 11:57:38+00:00,[],2025-01-28 12:12:51+00:00,2024-12-20 20:20:15+00:00,https://github.com/apache/airflow/pull/45109,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:dynamic-task-mapping', 'AIP-42'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2557667513, 'issue_id': 2752588486, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12437936005\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>âŒ</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/16e8a268753bd61c078f0a33f28e85496423975d""><img src=\'https://img.shields.io/badge/Commit-16e8a26-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 16e8a26 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 20, 20, 21, 6, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-20 20:21:06 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12437936005'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>âŒ</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/16e8a268753bd61c078f0a33f28e85496423975d""><img src='https://img.shields.io/badge/Commit-16e8a26-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 16e8a26 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2752501395,pull_request,closed,,AIP-72: Logging task runner messages in supervisor,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

I added this for more info for AF3 demo call, it is quite beneficial in the initial stages for debugging from the terminal.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-20 11:04:44+00:00,[],2024-12-20 14:27:39+00:00,2024-12-20 12:22:30+00:00,https://github.com/apache/airflow/pull/45108,"[('area:task-sdk', None)]",[],
2752423425,pull_request,closed,,AIP-72: Handling task retries in task SDK + execution API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44351

""Retries"" are majorly handled in airflow 2.x in here: https://github.com/apache/airflow/blob/main/airflow/models/taskinstance.py#L3082-L3101.

The idea here is that in case a task is retry able, defined by https://github.com/apache/airflow/blob/main/airflow/models/taskinstance.py#L1054-L1073, the task is marked as ""up_for_retry"". Rest of the part is taken care by the scheduler loop normally if the ti state is marked correctly.


Coming to task sdk, we cannot perform validations such as https://github.com/apache/airflow/blob/main/airflow/models/taskinstance.py#L1054-L1073 in the task runner / sdk side because we do not have/ should not have access to the database. 

![image (7)](https://github.com/user-attachments/assets/bc33ad10-5859-4fcd-a17d-7faba61463d2)

We can use the above state change diagram and handle the retry state while handling failed state. Instead of having API handler and states for ""up_for_retry"", we can handle it when we are handling failures - which we do by calling the https://github.com/apache/airflow/blob/main/airflow/api_fastapi/execution_api/routes/task_instances.py#L160-L212 API endpoint. If we can send in enough data to the api handler in the execution API, we should be able to handle the cases of retry well.

### What needs to be done for porting this to `task_sdk`?
1. Defining ""try_number"", ""max_retries"" for task instances ---> not needed because this is handled already in the scheduler side of things / parsing time and not at execution time, so we do not need to handle it. It is handled here https://github.com/apache/airflow/blob/main/airflow/models/dagrun.py#L1445-L1471 when a dag run is created and it is initialised with the initial values: max_tries(https://github.com/apache/airflow/blob/main/airflow/models/taskinstance.py#L1809) and try_number(https://github.com/apache/airflow/blob/main/airflow/models/taskinstance.py#L1808)

2. We need to have a mechanism that can send a signal from the task runner if retries are defined. We will send this in this fashion:
task runner informs the supervisor while failing that it needs to retry -> supervisor sends a normal request to the client (but with task_retries defined) -> client sends a normal API request (TITerminalStatePayload) to the execution API but with task_retries

3. At the execution API, we receive the request and perform a check to check if the Ti is eligible for retry, if it is, we mark it as ""up_for_retry"", the rest of things are taken care by the scheduler.

### Approach chosen

- We define a new state: `FAIL_WITHOUT_RETRY`, if the task runner sends a request that it wants to `FAIL_WITHOUT_RETRY`, we do not need to retry, this is done so that we prioritise retry over no retry. The cases where we should retry is far more than when we shouldn't. 
- `FAIL_WITHOUT_RETRY` is sent out for cases such as `AirflowFailException` or `AirflowSensorTimeout`.


#### Handling on task runner and execution side
1. The task is executed normally, and in cases when there is a failure, it is handled in this way:
For AirflowFailException, AirflowSensorTimeout, AirflowTaskTerminated, send FAIL_WITHOUT_RETRY
For any other case, send FAIL.

2. If `FAILED` state is sent, we attempt the retry.

#### Handling at execution API
1. For the case when we receive FAILED,
```
        elif ti_patch_payload.state == State.FAILED:
            if _is_eligible_to_retry(previous_state, try_number, max_tries):
                updated_state = State.UP_FOR_RETRY
            else:
                updated_state = State.FAILED
```

2. For case where we receive FAIL_WITHOUT_RETRY, just fail.



### Testing results
Right now the PR is meant to handle `BaseException` -- will extend to all other eligible TI exceptions in follow ups.


#### Scenario 1: With retries = 3 defined. 

DAG:
```
import sys
from time import sleep

from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from datetime import datetime, timedelta
from airflow.exceptions import AirflowTaskTimeout


def print_hello():
    1//0

with DAG(
    dag_id=""abcd"",
    schedule=None,
    catchup=False,
    tags=[""demo""],
) as dag:
    hello_task = PythonOperator(
        task_id=""say_hello"",
        python_callable=print_hello,
        retries=3
    )
```
Rightly marked as ""up_for_retry""
![image (3)](https://github.com/user-attachments/assets/a53ca5c1-4e86-421f-bcd4-80f41ed61816)

TI details with max_tries
![image (4)](https://github.com/user-attachments/assets/54f494b1-555d-438a-b5af-b3c203163bdb)

Try number in grid view
![image (5)](https://github.com/user-attachments/assets/fd47718d-3a56-45be-9cc9-d3fc4d595170)


#### Scenario 2: With retries not defined. 

DAG:
```
import sys
from time import sleep

from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from datetime import datetime, timedelta
from airflow.exceptions import AirflowTaskTimeout


def print_hello():
    1//0

with DAG(
    dag_id=""abcd"",
    schedule=None,
    catchup=False,
    tags=[""demo""],
) as dag:
    hello_task = PythonOperator(
        task_id=""say_hello"",
        python_callable=print_hello,
    )
```

Rightly marked as ""failed""
<img width=""1724"" alt=""image"" src=""https://github.com/user-attachments/assets/d5cce08c-39b1-499d-a87d-43d2cc2e074b"" />

Ti detiails with 0 max_tries:
<img width=""1724"" alt=""image"" src=""https://github.com/user-attachments/assets/9a862cc5-6310-4f33-a5cc-a0759bc72b1f"" />

Try number in grid view
<img width=""1724"" alt=""image"" src=""https://github.com/user-attachments/assets/6b0811d7-d01e-4bb4-92e4-98f679e6f935"" />

============

### Pending:

- [x] UT coverage for execution API for various scenarios
- [x] UT coverage for supervisor and task_runner, client
- [ ] Extending to various other scenarios when retry is needed -- eg: AirflowTaskTimeout / AirflowException


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-20 10:25:18+00:00,['amoghrajesh'],2025-02-06 12:58:32+00:00,2024-12-30 08:33:55+00:00,https://github.com/apache/airflow/pull/45106,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2556765024, 'issue_id': 2752423425, 'author': 'amoghrajesh', 'body': 'If we agree on the approach, I will work on the tests.', 'created_at': datetime.datetime(2024, 12, 20, 10, 55, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559301923, 'issue_id': 2752423425, 'author': 'amoghrajesh', 'body': 'It probably might also be a good idea to de couple the entire payload construction out of `TaskState`. We might need to handle future cases where ""fail"" ti state has specific attributes like `fail_stop` for example.\r\n\r\nSomewhat like: \r\n```\r\nclass TaskState(BaseModel):\r\n    """"""\r\n    Update a task\'s state.\r\n\r\n    If a process exits without sending one of these the state will be derived from the exit code:\r\n    - 0 = SUCCESS\r\n    - anything else = FAILED\r\n    """"""\r\n\r\n    state: TerminalTIState\r\n    end_date: datetime | None = None\r\n    type: Literal[""TaskState""] = ""TaskState""\r\n\r\nclass FailTask(BaseModel):\r\n    """"""\r\n    Update a task\'s state to failed. Inherits TaskState to be able to define attributes specific to\r\n    failure state.\r\n    """"""\r\n\r\n    state: TerminalTIState.FAILED\r\n    task_retries: int | None = None\r\n    fail_stop: bool = False\r\n    type: Literal[""FailTask""] = ""FailTask""\r\n```', 'created_at': datetime.datetime(2024, 12, 23, 9, 35, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563662725, 'issue_id': 2752423425, 'author': 'ashb', 'body': 'This still doesn\'t feel right to me @amoghrajesh -- I think ""should_fail"" as a property on the task state, and all the plumbing we need to set through the layers is a sign that the design isn\'t right yet.\r\n\r\nSpit-balling here, but what if we had a different state, so instead of sending `TerminalTIState.FAILED` we sent `TerminalTIState.FAIL_WITHOUT_RETRY` or something. By doing that it would mean we wouldn\'t need a new object process<->supervisor comms, nor `_fail_request_sent` as that would be handled by the existing terminal state mechanism', 'created_at': datetime.datetime(2024, 12, 27, 12, 37, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563848149, 'issue_id': 2752423425, 'author': 'amoghrajesh', 'body': '@ashb tested out with retries as 0, 3, None. Works as expected.\r\n<img width=""320"" alt=""image"" src=""https://github.com/user-attachments/assets/b5b78a53-6ad6-433f-b5bd-946fd657b74b"" />', 'created_at': datetime.datetime(2024, 12, 27, 16, 23, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2565170802, 'issue_id': 2752423425, 'author': 'amoghrajesh', 'body': 'Resolved all conversations. Merging this PR.', 'created_at': datetime.datetime(2024, 12, 30, 8, 33, 19, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-20 10:55:09 UTC): If we agree on the approach, I will work on the tests.

amoghrajesh (Issue Creator) on (2024-12-23 09:35:20 UTC): It probably might also be a good idea to de couple the entire payload construction out of `TaskState`. We might need to handle future cases where ""fail"" ti state has specific attributes like `fail_stop` for example.

Somewhat like: 
```
class TaskState(BaseModel):
    """"""
    Update a task's state.

    If a process exits without sending one of these the state will be derived from the exit code:
    - 0 = SUCCESS
    - anything else = FAILED
    """"""

    state: TerminalTIState
    end_date: datetime | None = None
    type: Literal[""TaskState""] = ""TaskState""

class FailTask(BaseModel):
    """"""
    Update a task's state to failed. Inherits TaskState to be able to define attributes specific to
    failure state.
    """"""

    state: TerminalTIState.FAILED
    task_retries: int | None = None
    fail_stop: bool = False
    type: Literal[""FailTask""] = ""FailTask""
```

ashb on (2024-12-27 12:37:28 UTC): This still doesn't feel right to me @amoghrajesh -- I think ""should_fail"" as a property on the task state, and all the plumbing we need to set through the layers is a sign that the design isn't right yet.

Spit-balling here, but what if we had a different state, so instead of sending `TerminalTIState.FAILED` we sent `TerminalTIState.FAIL_WITHOUT_RETRY` or something. By doing that it would mean we wouldn't need a new object process<->supervisor comms, nor `_fail_request_sent` as that would be handled by the existing terminal state mechanism

amoghrajesh (Issue Creator) on (2024-12-27 16:23:26 UTC): @ashb tested out with retries as 0, 3, None. Works as expected.
<img width=""320"" alt=""image"" src=""https://github.com/user-attachments/assets/b5b78a53-6ad6-433f-b5bd-946fd657b74b"" />

amoghrajesh (Issue Creator) on (2024-12-30 08:33:19 UTC): Resolved all conversations. Merging this PR.

"
2752235642,pull_request,closed,,Bump uv to 0.5.11,"https://github.com/astral-sh/uv/releases/tag/0.5.11

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-20 08:43:38+00:00,[],2024-12-29 18:05:34+00:00,2024-12-20 09:37:00+00:00,https://github.com/apache/airflow/pull/45105,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2564391515, 'issue_id': 2752235642, 'author': 'raphaelauv', 'body': 'the docker image of 2.10.4 is still using uv  0.4.29\r\n\r\ncould we backport this PR on 2.10.X ? thanks all', 'created_at': datetime.datetime(2024, 12, 28, 17, 59, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564529792, 'issue_id': 2752235642, 'author': 'potiuk', 'body': 'You can do it yourself. Maintainers don\'t do any backporting other than to latest version of latest released branch. And it\'s not blociking anyone to bump the UV version. Maybe you can just try to backpor it for 2.10.5 - there is no partucular need to wait for ""someone else"" to do it.', 'created_at': datetime.datetime(2024, 12, 28, 22, 49, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564784835, 'issue_id': 2752235642, 'author': 'raphaelauv', 'body': 'hello potiuk , thanks for the answser, my question was not explicit.\r\n\r\nabout `there is no partucular need to wait for ""someone else"" to do it.` \r\n\r\nI was aksing for guidance to apply the good process, cause I seen the doc https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#how-to-backport-pr-with-github-actions ( and many discussion on the slack `contributors` about backport ) and I\'m not a committer, so I don\'t know what to do.\r\n\r\nThanks', 'created_at': datetime.datetime(2024, 12, 29, 17, 9, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564801309, 'issue_id': 2752235642, 'author': 'potiuk', 'body': 'See https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#how-to-backport-pr-with-cherry-picker-cli \r\n\r\nFollowing this process you can cherry-pick and open PR regardless if you are committer or not.', 'created_at': datetime.datetime(2024, 12, 29, 18, 5, 33, tzinfo=datetime.timezone.utc)}]","raphaelauv on (2024-12-28 17:59:21 UTC): the docker image of 2.10.4 is still using uv  0.4.29

could we backport this PR on 2.10.X ? thanks all

potiuk on (2024-12-28 22:49:11 UTC): You can do it yourself. Maintainers don't do any backporting other than to latest version of latest released branch. And it's not blociking anyone to bump the UV version. Maybe you can just try to backpor it for 2.10.5 - there is no partucular need to wait for ""someone else"" to do it.

raphaelauv on (2024-12-29 17:09:44 UTC): hello potiuk , thanks for the answser, my question was not explicit.

about `there is no partucular need to wait for ""someone else"" to do it.` 

I was aksing for guidance to apply the good process, cause I seen the doc https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#how-to-backport-pr-with-github-actions ( and many discussion on the slack `contributors` about backport ) and I'm not a committer, so I don't know what to do.

Thanks

potiuk on (2024-12-29 18:05:33 UTC): See https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#how-to-backport-pr-with-cherry-picker-cli 

Following this process you can cherry-pick and open PR regardless if you are committer or not.

"
2752176898,pull_request,closed,,AIP-72: Add proper serialization for XCom and Variable responses,"Currently Xcom & Variables fail on main with following error:

```py
ValidationError: 1 validation error for
tagged-union[StartupDetails,XComResult,ConnectionResult,VariableResult,ErrorResponse]
  Unable to extract tag using discriminator 'type' [type=union_tag_not_found, input_value={'key':
'test_key', 'value': 'test_value'}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/union_tag_not_found
```

The entire stacktrace is:

```py
decoder.get_message()
task_sdk/src/airflow/sdk/execution_time/task_runner.py:177: in get_message
    msg = self.decoder.validate_json(line)
/usr/local/lib/python3.9/site-packages/pydantic/type_adapter.py:446: in validate_json
    return self.validator.validate_json(
E   pydantic_core._pydantic_core.ValidationError: 1 validation error for tagged-union[StartupDetails,XComResult,ConnectionResult,VariableResult,ErrorResponse]
E     Unable to extract tag using discriminator 'type' [type=union_tag_not_found, input_value={'key': 'test_key', 'value': 'test_value'}, input_type=dict]
E       For further information visit https://errors.pydantic.dev/2.10/v/union_tag_not_found
```

This commit addresses serialization bug for XCom and Variable responses. Specifically:

- Added `from_xcom_response` and `from_variable_response` class methods in XComResult and VariableResult, respectively, to convert autogenerated API responses into runtime-compatible result models.

- Updated the supervisorâ€™s `handle_requests` method to use these converters for `GetXCom` and `GetVariable` message handling.
- Adjusted tests in test_supervisor.py to verify the inclusion of the type field in serialized responses and ensure proper decoding using CommsDecoder.
- Improved test coverage by asserting that serialized responses match expected formats and verifying deserialization consistency.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-20 08:05:51+00:00,[],2024-12-20 09:35:48+00:00,2024-12-20 09:35:46+00:00,https://github.com/apache/airflow/pull/45104,"[('area:task-sdk', None)]",[],
2752096921,pull_request,closed,,Replacing gunicornmontor with uvicorn.run(),"
Related: https://github.com/apache/airflow/issues/43035


These are the stats comparing `uvicorn.run()` with` Gunicorn + GunicornMonitor`

<html><head></head><body>
<hr>
<h3><strong>Comparison: Uvicorn vs. Gunicorn Performance</strong></h3>
<h4><strong>Request Statistics</strong></h4>

Metric | Uvicorn | Gunicorn
-- | -- | --
Total Requests | 14,714 | 14,726
Total Failures | 0 | 13
Average Response Time | 12.05 ms | 13.46 ms
Min Response Time | 7 ms | 1 ms
Max Response Time | 195 ms | 216 ms
Average Size (bytes) | 4,608 | 4,603.93
Requests Per Second (RPS) | 49.05 | 49.09
Failures Per Second | 0 | 0.04


<hr>
<h3><strong>Observations</strong></h3>
<ol>
<li>
<p><strong>Response Times</strong>:</p>
<ul>
<li>Uvicorn demonstrates slightly lower average and maximum response times compared to Gunicorn.</li>
<li>Percentile analysis shows Uvicorn's response times are more consistent, with fewer extreme values at higher percentiles.</li>
</ul>
</li>
<li>
<p><strong>Failures</strong>:</p>
<ul>
<li>Uvicorn had <strong>no failures</strong>, whereas Gunicorn recorded <strong>13 failures</strong> caused by <code inline="""">RemoteDisconnected</code> errors. This could indicate potential issues in connection handling under load.</li>
</ul>
</li>
<li>
<p><strong>Performance Consistency</strong>:</p>
<ul>
<li>Uvicorn offers better consistency and reliability based on the above data.</li>
</ul>
</li>
</ol>
<hr>
</html>

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-12-20 07:12:36+00:00,[],2025-01-27 12:55:27+00:00,2025-01-24 09:03:08+00:00,https://github.com/apache/airflow/pull/45103,"[('area:CLI', ''), ('type:improvement', 'Changelog: Improvements')]","[{'comment_id': 2611548633, 'issue_id': 2752096921, 'author': 'vatsrahul1001', 'body': '> CI need fixing, most likely CLI tests need to be updated.\r\n\r\nFixed tests after updating `setproctitle `', 'created_at': datetime.datetime(2025, 1, 24, 4, 28, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2612008373, 'issue_id': 2752096921, 'author': 'pierrejeambrun', 'body': 'Ok, I think we left enough time for people to participated in case they feel that some other options are necessary. We can always improve later, merging.', 'created_at': datetime.datetime(2025, 1, 24, 9, 2, 47, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2025-01-24 04:28:43 UTC): Fixed tests after updating `setproctitle `

pierrejeambrun on (2025-01-24 09:02:47 UTC): Ok, I think we left enough time for people to participated in case they feel that some other options are necessary. We can always improve later, merging.

"
2752057521,pull_request,closed,,AIP-72: Adding missing supervisor handler for RTIF,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

While testing some end to end scenarios for RTIF and other DAGs, I realised that the RTIF table wasnt getting populated with RTIFs. It was empty, the UI showed it however.

The reason is because there was no handler in the supervisor which was sending the client request to the execution API server. This PR adds that while adding tests to supervisor and to the task runner which was only testing the ""startup"" and not ""run"". Removed an unecessary test too.

After changes:
<img width=""1311"" alt=""image"" src=""https://github.com/user-attachments/assets/86db7017-928d-4e26-8a20-efd9d468cd75"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-20 06:42:32+00:00,[],2024-12-20 08:28:49+00:00,2024-12-20 08:28:48+00:00,https://github.com/apache/airflow/pull/45102,"[('area:task-sdk', None)]",[],
2751610668,pull_request,closed,,Fix deferrable RedshiftClusterSensor,"We recently started running the system tests in deferrable mode and noticed the Redshift one fails in that case with a `'coroutine' object is not subscriptable` exception.  Moving [""Clusters""] to the following line allows the result to parse into a subscriptable object and the test works now.

TLDR:

this fails:
```
async with self.async_conn as client:
    response = await client.describe_clusters(ClusterIdentifier=cluster_identifier)[""Clusters]
    return response
```
but this works:
```
async with self.async_conn as client:
    response = await client.describe_clusters(ClusterIdentifier=cluster_identifier)
    return response[""Clusters""]
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-12-19 23:32:07+00:00,[],2024-12-19 23:56:53+00:00,2024-12-19 23:56:52+00:00,https://github.com/apache/airflow/pull/45098,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2751549239,pull_request,closed,,Unify Trigger and Clear Action button,"The goal is:
- Unify the action button behavior for clear / trigger and any further actions.
- Support a `withText=true` mode for a full button
- Support a `withText=false` mode for a small, compact action style button with tooltip

![Screenshot 2024-12-19 at 23 33 24](https://github.com/user-attachments/assets/9dbddc45-c0fb-4354-bde1-762366efc7d4)
![Screenshot 2024-12-19 at 23 33 33](https://github.com/user-attachments/assets/58e2c114-b2a7-43d3-aa5e-620f18d1b021)
![Screenshot 2024-12-19 at 23 33 49](https://github.com/user-attachments/assets/886c6a6f-be49-44f1-b5ee-a2795719eae0)
![Screenshot 2024-12-19 at 23 34 09](https://github.com/user-attachments/assets/dc8bca0a-ddfb-453c-b987-8126592f04b6)



",pierrejeambrun,2024-12-19 22:34:33+00:00,['pierrejeambrun'],2024-12-20 15:55:45+00:00,2024-12-20 15:55:43+00:00,https://github.com/apache/airflow/pull/45097,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2751418796,pull_request,closed,,Remove some leftover `processor_subdir` references,I missed these when I removed the rest in #45088.,jedcunningham,2024-12-19 21:02:43+00:00,[],2024-12-19 21:22:43+00:00,2024-12-19 21:22:41+00:00,https://github.com/apache/airflow/pull/45096,"[('area:dev-tools', '')]",[],
2751404618,pull_request,closed,,Ensure UI config is fetched before other queries,"Alternative to https://github.com/apache/airflow/pull/44989

Ensure that we have the UI config before any other request is made to the backend.

Ultimately, we should include this as part of the authentication flow.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-19 20:56:46+00:00,[],2025-01-07 19:22:46+00:00,2024-12-20 15:08:22+00:00,https://github.com/apache/airflow/pull/45095,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2561349881, 'issue_id': 2751404618, 'author': 'tirkarthi', 'body': ""For some reason the dags page filter buttons by state like failed, running etc. are not working and the url is not updated with the selected state value for `last_dag_run_state`. But selecting the filter from dashboard button applies the query parameter `last_dag_run_state` and it's working fine. I bisected to this commit using below command\r\n\r\nNot working\r\n\r\n(myenv) âžœ  ui git:(main) âœ— git checkout 5e0aeef897 src/\r\nUpdated 0 paths from e685b10ac1\r\n\r\nWorking\r\n\r\n(myenv) âžœ  ui git:(main) âœ— git checkout 5e0aeef897~1 src/\r\nUpdated 3 paths from 222dbe1da5"", 'created_at': datetime.datetime(2024, 12, 24, 18, 55, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561957593, 'issue_id': 2751404618, 'author': 'tirkarthi', 'body': ""Below seems to fix this issue. I don't see any changes to table state in the fix. Somewhere along the line the search params and table state seem to get out of sync.\r\n\r\n```patch\r\ngd src/pages/DagsList/DagsFilters.tsx | cat\r\ndiff --git a/airflow/ui/src/pages/DagsList/DagsFilters.tsx b/airflow/ui/src/pages/DagsList/DagsFilters.tsx\r\nindex 94cca4d5ee..2c766af8e4 100644\r\n--- a/airflow/ui/src/pages/DagsList/DagsFilters.tsx\r\n+++ b/airflow/ui/src/pages/DagsList/DagsFilters.tsx\r\n@@ -86,11 +86,11 @@ export const DagsFilters = () => {\r\n       } else {\r\n         searchParams.set(PAUSED_PARAM, val);\r\n       }\r\n-      setSearchParams(searchParams);\r\n       setTableURLState({\r\n         pagination: { ...pagination, pageIndex: 0 },\r\n         sorting,\r\n       });\r\n+      setSearchParams(searchParams);\r\n     },\r\n     [pagination, searchParams, setSearchParams, setTableURLState, sorting],\r\n   );\r\n@@ -103,11 +103,11 @@ export const DagsFilters = () => {\r\n         } else {\r\n           searchParams.set(LAST_DAG_RUN_STATE_PARAM, value);\r\n         }\r\n-        setSearchParams(searchParams);\r\n         setTableURLState({\r\n           pagination: { ...pagination, pageIndex: 0 },\r\n           sorting,\r\n         });\r\n+\tsetSearchParams(searchParams);\r\n       },\r\n       [pagination, searchParams, setSearchParams, setTableURLState, sorting],\r\n     );\r\n```"", 'created_at': datetime.datetime(2024, 12, 25, 17, 23, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576057550, 'issue_id': 2751404618, 'author': 'bbovenzi', 'body': 'Very weird. @tirkarthi, Do you want to open those changes as PR?', 'created_at': datetime.datetime(2025, 1, 7, 19, 22, 23, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-12-24 18:55:24 UTC): For some reason the dags page filter buttons by state like failed, running etc. are not working and the url is not updated with the selected state value for `last_dag_run_state`. But selecting the filter from dashboard button applies the query parameter `last_dag_run_state` and it's working fine. I bisected to this commit using below command

Not working

(myenv) âžœ  ui git:(main) âœ— git checkout 5e0aeef897 src/
Updated 0 paths from e685b10ac1

Working

(myenv) âžœ  ui git:(main) âœ— git checkout 5e0aeef897~1 src/
Updated 3 paths from 222dbe1da5

tirkarthi on (2024-12-25 17:23:13 UTC): Below seems to fix this issue. I don't see any changes to table state in the fix. Somewhere along the line the search params and table state seem to get out of sync.

```patch
gd src/pages/DagsList/DagsFilters.tsx | cat
diff --git a/airflow/ui/src/pages/DagsList/DagsFilters.tsx b/airflow/ui/src/pages/DagsList/DagsFilters.tsx
index 94cca4d5ee..2c766af8e4 100644
--- a/airflow/ui/src/pages/DagsList/DagsFilters.tsx
+++ b/airflow/ui/src/pages/DagsList/DagsFilters.tsx
@@ -86,11 +86,11 @@ export const DagsFilters = () => {
       } else {
         searchParams.set(PAUSED_PARAM, val);
       }
-      setSearchParams(searchParams);
       setTableURLState({
         pagination: { ...pagination, pageIndex: 0 },
         sorting,
       });
+      setSearchParams(searchParams);
     },
     [pagination, searchParams, setSearchParams, setTableURLState, sorting],
   );
@@ -103,11 +103,11 @@ export const DagsFilters = () => {
         } else {
           searchParams.set(LAST_DAG_RUN_STATE_PARAM, value);
         }
-        setSearchParams(searchParams);
         setTableURLState({
           pagination: { ...pagination, pageIndex: 0 },
           sorting,
         });
+	setSearchParams(searchParams);
       },
       [pagination, searchParams, setSearchParams, setTableURLState, sorting],
     );
```

bbovenzi (Issue Creator) on (2025-01-07 19:22:23 UTC): Very weird. @tirkarthi, Do you want to open those changes as PR?

"
2751404041,pull_request,closed,,Correctly set `owners` on DagModel after TaskSDK parsing change,"It turns out this behaviour wasn't adequetely tested, at least not using
serialized DAGs, and broke as a result of #44972

This test fixes this case, and adds/moves some of the tests from
models/test_dag.py into test_collection which more accurately represents where
the code it is testing now lives.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-12-19 20:56:21+00:00,[],2024-12-19 22:35:14+00:00,2024-12-19 22:08:20+00:00,https://github.com/apache/airflow/pull/45094,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', '')]",[],
2751283187,pull_request,closed,,"Create util for TI links, improve positioning of empty states","- Have a util to create links to task instances so we don't forget to add map_index
- Update position of ""No values found"" in the Datatable to go below instead of above the table header
- Make sure we always show the ""Wrap"" button on the right side of the Logs page
- Fix a few spots where we didn't use `getDuration` or `renderedMapIndex`



<img width=""1112"" alt=""Screenshot 2024-12-19 at 2 45 59â€¯PM"" src=""https://github.com/user-attachments/assets/ea3b7ec2-bcbe-49db-b1ed-977042d9e794"" />
<img width=""1099"" alt=""Screenshot 2024-12-19 at 2 46 06â€¯PM"" src=""https://github.com/user-attachments/assets/9fcfadb4-4ffa-4b5d-977f-8b4c33095aa1"" />



---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-19 19:48:57+00:00,[],2024-12-19 20:46:54+00:00,2024-12-19 20:46:53+00:00,https://github.com/apache/airflow/pull/45093,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2751246853,pull_request,closed,,Fix test/static check failures in main,"PR #45087 broke some tests and had a formatting error as well. This fixes it.

This is an alternative to #45091.",jedcunningham,2024-12-19 19:25:26+00:00,[],2024-12-19 19:59:14+00:00,2024-12-19 19:59:02+00:00,https://github.com/apache/airflow/pull/45092,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2555667330, 'issue_id': 2751246853, 'author': 'jedcunningham', 'body': ""We reverted as we found more and more failing tests. I'll let Daniel open a new PR."", 'created_at': datetime.datetime(2024, 12, 19, 19, 59, 2, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-19 19:59:02 UTC): We reverted as we found more and more failing tests. I'll let Daniel open a new PR.

"
2751220555,pull_request,closed,,"Revert ""Disable _sync_dag_perms until we can fix its implementation (#45087)","This reverts commit 80c5f3593aecbdcad77f83b62704c76f4d78f3a6.

#45087

There are static check failures and test failures. Easier to simply revert for now.",jedcunningham,2024-12-19 19:10:02+00:00,[],2024-12-19 19:45:58+00:00,2024-12-19 19:45:56+00:00,https://github.com/apache/airflow/pull/45091,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2555616063, 'issue_id': 2751220555, 'author': 'jedcunningham', 'body': 'Trying to fix vs revert here: #45092', 'created_at': datetime.datetime(2024, 12, 19, 19, 26, 45, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-19 19:26:45 UTC): Trying to fix vs revert here: #45092

"
2751149783,pull_request,closed,,Rename DAG to Dag on Trigger Dag form,"Rename DAG to Dag on Trigger Dag form

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-19 18:26:33+00:00,[],2024-12-19 19:36:21+00:00,2024-12-19 19:36:21+00:00,https://github.com/apache/airflow/pull/45090,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2751134107,pull_request,closed,,Add variable backend validations and checks,"related: #43709 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-19 18:17:04+00:00,[],2024-12-20 18:46:58+00:00,2024-12-20 18:46:58+00:00,https://github.com/apache/airflow/pull/45089,[],"[{'comment_id': 2555497931, 'issue_id': 2751134107, 'author': 'shubhamraj-git', 'body': '@jscheffl @pierrejeambrun @bbovenzi \r\nThis PR will handle the validation and checks and will unblock the\r\nhttps://github.com/apache/airflow/pull/44942', 'created_at': datetime.datetime(2024, 12, 19, 18, 20, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557137323, 'issue_id': 2751134107, 'author': 'pierrejeambrun', 'body': 'One test need fixing.', 'created_at': datetime.datetime(2024, 12, 20, 14, 38, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557228444, 'issue_id': 2751134107, 'author': 'jscheffl', 'body': '> One test need fixing.\r\n\r\nUps, had the same comment but now realize at the point coming back that it was pending :face_in_clouds:', 'created_at': datetime.datetime(2024, 12, 20, 15, 32, 7, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2024-12-19 18:20:29 UTC): @jscheffl @pierrejeambrun @bbovenzi 
This PR will handle the validation and checks and will unblock the
https://github.com/apache/airflow/pull/44942

pierrejeambrun on (2024-12-20 14:38:38 UTC): One test need fixing.

jscheffl on (2024-12-20 15:32:07 UTC): Ups, had the same comment but now realize at the point coming back that it was pending :face_in_clouds:

"
2751106731,pull_request,closed,,Remove `processor_subdir`,"This is in preparation for supporting bundles; the subdir concept will be superseded by separate local bundles. And things like the dag processor will be able to operate on a subset of bundles.
",jedcunningham,2024-12-19 18:02:21+00:00,[],2024-12-19 20:49:23+00:00,2024-12-19 20:49:22+00:00,https://github.com/apache/airflow/pull/45088,"[('AIP-66: DAG Bundle/Manifest', '')]",[],
2751093495,pull_request,closed,,Disable _sync_dag_perms until we can fix its implementation,"Currently _sync_dag_perms is FAB specific. We need to re-implement it using the auth manager interface. In the short term, we are going to disable it but this should be fixed and re-enabled before AF3 is released.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dimberman,2024-12-19 17:57:55+00:00,[],2024-12-19 19:04:40+00:00,2024-12-19 18:27:58+00:00,https://github.com/apache/airflow/pull/45087,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2750983656,pull_request,closed,,Prefer rendered_map_index value if defined over map_index.,"`rendered_map_index` when defined will have more user friendly value which can be used in the UI instead of `map_index` which is only a number. This is useful in mapped tasks and legacy UI had this preference.

Minor changes : 

* Fix a warning regarding prefer undefined over null from eslint in tooltip.tsx
* Use `queue up new tasks` as per the legacy UI.

main

![image](https://github.com/user-attachments/assets/1b005646-1b99-42bb-a5e8-02243995676a)

With PR

![image](https://github.com/user-attachments/assets/d7b7ebea-b8c9-4256-8c34-49deddb9477f)

",tirkarthi,2024-12-19 17:13:47+00:00,[],2024-12-19 17:28:23+00:00,2024-12-19 17:28:22+00:00,https://github.com/apache/airflow/pull/45086,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2750977544,pull_request,closed,,Introduce gcp translation (V3) glossaries providers,"Operators:
- TranslateCreateGlossaryOperator
- TranslateUpdateGlossaryOperator
- TranslateListGlossariesOperator
- TranslateDeleteGlossaryOperator

This set of operators allows to work with custom translation dictionaries (glossaries), using Google Cloud Translate V3 API.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-12-19 17:11:20+00:00,[],2024-12-20 22:34:15+00:00,2024-12-20 22:34:15+00:00,https://github.com/apache/airflow/pull/45085,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2750955363,pull_request,closed,,Google provider delete deprecated reaching removal date (December 2024),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-12-19 17:02:27+00:00,[],2024-12-21 07:14:17+00:00,2024-12-19 20:48:23+00:00,https://github.com/apache/airflow/pull/45084,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2750857599,pull_request,closed,,DNM: Add Elasticsearch helm tests,"DRAFT to hopefully get CI tests, this change is included of #45082 intended to be merged as a whole.
",topherinternational,2024-12-19 16:26:07+00:00,[],2024-12-19 20:23:15+00:00,2024-12-19 20:19:26+00:00,https://github.com/apache/airflow/pull/45083,[],"[{'comment_id': 2555702007, 'issue_id': 2750857599, 'author': 'topherinternational', 'body': 'Closing, was just testing here.', 'created_at': datetime.datetime(2024, 12, 19, 20, 19, 26, tzinfo=datetime.timezone.utc)}]","topherinternational (Issue Creator) on (2024-12-19 20:19:26 UTC): Closing, was just testing here.

"
2750854624,pull_request,closed,,Chart: add OpenSearch remote logging options,"This change duplicates the existing elasticsearch configurations to support the new OpenSearch remote logging option added in #41799.

In addition to adding the `opensearch` block in `values.yaml`, it also adds a disambiguation check to prevent users from enabling both Elasticsearch and openSearch remote logging, as Airflow does not support using both at the same time.

Finally, a suite of tests is added to test the existing Elasticsearch configuration options as well as the new OpenSearch options. A few existing tests have been moved to put all of the ES/OS/remote logging behaviors under a single test module.
",topherinternational,2024-12-19 16:24:59+00:00,[],2025-02-05 15:52:02+00:00,2025-01-03 13:32:52+00:00,https://github.com/apache/airflow/pull/45082,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2566881431, 'issue_id': 2750854624, 'author': 'eladkal', 'body': 'cc @Owen-CH-Leung', 'created_at': datetime.datetime(2025, 1, 1, 7, 4, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567993590, 'issue_id': 2750854624, 'author': 'Owen-CH-Leung', 'body': 'LGTM!', 'created_at': datetime.datetime(2025, 1, 2, 15, 55, 32, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-01-01 07:04:43 UTC): cc @Owen-CH-Leung

Owen-CH-Leung on (2025-01-02 15:55:32 UTC): LGTM!

"
2750611491,pull_request,closed,,[v2-10-test] Handle relative paths when sanitizing URLs (#41995),"* Handle relative paths when sanitizing URLs

In the initial PR(https://github.com/apache/airflow/pull/41665) we didn't handle the relative path in URL which led to issue(https://github.com/apache/airflow/issues/41977). This PR aims at handling the relative path case when sanitizing URLs

* Add PR suggestions

* Update code comment (cherry picked from commit 0429bf4e2839f66433d0abfa9c8c6dff6568e965)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-19 15:00:37+00:00,[],2025-01-28 12:14:06+00:00,2024-12-20 12:52:21+00:00,https://github.com/apache/airflow/pull/45080,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2556916050, 'issue_id': 2750611491, 'author': 'potiuk', 'body': 'Looks good to go :)', 'created_at': datetime.datetime(2024, 12, 20, 12, 30, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2556948127, 'issue_id': 2750611491, 'author': 'potiuk', 'body': '> Yeah. I am not sure why it has been missing, but a user noticed that it was not in https://github.com/apache/airflow/pull/41995#issuecomment-2554458054  even if it had 2.10.2 as milestone, so we missed it somehow (cc: @utkarsharma2 )', 'created_at': datetime.datetime(2024, 12, 20, 12, 52, 12, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-20 12:30:36 UTC): Looks good to go :)

potiuk (Issue Creator) on (2024-12-20 12:52:12 UTC): 

"
2750372362,pull_request,closed,,[v2-10-test] Add traceback log output when sigterm was sent (#44880),"Co-authored-by: Ulada Zakharava <vlada_zakharava@epam.com>
(cherry picked from commit 9186fc57907c89f2f871d54f981f2b6892920e2f)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-19 13:40:38+00:00,[],2025-01-28 12:15:57+00:00,2024-12-20 12:50:06+00:00,https://github.com/apache/airflow/pull/45077,"[('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]","[{'comment_id': 2556917709, 'issue_id': 2750372362, 'author': 'potiuk', 'body': 'Also looks good to go...', 'created_at': datetime.datetime(2024, 12, 20, 12, 31, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2556944835, 'issue_id': 2750372362, 'author': 'potiuk', 'body': 'I have not seen it to be flaky. I think caplog behaviour is bad in **some** cases only.', 'created_at': datetime.datetime(2024, 12, 20, 12, 50, 2, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-20 12:31:33 UTC): Also looks good to go...

potiuk (Issue Creator) on (2024-12-20 12:50:02 UTC): I have not seen it to be flaky. I think caplog behaviour is bad in **some** cases only.

"
2750351205,pull_request,closed,,[v2-10-test] Only run ARM collection tests in main branch (#45068),"The ARM collection tests are testing if all tests can be properly collected when packages not available on ARM are removed. We currently do not have such packages, but since this is only valid for providers and in version branches we never touch providers, we should just skip the test on non-main branch.
(cherry picked from commit d1245cd0771f23be8f9d378f93b127fe13d3706f)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-19 13:33:29+00:00,[],2024-12-19 15:06:43+00:00,2024-12-19 15:06:41+00:00,https://github.com/apache/airflow/pull/45076,"[('area:dev-tools', '')]",[],
2750338036,pull_request,closed,,AIP-72: Allow pushing and pulling XCom from Task Context,"Part of https://github.com/apache/airflow/issues/44481

There is a lot of cleanup to do but I wanted to get a basic DAG that uses XCom working first.

Example DAG used: `tutorial_dag`

```py

from __future__ import annotations

# [START tutorial]
# [START import_module]
import json
import textwrap

import pendulum

# The DAG object; we'll need this to instantiate a DAG
from airflow.models.dag import DAG

# Operators; we need this to operate!
from airflow.providers.standard.operators.python import PythonOperator

# [END import_module]

# [START instantiate_dag]
with DAG(
    ""tutorial_dag"",
    # [START default_args]
    # These args will get passed on to each operator
    # You can override them on a per-task basis during operator initialization
    default_args={""retries"": 2},
    # [END default_args]
    description=""DAG tutorial"",
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),
    catchup=False,
    tags=[""example""],
) as dag:
    # [END instantiate_dag]
    # [START documentation]
    dag.doc_md = __doc__
    # [END documentation]

    # [START extract_function]
    def extract(**kwargs):
        ti = kwargs[""ti""]
        data_string = '{""1001"": 301.27, ""1002"": 433.21, ""1003"": 502.22}'
        ti.xcom_push(""order_data"", data_string)

    # [END extract_function]

    # [START transform_function]
    def transform(**kwargs):
        ti = kwargs[""ti""]
        extract_data_string = ti.xcom_pull(task_ids=""extract"", key=""order_data"")
        order_data = json.loads(extract_data_string)

        total_order_value = 0
        for value in order_data.values():
            total_order_value += value

        total_value = {""total_order_value"": total_order_value}
        total_value_json_string = json.dumps(total_value)
        ti.xcom_push(""total_order_value"", total_value_json_string)

    # [END transform_function]

    # [START load_function]
    def load(**kwargs):
        ti = kwargs[""ti""]
        total_value_string = ti.xcom_pull(task_ids=""transform"", key=""total_order_value"")
        total_order_value = json.loads(total_value_string)

        print(total_order_value)

    # [END load_function]

    # [START main_flow]
    extract_task = PythonOperator(
        task_id=""extract"",
        python_callable=extract,
    )
    extract_task.doc_md = textwrap.dedent(
        """"""\
    #### Extract task
    A simple Extract task to get data ready for the rest of the data pipeline.
    In this case, getting data is simulated by reading from a hardcoded JSON string.
    This data is then put into xcom, so that it can be processed by the next task.
    """"""
    )

    transform_task = PythonOperator(
        task_id=""transform"",
        python_callable=transform,
    )
    transform_task.doc_md = textwrap.dedent(
        """"""\
    #### Transform task
    A simple Transform task which takes in the collection of order data from xcom
    and computes the total order value.
    This computed value is then put into xcom, so that it can be processed by the next task.
    """"""
    )

    load_task = PythonOperator(
        task_id=""load"",
        python_callable=load,
    )
    load_task.doc_md = textwrap.dedent(
        """"""\
    #### Load task
    A simple Load task which takes in the result of the Transform task, by reading it
    from xcom and instead of saving it to end user review, just prints it out.
    """"""
    )

    extract_task >> transform_task >> load_task
```

---
<img width=""1703"" alt=""image"" src=""https://github.com/user-attachments/assets/10025ef4-0410-4c2a-9bb6-1e68f51a8805"" />

<img width=""1710"" alt=""image"" src=""https://github.com/user-attachments/assets/201b61c0-3998-4b06-b0d4-2145120321f8"" />

---
<img width=""1721"" alt=""image"" src=""https://github.com/user-attachments/assets/dd9c50e3-20c5-4762-99f9-c02a8c16732e"" />


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-19 13:28:56+00:00,[],2024-12-24 11:37:43+00:00,2024-12-24 11:37:42+00:00,https://github.com/apache/airflow/pull/45075,"[('area:task-sdk', None)]",[],
2750262237,pull_request,closed,,AIP-72: Logging updated state in execution API server,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

When the task SDK calls task change APIs in the execution API server, the execution API logs that the task instance was updated -- but not to which state. Adding this information can be helpful while debugging and tracking requests.

Example for deferred
![image](https://github.com/user-attachments/assets/b17640d1-34c7-485b-82ea-71bbebf6786c)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-19 13:01:16+00:00,[],2024-12-19 14:39:13+00:00,2024-12-19 14:39:10+00:00,https://github.com/apache/airflow/pull/45074,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2750211261,pull_request,open,,Use custom dag_folder not settings.DAGS_FOLDER for FileLoadStat,The stats would still use `settings.DAGS_FOLDER` despite dag_folder arg being set to a different path and used for the actual dags parsing.,radujica,2024-12-19 12:43:51+00:00,[],2025-02-04 13:43:41+00:00,,https://github.com/apache/airflow/pull/45073,[],"[{'comment_id': 2553751299, 'issue_id': 2750211261, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 19, 12, 43, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553825230, 'issue_id': 2750211261, 'author': 'radujica', 'body': ""I would love to write a test but for the life of me I can't find a tl;dr on how to run the dagbag tests quickly and locally without any Docker breeze.\r\n\r\nI would have expected this to simply be:\r\n\r\n```python\r\nconda create -n airflow python==3.12\r\npip install -e .[devel]\r\npytest tests/models/test_dagbag.py::test_dagbag_dag_collection\r\n```"", 'created_at': datetime.datetime(2024, 12, 19, 12, 58, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553851391, 'issue_id': 2750211261, 'author': 'ashb', 'body': '@radujica We switched to uv recently. Something like this should work\r\n\r\n```\r\nuv venv\r\nuv sync  --extra devel --group dev\r\n.venv/bin/pytest tests/models/test_dagbag.py::test_dagbag_dag_collection\r\n```', 'created_at': datetime.datetime(2024, 12, 19, 13, 4, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553936381, 'issue_id': 2750211261, 'author': 'potiuk', 'body': 'TL;DR; is directly there in the contributing docs BTW: https://github.com/apache/airflow/blob/main/contributing-docs/07_local_virtualenv.rst', 'created_at': datetime.datetime(2024, 12, 19, 13, 20, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553954812, 'issue_id': 2750211261, 'author': 'potiuk', 'body': 'Also @ashb - not sure if you know but `uv run pytest ...` is  a simpler replacement when you already did sync once. It will repeat the latest sync (if needed) and activate the default venv for the command :)', 'created_at': datetime.datetime(2024, 12, 19, 13, 24, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553996902, 'issue_id': 2750211261, 'author': 'ashb', 'body': ""`uv run` -- knew about but forgot as I'm so used to activating venvs for my workflow."", 'created_at': datetime.datetime(2024, 12, 19, 13, 32, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2554577838, 'issue_id': 2750211261, 'author': 'radujica', 'body': 'Thank you for the swift input both :)\r\n\r\nHad lazily assumed I could just use `conda` but clearly it misses something that `uv` does not, as the error went away after using `uv`. For posterity, this works fine on my mac:\r\n\r\n```bash\r\nuv venv\r\nuv sync --extra devel\r\nuv run pytest tests/models/test_dagbag.py::TestDagBag::test_dagbag_dag_collection\r\n```\r\n\r\nNever used `uv` before and funny enough, it seems to override what `conda` does, i.e. I created a new conda env and installed pytest inside however pytest still points to the pytest installed by uv ""outside"" the conda env.\r\n\r\nAnyway, will update PR with test soon enough.', 'created_at': datetime.datetime(2024, 12, 19, 15, 19, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563702701, 'issue_id': 2750211261, 'author': 'radujica', 'body': '@ashb @XD-DENG not urgent, enjoy holidays! just to say this is ready for review IMO', 'created_at': datetime.datetime(2024, 12, 27, 13, 28, 16, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-19 12:43:55 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

radujica (Issue Creator) on (2024-12-19 12:58:25 UTC): I would love to write a test but for the life of me I can't find a tl;dr on how to run the dagbag tests quickly and locally without any Docker breeze.

I would have expected this to simply be:

```python
conda create -n airflow python==3.12
pip install -e .[devel]
pytest tests/models/test_dagbag.py::test_dagbag_dag_collection
```

ashb on (2024-12-19 13:04:28 UTC): @radujica We switched to uv recently. Something like this should work

```
uv venv
uv sync  --extra devel --group dev
.venv/bin/pytest tests/models/test_dagbag.py::test_dagbag_dag_collection
```

potiuk on (2024-12-19 13:20:53 UTC): TL;DR; is directly there in the contributing docs BTW: https://github.com/apache/airflow/blob/main/contributing-docs/07_local_virtualenv.rst

potiuk on (2024-12-19 13:24:12 UTC): Also @ashb - not sure if you know but `uv run pytest ...` is  a simpler replacement when you already did sync once. It will repeat the latest sync (if needed) and activate the default venv for the command :)

ashb on (2024-12-19 13:32:03 UTC): `uv run` -- knew about but forgot as I'm so used to activating venvs for my workflow.

radujica (Issue Creator) on (2024-12-19 15:19:56 UTC): Thank you for the swift input both :)

Had lazily assumed I could just use `conda` but clearly it misses something that `uv` does not, as the error went away after using `uv`. For posterity, this works fine on my mac:

```bash
uv venv
uv sync --extra devel
uv run pytest tests/models/test_dagbag.py::TestDagBag::test_dagbag_dag_collection
```

Never used `uv` before and funny enough, it seems to override what `conda` does, i.e. I created a new conda env and installed pytest inside however pytest still points to the pytest installed by uv ""outside"" the conda env.

Anyway, will update PR with test soon enough.

radujica (Issue Creator) on (2024-12-27 13:28:16 UTC): @ashb @XD-DENG not urgent, enjoy holidays! just to say this is ready for review IMO

"
2750121478,pull_request,open,,Add ability to pass extra parameters to Hive Client Wrapper connection,"Closes: #45049

Add extra fields to Hive Client Wrapper connection so it is possible to pass extra parameters which are used to construct JDBC connection string. The extra fields are SSL Trust Store, SSL Trust Store password and Transport mode.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",tomwit-nx,2024-12-19 12:10:31+00:00,[],2024-12-27 10:35:56+00:00,,https://github.com/apache/airflow/pull/45071,"[('area:providers', ''), ('kind:documentation', ''), ('provider:apache-hive', '')]","[{'comment_id': 2553619167, 'issue_id': 2750121478, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 19, 12, 10, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563536600, 'issue_id': 2750121478, 'author': 'tomwit-nx', 'body': '> Actually - this is not securre enough.\r\n> \r\n> The problem is that you can pass many, many bad things via JDBC url - when the values are not properly escaped. It\'s enough to pass `;` as value of any of the paremeters you pass from extra. And when it happens, the user who has permission to configure the connection via UI might even perform RCE in a number of cases.\r\n> \r\n> The recommendation here is:\r\n> \r\n> * only allow fixed values to be passed via extra (bool for example) to control how the JDBC URL is constructed\r\n> * only allow ""free-form"" parameters to be passed by **init** parameters of the operator/hook - that can only be done by the DAG author, and DAG author by definitiion and security model of Airflow https://airflow.apache.org/docs/apache-airflow/stable/security/security_model.html can do more than connection editing user\r\n> * sanitize the input (but this one is potentially very difficult)\r\n> \r\n> While we already warn against the potentially Conection editing user being able to have more capabilities - so this is not strictly security issue, this is part of ""security hardeninig"" - we should not add ""easy"" ways for those users to be able to perform all kinds of attacks.\r\n\r\nI guess this also applies to the already existing `Principal` and `Proxy User` fields? I see that they only validate if a `;` character was passed', 'created_at': datetime.datetime(2024, 12, 27, 10, 7, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563555990, 'issue_id': 2750121478, 'author': 'potiuk', 'body': '> I guess this also applies to the already existing Principal and Proxy User fields? I see that they only validate if a ; character was passed\r\n\r\nI think there are more validations needed. Passing arbitrary parameter as path to jdbc is dangerous (what happens if for example jdbc driver displays content of the file when it is wrong and you pass ""/etc/passwd""` ?. This is just example, it could be even more diastrous - printing more secret keys and secret variables stored somewhere on remote system.  I am not sure if you can make it ""secure"" when this parameter is passed via UI and free-form.\r\n\r\nThere are only few values allowed for transportMode I guess, so it is safer to enumerate them rather than pass directly. When it comes to password, there is a question how `;` is going to be passed (i..e what form of escaping should be there)?', 'created_at': datetime.datetime(2024, 12, 27, 10, 26, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563563977, 'issue_id': 2750121478, 'author': 'tomwit-nx', 'body': '> > I guess this also applies to the already existing Principal and Proxy User fields? I see that they only validate if a ; character was passed\r\n> \r\n> I think there are more validations needed. Passing arbitrary parameter as path to jdbc is dangerous (what happens if for example jdbc driver displays content of the file when it is wrong and you pass ""/etc/passwd""` ?. This is just example, it could be even more diastrous - printing more secret keys and secret variables stored somewhere on remote system. I am not sure if you can make it ""secure"" when this parameter is passed via UI and free-form.\r\n> \r\n> There are only few values allowed for transportMode I guess, so it is safer to enumerate them rather than pass directly. When it comes to password, there is a question how `;` is going to be passed (i..e what form of escaping should be there)?\r\n\r\nThanks for the insight. I will see what I can do.', 'created_at': datetime.datetime(2024, 12, 27, 10, 35, 55, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-19 12:10:37 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

tomwit-nx (Issue Creator) on (2024-12-27 10:07:17 UTC): I guess this also applies to the already existing `Principal` and `Proxy User` fields? I see that they only validate if a `;` character was passed

potiuk on (2024-12-27 10:26:35 UTC): I think there are more validations needed. Passing arbitrary parameter as path to jdbc is dangerous (what happens if for example jdbc driver displays content of the file when it is wrong and you pass ""/etc/passwd""` ?. This is just example, it could be even more diastrous - printing more secret keys and secret variables stored somewhere on remote system.  I am not sure if you can make it ""secure"" when this parameter is passed via UI and free-form.

There are only few values allowed for transportMode I guess, so it is safer to enumerate them rather than pass directly. When it comes to password, there is a question how `;` is going to be passed (i..e what form of escaping should be there)?

tomwit-nx (Issue Creator) on (2024-12-27 10:35:55 UTC): Thanks for the insight. I will see what I can do.

"
2749770270,pull_request,closed,,AIP-72: Handling `up_for_retry` task instance states,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-19 09:44:49+00:00,[],2024-12-30 12:28:00+00:00,2024-12-30 12:28:00+00:00,https://github.com/apache/airflow/pull/45070,"[('area:task-sdk', None)]","[{'comment_id': 2565421534, 'issue_id': 2749770270, 'author': 'amoghrajesh', 'body': 'We do not need this PR anymore, handled using #45106', 'created_at': datetime.datetime(2024, 12, 30, 12, 27, 58, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-30 12:27:58 UTC): We do not need this PR anymore, handled using #45106

"
2749665791,pull_request,closed,,Update path of example dags in docs,Same as https://github.com/apache/airflow/pull/45033 just for all providers,eladkal,2024-12-19 08:58:57+00:00,[],2024-12-19 10:07:00+00:00,2024-12-19 10:06:56+00:00,https://github.com/apache/airflow/pull/45069,"[('provider:microsoft-azure', 'Azure-related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:common-sql', ''), ('provider:databricks', ''), ('provider:docker', ''), ('provider:elasticsearch', ''), ('provider:http', ''), ('provider:jdbc', ''), ('provider:ftp', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:asana', ''), ('provider:dingding', ''), ('provider:github', ''), ('provider:jenkins', ''), ('provider:apache-kafka', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-spark', ''), ('provider:apache-beam', ''), ('provider:apache-livy', ''), ('provider:apache-drill', ''), ('provider:apache-cassandra', ''), ('provider:apache-flink', ''), ('provider:apache-kylin', ''), ('provider:apache-pig', ''), ('provider:influxdb', ''), ('provider:apache-pinot', ''), ('provider:common-io', ''), ('provider:apache-iceberg', '')]",[],
2749657527,pull_request,closed,,Only run ARM collection tests in main branch,"The ARM collection tests are testing if all tests can be properly collected when packages not available on ARM are removed. We currently do not have such packages, but since this is only valid for providers and in version branches we never touch providers, we should just skip the test on non-main branch.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-19 08:54:46+00:00,[],2024-12-19 10:08:12+00:00,2024-12-19 10:07:23+00:00,https://github.com/apache/airflow/pull/45068,"[('area:dev-tools', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2553310356, 'issue_id': 2749657527, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12410514506\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>âŒ</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/d1245cd0771f23be8f9d378f93b127fe13d3706f""><img src=\'https://img.shields.io/badge/Commit-d1245cd-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker d1245cd v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 19, 10, 8, 11, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-19 10:08:11 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12410514506'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>âŒ</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/d1245cd0771f23be8f9d378f93b127fe13d3706f""><img src='https://img.shields.io/badge/Commit-d1245cd-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker d1245cd v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2749454980,pull_request,closed,,Added job_clusters as a templated parameter to CreateDatabricksWorkflowOperator,"Reverts apache/airflow#45035, which had removed the changes done in #42438. This PR reinstates those changes back as the CI failure issues caused after merging #42438 were unrelated to the change. ",kunaljubce,2024-12-19 07:14:50+00:00,[],2025-02-08 09:34:22+00:00,2025-02-06 19:28:19+00:00,https://github.com/apache/airflow/pull/45066,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2632466924, 'issue_id': 2749454980, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 4, 0, 14, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2640333061, 'issue_id': 2749454980, 'author': 'arollet-decathlon', 'body': ""Hello everyone, \r\nIt would be great to see this PR merged, especially since it looks like this change is documented in the provider's Changelog but is not present in codebase: https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/databricks/CHANGELOG.rst?plain=1#L58\r\n\r\nGood day"", 'created_at': datetime.datetime(2025, 2, 6, 16, 27, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2640566886, 'issue_id': 2749454980, 'author': 'kunaljubce', 'body': '@potiuk Can we merge this please?', 'created_at': datetime.datetime(2025, 2, 6, 17, 41, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2642792876, 'issue_id': 2749454980, 'author': 'karthi-keyan-n', 'body': ""Hi folks, is there any view on the release plan for this fix? I'm currently using 2.10.4 and I see the changes has not been tagged with 2.10.5rc1."", 'created_at': datetime.datetime(2025, 2, 7, 12, 30, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2642815418, 'issue_id': 2749454980, 'author': 'potiuk', 'body': ""> Hi folks, is there any view on the release plan for this fix? I'm currently using 2.10.4 and I see the changes has not been tagged with 2.10.5rc1.\r\n\r\nNo - they are not. They are part of the providers's release. Providers are released independently from Airfow and you can uprade it on your onw. In fact there is nothing to prevent you to build a dev/pre-release version of databricks provider yourself, install it in your environment, try it out and provide feedback. It's super easy:\r\n\r\n1) checkout airflow repo\r\n2) install breeze: `uv pip install -e ./dev/breeze`\r\n3) `breeze release-management prepare-provider-packages databricks --version-suffix-for-pypi dev0`\r\n4) Install resulting package that will be placed in dist.\r\n\r\nCan you please test it and see if it works - and then when we come to releasing providers (which will likely happen in the next few weeks) - you willbe able to confirm and test RC candidate - when we ask here and vote +1 on the release.\r\n\r\nCan we count on your help there?"", 'created_at': datetime.datetime(2025, 2, 7, 12, 42, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2642819735, 'issue_id': 2749454980, 'author': 'potiuk', 'body': 'This is how it works for me:\r\n\r\n![image](https://github.com/user-attachments/assets/237558dd-9154-4449-bceb-5a0f3f3464b8)', 'created_at': datetime.datetime(2025, 2, 7, 12, 45, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2644747627, 'issue_id': 2749454980, 'author': 'karthi-keyan-n', 'body': '> checkout airflow repo\r\ninstall breeze: uv pip install -e ./dev/breeze\r\nbreeze release-management prepare-provider-packages databricks --version-suffix-for-pypi dev0\r\nInstall resulting package that will be placed in dist.\r\n\r\nHey @potiuk I followed your steps to install and validate. But got stuck post that. \r\n\r\n\r\n1. I executed the commands which you shared and it generate .whl file in dist directory. `dist/apache_airflow_providers_databricks-7.0.0.dev0-py3-none-any.whl`\r\n2. I googled and found the command `pip install dist/apache_airflow_providers_databricks-7.0.0.dev0-py3-none-any.whl` to install the wheel packages.\r\n3. I executed the command in the same directory (airflow source code) and I guess it install airflow there. (This is my assumption)\r\n\r\nOther things which I tried was,\r\n\r\n1. Build a docker container in local and tried to substitute it with the apache/airflow docker image in my custom airflow code to bring up the airflow env. Post this, I triggered the DAG and I saw only notebook params field in `rendered template` section.\r\n<img width=""672"" alt=""image"" src=""https://github.com/user-attachments/assets/20897eb5-8abd-4eea-a8cd-b0ec5b42982e"" />\r\n\r\n2. I did some digging and went through the docker file and found `ARG AIRFLOW_VERSION=""2.10.4""` in docker file. \r\n3. I also went through the `INSTALL` doc within the airflow source code repo to bring up the test env.\r\n\r\nIf you don\'t mind, would you able to point me to the right direction from where I can setup in my local and validate? It would be great if you can share the doc for substituting the official airflow image with the custom build image from source code which will make the task earlier to quickly validate', 'created_at': datetime.datetime(2025, 2, 8, 9, 33, 7, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-02-04 00:14:51 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

arollet-decathlon on (2025-02-06 16:27:32 UTC): Hello everyone, 
It would be great to see this PR merged, especially since it looks like this change is documented in the provider's Changelog but is not present in codebase: https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/databricks/CHANGELOG.rst?plain=1#L58

Good day

kunaljubce (Issue Creator) on (2025-02-06 17:41:42 UTC): @potiuk Can we merge this please?

karthi-keyan-n on (2025-02-07 12:30:14 UTC): Hi folks, is there any view on the release plan for this fix? I'm currently using 2.10.4 and I see the changes has not been tagged with 2.10.5rc1.

potiuk on (2025-02-07 12:42:40 UTC): No - they are not. They are part of the providers's release. Providers are released independently from Airfow and you can uprade it on your onw. In fact there is nothing to prevent you to build a dev/pre-release version of databricks provider yourself, install it in your environment, try it out and provide feedback. It's super easy:

1) checkout airflow repo
2) install breeze: `uv pip install -e ./dev/breeze`
3) `breeze release-management prepare-provider-packages databricks --version-suffix-for-pypi dev0`
4) Install resulting package that will be placed in dist.

Can you please test it and see if it works - and then when we come to releasing providers (which will likely happen in the next few weeks) - you willbe able to confirm and test RC candidate - when we ask here and vote +1 on the release.

Can we count on your help there?

potiuk on (2025-02-07 12:45:07 UTC): This is how it works for me:

![image](https://github.com/user-attachments/assets/237558dd-9154-4449-bceb-5a0f3f3464b8)

karthi-keyan-n on (2025-02-08 09:33:07 UTC): install breeze: uv pip install -e ./dev/breeze
breeze release-management prepare-provider-packages databricks --version-suffix-for-pypi dev0
Install resulting package that will be placed in dist.

Hey @potiuk I followed your steps to install and validate. But got stuck post that. 


1. I executed the commands which you shared and it generate .whl file in dist directory. `dist/apache_airflow_providers_databricks-7.0.0.dev0-py3-none-any.whl`
2. I googled and found the command `pip install dist/apache_airflow_providers_databricks-7.0.0.dev0-py3-none-any.whl` to install the wheel packages.
3. I executed the command in the same directory (airflow source code) and I guess it install airflow there. (This is my assumption)

Other things which I tried was,

1. Build a docker container in local and tried to substitute it with the apache/airflow docker image in my custom airflow code to bring up the airflow env. Post this, I triggered the DAG and I saw only notebook params field in `rendered template` section.
<img width=""672"" alt=""image"" src=""https://github.com/user-attachments/assets/20897eb5-8abd-4eea-a8cd-b0ec5b42982e"" />

2. I did some digging and went through the docker file and found `ARG AIRFLOW_VERSION=""2.10.4""` in docker file. 
3. I also went through the `INSTALL` doc within the airflow source code repo to bring up the test env.

If you don't mind, would you able to point me to the right direction from where I can setup in my local and validate? It would be great if you can share the doc for substituting the official airflow image with the custom build image from source code which will make the task earlier to quickly validate

"
2749272549,pull_request,closed,,Fix pr number on newsfragment,Just forgot to rename it after opening the PR and didn't notice it :),jedcunningham,2024-12-19 05:07:16+00:00,[],2024-12-19 08:13:54+00:00,2024-12-19 08:13:39+00:00,https://github.com/apache/airflow/pull/45065,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2748924888,pull_request,closed,,"[2-10-test] Bump hatch version in breeze and prevent ""get-workflow-info"" failure â€¦","â€¦(#45041)

We enabled dependabot to bump dependencies for various Python requirements we have in Airflow and it found out that we have pretty out-dated hatch - pinned because of metadata stability when building packages. The update caused ""get-workflow-info"" step in CI to fail because the ""get-workflow-info"" commmand contained output from uv upgrading breeze while it was running.

This PR bumps the version manually to the latest version, also it sets `SKIP_BREEZE_SELF_UPGRADE_CHECK` variable to true in the `get-workflow-info` step - to prevent breeze from checking and automatically upgrading itself.

This will not make future dependabot PRs to succeed, because those PRs will not update hash of README file - so the PRs will fail at the pre-commit stage, but at least it will be clear what should be done to fix it.

Also a bit of cleanup has been done opportunistically:

* the TODO on flit automation can now be removed as we have dependabot taking care about it automatically in both places that we were supposed to automate

* the importlib_resources exclusions were only used for Python < 3.9 and we are now >= 3.0 so we can remove it

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-18 23:21:03+00:00,[],2024-12-19 08:44:44+00:00,2024-12-19 08:44:42+00:00,https://github.com/apache/airflow/pull/45064,"[('area:dev-tools', '')]",[],
2748920350,pull_request,closed,,[v2-10-test] Avoid 1.1.8 version of msgraph-core (#45044),"The 1.1.8 version of msgraph-core is buggy - importing some basic classes causes import error ""ABCMeta"" is not subscriptable.

We are removing the version from azure provider dependencies hoping that it will be fixed in the next version.

https://github.com/microsoftgraph/msgraph-sdk-python-core/issues/781

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-18 23:16:07+00:00,[],2024-12-19 08:44:34+00:00,2024-12-19 08:44:31+00:00,https://github.com/apache/airflow/pull/45063,[],"[{'comment_id': 2552446592, 'issue_id': 2748920350, 'author': 'potiuk', 'body': 'We need to backport it, to keep CI from failing.', 'created_at': datetime.datetime(2024, 12, 18, 23, 16, 41, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-18 23:16:41 UTC): We need to backport it, to keep CI from failing.

"
2748871007,pull_request,closed,,Add dry run for backfill,"Closes [#44395](https://github.com/apache/airflow/issues/44395)

Response:
<img width=""1289"" alt=""image"" src=""https://github.com/user-attachments/assets/519b31c3-e980-441b-8c07-8e7375907ea9"" />
",prabhusneha,2024-12-18 22:32:08+00:00,[],2025-01-12 16:48:53+00:00,2025-01-12 16:48:52+00:00,https://github.com/apache/airflow/pull/45062,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2558933642, 'issue_id': 2748871007, 'author': 'prabhusneha', 'body': ""> As discussed with daniel, maybe a separate endpoint makes more sense to avoid mixed returned type `BackfillResponse | BackfillDryRunResponse` on the same endpoint. That's hard to handle for clients.\r\n\r\nCreated a separate endpoint for dry run."", 'created_at': datetime.datetime(2024, 12, 23, 5, 25, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566760399, 'issue_id': 2748871007, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 3, 28, tzinfo=datetime.timezone.utc)}]","prabhusneha (Issue Creator) on (2024-12-23 05:25:31 UTC): Created a separate endpoint for dry run.

jscheffl on (2025-01-01 00:03:28 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

"
2748833164,pull_request,open,,AIP-79 Generate assets for Flask application in FAB provider (#44744),"Revert the revert #45057 of #44744.

It failed because of:

```
Traceback (most recent call last):
  File ""/opt/airflow/./scripts/ci/pre_commit/compile_www_assets.py"", line 86, in <module>
    if is_fab_provider_installed():
  File ""/opt/airflow/./scripts/ci/pre_commit/compile_www_assets.py"", line 79, in is_fab_provider_installed
    return importlib.util.find_spec(""airflow.providers.fab"") is not None
  File ""/usr/local/lib/python3.9/importlib/util.py"", line 94, in find_spec
    parent = __import__(parent_name, fromlist=['__path__'])
ModuleNotFoundError: No module named 'airflow'
```

I updated the function `is_fab_provider_installed` and check if airflow is installed first. I ran `breeze release-management prepare-airflow-package --package-format wheel` and it succeeds (but fails without the fix).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-18 22:02:49+00:00,[],2025-02-07 19:17:10+00:00,,https://github.com/apache/airflow/pull/45060,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2552358876, 'issue_id': 2748833164, 'author': 'vincbeck', 'body': 'Running all tests just to be sure', 'created_at': datetime.datetime(2024, 12, 18, 22, 6, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2643801570, 'issue_id': 2748833164, 'author': 'vincbeck', 'body': 'I updated this PR to create a new pre-commit to generate assets from FAB provider. It is basically the solution 2 described by @potiuk in [this comment](https://github.com/apache/airflow/pull/45060#discussion_r1943332556). I duplicated the script `scripts/ci/pre_commit/compile_www_assets.py` to `scripts/ci/pre_commit/compile_fab_assets.py`to make it easier when we remove the Airflow 2 Flask UI, we will only have to delete `scripts/ci/pre_commit/compile_www_assets.py` (and its associated pre-commit).\r\n\r\nThe artifacts from FAB provider are not built on build time but are now part of the codebase.', 'created_at': datetime.datetime(2025, 2, 7, 19, 13, 37, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-12-18 22:06:49 UTC): Running all tests just to be sure

vincbeck (Issue Creator) on (2025-02-07 19:13:37 UTC): I updated this PR to create a new pre-commit to generate assets from FAB provider. It is basically the solution 2 described by @potiuk in [this comment](https://github.com/apache/airflow/pull/45060#discussion_r1943332556). I duplicated the script `scripts/ci/pre_commit/compile_www_assets.py` to `scripts/ci/pre_commit/compile_fab_assets.py`to make it easier when we remove the Airflow 2 Flask UI, we will only have to delete `scripts/ci/pre_commit/compile_www_assets.py` (and its associated pre-commit).

The artifacts from FAB provider are not built on build time but are now part of the codebase.

"
2748766867,pull_request,closed,,Use Airflow config in `SimpleAuthManager` instead of Flask app config,"The simple auth manager uses the Flask config to get the list of users. Since we are moving away from Flask and simple auth manager should work without Flask, I propose to use the Airflow config instead. That also makes us one step closer to have the simple auth manager no longer dependent on Flask appbuilder. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-18 21:17:33+00:00,[],2024-12-20 22:12:12+00:00,2024-12-20 22:12:10+00:00,https://github.com/apache/airflow/pull/45059,"[('kind:documentation', '')]",[],
2748710505,pull_request,closed,,Bugfix CI problems after PR 44744 to compile www assets,"Fixes broken canary in https://github.com/apache/airflow/actions/runs/12399970802/job/34616478712

as introduced by #44744
as alternative to #45057",jscheffl,2024-12-18 20:39:35+00:00,[],2024-12-18 21:43:40+00:00,2024-12-18 21:43:40+00:00,https://github.com/apache/airflow/pull/45058,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2552264812, 'issue_id': 2748710505, 'author': 'jscheffl', 'body': 'Okay, I _thought_ this is an easy fix... but it seems the pre-commit is also failing on a clean worktree - not an expert but smells like the yarn.lock is missing and needs to be added. But it is not generated so I can not add it.\r\n\r\nI propose to go rather the reversion route and then make it ""right"".', 'created_at': datetime.datetime(2024, 12, 18, 21, 4, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552284484, 'issue_id': 2748710505, 'author': 'jscheffl', 'body': 'Attempting another yarn.lock, maybe this fixes it...', 'created_at': datetime.datetime(2024, 12, 18, 21, 17, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552316076, 'issue_id': 2748710505, 'author': 'jscheffl', 'body': 'Okay, giving.up here :-(', 'created_at': datetime.datetime(2024, 12, 18, 21, 39, 35, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-18 21:04:22 UTC): Okay, I _thought_ this is an easy fix... but it seems the pre-commit is also failing on a clean worktree - not an expert but smells like the yarn.lock is missing and needs to be added. But it is not generated so I can not add it.

I propose to go rather the reversion route and then make it ""right"".

jscheffl (Issue Creator) on (2024-12-18 21:17:31 UTC): Attempting another yarn.lock, maybe this fixes it...

jscheffl (Issue Creator) on (2024-12-18 21:39:35 UTC): Okay, giving.up here :-(

"
2748690443,pull_request,closed,,"Revert ""AIP-79 Generate assets for Flask application in FAB provider""","Reverts apache/airflow#44744

Seems to be the ""quickest"" way to fix main, will re-open a PR to merge back again with full tests after

FYI @vincbeck 

Broken build: https://github.com/apache/airflow/actions/runs/12399970802/job/34616478712",jscheffl,2024-12-18 20:26:22+00:00,[],2025-01-11 19:43:09+00:00,2024-12-18 21:39:42+00:00,https://github.com/apache/airflow/pull/45057,"[('area:dev-tools', '')]","[{'comment_id': 2552221997, 'issue_id': 2748690443, 'author': 'jscheffl', 'body': 'Note: I#ll have another PR as fix in 5min, maybe that saves a reversion...', 'created_at': datetime.datetime(2024, 12, 18, 20, 36, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552230945, 'issue_id': 2748690443, 'author': 'jscheffl', 'body': 'I propose to close this in favor of #45058', 'created_at': datetime.datetime(2024, 12, 18, 20, 41, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552248656, 'issue_id': 2748690443, 'author': 'potiuk', 'body': 'Yep.', 'created_at': datetime.datetime(2024, 12, 18, 20, 53, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552265811, 'issue_id': 2748690443, 'author': 'jscheffl', 'body': 'Other PR as quick fix failed, so I change my opinion and would propose the reversion route. Then we can re-apply and check fully.', 'created_at': datetime.datetime(2024, 12, 18, 21, 5, 3, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-18 20:36:06 UTC): Note: I#ll have another PR as fix in 5min, maybe that saves a reversion...

jscheffl (Issue Creator) on (2024-12-18 20:41:55 UTC): I propose to close this in favor of #45058

potiuk on (2024-12-18 20:53:51 UTC): Yep.

jscheffl (Issue Creator) on (2024-12-18 21:05:03 UTC): Other PR as quick fix failed, so I change my opinion and would propose the reversion route. Then we can re-apply and check fully.

"
2748687263,pull_request,closed,,fix(security): disable automatic mounting of service account tokens,"Setting automountServiceAccountToken: true in a Kubernetes Pod's specification ensures that the pod automatically mounts a service account token, granting it access to the Kubernetes API. While this is necessary for applications that interact with the API, enabling this feature indiscriminately can introduce several security risks:

**Excessive Permissions**: By default, the mounted service account token may have broader permissions than the pod requires. If an attacker compromises the pod, they could exploit these permissions to perform unauthorized actions within the cluster. 

**Privilege Escalation**: A compromised pod with an automatically mounted service account token can interact with the Kubernetes API, potentially allowing an attacker to escalate privileges and gain control over additional cluster resources. 

**Increased Attack Surface**: Mounting the service account token into a pod's filesystem increases the pod's attack surface, making it more susceptible to security breaches. 

Best Practices:

Disable Automatic Mounting : Set automountServiceAccountToken: false for pods that do not require interaction with the Kubernetes API. This minimizes the risk by ensuring that only pods needing API access have the token mounted. ",gsingh935,2024-12-18 20:24:09+00:00,[],2025-02-09 00:16:29+00:00,2025-02-09 00:16:29+00:00,https://github.com/apache/airflow/pull/45056,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2629642437, 'issue_id': 2748687263, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 3, 0, 15, 41, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-02-03 00:15:41 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2748565453,pull_request,closed,,Add task logs across tries,"First part of https://github.com/apache/airflow/issues/44663 to see task logs across tries

More advanced filtering and formatting will be added later

<img width=""1345"" alt=""Screenshot 2024-12-18 at 2 09 07â€¯PM"" src=""https://github.com/user-attachments/assets/43f341ac-7041-4985-b530-082d059a4ada"" />



---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-18 19:13:43+00:00,[],2024-12-19 15:59:53+00:00,2024-12-18 20:55:57+00:00,https://github.com/apache/airflow/pull/45054,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2552133884, 'issue_id': 2748565453, 'author': 'jscheffl', 'body': 'I assume unrelated to this PR but on the task there is a `NaN` displayed for duration when it is still running:\r\n![image](https://github.com/user-attachments/assets/eae0d4b6-d761-40b2-ac5f-9ec739d48662)\r\n(Did not know that there is a plural form of `NaN` existing. :-D )', 'created_at': datetime.datetime(2024, 12, 18, 19, 43, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552251353, 'issue_id': 2748565453, 'author': 'bbovenzi', 'body': 'Yes I can add autorefresh and fix the duration in other PRs', 'created_at': datetime.datetime(2024, 12, 18, 20, 55, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2554792285, 'issue_id': 2748565453, 'author': 'tirkarthi', 'body': '@bbovenzi @jscheffl   I have a PR open to handle NaN across API calls and in UI for running dagruns and task instance. Happy to know your thoughts. https://github.com/apache/airflow/pull/44989', 'created_at': datetime.datetime(2024, 12, 19, 15, 59, 51, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-18 19:43:23 UTC): I assume unrelated to this PR but on the task there is a `NaN` displayed for duration when it is still running:
![image](https://github.com/user-attachments/assets/eae0d4b6-d761-40b2-ac5f-9ec739d48662)
(Did not know that there is a plural form of `NaN` existing. :-D )

bbovenzi (Issue Creator) on (2024-12-18 20:55:47 UTC): Yes I can add autorefresh and fix the duration in other PRs

tirkarthi on (2024-12-19 15:59:51 UTC): @bbovenzi @jscheffl   I have a PR open to handle NaN across API calls and in UI for running dagruns and task instance. Happy to know your thoughts. https://github.com/apache/airflow/pull/44989

"
2748478077,pull_request,closed,,fix: Get the pid of xcom command dynamically,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

fix: #45047

When [share process namespace](https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/) is set, the pid will never be 1, thus failing to execute kill command of xcom sidecar container, so we need to get the pid dynamically using `pgrep`.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Laerte,2024-12-18 18:26:44+00:00,[],2024-12-18 21:50:59+00:00,2024-12-18 21:46:20+00:00,https://github.com/apache/airflow/pull/45053,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2552000753, 'issue_id': 2748478077, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 18, 18, 26, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552325086, 'issue_id': 2748478077, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 18, 21, 46, 22, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-18 18:26:48 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-12-18 21:46:22 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2748445922,pull_request,closed,,Add MessageDeduplicationId support to AWS SqsPublishOperator,"Closes : #44876

Currently, the `SqsPublishOperator` in Airflow does not support the `MessageDeduplicationId` parameter for deduplication of messages sent to AWS SQS FIFO queues. Users are forced to rely solely on `ContentBasedDeduplication`, which may not be suitable for all scenarios. 

This PR aims to add support for `MessageDeduplicationId ` and test for deduplication to provide more flexibility and control over message deduplication.

(https://boto3.amazonaws.com/v1/documentation/api/1.35.6/reference/services/sqs/client/send_message.html))


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2024-12-18 18:07:18+00:00,[],2025-01-07 10:06:27+00:00,2025-01-07 10:06:27+00:00,https://github.com/apache/airflow/pull/45051,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2558316240, 'issue_id': 2748445922, 'author': 'Prab-27', 'body': '> Needs also a test for the success scenario. You can add the needed changes to `test_execute_success` or write a separated test if needed\r\n\r\nDone!', 'created_at': datetime.datetime(2024, 12, 22, 3, 28, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573388680, 'issue_id': 2748445922, 'author': 'vincbeck', 'body': '@eladkal ?', 'created_at': datetime.datetime(2025, 1, 6, 15, 49, 24, tzinfo=datetime.timezone.utc)}]","Prab-27 (Issue Creator) on (2024-12-22 03:28:38 UTC): Done!

vincbeck on (2025-01-06 15:49:24 UTC): @eladkal ?

"
2748316084,pull_request,closed,,Add clear dag run list action,"Only the last commit is relevant, this is build on top of https://github.com/apache/airflow/pull/45039, and add the 'clear run' list action on the dag run list:

![Screenshot 2024-12-18 at 17 54 28](https://github.com/user-attachments/assets/2b4b7c67-754f-480c-bc52-9a01e39fb244)
",pierrejeambrun,2024-12-18 16:54:36+00:00,['pierrejeambrun'],2024-12-19 15:55:39+00:00,2024-12-19 15:55:37+00:00,https://github.com/apache/airflow/pull/45045,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2748273850,pull_request,closed,,Avoid 1.1.8 version of msgraph-core,"The 1.1.8 version of msgraph-core is buggy - importing some basic classes causes import error ""ABCMeta"" is not subscriptable.

We are removing the version from azure provider dependencies hoping that it will be fixed in the next version.

https://github.com/microsoftgraph/msgraph-sdk-python-core/issues/781

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-18 16:33:48+00:00,[],2024-12-18 22:58:26+00:00,2024-12-18 16:36:45+00:00,https://github.com/apache/airflow/pull/45044,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2748254696,pull_request,closed,,AIP-72: Allow retrieving Connection from Task Context,"part of https://github.com/apache/airflow/issues/44481

- Added a minimal Connection user-facing object in Task SDK definition for use in the DAG file
- Added logic to get Connections in the context. Fixed some bugs in the way related to Connection parsing/serializing!


Now, we have following Connection related objects:
- `ConnectionResponse` is auto-generated and tightly coupled with the API schema.
- `ConnectionResult` is runtime-specific and meant for internal communication between Supervisor & Task Runner.
- `Connection` class here is where the public-facing, user-relevant aspects are exposed, hiding internal details.

**Next up**:

- Same for XCom & Variable
- Implementation of BaseHook.get_conn

Tested it with a DAG:

<img width=""1711"" alt=""image"" src=""https://github.com/user-attachments/assets/14d28fb7-f6c5-4fbe-b226-46873af2d0f3"" />

DAG:

```py
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow.models.dag import dag


class CustomOperator(BaseOperator):
    def execute(self, context):
        import os
        os.environ[""AIRFLOW_CONN_AIRFLOW_DB""] = ""sqlite:///home/airflow/airflow.db""
        task_id = context[""task_instance""].task_id
        print(f""Hello World {task_id}!"")
        print(context)
        print(context[""conn""].airflow_db)
        assert context[""conn""].airflow_db.conn_id == ""airflow_db""


@dag()
def super_basic_run():
    CustomOperator(task_id=""hello"")


super_basic_run()

```

For case where a **connection is not found**

<img width=""1435"" alt=""image"" src=""https://github.com/user-attachments/assets/7c5e0cb4-6ed4-41aa-9a57-e5641adce954"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-18 16:25:06+00:00,[],2024-12-19 09:51:14+00:00,2024-12-19 09:51:13+00:00,https://github.com/apache/airflow/pull/45043,"[('area:task-sdk', None)]",[],
2748217491,pull_request,closed,,Prepare docs for Nov 1st wave of providers Dec 2024,,eladkal,2024-12-18 16:08:00+00:00,[],2024-12-20 17:34:49+00:00,2024-12-20 17:34:45+00:00,https://github.com/apache/airflow/pull/45042,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:apache-kafka', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-beam', ''), ('provider:apache-livy', ''), ('provider:apache-drill', ''), ('provider:apache-cassandra', ''), ('provider:apache-flink', ''), ('provider:apache-hdfs', ''), ('provider:apache-kylin', ''), ('provider:apache-impala', ''), ('provider:apache-iceberg', '')]",[],
2748213860,pull_request,closed,,"Bump hatch version in breeze and prevent ""get-workflow-info"" failure","We enabled dependabot to bump dependencies for various Python requirements we have in Airflow and it found out that we have pretty out-dated hatch - pinned because of metadata stability when building packages. The update caused ""get-workflow-info"" step in CI to fail because the ""get-workflow-info"" commmand contained output from uv upgrading breeze while it was running.

This PR bumps the version manually to the latest version, also it sets `SKIP_BREEZE_SELF_UPGRADE_CHECK` variable to true in the `get-workflow-info` step - to prevent breeze from checking and automatically upgrading itself.

This will not make future dependabot PRs to succeed, because those PRs will not update hash of README file - so the PRs will fail at the pre-commit stage, but at least it will be clear what should be done to fix it.

Also a bit of cleanup has been done opportunistically:

* the TODO on flit automation can now be removed as we have
  dependabot taking care about it automatically in both places
  that we were supposed to automate

* the importlib_resources exclusions were only used for Python
  < 3.9 and we are now >= 3.0 so we can remove it

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-18 16:06:18+00:00,[],2024-12-18 23:21:33+00:00,2024-12-18 16:37:11+00:00,https://github.com/apache/airflow/pull/45041,"[('area:dev-tools', '')]",[],
2748212215,pull_request,closed,,Upgrade cryptography package to fix vulnerable OpenSSL,"Upgrade cryptography package to fix vulnerable OpenSSL

https://github.com/advisories/GHSA-h4gh-qq45-vh27",gsingh935,2024-12-18 16:05:34+00:00,[],2024-12-19 00:12:01+00:00,2024-12-18 18:53:06+00:00,https://github.com/apache/airflow/pull/45040,"[('area:dev-tools', '')]","[{'comment_id': 2551718588, 'issue_id': 2748212215, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 18, 16, 5, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552046768, 'issue_id': 2748212215, 'author': 'potiuk', 'body': 'BTW. That issue picked my interest - and I looked closely - it seems that the ""constraint"" cryptography is held by yandexcloud - and I created an issue for them to address it https://github.com/yandex-cloud/python-sdk/issues/131 \r\n\r\nI think it\'s an important one and we should even consider suspending Yandexcloud if they cannot lift the limitation. But FYI @gsingh935 -> if you are not using yandexcloud, you are absolutely free to upgrade cryptography on your own. Our constraints are just constraints, not requirements, and if you think you should upgrade a dependency for whatever reason and airflow does not ""hold"" the dependency as a requirement - you are on your own to do it, we are not preventing it, you just need to make sure to test if it will work for you.', 'created_at': datetime.datetime(2024, 12, 18, 18, 52, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552047485, 'issue_id': 2748212215, 'author': 'potiuk', 'body': 'I am closing this issue as this was really wrongly addressing the issue.', 'created_at': datetime.datetime(2024, 12, 18, 18, 53, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552166529, 'issue_id': 2748212215, 'author': 'gsingh935', 'body': '@potiuk - seems like the cryptography version for yandex-cloud has already been bumped to 43.0.1 which should address the issue.\r\nhttps://github.com/yandex-cloud/python-sdk/pull/127/files', 'created_at': datetime.datetime(2024, 12, 18, 20, 2, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552507296, 'issue_id': 2748212215, 'author': 'pierrejeambrun', 'body': 'I should have looked closer.  Thanks for checking @potiuk', 'created_at': datetime.datetime(2024, 12, 19, 0, 11, 59, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-18 16:05:38 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-12-18 18:52:42 UTC): BTW. That issue picked my interest - and I looked closely - it seems that the ""constraint"" cryptography is held by yandexcloud - and I created an issue for them to address it https://github.com/yandex-cloud/python-sdk/issues/131 

I think it's an important one and we should even consider suspending Yandexcloud if they cannot lift the limitation. But FYI @gsingh935 -> if you are not using yandexcloud, you are absolutely free to upgrade cryptography on your own. Our constraints are just constraints, not requirements, and if you think you should upgrade a dependency for whatever reason and airflow does not ""hold"" the dependency as a requirement - you are on your own to do it, we are not preventing it, you just need to make sure to test if it will work for you.

potiuk on (2024-12-18 18:53:06 UTC): I am closing this issue as this was really wrongly addressing the issue.

gsingh935 (Issue Creator) on (2024-12-18 20:02:36 UTC): @potiuk - seems like the cryptography version for yandex-cloud has already been bumped to 43.0.1 which should address the issue.
https://github.com/yandex-cloud/python-sdk/pull/127/files

pierrejeambrun on (2024-12-19 00:11:59 UTC): I should have looked closer.  Thanks for checking @potiuk

"
2748190439,pull_request,closed,,Add clear dag run to UI,"Add the clear dag run button for all tasks and only failed ones.

Closes:
https://github.com/apache/airflow/issues/44859

I'll follow up by adding the capabilities to add / update the note of the run when clearing it.

![Screenshot 2024-12-19 at 15 00 56](https://github.com/user-attachments/assets/af9690a1-1fb0-4e21-8b91-f38cea9c738d)

![Screenshot 2024-12-19 at 15 01 18](https://github.com/user-attachments/assets/ba5db1eb-b7e8-4322-9c23-10c10291286b)

![Screenshot 2024-12-19 at 15 02 13](https://github.com/user-attachments/assets/859a053c-c383-4099-bd36-f7d42a92f239)
",pierrejeambrun,2024-12-18 15:55:36+00:00,[],2024-12-19 15:39:44+00:00,2024-12-19 14:15:27+00:00,https://github.com/apache/airflow/pull/45039,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2554164315, 'issue_id': 2748190439, 'author': 'pierrejeambrun', 'body': 'Comments addressed, screenshot updated.', 'created_at': datetime.datetime(2024, 12, 19, 14, 2, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2554685973, 'issue_id': 2748190439, 'author': 'jscheffl', 'body': 'Cool!', 'created_at': datetime.datetime(2024, 12, 19, 15, 39, 43, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-12-19 14:02:40 UTC): Comments addressed, screenshot updated.

jscheffl on (2024-12-19 15:39:43 UTC): Cool!

"
2748180131,pull_request,closed,,Add support for custom celery configs,"closes: https://github.com/apache/airflow/issues/45037

Description:
Currently Airflow support limited celery options only. This PR adds the support for the additional celery config for celery workers.

1. Changes are completely backward compatible
2. No test cases found for these changes
3. If the config is not available then default value of {} is taken which will be same as earlier only
4. If config is available then it will be added to the celery config and applied to celery workers.",arorasachin9,2024-12-18 15:51:36+00:00,[],2024-12-23 13:53:06+00:00,2024-12-23 13:53:03+00:00,https://github.com/apache/airflow/pull/45038,"[('area:providers', ''), ('provider:celery', '')]","[{'comment_id': 2551685313, 'issue_id': 2748180131, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 18, 15, 51, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552018732, 'issue_id': 2748180131, 'author': 'arorasachin9', 'body': 'Addressed the comments. CI is failing not able to debug why CI pipeline is failing.', 'created_at': datetime.datetime(2024, 12, 18, 18, 36, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552098384, 'issue_id': 2748180131, 'author': 'jscheffl', 'body': 'Except some minor comment I think it is good, let me check what is broken on CI. Nothing related to your code.\r\nIgnore that it is ""red"" atm, will be better once you push the next change on the PR.\r\n\r\nThen I think... LGTM!', 'created_at': datetime.datetime(2024, 12, 18, 19, 22, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2558527410, 'issue_id': 2748180131, 'author': 'jscheffl', 'body': ""Somthing is wrong with this PR and CI - I don't see the reason but I am very sure it is not related to the changes. I am on it..."", 'created_at': datetime.datetime(2024, 12, 22, 17, 24, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559299528, 'issue_id': 2748180131, 'author': 'arorasachin9', 'body': '@jscheffl I have fixed the unit test. The CI is passing. and Thanks for the help in dubuging the CI issue.', 'created_at': datetime.datetime(2024, 12, 23, 9, 33, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559750663, 'issue_id': 2748180131, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 23, 13, 53, 5, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-18 15:51:42 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

arorasachin9 (Issue Creator) on (2024-12-18 18:36:58 UTC): Addressed the comments. CI is failing not able to debug why CI pipeline is failing.

jscheffl on (2024-12-18 19:22:18 UTC): Except some minor comment I think it is good, let me check what is broken on CI. Nothing related to your code.
Ignore that it is ""red"" atm, will be better once you push the next change on the PR.

Then I think... LGTM!

jscheffl on (2024-12-22 17:24:06 UTC): Somthing is wrong with this PR and CI - I don't see the reason but I am very sure it is not related to the changes. I am on it...

arorasachin9 (Issue Creator) on (2024-12-23 09:33:54 UTC): @jscheffl I have fixed the unit test. The CI is passing. and Thanks for the help in dubuging the CI issue.

boring-cyborg[bot] on (2024-12-23 13:53:05 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2748091124,pull_request,closed,,"Revert ""Added job_clusters as a templated parameter to CreateDatabricksWorkflowOperator""",Reverts apache/airflow#45022,kunaljubce,2024-12-18 15:16:02+00:00,[],2024-12-18 15:51:29+00:00,2024-12-18 15:51:28+00:00,https://github.com/apache/airflow/pull/45035,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2551604338, 'issue_id': 2748091124, 'author': 'amoghrajesh', 'body': 'While necessary to unblock main, doesnt look like it can cause the errors. Lets try a retrigger or we can merge this', 'created_at': datetime.datetime(2024, 12, 18, 15, 22, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551622132, 'issue_id': 2748091124, 'author': 'kunaljubce', 'body': '@amoghrajesh Retrigger as in retrigger the failed workflow?', 'created_at': datetime.datetime(2024, 12, 18, 15, 29, 43, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2024-12-18 15:22:14 UTC): While necessary to unblock main, doesnt look like it can cause the errors. Lets try a retrigger or we can merge this

kunaljubce (Issue Creator) on (2024-12-18 15:29:43 UTC): @amoghrajesh Retrigger as in retrigger the failed workflow?

"
2747935762,pull_request,closed,,Update Example URL in YDB docs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fix YDB Example URL after changing providers folder structure

<!-- Please keep an empty line above the dashes. -->
---

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vgvoleg,2024-12-18 14:12:28+00:00,[],2024-12-19 08:50:21+00:00,2024-12-19 08:50:21+00:00,https://github.com/apache/airflow/pull/45033,"[('area:providers', ''), ('kind:documentation', ''), ('provider:ydb', '')]",[],
2747814763,pull_request,closed,,Add failure test to Edge integration test,"I realized that the Edge Executor / Worker missed to have some failure tests in the intergation test DAG.

This PR adds some tasks with failure and retry to also cover these cases.

The DAG test graph now looks like:
![image](https://github.com/user-attachments/assets/29c7bb10-c837-4169-8348-a27ad344c8e7)


FYI @AutomationDev85 ",jscheffl,2024-12-18 13:25:49+00:00,[],2024-12-18 17:40:16+00:00,2024-12-18 17:40:16+00:00,https://github.com/apache/airflow/pull/45031,"[('area:providers', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2747754107,pull_request,closed,,"Fix type of ""moment"" when running an e2e example for deferred TI","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

While trying to run an e2e example of a task that defers and then launches a trigger:
```
from airflow import DAG

from airflow.providers.standard.sensors.date_time import DateTimeSensorAsync
from airflow.utils import timezone
import datetime

with DAG(
    dag_id=""demo_deferred"",
    schedule=None,
    catchup=False,
) as dag:
    DateTimeSensorAsync(
            task_id=""async"",
            target_time=str(timezone.utcnow() + datetime.timedelta(seconds=3)),
            poke_interval=60,
            timeout=600,
        )
```

I realised that the ""moment"" inside ""trigger_kwargs"" is of `pendulum.DateTime` type, and since we have a ""dict[str, ANY]`, defined here: https://github.com/apache/airflow/blob/main/airflow/api_fastapi/execution_api/datamodels/taskinstance.py#L82
 
on its datamodel (we cant really have a `UtcDateTime` for one specific field, like we do [here](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/execution_api/datamodels/taskinstance.py#L57C15-L57C26)), it fails to match the type defined in the `Trigger` table which is datetime. 

So, I have added a ""before"" validator that checks for the type being string and if it is a string, translates it to a datetime object. 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-18 12:59:21+00:00,[],2024-12-18 17:40:42+00:00,2024-12-18 17:40:40+00:00,https://github.com/apache/airflow/pull/45030,[],"[{'comment_id': 2551528043, 'issue_id': 2747754107, 'author': 'amoghrajesh', 'body': 'Simplifies it better now. This is a working example:\r\n```\r\nclass A(BaseModel):\r\n    """"""Schema for updating TaskInstance to a deferred state.""""""\r\n    trigger_kwargs: Annotated[dict[str, Any], Field(default_factory=dict)]\r\n    @field_validator(""trigger_kwargs"")\r\n    def validate_moment(cls, v):\r\n        if ""moment"" in v:\r\n            v[""moment""] = AwareDatetimeAdapter.validate_strings(v[""moment""])\r\n        return v\r\n\r\nA(trigger_kwargs={""key"": ""value"", ""moment"": ""2024-12-18T00:00:00Z""})\r\nOut[27]: A(trigger_kwargs={\'key\': \'value\', \'moment\': datetime.datetime(2024, 12, 18, 0, 0, tzinfo=TzInfo(UTC))})\r\nA(trigger_kwargs={""key"": ""value"", ""moment"": ""2024-12-18T00:00:00""})\r\nTraceback (most recent call last):\r\n  File ""/Users/amoghdesai/Documents/OSS/airflow/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3550, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File ""<ipython-input-28-ec6c9f9d0fce>"", line 1, in <module>\r\n    A(trigger_kwargs={""key"": ""value"", ""moment"": ""2024-12-18T00:00:00""})\r\n  File ""/Users/amoghdesai/Documents/OSS/airflow/.venv/lib/python3.9/site-packages/pydantic/main.py"", line 214, in __init__\r\n    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\r\npydantic_core._pydantic_core.ValidationError: 1 validation error for A\r\ntrigger_kwargs\r\n  Input should have timezone info [type=timezone_aware, input_value=\'2024-12-18T00:00:00\', input_type=str]\r\n    For further information visit https://errors.pydantic.dev/2.10/v/timezone_aware\r\n```', 'created_at': datetime.datetime(2024, 12, 18, 14, 54, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-18 14:54:00 UTC): Simplifies it better now. This is a working example:
```
class A(BaseModel):
    """"""Schema for updating TaskInstance to a deferred state.""""""
    trigger_kwargs: Annotated[dict[str, Any], Field(default_factory=dict)]
    @field_validator(""trigger_kwargs"")
    def validate_moment(cls, v):
        if ""moment"" in v:
            v[""moment""] = AwareDatetimeAdapter.validate_strings(v[""moment""])
        return v

A(trigger_kwargs={""key"": ""value"", ""moment"": ""2024-12-18T00:00:00Z""})
Out[27]: A(trigger_kwargs={'key': 'value', 'moment': datetime.datetime(2024, 12, 18, 0, 0, tzinfo=TzInfo(UTC))})
A(trigger_kwargs={""key"": ""value"", ""moment"": ""2024-12-18T00:00:00""})
Traceback (most recent call last):
  File ""/Users/amoghdesai/Documents/OSS/airflow/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py"", line 3550, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-28-ec6c9f9d0fce>"", line 1, in <module>
    A(trigger_kwargs={""key"": ""value"", ""moment"": ""2024-12-18T00:00:00""})
  File ""/Users/amoghdesai/Documents/OSS/airflow/.venv/lib/python3.9/site-packages/pydantic/main.py"", line 214, in __init__
    validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
pydantic_core._pydantic_core.ValidationError: 1 validation error for A
trigger_kwargs
  Input should have timezone info [type=timezone_aware, input_value='2024-12-18T00:00:00', input_type=str]
    For further information visit https://errors.pydantic.dev/2.10/v/timezone_aware
```

"
2747657916,pull_request,closed,,Fix DB isolation tests on v2-10-test,"Unfortunately in #45021 I over-looked and left one failure in pytests.
With this v2-10-test should be green again.",jscheffl,2024-12-18 12:16:27+00:00,[],2024-12-18 13:27:12+00:00,2024-12-18 13:27:12+00:00,https://github.com/apache/airflow/pull/45029,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2747631507,pull_request,closed,,Implement Asset.ref for name or URI references,"This allows us to refer to an asset without needing the original object, making it easier to schedule against an asset.

I also added some minor improvements to `register_asset_change` so we can save a db query or the asset-model conversion in some cases.

There are a couple of possible sytax designs available:

```python
# Magic constructor.
AssetRef(name=""asset-1"")
AssetRef(uri=""s3://bucket/assets/1"")

# Magic factory method on Asset.
Asset.ref(name=""asset-1"")
Asset.ref(uri=""s3://bucket/assets/1"")
```

Iâ€™m opting for the second one with a factory method since it is easier to implement, but we can discuss which one we like better.",uranusjr,2024-12-18 12:03:56+00:00,[],2024-12-26 06:59:08+00:00,2024-12-26 06:59:06+00:00,https://github.com/apache/airflow/pull/45028,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('AIP-75', 'Asset-Centric Syntax'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-sdk', None)]",[],
2747587861,pull_request,closed,,Implement AlloyDB operators: create/update/delete clusters,"Introduce the first batch of operators for Google Cloud AlloyDB service:
- `AlloyDBCreateClusterOperator`
- `AlloyDBUpdateClusterOperator`
- `AlloyDBDeleteClusterOperator`
",moiseenkov,2024-12-18 11:43:11+00:00,[],2024-12-19 11:15:03+00:00,2024-12-19 11:15:03+00:00,https://github.com/apache/airflow/pull/45027,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2553449999, 'issue_id': 2747587861, 'author': 'potiuk', 'body': 'random issue.', 'created_at': datetime.datetime(2024, 12, 19, 11, 14, 59, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-19 11:14:59 UTC): random issue.

"
2747475842,pull_request,open,,Adding functionality to return export ARN for point in time export in DynamoDBToS3Operator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #28830 https://github.com/apache/airflow/issues/28830

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Enable DynamoDbToS3Operator to return point in time export ARN to x_com to be used by downstream tasks
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",tssahota,2024-12-18 10:52:07+00:00,[],2025-01-14 18:28:44+00:00,,https://github.com/apache/airflow/pull/45025,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2551001484, 'issue_id': 2747475842, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 18, 10, 52, 30, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-18 10:52:30 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2747320528,pull_request,closed,,Fix clear dagrun endpoint,"During the development of the associated frontend I noticed that this endpoint wasn't working properly.

There was a small difference introduced compared to the legacy implementation, tasks were not cleared for some dags.",pierrejeambrun,2024-12-18 09:46:13+00:00,['pierrejeambrun'],2024-12-18 11:29:40+00:00,2024-12-18 11:29:38+00:00,https://github.com/apache/airflow/pull/45024,[],"[{'comment_id': 2550901291, 'issue_id': 2747320528, 'author': 'eladkal', 'body': 'We also plan some refactor for clear https://github.com/apache/airflow/issues/44867#issuecomment-2548587582', 'created_at': datetime.datetime(2024, 12, 18, 10, 4, 52, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-12-18 10:04:52 UTC): We also plan some refactor for clear https://github.com/apache/airflow/issues/44867#issuecomment-2548587582

"
2747265747,pull_request,closed,,Fix DataflowJobLink for Beam operators in deferrable mode,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have fixed `DataflowJobLink` in deferrable mode for `BeamRunPythonPipelineOperator` and `BeamRunJavaPipelineOperator`

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-12-18 09:23:49+00:00,[],2024-12-21 20:03:59+00:00,2024-12-21 20:03:59+00:00,https://github.com/apache/airflow/pull/45023,"[('area:providers', ''), ('provider:apache-beam', '')]",[],
2747206584,pull_request,closed,,Added job_clusters as a templated parameter to CreateDatabricksWorkflowOperator,"Fixes #42438

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-12-18 08:59:13+00:00,[],2024-12-18 13:30:03+00:00,2024-12-18 13:30:03+00:00,https://github.com/apache/airflow/pull/45022,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2551043674, 'issue_id': 2747206584, 'author': 'kunaljubce', 'body': '@pankajkoti The scope of #42438 fix seems to be very small. Can you please review and let me know if I am missing anything?', 'created_at': datetime.datetime(2024, 12, 18, 11, 13, 9, tzinfo=datetime.timezone.utc)}]","kunaljubce (Issue Creator) on (2024-12-18 11:13:09 UTC): @pankajkoti The scope of #42438 fix seems to be very small. Can you please review and let me know if I am missing anything?

"
2747081911,pull_request,closed,,Fix DB isolation tests on v2-10-test,"I failed in backporting to v2-10-test, but in both PRs some else ""falls apart"".

This PR fixes DB Isolation test reported as ""failed"" from a test CI run in https://github.com/apache/airflow/actions/runs/12388030828/job/34578488895

From my point of view the tests are OK in general but just test are broken in DB isolation mode. Seems not really being a harm in 2.10.4.",jscheffl,2024-12-18 08:01:09+00:00,[],2024-12-18 14:32:30+00:00,2024-12-18 09:05:14+00:00,https://github.com/apache/airflow/pull/45021,[],"[{'comment_id': 2551234443, 'issue_id': 2747081911, 'author': 'shahar1', 'body': 'Thanks :)', 'created_at': datetime.datetime(2024, 12, 18, 12, 45, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551472820, 'issue_id': 2747081911, 'author': 'potiuk', 'body': 'nice!', 'created_at': datetime.datetime(2024, 12, 18, 14, 32, 28, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-12-18 12:45:32 UTC): Thanks :)

potiuk on (2024-12-18 14:32:28 UTC): nice!

"
2747017286,pull_request,closed,,Add BigQuery job link,"This pull request introduces a new helper class for constructing BigQuery Job Detail Links and integrates it into the existing BigQuery operators and links in the Google Cloud provider for Airflow. The most important changes include the addition of the `BigQueryJobDetailLink` class, its integration into the `BigQueryInsertJobOperator`, and the necessary imports and configurations.

New feature addition:

* Added `BIGQUERY_JOB_DETAIL_LINK` constant to construct URLs for BigQuery Job Detail Links in `airflow/providers/google/cloud/links/bigquery.py`.
* Created `BigQueryJobDetailLink` class to handle the construction and persistence of BigQuery Job Detail Links in `airflow/providers/google/cloud/links/bigquery.py`.

Integration into existing operators:

* Imported `BigQueryJobDetailLink` in `airflow/providers/google/cloud/operators/bigquery.py` to make it available for use in BigQuery operators.
* Updated `operator_extra_links` in `BigQueryInsertJobOperator` to include `BigQueryJobDetailLink` in `airflow/providers/google/cloud/operators/bigquery.py`.
* Added logic to persist BigQuery Job Detail Links in the `execute` method of `BigQueryInsertJobOperator` in `airflow/providers/google/cloud/operators/bigquery.py`.

Configuration update:

* Added `BigQueryJobDetailLink` to the `extra-links` section in `airflow/providers/google/provider.yaml` to ensure it is recognized as an extra link.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",nakamura1878,2024-12-18 07:27:29+00:00,[],2024-12-26 18:44:21+00:00,2024-12-26 17:30:02+00:00,https://github.com/apache/airflow/pull/45020,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('type:new-feature', 'Changelog: New Features')]","[{'comment_id': 2550555845, 'issue_id': 2747017286, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 18, 7, 27, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562973420, 'issue_id': 2747017286, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 26, 17, 30, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562975113, 'issue_id': 2747017286, 'author': 'shahar1', 'body': ""@nakamura1878  Woops, only now I noticed that this PR was targeted at `v2-10-test` - PRs for providers should target the `main` branch.\r\nI'll take care of reverting this PR on `v2-10-test` and porting it to `main`."", 'created_at': datetime.datetime(2024, 12, 26, 17, 32, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562976269, 'issue_id': 2747017286, 'author': 'potiuk', 'body': ""> @nakamura1878 Woops, only now I noticed that this PR was targeted at v2-10-test - PRs for providers should target the main branch.\r\nI'll take care of reverting this PR on v2-10-test and porting it to main.\r\n\r\nYep - we could do it, but we could also bring it to main (forward-port :) ) without reverting - there is no big harm in getting it in."", 'created_at': datetime.datetime(2024, 12, 26, 17, 34, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562976612, 'issue_id': 2747017286, 'author': 'jscheffl', 'body': 'I also just noticed it was on the ""wrong"" branch - but only because I had a test on v2-10-test running that was cancelled due to the merge.', 'created_at': datetime.datetime(2024, 12, 26, 17, 35, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562979998, 'issue_id': 2747017286, 'author': 'shahar1', 'body': '> I also just noticed it was on the ""wrong"" branch - but only because I had a test on v2-10-test running that was cancelled due to the merge.\r\n\r\nApologies for that :)\r\n@potiuk fair enough. Is there any stance about removing the providers from `v2-10-test` to avoid such confusion? I assume that it hasn\'t been done until now for a reason, not sure what though considering that we continue maintaining them in `main`.', 'created_at': datetime.datetime(2024, 12, 26, 17, 40, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562982517, 'issue_id': 2747017286, 'author': 'jscheffl', 'body': '> > I also just noticed it was on the ""wrong"" branch - but only because I had a test on v2-10-test running that was cancelled due to the merge.\r\n> \r\n> Apologies for that :) @potiuk fair enough. Is there any stance about removing the providers from `v2-10-test` to avoid such confusion? I assume that it hasn\'t been done until now for a reason, not sure what though considering that we continue maintaining them in `main`.\r\n\r\nNo we just keep them here. Would be ""too much"" cleanup and CI has still a lot of dependencies and cross-checks.', 'created_at': datetime.datetime(2024, 12, 26, 17, 43, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563020013, 'issue_id': 2747017286, 'author': 'potiuk', 'body': '> > > I also just noticed it was on the ""wrong"" branch - but only because I had a test on v2-10-test running that was cancelled due to the merge.\r\n> > \r\n> > \r\n> > Apologies for that :) @potiuk fair enough. Is there any stance about removing the providers from `v2-10-test` to avoid such confusion? I assume that it hasn\'t been done until now for a reason, not sure what though considering that we continue maintaining them in `main`.\r\n> \r\n> No we just keep them here. Would be ""too much"" cleanup and CI has still a lot of dependencies and cross-checks.\r\n\r\nActually it could be possible eventually. We have been removing all the ""remnants"" of provider tests from CI and I think with some future refactoring of providers into separate projects (working on it) - it could be possible eventually. I might attempt it as part of https://github.com/apache/airflow/issues/42632 and after https://github.com/apache/airflow/issues/44511 is completed. \r\n\r\nFor now the remaining parts are: \r\n* ""airflow"" contains some tests that are expecting providers (executors and few others) as mentioned by @jscheffl \r\n* airflow ""editable"" build expects the ""extras"" to use provider\'s dependencies not providers itself (but that could be likely mitigated easily - and we could use the ""released"" providers in `v2-10-test`\r\n\r\nIt\'s actually quite likely that for Airflow 3 we will have ""non-providers"" code only in `v3-0-test`.', 'created_at': datetime.datetime(2024, 12, 26, 18, 44, 20, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-18 07:27:32 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-12-26 17:30:04 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

shahar1 on (2024-12-26 17:32:42 UTC): @nakamura1878  Woops, only now I noticed that this PR was targeted at `v2-10-test` - PRs for providers should target the `main` branch.
I'll take care of reverting this PR on `v2-10-test` and porting it to `main`.

potiuk on (2024-12-26 17:34:33 UTC): I'll take care of reverting this PR on v2-10-test and porting it to main.

Yep - we could do it, but we could also bring it to main (forward-port :) ) without reverting - there is no big harm in getting it in.

jscheffl on (2024-12-26 17:35:02 UTC): I also just noticed it was on the ""wrong"" branch - but only because I had a test on v2-10-test running that was cancelled due to the merge.

shahar1 on (2024-12-26 17:40:29 UTC): Apologies for that :)
@potiuk fair enough. Is there any stance about removing the providers from `v2-10-test` to avoid such confusion? I assume that it hasn't been done until now for a reason, not sure what though considering that we continue maintaining them in `main`.

jscheffl on (2024-12-26 17:43:56 UTC): No we just keep them here. Would be ""too much"" cleanup and CI has still a lot of dependencies and cross-checks.

potiuk on (2024-12-26 18:44:20 UTC): Actually it could be possible eventually. We have been removing all the ""remnants"" of provider tests from CI and I think with some future refactoring of providers into separate projects (working on it) - it could be possible eventually. I might attempt it as part of https://github.com/apache/airflow/issues/42632 and after https://github.com/apache/airflow/issues/44511 is completed. 

For now the remaining parts are: 
* ""airflow"" contains some tests that are expecting providers (executors and few others) as mentioned by @jscheffl 
* airflow ""editable"" build expects the ""extras"" to use provider's dependencies not providers itself (but that could be likely mitigated easily - and we could use the ""released"" providers in `v2-10-test`

It's actually quite likely that for Airflow 3 we will have ""non-providers"" code only in `v3-0-test`.

"
2746992080,pull_request,closed,,Upgrade v2-10-test dependencies,"I failed in backporting to v2-10-test, but in both PRs some else ""falls apart"".

This PR fixes depdencies reported as ""fixes needed"" from a test CI run in https://github.com/apache/airflow/actions/runs/12388030828/job/34578488895

(There might be more coming, let's see what other tests fail on v2-10-test)",jscheffl,2024-12-18 07:16:29+00:00,[],2025-01-28 12:16:22+00:00,2024-12-18 09:06:50+00:00,https://github.com/apache/airflow/pull/45019,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2550755713, 'issue_id': 2746992080, 'author': 'jscheffl', 'body': 'Merging, other DB isolation test is fixed in #45021', 'created_at': datetime.datetime(2024, 12, 18, 9, 6, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551334073, 'issue_id': 2746992080, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 12, 18, 13, 31, 9, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-12-18 09:06:44 UTC): Merging, other DB isolation test is fixed in #45021

potiuk on (2024-12-18 13:31:09 UTC): Nice!

"
2746952531,pull_request,closed,,Bump uv to 0.5.10,"https://pypi.org/project/uv/0.5.10/
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-18 06:55:48+00:00,[],2024-12-18 07:33:29+00:00,2024-12-18 07:33:28+00:00,https://github.com/apache/airflow/pull/45018,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2746943362,pull_request,closed,,Remove deprecated `DEFAULT_CELERY_CONFIG` from core config_templates,This default dict has been moved to the celery provider. We no longer need to support the old import in Airflow 3.,jedcunningham,2024-12-18 06:50:18+00:00,[],2024-12-18 14:04:16+00:00,2024-12-18 13:23:56+00:00,https://github.com/apache/airflow/pull/45017,[],[],
2746371965,pull_request,closed,,Team Based Configuration (AIP-67),"### PLEASE READ DESCRIPTION

Context: In the context of multi team airflow, teams will have their own configuration files for the components that run on team-only hosts (for workers, dag parsers, etc running on those hosts). However some team components must live along side one another on the scheduler host, namely executors, and some airflow configuration affecting teams must also be accessible to the scheduler.

This commit delivers the capability for airflow `conf` to load and allow access to multiple team configurations in addition to the main/global configuration we have today.

A new config is added `core.multi_team_configurations` (the name is not set in stone) in which teams and their associated configuration files are specified. E.g.:
```
path/to/team_a/config:team_a,different/path/team_b/configuration:team_b
```

Airflow conf, during initialization, loads each of these configurations and makes them accessible by id, e.g.: `conf.get(""core"", ""executor"", team_id=""team_a"")`

Within those team configurations, teams can specify the executors they would like to use and the associated configuration for those executors. Since each team configuration is loaded and stored separately, this allows multiple instances of the same executor to be configured.

The Base executor has been updated with a config shim to allow easier access to team based executor configations and the AWS ECS executor has been updated to use it as a proof of concept. Other executors will need to be updated to be ""multi team compliant"" at a later time to minimize the size and scope of this commit.

#### NOTE: There was an initial proposal to move to TOML format for Airflow config and store all configuration (both team and gloabl) in one file. This is still a possibility in the future, but the approach in this commit was decided for the following reasons:
1. It leverages the same configuration format as Airflow always had, so there is less barrier to entry and migration for users
2. It is a simpler implementation, which simplifies the overall process of releasing an initial version of multi-team airflow
3. Separate files for teams is actually a nice mechanism for management of the overall cluster. Teams can update their own files as they see fit and they only need to be synced onto the scheduler host for pickup, rather than the configuration changes needing to be made to a shared file which no team should be able to view (otherwise they would see the configuration from other teams).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-12-17 23:57:54+00:00,[],2025-02-09 00:16:30+00:00,2025-02-09 00:16:30+00:00,https://github.com/apache/airflow/pull/45016,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('aip-67', 'multi-team')]","[{'comment_id': 2550527270, 'issue_id': 2746371965, 'author': 'kaxil', 'body': 'Nice, should we convert it to a draft PR to avoid an accidental merge, since this is for 3.1', 'created_at': datetime.datetime(2024, 12, 18, 7, 9, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552277410, 'issue_id': 2746371965, 'author': 'o-nikolas', 'body': '> Nice, should we convert it to a draft PR to avoid an accidental merge, since this is for 3.1\r\n\r\n@kaxil \r\nI can update the PR to add more gating logic. Right now there is some in the executor loader, but I can add another one on the use of the `core.multi_team_configurations` config (such that users cannot enable multi team configurations).\r\n\r\nOtherwise it will be difficult to develop the rest of the features without the merging of this one. WDYT?', 'created_at': datetime.datetime(2024, 12, 18, 21, 12, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2632466959, 'issue_id': 2746371965, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 2, 4, 0, 14, 52, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-12-18 07:09:30 UTC): Nice, should we convert it to a draft PR to avoid an accidental merge, since this is for 3.1

o-nikolas (Issue Creator) on (2024-12-18 21:12:44 UTC): @kaxil 
I can update the PR to add more gating logic. Right now there is some in the executor loader, but I can add another one on the use of the `core.multi_team_configurations` config (such that users cannot enable multi team configurations).

Otherwise it will be difficult to develop the rest of the features without the merging of this one. WDYT?

github-actions[bot] on (2025-02-04 00:14:52 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2746214014,pull_request,closed,,Add missing newsfragment file for #44938,"newsfragement file missed part of this change #44938.
 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-17 22:17:44+00:00,[],2025-01-28 12:17:20+00:00,2024-12-17 22:41:43+00:00,https://github.com/apache/airflow/pull/45015,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2746167050,pull_request,closed,,Cleanup CI after Airflow 2.10.4 release,"Airflow 2.10.4 was released! Wohooo! Time to clean-up some leftovers:
- Make backcompat tests with 2.10.4 and not 2.10.3
- Add version reference in global constants
- Remove workaround for eval-type-backport because of Pydantic change",jscheffl,2024-12-17 21:55:14+00:00,[],2024-12-18 06:52:05+00:00,2024-12-18 06:52:05+00:00,https://github.com/apache/airflow/pull/45014,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]",[],
2746142796,pull_request,closed,,Make test_dms in AWS triggers skipped when no aiobotocore available,"In case aiobotocore is not installed (which might happen when the latest botocore is used) we should skip the test_dms test.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-17 21:40:25+00:00,[],2024-12-17 22:00:57+00:00,2024-12-17 22:00:55+00:00,https://github.com/apache/airflow/pull/45013,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2746073543,pull_request,closed,,Helm Chart: Add startupProbe to flower deployment,"Fixes a crash loop when the readinessProbe is not ready when the container is live.

closes: #44846 
",topherinternational,2024-12-17 21:11:35+00:00,[],2025-01-27 13:39:38+00:00,2025-01-27 13:39:38+00:00,https://github.com/apache/airflow/pull/45012,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2573058539, 'issue_id': 2746073543, 'author': 'topherinternational', 'body': '@amoghrajesh @romsharon98 any comment/review here?', 'created_at': datetime.datetime(2025, 1, 6, 12, 56, 52, tzinfo=datetime.timezone.utc)}]","topherinternational (Issue Creator) on (2025-01-06 12:56:52 UTC): @amoghrajesh @romsharon98 any comment/review here?

"
2746058366,pull_request,closed,,Remove `default_view` property from DAG class and model,"This doesn't make sense in the new UI in Airflow 3 anymore.

Relates to #43519
",ashb,2024-12-17 21:05:44+00:00,[],2025-01-11 19:45:17+00:00,2025-01-11 19:45:16+00:00,https://github.com/apache/airflow/pull/45011,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:db-migrations', 'PRs with DB migration'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2549629551, 'issue_id': 2746058366, 'author': 'ashb', 'body': '(Yes, this def needs a news fragment, and likely a rule in our Ruff checks)', 'created_at': datetime.datetime(2024, 12, 17, 21, 6, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2550732935, 'issue_id': 2746058366, 'author': 'ashb', 'body': 'cc @uranusjr @Lee-W (I think you are working on ruff rules)', 'created_at': datetime.datetime(2024, 12, 18, 8, 56, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551434351, 'issue_id': 2746058366, 'author': 'bbovenzi', 'body': 'Do we want to remove `dag_default_view` from the airflow config at the same time or in another PR?', 'created_at': datetime.datetime(2024, 12, 18, 14, 16, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551555070, 'issue_id': 2746058366, 'author': 'Lee-W', 'body': ""> cc @uranusjr @Lee-W (I think you are working on ruff rules)\r\n\r\nThanks for reminding us ðŸ™Œ I'll add a rule once merged"", 'created_at': datetime.datetime(2024, 12, 18, 15, 2, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563764618, 'issue_id': 2746058366, 'author': 'ashb', 'body': ""(If someone wants to finish this off before I'm back on week starting 6th January feel free.)"", 'created_at': datetime.datetime(2024, 12, 27, 14, 41, 43, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-12-17 21:06:12 UTC): (Yes, this def needs a news fragment, and likely a rule in our Ruff checks)

ashb (Issue Creator) on (2024-12-18 08:56:50 UTC): cc @uranusjr @Lee-W (I think you are working on ruff rules)

bbovenzi on (2024-12-18 14:16:02 UTC): Do we want to remove `dag_default_view` from the airflow config at the same time or in another PR?

Lee-W on (2024-12-18 15:02:18 UTC): Thanks for reminding us ðŸ™Œ I'll add a rule once merged

ashb (Issue Creator) on (2024-12-27 14:41:43 UTC): (If someone wants to finish this off before I'm back on week starting 6th January feel free.)

"
2746043891,pull_request,closed,,[v2-10-test] Bugfix some Doc urls in repo (#45007),"* Fix pre-commit doc URL

* Fix other broken URLs to GIT in docs
(cherry picked from commit 947c25d5e9d7bdfaf82bccf5bca58bac8c38daed)

Co-authored-by: Jens Scheffler <95105677+jscheffl@users.noreply.github.com>",github-actions[bot],2024-12-17 20:58:24+00:00,[],2025-01-11 19:43:11+00:00,2024-12-18 17:03:08+00:00,https://github.com/apache/airflow/pull/45010,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2549631055, 'issue_id': 2746043891, 'author': 'jscheffl', 'body': 'Re-building...', 'created_at': datetime.datetime(2024, 12, 17, 21, 6, 52, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-17 21:06:52 UTC): Re-building...

"
2746043609,pull_request,closed,,Add option in auth manager interface to define FastAPI api,"Resolves #44882 and #44847.

Today there is an option to extend the Flask Rest API in the auth manager interface. That allows, for instance, the FAB auth manager to extend the Rest API and define users, roles and permissions related APIs.

In Airflow 3, we are moving away from Flask and use FastApi as engine for APIs. As such, the auth manager interface should have an option to extend this API using FastAPI (instead of Flask).

In FAB auth manager, instead of converting all the APIs defined with Flask to FastAPI, we use `WSGIMiddleware` to embed a minimal Flask application that host the APIs.

With this PR: `GET http://localhost:29091/auth/auth/fab/v1/roles` return the list of roles. The duplicate `auth/auth` in the API path will be removed when the legacy Airflow 2 is gone.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-17 20:58:12+00:00,[],2024-12-20 23:19:46+00:00,2024-12-20 23:19:45+00:00,https://github.com/apache/airflow/pull/45009,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2557438555, 'issue_id': 2746043609, 'author': 'vincbeck', 'body': 'Tests are passing ðŸ¥³', 'created_at': datetime.datetime(2024, 12, 20, 17, 34, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557439192, 'issue_id': 2746043609, 'author': 'vincbeck', 'body': 'Let me know if you have more questions/concerns @jedcunningham', 'created_at': datetime.datetime(2024, 12, 20, 17, 35, 1, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-12-20 17:34:33 UTC): Tests are passing ðŸ¥³

vincbeck (Issue Creator) on (2024-12-20 17:35:01 UTC): Let me know if you have more questions/concerns @jedcunningham

"
2746009152,pull_request,closed,,AIP-72 Add Task Scheduling Metadata to TaskInstance,"This is a sugar topping to PR #44982:
It adds support for scheduling relevant task instance fields ""pool slots"", ""priority weight"" and ""queue"".

Note: Only the last commit of this PR is relevant, the branch builds on top of #44982 - will rebase once the other PR is merged.",jscheffl,2024-12-17 20:41:15+00:00,[],2025-01-12 20:14:03+00:00,2025-01-12 20:14:03+00:00,https://github.com/apache/airflow/pull/45008,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:providers', ''), ('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('AIP-69', 'Edge Executor'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2552431197, 'issue_id': 2746009152, 'author': 'ashb', 'body': ""Oh just notices this is a chained PR, I'll look at the base one instead."", 'created_at': datetime.datetime(2024, 12, 18, 23, 2, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585774328, 'issue_id': 2746009152, 'author': 'jscheffl', 'body': '@ashb @kaxil ...forgot to ""un-draft"", after the base has been merged, this would be the next small step.', 'created_at': datetime.datetime(2025, 1, 12, 15, 18, 16, tzinfo=datetime.timezone.utc)}]","ashb on (2024-12-18 23:02:39 UTC): Oh just notices this is a chained PR, I'll look at the base one instead.

jscheffl (Issue Creator) on (2025-01-12 15:18:16 UTC): @ashb @kaxil ...forgot to ""un-draft"", after the base has been merged, this would be the next small step.

"
2745887820,pull_request,closed,,Bugfix some Doc urls in repo,"While I was working on PR #44982 and hitting a pre-commit error I noticed that the link to the docs are outdated.

Went through the obvious links to contribution docs and updated ""some"" broken links with the correct URL as on main.

Does this need to be back-ported to v2-10-test branch?",jscheffl,2024-12-17 19:44:34+00:00,[],2024-12-17 20:58:27+00:00,2024-12-17 20:57:38+00:00,https://github.com/apache/airflow/pull/45007,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2549475963, 'issue_id': 2745887820, 'author': 'potiuk', 'body': '> Does this need to be back-ported to v2-10-test branch?\r\n\r\nWe can attempt to do it, but pretty much only release managers and people helping with backporting need to use breeze. The links in docker-stack might actually be useful though', 'created_at': datetime.datetime(2024, 12, 17, 19, 52, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549613734, 'issue_id': 2745887820, 'author': 'jscheffl', 'body': 'Merging... tests are failing but also failing with the same on main: https://github.com/apache/airflow/actions/runs/12380031516/job/34555973915\r\nUnrelated to this PR.', 'created_at': datetime.datetime(2024, 12, 17, 20, 57, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549615243, 'issue_id': 2745887820, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45010""><img src=""https://img.shields.io/badge/PR-45010-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 17, 20, 58, 26, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-17 19:52:25 UTC): We can attempt to do it, but pretty much only release managers and people helping with backporting need to use breeze. The links in docker-stack might actually be useful though

jscheffl (Issue Creator) on (2024-12-17 20:57:30 UTC): Merging... tests are failing but also failing with the same on main: https://github.com/apache/airflow/actions/runs/12380031516/job/34555973915
Unrelated to this PR.

github-actions[bot] on (2024-12-17 20:58:26 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45010""><img src=""https://img.shields.io/badge/PR-45010-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2745843094,pull_request,closed,,Added MS Graph connection type,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Added a dedicated MS Graph connection type.

Thanks to that we can now get the hook using the BaseHook.get_hook(conn_id=""msgraph_conn_id"") to get the KiotaRequestAdapterHook.  This was until now impossible as the MSGraphAsyncOperator was using a HTTP connection.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-12-17 19:24:52+00:00,[],2024-12-18 15:47:46+00:00,2024-12-18 15:47:46+00:00,https://github.com/apache/airflow/pull/45006,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2745541054,pull_request,closed,,AIP-72: Fix floating point imprecision in TI Duration calculation for SQLite,"[julianday](https://www.sqlite.org/lang_datefunc.html#:~:text=The%20number%20of%20days%20including%20fractional%20days%20since%20%2D4713%2D11%2D24%2012%3A00%3A00%20Example%3A%202460825.09444444) returns timestamps as fractional days. Multiplying this value by 86400 (seconds in a day) introduces minor floating-point inaccuracies, which can cause subtle errors in downstream calculations or assertions.

Example ( [PR failure](https://github.com/apache/airflow/actions/runs/12350551354/job/34464066950#step:7:2178) ):

```sql
SELECT (julianday('2024-06-01T01:00:00') - julianday('2024-06-01T00:00:00')) * 86400;
-- Result: 3599.999986588955 (instead of 3600.0)
```

After:

```sql
SELECT 
  (strftime('%s', '2024-06-01T01:00:00') - strftime('%s', '2024-06-01T00:00:00'))
  + ROUND((strftime('%f', '2024-06-01T01:00:00') - strftime('%f', '2024-06-01T00:00:00')), 3);
-- Result: 3600.0
```

Even with the milli-second precision:

```sql
SELECT 
  (strftime('%s', '2024-06-01T01:00:00.456') - strftime('%s', '2024-06-01T00:00:00.123'))
  + ROUND((strftime('%f', '2024-06-01T01:00:00.456') - strftime('%f', '2024-06-01T00:00:00.123')), 3);
-- Result: 3600.333
```

Some sources:

- https://stackoverflow.com/questions/289680/difference-between-2-dates-in-sqlite
- https://stackoverflow.com/questions/40419417/operating-with-datetimes-in-sqlite
- https://stackoverflow.com/questions/35552867/sqlite-difference-between-dates-in-millisecond
- [https://www.sqlite.org/lang_datefunc.html](https://www.sqlite.org/lang_datefunc.html#:~:text=The%20number%20of%20days%20including%20fractional%20days%20since%20%2D4713%2D11%2D24%2012%3A00%3A00%20Example%3A%202460825.09444444)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-17 17:16:15+00:00,[],2024-12-18 08:41:08+00:00,2024-12-18 08:41:07+00:00,https://github.com/apache/airflow/pull/45002,[],[],
2745506216,pull_request,closed,,Fix MetastoreHivePartitionSensor failing due to duplicate aliases,"MetastoreHivePartitionSensor is not working.

The query it uses to list partitions https://github.com/apache/airflow/blob/83da311e4ce5a7965b2e1c412941a8f26ad8225e/providers/src/airflow/providers/google/cloud/hooks/dataproc_metastore.py#L648
        
```
query = f""""""
                SELECT *
                FROM PARTITIONS
                INNER JOIN TBLS
                ON PARTITIONS.TBL_ID = TBLS.TBL_ID
                WHERE
                    TBLS.TBL_NAME = '{table}'""""""
```

fails, due to Duplicate Aliases (https://cloud.google.com/spanner/docs/reference/standard-sql/query-syntax#duplicate_aliases)

This query fixes the issue:

```
query = f""""""
            SELECT PARTITIONS.*, TBLS.TBL_TYPE, TBLS.TBL_NAME
            FROM PARTITIONS
            INNER JOIN TBLS ON PARTITIONS.TBL_ID = TBLS.TBL_ID
            WHERE TBLS.TBL_NAME = '{table}'""""""
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",CYarros10,2024-12-17 17:02:09+00:00,[],2024-12-18 13:27:47+00:00,2024-12-18 13:27:47+00:00,https://github.com/apache/airflow/pull/45001,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2745341009,pull_request,closed,,Bump hatch from 1.9.4 to 1.14.0 in /dev/breeze,"Bumps [hatch](https://github.com/pypa/hatch) from 1.9.4 to 1.14.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/pypa/hatch/releases"">hatch's releases</a>.</em></p>
<blockquote>
<h2>Hatchling v1.14.0</h2>
<p><em><strong>Added:</strong></em></p>
<ul>
<li>Add <code>trove-classifiers</code> as a dependency</li>
</ul>
<p><em><strong>Fixed:</strong></em></p>
<ul>
<li>Properly normalize metadata descriptions that contain line breaks</li>
</ul>
<h2>Hatch v1.14.0</h2>
<p><em><strong>Added:</strong></em></p>
<ul>
<li>Upgrade default CPython distributions to 20241206</li>
<li>Bump the minimum supported version of Hatchling to 1.26.3</li>
<li>Update <code>virtualenv</code> dependency</li>
</ul>
<h2>Hatchling v1.13.0</h2>
<p><em><strong>Added:</strong></em></p>
<ul>
<li>Update the set of known trove classifiers to version 2023.2.8</li>
</ul>
<h2>Hatch v1.13.0</h2>
<p><em><strong>Added:</strong></em></p>
<ul>
<li>Support managing Python 3.13 distributions</li>
</ul>
<h2>Hatchling v1.12.2</h2>
<p><em><strong>Fixed:</strong></em></p>
<ul>
<li>Add <code>macos-max-compat</code> option to the <code>wheel</code> target that is enabled by default to support the latest version 22.0 of the <code>packaging</code> library</li>
</ul>
<h2>Hatchling v1.12.1</h2>
<p><em><strong>Fixed:</strong></em></p>
<ul>
<li>Fix minor regression in the PEP 517/660 function signatures that was discovered by Fedora</li>
</ul>
<h2>Hatchling v1.12.0</h2>
<p><em><strong>Added:</strong></em></p>
<ul>
<li>Improve readability of exceptions</li>
<li>Add <code>extra_metadata</code> build data to the <code>wheel</code> target</li>
<li>Retroactively support <code>License-Expression</code> core metadata starting at version 2.1</li>
<li>Add more type hints</li>
<li>Update the set of known trove classifiers to version 2022.12.22</li>
<li>Update SPDX license information to version 3.19</li>
<li>Store Hatchling's metadata in <code>pyproject.toml</code></li>
</ul>
<p><em><strong>Fixed:</strong></em></p>
<ul>
<li>Acknowledge the <code>ARCHFLAGS</code> environment variable on macOS for the <code>wheel</code> target when build hooks set the <code>infer_tag</code> build data to <code>true</code></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/hatch/commit/55dd8409fd4f8dde5869003d24b04d43dab192a9""><code>55dd840</code></a> Update macOS runners (<a href=""https://redirect.github.com/pypa/hatch/issues/1855"">#1855</a>)</li>
<li><a href=""https://github.com/pypa/hatch/commit/72f7deffe1a82c77931036daffab9bc6839b11bf""><code>72f7def</code></a> release Hatch v1.14.0</li>
<li><a href=""https://github.com/pypa/hatch/commit/ffe7acf9e1fbdc3fd57ce2e0601a6906107465f2""><code>ffe7acf</code></a> update hatchling</li>
<li><a href=""https://github.com/pypa/hatch/commit/2dfdd58095828cd86b6895802b0c4342bb37de34""><code>2dfdd58</code></a> release Hatch v1.13.1</li>
<li><a href=""https://github.com/pypa/hatch/commit/054bb7f4e4c18bac51a505771b8d04c0b8fb070e""><code>054bb7f</code></a> Update distributions</li>
<li><a href=""https://github.com/pypa/hatch/commit/f81343612eede35edfea67310fff3672cb881ce1""><code>f813436</code></a> Update pypa/gh-action-pypi-publish action</li>
<li><a href=""https://github.com/pypa/hatch/commit/3b4f9c8c77194c47f9935e097506b9a8efe10a41""><code>3b4f9c8</code></a> Update virtualenv (<a href=""https://redirect.github.com/pypa/hatch/issues/1849"">#1849</a>)</li>
<li><a href=""https://github.com/pypa/hatch/commit/be9861df0ea78a0a5298def32e63308082671019""><code>be9861d</code></a> Improve distribution variant config docs</li>
<li><a href=""https://github.com/pypa/hatch/commit/4e3c515bb15fd5533ced963c70308e2a271905d9""><code>4e3c515</code></a> release Hatch v1.13.0</li>
<li><a href=""https://github.com/pypa/hatch/commit/204c0cdc30990c0b5a983f5705967867e727982e""><code>204c0cd</code></a> Support managing Python 3.13 distributions (<a href=""https://redirect.github.com/pypa/hatch/issues/1753"">#1753</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/pypa/hatch/compare/hatch-v1.9.4...hatch-v1.14.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=hatch&package-manager=pip&previous-version=1.9.4&new-version=1.14.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-12-17 16:03:16+00:00,[],2024-12-18 16:07:16+00:00,2024-12-18 16:07:06+00:00,https://github.com/apache/airflow/pull/45000,"[('area:dev-tools', ''), ('area:dependencies', 'Issues related to dependencies problems')]","[{'comment_id': 2549465406, 'issue_id': 2745341009, 'author': 'potiuk', 'body': 'Interesting :) Need to take a look.', 'created_at': datetime.datetime(2024, 12, 17, 19, 47, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549471060, 'issue_id': 2745341009, 'author': 'potiuk', 'body': 'I think the auto-upgrade of breeze is interfering with dependabot, I will need to take a closer look - as we are both using and upgrading `breeze` at the same time, which might be a bit tricky - also there is the stored ""hash"" in breeze README that is used for auto-upgrade of breeze that might make it difficult for the dependabot upgrades in breeze.', 'created_at': datetime.datetime(2024, 12, 17, 19, 49, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551721941, 'issue_id': 2745341009, 'author': 'potiuk', 'body': 'Closing in favour of #45041 that also contains the fix to failing ""get-workflow-info"" steps.', 'created_at': datetime.datetime(2024, 12, 18, 16, 7, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551722145, 'issue_id': 2745341009, 'author': 'dependabot[bot]', 'body': ""OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file.\n\nIf you change your mind, just re-open this PR and I'll resolve any conflicts on it."", 'created_at': datetime.datetime(2024, 12, 18, 16, 7, 9, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-17 19:47:14 UTC): Interesting :) Need to take a look.

potiuk on (2024-12-17 19:49:28 UTC): I think the auto-upgrade of breeze is interfering with dependabot, I will need to take a closer look - as we are both using and upgrading `breeze` at the same time, which might be a bit tricky - also there is the stored ""hash"" in breeze README that is used for auto-upgrade of breeze that might make it difficult for the dependabot upgrades in breeze.

potiuk on (2024-12-18 16:07:03 UTC): Closing in favour of #45041 that also contains the fix to failing ""get-workflow-info"" steps.

dependabot[bot] (Issue Creator) on (2024-12-18 16:07:09 UTC): OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`. You can also ignore all major, minor, or patch releases for a dependency by adding an [`ignore` condition](https://docs.github.com/en/code-security/supply-chain-security/configuration-options-for-dependency-updates#ignore) with the desired `update_types` to your config file.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.

"
2745338176,pull_request,closed,,Bump apache-airflow from 2.10.3 to 2.10.4,"Bumps [apache-airflow](https://github.com/apache/airflow) from 2.10.3 to 2.10.4.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/apache/airflow/releases"">apache-airflow's releases</a>.</em></p>
<blockquote>
<h2>Apache Airflow 2.10.4</h2>
<h1>Significant Changes</h1>
<h2>TaskInstance <code>priority_weight</code> is capped in 32-bit signed integer ranges (<a href=""https://redirect.github.com/apache/airflow/issues/43611"">#43611</a>)</h2>
<p>Some database engines are limited to 32-bit integer values. As some users reported errors in
weight rolled-over to negative values, we decided to cap the value to the 32-bit integer. Even
if internally in python smaller or larger values to 64 bit are supported, <code>priority_weight</code> is
capped and only storing values from -2147483648 to 2147483647.</p>
<h2>Bug Fixes</h2>
<ul>
<li>Fix stats of dynamic mapped tasks after automatic retries of failed tasks (<a href=""https://redirect.github.com/apache/airflow/issues/44300"">#44300</a>)</li>
<li>Fix wrong display of multi-line messages in the log after filtering (<a href=""https://redirect.github.com/apache/airflow/issues/44457"">#44457</a>)</li>
<li>Allow &quot;/&quot; in metrics validator (<a href=""https://redirect.github.com/apache/airflow/issues/42934"">#42934</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44515"">#44515</a>)</li>
<li>Fix gantt flickering (<a href=""https://redirect.github.com/apache/airflow/issues/44488"">#44488</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44517"">#44517</a>)</li>
<li>Fix problem with inability to remove fields from Connection form (<a href=""https://redirect.github.com/apache/airflow/issues/40421"">#40421</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44442"">#44442</a>)</li>
<li>Check pool_slots on partial task import instead of execution (<a href=""https://redirect.github.com/apache/airflow/issues/39724"">#39724</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42693"">#42693</a>)</li>
<li>Avoid grouping task instance stats by try_number for dynamic mapped tasks (<a href=""https://redirect.github.com/apache/airflow/issues/44300"">#44300</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44319"">#44319</a>)</li>
<li>Re-queue task when they are stuck in queued (<a href=""https://redirect.github.com/apache/airflow/issues/43520"">#43520</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44158"">#44158</a>)</li>
<li>Suppress the warnings where we check for sensitive values (<a href=""https://redirect.github.com/apache/airflow/issues/44148"">#44148</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44167"">#44167</a>)</li>
<li>Fix get_task_instance_try_details to return appropriate schema (<a href=""https://redirect.github.com/apache/airflow/issues/43830"">#43830</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44133"">#44133</a>)</li>
<li>Log message source details are grouped (<a href=""https://redirect.github.com/apache/airflow/issues/43681"">#43681</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44070"">#44070</a>)</li>
<li>Fix duplication of Task tries in the UI (<a href=""https://redirect.github.com/apache/airflow/issues/43891"">#43891</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43950"">#43950</a>)</li>
<li>Add correct mime-type in OpenAPI spec (<a href=""https://redirect.github.com/apache/airflow/issues/43879"">#43879</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43901"">#43901</a>)</li>
<li>Disable extra links button if link is null or empty (<a href=""https://redirect.github.com/apache/airflow/issues/43844"">#43844</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43851"">#43851</a>)</li>
<li>Disable XCom list ordering by execution_date (<a href=""https://redirect.github.com/apache/airflow/issues/43680"">#43680</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43696"">#43696</a>)</li>
<li>Fix venv numpy example which needs to be 1.26 at least to be working in Python 3.12 (<a href=""https://redirect.github.com/apache/airflow/issues/43659"">#43659</a>)</li>
<li>Fix Try Selector in Mapped Tasks also on Index 0 (<a href=""https://redirect.github.com/apache/airflow/issues/43590"">#43590</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43591"">#43591</a>)</li>
<li>Prevent using <code>trigger_rule=&quot;always&quot;</code> in a dynamic mapped task (<a href=""https://redirect.github.com/apache/airflow/issues/43810"">#43810</a>)</li>
<li>Prevent using <code>trigger_rule=TriggerRule.ALWAYS</code> in a task-generated mapping within bare tasks (<a href=""https://redirect.github.com/apache/airflow/issues/44751"">#44751</a>)</li>
</ul>
<h2>Doc Only Changes</h2>
<ul>
<li>Update XCom docs around containers/helm (<a href=""https://redirect.github.com/apache/airflow/issues/44570"">#44570</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44573"">#44573</a>)</li>
</ul>
<h2>Miscellaneous</h2>
<ul>
<li>Raise deprecation warning when accessing inlet or outlet events through str (<a href=""https://redirect.github.com/apache/airflow/issues/43922"">#43922</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/apache/airflow/blob/main/RELEASE_NOTES.rst"">apache-airflow's changelog</a>.</em></p>
<blockquote>
<h2>Airflow 2.10.4 (2024-12-16)</h2>
<p>Significant Changes
^^^^^^^^^^^^^^^^^^^</p>
<p>TaskInstance <code>priority_weight</code> is capped in 32-bit signed integer ranges (<a href=""https://redirect.github.com/apache/airflow/issues/43611"">#43611</a>)
&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</p>
<p>Some database engines are limited to 32-bit integer values. As some users reported errors in
weight rolled-over to negative values, we decided to cap the value to the 32-bit integer. Even
if internally in python smaller or larger values to 64 bit are supported, <code>priority_weight</code> is
capped and only storing values from -2147483648 to 2147483647.</p>
<p>Bug Fixes
^^^^^^^^^</p>
<ul>
<li>Fix stats of dynamic mapped tasks after automatic retries of failed tasks (<a href=""https://redirect.github.com/apache/airflow/issues/44300"">#44300</a>)</li>
<li>Fix wrong display of multi-line messages in the log after filtering (<a href=""https://redirect.github.com/apache/airflow/issues/44457"">#44457</a>)</li>
<li>Allow &quot;/&quot; in metrics validator (<a href=""https://redirect.github.com/apache/airflow/issues/42934"">#42934</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44515"">#44515</a>)</li>
<li>Fix gantt flickering (<a href=""https://redirect.github.com/apache/airflow/issues/44488"">#44488</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44517"">#44517</a>)</li>
<li>Fix problem with inability to remove fields from Connection form (<a href=""https://redirect.github.com/apache/airflow/issues/40421"">#40421</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44442"">#44442</a>)</li>
<li>Check pool_slots on partial task import instead of execution (<a href=""https://redirect.github.com/apache/airflow/issues/39724"">#39724</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42693"">#42693</a>)</li>
<li>Avoid grouping task instance stats by try_number for dynamic mapped tasks (<a href=""https://redirect.github.com/apache/airflow/issues/44300"">#44300</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44319"">#44319</a>)</li>
<li>Re-queue task when they are stuck in queued (<a href=""https://redirect.github.com/apache/airflow/issues/43520"">#43520</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44158"">#44158</a>)</li>
<li>Suppress the warnings where we check for sensitive values (<a href=""https://redirect.github.com/apache/airflow/issues/44148"">#44148</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44167"">#44167</a>)</li>
<li>Fix get_task_instance_try_details to return appropriate schema (<a href=""https://redirect.github.com/apache/airflow/issues/43830"">#43830</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44133"">#44133</a>)</li>
<li>Log message source details are grouped (<a href=""https://redirect.github.com/apache/airflow/issues/43681"">#43681</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44070"">#44070</a>)</li>
<li>Fix duplication of Task tries in the UI (<a href=""https://redirect.github.com/apache/airflow/issues/43891"">#43891</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43950"">#43950</a>)</li>
<li>Add correct mime-type in OpenAPI spec (<a href=""https://redirect.github.com/apache/airflow/issues/43879"">#43879</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43901"">#43901</a>)</li>
<li>Disable extra links button if link is null or empty (<a href=""https://redirect.github.com/apache/airflow/issues/43844"">#43844</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43851"">#43851</a>)</li>
<li>Disable XCom list ordering by execution_date (<a href=""https://redirect.github.com/apache/airflow/issues/43680"">#43680</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43696"">#43696</a>)</li>
<li>Fix venv numpy example which needs to be 1.26 at least to be working in Python 3.12 (<a href=""https://redirect.github.com/apache/airflow/issues/43659"">#43659</a>)</li>
<li>Fix Try Selector in Mapped Tasks also on Index 0 (<a href=""https://redirect.github.com/apache/airflow/issues/43590"">#43590</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43591"">#43591</a>)</li>
<li>Prevent using <code>trigger_rule=&quot;always&quot;</code> in a dynamic mapped task (<a href=""https://redirect.github.com/apache/airflow/issues/43810"">#43810</a>)</li>
<li>Prevent using <code>trigger_rule=TriggerRule.ALWAYS</code> in a task-generated mapping within bare tasks (<a href=""https://redirect.github.com/apache/airflow/issues/44751"">#44751</a>)</li>
</ul>
<p>Doc Only Changes
&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</p>
<ul>
<li>Update XCom docs around containers/helm (<a href=""https://redirect.github.com/apache/airflow/issues/44570"">#44570</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44573"">#44573</a>)</li>
</ul>
<p>Miscellaneous
&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</p>
<ul>
<li>Raise deprecation warning when accessing inlet or outlet events through str (<a href=""https://redirect.github.com/apache/airflow/issues/43922"">#43922</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/apache/airflow/commit/c083e456fa02c6cb32cdbe0c9ed3c3b2380beccd""><code>c083e45</code></a> Update RELEASE_NOTES.rst</li>
<li><a href=""https://github.com/apache/airflow/commit/0fc487d355856d3209ced13d0e5740ed56535bb0""><code>0fc487d</code></a> Update version to 2.10.4</li>
<li><a href=""https://github.com/apache/airflow/commit/17495d79b12a17a0607ebef4767f3054e60f9905""><code>17495d7</code></a> Fixing cli test failure in CI (<a href=""https://redirect.github.com/apache/airflow/issues/44679"">#44679</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44806"">#44806</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/9e3a976cfa27f27e6f88cdff6621395eb3f09827""><code>9e3a976</code></a> [BACKPORT] Prevent using <code>trigger_rule=TriggerRule.ALWAYS</code> in a task-generate...</li>
<li><a href=""https://github.com/apache/airflow/commit/d8e93c2ee01ae6a58192b0f885ec42a9f6035356""><code>d8e93c2</code></a> Prevent using trigger_rule=&quot;always&quot; in a dynamic mapped task (<a href=""https://redirect.github.com/apache/airflow/issues/43810"">#43810</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/4f9cf5460980d24838811951c41d41fcc1fe8f4f""><code>4f9cf54</code></a> [v2-10-test] Random doc typos (<a href=""https://redirect.github.com/apache/airflow/issues/44750"">#44750</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44758"">#44758</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/1dc0cc4aa3e03c3b7019b3a04981c6d0b4a2f1e6""><code>1dc0cc4</code></a> Double-check TaskInstance state if it differs from the Executor state. (<a href=""https://redirect.github.com/apache/airflow/issues/43063"">#43063</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/607682c33f81a31fd1458219957d559bb036e6e1""><code>607682c</code></a> Fix test_deprecated_options_with_new_section (<a href=""https://redirect.github.com/apache/airflow/issues/44647"">#44647</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/48d2a24d4de9390264fca9ad5c04c9d4f6992a55""><code>48d2a24</code></a> [v2-10-test] Fix tests badge in README.md (<a href=""https://redirect.github.com/apache/airflow/issues/44505"">#44505</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/44587"">#44587</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/ade67637cfb5f513a5767e85fa9d5a6ec3c8f716""><code>ade6763</code></a> Fix wrong display of multiline messages in the log after filtering (<a href=""https://redirect.github.com/apache/airflow/issues/44457"">#44457</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/apache/airflow/compare/2.10.3...2.10.4"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=apache-airflow&package-manager=pip&previous-version=2.10.3&new-version=2.10.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-12-17 16:02:36+00:00,[],2024-12-17 18:38:07+00:00,2024-12-17 18:37:59+00:00,https://github.com/apache/airflow/pull/44999,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2745335985,pull_request,closed,,Bump keyring from 10.1 to 25.5.0,"Bumps [keyring](https://github.com/jaraco/keyring) from 10.1 to 25.5.0.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/jaraco/keyring/blob/main/NEWS.rst"">keyring's changelog</a>.</em></p>
<blockquote>
<h1>v25.5.0</h1>
<h2>Features</h2>
<ul>
<li>When parsing <code>keyring_path</code> from the config, the home directory is now expanded from <code>~</code>. (<a href=""https://redirect.github.com/jaraco/keyring/issues/696"">#696</a>)</li>
</ul>
<h2>Bugfixes</h2>
<ul>
<li>In get_credential, now returns None when the indicated username is not found. (<a href=""https://redirect.github.com/jaraco/keyring/issues/698"">#698</a>)</li>
</ul>
<h1>v25.4.1</h1>
<h2>Bugfixes</h2>
<ul>
<li>Fixed ValueError for AnonymousCredentials in CLI. (<a href=""https://redirect.github.com/jaraco/keyring/issues/694"">#694</a>)</li>
</ul>
<h1>v25.4.0</h1>
<h2>Features</h2>
<ul>
<li>Refined type spec and interfaces on credential objects. Introduced AnonymousCredential to model a secret without a username. (<a href=""https://redirect.github.com/jaraco/keyring/issues/689"">#689</a>)</li>
</ul>
<h1>v25.3.0</h1>
<h2>Features</h2>
<ul>
<li>Deprecated support for empty usernames. Now all backends will reject an empty string as input for the 'username' field when setting a password. Later this deprecation will become a more visible user warning and even later an error. If this warning is triggered in your environment, please consider using a static value (even 'username') or comment in the issue and describe the use-case that demands support for empty usernames. (<a href=""https://redirect.github.com/jaraco/keyring/issues/668"">#668</a>)</li>
</ul>
<h1>v25.2.1</h1>
<h2>Bugfixes</h2>
<ul>
<li>Fix typo in CLI creds mode. (<a href=""https://redirect.github.com/jaraco/keyring/issues/681"">#681</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/jaraco/keyring/commit/999a2f945a6449a914f192a2fad5805183a6f09d""><code>999a2f9</code></a> Finalize</li>
<li><a href=""https://github.com/jaraco/keyring/commit/8279fd8db45303b897e74bc4dbf4ff10e7b61345""><code>8279fd8</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>
<li><a href=""https://github.com/jaraco/keyring/commit/ccaee76a2aecc8173212b89894d1cdba0e2fa9fa""><code>ccaee76</code></a> Merge pull request <a href=""https://redirect.github.com/jaraco/keyring/issues/699"">#699</a> from JamieBeverley/bugfix/wrong_username</li>
<li><a href=""https://github.com/jaraco/keyring/commit/103c53550cf3e9904666c43138d32e827befe0ac""><code>103c535</code></a> ðŸ§Žâ€â™€ï¸ Genuflect to the types.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/5e4b99eefb5e905836dc2259d44e0c90b11263ba""><code>5e4b99e</code></a> Unified the Windows.get_password and .get_credential logic through a new _res...</li>
<li><a href=""https://github.com/jaraco/keyring/commit/f33fcfb6421a532db2ab87a486fb074859631ef5""><code>f33fcfb</code></a> Restore the indentation on the check, keeping the logic in the only place it'...</li>
<li><a href=""https://github.com/jaraco/keyring/commit/2f3f4eccdf3ab178235128aa9409e2895d21ecd8""><code>2f3f4ec</code></a> Updated comment to match new behavior.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/562c69fdf66a9fba6d7aeb12b778f8a4fc1580b8""><code>562c69f</code></a> ðŸ‘¹ Feed the hobgoblins (delint).</li>
<li><a href=""https://github.com/jaraco/keyring/commit/916c0390067b774b062fe01ac829bcb1ff693626""><code>916c039</code></a> Add news fragment.</li>
<li><a href=""https://github.com/jaraco/keyring/commit/8e2f8b2841284e8f0050e844b1c156a9816c7b0f""><code>8e2f8b2</code></a> Merge pull request <a href=""https://redirect.github.com/jaraco/keyring/issues/696"">#696</a> from torarvid/torarvid/expanduser</li>
<li>Additional commits viewable in <a href=""https://github.com/jaraco/keyring/compare/10.1...v25.5.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyring&package-manager=pip&previous-version=10.1&new-version=25.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-12-17 16:02:02+00:00,[],2024-12-17 19:17:18+00:00,2024-12-17 19:17:10+00:00,https://github.com/apache/airflow/pull/44998,"[('area:dev-tools', ''), ('area:dependencies', 'Issues related to dependencies problems')]",[],
2745329645,pull_request,closed,,Bump openlineage-airflow from 1.20.5 to 1.25.0,"Bumps openlineage-airflow from 1.20.5 to 1.25.0.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=openlineage-airflow&package-manager=pip&previous-version=1.20.5&new-version=1.25.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-12-17 16:00:14+00:00,[],2024-12-17 19:18:57+00:00,2024-12-17 19:18:49+00:00,https://github.com/apache/airflow/pull/44997,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2745310637,pull_request,closed,,feat: Add OpenLineage support for non-query jobs in BigQueryInsertJobOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for all BQ job types other than `QUERY` in BigQueryInsertJobOperator (that was already supported).


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-17 15:55:23+00:00,[],2025-01-03 10:08:30+00:00,2025-01-03 10:07:21+00:00,https://github.com/apache/airflow/pull/44996,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2567695466, 'issue_id': 2745310637, 'author': 'potiuk', 'body': '@kacpermuda  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.', 'created_at': datetime.datetime(2025, 1, 2, 12, 22, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567695994, 'issue_id': 2745310637, 'author': 'potiuk', 'body': 'Actually.. I rebased it myself :)', 'created_at': datetime.datetime(2025, 1, 2, 12, 22, 55, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:22:33 UTC): @kacpermuda  - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.

potiuk on (2025-01-02 12:22:55 UTC): Actually.. I rebased it myself :)

"
2745150949,pull_request,closed,,Deprecate `conf` from Task Context,"(Pulling this back in v2-10-test -- removed it while force-pushing due to other conflicts. Original PR: https://github.com/apache/airflow/pull/44968)

This was initially added in response to https://github.com/apache/airflow/issues/168. However, we now have `ti.log_url` that is used for that; example usages:

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/airflow/models/taskinstance.py#L1362

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/providers/src/airflow/providers/smtp/notifications/templates/email.html#L28

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/docs/apache-airflow/howto/email-config.rst?plain=1#L76

So, to simplify what we need to pass from API server to the Task SDK in preparation for Airflow 3, I want to simplify and remove things that aren't needed. In this case, this is good so we don't pass/expore secrets unnecesarily via `conf`. This is removed in Airflow 3 and deprecated in 2.10.x/2.11

Mailing list Thread: https://lists.apache.org/thread/2n0l8y2oyq4442p0lsnmbbcl6rmbj3k7

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-17 14:55:54+00:00,[],2025-01-28 12:18:06+00:00,2024-12-17 19:32:22+00:00,https://github.com/apache/airflow/pull/44993,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2745097294,pull_request,closed,,Add back Branch Protection for `v2-10-test`,"Branches are synced again: https://github.com/apache/airflow/compare/v2-10-stable...v2-10-test

<img width=""1262"" alt=""image"" src=""https://github.com/user-attachments/assets/daf83dfd-57c3-4da8-b9ac-0a14b1f01c36"" />


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-17 14:30:30+00:00,[],2024-12-17 14:46:31+00:00,2024-12-17 14:46:30+00:00,https://github.com/apache/airflow/pull/44992,"[('area:dev-tools', '')]",[],
2745072555,pull_request,closed,,Temporarily remove branch protection on `v2-10-test`,"Temporarily remove branch protectino on v2-10-test so we can bring v2-10-test and v2-10-stable in-sync

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-17 14:20:32+00:00,[],2024-12-17 14:23:38+00:00,2024-12-17 14:23:36+00:00,https://github.com/apache/airflow/pull/44991,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2744992243,pull_request,closed,,Wait for config API to avoid NaN passed to offset. ,"Whenever a page is loaded the offset and limit values are passed to the API from pagination object. `limit` is fetched from `config` API through `page_size` in airflow.cfg. As `pagination.pageSize` is undefined `offset` which is `pagination.pageIndex * pagination.pageSize` becomes NaN and passed to the API causing backend to return 422 if the API call for a resource is made before `config` finishes. Once config finishes the offset value is calculated properly and then passed to API resulting in two API calls with 1 invalid returning 422 and then again passing with valid offset value to fetch the correct response. Use `enabled` option to not make call if the `offset` is `NaN`. Another option would be default value for `pagination.pageSize` but that would result in 2 API calls with default value and later the value from `config` API call.

Another issue is that for running dagruns and running/deferred task instances the `end_date` is not present causing `NaN` to be displayed in UI in dagrun duration, task instance duration, etc. Use current time if end_date is not present like the legacy UI.

To reproduce : 

1. Open console and visit http://localhost:8000/webapp/dags
2. The console will log API calls sending NaN

http://localhost:8000/public/dags?offset=NaN&only_active=true&order_by=-last_run_start_date
http://localhost:8000/ui/dags/recent_dag_runs?dag_runs_limit=14&offset=NaN&only_active=true",tirkarthi,2024-12-17 13:47:11+00:00,[],2024-12-19 18:02:12+00:00,2024-12-19 17:40:11+00:00,https://github.com/apache/airflow/pull/44989,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2555372128, 'issue_id': 2744992243, 'author': 'tirkarthi', 'body': 'I think this is something easier to forget as APIs are more widely used in UI and should be enforced or as a convention someway but not sure how.', 'created_at': datetime.datetime(2024, 12, 19, 17, 46, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2555452457, 'issue_id': 2744992243, 'author': 'bbovenzi', 'body': ""Yeah, I definitely don't like having to remember to manually add this every single time. I'll try to play with a more elegant solution"", 'created_at': datetime.datetime(2024, 12, 19, 18, 2, 11, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-12-19 17:46:39 UTC): I think this is something easier to forget as APIs are more widely used in UI and should be enforced or as a convention someway but not sure how.

bbovenzi on (2024-12-19 18:02:11 UTC): Yeah, I definitely don't like having to remember to manually add this every single time. I'll try to play with a more elegant solution

"
2744966554,pull_request,closed,,Add only_failed option to clear DagRun endpoint,"We are missing the ability to clear `only_failed` tasks in the clear dag_run endpoint.

Legacy UI is plugged onto a private `clear_dagrun` endpoint for dag_run clearing. I think we don't need that endpoint anymore but we need the option in the public API though.",pierrejeambrun,2024-12-17 13:36:20+00:00,['pierrejeambrun'],2024-12-18 11:30:46+00:00,2024-12-18 11:30:44+00:00,https://github.com/apache/airflow/pull/44988,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2744909731,pull_request,closed,,Remove references to AIRFLOW_V_2_9_PLUS,Followup on https://github.com/apache/airflow/pull/44956,eladkal,2024-12-17 13:11:40+00:00,[],2024-12-18 12:39:23+00:00,2024-12-18 12:39:19+00:00,https://github.com/apache/airflow/pull/44987,"[('provider:google', 'Google (including GCP) related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:logging', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:trino', ''), ('provider:openlineage', 'AIP-53'), ('provider:elasticsearch', ''), ('provider:presto', ''), ('provider:opensearch', ''), ('provider:common-io', ''), ('provider:fab', ''), ('provider:common-compat', ''), ('provider:standard', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2744865185,pull_request,closed,,Enforce to forbid extra fields under execution_api,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44978 
related: #44306

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-12-17 12:53:29+00:00,[],2025-02-05 12:53:41+00:00,2025-02-05 12:53:41+00:00,https://github.com/apache/airflow/pull/44986,[],"[{'comment_id': 2552612321, 'issue_id': 2744865185, 'author': 'jx2lee', 'body': 'Adding `extra` field in xcoms/variable datamodels, test passed.. so I added only task_instance test. Do i miss anything?\r\ne.g in, [TestGetVariable.test_variable_get_from_db](), request with `params` extra fields but test passed (expected this test to fail, but...ðŸ˜­)\r\n```\r\n    def test_variable_get_from_db(self, client, session):\r\n        Variable.set(key=""var1"", value=""value"", session=session)\r\n        session.commit()\r\n\r\n        response = client.get(""/execution/variables/var1"", params={""foo"": ""bar""})\r\n\r\n        assert response.status_code == 200\r\n        assert response.json() == {""key"": ""var1"", ""value"": ""value""}\r\n\r\n        # Remove connection\r\n        Variable.delete(key=""var1"", session=session)\r\n        session.commit()\r\n```', 'created_at': datetime.datetime(2024, 12, 19, 1, 56, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2557161750, 'issue_id': 2744865185, 'author': 'jx2lee', 'body': ""@pierrejeambrun Thanks for sharing issue.\r\n\r\n> I suggest to consolidate the approach for all of our APIs.\r\n> \r\n> Most likely Bodies / input payloads have `forbid_extra=True`, but Responses do not. (because this is useful for filtering down a subpart of a model, and this feature is used by some endpoints).\r\n\r\nI'll review the shared [PR](https://github.com/apache/airflow/pull/44306) and make adjustments based on it!\r\n(Once the above PR is completed..!)"", 'created_at': datetime.datetime(2024, 12, 20, 14, 53, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633825620, 'issue_id': 2744865185, 'author': 'pierrejeambrun', 'body': 'One test to remove and we should be good.', 'created_at': datetime.datetime(2025, 2, 4, 12, 55, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633832425, 'issue_id': 2744865185, 'author': 'jx2lee', 'body': ""> One test to remove and we should be good.\n\nI'm in gym now, go back to fix soon!"", 'created_at': datetime.datetime(2025, 2, 4, 12, 57, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634484148, 'issue_id': 2744865185, 'author': 'pierrejeambrun', 'body': 'Re-running failed job', 'created_at': datetime.datetime(2025, 2, 4, 16, 30, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2636290385, 'issue_id': 2744865185, 'author': 'jx2lee', 'body': '@pierrejeambrun Do i need to modify code?', 'created_at': datetime.datetime(2025, 2, 5, 10, 10, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2636778388, 'issue_id': 2744865185, 'author': 'pierrejeambrun', 'body': 'CI is green, merging, thanks.', 'created_at': datetime.datetime(2025, 2, 5, 12, 53, 37, tzinfo=datetime.timezone.utc)}]","jx2lee (Issue Creator) on (2024-12-19 01:56:57 UTC): Adding `extra` field in xcoms/variable datamodels, test passed.. so I added only task_instance test. Do i miss anything?
e.g in, [TestGetVariable.test_variable_get_from_db](), request with `params` extra fields but test passed (expected this test to fail, but...ðŸ˜­)
```
    def test_variable_get_from_db(self, client, session):
        Variable.set(key=""var1"", value=""value"", session=session)
        session.commit()

        response = client.get(""/execution/variables/var1"", params={""foo"": ""bar""})

        assert response.status_code == 200
        assert response.json() == {""key"": ""var1"", ""value"": ""value""}

        # Remove connection
        Variable.delete(key=""var1"", session=session)
        session.commit()
```

jx2lee (Issue Creator) on (2024-12-20 14:53:32 UTC): @pierrejeambrun Thanks for sharing issue.


I'll review the shared [PR](https://github.com/apache/airflow/pull/44306) and make adjustments based on it!
(Once the above PR is completed..!)

pierrejeambrun on (2025-02-04 12:55:04 UTC): One test to remove and we should be good.

jx2lee (Issue Creator) on (2025-02-04 12:57:59 UTC): I'm in gym now, go back to fix soon!

pierrejeambrun on (2025-02-04 16:30:30 UTC): Re-running failed job

jx2lee (Issue Creator) on (2025-02-05 10:10:05 UTC): @pierrejeambrun Do i need to modify code?

pierrejeambrun on (2025-02-05 12:53:37 UTC): CI is green, merging, thanks.

"
2744826731,pull_request,closed,,Deprecation policy for apache-airflow-providers-google package,"This PR announces deprecation policy for Google provider.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-12-17 12:36:55+00:00,[],2024-12-24 10:22:28+00:00,2024-12-24 10:22:28+00:00,https://github.com/apache/airflow/pull/44985,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2560949126, 'issue_id': 2744826731, 'author': 'moiseenkov', 'body': 'Hi @potiuk , could we merge it please?', 'created_at': datetime.datetime(2024, 12, 24, 10, 18, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560951050, 'issue_id': 2744826731, 'author': 'potiuk', 'body': '> Hi @potiuk , could we merge it please?\r\n\r\nThere was a comment from @eladkal that needs to be addressed', 'created_at': datetime.datetime(2024, 12, 24, 10, 20, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2560951343, 'issue_id': 2744826731, 'author': 'potiuk', 'body': ""(unless it's already addressed :)"", 'created_at': datetime.datetime(2024, 12, 24, 10, 20, 47, tzinfo=datetime.timezone.utc)}]","moiseenkov on (2024-12-24 10:18:38 UTC): Hi @potiuk , could we merge it please?

potiuk on (2024-12-24 10:20:29 UTC): There was a comment from @eladkal that needs to be addressed

potiuk on (2024-12-24 10:20:47 UTC): (unless it's already addressed :)

"
2744492337,pull_request,closed,,Support Task execution interface (AIP-72) in Airflow 3 in EdgeExecutor,"The introduction of AIP-72 and removal of AIP-44 in main broke the EdgeExecutor/EdgeWorker on main.

This PR makes it working again as the second executor supporting AIP-72 for the first ""edge cases"" and check.

Note: Two commits, first one is an extension in the Executor API which is needed to ship a session context to EdgeExecutor not to break DB lock during scheduling as EdgeExecutor need to write to DB. Let me know if I should separate into two PRs... (as of dev rules core and provider changes bundled here)

@ashb Would very much favor a review from you here if the design anticipated for AIP-72 is correctly understood how integrated.

If you want to test with Airflow 3, use:
`breeze start-airflow --python 3.12 --load-example-dags --backend postgres --executor EdgeExecutor --answer y`

In Airflow 3 the ""example_bash_operator"" is working, not all other DAGs.

If somebody wants to test Airflow 2.10 as regression, this can be made via:
`breeze down && rm dist/* && breeze release-management prepare-provider-packages --include-not-ready-providers edge && breeze start-airflow --python 3.12 --load-example-dags --backend postgres --executor EdgeExecutor --answer y --use-airflow-version 2.10.4 --use-packages-from-dist`

FYI @AutomationDev85 ",jscheffl,2024-12-17 10:10:31+00:00,[],2025-01-07 22:03:11+00:00,2025-01-07 22:03:11+00:00,https://github.com/apache/airflow/pull/44982,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:providers', ''), ('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('AIP-69', 'Edge Executor'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2744462954,pull_request,closed,,AIP-72: Handling `up_for_retry` task instance states for `AirflowTaskTimeout` and `AirflowException`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Only last 2 commits are relevant.

Dependent on https://github.com/apache/airflow/pull/44977 and hence on https://github.com/apache/airflow/pull/44954.
Handling the case of `up_for_retry` from the task SDK.

This exception can be thrown in multiple cases, two valid examples are:

1. I have a dag which times out in 1 second but the task sleeps for 100 seconds, it will end up throwing the `AirflowTaskTimeout` exception:
```
import sys
from time import sleep

from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator
from datetime import datetime, timedelta

from airflow.sdk.definitions.baseoperator import AirflowException


def print_hello():
    sleep(100)

with DAG(
    dag_id=""hello_world_single_task"",
    default_args={
        ""owner"": ""airflow"",
        ""depends_on_past"": False,
        ""retries"": 1,
    },
    description=""A simple Hello World DAG with one task"",
    schedule=None,
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=[""example""],
) as dag:
    hello_task = PythonOperator(
        retries=1,
        task_id=""say_hello"",
        execution_timeout=timedelta(seconds=1),
        python_callable=print_hello,
    )
```
Should be marked with `up_for_retry`
<img width=""1722"" alt=""image"" src=""https://github.com/user-attachments/assets/8de40ddb-0bfb-4faa-a02e-5a6567570e15"" />


2. A task raises the `AirflowException` 
Example: If we are unable to render the pod template for K8s while using K8sExecutor with Airflow.
```
@provide_session
def get_rendered_k8s_spec(task_instance: TaskInstance, session=NEW_SESSION) -> dict | None:
    """"""Fetch rendered template fields from DB.""""""
    from airflow.models.renderedtifields import RenderedTaskInstanceFields

    rendered_k8s_spec = RenderedTaskInstanceFields.get_k8s_pod_yaml(task_instance, session=session)
    if not rendered_k8s_spec:
        try:
            rendered_k8s_spec = render_k8s_pod_yaml(task_instance)
        except (TemplateAssertionError, UndefinedError) as e:
            raise AirflowException(f""Unable to render a k8s spec for this taskinstance: {e}"") from e
    return rendered_k8s_spec
```


Key changes:
1. This PR adds the `up_for_retry` state into `TerminalTIState` as it is a terminal state and on hitting this state, anything additional work apart from marking it to that state needn't be done.
2. Called the API from task runner when AirflowTaskTimeout, AirflowException is raised.




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-17 09:58:11+00:00,['amoghrajesh'],2024-12-19 08:13:15+00:00,2024-12-19 08:13:15+00:00,https://github.com/apache/airflow/pull/44981,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2548924227, 'issue_id': 2744462954, 'author': 'amoghrajesh', 'body': 'Thanks @kaxil and @dstandish. I got confused here with similar names ""up_for_retry"" and ""upstream_failed"". Will take a look and redo it tomorrow. Thanks', 'created_at': datetime.datetime(2024, 12, 17, 16, 18, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553033415, 'issue_id': 2744462954, 'author': 'amoghrajesh', 'body': 'Closing this PR as it is easier to create a new one', 'created_at': datetime.datetime(2024, 12, 19, 8, 13, 13, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-17 16:18:53 UTC): Thanks @kaxil and @dstandish. I got confused here with similar names ""up_for_retry"" and ""upstream_failed"". Will take a look and redo it tomorrow. Thanks

amoghrajesh (Issue Creator) on (2024-12-19 08:13:13 UTC): Closing this PR as it is easier to create a new one

"
2744270145,pull_request,closed,,Fixing a typo in serializers.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-17 08:37:14+00:00,[],2025-01-11 19:43:19+00:00,2024-12-17 18:56:41+00:00,https://github.com/apache/airflow/pull/44979,"[('kind:documentation', '')]",[],
2744151408,pull_request,closed,,AIP-72: Handling `failed` TI state for `AirflowTaskTerminated`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/44414

This is an addition to https://github.com/apache/airflow/pull/44954 and is dependent on it.
Only last commit is relevant cb493eee920229ac0358282f12d354d96121e1bf

We do not have to handle the case of external task state updates specifically in task_runner because public UI APIs will directly do that job - core APIs. So there is no scenario when one of these exceptions are thrown due to this: https://github.com/apache/airflow/blob/83da311e4ce5a7965b2e1c412941a8f26ad8225e/task_sdk/src/airflow/sdk/execution_time/supervisor.py#L608-L615

We check with the database for the state with the heartbeat and if ever there is a different state, other than running: https://github.com/apache/airflow/blob/83da311e4ce5a7965b2e1c412941a8f26ad8225e/airflow/api_fastapi/execution_api/routes/task_instances.py#L210-L218, we fail with a 409.

But, if this state is ever hit, we should just mark the TI as failed. There are UTs https://github.com/apache/airflow/compare/main...astronomer:airflow:AIP72-taskterminated-or-afexception?expand=1#diff-413c3c59636a3c7b41b8bb822827d18a959778d0b6331532e0db175c829dbfd2R342-R397 which handle this portion to check if it fails or not.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-17 07:35:36+00:00,['amoghrajesh'],2024-12-19 16:18:37+00:00,2024-12-19 16:18:34+00:00,https://github.com/apache/airflow/pull/44977,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2744091280,pull_request,closed,,Use SSH to authenticate GitDagBundle,"This uses SSH hook to authenticate GitDagBundle when provided.

",ephraimbuddy,2024-12-17 06:57:53+00:00,[],2025-01-16 20:19:51+00:00,2025-01-16 11:04:10+00:00,https://github.com/apache/airflow/pull/44976,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2744023431,pull_request,closed,,Remove redundant vars from supervisor code,"Afer we moved `resp = None` at the top-level, we don't need this.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-17 06:12:32+00:00,[],2024-12-17 06:52:50+00:00,2024-12-17 06:52:45+00:00,https://github.com/apache/airflow/pull/44974,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:task-sdk', None)]",[],
2743756190,pull_request,closed,,Add write feature to ESTaskHandler,"For remote logging with Elasticsearch, currently only reading log is supported. Users need to deploy other softwares (such as filebeat & logstash) to ship Airflow task logs to Elasticsearch. Also, user would need to ensure the log messages contain a valid log_id of format {dag_id}-{task_id}-{execution_date}-{try_number} in order for reading remote log to work.

This PR will enable the ElasticSearchTaskHandler to automatically write each task log to Elasticsearch after each DAG task is completed. 2 more config are introduced (namely: `write_to_es` and `target_index`, which are set to False and `airflow-logs` by default`) 

The ElasticSearchTaskHandler will now also consider the config `delete_local_logs` in `logging` session. When both `write_to_es` and `delete_local_logs` are set to True, the handler will delete local task logs upon successfully writing logs to ES.

related: #42780 

",Owen-CH-Leung,2024-12-17 01:58:18+00:00,[],2025-01-13 16:15:33+00:00,2025-01-13 16:15:33+00:00,https://github.com/apache/airflow/pull/44973,"[('area:providers', ''), ('area:logging', ''), ('kind:documentation', ''), ('provider:elasticsearch', '')]",[],
2743597771,pull_request,closed,,Swap Dag Parsing to use the TaskSDK machinery.,"As part of Airflow 3 DAG definition files will have to use the Task SDK for
all their classes, and anything involving running user code will need to be
de-coupled from the database in the user-code process.

This change moves all of the ""serialization"" change up to the
DagFileProcessorManager, using the new function introduced in #44898 and the
""subprocess"" machinery introduced in #44874.

**Important Note**: this change does not remove the ability for dag processes
to access the DB for Variables etc. That will come in a future change.

Some key parts of this change:

- It builds upon the WatchedSubprocess from the TaskSDK. Right now this puts a
  nasty/unwanted depenednecy between the Dag Parsing code upon the TaskSDK.
  This will be addressed before release (we have talked about introducing a
  new ""apache-airflow-base-executor"" dist where this subprocess+supervisor
  could live, as the ""execution_time"" folder in the Task SDK is more a feature
  of the executor, not of the TaskSDK itself)
- A number of classes that we need to send between processes have been
  converted to Pydantic for ease of serialization.
- In order to not have to serialize everything in the subprocess and deserialize everything
  in the parent Manager process, we have created a `LazyDeserializedDAG` class
  that provides lazy access to much of the properties needed to create update
  the DAG related DB objects, without needing to fully deserialize the entire
  DAG structure.
- Classes switched to attrs based for less boilerplate in constructors.
- Internal timers convert to `time.monotonic` where possible, and `time.time`
  where not, we only need second diff between two points, not datetime objects
- With the earlier removal of ""sync mode"" for SQLite in #44839 the need for
  separate TERMIANTE and END messages over the control socket can go

Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>
Co-authored-by: Daniel Imberman <daniel.imberman@gmail.com>

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-12-16 23:25:04+00:00,[],2024-12-19 14:19:15+00:00,2024-12-19 14:19:12+00:00,https://github.com/apache/airflow/pull/44972,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:serialization', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2547112609, 'issue_id': 2743597771, 'author': 'ashb', 'body': ""The tests aren't 100% finished yet.\r\n\r\nAnd this change is larger than I would have liked, but at least it's a net-negative change"", 'created_at': datetime.datetime(2024, 12, 16, 23, 25, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547159823, 'issue_id': 2743597771, 'author': 'ashb', 'body': ""I don't expect tests to pass yet, but I want to give people the chance to see this PR, and I know @jedcunningham is waiting on this for some of his DAG versioning work."", 'created_at': datetime.datetime(2024, 12, 16, 23, 49, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547646421, 'issue_id': 2743597771, 'author': 'kaxil', 'body': '>Right now this puts a\r\nnasty/unwanted depenednecy between the Dag Parsing code upon the TaskSDK.\r\n\r\nI think that is unavoidable, as user code will come from Task SDK\r\n\r\n\r\n>This will be addressed before release (we have talked about introducing a\r\nnew ""apache-airflow-base-executor"" dist where this subprocess+supervisor\r\ncould live, as the ""execution_time"" folder in the Task SDK is more a feature\r\nof the executor, not of the TaskSDK itself)\r\n\r\nRight, I think processor will have to depend on both Task SDK (user-facing code) + Base Executor dist -- after that separation', 'created_at': datetime.datetime(2024, 12, 17, 6, 59, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552438173, 'issue_id': 2743597771, 'author': 'ashb', 'body': 'Right, I think this should now pass the tests, the only thing I\'m not sure about this is the xfail I\'ve put for the ""simple ti roundtrip exec config tests"" -- Either we should remove it or make it work, but I\'m not sure if we need to pass down executor config via TI anymore\r\n\r\n@kaxil Any ideas the best plan for that one?', 'created_at': datetime.datetime(2024, 12, 18, 23, 9, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2552438662, 'issue_id': 2743597771, 'author': 'ashb', 'body': '(I still need to rename a class and file, but that is a non-meaningful/non-review-impacting change.', 'created_at': datetime.datetime(2024, 12, 18, 23, 9, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553093028, 'issue_id': 2743597771, 'author': 'kaxil', 'body': '> Right, I think this should now pass the tests, the only thing I\'m not sure about this is the xfail I\'ve put for the ""simple ti roundtrip exec config tests"" -- Either we should remove it or make it work, but I\'m not sure if we need to pass down executor config via TI anymore\r\n> \r\n> @kaxil Any ideas the best plan for that one?\r\n\r\nSince we are planning to handle callbacks via Executor/worker interface too -- don\'t think we need to pass it explicitly from TI, instead just handle it on the server side before sending TI/request to the worker.', 'created_at': datetime.datetime(2024, 12, 19, 8, 43, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553569262, 'issue_id': 2743597771, 'author': 'ashb', 'body': ""I'm going to run this with full tests, I want the kube tests to see if there is something broken not covered by unit tests"", 'created_at': datetime.datetime(2024, 12, 19, 12, 1, 34, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-12-16 23:25:47 UTC): The tests aren't 100% finished yet.

And this change is larger than I would have liked, but at least it's a net-negative change

ashb (Issue Creator) on (2024-12-16 23:49:38 UTC): I don't expect tests to pass yet, but I want to give people the chance to see this PR, and I know @jedcunningham is waiting on this for some of his DAG versioning work.

kaxil on (2024-12-17 06:59:15 UTC): nasty/unwanted depenednecy between the Dag Parsing code upon the TaskSDK.

I think that is unavoidable, as user code will come from Task SDK


new ""apache-airflow-base-executor"" dist where this subprocess+supervisor
could live, as the ""execution_time"" folder in the Task SDK is more a feature
of the executor, not of the TaskSDK itself)

Right, I think processor will have to depend on both Task SDK (user-facing code) + Base Executor dist -- after that separation

ashb (Issue Creator) on (2024-12-18 23:09:02 UTC): Right, I think this should now pass the tests, the only thing I'm not sure about this is the xfail I've put for the ""simple ti roundtrip exec config tests"" -- Either we should remove it or make it work, but I'm not sure if we need to pass down executor config via TI anymore

@kaxil Any ideas the best plan for that one?

ashb (Issue Creator) on (2024-12-18 23:09:26 UTC): (I still need to rename a class and file, but that is a non-meaningful/non-review-impacting change.

kaxil on (2024-12-19 08:43:53 UTC): Since we are planning to handle callbacks via Executor/worker interface too -- don't think we need to pass it explicitly from TI, instead just handle it on the server side before sending TI/request to the worker.

ashb (Issue Creator) on (2024-12-19 12:01:34 UTC): I'm going to run this with full tests, I want the kube tests to see if there is something broken not covered by unit tests

"
2743502962,pull_request,closed,,"Introduce GCP translation (V3), translate document providers","- Add TranslateDocumentOperator and TranslateDocumentBatchOperator operators.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-12-16 22:13:46+00:00,[],2024-12-18 10:01:05+00:00,2024-12-18 10:01:05+00:00,https://github.com/apache/airflow/pull/44971,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2549371987, 'issue_id': 2743502962, 'author': 'potiuk', 'body': 'cc: @MaksYermak ?', 'created_at': datetime.datetime(2024, 12, 17, 19, 3, 46, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-17 19:03:46 UTC): cc: @MaksYermak ?

"
2743411514,pull_request,closed,,Fix python task context test - conf has been removed,"PR #44820 removed `conf` from task context, but these tests still expect it.",jedcunningham,2024-12-16 21:14:13+00:00,[],2024-12-17 09:27:04+00:00,2024-12-16 22:05:26+00:00,https://github.com/apache/airflow/pull/44970,"[('area:providers', ''), ('provider:standard', '')]","[{'comment_id': 2547923026, 'issue_id': 2743411514, 'author': 'kaxil', 'body': 'Thanks for fixing it Jed', 'created_at': datetime.datetime(2024, 12, 17, 9, 27, 2, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-12-17 09:27:02 UTC): Thanks for fixing it Jed

"
2743298337,pull_request,closed,,Remove unreachable code in `_transform_ti_states`,"Small improvements in airflow/api_fastapi/common/parameters.py:_transform_ti_states

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-16 20:07:24+00:00,[],2024-12-17 00:41:00+00:00,2024-12-17 00:40:58+00:00,https://github.com/apache/airflow/pull/44969,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2743248306,pull_request,closed,,Deprecate `conf` from Task Context,"This was initially added in response to https://github.com/apache/airflow/issues/168. However, we now have `ti.log_url` that is used for that; example usages:

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/airflow/models/taskinstance.py#L1362

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/providers/src/airflow/providers/smtp/notifications/templates/email.html#L28

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/docs/apache-airflow/howto/email-config.rst?plain=1#L76

So, to simplify what we need to pass from API server to the Task SDK in preparation for Airflow 3, I want to simplify and remove things that aren't needed. In this case, this is good so we don't pass/expore secrets unnecesarily via `conf`. This is removed in Airflow 3 and deprecated in 2.10.x/2.11

Mailing list Thread: https://lists.apache.org/thread/2n0l8y2oyq4442p0lsnmbbcl6rmbj3k7

PR for Airflow 3: https://github.com/apache/airflow/pull/44820

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-16 19:43:59+00:00,[],2024-12-17 14:50:47+00:00,2024-12-17 10:59:02+00:00,https://github.com/apache/airflow/pull/44968,[],"[{'comment_id': 2546555476, 'issue_id': 2743248306, 'author': 'kaxil', 'body': '@jscheffl / @uranusjr -- Does this good look for 2.10.5/2.11?', 'created_at': datetime.datetime(2024, 12, 16, 19, 44, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546639050, 'issue_id': 2743248306, 'author': 'kaxil', 'body': '> Look good.\r\n> \r\n> Can you please also add a deprecation note to https://github.com/apache/airflow/blob/v2-10-test/docs/apache-airflow/templates-ref.rst#deprecated-variables ?\r\n> \r\n> Newsfragment would also be good!\r\n\r\nDone in https://github.com/apache/airflow/pull/44968/commits/a28a1189394b6fc7b9258231cbdcacd89a98515a', 'created_at': datetime.datetime(2024, 12, 16, 20, 16, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547409350, 'issue_id': 2743248306, 'author': 'uranusjr', 'body': 'Should this target 2.11.0 instead? It may be weird for users if a deprecation warning starts showing up when they do a patch version upgrade.', 'created_at': datetime.datetime(2024, 12, 17, 3, 7, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547565919, 'issue_id': 2743248306, 'author': 'jscheffl', 'body': ""> Should this target 2.11.0 instead? It may be weird for users if a deprecation warning starts showing up when they do a patch version upgrade.\r\n\r\nWe had this for other places as well - if we know about a deprecation we should inform users as soon as we know. I'd also propose to not hold-back the information about upcoming deprecation."", 'created_at': datetime.datetime(2024, 12, 17, 5, 54, 53, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-12-16 19:44:48 UTC): @jscheffl / @uranusjr -- Does this good look for 2.10.5/2.11?

kaxil (Issue Creator) on (2024-12-16 20:16:30 UTC): Done in https://github.com/apache/airflow/pull/44968/commits/a28a1189394b6fc7b9258231cbdcacd89a98515a

uranusjr on (2024-12-17 03:07:12 UTC): Should this target 2.11.0 instead? It may be weird for users if a deprecation warning starts showing up when they do a patch version upgrade.

jscheffl on (2024-12-17 05:54:53 UTC): We had this for other places as well - if we know about a deprecation we should inform users as soon as we know. I'd also propose to not hold-back the information about upcoming deprecation.

"
2743203525,pull_request,closed,,"Compare k8s executor against alias, not full ExecutorName repr","This is a permanent fix for what was patched in #44931 (thanks again @amoghrajesh!). Here we extract the alias from the ExecutorName of the default executor to compare with instead of using string repr of the entire name. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-12-16 19:26:15+00:00,[],2024-12-17 06:37:48+00:00,2024-12-17 06:37:47+00:00,https://github.com/apache/airflow/pull/44967,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2546463347, 'issue_id': 2743203525, 'author': 'o-nikolas', 'body': 'CC @amoghrajesh @potiuk', 'created_at': datetime.datetime(2024, 12, 16, 19, 26, 59, tzinfo=datetime.timezone.utc)}]","o-nikolas (Issue Creator) on (2024-12-16 19:26:59 UTC): CC @amoghrajesh @potiuk

"
2743153858,pull_request,closed,,Add dependaboat to check upgrades daily,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-16 19:00:11+00:00,[],2024-12-21 05:24:25+00:00,2024-12-17 15:57:58+00:00,https://github.com/apache/airflow/pull/44966,"[('area:dev-tools', '')]","[{'comment_id': 2546414080, 'issue_id': 2743153858, 'author': 'gopidesupavan', 'body': ""We can configure if any prefix required in PR title. ?\r\n\r\ncurrently it doesn't support the cron expression, so have given daily.\r\n\r\nWe have dependency in pre-commit , but unfortunately  dependaboat is not supported to bump dependencies in pre-commit."", 'created_at': datetime.datetime(2024, 12, 16, 19, 4, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546433833, 'issue_id': 2743153858, 'author': 'gopidesupavan', 'body': 'Do we need to group any package updates ? \r\n\r\nhttps://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file#groups\r\n\r\nhttps://github.blog/changelog/2023-06-30-grouped-version-updates-for-dependabot-public-beta/', 'created_at': datetime.datetime(2024, 12, 16, 19, 14, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549215549, 'issue_id': 2743153858, 'author': 'gopidesupavan', 'body': 'Thanks for the merge :) was bit of on travel today. it looks like dependaboat already started playing his role. hahah', 'created_at': datetime.datetime(2024, 12, 17, 18, 3, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549218206, 'issue_id': 2743153858, 'author': 'gopidesupavan', 'body': 'https://github.com/apache/airflow/pulls/app%2Fdependabot', 'created_at': datetime.datetime(2024, 12, 17, 18, 4, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549305360, 'issue_id': 2743153858, 'author': 'gopidesupavan', 'body': '> LGTM - but added one more comment about adding `./dev/breeze` as well.\r\n\r\nThanks for pointing missed that :)', 'created_at': datetime.datetime(2024, 12, 17, 18, 40, 19, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-12-16 19:04:06 UTC): We can configure if any prefix required in PR title. ?

currently it doesn't support the cron expression, so have given daily.

We have dependency in pre-commit , but unfortunately  dependaboat is not supported to bump dependencies in pre-commit.

gopidesupavan (Issue Creator) on (2024-12-16 19:14:49 UTC): Do we need to group any package updates ? 

https://docs.github.com/en/code-security/dependabot/dependabot-version-updates/configuration-options-for-the-dependabot.yml-file#groups

https://github.blog/changelog/2023-06-30-grouped-version-updates-for-dependabot-public-beta/

gopidesupavan (Issue Creator) on (2024-12-17 18:03:27 UTC): Thanks for the merge :) was bit of on travel today. it looks like dependaboat already started playing his role. hahah

gopidesupavan (Issue Creator) on (2024-12-17 18:04:54 UTC): https://github.com/apache/airflow/pulls/app%2Fdependabot

gopidesupavan (Issue Creator) on (2024-12-17 18:40:19 UTC): Thanks for pointing missed that :)

"
2742638511,pull_request,closed,,Set container name to envSourceContainerName in KEDA ScaledObject,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44798 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-12-16 15:06:56+00:00,[],2025-01-27 12:20:31+00:00,2025-01-27 02:21:28+00:00,https://github.com/apache/airflow/pull/44963,"[('area:helm-chart', 'Airflow Helm Chart'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2581166242, 'issue_id': 2742638511, 'author': 'eladkal', 'body': 'Can you resolve conflicts and rebase?', 'created_at': datetime.datetime(2025, 1, 9, 20, 13, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581643774, 'issue_id': 2742638511, 'author': 'jx2lee', 'body': '@eladkal Yes, Done!', 'created_at': datetime.datetime(2025, 1, 10, 3, 0, 18, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-01-09 20:13:39 UTC): Can you resolve conflicts and rebase?

jx2lee (Issue Creator) on (2025-01-10 03:00:18 UTC): @eladkal Yes, Done!

"
2742474250,pull_request,closed,,Correct the Session argument's type hint in ApplessSecurityManager,"In #33901 this was moved to a new file and mistakenly changed to
flask_session.

It's not clear to me why this didn't cause errors, but it was highlighted in
my editor as an invalid type :shrug:
",ashb,2024-12-16 14:00:17+00:00,[],2024-12-16 14:39:41+00:00,2024-12-16 14:39:37+00:00,https://github.com/apache/airflow/pull/44962,"[('area:webserver', 'Webserver related Issues')]",[],
2742467522,pull_request,closed,,Add asset events to dashboard,"Add asset events to dashboard to display the top 6 events sorted by default newest first (latest) asset events. The source links to the task instance the created the event. The selected time from filter is applied to the API to get only events in last 12 hours, past week etc. The triggered dagruns links to the dagruns triggered due to the asset event.

Notes to reviewer and self

1. The UI prototype had small circle to denote the task instance and dagrun status but this might cause more API calls.
2. The first dagrun is linked with the prototype a link to ""+n more"" where n are the remaining dagruns. But currently there is no asset page to link to for better information and how do we display the same.
3. When there is `from_rest_api` it's usually from API and source is displayed as API. Similar can be done for asset events from trigger. Opened #44944 for discussion.
4. The UI prototype displays `asset.uri` for the card. Do we need to display `asset.name` or `asset.uri` ?
5. The variant should be flushed but typescript doesn't agree with the variant to remove border as per design.
6. In case of no events does this section needs to be displayed?
7. Padding, margin and other style comments welcome.

Related #42700 

![image](https://github.com/user-attachments/assets/b5a36391-d1cd-47ef-9540-805cd9293327)

![image](https://github.com/user-attachments/assets/b41bf4f4-b0e6-42e2-9fee-32391c407538)
",tirkarthi,2024-12-16 13:57:22+00:00,[],2025-01-27 12:59:14+00:00,2025-01-23 19:50:28+00:00,https://github.com/apache/airflow/pull/44961,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2545702753, 'issue_id': 2742467522, 'author': 'tirkarthi', 'body': 'cc: @uranusjr @Lee-W for feedback on asset events in UI', 'created_at': datetime.datetime(2024, 12, 16, 13, 58, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566760508, 'issue_id': 2742467522, 'author': 'jscheffl', 'body': 'Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.', 'created_at': datetime.datetime(2025, 1, 1, 0, 3, 49, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-12-16 13:58:11 UTC): cc: @uranusjr @Lee-W for feedback on asset events in UI

jscheffl on (2025-01-01 00:03:49 UTC): Note: As PR #45312 has been merged, the code formatting rules have changed for new UI. Please rebase and re-run pre-commit checks to ensure that formatting in folder airflow/ui is adjusted.

"
2742464707,pull_request,closed,,Accept task_key as an argument in `DatabricksNotebookOperator`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


<!-- Please keep an empty line above the dashes. -->
This PR introduces the ability for users to explicitly specify `databricks_task_key` as a parameter for the `DatabricksNotebookOperator`. If `databricks_task_key` is not provided, a default value is generated using the hash of the `dag_id` and `task_id`.

Key Changes:
* Users can now define databricks_task_key explicitly.
* When not provided, the key defaults to a deterministic hash based on dag_id and task_id.

Fixes: #41816
Fixes: #44250
related: #43106



---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hardeybisey,2024-12-16 13:56:19+00:00,[],2024-12-26 07:46:58+00:00,2024-12-26 07:46:58+00:00,https://github.com/apache/airflow/pull/44960,"[('area:providers', ''), ('provider:databricks', '')]",[],
2742370994,pull_request,closed,,Chart: Default airflow version to 2.10.4,,utkarsharma2,2024-12-16 13:16:15+00:00,[],2025-02-05 15:52:02+00:00,2024-12-16 15:03:05+00:00,https://github.com/apache/airflow/pull/44959,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2742348493,pull_request,closed,,Airflow 2.10.4 has been released,,utkarsharma2,2024-12-16 13:06:16+00:00,[],2024-12-16 18:12:32+00:00,2024-12-16 18:12:31+00:00,https://github.com/apache/airflow/pull/44958,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2742222361,pull_request,closed,,[edge] Replaced null value with question mark in edge logs,"# Overview

In our environment we facing sporadically a null value in a log chunk and this breaks the push into the postgres. Idea of this PR is to replace the null value with question mark to be able to find the null value in the log file and having a not crashing instance.

# Details of changes:
* Replace null value in log chunk with question mark sign.",AutomationDev85,2024-12-16 12:13:28+00:00,[],2024-12-16 13:05:39+00:00,2024-12-16 13:05:39+00:00,https://github.com/apache/airflow/pull/44957,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2741950853,pull_request,closed,,Bump min version of Providers to 2.9,,eladkal,2024-12-16 10:21:34+00:00,[],2024-12-16 18:32:38+00:00,2024-12-16 16:02:24+00:00,https://github.com/apache/airflow/pull/44956,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-beam', ''), ('provider:apache-drill', ''), ('provider:apache-cassandra', ''), ('provider:apache-flink', ''), ('provider:apache-hdfs', ''), ('provider:apache-impala', ''), ('provider:apache-iceberg', '')]","[{'comment_id': 2546324482, 'issue_id': 2741950853, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 12, 16, 18, 16, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546331550, 'issue_id': 2741950853, 'author': 'potiuk', 'body': 'Also we should remove all conditional code with `AIRFLOW_V_2_9_PLUS`. \r\n\r\nI\'ve added a point about ti in ""bumping min version"", \r\n\r\n> 4. Remove `AIRFLOW_V_2_X_PLUS` in all tests (review and update skipif and other conditional\r\n>    behaviour and test_compat.py, where X is the TARGET version we change to. For example\r\n>   when we update min Airflow version to 2.9.0, we should remove all references to AIRFLOW_V_2_9_PLUS\r\n>   simply because ""everything"" in our tests is already 2.9.0+ and there is no need to exclude or\r\n>   modify tests for earlier versions of Airflow.\r\n\r\nhttps://github.com/apache/airflow/blob/main/dev/README_RELEASE_PROVIDER_PACKAGES.md#bump-min-airflow-version-for-providers\r\n\r\nI can do it tomorrow if no-one does it before and if no-one does it before.', 'created_at': datetime.datetime(2024, 12, 16, 18, 19, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546345252, 'issue_id': 2741950853, 'author': 'eladkal', 'body': ""> Also we should remove all conditional code with `AIRFLOW_V_2_9_PLUS`.\r\n\r\nAhhhhh. I looked for `AIRFLOW_V_2_8_PLUS` and didn't find any. I will handle this tommorow."", 'created_at': datetime.datetime(2024, 12, 16, 18, 27, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546355312, 'issue_id': 2741950853, 'author': 'potiuk', 'body': ""> Ahhhhh. I looked for AIRFLOW_V_2_8_PLUS and didn't find any. I will handle this tommorow.\r\n\r\nYeah. It's not really obvious that we need to remove v2.9 when we set min to be v2.9 :) - I know. Had the same problem. \r\n\r\nBut it's the case actually -  and I tried to make it explicit with the example :)."", 'created_at': datetime.datetime(2024, 12, 16, 18, 32, 24, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-16 18:16:08 UTC): Nice!

potiuk on (2024-12-16 18:19:58 UTC): Also we should remove all conditional code with `AIRFLOW_V_2_9_PLUS`. 

I've added a point about ti in ""bumping min version"", 


https://github.com/apache/airflow/blob/main/dev/README_RELEASE_PROVIDER_PACKAGES.md#bump-min-airflow-version-for-providers

I can do it tomorrow if no-one does it before and if no-one does it before.

eladkal (Issue Creator) on (2024-12-16 18:27:13 UTC): Ahhhhh. I looked for `AIRFLOW_V_2_8_PLUS` and didn't find any. I will handle this tommorow.

potiuk on (2024-12-16 18:32:24 UTC): Yeah. It's not really obvious that we need to remove v2.9 when we set min to be v2.9 :) - I know. Had the same problem. 

But it's the case actually -  and I tried to make it explicit with the example :).

"
2741810230,pull_request,closed,,AIP-72: Handling `failed` TI state for `AirflowFailException` & `AirflowSensorTimeout`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/44414

We already have support for handling terminal states from the task execution side as well as the task SDK client side. (almost) and failed state is part of the terminal state.

This PR extends the task runner's run function to handle cases when we have to fail a task: `AirflowFailException, AirflowSensorTimeout`. It is functionally very similar to #44786

As part of failing a task, multiple other things also needs to be done like:
- Callbacks: which will eventually be converted to teardown tasks
- Retries: Handled in https://github.com/apache/airflow/issues/44351
- unmapping TIs: https://github.com/apache/airflow/issues/44351
- Handling task history: will be handled by https://github.com/apache/airflow/issues/44952
- Handling downstream tasks and non teardown tasks: will be handled by https://github.com/apache/airflow/issues/44951

### Testing performed
#### End to End with Postman

1. Run airflow with breeze and run any DAG
![image](https://github.com/user-attachments/assets/fafc89ea-4e28-4802-912b-d72bf401d94b)

2. Login to metadata DB and get the ""id"" for your task instance from TI table
![image](https://github.com/user-attachments/assets/75440f0f-f62a-4277-a2e6-cb78bd666dd4)

3. Send a request to `fail` your task
![image](https://github.com/user-attachments/assets/5991e944-f416-4b79-9954-15f1a6ebdd79)

Or using curl:
```
curl --location --request PATCH 'http://localhost:29091/execution/task-instances/0193cec2-f46b-7348-9c27-9869d835dc7b/state' \
--header 'Content-Type: application/json' \
--data '{
    ""state"": ""failed"",
    ""end_date"": ""2024-10-31T12:00:00Z""
}'
```

4. Refresh back the Airflow UI to see that the task is in failed state.
![image](https://github.com/user-attachments/assets/bb866dc6-e1d6-435e-abe4-2d04c97280ad)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-16 09:22:00+00:00,['amoghrajesh'],2024-12-18 07:34:45+00:00,2024-12-18 07:34:44+00:00,https://github.com/apache/airflow/pull/44954,"[('area:task-sdk', None)]","[{'comment_id': 2550499974, 'issue_id': 2741810230, 'author': 'amoghrajesh', 'body': '@kaxil I will merge this PR once the CI is green to unblock the other PRs which are based on this branch', 'created_at': datetime.datetime(2024, 12, 18, 6, 54, 55, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-18 06:54:55 UTC): @kaxil I will merge this PR once the CI is green to unblock the other PRs which are based on this branch

"
2741749518,pull_request,closed,,Update release docs for bump min Airflow version for providers,adjust release docs to match changes introduced in https://github.com/apache/airflow/pull/44318,eladkal,2024-12-16 08:54:45+00:00,[],2024-12-16 11:48:25+00:00,2024-12-16 11:48:22+00:00,https://github.com/apache/airflow/pull/44953,"[('area:providers', ''), ('area:dev-tools', '')]",[],
2741017350,pull_request,open,,Fixes DatabricksPartitionSensor from immediately failing; returns false in poke method for DatabricksPartitionSensor,"Databricks Partition should return False, not an error. As is, it fails immediately if the partition isn't present. Ie; it has no ability to poke. Let me know if you want any changes.

closes: https://github.com/apache/airflow/issues/44950
related: #ISSUE

---",big-c-note,2024-12-16 00:16:23+00:00,[],2025-01-26 07:59:19+00:00,,https://github.com/apache/airflow/pull/44949,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2544224991, 'issue_id': 2741017350, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 16, 0, 16, 28, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-16 00:16:28 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2740954878,pull_request,closed,,Fix edge doc merge conflict artefact,I found a merge-conflict artifact in edge executor ... probably resulting from a merge conflict. Lines 308-310 are actually a copy from lines 35-37,jscheffl,2024-12-15 22:47:22+00:00,[],2024-12-16 05:51:35+00:00,2024-12-16 05:51:34+00:00,https://github.com/apache/airflow/pull/44948,"[('area:providers', ''), ('kind:documentation', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2740938760,pull_request,closed,,Update hatchling on broken canary check,"Hatchling was released and broke canary. See https://github.com/apache/airflow/actions/runs/12341655218/job/34440551029

This PR makes the needed upgrade",jscheffl,2024-12-15 22:20:48+00:00,[],2024-12-16 19:05:26+00:00,2024-12-16 04:41:04+00:00,https://github.com/apache/airflow/pull/44947,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2546265116, 'issue_id': 2740938760, 'author': 'potiuk', 'body': '> It seems dependaboat is not working properly on our repo for pip packaging upgrades, some time back we have made changes at dependaboat repo to upgrade dependency under build-requires.\r\n\r\n> I think it might require some config changes or workflow changes in this repo. I will look into tomorrow.\r\n\r\nIs that change released already ? If so, then I am quite sure we need to configure it - and then we will be able to disable the manual check we have now that breaks canary for build-dependencies.', 'created_at': datetime.datetime(2024, 12, 16, 17, 46, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546265433, 'issue_id': 2740938760, 'author': 'potiuk', 'body': 'Nice one BTW!', 'created_at': datetime.datetime(2024, 12, 16, 17, 46, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546301284, 'issue_id': 2740938760, 'author': 'gopidesupavan', 'body': '> > It seems dependaboat is not working properly on our repo for pip packaging upgrades, some time back we have made changes at dependaboat repo to upgrade dependency under build-requires.\r\n> \r\n> > I think it might require some config changes or workflow changes in this repo. I will look into tomorrow.\r\n> \r\n> Is that change released already ? If so, then I am quite sure we need to configure it - and then we will be able to disable the manual check we have now that breaks canary for build-dependencies.\r\n\r\nYes its released , oh okay , i thought dependaboat already configured on our repo and could see frequently prs from dependaboat for UI library upgrades.', 'created_at': datetime.datetime(2024, 12, 16, 18, 4, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546341072, 'issue_id': 2740938760, 'author': 'potiuk', 'body': ""> Yes its released , oh okay , i thought dependaboat already configured on our repo and could see frequently prs from dependaboat for UI library upgrades.\r\n\r\nWe are using dynamic dependencies generated by hatch_build.py - not stored in pyproject.toml, so we don't use dependabot for Python {yet)."", 'created_at': datetime.datetime(2024, 12, 16, 18, 25, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546416419, 'issue_id': 2740938760, 'author': 'gopidesupavan', 'body': ""> > Yes its released , oh okay , i thought dependaboat already configured on our repo and could see frequently prs from dependaboat for UI library upgrades.\r\n> \r\n> We are using dynamic dependencies generated by hatch_build.py - not stored in pyproject.toml, so we don't use dependabot for Python {yet).\r\n\r\noh okay, have raised change here https://github.com/apache/airflow/pull/44966. :)"", 'created_at': datetime.datetime(2024, 12, 16, 19, 5, 24, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-16 17:46:33 UTC): Is that change released already ? If so, then I am quite sure we need to configure it - and then we will be able to disable the manual check we have now that breaks canary for build-dependencies.

potiuk on (2024-12-16 17:46:42 UTC): Nice one BTW!

gopidesupavan on (2024-12-16 18:04:26 UTC): Yes its released , oh okay , i thought dependaboat already configured on our repo and could see frequently prs from dependaboat for UI library upgrades.

potiuk on (2024-12-16 18:25:05 UTC): We are using dynamic dependencies generated by hatch_build.py - not stored in pyproject.toml, so we don't use dependabot for Python {yet).

gopidesupavan on (2024-12-16 19:05:24 UTC): oh okay, have raised change here https://github.com/apache/airflow/pull/44966. :)

"
2740796594,pull_request,closed,,Fix notify-slack-failure job in workflow,"Have updated slack notification job to pin the github commit sha, part of this https://github.com/apache/airflow/pull/44935.

It seems action is expecting the method name. We have missed failure alert ðŸ˜ž 
https://github.com/apache/airflow/actions/runs/12336892300/job/34431569084

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-15 18:01:51+00:00,[],2024-12-15 19:06:03+00:00,2024-12-15 19:05:56+00:00,https://github.com/apache/airflow/pull/44945,"[('area:dev-tools', '')]","[{'comment_id': 2543985489, 'issue_id': 2740796594, 'author': 'jscheffl', 'body': 'Interesting. How did it work before?!?', 'created_at': datetime.datetime(2024, 12, 15, 18, 13, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543991493, 'issue_id': 2740796594, 'author': 'gopidesupavan', 'body': '> Interesting. How did it work before?!?\r\n\r\nSlack 2.0.0 introduced breaking changes. I think now we have to provide explicitly which method we are calling. Ex: they have multiple methods updateMessage, postMessage etc;\r\n\r\nNot sure how to test this, it might end up multiple turns to workout these if again fails or best case hopefully it works after this merge', 'created_at': datetime.datetime(2024, 12, 15, 18, 28, 6, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-15 18:13:48 UTC): Interesting. How did it work before?!?

gopidesupavan (Issue Creator) on (2024-12-15 18:28:06 UTC): Slack 2.0.0 introduced breaking changes. I think now we have to provide explicitly which method we are calling. Ex: they have multiple methods updateMessage, postMessage etc;

Not sure how to test this, it might end up multiple turns to workout these if again fails or best case hopefully it works after this merge

"
2740498410,pull_request,closed,,Add variables,"related: #43709 

<img width=""1051"" alt=""image"" src=""https://github.com/user-attachments/assets/60e19bed-920e-4d38-934b-51f8e44f0463"" />

<img width=""1051"" alt=""image"" src=""https://github.com/user-attachments/assets/980d0fcc-8678-4654-b653-fdeff224de72"" />


<img width=""1051"" alt=""image"" src=""https://github.com/user-attachments/assets/7668b223-caf3-4ec4-90d1-21b868a79fea"" />

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-15 10:05:45+00:00,[],2024-12-24 20:53:58+00:00,2024-12-24 20:53:58+00:00,https://github.com/apache/airflow/pull/44942,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2740496167,pull_request,open,,Modify providers release process for transition to trusted publishing,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-15 10:03:59+00:00,[],2025-01-20 16:53:59+00:00,,https://github.com/apache/airflow/pull/44941,"[('area:dev-tools', '')]","[{'comment_id': 2544032202, 'issue_id': 2740496167, 'author': 'eladkal', 'body': ""I'll review tommorow"", 'created_at': datetime.datetime(2024, 12, 15, 20, 0, 10, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-12-15 20:00:10 UTC): I'll review tommorow

"
2740455976,pull_request,closed,,[v2-10-test] Set Autocomplete Off on Login Form - Main (#44929),"* #44019 - Set autocomplete to off for username and password login form

* fixed static check
(cherry picked from commit c77c7f003a2458698a1d5a440670b9728783ff78)

Co-authored-by: James Regan <spartyman1234@gmail.com>",github-actions[bot],2024-12-15 09:26:21+00:00,[],2025-01-11 19:43:30+00:00,2024-12-15 15:18:54+00:00,https://github.com/apache/airflow/pull/44940,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2543659722, 'issue_id': 2740455976, 'author': 'jscheffl', 'body': 'Re-trigger build...', 'created_at': datetime.datetime(2024, 12, 15, 9, 38, 14, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-15 09:38:14 UTC): Re-trigger build...

"
2740168525,pull_request,closed,,Fix task id validation in BaseOperator,"When dag contains TaskGroup, currently its not accounting TaskGroup id in the task id validation. Causing the scheduler loop failures.

Now this will show as dag import errors in UI.

<img width=""915"" alt=""image"" src=""https://github.com/user-attachments/assets/6396528b-6e40-4b70-984f-2c66596d2d12"" />


related: #44738

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-14 22:24:29+00:00,[],2024-12-15 09:30:28+00:00,2024-12-15 06:20:57+00:00,https://github.com/apache/airflow/pull/44939,"[('area:task-sdk', None)]",[],
2740161156,pull_request,closed,,[v2-10-test] Fix task id validation in BaseOperator,"When dag contains TaskGroup, currently its not accounting TaskGroup id in the task id validation. Causing the scheduler loop failures.

backports: #44939

closes: #44738

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-14 22:01:08+00:00,[],2025-01-28 12:18:41+00:00,2024-12-15 06:21:13+00:00,https://github.com/apache/airflow/pull/44938,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2543373180, 'issue_id': 2740161156, 'author': 'gopidesupavan', 'body': 'before fix, able to re produce.\r\n\r\n<img width=""1334"" alt=""image"" src=""https://github.com/user-attachments/assets/966c3a07-4f6d-41bc-b441-af7442a48934"" />\r\n\r\n\r\n\r\n\r\nAfter fix, it will show as dag import errors.\r\n\r\n![image](https://github.com/user-attachments/assets/edcbf109-3f08-4153-bf38-a881576bf548)', 'created_at': datetime.datetime(2024, 12, 14, 23, 19, 39, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-12-14 23:19:39 UTC): before fix, able to re produce.

<img width=""1334"" alt=""image"" src=""https://github.com/user-attachments/assets/966c3a07-4f6d-41bc-b441-af7442a48934"" />




After fix, it will show as dag import errors.

![image](https://github.com/user-attachments/assets/edcbf109-3f08-4153-bf38-a881576bf548)

"
2740089964,pull_request,closed,,[v2-10-test] Fix premature evaluation in mapped task group,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
will be ported to `main` by: #40460
related: #34023


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-14 18:35:31+00:00,[],2024-12-17 21:07:46+00:00,2024-12-17 21:07:43+00:00,https://github.com/apache/airflow/pull/44937,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', ''), ('area:dynamic-task-mapping', 'AIP-42')]","[{'comment_id': 2548700348, 'issue_id': 2740089964, 'author': 'kaxil', 'body': '@shahar1 Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.', 'created_at': datetime.datetime(2024, 12, 17, 15, 7, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549462624, 'issue_id': 2740089964, 'author': 'shahar1', 'body': '> @shahar1 Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.\r\n\r\nVerified and it works great :)', 'created_at': datetime.datetime(2024, 12, 17, 19, 45, 50, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-12-17 15:07:02 UTC): @shahar1 Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.

shahar1 (Issue Creator) on (2024-12-17 19:45:50 UTC): Verified and it works great :)

"
2740088479,pull_request,closed,,[v2-10-test] Fix premature evaluation in mapped task group,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
backports: #40460 
related: #34023


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-14 18:32:14+00:00,[],2024-12-14 18:32:35+00:00,2024-12-14 18:32:35+00:00,https://github.com/apache/airflow/pull/44936,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]",[],
2739974921,pull_request,closed,,Pin slackapi/slack-github-action to v2.0.0 sha,"As per ASF, we should pin all the external actions.

https://infra.apache.org/github-actions-policy.html

slackapi/slack-github-action: https://github.com/slackapi/slack-github-action/releases/tag/v2.0.0

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-14 16:23:29+00:00,[],2024-12-14 23:21:18+00:00,2024-12-14 23:21:14+00:00,https://github.com/apache/airflow/pull/44935,"[('area:dev-tools', '')]","[{'comment_id': 2543373381, 'issue_id': 2739974921, 'author': 'gopidesupavan', 'body': 'Failures are un related, merging now.', 'created_at': datetime.datetime(2024, 12, 14, 23, 20, 57, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-12-14 23:20:57 UTC): Failures are un related, merging now.

"
2739949137,pull_request,closed,,Pin github/codeql-action action,"As per ASF, we should pin all the external actions.

https://infra.apache.org/github-actions-policy.html

codeql-action: https://github.com/github/codeql-action/tree/v3.27.9

Slack action need to be updated, I will raise separate change, latest slack action release has introduced breaking changes, need to check. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-14 15:33:36+00:00,[],2024-12-14 17:52:16+00:00,2024-12-14 17:51:41+00:00,https://github.com/apache/airflow/pull/44934,"[('area:dev-tools', '')]","[{'comment_id': 2543203158, 'issue_id': 2739949137, 'author': 'amoghrajesh', 'body': 'Some checks failing', 'created_at': datetime.datetime(2024, 12, 14, 17, 47, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543203783, 'issue_id': 2739949137, 'author': 'potiuk', 'body': ""We don't have to pin actions prefixed with `github/` \r\n\r\n```\r\nYou MAY use all actions internal to the apache/*, github/* and actions/* namespaces without restrictions.\r\n```"", 'created_at': datetime.datetime(2024, 12, 14, 17, 48, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543205611, 'issue_id': 2739949137, 'author': 'gopidesupavan', 'body': '> https://infra.apache.org/github-actions-policy.html\r\n\r\noh yeah my bad, missed. will close this one :)', 'created_at': datetime.datetime(2024, 12, 14, 17, 50, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543205984, 'issue_id': 2739949137, 'author': 'gopidesupavan', 'body': 'closing this one, as github/* namespace allowed to use without commit sha.', 'created_at': datetime.datetime(2024, 12, 14, 17, 51, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543206328, 'issue_id': 2739949137, 'author': 'gopidesupavan', 'body': '> Some checks failing\r\n\r\nsorry closed as it not needed :)', 'created_at': datetime.datetime(2024, 12, 14, 17, 52, 15, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2024-12-14 17:47:07 UTC): Some checks failing

potiuk on (2024-12-14 17:48:04 UTC): We don't have to pin actions prefixed with `github/` 

```
You MAY use all actions internal to the apache/*, github/* and actions/* namespaces without restrictions.
```

gopidesupavan (Issue Creator) on (2024-12-14 17:50:55 UTC): oh yeah my bad, missed. will close this one :)

gopidesupavan (Issue Creator) on (2024-12-14 17:51:41 UTC): closing this one, as github/* namespace allowed to use without commit sha.

gopidesupavan (Issue Creator) on (2024-12-14 17:52:15 UTC): sorry closed as it not needed :)

"
2739724027,pull_request,closed,,AIP-79 Register endpoints from auth manager into FastAPI,"
closes: #44882




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2024-12-14 09:21:44+00:00,[],2025-01-28 17:51:57+00:00,2025-01-28 17:51:57+00:00,https://github.com/apache/airflow/pull/44932,[],"[{'comment_id': 2545622475, 'issue_id': 2739724027, 'author': 'jason810496', 'body': 'Thanks for the reminder! Iâ€™ll wait until https://github.com/apache/airflow/issues/44847 is resolved.', 'created_at': datetime.datetime(2024, 12, 16, 13, 22, 32, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-12-16 13:22:32 UTC): Thanks for the reminder! Iâ€™ll wait until https://github.com/apache/airflow/issues/44847 is resolved.

"
2739596812,pull_request,closed,,Fix failing KubeExecutor tests due to #44710,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Recent changes brought in by https://github.com/apache/airflow/pull/44710/ leads to KubeExecutor tests failing.
The reason is because for some reason, the `default_executor` ends up being: `':KubernetesExecutor:'`. This might not be the best fix for it and would require internally debugging things, but it will unblock main CI for now.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-14 05:59:01+00:00,[],2024-12-16 18:34:20+00:00,2024-12-14 17:56:37+00:00,https://github.com/apache/airflow/pull/44931,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2543127033, 'issue_id': 2739596812, 'author': 'eladkal', 'body': 'Lets also please amment the commit message and change the title as this is a fix that we will note in the change log so users needs to know what this is about.', 'created_at': datetime.datetime(2024, 12, 14, 14, 16, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543252498, 'issue_id': 2739596812, 'author': 'potiuk', 'body': 'Somehow that fix (while necessaryf for now) seems to be just workaround cc: @o-nikolas -> was it deliberate change or side-effect ?', 'created_at': datetime.datetime(2024, 12, 14, 18, 18, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543253836, 'issue_id': 2739596812, 'author': 'potiuk', 'body': 'And good job @amoghrajesh on quick-fixing.', 'created_at': datetime.datetime(2024, 12, 14, 18, 19, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543258795, 'issue_id': 2739596812, 'author': 'amoghrajesh', 'body': 'Thanks! Yeah i didnt get enough time to actually debug what went wrong. So, workaround for now', 'created_at': datetime.datetime(2024, 12, 14, 18, 21, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543306859, 'issue_id': 2739596812, 'author': 'o-nikolas', 'body': '> Somehow that fix (while necessaryf for now) seems to be just workaround cc: @o-nikolas -> was it deliberate change or side-effect ?\r\nThere is a lot of context to explain haha, here goes!:\r\n\r\nThis was a deliberate change. Until now we\'ve had the executor name/module path and optionally an alias. If it is a custom executor (provided as a module path) the str repr is `<alias>:<module_path>`. With a ""core executor"" like k8s, we don\'t show the module path because users just provide the always existing ""KubernetesExecutor"" alias. There was a specific branch in the code to do that.\r\nNow when I wrote the changes for team_id the new repr for executors is `<team_id>:<alias>:<module>` and I removed the specail custom branch (or updated really, it\'s still a little special because no module path is shown and you can\'t override the alias) for the ""core executors"". If it is a ""core executor"" like Kubernetes we don\'t show the module path (as mentioned before) and just show its alias, and no team id exists in that test, so the string repr ends up as `:KubernetesExecutor:` with blanks on both sides (kind of like an AWS resource ARN). If there was a team id, it\'d be `my_team:KubernetesExecutor:`. This is why it changed. \r\n\r\nFWIW if it was a custom module path executor, with an alias and a team it would be `my_team:my_cool_exec:exec.module.path.CoolExec`\r\n\r\nI could go back and remove this update, but I really do like that the ""core executors"" are moving closer inline with other executors. The problem comes with how the code here is fetching an executor name (not the executor itself) and comparing it to the `airflow.executors.executor_constants.KUBERNETES_EXECUTOR` which are NOT the same thing.\r\n\r\nDoes that make sense? I know it\'s kind of nuanced and complicated. What do folks think?\r\n\r\nI can look on Monday at updating this code, or what a long term fix might look like.', 'created_at': datetime.datetime(2024, 12, 14, 18, 39, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543320153, 'issue_id': 2739596812, 'author': 'potiuk', 'body': 'yeah. makes perfect sense. I think we should not compare it to the name but determine the class name from the ""default_executor"" and compare it with K8SExecutor class.', 'created_at': datetime.datetime(2024, 12, 14, 19, 28, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543320381, 'issue_id': 2739596812, 'author': 'potiuk', 'body': '(and later when team_id is served when team_id is set for executor, it should only query for tasks with the team_id of course).', 'created_at': datetime.datetime(2024, 12, 14, 19, 29, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2544697690, 'issue_id': 2739596812, 'author': 'amoghrajesh', 'body': 'Thanks @o-nikolas! Yeah that makes good sense.\r\n\r\n> I could go back and remove this update, but I really do like that the ""core executors"" are moving closer inline with other executors. The problem comes with how the code here is fetching an executor name (not the executor itself) and comparing it to the airflow.executors.executor_constants.KUBERNETES_EXECUTOR which are NOT the same thing.\r\n\r\nYea as Jarek mentioned, we should just try to compare the class names or the `repr` values instead. The logic in `clear_not_launched_queued_tasks` and related places should probably be updated to consider the match with team id too', 'created_at': datetime.datetime(2024, 12, 16, 6, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546358779, 'issue_id': 2739596812, 'author': 'o-nikolas', 'body': ""Okay, sounds good, @potiuk @amoghrajesh\r\n\r\nI'll take a look at a more permanent change today.\r\n\r\nAlso note, that I updated me previous comment with more code-formatted text, since it was hiding some of the text! It should be _even_ more clear to read now. Sorry for that extra confusion :sweat_smile:"", 'created_at': datetime.datetime(2024, 12, 16, 18, 34, 18, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-12-14 14:16:45 UTC): Lets also please amment the commit message and change the title as this is a fix that we will note in the change log so users needs to know what this is about.

potiuk on (2024-12-14 18:18:29 UTC): Somehow that fix (while necessaryf for now) seems to be just workaround cc: @o-nikolas -> was it deliberate change or side-effect ?

potiuk on (2024-12-14 18:19:07 UTC): And good job @amoghrajesh on quick-fixing.

amoghrajesh (Issue Creator) on (2024-12-14 18:21:08 UTC): Thanks! Yeah i didnt get enough time to actually debug what went wrong. So, workaround for now

o-nikolas on (2024-12-14 18:39:16 UTC): There is a lot of context to explain haha, here goes!:

This was a deliberate change. Until now we've had the executor name/module path and optionally an alias. If it is a custom executor (provided as a module path) the str repr is `<alias>:<module_path>`. With a ""core executor"" like k8s, we don't show the module path because users just provide the always existing ""KubernetesExecutor"" alias. There was a specific branch in the code to do that.
Now when I wrote the changes for team_id the new repr for executors is `<team_id>:<alias>:<module>` and I removed the specail custom branch (or updated really, it's still a little special because no module path is shown and you can't override the alias) for the ""core executors"". If it is a ""core executor"" like Kubernetes we don't show the module path (as mentioned before) and just show its alias, and no team id exists in that test, so the string repr ends up as `:KubernetesExecutor:` with blanks on both sides (kind of like an AWS resource ARN). If there was a team id, it'd be `my_team:KubernetesExecutor:`. This is why it changed. 

FWIW if it was a custom module path executor, with an alias and a team it would be `my_team:my_cool_exec:exec.module.path.CoolExec`

I could go back and remove this update, but I really do like that the ""core executors"" are moving closer inline with other executors. The problem comes with how the code here is fetching an executor name (not the executor itself) and comparing it to the `airflow.executors.executor_constants.KUBERNETES_EXECUTOR` which are NOT the same thing.

Does that make sense? I know it's kind of nuanced and complicated. What do folks think?

I can look on Monday at updating this code, or what a long term fix might look like.

potiuk on (2024-12-14 19:28:23 UTC): yeah. makes perfect sense. I think we should not compare it to the name but determine the class name from the ""default_executor"" and compare it with K8SExecutor class.

potiuk on (2024-12-14 19:29:17 UTC): (and later when team_id is served when team_id is set for executor, it should only query for tasks with the team_id of course).

amoghrajesh (Issue Creator) on (2024-12-16 06:17:00 UTC): Thanks @o-nikolas! Yeah that makes good sense.


Yea as Jarek mentioned, we should just try to compare the class names or the `repr` values instead. The logic in `clear_not_launched_queued_tasks` and related places should probably be updated to consider the match with team id too

o-nikolas on (2024-12-16 18:34:18 UTC): Okay, sounds good, @potiuk @amoghrajesh

I'll take a look at a more permanent change today.

Also note, that I updated me previous comment with more code-formatted text, since it was hiding some of the text! It should be _even_ more clear to read now. Sorry for that extra confusion :sweat_smile:

"
2739595693,pull_request,closed,,Fix static checks in common SQL hooks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
related: #43747

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-14 05:55:29+00:00,[],2024-12-14 06:51:51+00:00,2024-12-14 06:51:47+00:00,https://github.com/apache/airflow/pull/44930,"[('area:providers', ''), ('provider:common-sql', '')]",[],
2739584667,pull_request,closed,,Set Autocomplete Off on Login Form - Main,"closes: #44019

Updated main Javascript to apply autocomplete=""off"" to both username and password inputs on login page. This will help prevent the browser from providing hints for the username (and password), as requested in the Issue.

Based on Flask-AppBuilder source code, i.e. https://github.com/dpgaspar/Flask-AppBuilder/tree/master/flask_appbuilder/templates/appbuilder/general/security (see login_db.html and login_ldap.html), this should work for both AUTH_DB (default) and AUTH_LDAP authentication, since they both apparently use the same HTML elements in the form.",geraj1010,2024-12-14 05:34:56+00:00,[],2024-12-15 19:54:07+00:00,2024-12-15 09:25:34+00:00,https://github.com/apache/airflow/pull/44929,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2543048915, 'issue_id': 2739584667, 'author': 'jscheffl', 'body': 'Small issue in static check, can you resolve this? Best is to use pre-commit locally then you can catch it before submitting to CI', 'created_at': datetime.datetime(2024, 12, 14, 10, 38, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543328347, 'issue_id': 2739584667, 'author': 'geraj1010', 'body': '> I actually am not a fan that autocomplete is turned off just in sake of ""security"" as usability suffers with this. In my view this is more convenience and is something to be considered on a shared PC... but anyway.\r\n\r\nYea I can see that. Perhaps maybe next iteration can turn this into a Webserver environment variable/Airflow Configuration setting?', 'created_at': datetime.datetime(2024, 12, 14, 20, 0, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543439054, 'issue_id': 2739584667, 'author': 'geraj1010', 'body': '> Small issue in static check, can you resolve this? Best is to use pre-commit locally then you can catch it before submitting to CI\r\n\r\nRight on, thanks for the heads up. All fixed now.', 'created_at': datetime.datetime(2024, 12, 15, 4, 7, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543635722, 'issue_id': 2739584667, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44940""><img src=""https://img.shields.io/badge/PR-44940-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 15, 9, 26, 23, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-12-14 10:38:19 UTC): Small issue in static check, can you resolve this? Best is to use pre-commit locally then you can catch it before submitting to CI

geraj1010 (Issue Creator) on (2024-12-14 20:00:32 UTC): Yea I can see that. Perhaps maybe next iteration can turn this into a Webserver environment variable/Airflow Configuration setting?

geraj1010 (Issue Creator) on (2024-12-15 04:07:28 UTC): Right on, thanks for the heads up. All fixed now.

github-actions[bot] on (2024-12-15 09:26:23 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44940""><img src=""https://img.shields.io/badge/PR-44940-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2739564808,pull_request,closed,,Bump uv to 0.5.9,"https://pypi.org/project/uv/0.5.9/
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-14 04:46:28+00:00,[],2024-12-14 14:08:04+00:00,2024-12-14 14:06:59+00:00,https://github.com/apache/airflow/pull/44928,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2543115026, 'issue_id': 2739564808, 'author': 'kaxil', 'body': '> UV is very super fast doing releases :)\r\n\r\n100%', 'created_at': datetime.datetime(2024, 12, 14, 13, 42, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543122426, 'issue_id': 2739564808, 'author': 'kaxil', 'body': 'Failure is unrelated (should be fixed in https://github.com/apache/airflow/pull/44931), merging', 'created_at': datetime.datetime(2024, 12, 14, 14, 6, 51, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-12-14 13:42:09 UTC): 100%

kaxil (Issue Creator) on (2024-12-14 14:06:51 UTC): Failure is unrelated (should be fixed in https://github.com/apache/airflow/pull/44931), merging

"
2739385476,pull_request,closed,,Import `os` in executor_loader,"That import was removed in #44839, but #44710 wasn't up-to-date with main so static checks there didn't fail. This simply adds it back.",jedcunningham,2024-12-14 00:00:04+00:00,[],2024-12-17 20:55:06+00:00,2024-12-14 00:28:38+00:00,https://github.com/apache/airflow/pull/44927,"[('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2546285645, 'issue_id': 2739385476, 'author': 'o-nikolas', 'body': ""Thanks @jedcunningham \r\nI'm not sure how that happened or wasn't detected. Seems like a test should have failed but didn't? Are we missing coverage?"", 'created_at': datetime.datetime(2024, 12, 16, 17, 56, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546540361, 'issue_id': 2739385476, 'author': 'jedcunningham', 'body': 'No worries, this is just a standard ""branch wasn\'t up to date with main, and tests run from the branch"" scenario. Nothing missing really, just every so often we will have to fix these types of things.', 'created_at': datetime.datetime(2024, 12, 16, 19, 41, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2548440693, 'issue_id': 2739385476, 'author': 'potiuk', 'body': 'Cross-merging PRs. yeah. \r\n\r\nAnd actually yes we **could** do something about it - that could go away if we had the possibility of using ""Merge Queue"" functionality: https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-a-merge-queue\r\n\r\nThe merge queue functionality works in the way, that instead of merging, committer adds PR to merge queue, and they are run in sequence - automatically rebasing them after the previously merged PR is merged - and only actually merging the PR when that ""queued"" PR had succeded again after rebase. \r\n\r\nSo far it was blocked as  INFRA tooling is unable to retrieve ""merger identity"" for necessary ICLA ""audit logs"" when merge queue is used. But @davidarthur from Kafka team run a sandbox environment https://issues.apache.org/jira/browse/INFRA-25932 where   he had shown how it is possible - so now it hangs a bit on INFRA making a decision whether to invest in it, implement missing piece and enable it. \r\n\r\nIf people here would like to comment on ths INFRA ticket and encourage it, having the possibility of using Merge Queues could help us to avoid this kind of issues, without impacting the velocity of merges.', 'created_at': datetime.datetime(2024, 12, 17, 13, 18, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549180171, 'issue_id': 2739385476, 'author': 'o-nikolas', 'body': ""That sounds like an awesome mechanism @potiuk I added a +1 to the ticket (I didn't want to pollute the comment stream where details are being hashed out)."", 'created_at': datetime.datetime(2024, 12, 17, 17, 49, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549193129, 'issue_id': 2739385476, 'author': 'ashb', 'body': 'Merge queue are a double edge sword, especially with our full test matrix taking ~1 hour and our sometimes flakey tests and it would greatly limit the number of PRs we could merge.', 'created_at': datetime.datetime(2024, 12, 17, 17, 53, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549455871, 'issue_id': 2739385476, 'author': 'potiuk', 'body': '> Merge queue are a double edge sword, especially with our full test matrix taking ~1 hour and our sometimes flakey tests and it would greatly limit the number of PRs we could merge.\r\n\r\nNot when we go back and have ARC enabled, our tests elapsed time will go back to 20 minutes, and we already have done pretty damn good job (and continue doing so) on battling flaky tests. With our team effort we already have sometimes days without flaky tests, and yes while I would not want to use merge queues two months ago, I think we are pretty much ready to get it and get it much more stable (especially after we bring back 16 processor machines in our S3 to complete our tests 4 and sometimes even 8 times faster than the current builds. CC: @hussein-awala  :D', 'created_at': datetime.datetime(2024, 12, 17, 19, 41, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549458470, 'issue_id': 2739385476, 'author': 'potiuk', 'body': 'PLus merge queue will STILL use the selective checks optimizations - that is not going to change - so most of the PRS will be done in 10 minutes even without ARC (and maybe less than 4-5 minutes with ARC).', 'created_at': datetime.datetime(2024, 12, 17, 19, 43, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549609003, 'issue_id': 2739385476, 'author': 'o-nikolas', 'body': 'I also think consistency is very important and worth paying a time cost for. Something could have been dropped that was harder to detect except in narrow runtime circumstances.', 'created_at': datetime.datetime(2024, 12, 17, 20, 55, 5, tzinfo=datetime.timezone.utc)}]","o-nikolas on (2024-12-16 17:56:57 UTC): Thanks @jedcunningham 
I'm not sure how that happened or wasn't detected. Seems like a test should have failed but didn't? Are we missing coverage?

jedcunningham (Issue Creator) on (2024-12-16 19:41:22 UTC): No worries, this is just a standard ""branch wasn't up to date with main, and tests run from the branch"" scenario. Nothing missing really, just every so often we will have to fix these types of things.

potiuk on (2024-12-17 13:18:29 UTC): Cross-merging PRs. yeah. 

And actually yes we **could** do something about it - that could go away if we had the possibility of using ""Merge Queue"" functionality: https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/configuring-pull-request-merges/managing-a-merge-queue

The merge queue functionality works in the way, that instead of merging, committer adds PR to merge queue, and they are run in sequence - automatically rebasing them after the previously merged PR is merged - and only actually merging the PR when that ""queued"" PR had succeded again after rebase. 

So far it was blocked as  INFRA tooling is unable to retrieve ""merger identity"" for necessary ICLA ""audit logs"" when merge queue is used. But @davidarthur from Kafka team run a sandbox environment https://issues.apache.org/jira/browse/INFRA-25932 where   he had shown how it is possible - so now it hangs a bit on INFRA making a decision whether to invest in it, implement missing piece and enable it. 

If people here would like to comment on ths INFRA ticket and encourage it, having the possibility of using Merge Queues could help us to avoid this kind of issues, without impacting the velocity of merges.

o-nikolas on (2024-12-17 17:49:24 UTC): That sounds like an awesome mechanism @potiuk I added a +1 to the ticket (I didn't want to pollute the comment stream where details are being hashed out).

ashb on (2024-12-17 17:53:37 UTC): Merge queue are a double edge sword, especially with our full test matrix taking ~1 hour and our sometimes flakey tests and it would greatly limit the number of PRs we could merge.

potiuk on (2024-12-17 19:41:53 UTC): Not when we go back and have ARC enabled, our tests elapsed time will go back to 20 minutes, and we already have done pretty damn good job (and continue doing so) on battling flaky tests. With our team effort we already have sometimes days without flaky tests, and yes while I would not want to use merge queues two months ago, I think we are pretty much ready to get it and get it much more stable (especially after we bring back 16 processor machines in our S3 to complete our tests 4 and sometimes even 8 times faster than the current builds. CC: @hussein-awala  :D

potiuk on (2024-12-17 19:43:27 UTC): PLus merge queue will STILL use the selective checks optimizations - that is not going to change - so most of the PRS will be done in 10 minutes even without ARC (and maybe less than 4-5 minutes with ARC).

o-nikolas on (2024-12-17 20:55:05 UTC): I also think consistency is very important and worth paying a time cost for. Something could have been dropped that was harder to detect except in narrow runtime circumstances.

"
2739374433,pull_request,closed,,Set Autocomplete Off on Login Form - Main,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
closes: #44019 

Updated main Javascript to apply autocomplete=""off"" to both username and password inputs on login page. This will help prevent the browser from providing hints for the username (and password), as requested in the Issue.

Based on Flask-AppBuilder source code, i.e. https://github.com/dpgaspar/Flask-AppBuilder/tree/master/flask_appbuilder/templates/appbuilder/general/security (see login_db.html and login_ldap.html), this should work for both AUTH_DB (default) and AUTH_LDAP authentication, since they both apparently use the same HTML elements in the form.

",geraj1010,2024-12-13 23:42:46+00:00,[],2024-12-14 05:32:25+00:00,2024-12-14 05:32:00+00:00,https://github.com/apache/airflow/pull/44926,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2542592716, 'issue_id': 2739374433, 'author': 'geraj1010', 'body': 'Irrelevant commits are here, closing to resolve this.', 'created_at': datetime.datetime(2024, 12, 14, 0, 38, 47, tzinfo=datetime.timezone.utc)}]","geraj1010 (Issue Creator) on (2024-12-14 00:38:47 UTC): Irrelevant commits are here, closing to resolve this.

"
2739332298,pull_request,closed,,Fix short circuit in mapped tasks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #43883


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-13 22:48:18+00:00,[],2025-02-08 19:27:08+00:00,2025-02-08 19:27:08+00:00,https://github.com/apache/airflow/pull/44925,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', ''), ('area:dynamic-task-mapping', 'AIP-42')]","[{'comment_id': 2642895710, 'issue_id': 2739332298, 'author': 'shahar1', 'body': ""Currently blocked as short circuit operators have not been ported yet.\r\n@ashb Is there anyone currently working on it? (I'd be happy to step in if not)"", 'created_at': datetime.datetime(2025, 2, 7, 13, 20, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2644743411, 'issue_id': 2739332298, 'author': 'shahar1', 'body': 'Drafting, as I start working on implementing the ShortCircuit operator for Airflow 3.\r\nThe contents of this PR might be integrated there already.', 'created_at': datetime.datetime(2025, 2, 8, 9, 23, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2645912199, 'issue_id': 2739332298, 'author': 'shahar1', 'body': 'Will be merged as part of #46584', 'created_at': datetime.datetime(2025, 2, 8, 19, 27, 8, tzinfo=datetime.timezone.utc)}]","shahar1 (Issue Creator) on (2025-02-07 13:20:16 UTC): Currently blocked as short circuit operators have not been ported yet.
@ashb Is there anyone currently working on it? (I'd be happy to step in if not)

shahar1 (Issue Creator) on (2025-02-08 09:23:21 UTC): Drafting, as I start working on implementing the ShortCircuit operator for Airflow 3.
The contents of this PR might be integrated there already.

shahar1 (Issue Creator) on (2025-02-08 19:27:08 UTC): Will be merged as part of #46584

"
2739301017,pull_request,closed,,"Move DAG bundle config into config, not db","This moves the DAG bundle config into the Airflow config, instead of being in the db. This:

- makes it much easier to configure a fresh Airflow instance - no api/cli calls required
- avoids some security concerns by ensuring only deployment managers, with direct access to the instance, can configure these

The primary downside is this does mean you cannot reconfigure an existing bundle in a running Airflow instance.",jedcunningham,2024-12-13 22:27:06+00:00,[],2024-12-17 21:59:33+00:00,2024-12-17 21:59:32+00:00,https://github.com/apache/airflow/pull/44924,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2549726767, 'issue_id': 2739301017, 'author': 'jedcunningham', 'body': 'Remaining failure is unrelated.', 'created_at': datetime.datetime(2024, 12, 17, 21, 59, 2, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-17 21:59:02 UTC): Remaining failure is unrelated.

"
2739237858,pull_request,closed,,Fix static checks in openapi-gen,"https://github.com/apache/airflow/pull/44795/files
https://github.com/apache/airflow/actions/runs/12321831747/job/34394398345#step:8:668

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-13 21:28:58+00:00,[],2024-12-13 21:44:40+00:00,2024-12-13 21:44:31+00:00,https://github.com/apache/airflow/pull/44922,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2739219018,pull_request,closed,,Revert removal of Pydantic model support from PR 44552 to restore compatibility with Airflow 2.10,"PR #44552 removed Pydantic models as cleanup for Airflow 3.

Unfortunately it seems I approved and over-looked in the review that in the compatibility layer to Airflow 2.10 the method calls for serialization using pydantic models were also ""cleaned"".

This PR reverts the code in these sections to make Edge Worker compatible with Airflow 2.10 again.",jscheffl,2024-12-13 21:12:48+00:00,[],2024-12-13 22:13:33+00:00,2024-12-13 22:13:33+00:00,https://github.com/apache/airflow/pull/44921,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2738892001,pull_request,closed,,AIP-72: Simplify `test_get_templated_fields` test,"- Removed logic to do `ast.literal_eval` by changing set to a single member instead of two!
- Added ids for each parameter so we can now see the following:

```
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[None] PASSED                                                                                                  [  6%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[list] PASSED                                                                                                  [ 12%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[empty_dict] PASSED                                                                                            [ 18%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[empty_tuple] PASSED                                                                                           [ 25%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[empty_set] PASSED                                                                                             [ 31%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[string] PASSED                                                                                                [ 37%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[dict] PASSED                                                                                                  [ 43%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[tuple] PASSED                                                                                                 [ 50%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[set] PASSED                                                                                                   [ 56%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_string] PASSED                                                                                      [ 62%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field10-2018-12-06] PASSED                                                                          [ 68%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[datetime] PASSED                                                                                              [ 75%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[class_with_custom_attributes] PASSED                                                                          [ 81%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[nested_class_with_custom_attributes] PASSED                                                                   [ 87%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[large_string] PASSED                                                                                          [ 93%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[large_object] PASSED                                                                                          [100%]
```

instead of the following large string (that we had before):

```
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[None-None] PASSED                                                                                             [  6%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field1-expected_rendered_field1] PASSED                                                             [ 12%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field2-expected_rendered_field2] PASSED                                                             [ 18%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field3-()] PASSED                                                                                   [ 25%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field4-set()] PASSED                                                                                [ 31%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[test-string-test-string] PASSED                                                                               [ 37%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field6-expected_rendered_field6] PASSED                                                             [ 43%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field7-('foo', 'bar')] PASSED                                                                       [ 50%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field8-{'foo'}] PASSED                                                                              [ 56%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[{{ task.task_id }}-test] PASSED                                                                               [ 62%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field10-2018-12-06] PASSED                                                                          [ 68%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field11-2018-12-06 10:55:00+00:00] PASSED                                                           [ 75%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field12-ClassWithCustomAttributes({'att1': 'test', 'att2': '{{ task.task_id }}', 'template_fields': ['att1']})] PASSED [ 81%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field13-ClassWithCustomAttributes({'nested1': ClassWithCustomAttributes({'att1': 'test', 'att2': '{{ task.task_id }}', 'template_fields': ['att1']}), 'nested2': ClassWithCustomAttributes({'att3': '{{ task.task_id }}', 'att4': '{{ task.task_id }}', 'template_fields': ['att3']}), 'template_fields': ['nested1']})] PASSED [ 87%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa-Truncated. You can change this behaviour in [core]max_templated_field_length. 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'... ] PASSED [ 93%]
tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_get_templated_fields[templated_field15-Truncated. You can change this behaviour in [core]max_templated_field_length. 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'... ] PASSED [100%]
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-13 17:41:01+00:00,[],2024-12-13 18:30:12+00:00,2024-12-13 18:30:11+00:00,https://github.com/apache/airflow/pull/44920,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2738716459,pull_request,closed,,Add Oliver to Bosch Teamlist,"Always wanted to and forgot but... @OliverWannenwetsch was missing in the team as key member!

FYI @wolfdn @AutomationDev85 @clellmann @majorosdonat ",jscheffl,2024-12-13 16:04:27+00:00,[],2024-12-13 16:35:04+00:00,2024-12-13 16:35:04+00:00,https://github.com/apache/airflow/pull/44917,[],[],
2738511590,pull_request,closed,,[edge] Sync executor with job table,"# Description

In multi scheduler deployment the Edge_Job table an executor self.running (contains the running task_instance keys which were scheduled by the scheduler)  running out of sync. This PR adds a sync for the running. First it detect the jobs which are in the self.running but removed in the table. Then it removed this jobs from the running. After that the self.runnig contains only the job with were run by the executor and available in the DB.

# Details about changes
* Sync self.running with the edge_job table
",AutomationDev85,2024-12-13 14:21:15+00:00,[],2024-12-13 15:20:03+00:00,2024-12-13 15:20:03+00:00,https://github.com/apache/airflow/pull/44916,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2738469794,pull_request,closed,,Fix docker version for Rancher Desktop,"Fix an issue where the Docker version could not be recognized when using Rancher Desktop and running the breeze command.
Changed to extract only the parts that can be recognized as versions from the version string.


Command that cause problems.
```
breeze --python 3.9 --backend postgres
```

Error message.
```
Traceback (most recent call last):
  File ""/Users/tnk-ysk/.local/bin/breeze"", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/rich_click/rich_command.py"", line 367, in __call__
    return super().__call__(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1157, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/rich_click/rich_command.py"", line 152, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1666, in invoke
    rv = super().invoke(ctx)
         ^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/decorators.py"", line 33, in new_func
    return f(get_current_context(), *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/work/study/tnk-ysk/airflow/dev/breeze/src/airflow_breeze/commands/main_command.py"", line 133, in main
    ctx.forward(shell, extra_args={})
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 804, in forward
    return __self.invoke(__cmd, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/click/core.py"", line 783, in invoke
    return __callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/work/study/tnk-ysk/airflow/dev/breeze/src/airflow_breeze/commands/developer_commands.py"", line 456, in shell
    result = enter_shell(shell_params=shell_params)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/work/study/tnk-ysk/airflow/dev/breeze/src/airflow_breeze/utils/docker_command_utils.py"", line 757, in enter_shell
    perform_environment_checks(quiet=shell_params.quiet)
  File ""/Users/tnk-ysk/work/study/tnk-ysk/airflow/dev/breeze/src/airflow_breeze/utils/docker_command_utils.py"", line 511, in perform_environment_checks
    check_docker_version(quiet)
  File ""/Users/tnk-ysk/work/study/tnk-ysk/airflow/dev/breeze/src/airflow_breeze/utils/docker_command_utils.py"", line 218, in check_docker_version
    good_version = compare_version(docker_version, MIN_DOCKER_VERSION)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/work/study/tnk-ysk/airflow/dev/breeze/src/airflow_breeze/utils/docker_command_utils.py"", line 165, in compare_version
    return version.parse(current_version) >= version.parse(min_version)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/packaging/version.py"", line 56, in parse
    return Version(version)
           ^^^^^^^^^^^^^^^^
  File ""/Users/tnk-ysk/.local/share/uv/tools/apache-airflow-breeze/lib/python3.11/site-packages/packaging/version.py"", line 202, in __init__
    raise InvalidVersion(f""Invalid version: {version!r}"")
packaging.version.InvalidVersion: Invalid version: '27.2.1-rd'
```",tnk-ysk,2024-12-13 14:00:08+00:00,[],2024-12-13 16:49:59+00:00,2024-12-13 16:49:58+00:00,https://github.com/apache/airflow/pull/44915,"[('area:dev-tools', '')]","[{'comment_id': 2541851516, 'issue_id': 2738469794, 'author': 'potiuk', 'body': 'Nice!  thank you !', 'created_at': datetime.datetime(2024, 12, 13, 16, 49, 55, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-13 16:49:55 UTC): Nice!  thank you !

"
2738451493,pull_request,closed,,Handle purging of restarting edge jobs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
If an edge job goes to up_for_retry or restarting state, purging from the database and running jobs are not handled. This leads to remain visible in up_for_retry state in the Admin/Edge Worker job page.
This PR adds handling of these states.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-12-13 13:51:07+00:00,[],2024-12-13 14:37:13+00:00,2024-12-13 14:37:13+00:00,https://github.com/apache/airflow/pull/44914,"[('area:providers', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2738431562,pull_request,closed,,add check to find if common.compat provider is changed in a non-compatible way,"This hook ensures API stability of common.compat provider by validating method signatures between staged and committed versions of Python files

- detect removed methods
- prevent removal of existing arguments
- require default values for new arguments

Few things missing: how to handle imports? Important part of common.compat provider is handling different import paths for different airflow version - for example dataset->asset rename.  
However, at some point we want to drop old version and remove old import. 
Also, we can just import something for internal use in some method, it should not be an API surface.  


Another is nested classes/methods: this wouldn't detect change in NoOpCollector:

```
def get_hook_lineage_collector():
    # Dataset has been renamed as Asset in 3.0
    if AIRFLOW_V_3_0_PLUS:
        from airflow.lineage.hook import get_hook_lineage_collector

        return get_hook_lineage_collector()

    # HookLineageCollector added in 2.10
    if AIRFLOW_V_2_10_PLUS:
        return _get_asset_compat_hook_lineage_collector()

    # For the case that airflow has not yet upgraded to 2.10 or higher,
    # but using the providers that already uses `get_hook_lineage_collector`
    class NoOpCollector:
        """"""
        NoOpCollector is a hook lineage collector that does nothing.

        It is used when you want to disable lineage collection.
        """"""

        # for providers that support asset rename
        def add_input_asset(self, *_, **__):
            pass

        def add_output_asset(self, *_, **__):
            pass

        # for providers that do not support asset rename
        def add_input_dataset(self, *_, **__):
            pass

        def add_output_dataset(self, *_, **__):
            pass

    return NoOpCollector()
```",mobuchowski,2024-12-13 13:41:08+00:00,[],2025-01-11 19:43:37+00:00,2024-12-31 14:50:56+00:00,https://github.com/apache/airflow/pull/44913,"[('area:dev-tools', '')]","[{'comment_id': 2541586255, 'issue_id': 2738431562, 'author': 'potiuk', 'body': 'Nice .. I like the idea. Tried to do similar thing to `common.sql` with stubgen (after initial attempt of doing it similarly to you) - but this explicit approach is I think better - even if requires more code. \r\n\r\nOne other option I saw in Android OS (and maybe that is a good idea for you to explore) - was to turn the signatures into a plain-text file where you keep signatures of public methods - and keep it in the repository next to the code. Then you do not have to check-out the previous version of the code (Which is not always available - in CI we only retrieve single commit and we do not have parent commit by default) - you just generate a new version of such signature ""dump"" file - then pre-commit framework will automatically see that the dump has changed and will fail precommit  (and you would have to commit such modifed file to accept  changed signatures)', 'created_at': datetime.datetime(2024, 12, 13, 14, 30, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541589235, 'issue_id': 2738431562, 'author': 'potiuk', 'body': 'Smth like that:\r\n\r\n```txt\r\nmethod1(a:string, b:string) -> int\r\nmethod2(a:string, b:int) -> bool\r\n```', 'created_at': datetime.datetime(2024, 12, 13, 14, 32, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541596724, 'issue_id': 2738431562, 'author': 'potiuk', 'body': 'This is such a ""current.txt"" generated in Android AOSP file https://android.googlesource.com/platform/frameworks/base/+/160bb7fa60e8ece654e6ce999b6c16af50ee7357/api/current.txt', 'created_at': datetime.datetime(2024, 12, 13, 14, 35, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543970859, 'issue_id': 2738431562, 'author': 'mobuchowski', 'body': '>One other option I saw in Android OS (and maybe that is a good idea for you to explore) - was to turn the signatures into a plain-text file where you keep signatures of public methods - and keep it in the repository next to the code. Then you do not have to check-out the previous version of the code (Which is not always available - in CI we only retrieve single commit and we do not have parent commit by default) - you just generate a new version of such signature ""dump"" file - then pre-commit framework will automatically see that the dump has changed and will fail precommit (and you would have to commit such modifed file to accept changed signatures)\r\n\r\n@potiuk I like it - I think the advantage of this idea is that it allows you to _break_ the compatibility way easier - for example, if the old version of Airflow goes out of scope and providers can move to regular import from core Airflow.\r\n\r\nHowever, the two main issues remain: handling of imports - maybe mark them as API too somehow? This would allow us only to track relevant ones.\r\n\r\nThose nested classes - still not sure how to handle those. And I think if we\'re introducing this type of hook completeness is rather important, because when it passes, it suggests that all is good - while we can still have issues here.', 'created_at': datetime.datetime(2024, 12, 15, 17, 39, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543993069, 'issue_id': 2738431562, 'author': 'potiuk', 'body': '> However, the two main issues remain: handling of imports - maybe mark them as API too somehow? This would allow us only to track relevant ones.\r\n\r\nYes. We could generate that text file as part of imports.\r\n\r\n> Those nested classes - still not sure how to handle those. And I think if we\'re introducing this type of hook completeness is rather important, because when it passes, it suggests that all is good - while we can still have issues here.\r\n\r\nI am not sure if we want to handle or expose nested classes in compat. For me ""nested"" almost by definition means ""private"" and if we are using it differently, we should stop.', 'created_at': datetime.datetime(2024, 12, 15, 18, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2545237256, 'issue_id': 2738431562, 'author': 'mobuchowski', 'body': '@potiuk see that example from example: \r\n\r\n```\r\ndef get_hook_lineage_collector():\r\n    # Dataset has been renamed as Asset in 3.0\r\n    if AIRFLOW_V_3_0_PLUS:\r\n        from airflow.lineage.hook import get_hook_lineage_collector\r\n\r\n        return get_hook_lineage_collector()\r\n\r\n    # HookLineageCollector added in 2.10\r\n    if AIRFLOW_V_2_10_PLUS:\r\n        return _get_asset_compat_hook_lineage_collector()\r\n\r\n    # For the case that airflow has not yet upgraded to 2.10 or higher,\r\n    # but using the providers that already uses `get_hook_lineage_collector`\r\n    class NoOpCollector:\r\n        """"""\r\n        NoOpCollector is a hook lineage collector that does nothing.\r\n\r\n        It is used when you want to disable lineage collection.\r\n        """"""\r\n\r\n        # for providers that support asset rename\r\n        def add_input_asset(self, *_, **__):\r\n            pass\r\n\r\n        def add_output_asset(self, *_, **__):\r\n            pass\r\n\r\n        # for providers that do not support asset rename\r\n        def add_input_dataset(self, *_, **__):\r\n            pass\r\n\r\n        def add_output_dataset(self, *_, **__):\r\n            pass\r\n\r\n    return NoOpCollector()\r\n```\r\n\r\nThis could be done in a different way:\r\n\r\n```\r\n# Top-level code\r\n# Dataset has been renamed as Asset in 3.0\r\nif AIRFLOW_V_3_0_PLUS:\r\n    from airflow.lineage.hook import get_hook_lineage_collector\r\n\r\n    return get_hook_lineage_collector()\r\n\r\n# HookLineageCollector added in 2.10\r\nelif AIRFLOW_V_2_10_PLUS:\r\n    return _get_asset_compat_hook_lineage_collector()\r\n\r\nelse:\r\n    # For the case that airflow has not yet upgraded to 2.10 or higher,\r\n    # but using the providers that already uses `get_hook_lineage_collector`\r\n    def get_hook_lineage_collector():\r\n        class NoOpCollector:\r\n            """"""\r\n            NoOpCollector is a hook lineage collector that does nothing.\r\n\r\n            It is used when you want to disable lineage collection.\r\n            """"""\r\n\r\n            # for providers that support asset rename\r\n            def add_input_asset(self, *_, **__):\r\n                pass\r\n\r\n            def add_output_asset(self, *_, **__):\r\n                pass\r\n\r\n            # for providers that do not support asset rename\r\n            def add_input_dataset(self, *_, **__):\r\n                pass\r\n\r\n            def add_output_dataset(self, *_, **__):\r\n                pass\r\n\r\n        return NoOpCollector()\r\n ```\r\n\r\nHowever, it still would require parsing version variables - and this is pretty important since it\'s good chunk of a reason why common.compat exists in the first place.', 'created_at': datetime.datetime(2024, 12, 16, 10, 47, 3, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-13 14:30:55 UTC): Nice .. I like the idea. Tried to do similar thing to `common.sql` with stubgen (after initial attempt of doing it similarly to you) - but this explicit approach is I think better - even if requires more code. 

One other option I saw in Android OS (and maybe that is a good idea for you to explore) - was to turn the signatures into a plain-text file where you keep signatures of public methods - and keep it in the repository next to the code. Then you do not have to check-out the previous version of the code (Which is not always available - in CI we only retrieve single commit and we do not have parent commit by default) - you just generate a new version of such signature ""dump"" file - then pre-commit framework will automatically see that the dump has changed and will fail precommit  (and you would have to commit such modifed file to accept  changed signatures)

potiuk on (2024-12-13 14:32:10 UTC): Smth like that:

```txt
method1(a:string, b:string) -> int
method2(a:string, b:int) -> bool
```

potiuk on (2024-12-13 14:35:50 UTC): This is such a ""current.txt"" generated in Android AOSP file https://android.googlesource.com/platform/frameworks/base/+/160bb7fa60e8ece654e6ce999b6c16af50ee7357/api/current.txt

mobuchowski (Issue Creator) on (2024-12-15 17:39:36 UTC): @potiuk I like it - I think the advantage of this idea is that it allows you to _break_ the compatibility way easier - for example, if the old version of Airflow goes out of scope and providers can move to regular import from core Airflow.

However, the two main issues remain: handling of imports - maybe mark them as API too somehow? This would allow us only to track relevant ones.

Those nested classes - still not sure how to handle those. And I think if we're introducing this type of hook completeness is rather important, because when it passes, it suggests that all is good - while we can still have issues here.

potiuk on (2024-12-15 18:33:00 UTC): Yes. We could generate that text file as part of imports.


I am not sure if we want to handle or expose nested classes in compat. For me ""nested"" almost by definition means ""private"" and if we are using it differently, we should stop.

mobuchowski (Issue Creator) on (2024-12-16 10:47:03 UTC): @potiuk see that example from example: 

```
def get_hook_lineage_collector():
    # Dataset has been renamed as Asset in 3.0
    if AIRFLOW_V_3_0_PLUS:
        from airflow.lineage.hook import get_hook_lineage_collector

        return get_hook_lineage_collector()

    # HookLineageCollector added in 2.10
    if AIRFLOW_V_2_10_PLUS:
        return _get_asset_compat_hook_lineage_collector()

    # For the case that airflow has not yet upgraded to 2.10 or higher,
    # but using the providers that already uses `get_hook_lineage_collector`
    class NoOpCollector:
        """"""
        NoOpCollector is a hook lineage collector that does nothing.

        It is used when you want to disable lineage collection.
        """"""

        # for providers that support asset rename
        def add_input_asset(self, *_, **__):
            pass

        def add_output_asset(self, *_, **__):
            pass

        # for providers that do not support asset rename
        def add_input_dataset(self, *_, **__):
            pass

        def add_output_dataset(self, *_, **__):
            pass

    return NoOpCollector()
```

This could be done in a different way:

```
# Top-level code
# Dataset has been renamed as Asset in 3.0
if AIRFLOW_V_3_0_PLUS:
    from airflow.lineage.hook import get_hook_lineage_collector

    return get_hook_lineage_collector()

# HookLineageCollector added in 2.10
elif AIRFLOW_V_2_10_PLUS:
    return _get_asset_compat_hook_lineage_collector()

else:
    # For the case that airflow has not yet upgraded to 2.10 or higher,
    # but using the providers that already uses `get_hook_lineage_collector`
    def get_hook_lineage_collector():
        class NoOpCollector:
            """"""
            NoOpCollector is a hook lineage collector that does nothing.

            It is used when you want to disable lineage collection.
            """"""

            # for providers that support asset rename
            def add_input_asset(self, *_, **__):
                pass

            def add_output_asset(self, *_, **__):
                pass

            # for providers that do not support asset rename
            def add_input_dataset(self, *_, **__):
                pass

            def add_output_dataset(self, *_, **__):
                pass

        return NoOpCollector()
 ```

However, it still would require parsing version variables - and this is pretty important since it's good chunk of a reason why common.compat exists in the first place.

"
2738340820,pull_request,closed,,[v2-10-test] Fix short circuit in mapped tasks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
will be ported to `main` by: #44925
related: #43883


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-12-13 12:57:15+00:00,['uranusjr'],2025-01-28 12:16:48+00:00,2024-12-18 06:32:12+00:00,https://github.com/apache/airflow/pull/44912,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2548706246, 'issue_id': 2738340820, 'author': 'kaxil', 'body': '@shahar1 Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.', 'created_at': datetime.datetime(2024, 12, 17, 15, 9, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549458653, 'issue_id': 2738340820, 'author': 'shahar1', 'body': '> @shahar1 Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.\r\n\r\nVerified and it works great :)', 'created_at': datetime.datetime(2024, 12, 17, 19, 43, 34, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-12-17 15:09:14 UTC): @shahar1 Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.

shahar1 (Issue Creator) on (2024-12-17 19:43:34 UTC): Verified and it works great :)

"
2738189297,pull_request,closed,,Allow configuration of sqlalchemy query parameter for JdbcHook and PostgresHook through extras,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This MR allows you to specify sqlalchemy query parameters used when building the sqlalchemy URI through the extra options specified within the connection for as well the JdbcHook as the PostgresHook.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-12-13 11:35:27+00:00,[],2024-12-18 15:39:46+00:00,2024-12-18 15:39:46+00:00,https://github.com/apache/airflow/pull/44910,"[('area:providers', ''), ('provider:jdbc', ''), ('provider:postgres', '')]",[],
2738118345,pull_request,closed,,Better error handling to prevent flaky test_last_chance_exception_handling test,"If the launched subprocess (which in tests just _immediately_ raises an
Exception) exits very quickly before we even try to send the startup message
it would fail with a BrokenPipeError. All we need to do in this case is handle
it as the exit code of the task and it's message (which we already test) will
cover it.

This particular behaviour is hard to reliably catch in tests, so no tests are
added here.
",ashb,2024-12-13 10:56:56+00:00,[],2024-12-13 11:25:12+00:00,2024-12-13 11:25:11+00:00,https://github.com/apache/airflow/pull/44909,"[('area:task-sdk', None)]",[],
2738077896,pull_request,closed,,Add ``airflow config lint`` cli command for lint the configuration changes from Airflow 2.x to Airflow 3.0,"This PR introduces the `airflow config lint` command as part of the Airflow CLI config commands for migration tooling for Airflow 3.0. The purpose of this command is to help users transition from Airflow 2.x to 3.0 by identifying and providing actionable feedback on removed and renamed configuration parameters.

Implementation details:
- Identify parameters that are no longer valid in Airflow 3.0 based on [44555](https://github.com/apache/airflow/issues/44555)
- Highlights renamed parameters and provides guidance for transitioning to their new names and sections in the lint error.
- Provider users options to specify sections, options, and ignore lists for granular control.


<hr>
<h3>CLI Usage Examples:</h3>
<ol>
<li>
<p><strong>Lint all sections and options</strong>:</p>
<pre><code class=""language-bash"">airflow config lint
</code></pre>
</li>
<li>
<p><strong>Lint a specific sections</strong>:</p>
<pre><code class=""language-bash"">airflow config lint --section core,webserver
</code></pre>
</li>
<li>
<p><strong>Lint a specific sections and options</strong>:</p>
<pre><code class=""language-bash"">airflow config lint --section smtp --option smtp_user
</code></pre>
</li>
<li>
<p><strong>Ignore a specific sections during linting</strong>:</p>
<pre><code class=""language-bash"">airflow config lint --ignore-section webserver,api
</code></pre>
</li>
<li>
<p><strong>Ignore a specific options during linting</strong>:</p>
<pre><code class=""language-bash"">airflow config lint --ignore-option smtp_user,session_lifetime_days
</code></pre>
</li>
<li>
<p><strong>Enable verbose output for detailed feedback</strong>:</p>
<pre><code class=""language-bash"">airflow config lint --verbose
</code></pre>
</li>
</ol>

Following is the screenshot of the command used:
<img width=""1160"" alt=""Screenshot 2024-12-17 at 2 56 15â€¯AM"" src=""https://github.com/user-attachments/assets/98e0fcf6-e646-4f83-a262-a59e3c8a4444"" />

closes: [#44555](https://github.com/apache/airflow/issues/44555)
related: [#41641](https://github.com/apache/airflow/issues/41641)
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sunank200,2024-12-13 10:39:39+00:00,['sunank200'],2024-12-19 08:33:47+00:00,2024-12-19 08:32:53+00:00,https://github.com/apache/airflow/pull/44908,"[('area:CLI', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2541357641, 'issue_id': 2738077896, 'author': 'potiuk', 'body': 'NAAAAJS', 'created_at': datetime.datetime(2024, 12, 13, 12, 37, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542210815, 'issue_id': 2738077896, 'author': 'sunank200', 'body': '> Awesome, looks really nice! @sunank200 one comment but thats just a thought. Will it also be possible to add a short README or so in order for someone to deprecate any future options? (Although i think all are done)\r\n\r\nReadme for in how to deprecate options in future? @amoghrajesh can you elaborate on this, please', 'created_at': datetime.datetime(2024, 12, 13, 20, 1, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543866914, 'issue_id': 2738077896, 'author': 'amoghrajesh', 'body': '> > Awesome, looks really nice! @sunank200 one comment but thats just a thought. Will it also be possible to add a short README or so in order for someone to deprecate any future options? (Although i think all are done)\r\n> \r\n> Readme for in how to deprecate options in future? @amoghrajesh can you elaborate on this, please\r\n\r\nYeah, that is what I was hinting at. But looking at the state of this PR, it is a good example for how to do it later in future. So I wouldnt ask for that anymore', 'created_at': datetime.datetime(2024, 12, 15, 13, 5, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2544250188, 'issue_id': 2738077896, 'author': 'uranusjr', 'body': 're: The README topic, I feel at least we should introduce a news fragment on this.\r\n\r\nWe should probably add a page in documentation that guides people through the migrations. This would be useful for us in blogposts and discussions on Airflow 2-to-3 upgrade path. (This should be a separate PR.)', 'created_at': datetime.datetime(2024, 12, 16, 0, 45, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2544252422, 'issue_id': 2738077896, 'author': 'uranusjr', 'body': 'Also tentitively backporting this to 2.11 since it would be very useful for users if it is possible to run the check before upgrading. We need to check if the command actually works manually too.', 'created_at': datetime.datetime(2024, 12, 16, 0, 48, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547475976, 'issue_id': 2738077896, 'author': 'Lee-W', 'body': 'one test case failed', 'created_at': datetime.datetime(2024, 12, 17, 4, 21, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2547622115, 'issue_id': 2738077896, 'author': 'sunank200', 'body': '> one test case failed\r\n\r\nIt was from different section and fixed it now.', 'created_at': datetime.datetime(2024, 12, 17, 6, 42, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2550503943, 'issue_id': 2738077896, 'author': 'Lee-W', 'body': ""@sunank200 One discussion has not yet been resolved. Could you please check whether that has been addressed? If so, I'll merge it. Thanks!"", 'created_at': datetime.datetime(2024, 12, 18, 6, 57, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553074534, 'issue_id': 2738077896, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12409042386\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>âŒ</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/bc813c62ab7acab8138b43d4d83e1e94254c3183""><img src=\'https://img.shields.io/badge/Commit-bc813c6-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker bc813c6 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 19, 8, 33, 45, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-13 12:37:20 UTC): NAAAAJS

sunank200 (Issue Creator) on (2024-12-13 20:01:35 UTC): Readme for in how to deprecate options in future? @amoghrajesh can you elaborate on this, please

amoghrajesh on (2024-12-15 13:05:53 UTC): Yeah, that is what I was hinting at. But looking at the state of this PR, it is a good example for how to do it later in future. So I wouldnt ask for that anymore

uranusjr on (2024-12-16 00:45:13 UTC): re: The README topic, I feel at least we should introduce a news fragment on this.

We should probably add a page in documentation that guides people through the migrations. This would be useful for us in blogposts and discussions on Airflow 2-to-3 upgrade path. (This should be a separate PR.)

uranusjr on (2024-12-16 00:48:18 UTC): Also tentitively backporting this to 2.11 since it would be very useful for users if it is possible to run the check before upgrading. We need to check if the command actually works manually too.

Lee-W on (2024-12-17 04:21:27 UTC): one test case failed

sunank200 (Issue Creator) on (2024-12-17 06:42:20 UTC): It was from different section and fixed it now.

Lee-W on (2024-12-18 06:57:58 UTC): @sunank200 One discussion has not yet been resolved. Could you please check whether that has been addressed? If so, I'll merge it. Thanks!

github-actions[bot] on (2024-12-19 08:33:45 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12409042386'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>âŒ</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/bc813c62ab7acab8138b43d4d83e1e94254c3183""><img src='https://img.shields.io/badge/Commit-bc813c6-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker bc813c6 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2737991778,pull_request,closed,,"AIP-72: Handling ""up_for_reschedule"" task instance states","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/44414

### Server side changes (execution api):
1. Handling `TIRescheduleStatePayload` in `ti_update_state` -> covered by unit test: `test_ti_update_state_to_reschedule`
2. Defining a datamodel for TIRescheduleStatePayload and adding it to the discriminator: ti_state_discriminator

### Client side changes (task sdk):

#### HTTP client:
Added a new function defer that sends a patch request to the `task-instances/{id}/state execution` api with payload: `RescheduleTask`

#### Comms:
Defining a new data model to send a request to patch ti as ""up_for_reschedule"" from task runner to supervisor: `RescheduleTask`  (Added to ToSupervisor)

#### Supervisor:
1. Extended `handle_requests` to receive requests from task runner and forwarding the message to http client to call reschedule.

#### TaskRunner:
Task runner executes: ti.task.execute and raises `AirflowRescheduleException` for rescheduling. This sends a request to supervisor using `SUPERVISOR_COMMS`

Example DAG with which this was tested:
```
from datetime import datetime, timedelta
from airflow.exceptions import AirflowRescheduleException
from airflow.decorators import dag, task
from airflow.utils import timezone


@dag()
def reschedule_dag():
    @task
    def raise_reschedule_exception(**kwargs):
        raise AirflowRescheduleException(reschedule_date=timezone.datetime(2025, 1, 1))

    raise_reschedule_exception()


reschedule_dag()
```



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-13 09:58:06+00:00,['amoghrajesh'],2024-12-18 14:54:23+00:00,2024-12-18 14:54:22+00:00,https://github.com/apache/airflow/pull/44907,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]","[{'comment_id': 2551453265, 'issue_id': 2737991778, 'author': 'amoghrajesh', 'body': '@kaxil merging this one. I think I have handled the comments on this', 'created_at': datetime.datetime(2024, 12, 18, 14, 23, 57, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-18 14:23:57 UTC): @kaxil merging this one. I think I have handled the comments on this

"
2737940929,pull_request,closed,,Raise alarm in Slack only on first attempt,"We have this cool Slack alarm from Github in internal-ci-cd channel.

Sometimes we have a flaky infrastructure or intermittend problem. Also if we make a re-run we get an alarm to slack again on repeated failure.
This PR checkes and only raises an alarm on first attempt.",jscheffl,2024-12-13 09:31:39+00:00,[],2024-12-13 11:49:08+00:00,2024-12-13 11:49:07+00:00,https://github.com/apache/airflow/pull/44906,"[('area:dev-tools', '')]",[],
2737713391,pull_request,closed,,Don't commit for read-only query,,uranusjr,2024-12-13 07:57:43+00:00,[],2024-12-14 01:59:31+00:00,2024-12-14 01:59:30+00:00,https://github.com/apache/airflow/pull/44905,"[('area:task-sdk', None)]","[{'comment_id': 2540937160, 'issue_id': 2737713391, 'author': 'uranusjr', 'body': 'Why are those things failingâ€¦', 'created_at': datetime.datetime(2024, 12, 13, 9, 8, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541046231, 'issue_id': 2737713391, 'author': 'uranusjr', 'body': 'I donâ€™t know why it failed, but I found a way that works.', 'created_at': datetime.datetime(2024, 12, 13, 10, 3, 14, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-12-13 09:08:07 UTC): Why are those things failingâ€¦

uranusjr (Issue Creator) on (2024-12-13 10:03:14 UTC): I donâ€™t know why it failed, but I found a way that works.

"
2737628323,pull_request,closed,,Run RC release command CI check only on canary runs.,"This check takes around 9-10 minutes. As discussed in slack, this check can be run only on canary builds. This helps in improving PRs related to new UI (AIP 38) reducing current time from 10 minutes including this check to 2-3 minutes per run as this step is skipped and also saving CI resources for other PRs.

Ref : https://apache-airflow.slack.com/archives/C07813CNKA8/p1733985375943499",tirkarthi,2024-12-13 07:13:44+00:00,[],2024-12-13 09:40:47+00:00,2024-12-13 09:40:47+00:00,https://github.com/apache/airflow/pull/44904,"[('area:dev-tools', '')]",[],
2737547822,pull_request,closed,,Add link to respective dagrun and task instance from recent runs.,Since dagrun and task instance page are added the recent runs bar chart could link to the respective dagrun and taskinstance making it quick to get to the instance especially when the instance is in failed state for debugging.,tirkarthi,2024-12-13 06:36:29+00:00,[],2024-12-13 13:55:03+00:00,2024-12-13 13:55:02+00:00,https://github.com/apache/airflow/pull/44903,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2737022257,pull_request,closed,,AIP-72: Pass context keys from API Server to Workers,"Part of https://github.com/apache/airflow/issues/44481

This commit augments the TI context available in the Task Execution Interface with the one from the Execution API Server.

In future PRs the following will be added:

- More methods on TI like ti.xcom_pull, ti.xcom_push etc
- Lazy fetching of connections, variables
- Verifying the ""get_current_context"" is working
f3ea195c89

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-12 22:48:19+00:00,[],2024-12-17 06:42:12+00:00,2024-12-16 16:11:20+00:00,https://github.com/apache/airflow/pull/44899,"[('area:task-sdk', None)]",[],
2737013903,pull_request,closed,,Extract all the various DB update calls and processes for Dag Parsing to one place,"The updates to the various DB tables as a result of DAG file parsing and collection are scattered throughout the code base.

This change gathers them all in to one place to make it easier to a) find, and b) see what is changed.

The current situation is the result of organic code growth, but it is now almost impossible to find all the things we update as they are not organized, and were scatterd across at least DagBag, DagProcessor.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dimberman,2024-12-12 22:40:55+00:00,[],2024-12-13 15:51:20+00:00,2024-12-13 15:51:18+00:00,https://github.com/apache/airflow/pull/44898,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2541314274, 'issue_id': 2737013903, 'author': 'ashb', 'body': 'Re-triggering with full tests', 'created_at': datetime.datetime(2024, 12, 13, 12, 12, 12, tzinfo=datetime.timezone.utc)}]","ashb on (2024-12-13 12:12:12 UTC): Re-triggering with full tests

"
2736973891,pull_request,closed,,Bump nanoid from 3.3.7 to 3.3.8 in /airflow/ui,"Bumps [nanoid](https://github.com/ai/nanoid) from 3.3.7 to 3.3.8.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/ai/nanoid/blob/main/CHANGELOG.md"">nanoid's changelog</a>.</em></p>
<blockquote>
<h2>3.3.8</h2>
<ul>
<li>Fixed a way to break Nano ID by passing non-integer size (by <a href=""https://github.com/myndzi""><code>@â€‹myndzi</code></a>).</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/ai/nanoid/commit/3044cd5e73f4cf31795f61f6e6b961c8c0a5c744""><code>3044cd5</code></a> Release 3.3.8 version</li>
<li><a href=""https://github.com/ai/nanoid/commit/4fe34959c34e5b3573889ed4f24fe91d1d3e7231""><code>4fe3495</code></a> Update size limit</li>
<li><a href=""https://github.com/ai/nanoid/commit/d643045f40d6dc8afa000a644d857da1436ed08c""><code>d643045</code></a> Fix pool pollution, infinite loop (<a href=""https://redirect.github.com/ai/nanoid/issues/510"">#510</a>)</li>
<li>See full diff in <a href=""https://github.com/ai/nanoid/compare/3.3.7...3.3.8"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nanoid&package-manager=npm_and_yarn&previous-version=3.3.7&new-version=3.3.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-12-12 22:10:08+00:00,[],2024-12-13 08:59:27+00:00,2024-12-13 08:59:19+00:00,https://github.com/apache/airflow/pull/44897,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2736892144,pull_request,closed,,Rename pre-2-7 defaults to provider_config_fallback_defaults,"After unsuccessful atempts to remove them, renaming and adding appropriate warning against removing them seems to be a good idea.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-12 21:14:24+00:00,[],2024-12-12 22:19:51+00:00,2024-12-12 22:19:50+00:00,https://github.com/apache/airflow/pull/44895,[],[],
2736866162,pull_request,closed,,AIP-72: Add some basic Task Context keys,"part of https://github.com/apache/airflow/issues/44481 . This adds some readily available context keys

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-12 20:56:35+00:00,[],2024-12-12 21:25:14+00:00,2024-12-12 21:25:12+00:00,https://github.com/apache/airflow/pull/44894,"[('area:task-sdk', None)]",[],
2736789090,pull_request,closed,,"Add Google Vertex AI Feature Store - Feature View Sync Operators, Sensor","This PR adds support for [Google Cloud Vertex AI Feature Store synchronization](https://cloud.google.com/vertex-ai/docs/featurestore/latest/sync-data) operations in Apache Airflow. 

[Vertex AI Feature Store](https://cloud.google.com/vertex-ai/docs/featurestore/latest/overview) is a managed, cloud-native feature store service that's integral to Vertex AI. It streamlines your ML feature management and online serving processes by letting you manage your feature data in a BigQuery table or view. You can then serve features online directly from the BigQuery data source.

## Components Added

1. **SyncFeatureViewOperator**: Triggers synchronization of a feature view, updating online serving data from the batch source
2. **GetFeatureViewSyncOperator**: Retrieves status and details of a feature view sync operation
3. **FeatureViewSyncSensor**: Monitors the progress of feature view sync operations
4. **FeatureStoreHook**: Core integration with the Vertex AI Feature Store API

## Usage Example

```python
    sync_task = SyncFeatureViewOperator(
        task_id=""sync_task"",
        project_id=PROJECT_ID,
        location=REGION,
        feature_online_store_id=FEATURE_ONLINE_STORE_ID,
        feature_view_id=FEATURE_VIEW_ID,
    )
    wait_for_sync = FeatureViewSyncSensor(
        task_id=""wait_for_sync"",
        location=REGION,
        feature_view_sync_name=""{{ task_instance.xcom_pull(task_ids='sync_task', key='return_value')}}"",
        poke_interval=60,  # Check every minute
        timeout=600,  # Timeout after 10 minutes
        mode=""reschedule"",
    )
    get_task = GetFeatureViewSyncOperator(
        task_id=""get_task"",
        location=REGION,
        feature_view_sync_name=""{{ task_instance.xcom_pull(task_ids='sync_task', key='return_value')}}"",
    )
    sync_task >> wait_for_sync >> get_task
```",CYarros10,2024-12-12 20:10:32+00:00,[],2024-12-16 18:13:13+00:00,2024-12-16 18:13:13+00:00,https://github.com/apache/airflow/pull/44891,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2736689482,pull_request,closed,,Support multiple SQL queries in Dataproc SQL job,"
<!-- Please keep an empty line above the dashes. -->

DataProcJobBuilder.add_query(query) is misleading, because it can make you think that you can call this function multiple times with different queries and then execute and it will send all queries, but it fact it will sent the last one since its override the queries.

I've added set_queries function which takes a list of strings and send it. Dataproc supports queries list.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amirmor1,2024-12-12 19:13:04+00:00,[],2024-12-15 20:42:53+00:00,2024-12-15 20:42:53+00:00,https://github.com/apache/airflow/pull/44890,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2736626826,pull_request,closed,,"Remove fallback for old, pre 2.7, providers","In ~2.7, we moved provider config from core into the providers themselves. However, if providers that were released before that change was used on 2.7+, there could be failures because the config wouldn't be in those providers! So, we added a fallback for all of the configs that were moved.

As we move toward Airflow 3, we don't need to carry this baggage forever. This does mean provider released in earlier than mid 2023 won't work with Airflow 3 (and I'd imagine there will be other reasons they wont work as well).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-12 18:36:18+00:00,[],2024-12-12 21:21:12+00:00,2024-12-12 21:21:12+00:00,https://github.com/apache/airflow/pull/44888,"[('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2540036581, 'issue_id': 2736626826, 'author': 'potiuk', 'body': 'Closing in favour of #44895', 'created_at': datetime.datetime(2024, 12, 12, 21, 21, 8, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-12-12 21:21:08 UTC): Closing in favour of #44895

"
2736578961,pull_request,closed,,"Remove fallback for old, pre 2.7, providers","In ~2.7, we moved provider config from core into the providers themselves. However, if providers that were released before that change was used on 2.7+, there could be failures because the config wouldn't be in those providers! So, we added a fallback for all of the configs that were moved.

As we move toward Airflow 3, we don't need to carry this baggage forever. This does mean provider released in earlier than mid 2023 won't work with Airflow 3 (and I'd imagine there will be other reasons they wont work as well).

(This was attempted in #44755, but it was reverted as we missed some test failures)",jedcunningham,2024-12-12 18:08:00+00:00,[],2024-12-12 18:37:13+00:00,2024-12-12 18:13:03+00:00,https://github.com/apache/airflow/pull/44887,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:logging', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2539702240, 'issue_id': 2736578961, 'author': 'jedcunningham', 'body': '@potiuk is going to pick this up and open a replacement PR.', 'created_at': datetime.datetime(2024, 12, 12, 18, 13, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539749019, 'issue_id': 2736578961, 'author': 'potiuk', 'body': 'Replacement PR in #44888', 'created_at': datetime.datetime(2024, 12, 12, 18, 37, 11, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-12 18:13:03 UTC): @potiuk is going to pick this up and open a replacement PR.

potiuk on (2024-12-12 18:37:11 UTC): Replacement PR in #44888

"
2736560516,pull_request,closed,,"Revert ""Remove fallback for old, pre 2.7, providers (#44755)""","This reverts commit 02821cc369205b7df5553b79dc19969f63ba0a95.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-12-12 17:58:06+00:00,[],2024-12-12 17:59:55+00:00,2024-12-12 17:59:55+00:00,https://github.com/apache/airflow/pull/44886,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:logging', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]",[],
2736266593,pull_request,closed,,Add traceback output for task in case when SIGTERM was sent during task execution,"This PR adds ability to output traceback when a task instance is killed externally and SIGTERM is sent to a task runner process.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-12-12 15:44:55+00:00,[],2025-01-28 12:15:36+00:00,2024-12-19 13:31:08+00:00,https://github.com/apache/airflow/pull/44880,"[('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2540131035, 'issue_id': 2736266593, 'author': 'ashb', 'body': 'Can you explain why this is useful helpful? I imagine the stack trace is going to be large and mostly not relevent to when a task was SIGTERMd.', 'created_at': datetime.datetime(2024, 12, 12, 22, 23, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541007958, 'issue_id': 2736266593, 'author': 'VladaZakharova', 'body': '> Can you explain why this is useful helpful? I imagine the stack trace is going to be large and mostly not relevent to when a task was SIGTERMd.\r\n\r\nI agree the traceback can be large in some cases, but the idea is to get the code line on which the task was killed. Ideally it will help to troubleshoot issues that we get', 'created_at': datetime.datetime(2024, 12, 13, 9, 43, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541346722, 'issue_id': 2736266593, 'author': 'shahar1', 'body': ""> > Can you explain why this is useful helpful? I imagine the stack trace is going to be large and mostly not relevent to when a task was SIGTERMd.\r\n> \r\n> I agree the traceback can be large in some cases, but the idea is to get the code line on which the task was killed. Ideally it will help to troubleshoot issues that we get\r\n\r\nFollowing Ash's comment - maybe it would be better to utilize a flag/configuration to enable it?"", 'created_at': datetime.datetime(2024, 12, 13, 12, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541412629, 'issue_id': 2736266593, 'author': 'potiuk', 'body': '> Following Ash\'s comment - maybe it would be better to utilize a flag/configuration to enable it?\r\n\r\nYeah. Configuration to enable it would be better. I think the stackrace where the task was killed is not too useful - really - I am not even sure if it will actually show the place where the process is. Signals are always delivered to the main thread (which is one limitation), and I am not even sure if the stacktrace in this case will be showing where the thread was ""in"" before.\r\n\r\nDo you have some examples of such stack-traces generated with it that looks like ""useful"" @VladaZakharova  ?', 'created_at': datetime.datetime(2024, 12, 13, 12, 59, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541615989, 'issue_id': 2736266593, 'author': 'VladaZakharova', 'body': '> > Following Ash\'s comment - maybe it would be better to utilize a flag/configuration to enable it?\r\n> \r\n> Yeah. Configuration to enable it would be better. I think the stackrace where the task was killed is not too useful - really - I am not even sure if it will actually show the place where the process is. Signals are always delivered to the main thread (which is one limitation), and I am not even sure if the stacktrace in this case will be showing where the thread was ""in"" before.\r\n> \r\n> Do you have some examples of such stack-traces generated with it that looks like ""useful"" @VladaZakharova ?\r\n\r\nI think something like this can be useful:\r\n\r\n```\r\nfrom datetime import timedelta\r\nimport time\r\n\r\nimport airflow\r\nfrom providers.src.airflow.providers.standard.operators.python import PythonOperator\r\n\r\n\r\nwith airflow.DAG(\r\n    ""trace_import_timeout"",\r\n    start_date=datetime(2022, 1, 1),\r\n    schedule=None) as dag:\r\n    def f():\r\n        print(""Sleeping"")\r\n        time.sleep(3660)\r\n\r\n\r\n    for ind in range(2):\r\n        PythonOperator(\r\n            dag=dag,\r\n            task_id=f""sleep_120_{ind}"",\r\n            python_callable=f,\r\n        )\r\n```\r\n\r\nAnd the output in the logs will look like this:\r\n```\r\n[2024-12-12, 14:07:20 UTC] {taskinstance.py:2813} ERROR - Received SIGTERM. Terminating subprocesses.\r\n[2024-12-12, 14:07:20 UTC] {taskinstance.py:2814} ERROR - Stacktrace: \r\n  File ""/usr/local/bin/***"", line 8, in <module>\r\n    sys.exit(main())\r\n  File ""/opt/***/***/__main__.py"", line 58, in main\r\n    args.func(args)\r\n  File ""/opt/***/***/cli/cli_config.py"", line 49, in command\r\n    return func(*args, **kwargs)\r\n  File ""/opt/***/***/utils/cli.py"", line 111, in wrapper\r\n    return f(*args, **kwargs)\r\n...\r\n    return func(*args, **kwargs)\r\n  File ""/files/dags/core/example_logs_trace.py"", line 14, in f\r\n    time.sleep(3660)\r\n  File ""/opt/***/***/models/taskinstance.py"", line 2814, in signal_handler\r\n    self.log.error(""Stacktrace: \\n%s"", """".join(traceback.format_stack()))\r\n```\r\nWhich shows what command it was executing when the SIGTERM happened. \r\n\r\nAlso we already have this output if the task failed due to timeout:\r\n```\r\n[2024-12-12, 13:55:41 UTC] {timeout.py:68} ERROR - Process timed out, PID: 1255\r\n[2024-12-12, 13:55:41 UTC] {taskinstance.py:3041} ERROR - Task failed with exception\r\nTraceback (most recent call last):\r\n  File ""/opt/airflow/airflow/models/taskinstance.py"", line 743, in _execute_task\r\n    result = _execute_callable(context=context, **execute_callable_kwargs)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/opt/airflow/airflow/models/taskinstance.py"", line 714, in _execute_callable\r\n    return ExecutionCallableRunner(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 269, in run\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/opt/airflow/airflow/models/baseoperator.py"", line 378, in wrapper\r\n    return func(self, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"", line 195, in execute\r\n    return_value = self.execute_callable()\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"", line 221, in execute_callable\r\n    return runner.run(*self.op_args, **self.op_kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 269, in run\r\n    return func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/files/dags/core/example_logs_trace.py"", line 14, in f\r\n    time.sleep(3660)\r\n  File ""/opt/airflow/airflow/utils/timeout.py"", line 69, in handle_timeout\r\n    raise AirflowTaskTimeout(self.error_message)\r\nairflow.exceptions.AirflowTaskTimeout: Timeout, PID: 1255\r\n```\r\n\r\nMaybe it makes sense to make the output the same short as when we have a timeout error. We still can see in this example that it outputs the place where it failed', 'created_at': datetime.datetime(2024, 12, 13, 14, 45, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553995970, 'issue_id': 2736266593, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12413695687\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>âŒ</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/9186fc57907c89f2f871d54f981f2b6892920e2f""><img src=\'https://img.shields.io/badge/Commit-9186fc5-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 9186fc5 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 19, 13, 31, 54, tzinfo=datetime.timezone.utc)}]","ashb on (2024-12-12 22:23:47 UTC): Can you explain why this is useful helpful? I imagine the stack trace is going to be large and mostly not relevent to when a task was SIGTERMd.

VladaZakharova (Issue Creator) on (2024-12-13 09:43:44 UTC): I agree the traceback can be large in some cases, but the idea is to get the code line on which the task was killed. Ideally it will help to troubleshoot issues that we get

shahar1 on (2024-12-13 12:31:07 UTC): Following Ash's comment - maybe it would be better to utilize a flag/configuration to enable it?

potiuk on (2024-12-13 12:59:26 UTC): Yeah. Configuration to enable it would be better. I think the stackrace where the task was killed is not too useful - really - I am not even sure if it will actually show the place where the process is. Signals are always delivered to the main thread (which is one limitation), and I am not even sure if the stacktrace in this case will be showing where the thread was ""in"" before.

Do you have some examples of such stack-traces generated with it that looks like ""useful"" @VladaZakharova  ?

VladaZakharova (Issue Creator) on (2024-12-13 14:45:40 UTC): I think something like this can be useful:

```
from datetime import timedelta
import time

import airflow
from providers.src.airflow.providers.standard.operators.python import PythonOperator


with airflow.DAG(
    ""trace_import_timeout"",
    start_date=datetime(2022, 1, 1),
    schedule=None) as dag:
    def f():
        print(""Sleeping"")
        time.sleep(3660)


    for ind in range(2):
        PythonOperator(
            dag=dag,
            task_id=f""sleep_120_{ind}"",
            python_callable=f,
        )
```

And the output in the logs will look like this:
```
[2024-12-12, 14:07:20 UTC] {taskinstance.py:2813} ERROR - Received SIGTERM. Terminating subprocesses.
[2024-12-12, 14:07:20 UTC] {taskinstance.py:2814} ERROR - Stacktrace: 
  File ""/usr/local/bin/***"", line 8, in <module>
    sys.exit(main())
  File ""/opt/***/***/__main__.py"", line 58, in main
    args.func(args)
  File ""/opt/***/***/cli/cli_config.py"", line 49, in command
    return func(*args, **kwargs)
  File ""/opt/***/***/utils/cli.py"", line 111, in wrapper
    return f(*args, **kwargs)
...
    return func(*args, **kwargs)
  File ""/files/dags/core/example_logs_trace.py"", line 14, in f
    time.sleep(3660)
  File ""/opt/***/***/models/taskinstance.py"", line 2814, in signal_handler
    self.log.error(""Stacktrace: \n%s"", """".join(traceback.format_stack()))
```
Which shows what command it was executing when the SIGTERM happened. 

Also we already have this output if the task failed due to timeout:
```
[2024-12-12, 13:55:41 UTC] {timeout.py:68} ERROR - Process timed out, PID: 1255
[2024-12-12, 13:55:41 UTC] {taskinstance.py:3041} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 743, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 714, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 269, in run
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 378, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"", line 195, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"", line 221, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/opt/airflow/airflow/utils/operator_helpers.py"", line 269, in run
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File ""/files/dags/core/example_logs_trace.py"", line 14, in f
    time.sleep(3660)
  File ""/opt/airflow/airflow/utils/timeout.py"", line 69, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: Timeout, PID: 1255
```

Maybe it makes sense to make the output the same short as when we have a timeout error. We still can see in this example that it outputs the place where it failed

github-actions[bot] on (2024-12-19 13:31:54 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12413695687'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>âŒ</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/9186fc57907c89f2f871d54f981f2b6892920e2f""><img src='https://img.shields.io/badge/Commit-9186fc5-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 9186fc5 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2736073746,pull_request,open,,feat: kuberay job support,,chenkovsky,2024-12-12 14:29:26+00:00,[],2025-01-12 12:13:59+00:00,,https://github.com/apache/airflow/pull/44878,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2539113395, 'issue_id': 2736073746, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 12, 14, 29, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585709616, 'issue_id': 2736073746, 'author': 'chenkovsky', 'body': 'currently, the pod where the log is collected and the pod where xcom sidecar is located should be same. but for rayjob. log is on submitter, but xcom should be mounted on head. it seems that airflow cannot support this.', 'created_at': datetime.datetime(2025, 1, 12, 12, 13, 58, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-12 14:29:30 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

chenkovsky (Issue Creator) on (2025-01-12 12:13:58 UTC): currently, the pod where the log is collected and the pod where xcom sidecar is located should be same. but for rayjob. log is on submitter, but xcom should be mounted on head. it seems that airflow cannot support this.

"
2736003847,pull_request,closed,,AIP-84 add external dependencies asset condition,"Based on https://github.com/apache/airflow/pull/44701.

Only last commit is relevant. Add `asset-condition` join nodes.

Closes: https://github.com/apache/airflow/issues/42367",pierrejeambrun,2024-12-12 14:00:55+00:00,['pierrejeambrun'],2024-12-16 17:19:36+00:00,2024-12-16 17:19:34+00:00,https://github.com/apache/airflow/pull/44877,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2541991295, 'issue_id': 2736003847, 'author': 'bbovenzi', 'body': ""> I just want to confirm that it's expected for `assets` and `asset-alias` to appear as 'upstream' of the `asset-condition`. It should be consistent with the `getUpstreamAssets` but I just want to make sure.\r\n> \r\n> (Then I make the asset condition upstream of the first node of the graph which sounds normal).\r\n\r\nYes, that sounds right to me"", 'created_at': datetime.datetime(2024, 12, 13, 18, 8, 47, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-12-13 18:08:47 UTC): Yes, that sounds right to me

"
2735916506,pull_request,closed,,Deprecate gcp AutoML module,"closes: #38636

- Regarding the depreciation of AutoML API, deprecate the whole module content.
- Update documentation, regarding the deprecation's.
- Suggested removal date of September 30, 2025.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-12-12 13:28:57+00:00,[],2025-01-04 12:17:51+00:00,2024-12-20 22:33:28+00:00,https://github.com/apache/airflow/pull/44875,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2555746941, 'issue_id': 2735916506, 'author': 'potiuk', 'body': 'Needs rebase now.', 'created_at': datetime.datetime(2024, 12, 19, 20, 49, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2556914082, 'issue_id': 2735916506, 'author': 'olegkachur-e', 'body': '> Needs rebase now.\r\n\r\nThank you! Rebased.', 'created_at': datetime.datetime(2024, 12, 20, 12, 29, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-19 20:49:17 UTC): Needs rebase now.

olegkachur-e (Issue Creator) on (2024-12-20 12:29:16 UTC): Thank you! Rebased.

"
2735888992,pull_request,closed,,Restructure WatchedSubprocess and CommsDecoder for reuse in DagParsing,"The changes introduced here lets these existing classes serve ""double"" duty in
the execution time of TaskSDK and also the Parse Time in the DAG Processor
(but the actual switch to use these will be a separate bigger PR).

There are a few warts left here, namely:

- The default on `CommsDecoder`'s decoder argument is incorrect for
  subclasses, we might fix that later to be more dynamic about the default.
- The location of this code is not right for reuse in TaskSDK/execution time
  and parse time. There is a bigger bit of work being planned to move this all
  around before release of Airflow 3
- Some of the functions on the base `WatchedSubprocess` class are TI specific
  and maybe should be on a separate subclass
",ashb,2024-12-12 13:19:48+00:00,[],2024-12-12 14:04:06+00:00,2024-12-12 14:04:04+00:00,https://github.com/apache/airflow/pull/44874,"[('area:task-sdk', None)]",[],
2735832625,pull_request,closed,,feat: Add CLL to OpenLineage in BigQueryInsertJobOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
BigQueryInsertJobOperator already support OpenLineage for QUERY type jobs, but it lacks Column Level Lineage (CLL). 

This PR introduces CLL (Column-Level Lineage) to this operator based on SQL parsing, which can be useful in straightforward scenarios. However, since SQL parsing alone might not always provide all the details (e.g. in SQL query we can reference table only by table name, or dataset.table without the project_id), checks have been implemented to ensure accurate lineage. As a result CLL may not be included when there is uncertainty about its correctness.

There is another change not related to CLL: right now output table is duplicated into input tables. We are creating a list of input tables based on `referencedTables` property provided by Google and as it turns out, this also includes the destination table. So f.e. this query: 
`INSERT INTO `a.b.c` VALUES (1, ""a"", 23)`
 would return `a.b.c` as input table and output table.

This PR fixes it by removing output table from input tables. I am not sure if it's a correct approach as sometimes users may write a query that performs a process that moves data from one table to the same table but i think this is rare and also this kind of lineage information (from A to A) does not provide much value. Please let me know if you think I'm wrong.

I also refactored the mixin a bit to make it clearer and prepare for adding support for job types other than QUERY. I also change the class name - in the beginning it's supposed to be a general mixin, but BigQueryInsertJobOperator is so complex that this mixin will only be used with that class.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-12 12:58:32+00:00,[],2024-12-30 14:46:09+00:00,2024-12-30 14:43:26+00:00,https://github.com/apache/airflow/pull/44872,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2563782281, 'issue_id': 2735832625, 'author': 'kacpermuda', 'body': 'PR is ready to be merged, there is some unrelated flaky test that makes TestLocalExecutor timeout.', 'created_at': datetime.datetime(2024, 12, 27, 15, 3, 55, tzinfo=datetime.timezone.utc)}]","kacpermuda (Issue Creator) on (2024-12-27 15:03:55 UTC): PR is ready to be merged, there is some unrelated flaky test that makes TestLocalExecutor timeout.

"
2735618477,pull_request,closed,,Hide UI list backfills from documentation,"Private endpoints shoudn't appear in the documentation.

edit: move the setting to the router UI level.",pierrejeambrun,2024-12-12 11:22:11+00:00,['pierrejeambrun'],2024-12-12 15:33:54+00:00,2024-12-12 15:33:52+00:00,https://github.com/apache/airflow/pull/44871,[],[],
2735418485,pull_request,closed,,Add support for XCom page in browse and task instance tab,"Add support to display XCom details for a task instance in a tab. Add a clipboard button next to the value so that user can copy the value easily. The PR also adds global XCom page under browse similar to Events page currently. 

Notes for review and self : 

1. Events page is at `src/pages/Events/` should I move this also to `src/pages/XCom` from current `airflow/ui/src/pages/TaskInstance/XCom` . I started with task instance and later realized it's easier to make this page global .
2. Added `run_id` to the response for better filtering in retrieving value API in the global XCom page without any run id in the URL params.
3. Each XCom entry needs an API call passing `stringify: true` to get the value. I have added a `skeleton` but is it possible to set some value to reuse the `Skeleton` from Table's component.
4. Clipboard button was automatically generated from https://www.chakra-ui.com/docs/components/clipboard . Do I need to move these to individual files or disable the warnings?
5. The value can be pretty printed and highlighted for JSON like legacy UI but can try it in another PR.

```
/home/karthikeyan/stuff/python/airflow/airflow/ui/src/components/ui/clipboard.tsx
   38:27  warning  Declare only one React component per file  react/no-multi-comp
   47:31  warning  Declare only one React component per file  react/no-multi-comp
   61:32  warning  Declare only one React component per file  react/no-multi-comp
   72:30  warning  Declare only one React component per file  react/no-multi-comp
   92:36  warning  Declare only one React component per file  react/no-multi-comp
  104:31  warning  Declare only one React component per file  react/no-multi-comp
```

Related #44667 

![image](https://github.com/user-attachments/assets/dd3a73c6-8646-4274-a366-69aad7a153b4)

![image](https://github.com/user-attachments/assets/b8d67c65-c58d-4869-aad1-86104824ad4f)

XCom under browse page

![image](https://github.com/user-attachments/assets/d291bb29-f160-4fd7-817b-84921401cc3b)

",tirkarthi,2024-12-12 09:56:02+00:00,[],2024-12-16 20:44:35+00:00,2024-12-16 20:44:35+00:00,https://github.com/apache/airflow/pull/44869,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2538636607, 'issue_id': 2735418485, 'author': 'tirkarthi', 'body': 'Not sure why my pre-commit run and the one in CI are different.', 'created_at': datetime.datetime(2024, 12, 12, 11, 33, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538656016, 'issue_id': 2735418485, 'author': 'jscheffl', 'body': 'In the legacy UI in 2.10 I invested a bit of efforts making XCom better readable for users in https://github.com/apache/airflow/pull/40640 . Especially for Dicts and lists. Can you re-apply such feature also for the new XCom display, such that dicts are not just dumped as text? (I know I generated a set of side-effects as bugs which needed to be fixed, so in the new UI we have the chance to make it ""right the first time"" also with a re-usable component for DAG Run Conf.', 'created_at': datetime.datetime(2024, 12, 12, 11, 42, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538699296, 'issue_id': 2735418485, 'author': 'tirkarthi', 'body': 'Thanks @jscheffl, it needs porting `ReactJSON` related component from legacy UI and would like to tackle it in a separate PR as noted in the PR description since it seems to take fair bit of work.', 'created_at': datetime.datetime(2024, 12, 12, 11, 56, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538718473, 'issue_id': 2735418485, 'author': 'jscheffl', 'body': '> Thanks @jscheffl, it needs porting `ReactJSON` related component from legacy UI and would like to tackle it in a separate PR as noted in the PR description since it seems to take fair bit of work.\r\n\r\nFair. As long as it is not forgotten :-D And does not need to be e exactly the same component as in legacy if there are better components nowadays.\r\n\r\nRegarding (3) in your list above: In the past ""Rest API"" call the public XCom endpoint was used and for adding the ""ReactJSON"" I needed to add the ""stringify"" option as workarouns as the stringified version before used Python-style quotes which were not JSON parsable in the React / Javascript code. In the legacy this is really bad (in my view) and it would be better if in the new UI it is made ""right"" from the beginning. I wanted to prevent this in the past not having a breaking change in the REST API - but now would be the time with FastAPI anyway. So `stringify` might need to be set to `false` later back again to get a native object, else would be a waste to re-parse the string to JSON in TypeScript again after REST endpoint', 'created_at': datetime.datetime(2024, 12, 12, 12, 5, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538999993, 'issue_id': 2735418485, 'author': 'tirkarthi', 'body': ""Thanks @jscheffl, here is one rough attempt I can think of. Pass `stringify: false` in the API. Try `JSON.stringify()` and set highlight to true to use `<SyntaxHighlighter />`. On error just convert to string using `String()` and set highlight to be false to render it as normal `<Text>`. But this also means if there is `__str__` implemented for the custom object in Python land then JS `String()` value might be different in case the object doesn't fit `JSON.stringify`.\r\n\r\n![image](https://github.com/user-attachments/assets/6bda7f56-f687-47a2-827c-7bfa0d1cc760)"", 'created_at': datetime.datetime(2024, 12, 12, 13, 45, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2539052383, 'issue_id': 2735418485, 'author': 'jscheffl', 'body': '> Thanks @jscheffl, here is one rough attempt I can think of. Pass `stringify: false` in the API. Try `JSON.stringify()` and set highlight to true to use `<SyntaxHighlighter />`. On error just convert to string using `String()` and set highlight to be false to render it as normal `<Text>`. But this also means if there is `__str__` implemented for the custom object in Python land then JS `String()` value might be different in case the object doesn\'t fit `JSON.stringify`.\r\n> \r\n> ![image](https://private-user-images.githubusercontent.com/3972343/395181638-6bda7f56-f687-47a2-827c-7bfa0d1cc760.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzQwMTI2MzAsIm5iZiI6MTczNDAxMjMzMCwicGF0aCI6Ii8zOTcyMzQzLzM5NTE4MTYzOC02YmRhN2Y1Ni1mNjg3LTQ3YTItODI3Yy03YmZhMGQxY2M3NjAucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIxMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMTJUMTQwNTMwWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9M2M4Y2ZhODY4ZTE0NTk2NjVlMDU4NDI4YjZiYjhiM2E1NjQzMGI0Zjg2ZmZmNWI4ZDYyYmJlZjNhODgxNDAzOCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.loqThpXc82g86JH8Y6JPjQ-dYB5l2HLEU9okqUwSD94)\r\n\r\nYeah, but this is only rough :-) Then rather to it ""right"" in a follow-up PR :+1:', 'created_at': datetime.datetime(2024, 12, 12, 14, 6, 45, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-12-12 11:33:41 UTC): Not sure why my pre-commit run and the one in CI are different.

jscheffl on (2024-12-12 11:42:45 UTC): In the legacy UI in 2.10 I invested a bit of efforts making XCom better readable for users in https://github.com/apache/airflow/pull/40640 . Especially for Dicts and lists. Can you re-apply such feature also for the new XCom display, such that dicts are not just dumped as text? (I know I generated a set of side-effects as bugs which needed to be fixed, so in the new UI we have the chance to make it ""right the first time"" also with a re-usable component for DAG Run Conf.

tirkarthi (Issue Creator) on (2024-12-12 11:56:31 UTC): Thanks @jscheffl, it needs porting `ReactJSON` related component from legacy UI and would like to tackle it in a separate PR as noted in the PR description since it seems to take fair bit of work.

jscheffl on (2024-12-12 12:05:09 UTC): Fair. As long as it is not forgotten :-D And does not need to be e exactly the same component as in legacy if there are better components nowadays.

Regarding (3) in your list above: In the past ""Rest API"" call the public XCom endpoint was used and for adding the ""ReactJSON"" I needed to add the ""stringify"" option as workarouns as the stringified version before used Python-style quotes which were not JSON parsable in the React / Javascript code. In the legacy this is really bad (in my view) and it would be better if in the new UI it is made ""right"" from the beginning. I wanted to prevent this in the past not having a breaking change in the REST API - but now would be the time with FastAPI anyway. So `stringify` might need to be set to `false` later back again to get a native object, else would be a waste to re-parse the string to JSON in TypeScript again after REST endpoint

tirkarthi (Issue Creator) on (2024-12-12 13:45:51 UTC): Thanks @jscheffl, here is one rough attempt I can think of. Pass `stringify: false` in the API. Try `JSON.stringify()` and set highlight to true to use `<SyntaxHighlighter />`. On error just convert to string using `String()` and set highlight to be false to render it as normal `<Text>`. But this also means if there is `__str__` implemented for the custom object in Python land then JS `String()` value might be different in case the object doesn't fit `JSON.stringify`.

![image](https://github.com/user-attachments/assets/6bda7f56-f687-47a2-827c-7bfa0d1cc760)

jscheffl on (2024-12-12 14:06:45 UTC): Yeah, but this is only rough :-) Then rather to it ""right"" in a follow-up PR :+1:

"
2735283429,pull_request,closed,,Remove reparse on DAG depending on asset alias,"I suspect we no longer need this since alias resolution now happens very late in the scheduling process. A DAG *should* be able to automatically understand the alias is resolved without a reparse after refactorings introduced in cccc9334e3123423f678c7d237c544b45a76743e.

Letâ€™s see what CI thinks.",uranusjr,2024-12-12 08:59:25+00:00,[],2024-12-16 07:20:25+00:00,2024-12-16 07:20:24+00:00,https://github.com/apache/airflow/pull/44866,[],"[{'comment_id': 2540277359, 'issue_id': 2735283429, 'author': 'Lee-W', 'body': ""@uranusjr would like to confirm whether it works on your local. I tried with commit `7bdf1877`  (there's task_sdk issue currently I think) but it seems to break the scheduler"", 'created_at': datetime.datetime(2024, 12, 13, 0, 27, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2540502717, 'issue_id': 2735283429, 'author': 'uranusjr', 'body': 'Still some problems. Donâ€™t merge this yet.', 'created_at': datetime.datetime(2024, 12, 13, 4, 1, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2544781712, 'issue_id': 2735283429, 'author': 'uranusjr', 'body': 'I canâ€™t come up with a good way to test this (our test setup does not lend well toward real scheduler isolation). Iâ€™m going to just cross fingers and merge this if @Lee-W does not reject.', 'created_at': datetime.datetime(2024, 12, 16, 7, 17, 33, tzinfo=datetime.timezone.utc)}]","Lee-W on (2024-12-13 00:27:49 UTC): @uranusjr would like to confirm whether it works on your local. I tried with commit `7bdf1877`  (there's task_sdk issue currently I think) but it seems to break the scheduler

uranusjr (Issue Creator) on (2024-12-13 04:01:17 UTC): Still some problems. Donâ€™t merge this yet.

uranusjr (Issue Creator) on (2024-12-16 07:17:33 UTC): I canâ€™t come up with a good way to test this (our test setup does not lend well toward real scheduler isolation). Iâ€™m going to just cross fingers and merge this if @Lee-W does not reject.

"
2734963629,pull_request,closed,,Refactor documentation modal component to use it for dag and task.,"On testing the task docs were also displayed with ""dag docs"" button in the task details page. Refactor the component to be common and pass `isDag` to use ""Dag"" or ""task"" so that it's displayed as ""Task Docs"" in the task details page.",tirkarthi,2024-12-12 06:13:22+00:00,[],2024-12-12 15:41:05+00:00,2024-12-12 15:41:05+00:00,https://github.com/apache/airflow/pull/44863,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2734848832,pull_request,closed,,Fixing rendering of Airflow RC testing email links,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Airflow RC testing emails had links that were not redirecting properly.
![image](https://github.com/user-attachments/assets/989ee1c3-6350-4ce2-9b05-e8e102085b45)

Fixing the rendering

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-12 05:18:13+00:00,[],2024-12-12 05:58:09+00:00,2024-12-12 05:58:09+00:00,https://github.com/apache/airflow/pull/44862,"[('area:dev-tools', '')]",[],
2734628975,pull_request,closed,,Fetch recent dag runs using dag id instead of dag display pattern.,Support to filter by dag id was added in https://github.com/apache/airflow/pull/44737 . Using this filter makes matching better since dagIdPattern might cause other dags which are substrings to be also matched.,tirkarthi,2024-12-12 03:13:24+00:00,[],2024-12-12 04:29:29+00:00,2024-12-12 04:29:29+00:00,https://github.com/apache/airflow/pull/44861,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2734197649,pull_request,closed,,Handle the next URL after logging in in the simple auth manager,"Resolves #44848.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-11 22:58:09+00:00,[],2024-12-12 14:59:58+00:00,2024-12-12 14:59:57+00:00,https://github.com/apache/airflow/pull/44856,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2734196993,pull_request,closed,,Update sort and filter defaults,"Make it easier to navigate around the new UI with some better defaults

All dag run and task instance tables to sort by start_date
Dags list to sort by last_run_start_date
Time range selectors to the Past Week


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-11 22:57:34+00:00,[],2024-12-12 20:51:58+00:00,2024-12-12 20:51:56+00:00,https://github.com/apache/airflow/pull/44855,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2734075550,pull_request,closed,,Add grid data to graph,"Branch based off of https://github.com/apache/airflow/pull/44332.

Use grid_data to show task instances in graph view.

- Adds a dropdown to DagVizModal to switch between dag runs
- Clicking on a Task Name will select it
- Changing Task or Dag Run will update the url and when you close the modal you will go to the corresponding Details page


<img width=""1111"" alt=""Screenshot 2024-12-11 at 4 34 20â€¯PM"" src=""https://github.com/user-attachments/assets/28393ae3-a17e-4435-84e3-0e4d8351c024"" />

<img width=""1111"" alt=""Screenshot 2024-12-11 at 4 36 00â€¯PM"" src=""https://github.com/user-attachments/assets/b5546aa1-e29f-4b88-a5e6-028d33f96450"" />


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-11 21:34:48+00:00,[],2025-01-08 14:35:47+00:00,2025-01-08 14:35:46+00:00,https://github.com/apache/airflow/pull/44854,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2733849884,pull_request,closed,,Update Helm eviction configuration guide to reflect `workers.safeToEvict` default value,"The `workers.safeToEvict` default value was changed to `false` in #40229 and the Helm chart guide should reflect that.

related: #40229

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sean-rose,2024-12-11 19:56:38+00:00,[],2025-01-03 05:32:27+00:00,2025-01-03 05:32:17+00:00,https://github.com/apache/airflow/pull/44852,"[('area:helm-chart', 'Airflow Helm Chart'), ('kind:documentation', '')]","[{'comment_id': 2568713123, 'issue_id': 2733849884, 'author': 'jedcunningham', 'body': 'Good catch, thanks!', 'created_at': datetime.datetime(2025, 1, 3, 5, 32, 26, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2025-01-03 05:32:26 UTC): Good catch, thanks!

"
2733706915,pull_request,closed,,Bump `uv` to `0.5.8`,"https://pypi.org/project/uv/0.5.8/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-11 18:38:03+00:00,[],2024-12-11 21:13:07+00:00,2024-12-11 20:31:42+00:00,https://github.com/apache/airflow/pull/44851,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2733686864,pull_request,closed,,Integrate API with Trigger Dag Run,"closes: #44857

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-11 18:27:21+00:00,[],2024-12-16 20:31:55+00:00,2024-12-16 20:31:55+00:00,https://github.com/apache/airflow/pull/44850,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2733415134,pull_request,closed,,Remove unused `dag_ids` argument to DagFile processor classes.,"This hasn't been possible to set in a while, (like since sometime before 2.0,
possibly even before 1.8) and the doc string gives a clue to the behaviour:
only to schedule certain dags, but that is not the job of the dag processor
and hasn't been involved in that flow since 2.0.

Time to go.
",ashb,2024-12-11 16:20:56+00:00,[],2024-12-11 17:52:31+00:00,2024-12-11 17:52:28+00:00,https://github.com/apache/airflow/pull/44845,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', '')]",[],
2733152321,pull_request,closed,, AIP-72: Extending SET RTIF endpoint to accept all JSONable types,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

An endpoint to set RTIF was added in #44359. This allowed only `dict[str, str]` entries to be passed down to the API which lead to issues when running tests with DAGs like:
```py
from __future__ import annotations

import sys
import time
from datetime import datetime

from airflow import DAG
from airflow.decorators import dag, task
from airflow.operators.bash import BashOperator


@dag(
    # every minute on the 30-second mark
    catchup=False,
    tags=[],
    schedule=None,
    start_date=datetime(2021, 1, 1),
)
def hello_dag():
    """"""
    ### TaskFlow API Tutorial Documentation
    This is a simple data pipeline example which demonstrates the use of
    the TaskFlow API using three simple tasks for Extract, Transform, and Load.
    Documentation that goes along with the Airflow TaskFlow API tutorial is
    located
    [here](https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html)
    """"""

    @task()
    def hello():
        print(""hello"")
        time.sleep(3)
        print(""goodbye"")
        print(""err mesg"", file=sys.stderr)

    hello()


hello_dag()
```

The reason for this is that the arguments such as `op_args` and `op_kwargs` for PythonOperator can be non str. So that leads to a conclusion that we should accept `str` keys but `JsonAble` values.

Some points to note for reviewers:
1. Type we store in the table: https://github.com/apache/airflow/blob/1eb683be3a79c80927e9af1e89dabb5e78ce3136/airflow/models/renderedtifields.py#L76. Hence we should be able to accept any JsonAble types and store them, for non JsonAble ones like tuple and set, we should convert them and do it.


### What does this PR change?
- Get rid of the `RTIFPayload` and consume the payload directly in the api handler.
- Handling special case of `tuples` - they are json serialisable but we used to store them as lists when passed as tuples, because of usage of json.dumps(). It has been made like this now:
```
    def is_jsonable(x):
        try:
            json.dumps(x)
            if isinstance(x, tuple):
                # Tuple is converted to list in json.dumps
                # so while it is jsonable, it changes the type which might be a surprise
                # for the user, so instead we return False here -- which will convert it to string
                return False
```
- Reusing `serialize_template_field` from `airflow.serialization.helpers` because copy pasting code will be expensive, hard to maintain. We will revisit it anyways when we port the logic of templating to TASK SDK. Discussion: https://github.com/apache/airflow/pull/44843/files#r1882834039
- Added test cases with different scopes and different types to handle different cases of templated_fields well.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-11 14:34:48+00:00,['amoghrajesh'],2024-12-13 17:43:50+00:00,2024-12-13 17:33:42+00:00,https://github.com/apache/airflow/pull/44843,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2538120231, 'issue_id': 2733152321, 'author': 'amoghrajesh', 'body': '@kaxil if we agree with my comment https://github.com/apache/airflow/pull/44843#discussion_r1881472643 here, then this payload:\r\n```\r\nJsonAbleValueTypes = Union[\r\n    dict[str, JsonValue],\r\n    list[JsonValue],\r\n    JsonValue,\r\n]\r\n```\r\n\r\nWill do the job really well. I just pushed a commit with those changes. Added some tests for variety of payloads too', 'created_at': datetime.datetime(2024, 12, 12, 8, 14, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538393429, 'issue_id': 2733152321, 'author': 'amoghrajesh', 'body': 'FYI, I ran the DAG from ash that found this issue:\r\n```\r\nfrom __future__ import annotations\r\n\r\nimport sys\r\nimport time\r\nfrom datetime import datetime\r\n\r\nfrom airflow.decorators import dag, task\r\n\r\n\r\n@dag(\r\n    # every minute on the 30-second mark\r\n    catchup=False,\r\n    tags=[],\r\n    schedule=None,\r\n    start_date=datetime(2021, 1, 1),\r\n)\r\ndef hello_dag():\r\n    """"""\r\n    ### TaskFlow API Tutorial Documentation\r\n    This is a simple data pipeline example which demonstrates the use of\r\n    the TaskFlow API using three simple tasks for Extract, Transform, and Load.\r\n    Documentation that goes along with the Airflow TaskFlow API tutorial is\r\n    located\r\n    [here](https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html)\r\n    """"""\r\n\r\n    @task()\r\n    def hello():\r\n        print(""hello"")\r\n        time.sleep(3)\r\n        print(""goodbye"")\r\n        print(""err mesg"", file=sys.stderr)\r\n\r\n    hello()\r\n\r\n\r\nhello_dag()\r\n\r\n```\r\n\r\n\r\nusing this UT:\r\n```\r\ndef test_startup_dag_with_no_templates_mixed_types(mocked_parse, test_dags_dir):\r\n    """"""Test startup of a simple DAG.""""""\r\n    what = StartupDetails(\r\n        ti=TaskInstance(id=uuid7(), task_id=""hello"", dag_id=""hello_dag"", run_id=""c"", try_number=1),\r\n        file=str(test_dags_dir / ""mydag.py""),\r\n        requests_fd=0,\r\n    )\r\n    ti  = parse(what)\r\n\r\n    with mock.patch(\r\n        ""airflow.sdk.execution_time.task_runner.SUPERVISOR_COMMS"", create=True\r\n    ) as mock_supervisor_comms:\r\n        mock_supervisor_comms.get_message.return_value = what\r\n        startup()\r\n        run(ti, log=mock.ANY)\r\n\r\n```\r\n\r\nResult:\r\n```\r\nHome of the user: /Users/amoghdesai\r\nAirflow home /Users/amoghdesai/airflow\r\nPASSED [100%][2024-12-12T15:16:57.104+0530] {dagbag.py:535} INFO - Filling up the DagBag from /Users/amoghdesai/Documents/OSS/airflow/task_sdk/tests/dags/mydag.py\r\n[2024-12-12T15:16:57.175+0530] {dagbag.py:535} INFO - Filling up the DagBag from /Users/amoghdesai/Documents/OSS/airflow/task_sdk/tests/dags/mydag.py\r\n2024-12-12 15:16:57 [debug    ] DAG file parsed                [task] file=/Users/amoghdesai/Documents/OSS/airflow/task_sdk/tests/dags/mydag.py\r\nhello\r\ngoodbye\r\n[2024-12-12T15:17:00.178+0530] {python.py:197} INFO - Done. Returned value was: None\r\n```', 'created_at': datetime.datetime(2024, 12, 12, 9, 47, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541086170, 'issue_id': 2733152321, 'author': 'amoghrajesh', 'body': 'War to fix the CI starts!', 'created_at': datetime.datetime(2024, 12, 13, 10, 14, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541929935, 'issue_id': 2733152321, 'author': 'kaxil', 'body': ""Merged this PR as-is so we don't keep main broken for this case. But I'll have PR in just a bit"", 'created_at': datetime.datetime(2024, 12, 13, 17, 34, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541943313, 'issue_id': 2733152321, 'author': 'kaxil', 'body': '@amoghrajesh Created https://github.com/apache/airflow/pull/44920', 'created_at': datetime.datetime(2024, 12, 13, 17, 41, 13, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-12 08:14:44 UTC): @kaxil if we agree with my comment https://github.com/apache/airflow/pull/44843#discussion_r1881472643 here, then this payload:
```
JsonAbleValueTypes = Union[
    dict[str, JsonValue],
    list[JsonValue],
    JsonValue,
]
```

Will do the job really well. I just pushed a commit with those changes. Added some tests for variety of payloads too

amoghrajesh (Issue Creator) on (2024-12-12 09:47:58 UTC): FYI, I ran the DAG from ash that found this issue:
```
from __future__ import annotations

import sys
import time
from datetime import datetime

from airflow.decorators import dag, task


@dag(
    # every minute on the 30-second mark
    catchup=False,
    tags=[],
    schedule=None,
    start_date=datetime(2021, 1, 1),
)
def hello_dag():
    """"""
    ### TaskFlow API Tutorial Documentation
    This is a simple data pipeline example which demonstrates the use of
    the TaskFlow API using three simple tasks for Extract, Transform, and Load.
    Documentation that goes along with the Airflow TaskFlow API tutorial is
    located
    [here](https://airflow.apache.org/docs/apache-airflow/stable/tutorial_taskflow_api.html)
    """"""

    @task()
    def hello():
        print(""hello"")
        time.sleep(3)
        print(""goodbye"")
        print(""err mesg"", file=sys.stderr)

    hello()


hello_dag()

```


using this UT:
```
def test_startup_dag_with_no_templates_mixed_types(mocked_parse, test_dags_dir):
    """"""Test startup of a simple DAG.""""""
    what = StartupDetails(
        ti=TaskInstance(id=uuid7(), task_id=""hello"", dag_id=""hello_dag"", run_id=""c"", try_number=1),
        file=str(test_dags_dir / ""mydag.py""),
        requests_fd=0,
    )
    ti  = parse(what)

    with mock.patch(
        ""airflow.sdk.execution_time.task_runner.SUPERVISOR_COMMS"", create=True
    ) as mock_supervisor_comms:
        mock_supervisor_comms.get_message.return_value = what
        startup()
        run(ti, log=mock.ANY)

```

Result:
```
Home of the user: /Users/amoghdesai
Airflow home /Users/amoghdesai/airflow
PASSED [100%][2024-12-12T15:16:57.104+0530] {dagbag.py:535} INFO - Filling up the DagBag from /Users/amoghdesai/Documents/OSS/airflow/task_sdk/tests/dags/mydag.py
[2024-12-12T15:16:57.175+0530] {dagbag.py:535} INFO - Filling up the DagBag from /Users/amoghdesai/Documents/OSS/airflow/task_sdk/tests/dags/mydag.py
2024-12-12 15:16:57 [debug    ] DAG file parsed                [task] file=/Users/amoghdesai/Documents/OSS/airflow/task_sdk/tests/dags/mydag.py
hello
goodbye
[2024-12-12T15:17:00.178+0530] {python.py:197} INFO - Done. Returned value was: None
```

amoghrajesh (Issue Creator) on (2024-12-13 10:14:06 UTC): War to fix the CI starts!

kaxil on (2024-12-13 17:34:06 UTC): Merged this PR as-is so we don't keep main broken for this case. But I'll have PR in just a bit

kaxil on (2024-12-13 17:41:13 UTC): @amoghrajesh Created https://github.com/apache/airflow/pull/44920

"
2732896193,pull_request,open,,Setup the airflow configuration and istio using helm,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vaibhav7797,2024-12-11 12:50:22+00:00,[],2025-01-14 09:51:55+00:00,,https://github.com/apache/airflow/pull/44841,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2732880400,pull_request,closed,,Setup the airflow configuration and istio-ingress using helm,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vaibhav7797,2024-12-11 12:43:55+00:00,[],2024-12-11 12:45:42+00:00,2024-12-11 12:45:39+00:00,https://github.com/apache/airflow/pull/44840,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2535891351, 'issue_id': 2732880400, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 11, 12, 44, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-11 12:44:00 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2732669611,pull_request,closed,,"Remove ""single process"" restrictions on SQLite in favour of using WAL mode","Since 2010(!) sqlite has had a WAL, or Write-Ahead Log mode of journalling
which allos multiple concurrent readers and one writer. More than good enough
for us for ""local"" use.

The primary driver for this change was a realisation that it is possible and
to reduce the amount of code in complexity in DagProcessorManager before
reworking it for AIP-72 support :- we have a lot of code in the
DagProcessorManager to support `if async_mode` that makes understanding the
flow complex.

Some useful docs and articles about this mode:

- [The offical docs](https://sqlite.org/wal.html)
- [Simon Willison's TIL](https://til.simonwillison.net/sqlite/enabling-wal-mode)
- [fly.io article about scaling read concurrency](https://fly.io/blog/sqlite-internals-wal/)

This still keeps the warning against using SQLite in production, but it
greatly reduces the restrictions what combos and settings can use this. In
short, when using an SQLite db it is now possible to:

- use LocalExecutor, including with more than 1 concurrent worker slot
- have multiple DAG parsing processes (even before AIP-72/TaskSDK changes to
  that)

We execute the `PRAGMA journal_mode` every time we connect, which is more
often that is strictly needed as this is one of the few modes thatis
persistent and a property of the DB file just for ease and to ensure that it
it is in the mode we want.

I have tested this with `breeze -b sqlite start_airflow` and a kicking off a
lot of tasks concurrently.

Will this be without problems? No, not entirely, but due to the
scheduler+webserver+api server process we've _already_ got the case where
multiple processes are operating on the DB file. This change just makes the
best use of that following the guidance of the SQLite project: Ensuring that
only a single process accesses the DB concurrently is not a requirement
anymore!
",ashb,2024-12-11 11:26:12+00:00,[],2024-12-11 13:53:39+00:00,2024-12-11 13:36:19+00:00,https://github.com/apache/airflow/pull/44839,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2535804727, 'issue_id': 2732669611, 'author': 'ashb', 'body': 'Looks like I left a load of `validate_database_executor_compatibility` in the tests.', 'created_at': datetime.datetime(2024, 12, 11, 12, 3, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536052061, 'issue_id': 2732669611, 'author': 'potiuk', 'body': 'This is a fantastic improvement. And it will make ""airflow standalone"" finally getting really usefuil for ""local experience"".', 'created_at': datetime.datetime(2024, 12, 11, 13, 53, 38, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-12-11 12:03:02 UTC): Looks like I left a load of `validate_database_executor_compatibility` in the tests.

potiuk on (2024-12-11 13:53:38 UTC): This is a fantastic improvement. And it will make ""airflow standalone"" finally getting really usefuil for ""local experience"".

"
2732549290,pull_request,closed,,chore: remove deprecated BigQuery facets from OpenLineage utils,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Recently a major version of Google provider (11.0.0) has been released and we forgot to do some removals. This PR removes deprecated facet from OpenLineage utils in Google provider.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-12-11 10:44:08+00:00,[],2024-12-11 13:34:10+00:00,2024-12-11 13:33:52+00:00,https://github.com/apache/airflow/pull/44838,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2732215049,pull_request,closed,,feat(asset): change asset inactive warning to log Asset instead of AssetModel,"## Why
As we don't want users to access the models directly, it might be better if we do not expose it in the log message 

## What
Change the ""asset cannot be activated"" warning to log Asset info instead of AssetModel.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-11 08:21:58+00:00,[],2024-12-13 09:29:00+00:00,2024-12-13 09:28:58+00:00,https://github.com/apache/airflow/pull/44836,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2731993835,pull_request,closed,,Add codeowners for Airflow/FAB migrations,"Added myself and would be happy to add anyone interested in the migration changes, please suggest in the reviews

",ephraimbuddy,2024-12-11 06:58:17+00:00,[],2024-12-11 08:30:23+00:00,2024-12-11 08:30:21+00:00,https://github.com/apache/airflow/pull/44835,"[('area:dev-tools', '')]",[],
2731676461,pull_request,closed,,docs(newsfragments): fix typo and improve significant newfragment template,"

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-11 02:42:54+00:00,['Lee-W'],2024-12-11 08:29:45+00:00,2024-12-11 08:29:43+00:00,https://github.com/apache/airflow/pull/44833,[],"[{'comment_id': 2533642535, 'issue_id': 2731676461, 'author': 'Lee-W', 'body': '> Would it be better to just have a checkbox for this instead? Prone to error.\r\n\r\ngood point! let me add it', 'created_at': datetime.datetime(2024, 12, 11, 5, 2, 20, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-12-11 05:02:20 UTC): good point! let me add it

"
2731650660,pull_request,closed,,Bring back accidentally removed test 'test_execute_openlineage_events()',"
Add Trino provider test `test_execute_openlineage_events()` which is accidently removed in PR : #44717 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2024-12-11 02:21:41+00:00,[],2024-12-11 06:59:02+00:00,2024-12-11 06:59:02+00:00,https://github.com/apache/airflow/pull/44832,"[('area:providers', ''), ('provider:trino', '')]",[],
2731644901,pull_request,closed,,Fail a task if an inlet or outlet asset is inactive or an inactive asset is added to an asset alias,"## Why this change
In AIP-74, we introduce a new ""name"" column to the Asset. We do not expect to have assets with the same name or URI. For example, `Asset(name=""test-name"", uri=""test://asset"")` and `Asset(""test-name"")` would be considered assets that violate this rule.

> Similar to how Dataset works, an asset can be declared by instantiating an Asset object. One difference from Dataset is that Asset will have an additional name argument. If given, this must be unique in the Airflow deployment, and is used to represent the asset in user-facing interfaces,

Currently, we do nothing when a task has an unexpected asset as an inlet or outlet. The following example works fine now, even though it should not.

```python
from __future__ import annotations


from airflow.decorators import dag, task
from airflow.sdk.definitions.asset import Asset


@dag(
    start_date=None,
    schedule=None,
    catchup=False,
)
def my_producer_dag():
    @task(
    	inlets=[
    		# name=""test"", uri=""""s3://my-bucket/my-key/""
    		Asset(""test"", ""s3://my-bucket/my-key/"")
    	],
    	outlets=[
    		# name=""s3://my-bucket/my-key/"", uri=""""s3://my-bucket/my-key/""
    		Asset(""s3://my-bucket/my-key/"") 
    	]
    )
    def my_producer_task():
        pass

    my_producer_task()


my_producer_dag()
```

Back to https://github.com/apache/airflow/pull/42612, we introduced the concept of AssetActive. These assets that are classified as inactive. While the first asset can still be activated, subsequent assets will not be activated. For example, if `Asset(""test"", ""s3://my-bucket/my-key/"")` is activated first, then `Asset(""s3://my-bucket/my-key/"")` will not be activated. This rule applies even if the assets are defined in different DAGs or in separate files.

## What's the change
The activation status of an asset has already been addressed in previous pull requests. In this pull request, we have implemented a task that checks for any inactive assets in the outlets or inlets. If any inactive assets are found, it raises an `AirflowExecuteWithInactiveAssetException`, which inherits from `AirflowFailException`, causing the task to fail.

Closes: https://github.com/apache/airflow/issues/44600

## Test

Tested with the following test cases. All of them worked fine before this fix and received a similar error message to the screenshot below after this fix.

<details>
    <summary>Inactive assets in inlets</summary>

```python
from __future__ import annotations

from airflow.decorators import dag, task
from airflow.sdk.definitions.asset import Asset


@dag(start_date=None, schedule=None, catchup=False)
def inactive_assets_in_inlets_dag():
    @task(
        inlets=[
            Asset(""inlet-test"", ""s3://inlet/my-key/""),
            Asset(""s3://inlet/my-key/""),
            Asset(""inlet-test2""),
        ],
    )
    def first_asset_task():
        pass

    @task(inlets=[Asset(uri=""inlet-test2"")])
    def second_asset_task():
        pass

    first_asset_task() >> second_asset_task()


inactive_assets_in_inlets_dag()
```

</details>


<details>
    <summary>Inactive assets in outlets</summary>

```python
from __future__ import annotations

from airflow.decorators import dag, task
from airflow.sdk.definitions.asset import Asset


@dag(start_date=None, schedule=None, catchup=False)
def inactive_assets_in_outlets_dag():
    @task(
        outlets=[
            Asset(""outlet-test"", ""s3://outlet/my-key/""),
            Asset(""s3://outlet/my-key/""),
            Asset(""outlet-test-2""),
        ],
    )
    def first_asset_task():
        pass

    @task(outlets=[Asset(uri=""outlet-test-2"")])
    def second_asset_task():
        pass

    first_asset_task() >> second_asset_task()


inactive_assets_in_outlets_dag()
```

</details>

<details>
    <summary>Inactive assets mixed in inlets and outlets</summary>


```python
from __future__ import annotations

from airflow.decorators import dag, task
from airflow.sdk.definitions.asset import Asset


@dag(start_date=None, schedule=None, catchup=False)
def inactive_assets_mixed_in_inlets_outlet_dag():
    @task(
        inlets=[
            Asset(""test"", ""s3://my-bucket/my-key/""),
        ],
        outlets=[Asset(""test2"")],
    )
    def first_asset_task():
        pass

    @task(
        inlets=[
            Asset(uri=""test2""),
        ],
        outlets=[
            Asset(""s3://my-bucket/my-key/""),
        ],
    )
    def second_asset_task():
        pass

    first_asset_task() >> second_asset_task()


inactive_assets_mixed_in_inlets_outlet_dag()
```

</details>

<details>
    <summary>Inactive assets cross files</summary>

```python
from __future__ import annotations

from airflow.decorators import dag, task
from airflow.sdk.definitions.asset import Asset


@dag(start_date=None, schedule=None, catchup=False)
def inactive_active_cross_file_dag_1():
    @task(inlets=[Asset(""cross"", ""s3://cross/my-key/"")])
    def first_asset_task():
        pass

    @task(outlets=[Asset(""cross2"", ""s3://cross2/my-key/"")])
    def second_asset_task():
        pass

    first_asset_task() >> second_asset_task()


inactive_active_cross_file_dag_1()
```

```python
from __future__ import annotations

from airflow.decorators import dag, task
from airflow.sdk.definitions.asset import Asset


@dag(start_date=None, schedule=None, catchup=False)
def inactive_active_cross_file_dag_2():
    @task(inlets=[Asset(""s3://cross2/my-key/"")])
    def first_asset_task():
        pass

    @task(outlets=[Asset(""cross"")])
    def second_asset_task():
        pass

    first_asset_task() >> second_asset_task()


inactive_active_cross_file_dag_2()
```

</details>



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-11 02:16:15+00:00,[],2024-12-25 07:52:33+00:00,2024-12-25 07:52:31+00:00,https://github.com/apache/airflow/pull/44831,[],"[{'comment_id': 2533645266, 'issue_id': 2731644901, 'author': 'Lee-W', 'body': '2 test cases still need to be fixed but the overall implementation is wrapped up', 'created_at': datetime.datetime(2024, 12, 11, 5, 4, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2540638224, 'issue_id': 2731644901, 'author': 'uranusjr', 'body': 'Should we also fail if an inactive asset is added by the user to an asset alias? I feel we should for consistency. If thatâ€™s the case, this should better be done _after_ the task is run (during the event-pushing phase) instead.', 'created_at': datetime.datetime(2024, 12, 13, 6, 19, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2540956199, 'issue_id': 2731644901, 'author': 'Lee-W', 'body': ""> Should we also fail if an inactive asset is added by the user to an asset alias? I feel we should for consistency.\r\n\r\nYes, this is also missed.\r\n\r\n> If thatâ€™s the case, this should better be done _after_ the task is run (during the event-pushing phase) instead.\r\n\r\nI'm not sure ðŸ¤” If we already know the task should fail, I think we should fail it at earlier stage (i.e., inlets and outlets cases). If this is a super resource consumsing task, this helps saving resource. But for the asset alias case, this is not something we can handle before task execution, we should do it after task execution."", 'created_at': datetime.datetime(2024, 12, 13, 9, 17, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2544920217, 'issue_id': 2731644901, 'author': 'Lee-W', 'body': '> Should we also fail if an inactive asset is added by the user to an asset alias? I feel we should for consistency. If thatâ€™s the case, this should better be done _after_ the task is run (during the event-pushing phase) instead.\r\n\r\njust handled `AssetAlias.add`', 'created_at': datetime.datetime(2024, 12, 16, 8, 34, 41, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-12-11 05:04:37 UTC): 2 test cases still need to be fixed but the overall implementation is wrapped up

uranusjr on (2024-12-13 06:19:24 UTC): Should we also fail if an inactive asset is added by the user to an asset alias? I feel we should for consistency. If thatâ€™s the case, this should better be done _after_ the task is run (during the event-pushing phase) instead.

Lee-W (Issue Creator) on (2024-12-13 09:17:45 UTC): Yes, this is also missed.


I'm not sure ðŸ¤” If we already know the task should fail, I think we should fail it at earlier stage (i.e., inlets and outlets cases). If this is a super resource consumsing task, this helps saving resource. But for the asset alias case, this is not something we can handle before task execution, we should do it after task execution.

Lee-W (Issue Creator) on (2024-12-16 08:34:41 UTC): just handled `AssetAlias.add`

"
2731425412,pull_request,closed,,IGNORE THIS - Just a test - do not review - do not merge,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-12-10 23:14:56+00:00,[],2024-12-10 23:26:05+00:00,2024-12-10 23:26:05+00:00,https://github.com/apache/airflow/pull/44830,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2731307982,pull_request,closed,,Fix Trino Provider intergation test after removal of deprecations,"Fix failing trino integration test after #44717 as reported failure in 
https://github.com/apache/airflow/actions/runs/12257257539/job/34194827484",jscheffl,2024-12-10 22:09:50+00:00,[],2024-12-11 02:47:49+00:00,2024-12-10 22:25:36+00:00,https://github.com/apache/airflow/pull/44829,"[('area:providers', '')]",[],
2731281175,pull_request,closed,,Add Task Details page,"Add a Task Details page in order to see a single task across many runs.

Closes [44669](https://github.com/apache/airflow/issues/44669)

I could use some help on deciding when to link to what level of dag/run/task/instance below:

Page with a few basic details in the header and listing only its own tasks. Start date links to the task instance while dag run id links to the dag run
<img width=""1381"" alt=""Screenshot 2024-12-10 at 4 52 56â€¯PM"" src=""https://github.com/user-attachments/assets/4b520fd4-3123-474b-b5d8-f1cdfa780780"">

Dag Run details page listing its task instances. Clicking on a task name goes to a task page while clicking start_date goes to the task instance page.
<img width=""1389"" alt=""Screenshot 2024-12-10 at 4 53 02â€¯PM"" src=""https://github.com/user-attachments/assets/b989efe1-b71c-4ddf-a148-9e1fb52a5f78"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-12-10 21:57:34+00:00,[],2024-12-11 18:05:37+00:00,2024-12-11 18:05:34+00:00,https://github.com/apache/airflow/pull/44828,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2536695859, 'issue_id': 2731281175, 'author': 'bbovenzi', 'body': 'Ok I decided to make the list of TIs only ever link to a single TI and not confuse users with links to Task or Dag Run too.\r\nI also turned ""Latest Run"" and ""Latest Instance"" fields on the Dag and Task cards into links.', 'created_at': datetime.datetime(2024, 12, 11, 17, 50, 26, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2024-12-11 17:50:26 UTC): Ok I decided to make the list of TIs only ever link to a single TI and not confuse users with links to Task or Dag Run too.
I also turned ""Latest Run"" and ""Latest Instance"" fields on the Dag and Task cards into links.

"
2731246252,pull_request,closed,,[v2-10-test] Bump nanoid from 3.3.7 to 3.3.8 in /airflow/www (#44821),"Bumps [nanoid](https://github.com/ai/nanoid) from 3.3.7 to 3.3.8.
- [Release notes](https://github.com/ai/nanoid/releases)
- [Changelog](https://github.com/ai/nanoid/blob/main/CHANGELOG.md)
- [Commits](https://github.com/ai/nanoid/compare/3.3.7...3.3.8)
(cherry picked from commit 102af5538a69ea5aef1bd558cb72e3dd47b608f0)

Co-authored-by: Dependabot [bot] <49699333+dependabot[bot]@users.noreply.github.com>

---
updated-dependencies:
- dependency-name: nanoid
  dependency-type: indirect
...

Signed-off-by: dependabot[bot] <support@github.com>
Co-authored-by: dependabot[bot] <49699333+dependabot[bot]@users.noreply.github.com>",github-actions[bot],2024-12-10 21:41:34+00:00,[],2025-01-28 12:19:02+00:00,2024-12-10 22:24:48+00:00,https://github.com/apache/airflow/pull/44827,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2731194170,pull_request,closed,,Remove deprecated `kubernetes` commands from core,These are deprecated in core and moved to the provider. We should remove them for Airflow 3.,jedcunningham,2024-12-10 21:08:29+00:00,[],2024-12-11 17:45:27+00:00,2024-12-11 17:45:25+00:00,https://github.com/apache/airflow/pull/44826,"[('area:CLI', ''), ('area:dev-tools', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2536499185, 'issue_id': 2731194170, 'author': 'jedcunningham', 'body': ""I need to undo a little of this, cli can't come from providers yet. So we are in a weird state where the cli is defined in core but the code itself is in the provider :("", 'created_at': datetime.datetime(2024, 12, 11, 16, 35, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536526919, 'issue_id': 2731194170, 'author': 'jedcunningham', 'body': 'Slowly piecing it together - they can [come from KE](https://github.com/apache/airflow/blob/42dfa7eee1d4816dfb95863c7e472c250eb5765b/providers/src/airflow/providers/cncf/kubernetes/executors/kubernetes_executor.py#L809-L813), but the cleanup pods is also useful for KPO... guess no one cares since no one has complained', 'created_at': datetime.datetime(2024, 12, 11, 16, 46, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2536595913, 'issue_id': 2731194170, 'author': 'jedcunningham', 'body': ""Okay, so this really is just cleanup, and there is no breaking change with it so we don't need a newsfragment either."", 'created_at': datetime.datetime(2024, 12, 11, 17, 15, 28, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2024-12-11 16:35:02 UTC): I need to undo a little of this, cli can't come from providers yet. So we are in a weird state where the cli is defined in core but the code itself is in the provider :(

jedcunningham (Issue Creator) on (2024-12-11 16:46:56 UTC): Slowly piecing it together - they can [come from KE](https://github.com/apache/airflow/blob/42dfa7eee1d4816dfb95863c7e472c250eb5765b/providers/src/airflow/providers/cncf/kubernetes/executors/kubernetes_executor.py#L809-L813), but the cleanup pods is also useful for KPO... guess no one cares since no one has complained

jedcunningham (Issue Creator) on (2024-12-11 17:15:28 UTC): Okay, so this really is just cleanup, and there is no breaking change with it so we don't need a newsfragment either.

"
2731186188,pull_request,open,,ARC: run docs build CI job on ARC runners,related: #44512 ,hussein-awala,2024-12-10 21:03:13+00:00,[],2025-02-03 00:15:44+00:00,,https://github.com/apache/airflow/pull/44825,"[('area:dev-tools', '')]","[{'comment_id': 2617240506, 'issue_id': 2731186188, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 28, 0, 15, 15, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-28 00:15:15 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2730985558,pull_request,closed,,Bring back accidentally removed test 'test_execute_openlineage_events()',"related: #44559
Add test test_execute_openlineage_events() which is accidently removed in PR  : #44717
also add conn_id in SQLExecuteQueryOperator 


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2024-12-10 19:17:02+00:00,[],2024-12-11 07:00:10+00:00,2024-12-11 01:40:01+00:00,https://github.com/apache/airflow/pull/44824,"[('area:providers', ''), ('provider:trino', '')]","[{'comment_id': 2532749927, 'issue_id': 2730985558, 'author': 'Prab-27', 'body': 'I am sorry for all of this', 'created_at': datetime.datetime(2024, 12, 10, 20, 2, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533787454, 'issue_id': 2730985558, 'author': 'potiuk', 'body': '> I am sorry for all of this\r\n\r\nNo worries :). We reviewed it and did not notice! We are humans and we make mistakes. That what makes us humans.', 'created_at': datetime.datetime(2024, 12, 11, 7, 0, 9, tzinfo=datetime.timezone.utc)}]","Prab-27 (Issue Creator) on (2024-12-10 20:02:44 UTC): I am sorry for all of this

potiuk on (2024-12-11 07:00:09 UTC): No worries :). We reviewed it and did not notice! We are humans and we make mistakes. That what makes us humans.

"
2730917213,pull_request,closed,,Do not display github-actions[bot] in RC testing issue content,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Noticed in https://github.com/apache/airflow/issues/44811 that we are displaying the github actions bot in the RC testing issues and thanking it too!

![image](https://github.com/user-attachments/assets/1b2a00b5-b4fd-4930-b8ec-bbed50d69c4d)


We shouldn't be doing that, this PR skips that.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-10 18:45:26+00:00,[],2024-12-11 06:50:21+00:00,2024-12-11 06:50:21+00:00,https://github.com/apache/airflow/pull/44823,"[('area:dev-tools', '')]","[{'comment_id': 2532608110, 'issue_id': 2730917213, 'author': 'potiuk', 'body': ':robot:', 'created_at': datetime.datetime(2024, 12, 10, 18, 49, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532628392, 'issue_id': 2730917213, 'author': 'kaxil', 'body': 'You broke integration tests with this change :P - https://github.com/apache/airflow/actions/runs/12262659739/job/34212827799?pr=44823\r\n\r\nI veto this change ;)-- jk ofcourse -- failure is unrelated\r\n\r\n\r\n![](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExenZiamVueWtqZnk2bWJnbm53NHR4OXR2ZHgzMHFrMDh6cnk0Z2xyayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ZkUlTZe2cgpjL6FfKW/giphy.gif)\r\n\r\n![](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExaGQ2dGNvcngzeHptcndhMWR2bWQ0b2JqMWV5amdhMGZteTZpd3FtZyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/VHxLlZT4w1NZYYQdJt/giphy.gif)', 'created_at': datetime.datetime(2024, 12, 10, 18, 59, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532636759, 'issue_id': 2730917213, 'author': 'potiuk', 'body': ':scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream:', 'created_at': datetime.datetime(2024, 12, 10, 19, 3, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533568980, 'issue_id': 2730917213, 'author': 'amoghrajesh', 'body': 'Hahah good one! Its been fixed by https://github.com/apache/airflow/pull/44829', 'created_at': datetime.datetime(2024, 12, 11, 3, 51, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533640341, 'issue_id': 2730917213, 'author': 'amoghrajesh', 'body': 'Reopening to trigger tests.', 'created_at': datetime.datetime(2024, 12, 11, 5, 0, 19, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-10 18:49:31 UTC): :robot:

kaxil on (2024-12-10 18:59:25 UTC): You broke integration tests with this change :P - https://github.com/apache/airflow/actions/runs/12262659739/job/34212827799?pr=44823

I veto this change ;)-- jk ofcourse -- failure is unrelated


![](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExenZiamVueWtqZnk2bWJnbm53NHR4OXR2ZHgzMHFrMDh6cnk0Z2xyayZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/ZkUlTZe2cgpjL6FfKW/giphy.gif)

![](https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExaGQ2dGNvcngzeHptcndhMWR2bWQ0b2JqMWV5amdhMGZteTZpd3FtZyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/VHxLlZT4w1NZYYQdJt/giphy.gif)

potiuk on (2024-12-10 19:03:34 UTC): :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream:

amoghrajesh (Issue Creator) on (2024-12-11 03:51:11 UTC): Hahah good one! Its been fixed by https://github.com/apache/airflow/pull/44829

amoghrajesh (Issue Creator) on (2024-12-11 05:00:19 UTC): Reopening to trigger tests.

"
2730879419,pull_request,closed,,Add notes to the Trigger Dag UI form,"Add notes to the Trigger Dag UI form

<img width=""915"" alt=""image"" src=""https://github.com/user-attachments/assets/02a53413-b528-4153-b72a-5ab03e0f8b80"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-10 18:24:57+00:00,[],2024-12-11 06:27:53+00:00,2024-12-11 06:27:53+00:00,https://github.com/apache/airflow/pull/44822,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2730801160,pull_request,closed,,Bump nanoid from 3.3.7 to 3.3.8 in /airflow/www,"Bumps [nanoid](https://github.com/ai/nanoid) from 3.3.7 to 3.3.8.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/ai/nanoid/blob/main/CHANGELOG.md"">nanoid's changelog</a>.</em></p>
<blockquote>
<h2>3.3.8</h2>
<ul>
<li>Fixed a way to break Nano ID by passing non-integer size (by <a href=""https://github.com/myndzi""><code>@â€‹myndzi</code></a>).</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/ai/nanoid/commit/3044cd5e73f4cf31795f61f6e6b961c8c0a5c744""><code>3044cd5</code></a> Release 3.3.8 version</li>
<li><a href=""https://github.com/ai/nanoid/commit/4fe34959c34e5b3573889ed4f24fe91d1d3e7231""><code>4fe3495</code></a> Update size limit</li>
<li><a href=""https://github.com/ai/nanoid/commit/d643045f40d6dc8afa000a644d857da1436ed08c""><code>d643045</code></a> Fix pool pollution, infinite loop (<a href=""https://redirect.github.com/ai/nanoid/issues/510"">#510</a>)</li>
<li>See full diff in <a href=""https://github.com/ai/nanoid/compare/3.3.7...3.3.8"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nanoid&package-manager=npm_and_yarn&previous-version=3.3.7&new-version=3.3.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-12-10 17:55:21+00:00,[],2024-12-10 21:41:38+00:00,2024-12-10 21:40:50+00:00,https://github.com/apache/airflow/pull/44821,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2532837684, 'issue_id': 2730801160, 'author': 'dependabot[bot]', 'body': ""OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.\n\nIf you change your mind, just re-open this PR and I'll resolve any conflicts on it."", 'created_at': datetime.datetime(2024, 12, 10, 20, 39, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532952348, 'issue_id': 2730801160, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>âœ…</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44827""><img src=""https://img.shields.io/badge/PR-44827-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 12, 10, 21, 41, 36, tzinfo=datetime.timezone.utc)}]","dependabot[bot] (Issue Creator) on (2024-12-10 20:39:05 UTC): OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.

github-actions[bot] on (2024-12-10 21:41:36 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>âœ…</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44827""><img src=""https://img.shields.io/badge/PR-44827-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2730783125,pull_request,closed,,Remove `conf` from Task Context,"This was initially added in response to https://github.com/apache/airflow/issues/168. However, we now have `ti.log_url` that is used for that; example usages:

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/airflow/models/taskinstance.py#L1362

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/providers/src/airflow/providers/smtp/notifications/templates/email.html#L28

https://github.com/apache/airflow/blob/dcd41f60f1c9b5583b49bfb49b6d85c640a2892c/docs/apache-airflow/howto/email-config.rst?plain=1#L76

So, to simplify what we need to pass from API server to the Task SDK, I want to simplify and remove things that aren't needed. In this case, this is good so we don't pass/expore secrets unnecesarily via `conf`.

Mailing list Thread: https://lists.apache.org/thread/2n0l8y2oyq4442p0lsnmbbcl6rmbj3k7 

We can add specific values as needed in upcoming versions.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-12-10 17:47:37+00:00,[],2024-12-16 19:45:30+00:00,2024-12-16 19:45:29+00:00,https://github.com/apache/airflow/pull/44820,"[('kind:documentation', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2730540997,pull_request,closed,,Refactor stat helper methods on DagFileProcessorManager,"This is some cleanup/preporatory work in order to swap the Dag processor over
to use the TaskSDK, and this small change is done to make the future work
easier.

The main bulk of this change is to remote the `get_*` helper methods and make
`_file_stats` a defaultdict instead, and then also swap the DagFileStat class
from a NamedTuple (which can't have defaults) to an attrs-defined class which
does.

To make some of the places of use nicer/still one line, the type of
last_duration was changed form a timedelta to a float, as this was what the
`get_last_runtime` method did, and we don't need any of the capabilities of a
timedelta object elsewhere.
",ashb,2024-12-10 16:03:52+00:00,[],2024-12-10 17:35:05+00:00,2024-12-10 17:29:07+00:00,https://github.com/apache/airflow/pull/44818,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2730526360,pull_request,closed,,Add search key on variables page,"related: #43709

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/48b47999-3acc-4610-bb8f-3568ac88f867"">

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-10 15:57:39+00:00,[],2024-12-10 17:07:18+00:00,2024-12-10 17:07:18+00:00,https://github.com/apache/airflow/pull/44817,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2730401819,pull_request,closed,,Another small fix of system tests,"This PR

- changes location for some Dataproc system tests;
- excludes some tasks from campaign_manager system tests that can fail sometimes because of expired DCLID parameter;
- changes input dataset for vertex-ai video classification system test

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-12-10 15:09:56+00:00,[],2024-12-11 13:50:08+00:00,2024-12-11 13:50:07+00:00,https://github.com/apache/airflow/pull/44815,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2532283672, 'issue_id': 2730401819, 'author': 'potiuk', 'body': 'static checks :(', 'created_at': datetime.datetime(2024, 12, 10, 16, 56, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535729528, 'issue_id': 2730401819, 'author': 'VladaZakharova', 'body': '> static checks :(\r\n\r\nthanks :)\r\nAgain this static checks ðŸŒž \r\nFixed!', 'created_at': datetime.datetime(2024, 12, 11, 11, 49, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-12-10 16:56:16 UTC): static checks :(

VladaZakharova (Issue Creator) on (2024-12-11 11:49:01 UTC): thanks :)
Again this static checks ðŸŒž 
Fixed!

"
2729674164,pull_request,open,,Add deferred pagination mode to GenericTransfer,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#43357](https://github.com/apache/airflow/pull/43357)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

As explained in my Airflow medium [blogpost](https://medium.com/apache-airflow/transfering-data-from-sap-hana-to-mssql-using-the-airflow-generictransfer-d29f147a9f1f), I've refactored the GenericTransfer to support deferred paginated reads.

When dealing with large datasets, not the whole dataset needs to be read into memory first before persisting it afterwards, as this could otherwise lead to out of memory errors on the worker executing the code.

I also took the opportunity to introduce an SQLExecuteQueryTrigger in the common sql provider, allowing the GenericTransfer to handle the paginated reads in deferred mode, so that the paginated reads can be decoupled from the writes, which shouldn't continuously block the worker as it can offload the reads to the triggerer while persisting the previous page in the meantime.

Once the [dialects PR](https://github.com/apache/airflow/pull/41327) is done, we could improve the way how the GenericTransfer handles the paginated SQL queries across different databases. At this moment the paginated SQL query can be customized through the paginated_sql_statement_format parameter.  The read size can be specified through the page_size parameter, maybe another (better) name could be preferred here but that I let you guy's decide how it's best named.  If no page_size is specified, then the original implementation is used and everything is read and persisted in one go.

Last but not least, I've moved the test code to test deferrable operators out of the microsoft azure provider and put it into the common test utils, so it can be re-used across multiple modules.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-12-10 10:19:17+00:00,[],2025-02-06 07:32:59+00:00,,https://github.com/apache/airflow/pull/44809,"[('area:providers', ''), ('provider:common-sql', ''), ('provider:standard', '')]","[{'comment_id': 2534064144, 'issue_id': 2729674164, 'author': 'dabla', 'body': 'Following dependency check is failing in breeze:\r\n\r\n```\r\npytest.param(\r\n            (""providers/src/airflow/providers/standard/operators/bash.py"",),\r\n            {\r\n                ""selected-providers-list-as-string"": ""common.compat standard"",\r\n                ""all-python-versions"": ""[\'3.9\']"",\r\n                ""all-python-versions-list-as-string"": ""3.9"",\r\n                ""python-versions"": ""[\'3.9\']"",\r\n                ""python-versions-list-as-string"": ""3.9"",\r\n                ""ci-image-build"": ""true"",\r\n                ""prod-image-build"": ""false"",\r\n                ""needs-helm-tests"": ""false"",\r\n                ""run-tests"": ""true"",\r\n                ""run-amazon-tests"": ""false"",\r\n                ""docs-build"": ""true"",\r\n                ""run-kubernetes-tests"": ""false"",\r\n                ""skip-pre-commits"": ""identity,lint-helm-chart,mypy-airflow,mypy-dev,mypy-docs,mypy-providers,mypy-task-sdk,""\r\n                ""ts-compile-format-lint-ui,ts-compile-format-lint-www"",\r\n                ""upgrade-to-newer-dependencies"": ""false"",\r\n                ""core-test-types-list-as-string"": ""Always Core Serialization"",\r\n                ""providers-test-types-list-as-string"": ""Providers[common.compat] Providers[standard]"",\r\n                ""needs-mypy"": ""true"",\r\n                ""mypy-checks"": ""[\'mypy-providers\']"",\r\n            },\r\n            id=""Providers standard tests and Serialization tests to run when airflow bash.py changed"",\r\n        ),\r\n```\r\n\r\n@eladkal @potiuk This error is logical, as I needed to add the common sql provider dependency as the GenericTransfer needs this dependency due to the newly introduced SQLExecuteQueryTrigger used to allow the deferred paging mechanism.\r\n\r\nBut after some reflection, it still feels unlogical to me that the GenericTransfer operator is part of the standard provider package, unless it allows more than just transferring data from database to database?  If not, it would be more logical it resides in the common sql provider or I\'m missing something?\r\n\r\nI\'ve been going through the code, and checked implementations of the get_records and insert_rows method, which where all implemented by a Hook extending the DbApiHook, but I suspect the DbApiHook was introduced after the GenericTransfer already existed.', 'created_at': datetime.datetime(2024, 12, 11, 7, 27, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566948586, 'issue_id': 2729674164, 'author': 'dabla', 'body': '> Following dependency check is failing in breeze:\r\n> \r\n> ```\r\n> pytest.param(\r\n>             (""providers/src/airflow/providers/standard/operators/bash.py"",),\r\n>             {\r\n>                 ""selected-providers-list-as-string"": ""common.compat standard"",\r\n>                 ""all-python-versions"": ""[\'3.9\']"",\r\n>                 ""all-python-versions-list-as-string"": ""3.9"",\r\n>                 ""python-versions"": ""[\'3.9\']"",\r\n>                 ""python-versions-list-as-string"": ""3.9"",\r\n>                 ""ci-image-build"": ""true"",\r\n>                 ""prod-image-build"": ""false"",\r\n>                 ""needs-helm-tests"": ""false"",\r\n>                 ""run-tests"": ""true"",\r\n>                 ""run-amazon-tests"": ""false"",\r\n>                 ""docs-build"": ""true"",\r\n>                 ""run-kubernetes-tests"": ""false"",\r\n>                 ""skip-pre-commits"": ""identity,lint-helm-chart,mypy-airflow,mypy-dev,mypy-docs,mypy-providers,mypy-task-sdk,""\r\n>                 ""ts-compile-format-lint-ui,ts-compile-format-lint-www"",\r\n>                 ""upgrade-to-newer-dependencies"": ""false"",\r\n>                 ""core-test-types-list-as-string"": ""Always Core Serialization"",\r\n>                 ""providers-test-types-list-as-string"": ""Providers[common.compat] Providers[standard]"",\r\n>                 ""needs-mypy"": ""true"",\r\n>                 ""mypy-checks"": ""[\'mypy-providers\']"",\r\n>             },\r\n>             id=""Providers standard tests and Serialization tests to run when airflow bash.py changed"",\r\n>         ),\r\n> ```\r\n> \r\n> @eladkal @potiuk This error is logical, as I needed to add the common sql provider dependency as the GenericTransfer needs this dependency due to the newly introduced SQLExecuteQueryTrigger used to allow the deferred paging mechanism.\r\n> \r\n> But after some reflection, it still feels unlogical to me that the GenericTransfer operator is part of the standard provider package, unless it allows more than just transferring data from database to database? If not, it would be more logical it resides in the common sql provider or I\'m missing something?\r\n> \r\n> I\'ve been going through the code, and checked implementations of the get_records and insert_rows method, which where all implemented by a Hook extending the DbApiHook, but I suspect the DbApiHook was introduced after the GenericTransfer already existed.\r\n\r\nHello @potiuk @eladkal could you check my above question whether it makes sense or not? Thx', 'created_at': datetime.datetime(2025, 1, 1, 10, 31, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566963048, 'issue_id': 2729674164, 'author': 'potiuk', 'body': ""> @eladkal @potiuk This error is logical, as I needed to add the common sql provider dependency as the GenericTransfer needs this dependency due to the newly introduced SQLExecuteQueryTrigger used to allow the deferred paging mechanism.\r\n\r\n> But after some reflection, it still feels unlogical to me that the GenericTransfer operator is part of the standard provider package, unless it allows more than just transferring data from database to database? If not, it would be more logical it resides in the common sql provider or I'm missing something?\r\n\r\nAbsolultely. It should be added to `common.sql` no doubts about that."", 'created_at': datetime.datetime(2025, 1, 1, 11, 14, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567011822, 'issue_id': 2729674164, 'author': 'dabla', 'body': ""> > @eladkal @potiuk This error is logical, as I needed to add the common sql provider dependency as the GenericTransfer needs this dependency due to the newly introduced SQLExecuteQueryTrigger used to allow the deferred paging mechanism.\r\n> \r\n> > But after some reflection, it still feels unlogical to me that the GenericTransfer operator is part of the standard provider package, unless it allows more than just transferring data from database to database? If not, it would be more logical it resides in the common sql provider or I'm missing something?\r\n> \r\n> Absolultely. It should be added to `common.sql` no doubts about that.\r\n\r\n@potiuk Okay but this would then have an impact on imports no? Or would you keep same structure as is and move the GenericTransfer from standard providers to common sql?"", 'created_at': datetime.datetime(2025, 1, 1, 13, 33, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567026175, 'issue_id': 2729674164, 'author': 'potiuk', 'body': '> @potiuk Okay but this would then have an impact on imports no? Or would you keep same structure as is and move the GenericTransfer from standard providers to common sql?\r\n\r\nGeneric Transfer has **only** been moved to ""standard"" provider recently as part of the preparation for Airflow 3. And the ""standard"" provider is not YET released in a `1.0.*` version - it is 0.0.3 now - because we have not completed yet extraction of everything there, and we expected that we might have some changes here and there, so Generic Transfer moved to the standard provider can be classified as mistake - should be moved to common.sql in the first place, and we can do it without taking care about back-compatibility.\r\n\r\nThe only back-compatibiity issue is that the old generic transfer should be redirected in Airflow 3 - but we can simply redirect it to the new place in common.sql, no problem with it whatsoever:\r\n\r\n* https://github.com/apache/airflow/blob/main/airflow/operators/__init__.py#L45', 'created_at': datetime.datetime(2025, 1, 1, 14, 14, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567714052, 'issue_id': 2729674164, 'author': 'potiuk', 'body': '@dabla  - I rebased it  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.', 'created_at': datetime.datetime(2025, 1, 2, 12, 38, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568081528, 'issue_id': 2729674164, 'author': 'dabla', 'body': '> @dabla - I rebased it -> we found and issue with @jscheffl with the new caching scheme - fixed in #45347 that would run ""main"" version of the tests.\r\n\r\nThx @jscheffl and @potiuk', 'created_at': datetime.datetime(2025, 1, 2, 16, 57, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582267552, 'issue_id': 2729674164, 'author': 'dabla', 'body': '@potiuk @eladkal Once [PR 45478](https://github.com/apache/airflow/pull/45478) is merged less files will be impacted here as I moved that extraction to a dedicated [PR](https://github.com/apache/airflow/pull/45478) to simplify the review of this one.', 'created_at': datetime.datetime(2025, 1, 10, 10, 6, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582284577, 'issue_id': 2729674164, 'author': 'dabla', 'body': '> > @potiuk Okay but this would then have an impact on imports no? Or would you keep same structure as is and move the GenericTransfer from standard providers to common sql?\r\n> \r\n> Generic Transfer has **only** been moved to ""standard"" provider recently as part of the preparation for Airflow 3. And the ""standard"" provider is not YET released in a `1.0.*` version - it is 0.0.3 now - because we have not completed yet extraction of everything there, and we expected that we might have some changes here and there, so Generic Transfer moved to the standard provider can be classified as mistake - should be moved to common.sql in the first place, and we can do it without taking care about back-compatibility.\r\n> \r\n> The only back-compatibiity issue is that the old generic transfer should be redirected in Airflow 3 - but we can simply redirect it to the new place in common.sql, no problem with it whatsoever:\r\n> \r\n> * https://github.com/apache/airflow/blob/main/airflow/operators/__init__.py#L45\r\n\r\nMoved the GenericTransfer to the common sql provider as this makes more sense.', 'created_at': datetime.datetime(2025, 1, 10, 10, 14, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2586456702, 'issue_id': 2729674164, 'author': 'dabla', 'body': ""@potiuk @eladkal I still have breeze test failing for selected tests on main (why do we only test on main branch?) since I moved the generic transfer to common sql, to me the expected values seems correct, but apparently I still get common.sql as additional provider for the bask operator, which is weird as standard provider doesn't need that dependency anymore since I moved the generic transfer, or is it because we run it against main branch, but then why?\r\n\r\n\r\n```\r\n=========================== short test summary info ============================\r\nFAILED tests/test_selective_checks.py::test_expected_output_pull_request_main[Providers standard tests and Serialization tests to run when airflow bash.py changed] - AssertionError: Correct value for 'selected-providers-list-as-string'\r\nassert 'common.compat common.sql standard' == 'common.compat standard'\r\n  \r\n  - common.compat standard\r\n  + common.compat common.sql standard\r\n  ?               +++++++++++\r\nFAILED tests/test_selective_checks.py::test_expected_output_pull_request_main[Force Core and Serialization tests to run when tests bash changed] - AssertionError: Correct value for 'providers-test-types-list-as-string'\r\nassert 'Providers[common.compat,common.sql] Providers[standard]' == 'Providers[common.compat] Providers[standard]'\r\n  \r\n  - Providers[common.compat] Providers[standard]\r\n  + Providers[common.compat,common.sql] Providers[standard]\r\n  ?                        +++++++++++\r\nFAILED tests/test_selective_checks.py::test_expected_output_pull_request_main[Only Python tests] - AssertionError: Correct value for 'providers-test-types-list-as-string'\r\nassert 'Providers[common.compat,common.sql] Providers[standard]' == 'Providers[common.compat] Providers[standard]'\r\n  \r\n  - Providers[common.compat] Providers[standard]\r\n  + Providers[common.compat,common.sql] Providers[standard]\r\n  ?                        +++++++++++\r\n```"", 'created_at': datetime.datetime(2025, 1, 13, 8, 15, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587205785, 'issue_id': 2729674164, 'author': 'potiuk', 'body': 'The root cause is here: https://github.com/apache/airflow/actions/runs/12743121090/job/35512486483?pr=44809\r\n\r\nYou need to run pre-commit with your change to regenerate .json file where we keep dependencies cross-providers.', 'created_at': datetime.datetime(2025, 1, 13, 14, 9, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587468368, 'issue_id': 2729674164, 'author': 'dabla', 'body': ""> The root cause is here: https://github.com/apache/airflow/actions/runs/12743121090/job/35512486483?pr=44809\r\n> \r\n> You need to run pre-commit with your change to regenerate .json file where we keep dependencies cross-providers.\r\n\r\nOk my bad, how many times didn't I already forgot that one ðŸ˜† Thx @potiuk"", 'created_at': datetime.datetime(2025, 1, 13, 15, 41, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587928074, 'issue_id': 2729674164, 'author': 'potiuk', 'body': ""> Ok my bad, how many times didn't I already forgot that one ðŸ˜† Thx @potiuk\r\n\r\nI actually never remember about it as well. I simply run `pre-commit install` and I don't have to remember about it any more :wink:"", 'created_at': datetime.datetime(2025, 1, 13, 18, 44, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627351203, 'issue_id': 2729674164, 'author': 'dabla', 'body': 'I\'m having trouble fixing this mypy error as both the .py and and .pyi files do have a correct signature, at least from what I see:\r\n\r\n```\r\nproviders/common/sql/src/airflow/providers/common/sql/triggers/sql.pyi:45: error:\r\nReturn type ""Coroutine[Any, Any, AsyncIterator[TriggerEvent]]"" of ""run""\r\nincompatible with return type ""AsyncIterator[TriggerEvent]"" in supertype\r\n""BaseTrigger""  [override]\r\n        async def run(self) -> AsyncIterator[TriggerEvent]: ...\r\n        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nFound 1 error in 1 file (checked [36](https://github.com/apache/airflow/actions/runs/13053144783/job/36418264340?pr=44809#step:6:37)09 source files)\r\nError 1 returned\r\nYou are running mypy with the folders selected. If you want to reproduce it l\r\n```', 'created_at': datetime.datetime(2025, 1, 31, 13, 32, 50, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2024-12-11 07:27:36 UTC): Following dependency check is failing in breeze:

```
pytest.param(
            (""providers/src/airflow/providers/standard/operators/bash.py"",),
            {
                ""selected-providers-list-as-string"": ""common.compat standard"",
                ""all-python-versions"": ""['3.9']"",
                ""all-python-versions-list-as-string"": ""3.9"",
                ""python-versions"": ""['3.9']"",
                ""python-versions-list-as-string"": ""3.9"",
                ""ci-image-build"": ""true"",
                ""prod-image-build"": ""false"",
                ""needs-helm-tests"": ""false"",
                ""run-tests"": ""true"",
                ""run-amazon-tests"": ""false"",
                ""docs-build"": ""true"",
                ""run-kubernetes-tests"": ""false"",
                ""skip-pre-commits"": ""identity,lint-helm-chart,mypy-airflow,mypy-dev,mypy-docs,mypy-providers,mypy-task-sdk,""
                ""ts-compile-format-lint-ui,ts-compile-format-lint-www"",
                ""upgrade-to-newer-dependencies"": ""false"",
                ""core-test-types-list-as-string"": ""Always Core Serialization"",
                ""providers-test-types-list-as-string"": ""Providers[common.compat] Providers[standard]"",
                ""needs-mypy"": ""true"",
                ""mypy-checks"": ""['mypy-providers']"",
            },
            id=""Providers standard tests and Serialization tests to run when airflow bash.py changed"",
        ),
```

@eladkal @potiuk This error is logical, as I needed to add the common sql provider dependency as the GenericTransfer needs this dependency due to the newly introduced SQLExecuteQueryTrigger used to allow the deferred paging mechanism.

But after some reflection, it still feels unlogical to me that the GenericTransfer operator is part of the standard provider package, unless it allows more than just transferring data from database to database?  If not, it would be more logical it resides in the common sql provider or I'm missing something?

I've been going through the code, and checked implementations of the get_records and insert_rows method, which where all implemented by a Hook extending the DbApiHook, but I suspect the DbApiHook was introduced after the GenericTransfer already existed.

dabla (Issue Creator) on (2025-01-01 10:31:42 UTC): Hello @potiuk @eladkal could you check my above question whether it makes sense or not? Thx

potiuk on (2025-01-01 11:14:08 UTC): Absolultely. It should be added to `common.sql` no doubts about that.

dabla (Issue Creator) on (2025-01-01 13:33:28 UTC): @potiuk Okay but this would then have an impact on imports no? Or would you keep same structure as is and move the GenericTransfer from standard providers to common sql?

potiuk on (2025-01-01 14:14:38 UTC): Generic Transfer has **only** been moved to ""standard"" provider recently as part of the preparation for Airflow 3. And the ""standard"" provider is not YET released in a `1.0.*` version - it is 0.0.3 now - because we have not completed yet extraction of everything there, and we expected that we might have some changes here and there, so Generic Transfer moved to the standard provider can be classified as mistake - should be moved to common.sql in the first place, and we can do it without taking care about back-compatibility.

The only back-compatibiity issue is that the old generic transfer should be redirected in Airflow 3 - but we can simply redirect it to the new place in common.sql, no problem with it whatsoever:

* https://github.com/apache/airflow/blob/main/airflow/operators/__init__.py#L45

potiuk on (2025-01-02 12:38:13 UTC): @dabla  - I rebased it  -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests.

dabla (Issue Creator) on (2025-01-02 16:57:25 UTC): Thx @jscheffl and @potiuk

dabla (Issue Creator) on (2025-01-10 10:06:34 UTC): @potiuk @eladkal Once [PR 45478](https://github.com/apache/airflow/pull/45478) is merged less files will be impacted here as I moved that extraction to a dedicated [PR](https://github.com/apache/airflow/pull/45478) to simplify the review of this one.

dabla (Issue Creator) on (2025-01-10 10:14:57 UTC): Moved the GenericTransfer to the common sql provider as this makes more sense.

dabla (Issue Creator) on (2025-01-13 08:15:56 UTC): @potiuk @eladkal I still have breeze test failing for selected tests on main (why do we only test on main branch?) since I moved the generic transfer to common sql, to me the expected values seems correct, but apparently I still get common.sql as additional provider for the bask operator, which is weird as standard provider doesn't need that dependency anymore since I moved the generic transfer, or is it because we run it against main branch, but then why?


```
=========================== short test summary info ============================
FAILED tests/test_selective_checks.py::test_expected_output_pull_request_main[Providers standard tests and Serialization tests to run when airflow bash.py changed] - AssertionError: Correct value for 'selected-providers-list-as-string'
assert 'common.compat common.sql standard' == 'common.compat standard'
  
  - common.compat standard
  + common.compat common.sql standard
  ?               +++++++++++
FAILED tests/test_selective_checks.py::test_expected_output_pull_request_main[Force Core and Serialization tests to run when tests bash changed] - AssertionError: Correct value for 'providers-test-types-list-as-string'
assert 'Providers[common.compat,common.sql] Providers[standard]' == 'Providers[common.compat] Providers[standard]'
  
  - Providers[common.compat] Providers[standard]
  + Providers[common.compat,common.sql] Providers[standard]
  ?                        +++++++++++
FAILED tests/test_selective_checks.py::test_expected_output_pull_request_main[Only Python tests] - AssertionError: Correct value for 'providers-test-types-list-as-string'
assert 'Providers[common.compat,common.sql] Providers[standard]' == 'Providers[common.compat] Providers[standard]'
  
  - Providers[common.compat] Providers[standard]
  + Providers[common.compat,common.sql] Providers[standard]
  ?                        +++++++++++
```

potiuk on (2025-01-13 14:09:32 UTC): The root cause is here: https://github.com/apache/airflow/actions/runs/12743121090/job/35512486483?pr=44809

You need to run pre-commit with your change to regenerate .json file where we keep dependencies cross-providers.

dabla (Issue Creator) on (2025-01-13 15:41:35 UTC): Ok my bad, how many times didn't I already forgot that one ðŸ˜† Thx @potiuk

potiuk on (2025-01-13 18:44:47 UTC): I actually never remember about it as well. I simply run `pre-commit install` and I don't have to remember about it any more :wink:

dabla (Issue Creator) on (2025-01-31 13:32:50 UTC): I'm having trouble fixing this mypy error as both the .py and and .pyi files do have a correct signature, at least from what I see:

```
providers/common/sql/src/airflow/providers/common/sql/triggers/sql.pyi:45: error:
Return type ""Coroutine[Any, Any, AsyncIterator[TriggerEvent]]"" of ""run""
incompatible with return type ""AsyncIterator[TriggerEvent]"" in supertype
""BaseTrigger""  [override]
        async def run(self) -> AsyncIterator[TriggerEvent]: ...
        ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Found 1 error in 1 file (checked [36](https://github.com/apache/airflow/actions/runs/13053144783/job/36418264340?pr=44809#step:6:37)09 source files)
Error 1 returned
You are running mypy with the folders selected. If you want to reproduce it l
```

"
2729484001,pull_request,closed,,AIP-72: Inline DAG injection for task runner tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/44805
Dependent on https://github.com/apache/airflow/pull/44786

### Why is it needed?
Every time when we port the different TI state handling in the task runner, it is usually followed by an integration test of sorts to test the end to end flow of whether that state is testable or not. For example:
1. For skipped state, we use the DAG https://github.com/apache/airflow/pull/44786/files#diff-cabbddd33130ce1a769412f5fc55dd23e4af4d0fa75f8981689daae769e0680dR1 and we test using the UT in task runner: https://github.com/apache/airflow/pull/44786/files#diff-413c3c59636a3c7b41b8bb822827d18a959778d0b6331532e0db175c829dbfd2R141-R161
2. For deferred state, we use the DAG: https://github.com/apache/airflow/pull/44241/files#diff-2152ed5392424771e27a69173b3c18caae717939719df8f5dbbbdfee5f9efd9bR1 and test it using UT in task runner: https://github.com/apache/airflow/pull/44241/files#diff-413c3c59636a3c7b41b8bb822827d18a959778d0b6331532e0db175c829dbfd2R93-R127

Due to this, when new ti states are added or tests for that matter, it eventually leads to a huge folder with DAGs under `task_sdk/tests/dags` which could soon get ever growing and unmanageable. 

### Solution
The solution is in two parts:
1. The first part would be the ability to create dynamic or in line dags which has been implemented using a DAGFactory kind of function:
```
def get_inline_dag(dag_id: str, tasks: BaseOperator) -> DAG:
    dag = DAG(
        dag_id=dag_id,
        default_args={""start_date"": timezone.datetime(2024, 12, 3)},
    )
    setattr(tasks, ""dag"", dag)

    return dag

```
This function is capable of accepting `one` task as of now and creating a DAG out of it and returning the DAG object which should suffice our current testing needs, if there is a need, we can extend this function to support more than one tasks and their relationships.
Usage:
```
    task = PythonOperator(
        task_id=""skip"",
        python_callable=lambda: (_ for _ in ()).throw(
            AirflowSkipException(""This task is being skipped intentionally.""),
        ),
    )

    dag = get_inline_dag(""basic_skipped"", task)
```
The usage is as simple as creating any task from any operator and passing it down to this function.

2. Mocking the parse function using KGB spy_agency: https://pypi.org/project/kgb/
The idea here is to use a spy agency to substitute out the `parse` function with a mock parser that does a bare minimum of the actual parser. We choose spy_agency over the mock library for two reasons primarily:
a) With `spy_agency`, you can mock specific methods or functions without affecting the entire class or module.
b) Minimal dispruption and ease of use.

### What is done so far?
1. Replaced usage of all ""actual"" dags with in line dags in task runner tests which either do parsing or run.
2. Deleted two DAGs
3. Cannot remove the other two DAGs as they are tied to test_supervisor.py tests which use the DAG path as of now. Can be taken in a follow up if needed. Example:
![image](https://github.com/user-attachments/assets/01baa82a-7b43-4ff1-bc7e-c2fc20cef50d)


### Impact
1. No need to create any more DAG files for integration tests for task runner, which could be frequent with current development rate for AIP 72.
2. Ability to easily create in line DAGs.

#### Examples:
Basic DAG
![image](https://github.com/user-attachments/assets/cf7a94b5-6c4c-4103-99a0-32047207a9b2)

deferred DAG
![image](https://github.com/user-attachments/assets/328f99d0-4483-48c5-9127-dd7812f47ae0)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-12-10 09:11:43+00:00,[],2024-12-10 20:05:30+00:00,2024-12-10 20:05:28+00:00,https://github.com/apache/airflow/pull/44808,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2531229562, 'issue_id': 2729484001, 'author': 'amoghrajesh', 'body': '> I wonder if this might be best done as a fixture builder -- i.e. a fixture which returns a function:\r\n> \r\n> ```python\r\n> @pytest.fixture\r\n> def mocked_parse(spy_agency):\r\n>     def set_dag(dag_id, task):\r\n>         dag = get_inline_dag(""super_basic"", task)\r\n>         agency.spy_on(parse, call_fake=lambda what: mocked_parse(what, dag, task.task_id))\r\n>     return set_dag\r\n> ```\r\n> \r\n> Which we could then use like this:\r\n> \r\n> ```python\r\n> def test_run_basic(time_machine, mocked_parse):\r\n>   mocked_parse(dag_id=""super_basic_run"", task=CustomOperator(task_id=""hello""))\r\n> ```\r\n\r\nActually I really like this, the tests can be made much simpler with this, no need to worry about manually adding spy_agency and complicating things.', 'created_at': datetime.datetime(2024, 12, 10, 10, 55, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531589748, 'issue_id': 2729484001, 'author': 'amoghrajesh', 'body': 'Rebased with main after merging #44725', 'created_at': datetime.datetime(2024, 12, 10, 13, 7, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532175969, 'issue_id': 2729484001, 'author': 'kaxil', 'body': 'Some static check failures', 'created_at': datetime.datetime(2024, 12, 10, 16, 11, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532178559, 'issue_id': 2729484001, 'author': 'amoghrajesh', 'body': '> Some static check failures\r\n\r\nHaha! Was just fixing it', 'created_at': datetime.datetime(2024, 12, 10, 16, 12, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532326592, 'issue_id': 2729484001, 'author': 'amoghrajesh', 'body': 'Finally green CI!', 'created_at': datetime.datetime(2024, 12, 10, 17, 15, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532619918, 'issue_id': 2729484001, 'author': 'kaxil', 'body': 'I force-pushed to rebase on top of main -- I wish GitHub makes ""rebase"" the default instead of ""merge"", the commit history to review becomes a lot cleaner', 'created_at': datetime.datetime(2024, 12, 10, 18, 55, 6, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-12-10 10:55:28 UTC): Actually I really like this, the tests can be made much simpler with this, no need to worry about manually adding spy_agency and complicating things.

amoghrajesh (Issue Creator) on (2024-12-10 13:07:42 UTC): Rebased with main after merging #44725

kaxil on (2024-12-10 16:11:52 UTC): Some static check failures

amoghrajesh (Issue Creator) on (2024-12-10 16:12:58 UTC): Haha! Was just fixing it

amoghrajesh (Issue Creator) on (2024-12-10 17:15:16 UTC): Finally green CI!

kaxil on (2024-12-10 18:55:06 UTC): I force-pushed to rebase on top of main -- I wish GitHub makes ""rebase"" the default instead of ""merge"", the commit history to review becomes a lot cleaner

"
2729408433,pull_request,closed,,[Backport] Fixing cli test failure in CI (#44679),"Original PR - https://github.com/apache/airflow/pull/44679

(cherry picked from commit 98e0977a53ea3dc55987f5a2c512fb3b590d3d1c)
",utkarsharma2,2024-12-10 08:39:33+00:00,[],2024-12-10 09:01:16+00:00,2024-12-10 09:01:13+00:00,https://github.com/apache/airflow/pull/44806,"[('area:CLI', '')]",[],
2728857155,pull_request,closed,,Remove leftovers of `kubernetes_environment_variables`,"Support for configuring env vars this way was removed before Airflow 2.0, so we can safely remove this without a newsfragment even!",jedcunningham,2024-12-10 03:19:54+00:00,[],2024-12-10 15:51:00+00:00,2024-12-10 07:29:53+00:00,https://github.com/apache/airflow/pull/44804,[],[],
2728598626,pull_request,closed,,Add asset alias detail route,This should work as-is now. ~~Tests are currently failing because  `/assets/alises/1` gets interpreted as an asset endpoint call to `aliases/1` currently. Depends on #44801.~~ Fixed.,uranusjr,2024-12-10 00:12:33+00:00,[],2024-12-10 14:28:58+00:00,2024-12-10 14:28:56+00:00,https://github.com/apache/airflow/pull/44803,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2728569722,pull_request,closed,,Adjust Timeout Action in Breeze Testing Command ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Adjust Timeout Action in Breeze Testing Command: Change sys.exit to kill all docker container

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-12-09 23:52:42+00:00,[],2024-12-10 12:21:34+00:00,2024-12-10 12:21:34+00:00,https://github.com/apache/airflow/pull/44802,"[('area:dev-tools', '')]",[],
2728560891,pull_request,closed,,Switch asset endpoints to use id instead of uri,"With the addition of Asset.name, we can't guarantee the uri to be unique anymore. Using uri also presents addition issues on endpoints since it conflicts with subroutes.",uranusjr,2024-12-09 23:48:19+00:00,[],2024-12-10 15:13:11+00:00,2024-12-10 15:13:08+00:00,https://github.com/apache/airflow/pull/44801,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2728245961,pull_request,closed,,Add CatalogId support to AWS GlueCatalogHook,"<!-- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements. See the NOTICE file distributed with this work for additional information regarding copyright ownership. The ASF licenses this file to you under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. -->
Implements support for custom CatalogId in AWS GlueCatalogHook methods. This enhancement allows users to specify a custom Data Catalog ID when interacting with AWS Glue services.

*Changes:*

- Added optional catalog_id parameter to get_partitions, get_table, get_partition, and create_partition
- Maintained backward compatibility (CatalogId defaults to None)
- Added comprehensive test coverage for both with/without CatalogId scenarios

*Testing Results:*

- All 905 AWS hooks tests passing (165.27s execution time)
- Added 20 new test cases for CatalogId functionality
- Verified both with/without CatalogId scenarios
- All existing tests remain passing, confirming backward compatibility
- 3 expected skips in hooks_signature tests (unrelated)

Closes: #43238

Link to Devin run:  https://app.devin.ai/sessions/f6e5706fdebf47cb8cafcb44e8dd3ccb",olsenbudanur,2024-12-09 20:56:53+00:00,[],2025-02-02 00:16:09+00:00,2025-02-02 00:16:09+00:00,https://github.com/apache/airflow/pull/44800,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2529430176, 'issue_id': 2728245961, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 12, 9, 20, 56, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529501527, 'issue_id': 2728245961, 'author': 'eladkal', 'body': 'Can you also add support for catalog in `GlueCatalogPartitionSensor` ?', 'created_at': datetime.datetime(2024, 12, 9, 21, 18, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529508409, 'issue_id': 2728245961, 'author': 'gopidesupavan', 'body': ""This is coming from boat account, don't think we accept prs from boat GitHub accounts?"", 'created_at': datetime.datetime(2024, 12, 9, 21, 22, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529518546, 'issue_id': 2728245961, 'author': 'olsenbudanur', 'body': ""> This is coming from boat account, don't think we accept prs from boat GitHub accounts?\r\n\r\n@gopidesupavan I'm using an AI tool, but the PR is not coming from a bot account. I am verifying the results as they get passed. Is that fine?"", 'created_at': datetime.datetime(2024, 12, 9, 21, 24, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529559017, 'issue_id': 2728245961, 'author': 'potiuk', 'body': ""> > This is coming from boat account, don't think we accept prs from boat GitHub accounts?\r\n> \r\n> @gopidesupavan I'm using an AI tool, but the PR is not coming from a bot account. I am verifying the results as they get passed. Is that fine?\r\n\r\nAs explained in the issue, yes you can contribute AI generated code if it follows the policy of the ASF: https://www.apache.org/legal/generative-tooling.html:\r\n\r\n> Given the above, code generated in whole or in part using AI can be contributed if the contributor ensures that:\r\n>\r\n> 1. The terms and conditions of the generative AI tool do not place any restrictions on use of the output that would be inconsistent with the [Open Source Definition](https://opensource.org/osd/).\r\n> 2. At least one of the following conditions is met:\r\n>    1. The output is not copyrightable subject matter (and would not be even if produced by a human).\r\n>    2. No third party materials are included in the output.\r\n>    3. Any third party materials that are included in the output are being used with permission (e.g., under a compatible open-source license) of the third party copyright holders and in compliance with the applicable license terms.\r\n> 3. A contributor obtains reasonable certainty that conditions 2.2 or 2.3 are met if the AI tool itself provides sufficient information about output that may be similar to training data, or from code scanning results.\r\n\r\nSo my quesiton is @olsenbudanur -> can you confirm (and somewhat explain how) those conditions are met ?"", 'created_at': datetime.datetime(2024, 12, 9, 21, 30, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529560409, 'issue_id': 2728245961, 'author': 'vincbeck', 'body': 'Code looks good, I agree with @eladkal suggestion, it would be awesome if you could do the same kind of changes in `GlueCatalogPartitionSensor `', 'created_at': datetime.datetime(2024, 12, 9, 21, 30, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529564089, 'issue_id': 2728245961, 'author': 'olsenbudanur', 'body': ""Asking Devin to look into GlueCatalogPartitionSensor right now! Will verify his results and push it up to this branch. Will send an update once that's done"", 'created_at': datetime.datetime(2024, 12, 9, 21, 31, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529570518, 'issue_id': 2728245961, 'author': 'olsenbudanur', 'body': '> Only if you (contributor) can fulfill the expectation of the generative tooling policy of the ASF. Otherwise we cannot accept it.\r\n\r\nAck. I am looking into the generative tooling policy + Devin policy as well', 'created_at': datetime.datetime(2024, 12, 9, 21, 34, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529623060, 'issue_id': 2728245961, 'author': 'olsenbudanur', 'body': ""Okay, added catalog_id to GlueCatalogPartitionSensor! Also, I can confirm that the tool abides by Apache's generative tooling terms:\r\n\r\n(copied from the issue thread)\r\n\r\nI've contacted the Devin (Cognition) team, and they confirmed that they reviewed the [Apache terms](https://www.apache.org/legal/generative-tooling.html) & [open-source terms](https://opensource.org/osd). They say everything looks fine (can tag someone from their team if needed)\r\n\r\n**1- The terms and conditions of the generative AI tool do not place any restrictions on use of the output that would be inconsistent with the [Open Source Definition](https://opensource.org/osd/)**\r\n\r\nAccording to [Devin's terms](https://www.cognition.ai/pages/terms-of-service), all outputs are fully owned by the user. No copyright and no third party materials.\r\n\r\n\r\n**2- At least one of the following conditions is met**\r\nThe output is not copyrightable subject matter. Also no third party materials are used.\r\n\r\n**3-**\r\nI am certain that this is not applicable.\r\n\r\n@potiuk is there anything I'm missing?"", 'created_at': datetime.datetime(2024, 12, 9, 22, 4, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529647278, 'issue_id': 2728245961, 'author': 'potiuk', 'body': 'As explained in the issue, this is licencing not ownership issue potentially - so you and devin should seek confirmation if this is OK to use such code via https://www.apache.org/legal/#communications', 'created_at': datetime.datetime(2024, 12, 9, 22, 16, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529655554, 'issue_id': 2728245961, 'author': 'olsenbudanur', 'body': 'Ack. Asked the Cognition team to reach out through the official channels + the issue thread. Will keep the further updates in the issue to avoid duplicate conversation threads. Ty for the prompt guidance here, interested to see if this goes through :) \r\n\r\n*will leave the PR open until this is resolved', 'created_at': datetime.datetime(2024, 12, 9, 22, 19, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617240548, 'issue_id': 2728245961, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 28, 0, 15, 17, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-12-09 20:56:58 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-12-09 21:18:54 UTC): Can you also add support for catalog in `GlueCatalogPartitionSensor` ?

gopidesupavan on (2024-12-09 21:22:55 UTC): This is coming from boat account, don't think we accept prs from boat GitHub accounts?

olsenbudanur (Issue Creator) on (2024-12-09 21:24:23 UTC): @gopidesupavan I'm using an AI tool, but the PR is not coming from a bot account. I am verifying the results as they get passed. Is that fine?

potiuk on (2024-12-09 21:30:31 UTC): As explained in the issue, yes you can contribute AI generated code if it follows the policy of the ASF: https://www.apache.org/legal/generative-tooling.html:


So my quesiton is @olsenbudanur -> can you confirm (and somewhat explain how) those conditions are met ?

vincbeck on (2024-12-09 21:30:56 UTC): Code looks good, I agree with @eladkal suggestion, it would be awesome if you could do the same kind of changes in `GlueCatalogPartitionSensor `

olsenbudanur (Issue Creator) on (2024-12-09 21:31:50 UTC): Asking Devin to look into GlueCatalogPartitionSensor right now! Will verify his results and push it up to this branch. Will send an update once that's done

olsenbudanur (Issue Creator) on (2024-12-09 21:34:29 UTC): Ack. I am looking into the generative tooling policy + Devin policy as well

olsenbudanur (Issue Creator) on (2024-12-09 22:04:48 UTC): Okay, added catalog_id to GlueCatalogPartitionSensor! Also, I can confirm that the tool abides by Apache's generative tooling terms:

(copied from the issue thread)

I've contacted the Devin (Cognition) team, and they confirmed that they reviewed the [Apache terms](https://www.apache.org/legal/generative-tooling.html) & [open-source terms](https://opensource.org/osd). They say everything looks fine (can tag someone from their team if needed)

**1- The terms and conditions of the generative AI tool do not place any restrictions on use of the output that would be inconsistent with the [Open Source Definition](https://opensource.org/osd/)**

According to [Devin's terms](https://www.cognition.ai/pages/terms-of-service), all outputs are fully owned by the user. No copyright and no third party materials.


**2- At least one of the following conditions is met**
The output is not copyrightable subject matter. Also no third party materials are used.

**3-**
I am certain that this is not applicable.

@potiuk is there anything I'm missing?

potiuk on (2024-12-09 22:16:34 UTC): As explained in the issue, this is licencing not ownership issue potentially - so you and devin should seek confirmation if this is OK to use such code via https://www.apache.org/legal/#communications

olsenbudanur (Issue Creator) on (2024-12-09 22:19:29 UTC): Ack. Asked the Cognition team to reach out through the official channels + the issue thread. Will keep the further updates in the issue to avoid duplicate conversation threads. Ty for the prompt guidance here, interested to see if this goes through :) 

*will leave the PR open until this is resolved

github-actions[bot] on (2025-01-28 00:15:17 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2728008754,pull_request,closed,,AIP-82 Use `hash` instead of `repr`,"Based on this [conversation](https://github.com/apache/airflow/pull/44456#discussion_r1876200836), it is better to use `hash` instead of `repr` to identify an object.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-09 19:13:41+00:00,[],2024-12-20 15:25:07+00:00,2024-12-20 15:25:05+00:00,https://github.com/apache/airflow/pull/44797,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2727944675,pull_request,closed,,AIP-82 Optimize/simplify query to fetch active assets,"Thanks to @dstandish feedbacks and recommendations [here](https://github.com/apache/airflow/pull/44456#discussion_r1876209901), I could optimize/simplify the query run in the dag processor to retrieve all the active assets.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-12-09 18:39:38+00:00,[],2024-12-09 19:52:49+00:00,2024-12-09 19:52:47+00:00,https://github.com/apache/airflow/pull/44796,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2727927763,pull_request,closed,,add time filter on asset events,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Adding timestamp filter on asset events similar to this PR: https://github.com/apache/airflow/pull/44654
",nishant-gupta-sh,2024-12-09 18:30:16+00:00,[],2024-12-13 20:03:20+00:00,2024-12-13 19:20:56+00:00,https://github.com/apache/airflow/pull/44795,"[('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2541224068, 'issue_id': 2727927763, 'author': 'pierrejeambrun', 'body': 'Static check (formatting) needs fixing before merging.', 'created_at': datetime.datetime(2024, 12, 13, 11, 18, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2541896277, 'issue_id': 2727927763, 'author': 'pierrejeambrun', 'body': ""I would recommend installing the pre-commit hooks and running them locally so you don't have to wait for the CI to know that some formatting is wrong.\r\n\r\nYou can take a look at https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst to get more information"", 'created_at': datetime.datetime(2024, 12, 13, 17, 15, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542098757, 'issue_id': 2727927763, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 13, 19, 20, 59, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-12-13 11:18:37 UTC): Static check (formatting) needs fixing before merging.

pierrejeambrun on (2024-12-13 17:15:46 UTC): I would recommend installing the pre-commit hooks and running them locally so you don't have to wait for the CI to know that some formatting is wrong.

You can take a look at https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst to get more information

boring-cyborg[bot] on (2024-12-13 19:20:59 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2727856737,pull_request,closed,,Add variable key search support,"related: #[43709](https://github.com/apache/airflow/issues/43709)

This is for adding variable key search for get variables.

<img width=""1417"" alt=""image"" src=""https://github.com/user-attachments/assets/dcf3d982-18b0-4b04-9329-36a47306d6a3"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-12-09 17:56:01+00:00,[],2024-12-10 15:11:00+00:00,2024-12-10 15:11:00+00:00,https://github.com/apache/airflow/pull/44794,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2727595700,pull_request,closed,,Bump uv to 0.5.7,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-12-09 16:17:08+00:00,[],2024-12-09 20:49:42+00:00,2024-12-09 20:49:41+00:00,https://github.com/apache/airflow/pull/44792,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2529327297, 'issue_id': 2727595700, 'author': 'gopidesupavan', 'body': 'One tests is failing it looks like flaky.', 'created_at': datetime.datetime(2024, 12, 9, 20, 3, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2529347123, 'issue_id': 2727595700, 'author': 'potiuk', 'body': 'Yep. Re-run it just in case.', 'created_at': datetime.datetime(2024, 12, 9, 20, 12, 18, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-12-09 20:03:27 UTC): One tests is failing it looks like flaky.

potiuk on (2024-12-09 20:12:18 UTC): Yep. Re-run it just in case.

"
2727502399,pull_request,closed,,Raise deprecation warning when accessing metadata through str,"This behavior will be removed in airflow 3 as assets have attributes name and uri, it would be confusing to identify which attribute should be used to filter the right asset

related: https://github.com/apache/airflow/pull/43922, https://github.com/apache/airflow/pull/44639

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-12-09 15:47:17+00:00,[],2025-01-28 12:19:48+00:00,2024-12-10 11:21:58+00:00,https://github.com/apache/airflow/pull/44791,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2530126972, 'issue_id': 2727502399, 'author': 'Lee-W', 'body': ""> Some tests fail but you probably know how to fix...\r\n\r\nI'm not sure at this moment ðŸ¤” but will take a look later today"", 'created_at': datetime.datetime(2024, 12, 10, 2, 54, 12, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-12-10 02:54:12 UTC): I'm not sure at this moment ðŸ¤” but will take a look later today

"
2727381644,pull_request,closed,,Fix offline SQL generation of migrations,"Offline SQL mode is broken, and this provides a fix for it, including a test to run the offline migration through the CI.

Changes:
 - refactored the migrations to remove dependency on inspectors and sessions
 - Updated the minimum version of the offline migration to 2.7.0, which is the oldest migration file we have in AF 3

",ephraimbuddy,2024-12-09 15:13:17+00:00,[],2024-12-13 23:07:44+00:00,2024-12-13 23:07:42+00:00,https://github.com/apache/airflow/pull/44790,"[('area:dev-tools', ''), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:db-migrations', 'PRs with DB migration')]",[],
2726957085,pull_request,closed,,Switch test_views_home.py from parsing files directly to using fixtures,"Although this test and UI will go away before release, the direct use of
`DagFileProcessor` to update/create things in the database is going to stop
shortly once DAG parsing is switched over to use Task SDK in the subprocess,
so to make that PR easier to review this change is being made now.
",ashb,2024-12-09 12:48:06+00:00,[],2024-12-09 13:30:52+00:00,2024-12-09 13:30:49+00:00,https://github.com/apache/airflow/pull/44788,"[('area:webserver', 'Webserver related Issues')]",[],
2726782476,pull_request,closed,,Added documentation for the SqlThresholdCheckOperator,"closes: #44782

I have added a documentation for the operator. Let me know if it is satisfactory, and whether I should change anything.

---
",dominikhei,2024-12-09 11:35:02+00:00,[],2024-12-09 19:52:10+00:00,2024-12-09 19:52:10+00:00,https://github.com/apache/airflow/pull/44787,"[('area:providers', ''), ('kind:documentation', ''), ('provider:common-sql', '')]",[],
