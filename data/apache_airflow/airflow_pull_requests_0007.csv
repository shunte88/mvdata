id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2592142425,pull_request,closed,,Fix pytest from working outside breeze,"This was missed in https://github.com/apache/airflow/pull/42985 . Without this `airflow.providers.__path__` had 2 registered paths:

```
['/Users/kaxilnaik/Documents/GitHub/astronomer/airflow/providers/src/airflow/providers',
 '/Users/kaxilnaik/Documents/GitHub/astronomer/airflow/providers']
```

This prevents the tests from running outside of breeze and we get the following error:

```
ERROR tests/core/test_settings.py::test_usage_data_collection_disabled[true-True-True] - airflow.exceptions.AirflowConfigException: (""The provider apache-airflow-providers-src-airflow-providers-amazon is attempting to contribute configuration section aws that has already been added before. The source of it: apache-airflow-providers-amazon. This is forbidden. A provider can only add new sections. It cannot contribute options to existing sections or override other provider's configuration."", <class 'UserWarning'>)
```

We get this error because the *Providers Manager* uses `airflow.providers.__path__` to register providers. Because we have 2 paths, it registers the same provider twice leading two the above error.

https://github.com/apache/airflow/blob/75b22940ac4d36c31380669da2aa32fe46d70d32/airflow/providers_manager.py#L662

Example registration:
```
('apache-airflow-providers-src-airflow-providers-yandex',
  {'yandex': {'description': 'This section contains settings for Yandex Cloud ', ...

('apache-airflow-providers-yandex',
  {'yandex': {'description': 'This section contains settings for Yandex Cloud '
```

This wasn't a problem in breeze as it sets `AIRFLOW_SOURCES` env var in Dockerfile https://github.com/apache/airflow/blob/75b22940ac4d36c31380669da2aa32fe46d70d32/scripts/docker/entrypoint_ci.sh#L24

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-16 14:52:59+00:00,[],2024-10-29 11:05:51+00:00,2024-10-16 15:01:02+00:00,https://github.com/apache/airflow/pull/43082,[],"[{'comment_id': 2417128518, 'issue_id': 2592142425, 'author': 'amoghrajesh', 'body': 'Ah thanks. Let me try it out by rebasing!', 'created_at': datetime.datetime(2024, 10, 16, 15, 13, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417132560, 'issue_id': 2592142425, 'author': 'amoghrajesh', 'body': 'Thank you @kaxil!\r\nIt works as expected!', 'created_at': datetime.datetime(2024, 10, 16, 15, 14, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443349760, 'issue_id': 2592142425, 'author': 'pratik-m', 'body': 'Hi @kaxil - I\'m trying to run tests locally (without breeze) and I\'m running into the error `ModuleNotFoundError: No module named \'airflow.providers\'`.  I couldn\'t find references to this issue..do I need to do any further setup to resolve this issue? \r\n\r\n**stacktrace**\r\n```\r\n(airflow-312) pratik@pratik-Inspiron-16-7630-2-in-1:~/personal/projects/airflow$ pytest tests/utils/test_db_cleanup.py\r\n================================================= test session starts ==================================================\r\nplatform linux -- Python 3.12.7, pytest-8.3.3, pluggy-1.5.0 -- /home/pratik/.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/bin/python\r\ncachedir: .pytest_cache\r\nrootdir: /home/pratik/personal/projects/airflow\r\nconfigfile: pyproject.toml\r\nplugins: requests-mock-1.12.1, anyio-4.4.0, custom-exit-code-0.3.0, instafail-0.5.0, mock-3.14.0, asyncio-0.24.0, timeouts-1.2.1, cov-5.0.0, xdist-3.6.1, rerunfailures-14.0, time-machine-2.15.0, icdiff-0.9\r\nasyncio: mode=Mode.STRICT, default_loop_scope=function\r\nsetup timeout: 0.0s, execution timeout: 0.0s, teardown timeout: 0.0s\r\ncollected 0 items / 1 error\r\n\r\n======================================================== ERRORS ========================================================\r\n___________________________________ ERROR collecting tests/utils/test_db_cleanup.py ____________________________________\r\nImportError while importing test module \'/home/pratik/personal/projects/airflow/tests/utils/test_db_cleanup.py\'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n../../../.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/lib/python3.12/site-packages/_pytest/python.py:493: in importtestmodule\r\n    mod = import_path(\r\n../../../.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/lib/python3.12/site-packages/_pytest/pathlib.py:582: in import_path\r\n    importlib.import_module(module_name)\r\n/usr/lib/python3.12/importlib/__init__.py:90: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n<frozen importlib._bootstrap>:1387: in _gcd_import\r\n    ???\r\n<frozen importlib._bootstrap>:1360: in _find_and_load\r\n    ???\r\n<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked\r\n    ???\r\n<frozen importlib._bootstrap>:935: in _load_unlocked\r\n    ???\r\n../../../.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/lib/python3.12/site-packages/_pytest/assertion/rewrite.py:184: in exec_module\r\n    exec(co, module.__dict__)\r\ntests/utils/test_db_cleanup.py:34: in <module>\r\n    from airflow.models import DagModel, DagRun, TaskInstance\r\nairflow/models/__init__.py:78: in __getattr__\r\n    val = import_string(f""{path}.{name}"")\r\nairflow/utils/module_loading.py:39: in import_string\r\n    module = import_module(module_path)\r\n/usr/lib/python3.12/importlib/__init__.py:90: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nairflow/models/dag.py:95: in <module>\r\n    from airflow.models.abstractoperator import AbstractOperator, TaskStateChangeCallback\r\nairflow/models/abstractoperator.py:33: in <module>\r\n    from airflow.template.templater import Templater\r\nairflow/template/templater.py:23: in <module>\r\n    from airflow.io.path import ObjectStoragePath\r\nairflow/io/__init__.py:30: in <module>\r\n    from airflow.providers_manager import ProvidersManager\r\nairflow/providers_manager.py:39: in <module>\r\n    from airflow.providers.standard.hooks.filesystem import FSHook\r\nE   ModuleNotFoundError: No module named \'airflow.providers\'\r\n=============================================== short test summary info ================================================\r\nERROR tests/utils/test_db_cleanup.py\r\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\r\n============================================= 1 warning, 1 error in 0.83s ==============================================\r\n(airflow-312) pratik@pratik-Inspiron-16-7630-2-in-1:~/personal/projects/airflow$\r\n\r\n```', 'created_at': datetime.datetime(2024, 10, 29, 6, 51, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443435476, 'issue_id': 2592142425, 'author': 'amoghrajesh', 'body': '@pratik-m if you are running it locally, you need to install the providers library, try running this from your root inside your virtual environment:\r\n```\r\npip install -e ./providers\r\n```', 'created_at': datetime.datetime(2024, 10, 29, 7, 24, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443555446, 'issue_id': 2592142425, 'author': 'pratik-m', 'body': 'Awesome! this worked ! Thanks @amoghrajesh !', 'created_at': datetime.datetime(2024, 10, 29, 8, 28, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443909802, 'issue_id': 2592142425, 'author': 'potiuk', 'body': 'Followed it up with simple instructions / guidelines https://github.com/apache/airflow/pull/43468 for contributors  - not yet fully describing how to use uv workspaces but should be good for now.', 'created_at': datetime.datetime(2024, 10, 29, 11, 5, 49, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2024-10-16 15:13:12 UTC): Ah thanks. Let me try it out by rebasing!

amoghrajesh on (2024-10-16 15:14:28 UTC): Thank you @kaxil!
It works as expected!

pratik-m on (2024-10-29 06:51:04 UTC): Hi @kaxil - I'm trying to run tests locally (without breeze) and I'm running into the error `ModuleNotFoundError: No module named 'airflow.providers'`.  I couldn't find references to this issue..do I need to do any further setup to resolve this issue? 

**stacktrace**
```
(airflow-312) pratik@pratik-Inspiron-16-7630-2-in-1:~/personal/projects/airflow$ pytest tests/utils/test_db_cleanup.py
================================================= test session starts ==================================================
platform linux -- Python 3.12.7, pytest-8.3.3, pluggy-1.5.0 -- /home/pratik/.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/bin/python
cachedir: .pytest_cache
rootdir: /home/pratik/personal/projects/airflow
configfile: pyproject.toml
plugins: requests-mock-1.12.1, anyio-4.4.0, custom-exit-code-0.3.0, instafail-0.5.0, mock-3.14.0, asyncio-0.24.0, timeouts-1.2.1, cov-5.0.0, xdist-3.6.1, rerunfailures-14.0, time-machine-2.15.0, icdiff-0.9
asyncio: mode=Mode.STRICT, default_loop_scope=function
setup timeout: 0.0s, execution timeout: 0.0s, teardown timeout: 0.0s
collected 0 items / 1 error

======================================================== ERRORS ========================================================
___________________________________ ERROR collecting tests/utils/test_db_cleanup.py ____________________________________
ImportError while importing test module '/home/pratik/personal/projects/airflow/tests/utils/test_db_cleanup.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
../../../.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/lib/python3.12/site-packages/_pytest/python.py:493: in importtestmodule
    mod = import_path(
../../../.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/lib/python3.12/site-packages/_pytest/pathlib.py:582: in import_path
    importlib.import_module(module_name)
/usr/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1387: in _gcd_import
    ???
<frozen importlib._bootstrap>:1360: in _find_and_load
    ???
<frozen importlib._bootstrap>:1331: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:935: in _load_unlocked
    ???
../../../.local/share/hatch/env/virtual/apache-airflow/lGCtOum7/airflow-312/lib/python3.12/site-packages/_pytest/assertion/rewrite.py:184: in exec_module
    exec(co, module.__dict__)
tests/utils/test_db_cleanup.py:34: in <module>
    from airflow.models import DagModel, DagRun, TaskInstance
airflow/models/__init__.py:78: in __getattr__
    val = import_string(f""{path}.{name}"")
airflow/utils/module_loading.py:39: in import_string
    module = import_module(module_path)
/usr/lib/python3.12/importlib/__init__.py:90: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
airflow/models/dag.py:95: in <module>
    from airflow.models.abstractoperator import AbstractOperator, TaskStateChangeCallback
airflow/models/abstractoperator.py:33: in <module>
    from airflow.template.templater import Templater
airflow/template/templater.py:23: in <module>
    from airflow.io.path import ObjectStoragePath
airflow/io/__init__.py:30: in <module>
    from airflow.providers_manager import ProvidersManager
airflow/providers_manager.py:39: in <module>
    from airflow.providers.standard.hooks.filesystem import FSHook
E   ModuleNotFoundError: No module named 'airflow.providers'
=============================================== short test summary info ================================================
ERROR tests/utils/test_db_cleanup.py
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
============================================= 1 warning, 1 error in 0.83s ==============================================
(airflow-312) pratik@pratik-Inspiron-16-7630-2-in-1:~/personal/projects/airflow$

```

amoghrajesh on (2024-10-29 07:24:11 UTC): @pratik-m if you are running it locally, you need to install the providers library, try running this from your root inside your virtual environment:
```
pip install -e ./providers
```

pratik-m on (2024-10-29 08:28:33 UTC): Awesome! this worked ! Thanks @amoghrajesh !

potiuk on (2024-10-29 11:05:49 UTC): Followed it up with simple instructions / guidelines https://github.com/apache/airflow/pull/43468 for contributors  - not yet fully describing how to use uv workspaces but should be good for now.

"
2592130987,pull_request,closed,,Move PyCharm instructions to top of the file,"These instructions do not work with my PyCharm if these instructions are not at the top of the file.

Follow-up of #42951

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-16 14:49:20+00:00,[],2024-10-16 15:14:37+00:00,2024-10-16 15:13:53+00:00,https://github.com/apache/airflow/pull/43081,"[('area:providers', ''), ('area:dev-tools', '')]","[{'comment_id': 2417132492, 'issue_id': 2592130987, 'author': 'vincbeck', 'body': 'Closing it. Imports must be at the top of the file, I thought it was a linter thing but it is a syntax thing. Not much I can do', 'created_at': datetime.datetime(2024, 10, 16, 15, 14, 28, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-10-16 15:14:28 UTC): Closing it. Imports must be at the top of the file, I thought it was a linter thing but it is a syntax thing. Not much I can do

"
2591838818,pull_request,closed,,fix syntax error on chain exemple of dags.rst,"On the line 128, contains an error that concatenates a string with a number. So, I just fixed transforming the number into a string.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",arthbraveheart,2024-10-16 13:06:21+00:00,[],2024-10-26 22:20:53+00:00,2024-10-26 22:20:51+00:00,https://github.com/apache/airflow/pull/43079,"[('kind:documentation', '')]","[{'comment_id': 2416789845, 'issue_id': 2591838818, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 16, 13, 6, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439720942, 'issue_id': 2591838818, 'author': 'potiuk', 'body': 'I rebased it - It was 90 commits behind.', 'created_at': datetime.datetime(2024, 10, 26, 20, 2, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439753510, 'issue_id': 2591838818, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 26, 22, 20, 53, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-16 13:06:25 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-26 20:02:25 UTC): I rebased it - It was 90 commits behind.

boring-cyborg[bot] on (2024-10-26 22:20:53 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2591752844,pull_request,closed,,Fix typo in pyproject.toml,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-10-16 12:32:18+00:00,[],2024-10-16 16:10:08+00:00,2024-10-16 15:04:11+00:00,https://github.com/apache/airflow/pull/43077,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2417144507, 'issue_id': 2591752844, 'author': 'ashb', 'body': 'This should have changed the import position via ruff. Something else might be going wrong.', 'created_at': datetime.datetime(2024, 10, 16, 15, 18, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417193072, 'issue_id': 2591752844, 'author': 'kaxil', 'body': ""> This should have changed the import position via ruff. Something else might be going wrong.\r\n\r\n@ashb you are right, main started failing. For weird reason it didn't fail on this PR.\r\n\r\nPR to fix failures: https://github.com/apache/airflow/pull/43087"", 'created_at': datetime.datetime(2024, 10, 16, 15, 34, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417215501, 'issue_id': 2591752844, 'author': 'potiuk', 'body': '@kaxil - @ashb - this one passed because it only triggered ""basic checks"" - pyproject.toml ""non-dependencies"" change is not considered as ""source file change"". Which maybe it should. I also see that ""test_common"" should be added as sources in selective checks to trigger tests when only test_common files change. PR is coming', 'created_at': datetime.datetime(2024, 10, 16, 15, 41, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417286544, 'issue_id': 2591752844, 'author': 'potiuk', 'body': 'Fix to avoid it in the future https://github.com/apache/airflow/pull/43088', 'created_at': datetime.datetime(2024, 10, 16, 16, 10, 7, tzinfo=datetime.timezone.utc)}]","ashb on (2024-10-16 15:18:39 UTC): This should have changed the import position via ruff. Something else might be going wrong.

kaxil on (2024-10-16 15:34:17 UTC): @ashb you are right, main started failing. For weird reason it didn't fail on this PR.

PR to fix failures: https://github.com/apache/airflow/pull/43087

potiuk on (2024-10-16 15:41:54 UTC): @kaxil - @ashb - this one passed because it only triggered ""basic checks"" - pyproject.toml ""non-dependencies"" change is not considered as ""source file change"". Which maybe it should. I also see that ""test_common"" should be added as sources in selective checks to trigger tests when only test_common files change. PR is coming

potiuk on (2024-10-16 16:10:07 UTC): Fix to avoid it in the future https://github.com/apache/airflow/pull/43088

"
2591717692,pull_request,closed,,Start porting DAG definition code to the Task SDK,"By ""definition code"" we mean anything needed at definition/parse time, leaving
anything to do with scheduling time decisions in Airflow's core.

Also in this PR I have _attempted_ to keep it to only porting defintiion code
for simple DAGs, leaving anything to do with mapped tasks or execution time in
core for now, but a few things ""leaked"" across.

And as the goal of this PR is to go from working state to working state some
of the code in Task SDK still imports from ""core"" (various types, enums or
helpers) that will need to be resolved before 3.0 release, but it is fine for
now.

I'm also aware that the class hierarchy with
airflow.models.baseoperator.BaseOperator (and to a lesser extend with DAG) in
particular is very messy right now, and we will need to think how we want to
add on the scheduling-time functions etc, as I'm not yet sold that having Core
Airflow depend upon the Task-SDK classes/import the code is the right
structure, but we can address that later

We will also need to addresses the rendered docs for the Task SDK in a future
PR -- the goal is that ""anything"" exposed on `airflow.sdk` directly is part of
the public API, but right now the renedered docs show DAG as
`airflow.sdk.definitions.dag.DAG` which is certainly not what we want users to
see.

closes https://github.com/apache/airflow/issues/43011
",ashb,2024-10-16 12:19:05+00:00,[],2024-10-30 18:23:51+00:00,2024-10-30 18:20:55+00:00,https://github.com/apache/airflow/pull/43076,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-sdk', None)]","[{'comment_id': 2416749341, 'issue_id': 2591717692, 'author': 'ashb', 'body': 'This is very much at the ""boring ground work stage"" - once we\'ve got this covered we can add some of the execution changes which is not of the n""execution interface"" side where it gets fun', 'created_at': datetime.datetime(2024, 10, 16, 12, 48, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420504750, 'issue_id': 2591717692, 'author': 'ashb', 'body': ""@kaxil @jscheffl I've just pushed latest changes to this. Probably not worth looking at it again until I've finished it and have a decent idea that the tests are passing locally, but in the last commit I've just pushed I have removed the old code I've ported over, so it might be slightly clearer where I've just moved code."", 'created_at': datetime.datetime(2024, 10, 17, 20, 35, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420585715, 'issue_id': 2591717692, 'author': 'ashb', 'body': 'Current mypy status:\r\n\r\n> Found 58 errors in 41 files (checked 1135 source files)\r\n\r\nTest wise, at least `tests/models/test_baseoperator.py` and `task_sdk/tests/` are passing.', 'created_at': datetime.datetime(2024, 10, 17, 21, 14, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442810509, 'issue_id': 2591717692, 'author': 'ashb', 'body': ""Okay, we should be getting there now.\r\n\r\nMypy should be happy, most of tests/models should pass\r\n\r\n```\r\nFAILED tests/models/test_mappedoperator.py::test_task_mapping_default_args - AssertionError: assert equals failed\r\n  'airflow'  'test'\r\nFAILED tests/models/test_mappedoperator.py::test_task_mapping_override_default_args - AssertionError: assert equals failed\r\n  DateTime(2016, 1, 1, 0, 0, 0, tzinfo=Timezone('UTC'))               DateTime(2024, 10, 28, 22, 38, 58, 228687, tzinfo=Timezone('UTC'))\r\nFAILED tests/models/test_mappedoperator.py::test_mapped_task_applies_default_args_classic - assert equals failed\r\n  None                              datetime.timedelta(seconds=1800)\r\nFAILED tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_pandas_dataframes_works_with_the_string_compare - ModuleNotFoundError: No module named 'pandas'\r\nFAILED tests/models/test_taskinstance.py::TestTaskInstance::test_set_dag - RuntimeError: Operator <Task(EmptyOperator): op_1> has not been assigned to a DAG yet\r\nFAILED tests/models/test_taskinstance.py::TestTaskInstance::test_infer_dag - ValueError: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(EmptyOperator): test_op_1>, <Task(EmptyOperator): test_op_2>]\r\nFAILED tests/models/test_taskinstance.py::TestTaskInstance::test_handle_failure - AttributeError: 'NoneType' object has no attribute 'args'\r\nFAILED tests/models/test_taskinstance.py::test_lazy_xcom_access_does_not_pickle_session - RuntimeError: unknown backend None\r\n```\r\n\r\n`8 failed, 1258 passed, 3 skipped, 1 warning in 58.45s` from running `pytest tests/serialization/test_dag_serialization.py tests/models/`"", 'created_at': datetime.datetime(2024, 10, 28, 22, 43, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444747800, 'issue_id': 2591717692, 'author': 'ashb', 'body': '(Adding the legacy api label)', 'created_at': datetime.datetime(2024, 10, 29, 16, 16, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445088817, 'issue_id': 2591717692, 'author': 'ashb', 'body': ""Taking this out of draft now as it is almost there, a few small errors to chase down/correct but otherwise where we want it to be.\r\n\r\n(Well that's not true, the change is about 10x what I'd _like_, but this was about as small as I could think to make it)"", 'created_at': datetime.datetime(2024, 10, 29, 18, 54, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2446803291, 'issue_id': 2591717692, 'author': 'ashb', 'body': ""Some note about the future direction of this: Right now the scheduler is still depending upon the TaskSDK, but that is _mostly_ to make the change as small as we can.\r\n\r\nOnce we have something like this accepted and merged we will look at making the Serialized DAG etc not depend on the TaskSDK (as the scheduler should be able to operate on a much simpler interface than the full DAG Authoring interface.) We'll need to explore what makes sense, and also how we usefully share enums (as as trigger rules) as it would be nice if the scheduler does not need to depend on the task-sdk"", 'created_at': datetime.datetime(2024, 10, 30, 11, 46, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2447914895, 'issue_id': 2591717692, 'author': 'ashb', 'body': 'There are lots more things to move over to the TaskSDK before AIP-72 will be complete which we will track in the project board, but since this is the big base, and slow to test due to unavoidable wide reaching changes we will merge this and follow up with future changes for the rest (things like Mapped operator, DagParam etc)', 'created_at': datetime.datetime(2024, 10, 30, 17, 42, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2448013828, 'issue_id': 2591717692, 'author': 'kaxil', 'body': 'Merging this, one of the failures around k8s test that took longer than an hour looks like a transient one:\r\n\r\n```\r\nProgress: airflow-python-3.9-v1.28.13   Error during running tests for Python 3.9, Kubernetes v1.28.13\r\nProgress: airflow-python-3.10-v1.29.8   Image: ""ghcr.io/apache/airflow/main/prod/python3.10-kubernetes"" with ID ""sha256:1547fde10197845f0938fd7d0fc5977273a4871e016c8102ce9c8eb33010d064"" not [...]\r\n```\r\n\r\nIf for some reason it fails on main too, we will debug it', 'created_at': datetime.datetime(2024, 10, 30, 18, 23, 41, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-10-16 12:48:02 UTC): This is very much at the ""boring ground work stage"" - once we've got this covered we can add some of the execution changes which is not of the n""execution interface"" side where it gets fun

ashb (Issue Creator) on (2024-10-17 20:35:56 UTC): @kaxil @jscheffl I've just pushed latest changes to this. Probably not worth looking at it again until I've finished it and have a decent idea that the tests are passing locally, but in the last commit I've just pushed I have removed the old code I've ported over, so it might be slightly clearer where I've just moved code.

ashb (Issue Creator) on (2024-10-17 21:14:07 UTC): Current mypy status:


Test wise, at least `tests/models/test_baseoperator.py` and `task_sdk/tests/` are passing.

ashb (Issue Creator) on (2024-10-28 22:43:10 UTC): Okay, we should be getting there now.

Mypy should be happy, most of tests/models should pass

```
FAILED tests/models/test_mappedoperator.py::test_task_mapping_default_args - AssertionError: assert equals failed
  'airflow'  'test'
FAILED tests/models/test_mappedoperator.py::test_task_mapping_override_default_args - AssertionError: assert equals failed
  DateTime(2016, 1, 1, 0, 0, 0, tzinfo=Timezone('UTC'))               DateTime(2024, 10, 28, 22, 38, 58, 228687, tzinfo=Timezone('UTC'))
FAILED tests/models/test_mappedoperator.py::test_mapped_task_applies_default_args_classic - assert equals failed
  None                              datetime.timedelta(seconds=1800)
FAILED tests/models/test_renderedtifields.py::TestRenderedTaskInstanceFields::test_pandas_dataframes_works_with_the_string_compare - ModuleNotFoundError: No module named 'pandas'
FAILED tests/models/test_taskinstance.py::TestTaskInstance::test_set_dag - RuntimeError: Operator <Task(EmptyOperator): op_1> has not been assigned to a DAG yet
FAILED tests/models/test_taskinstance.py::TestTaskInstance::test_infer_dag - ValueError: Tried to create relationships between tasks that don't have DAGs yet. Set the DAG for at least one task and try again: [<Task(EmptyOperator): test_op_1>, <Task(EmptyOperator): test_op_2>]
FAILED tests/models/test_taskinstance.py::TestTaskInstance::test_handle_failure - AttributeError: 'NoneType' object has no attribute 'args'
FAILED tests/models/test_taskinstance.py::test_lazy_xcom_access_does_not_pickle_session - RuntimeError: unknown backend None
```

`8 failed, 1258 passed, 3 skipped, 1 warning in 58.45s` from running `pytest tests/serialization/test_dag_serialization.py tests/models/`

ashb (Issue Creator) on (2024-10-29 16:16:08 UTC): (Adding the legacy api label)

ashb (Issue Creator) on (2024-10-29 18:54:47 UTC): Taking this out of draft now as it is almost there, a few small errors to chase down/correct but otherwise where we want it to be.

(Well that's not true, the change is about 10x what I'd _like_, but this was about as small as I could think to make it)

ashb (Issue Creator) on (2024-10-30 11:46:40 UTC): Some note about the future direction of this: Right now the scheduler is still depending upon the TaskSDK, but that is _mostly_ to make the change as small as we can.

Once we have something like this accepted and merged we will look at making the Serialized DAG etc not depend on the TaskSDK (as the scheduler should be able to operate on a much simpler interface than the full DAG Authoring interface.) We'll need to explore what makes sense, and also how we usefully share enums (as as trigger rules) as it would be nice if the scheduler does not need to depend on the task-sdk

ashb (Issue Creator) on (2024-10-30 17:42:44 UTC): There are lots more things to move over to the TaskSDK before AIP-72 will be complete which we will track in the project board, but since this is the big base, and slow to test due to unavoidable wide reaching changes we will merge this and follow up with future changes for the rest (things like Mapped operator, DagParam etc)

kaxil on (2024-10-30 18:23:41 UTC): Merging this, one of the failures around k8s test that took longer than an hour looks like a transient one:

```
Progress: airflow-python-3.9-v1.28.13   Error during running tests for Python 3.9, Kubernetes v1.28.13
Progress: airflow-python-3.10-v1.29.8   Image: ""ghcr.io/apache/airflow/main/prod/python3.10-kubernetes"" with ID ""sha256:1547fde10197845f0938fd7d0fc5977273a4871e016c8102ce9c8eb33010d064"" not [...]
```

If for some reason it fails on main too, we will debug it

"
2591626330,pull_request,closed,,Use asset in common provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-16 11:45:38+00:00,[],2024-10-17 09:23:55+00:00,2024-10-17 09:23:55+00:00,https://github.com/apache/airflow/pull/43075,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2591496176,pull_request,closed,,Replace Mateusz with Kalyan in the triage team,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-16 10:58:05+00:00,[],2024-10-16 12:15:20+00:00,2024-10-16 12:15:19+00:00,https://github.com/apache/airflow/pull/43074,"[('area:dev-tools', '')]","[{'comment_id': 2416493945, 'issue_id': 2591496176, 'author': 'rawwar', 'body': 'Thank you @potiuk!', 'created_at': datetime.datetime(2024, 10, 16, 11, 10, 34, tzinfo=datetime.timezone.utc)}]","rawwar on (2024-10-16 11:10:34 UTC): Thank you @potiuk!

"
2591478724,pull_request,closed,,Rename dataset as asset in UI,"As part of https://github.com/apache/airflow/issues/42307

---

Rename ``DagRunTriggeredByType.DATASET`` as ``DagRunTriggeredByType.ASSET`` and all the name ``dataset`` in all the UI components to ``asset``.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-16 10:51:23+00:00,['Lee-W'],2024-10-28 06:21:22+00:00,2024-10-23 06:16:45+00:00,https://github.com/apache/airflow/pull/43073,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:db-migrations', 'PRs with DB migration'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2428014469, 'issue_id': 2591478724, 'author': 'Lee-W', 'body': '> Mhm, I am not good with this PR. We will ""throw away"" the old UI once we have the New ready. Until then we need to maintain old and new UI.\r\n> \r\n> If we now mass-rename the legacy UI parts for Dataset->Asset... the legacy UI wiull diverge a lot from the 2.x line. This means any patch/contribution would need to be adjusted not to ""by accident"" convert Dataset to Asset in the 2.x line.\r\n> \r\n> Could we leave the legacy UI un-touched and rename just the new UI? because:\r\n> \r\n>     1. Maintenance on the legacy will be harder if the legacy diverges\r\n> \r\n>     2. Is is a un-needed change if the UI anyway will be removed (soon)\r\n\r\nI\'m unsure 🤔 The concept of datasets no longer exists in the main branch, so keeping these dataset things in the main branch seems odd. I\'m uncertain whether we anticipate many changes to the UI side in version 2.x, but even if so, those changes could probably go to the 2.x branch. But I\'m not heavily contributing to the UI end of Airflow, so I would love to know what @bbovenzi thinks.', 'created_at': datetime.datetime(2024, 10, 22, 1, 12, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429757753, 'issue_id': 2591478724, 'author': 'bbovenzi', 'body': 'Would the backend not also have issues with backporting changes to 2.10/11?\r\n\r\nI do agree that much of this work isn\'t necessary because we will be removing the `/api_connexion`, and `/www` directories.  It wasn\'t just confusing to mix ""asset"" and ""datasets"" in the codebase, it did introduce a few bugs. So I am ok with swapping everything over for consistency\'s sake.', 'created_at': datetime.datetime(2024, 10, 22, 16, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431000828, 'issue_id': 2591478724, 'author': 'Lee-W', 'body': '> Would the backend not also have issues with backporting changes to 2.10/11?\r\n\r\nYep, whenever I need to do that kind of change, I just did them in separate branch instead of just backporting the merged commit.\r\n\r\n> I do agree that much of this work isn\'t necessary because we will be removing the `/api_connexion`, and `/www` directories. It wasn\'t just confusing to mix ""asset"" and ""datasets"" in the codebase, it did introduce a few bugs. So I am ok with swapping everything over for consistency\'s sake.\r\n\r\nThanks for confirming. If it actually introduced bugs, I think it\'s better to just change it in main. I\'ll go ahead and merge it', 'created_at': datetime.datetime(2024, 10, 23, 6, 13, 11, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-10-22 01:12:17 UTC): I'm unsure 🤔 The concept of datasets no longer exists in the main branch, so keeping these dataset things in the main branch seems odd. I'm uncertain whether we anticipate many changes to the UI side in version 2.x, but even if so, those changes could probably go to the 2.x branch. But I'm not heavily contributing to the UI end of Airflow, so I would love to know what @bbovenzi thinks.

bbovenzi on (2024-10-22 16:37:54 UTC): Would the backend not also have issues with backporting changes to 2.10/11?

I do agree that much of this work isn't necessary because we will be removing the `/api_connexion`, and `/www` directories.  It wasn't just confusing to mix ""asset"" and ""datasets"" in the codebase, it did introduce a few bugs. So I am ok with swapping everything over for consistency's sake.

Lee-W (Issue Creator) on (2024-10-23 06:13:11 UTC): Yep, whenever I need to do that kind of change, I just did them in separate branch instead of just backporting the merged commit.


Thanks for confirming. If it actually introduced bugs, I think it's better to just change it in main. I'll go ahead and merge it

"
2591402923,pull_request,closed,,"Typo correction in 07_local_virtualenv.rst :""way""","Corrected typo from ""wey"" to ""way"" in the documentation file 07_local_virtualenv.rst.",biswa-b,2024-10-16 10:24:06+00:00,[],2024-10-16 12:17:29+00:00,2024-10-16 11:33:50+00:00,https://github.com/apache/airflow/pull/43072,"[('area:dev-tools', '')]","[{'comment_id': 2416386741, 'issue_id': 2591402923, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 16, 10, 24, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416546488, 'issue_id': 2591402923, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 16, 11, 33, 52, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-16 10:24:10 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-16 11:33:52 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2591388162,pull_request,closed,,Allow building docs for not-ready providers,"The `not-ready` providers were skipped in https://github.com/apache/airflow/pull/42873 as we were releasing a batch of providers.

I have manually gone ahead and uploaded inventories for edge & standard providers so this is no longer a problem.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-16 10:19:53+00:00,[],2024-10-16 11:27:02+00:00,2024-10-16 11:19:41+00:00,https://github.com/apache/airflow/pull/43071,"[('area:dev-tools', ''), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2416387561, 'issue_id': 2591388162, 'author': 'eladkal', 'body': 'When bulk releasing provider it builds everything we need to have a flag to include/exclude build of not ready providers (like we have with suspeneded)', 'created_at': datetime.datetime(2024, 10, 16, 10, 24, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416392072, 'issue_id': 2591388162, 'author': 'kaxil', 'body': '> When bulk releasing provider it builds everything we need to have a flag to include/exclude build of not ready providers (like we have with suspeneded)\r\n\r\nYup, working on it for a separate PR. We technically do have `--include-not-ready-providers` -- need to make sure it works for docs.\r\n\r\nEDIT:\r\nThe following command is already working, the same support is already there for `build-docs` too\r\n```\r\nbreeze release-management prepare-provider-documentation --dry-run --include-not-ready-providers\r\n```\r\nOutput:\r\n```\r\nSkipped on no changes: 93\r\n\r\nairbyte alibaba amazon apache.beam apache.cassandra apache.drill apache.druid apache.flink apache.hdfs apache.hive apache.iceberg apache.impala apache.kafka apache.kylin apache.livy apache.pig\r\napache.pinot apache.spark apprise arangodb asana atlassian.jira celery cloudant cncf.kubernetes cohere common.compat common.io common.sql databricks datadog dbt.cloud dingding discord docker edge\r\nelasticsearch exasol fab facebook ftp github google grpc hashicorp http imap influxdb jdbc jenkins microsoft.azure microsoft.mssql microsoft.psrp microsoft.winrm mongo mysql neo4j odbc openai openfaas\r\nopenlineage opensearch opsgenie oracle pagerduty papermill pgvector pinecone postgres presto qdrant redis salesforce samba segment sendgrid sftp singularity slack smtp snowflake sqlite ssh standard\r\ntableau telegram teradata trino vertica weaviate yandex ydb zendesk\r\n```\r\n\r\nWith just `breeze release-management prepare-provider-documentation --dry-run`:\r\n\r\n```\r\nSkipped on no changes: 91\r\n\r\nairbyte alibaba amazon apache.beam apache.cassandra apache.drill apache.druid apache.flink apache.hdfs apache.hive apache.iceberg apache.impala apache.kafka apache.kylin apache.livy apache.pig\r\napache.pinot apache.spark apprise arangodb asana atlassian.jira celery cloudant cncf.kubernetes cohere common.compat common.io common.sql databricks datadog dbt.cloud dingding discord docker\r\nelasticsearch exasol fab facebook ftp github google grpc hashicorp http imap influxdb jdbc jenkins microsoft.azure microsoft.mssql microsoft.psrp microsoft.winrm mongo mysql neo4j odbc openai openfaas\r\nopenlineage opensearch opsgenie oracle pagerduty papermill pgvector pinecone postgres presto qdrant redis salesforce samba segment sendgrid sftp singularity slack smtp snowflake sqlite ssh tableau\r\ntelegram teradata trino vertica weaviate yandex ydb zendesk\r\n```', 'created_at': datetime.datetime(2024, 10, 16, 10, 26, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-10-16 10:24:14 UTC): When bulk releasing provider it builds everything we need to have a flag to include/exclude build of not ready providers (like we have with suspeneded)

kaxil (Issue Creator) on (2024-10-16 10:26:00 UTC): Yup, working on it for a separate PR. We technically do have `--include-not-ready-providers` -- need to make sure it works for docs.

EDIT:
The following command is already working, the same support is already there for `build-docs` too
```
breeze release-management prepare-provider-documentation --dry-run --include-not-ready-providers
```
Output:
```
Skipped on no changes: 93

airbyte alibaba amazon apache.beam apache.cassandra apache.drill apache.druid apache.flink apache.hdfs apache.hive apache.iceberg apache.impala apache.kafka apache.kylin apache.livy apache.pig
apache.pinot apache.spark apprise arangodb asana atlassian.jira celery cloudant cncf.kubernetes cohere common.compat common.io common.sql databricks datadog dbt.cloud dingding discord docker edge
elasticsearch exasol fab facebook ftp github google grpc hashicorp http imap influxdb jdbc jenkins microsoft.azure microsoft.mssql microsoft.psrp microsoft.winrm mongo mysql neo4j odbc openai openfaas
openlineage opensearch opsgenie oracle pagerduty papermill pgvector pinecone postgres presto qdrant redis salesforce samba segment sendgrid sftp singularity slack smtp snowflake sqlite ssh standard
tableau telegram teradata trino vertica weaviate yandex ydb zendesk
```

With just `breeze release-management prepare-provider-documentation --dry-run`:

```
Skipped on no changes: 91

airbyte alibaba amazon apache.beam apache.cassandra apache.drill apache.druid apache.flink apache.hdfs apache.hive apache.iceberg apache.impala apache.kafka apache.kylin apache.livy apache.pig
apache.pinot apache.spark apprise arangodb asana atlassian.jira celery cloudant cncf.kubernetes cohere common.compat common.io common.sql databricks datadog dbt.cloud dingding discord docker
elasticsearch exasol fab facebook ftp github google grpc hashicorp http imap influxdb jdbc jenkins microsoft.azure microsoft.mssql microsoft.psrp microsoft.winrm mongo mysql neo4j odbc openai openfaas
openlineage opensearch opsgenie oracle pagerduty papermill pgvector pinecone postgres presto qdrant redis salesforce samba segment sendgrid sftp singularity slack smtp snowflake sqlite ssh tableau
telegram teradata trino vertica weaviate yandex ydb zendesk
```

"
2591052880,pull_request,closed,,passing the filetype for SlackAPIFileOperator,"related: #42889 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Bowrna,2024-10-16 08:18:37+00:00,[],2024-10-17 12:19:32+00:00,2024-10-17 12:19:32+00:00,https://github.com/apache/airflow/pull/43069,"[('area:providers', ''), ('provider:slack', '')]","[{'comment_id': 2418602829, 'issue_id': 2591052880, 'author': 'Bowrna', 'body': 'Tests passed now @shahar1', 'created_at': datetime.datetime(2024, 10, 17, 6, 11, 4, tzinfo=datetime.timezone.utc)}]","Bowrna (Issue Creator) on (2024-10-17 06:11:04 UTC): Tests passed now @shahar1

"
2590529264,pull_request,closed,,Remove DAG.get_num_active_runs,"We don't need this function.  There's already an almost-identical function on DagRun that we can use, namely DagRun.active_runs_of_dags.

Also simplified that one.
",dstandish,2024-10-16 03:54:41+00:00,[],2024-10-16 15:07:15+00:00,2024-10-16 15:07:13+00:00,https://github.com/apache/airflow/pull/43067,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2590478867,pull_request,closed,,Add min version to cloudpickle,"related to #42989

~~Cloudpickle 3.0.0 was released about a year ago in October 2023. I think that's a sufficient min version. Latest version of cloudpickle is 3.1.0, that was released last week~~

Apache beam  has a pin `~=2.2.1` even on latest release and its [main](https://github.com/apache/beam/blob/1487cf560fc2fff2f13ecf74aaf95a0ddbdc9d61/sdks/python/setup.py#L358) 

Hence, using a min version of 2.2.1 and above",rawwar,2024-10-16 03:19:06+00:00,[],2024-10-17 01:31:37+00:00,2024-10-16 20:02:48+00:00,https://github.com/apache/airflow/pull/43066,[],[],
2590421870,pull_request,closed,,[Backport] Remove zombie from executor,This is a backport for #42932,uranusjr,2024-10-16 02:39:26+00:00,[],2024-10-23 09:03:39+00:00,2024-10-16 04:08:35+00:00,https://github.com/apache/airflow/pull/43065,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2590416933,pull_request,closed,,Drop unneeded unique() call on SQL,See https://github.com/apache/airflow/pull/42932#discussion_r1801237830,uranusjr,2024-10-16 02:34:54+00:00,[],2024-10-16 04:08:52+00:00,2024-10-16 04:08:50+00:00,https://github.com/apache/airflow/pull/43064,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2590386703,pull_request,closed,,Double-check TaskInstance state if it differs from the Executor state.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #42991 (discussion)

<!-- Please keep an empty line above the dashes. -->

In the course of investigating https://github.com/apache/airflow/discussions/42991 I am a bit suspicious that there is a race condition between the DB fetch on line 285 and the executor state check on line 312.

Basically my suspicion is that the following order of operations is sometimes happening:

- (backfill_job_runner.py) TI returned from the DB contains the old state (queued)
- (celery worker) Worker dequeue the task and change state to running.
- (celery worker) Worker complete the task and change state to success.
- (backfill_job_runner.py) Executor state changes to success (celery async future thing)
- (backfill_job_runner.py) Fail state comparison (""The executor reported that the task instance finished with state success, but the task instance's state attribute is queued."")

More details on my situation in the above linked discussion, but important to know is in my case the worker is completing the task in about 300 milliseconds.

Therefore, I propose that the backfill job should ""double-check"" the task instance state if it is different from executor state by refreshing from DB. If the state is still different then fall back to the old logic of assuming that the task state has changed externally.

I am not sure if I've picked the right base for this PR. The backfill stuff is being totally re-written for Airflow 3 as part of [AIP-78](https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-78+Scheduler-managed+backfill) so I wouldn't know where to make this change or even if the same bug exists there.

# Update 2024-10-17

https://github.com/apache/airflow/discussions/42991#discussioncomment-10965832 I patched the change into my deployment and am seeing the added log line being emitted, and _not_ followed by the `The executor reported that the task instance finished with state success, but the task instance's state attribute is queued` message. This tells me that the refresh is probably necessary under such circumstances.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",antonysouthworth-halter,2024-10-16 02:09:19+00:00,[],2024-12-09 14:49:36+00:00,2024-12-09 14:49:32+00:00,https://github.com/apache/airflow/pull/43063,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:backfill', 'Specifically for backfill related')]","[{'comment_id': 2415580329, 'issue_id': 2590386703, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 16, 2, 9, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415979156, 'issue_id': 2590386703, 'author': 'potiuk', 'body': 'cc: @dstandish -> maybe with your recent backfll  experience you can comment on that - that seems like a good candidate to fix for 2.10 if it solves the issue (regardless from the fact that in Airflow 3 backfill is going to be differently).', 'created_at': datetime.datetime(2024, 10, 16, 7, 44, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517269250, 'issue_id': 2590386703, 'author': 'utkarsharma2', 'body': '@potiuk / @eladkal / @kaxil Do we need this for 2.10.4?', 'created_at': datetime.datetime(2024, 12, 4, 12, 53, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2517566211, 'issue_id': 2590386703, 'author': 'dstandish', 'body': '> cc: @dstandish -> maybe with your recent backfll experience you can comment on that - that seems like a good candidate to fix for 2.10 if it solves the issue (regardless from the fact that in Airflow 3 backfill is going to be differently).\r\n\r\nlemme see', 'created_at': datetime.datetime(2024, 12, 4, 14, 17, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2528205109, 'issue_id': 2590386703, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 9, 14, 49, 35, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-16 02:09:23 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-16 07:44:17 UTC): cc: @dstandish -> maybe with your recent backfll  experience you can comment on that - that seems like a good candidate to fix for 2.10 if it solves the issue (regardless from the fact that in Airflow 3 backfill is going to be differently).

utkarsharma2 on (2024-12-04 12:53:47 UTC): @potiuk / @eladkal / @kaxil Do we need this for 2.10.4?

dstandish on (2024-12-04 14:17:15 UTC): lemme see

boring-cyborg[bot] on (2024-12-09 14:49:35 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2590356875,pull_request,closed,,Reorganize ``api_fastapi`` folder into apps,"In preparation for adding https://github.com/apache/airflow/pull/43015, this PRs re-organizes the ``api_fastapi``. The goal will be to have 2 apps: `execution_api` (Task Execution API: AIP-72) and the `core_api` (UI and Public API).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-16 01:43:35+00:00,[],2024-10-16 12:37:38+00:00,2024-10-16 12:37:36+00:00,https://github.com/apache/airflow/pull/43062,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2416296089, 'issue_id': 2590356875, 'author': 'kaxil', 'body': 'Thanks @pierrejeambrun , I updated docs & tests\r\n\r\n> Good idea, I like the naming as well.\r\n> \r\n> I think we also need to mirror those changes on the `test` folder.\r\n> \r\n> In `17_adding_api_endpoints.rst` I think we still have a reference to `api_fastapi/views`.', 'created_at': datetime.datetime(2024, 10, 16, 9, 49, 22, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-10-16 09:49:22 UTC): Thanks @pierrejeambrun , I updated docs & tests

"
2590218571,pull_request,closed,,Print the key name when max_length is exceeded,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

We had the ambiguous error show up in our logs: airflow.exceptions.AirflowException: The key has to be less than 250 characters. We had a task_id >= 250 characters and it was because of long task group names and some nesting. The log message was not helpful in pointing out where the error was. Adding the key value to the exception was super helpful diagnosing where the issue was.




<!-- Please keep an empty line above the dashes. -->

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jabbera,2024-10-16 00:07:29+00:00,[],2024-10-17 07:48:16+00:00,2024-10-17 07:48:16+00:00,https://github.com/apache/airflow/pull/43061,[],"[{'comment_id': 2415982360, 'issue_id': 2590218571, 'author': 'potiuk', 'body': 'cc: @o-nikolas re our discussions with long task_id and MySQL.', 'created_at': datetime.datetime(2024, 10, 16, 7, 45, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415984124, 'issue_id': 2590218571, 'author': 'potiuk', 'body': 'Can you please fix the unit test @jabbera ?', 'created_at': datetime.datetime(2024, 10, 16, 7, 46, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417358703, 'issue_id': 2590218571, 'author': 'jabbera', 'body': '> Can you please fix the unit test @jabbera ?\r\n\r\n@potiuk  Should be all set.', 'created_at': datetime.datetime(2024, 10, 16, 16, 38, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417839915, 'issue_id': 2590218571, 'author': 'o-nikolas', 'body': '> cc: @o-nikolas re our discussions with long task_id and MySQL.\r\n\r\nThanks @potiuk! Looking :eyes:', 'created_at': datetime.datetime(2024, 10, 16, 20, 5, 8, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-16 07:45:56 UTC): cc: @o-nikolas re our discussions with long task_id and MySQL.

potiuk on (2024-10-16 07:46:40 UTC): Can you please fix the unit test @jabbera ?

jabbera (Issue Creator) on (2024-10-16 16:38:30 UTC): @potiuk  Should be all set.

o-nikolas on (2024-10-16 20:05:08 UTC): Thanks @potiuk! Looking :eyes:

"
2590009463,pull_request,closed,,WIP Add trigger to new UI,"Draft to add a new Trigger UI

WIP:
- [ ] Triggering of DAG run not working
- [ ] Validation of DAG run config missing
- [ ] Form field generation missing, just a plan JSON for the start
- [ ] JSON CodeMirror is not auto-formatted
- [ ] If DAG is paused, add the option to enable

![image](https://github.com/user-attachments/assets/2671a10d-5098-47f8-811a-51254edf88c3)
",jscheffl,2024-10-15 21:51:00+00:00,[],2024-11-06 21:16:43+00:00,2024-11-06 21:16:43+00:00,https://github.com/apache/airflow/pull/43058,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2460800556, 'issue_id': 2590009463, 'author': 'jscheffl', 'body': 'Close in favor of moving forward with #43367', 'created_at': datetime.datetime(2024, 11, 6, 21, 16, 43, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-11-06 21:16:43 UTC): Close in favor of moving forward with #43367

"
2589955571,pull_request,closed,,Rename views to routes for FastAPI apps,"This is part of the change I want to do for https://github.com/apache/airflow/pull/43015 but going to break it down to keep it manageable.

Since these are actual routes for APIs, renaming them to routes instead of views.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-15 21:20:12+00:00,[],2024-10-15 22:15:19+00:00,2024-10-15 22:15:18+00:00,https://github.com/apache/airflow/pull/43057,[],[],
2589940768,pull_request,closed,,Bump `uv` to `0.4.22`,"https://pypi.org/project/uv/0.4.22

I added `--no-sources` to our `uv pip install` command, without it, it fails with following error

```
error: Failed to build: `apache-airflow @ file:///dist/apache_airflow-3.0.0.dev0.tar.gz`
  Caused by: Failed to parse entry for: `local-providers`
  Caused by: Package is not included as workspace package in `tool.uv.workspace`
```
Example: https://github.com/apache/airflow/actions/runs/11354720505/job/31582868760#step:11:2896

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-15 21:10:12+00:00,[],2024-10-16 07:12:56+00:00,2024-10-16 00:04:57+00:00,https://github.com/apache/airflow/pull/43056,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2415176210, 'issue_id': 2589940768, 'author': 'kaxil', 'body': '@potiuk Got another one 😆', 'created_at': datetime.datetime(2024, 10, 15, 21, 11, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415179085, 'issue_id': 2589940768, 'author': 'kaxil', 'body': 'This one fixes an issue @ashb raised: https://github.com/astral-sh/uv/issues/8041', 'created_at': datetime.datetime(2024, 10, 15, 21, 13, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415182257, 'issue_id': 2589940768, 'author': 'potiuk', 'body': 'They are indeed working with lightning speed :)', 'created_at': datetime.datetime(2024, 10, 15, 21, 15, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415410442, 'issue_id': 2589940768, 'author': 'charliermarsh', 'body': ""Sorry for the `--no-sources` weirdness -- it'll be fixed in the next release: https://github.com/astral-sh/uv/pull/8235"", 'created_at': datetime.datetime(2024, 10, 16, 0, 48, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415411232, 'issue_id': 2589940768, 'author': 'kaxil', 'body': ""> Sorry for the `--no-sources` weirdness -- it'll be fixed in the next release: [astral-sh/uv#8235](https://github.com/astral-sh/uv/pull/8235)\r\n\r\nThanks @charliermarsh , I appreciate the quick turnaround"", 'created_at': datetime.datetime(2024, 10, 16, 0, 48, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415920630, 'issue_id': 2589940768, 'author': 'potiuk', 'body': 'Thanks @charliermarsh and the team (as usual :) . We are now getting more and more into using `uv workspaces` after our earlier discussions - so expect more of similar reports from us :)', 'created_at': datetime.datetime(2024, 10, 16, 7, 12, 54, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-10-15 21:11:26 UTC): @potiuk Got another one 😆

kaxil (Issue Creator) on (2024-10-15 21:13:24 UTC): This one fixes an issue @ashb raised: https://github.com/astral-sh/uv/issues/8041

potiuk on (2024-10-15 21:15:40 UTC): They are indeed working with lightning speed :)

charliermarsh on (2024-10-16 00:48:06 UTC): Sorry for the `--no-sources` weirdness -- it'll be fixed in the next release: https://github.com/astral-sh/uv/pull/8235

kaxil (Issue Creator) on (2024-10-16 00:48:59 UTC): Thanks @charliermarsh , I appreciate the quick turnaround

potiuk on (2024-10-16 07:12:54 UTC): Thanks @charliermarsh and the team (as usual :) . We are now getting more and more into using `uv workspaces` after our earlier discussions - so expect more of similar reports from us :)

"
2589894522,pull_request,closed,,feat: sensor to check status of Dataform action,"# Summary

Adds a new sensor to the Google Cloud provider that waits on the status of a target in a workflow invocation.

# Why might this be useful?

Right now I use Airflow to trigger a Dataform workflow on a schedule. I use the `async=True` argument on the `DataformCreateWorkflowInvocationOperator` and the `DataformWorkflowInvocationStateSensor` to wait until the workflow is complete before running subsequent steps. This approach is simple but comes with some tradeoffs due to its lack of granularity.

1. If any target in the workflow fails, the sensor will also fail. If I want to have subsequent tasks run for any target that does succeed, this approach will not work.
2. If I have multiple targets that my subsequent tasks depend on, there may be large gap between when Dataform completes the tasks. This approach has subsequent tasks run when the whole Dataform workflow is complete.

The sensor added in this PR addresses the trade offs listed above by providing a more granular sensor. Instead of waiting for the workflow to complete, it waits for a target within the workflow to complete.",steve148,2024-10-15 20:53:30+00:00,[],2024-11-06 15:20:08+00:00,2024-10-23 13:50:50+00:00,https://github.com/apache/airflow/pull/43055,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2415101388, 'issue_id': 2589894522, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 20, 53, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422912441, 'issue_id': 2589894522, 'author': 'steve148', 'body': 'Hey @shahar1! Thanks for having me here. I rebased the branch to add unit tests and update it to the latest.', 'created_at': datetime.datetime(2024, 10, 18, 17, 16, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432273944, 'issue_id': 2589894522, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 23, 13, 50, 53, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 20:53:35 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

steve148 (Issue Creator) on (2024-10-18 17:16:22 UTC): Hey @shahar1! Thanks for having me here. I rebased the branch to add unit tests and update it to the latest.

boring-cyborg[bot] on (2024-10-23 13:50:53 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2589673554,pull_request,closed,,chore(docs): add required import of BranchDayOfWeekOperator,I was following the docs here: https://airflow.apache.org/docs/apache-airflow/stable/_api/airflow/operators/weekday/index.html and adapting those two code blocks.  It failed because I didn't import BranchDayOfWeekOperator.  So I'm adding it here.  Let me know if that does not follow the project's standards.,sfirke,2024-10-15 19:25:39+00:00,[],2024-10-17 14:00:15+00:00,2024-10-17 12:43:51+00:00,https://github.com/apache/airflow/pull/43053,"[('area:providers', ''), ('provider:standard', '')]","[{'comment_id': 2414834683, 'issue_id': 2589673554, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 19, 25, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415996731, 'issue_id': 2589673554, 'author': 'potiuk', 'body': 'There is a bug added in recent changes that makes this PR fail - let me fix it and I will ask you to rebase it (missing provider)\r\n\r\nAlso before you rebase - I recommend installing `pre-commit` - then it will fix the static check issue automaticaly.', 'created_at': datetime.datetime(2024, 10, 16, 7, 52, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416372211, 'issue_id': 2589673554, 'author': 'kaxil', 'body': '> There is a bug added in recent changes that makes this PR fail - let me fix it and I will ask you to rebase it (missing provider)\r\n> \r\n> Also before you rebase - I recommend installing `pre-commit` - then it will fix the static check issue automaticaly.\r\n\r\nIt is fixed in https://github.com/apache/airflow/pull/43071 . Once that is merged, please rebase on `main` and docs should start building again :)', 'created_at': datetime.datetime(2024, 10, 16, 10, 20, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419386679, 'issue_id': 2589673554, 'author': 'shahar1', 'body': 'Rebased and fixed a linting error', 'created_at': datetime.datetime(2024, 10, 17, 12, 18, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419445915, 'issue_id': 2589673554, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 17, 12, 43, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419635453, 'issue_id': 2589673554, 'author': 'sfirke', 'body': 'Thanks for fixing my linting 🙏 I did this change in the GitHub web UI but will make future contributions using a proper dev environment.', 'created_at': datetime.datetime(2024, 10, 17, 14, 0, 14, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 19:25:44 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-16 07:52:39 UTC): There is a bug added in recent changes that makes this PR fail - let me fix it and I will ask you to rebase it (missing provider)

Also before you rebase - I recommend installing `pre-commit` - then it will fix the static check issue automaticaly.

kaxil on (2024-10-16 10:20:24 UTC): It is fixed in https://github.com/apache/airflow/pull/43071 . Once that is merged, please rebase on `main` and docs should start building again :)

shahar1 on (2024-10-17 12:18:24 UTC): Rebased and fixed a linting error

boring-cyborg[bot] on (2024-10-17 12:43:53 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

sfirke (Issue Creator) on (2024-10-17 14:00:14 UTC): Thanks for fixing my linting 🙏 I did this change in the GitHub web UI but will make future contributions using a proper dev environment.

"
2589653742,pull_request,closed,,Fix v2-10 build dependencies,"I saw tests on v2-10-test failing, this makes the builds successful again by updating needed dependencies

See: https://github.com/apache/airflow/actions/runs/11352541460/job/31575571791",jscheffl,2024-10-15 19:16:20+00:00,[],2024-10-24 09:58:44+00:00,2024-10-15 20:53:27+00:00,https://github.com/apache/airflow/pull/43052,"[('area:helm-chart', 'Airflow Helm Chart'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2589627090,pull_request,closed,,✨ Allow node_selector templating in KPO,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

### Description

Allow `node_selector` to be templated in KPO.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bdsoha,2024-10-15 19:02:04+00:00,[],2024-10-16 04:47:07+00:00,2024-10-15 21:52:35+00:00,https://github.com/apache/airflow/pull/43051,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2589614944,pull_request,closed,,replaced warning emoji in dev/breeze/README.md,"I removed an emoji from breeze's README.md file.
It caused me problems running breeze and I think it may happened to others too.
Also it's not necessary.

<details>
  <summary>The Error I Got</summary>
  I happens when python is trying to read the breeze readme and fails due to `UnicodeDecodeError`.

Traceback:
<pre>
Traceback (most recent call last):
  File ""C:\Users\Eilon\AppData\Local\Programs\Python\Python310-32\lib\runpy.py"", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""C:\Users\Eilon\AppData\Local\Programs\Python\Python310-32\lib\runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""C:\Users\Eilon\pipx\venvs\apache-airflow-breeze\Scripts\breeze.exe\__main__.py"", line 4, in <module>
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\breeze.py"", line 20, in <module>
    from airflow_breeze.commands.main_command import main
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\commands\main_command.py"", line 25, in <module>
    from airflow_breeze.commands.ci_image_commands import ci_image
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\commands\ci_image_commands.py"", line 32, in <module>
    from airflow_breeze.commands.common_image_options import (
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\commands\common_image_options.py"", line 23, in <module>
    from airflow_breeze.global_constants import (
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\global_constants.py"", line 30, in <module>
    from airflow_breeze.utils.path_utils import AIRFLOW_SOURCES_ROOT
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\utils\path_utils.py"", line 281, in <module>
    AIRFLOW_SOURCES_ROOT = find_airflow_sources_root_to_operate_on().resolve()
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\utils\path_utils.py"", line 266, in find_airflow_sources_root_to_operate_on
    reinstall_if_setup_changed()
  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\utils\path_utils.py"", line 180, in reinstall_if_setup_changed
    process_breeze_readme(breeze_sources, sources_hash)
<b>  File ""C:\Users\Eilon\Programming\python\open_source\airflow\dev\breeze\src\airflow_breeze\utils\path_utils.py"", line 149, in process_breeze_readme
    lines = breeze_readme.read_text().splitlines(keepends=True)</b>
  File ""C:\Users\Eilon\AppData\Local\Programs\Python\Python310-32\lib\pathlib.py"", line 1133, in read_text
    return f.read()
  File ""C:\Users\Eilon\AppData\Local\Programs\Python\Python310-32\lib\encodings\cp1252.py"", line 23, in decode
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 2143: character maps to <undefined>
</pre>

</details>

<!-- Please keep an empty line above the dashes. -->
---

",eilon246810,2024-10-15 18:56:38+00:00,[],2024-10-17 12:04:38+00:00,2024-10-15 20:44:44+00:00,https://github.com/apache/airflow/pull/43050,"[('invalid', ''), ('area:dev-tools', '')]","[{'comment_id': 2414823071, 'issue_id': 2589614944, 'author': 'kaxil', 'body': ""I think you will run into more problems. I don't think breeze has been tested on Windows, @potiuk correct me if I am wrong"", 'created_at': datetime.datetime(2024, 10, 15, 19, 18, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415049062, 'issue_id': 2589614944, 'author': 'potiuk', 'body': 'Yep. no windows no special encoding -  You are not supposed to use Breeze on windows - you should use WSL2. \r\n\r\nAlso - seems you have a problem with encoding of files checked out, the checkout by git is controlled by some configuration (Which we do not know).', 'created_at': datetime.datetime(2024, 10, 15, 20, 44, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415049642, 'issue_id': 2589614944, 'author': 'potiuk', 'body': 'Closing.', 'created_at': datetime.datetime(2024, 10, 15, 20, 44, 44, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-10-15 19:18:58 UTC): I think you will run into more problems. I don't think breeze has been tested on Windows, @potiuk correct me if I am wrong

potiuk on (2024-10-15 20:44:39 UTC): Yep. no windows no special encoding -  You are not supposed to use Breeze on windows - you should use WSL2. 

Also - seems you have a problem with encoding of files checked out, the checkout by git is controlled by some configuration (Which we do not know).

potiuk on (2024-10-15 20:44:44 UTC): Closing.

"
2589494705,pull_request,closed,,SSHHook expose auth_timeout parameter,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Expose an existing parameter on `SSHHook` so that it can be passed down to the `paramiko.SSHClient`

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gyandeeps,2024-10-15 17:59:01+00:00,[],2024-10-17 14:00:00+00:00,2024-10-17 05:10:41+00:00,https://github.com/apache/airflow/pull/43048,"[('area:providers', ''), ('provider:ssh', '')]","[{'comment_id': 2414670818, 'issue_id': 2589494705, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 17, 59, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418514905, 'issue_id': 2589494705, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 17, 5, 10, 43, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 17:59:05 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-17 05:10:43 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2589457356,pull_request,closed,,Decouple volume_configurations from capacity_provider_strategy,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #43046 
related: #43046 

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #43046 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pyrr,2024-10-15 17:43:45+00:00,[],2024-11-06 07:58:03+00:00,2024-11-06 07:58:03+00:00,https://github.com/apache/airflow/pull/43047,[],"[{'comment_id': 2414642868, 'issue_id': 2589457356, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 17, 43, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454021565, 'issue_id': 2589457356, 'author': 'eladkal', 'body': '@pyrr can you rebase and resolve conflicts?\r\nAlso please add unit test to avoid regression', 'created_at': datetime.datetime(2024, 11, 4, 7, 50, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2456222464, 'issue_id': 2589457356, 'author': 'pyrr', 'body': '@eladkal done.', 'created_at': datetime.datetime(2024, 11, 5, 4, 43, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2456893057, 'issue_id': 2589457356, 'author': 'romsharon98', 'body': '> @eladkal done.\r\n\r\nStatic checks need to be fixed', 'created_at': datetime.datetime(2024, 11, 5, 11, 13, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457361083, 'issue_id': 2589457356, 'author': 'pyrr', 'body': ""> Static checks need to be fixed\r\n\r\n@romsharon98 Fixed extra parameter issue-- should work now but I'm not sure how to run the unit tests on my end without waiting for you to trigger the workflow."", 'created_at': datetime.datetime(2024, 11, 5, 14, 42, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457379454, 'issue_id': 2589457356, 'author': 'romsharon98', 'body': ""> > Static checks need to be fixed\r\n> \r\n> @romsharon98 Fixed extra parameter issue-- should work now but I'm not sure how to run the unit tests on my end without waiting for you to trigger the workflow.\r\n\r\nYou can read more about how to run tests locally [here](https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#airflow-unit-tests)"", 'created_at': datetime.datetime(2024, 11, 5, 14, 50, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457414240, 'issue_id': 2589457356, 'author': 'pyrr', 'body': ""> > > Static checks need to be fixed\r\n> > \r\n> > \r\n> > @romsharon98 Fixed extra parameter issue-- should work now but I'm not sure how to run the unit tests on my end without waiting for you to trigger the workflow.\r\n> \r\n> You can read more about how to run tests locally [here](https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#airflow-unit-tests)\r\n\r\nThanks, will fix new error and QA tests on my side this time before requesting review."", 'created_at': datetime.datetime(2024, 11, 5, 15, 4, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457793097, 'issue_id': 2589457356, 'author': 'pyrr', 'body': '@romsharon98 \r\n\r\nTested locally + squashed the bug fix commits into one, good to retry workflow.', 'created_at': datetime.datetime(2024, 11, 5, 17, 37, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458090170, 'issue_id': 2589457356, 'author': 'pyrr', 'body': '@o-nikolas \r\n\r\nThanks for re-running the workflow, I see the tests are still failing. Not sure why since it works when I run the suite using breeze on my machine. Will investigate again.', 'created_at': datetime.datetime(2024, 11, 5, 20, 26, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458098989, 'issue_id': 2589457356, 'author': 'eladkal', 'body': '> @o-nikolas\r\n> \r\n> Thanks for re-running the workflow, I see the tests are still failing. Not sure why since it works when I run the suite using breeze on my machine. Will investigate again.\r\n\r\nIt fails on static checks. You just need to install and enable pre commit. It will automaticly fix it', 'created_at': datetime.datetime(2024, 11, 5, 20, 31, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458206079, 'issue_id': 2589457356, 'author': 'pyrr', 'body': 'Thanks @eladkal , I applied the pre-commit changes and fixed an additional issue with the expected_args.\r\n\r\nAlso @potiuk @ashb apologies for the code review request-- I committed another file I had modified locally for local testing.', 'created_at': datetime.datetime(2024, 11, 5, 21, 43, 8, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 17:43:48 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-11-04 07:50:17 UTC): @pyrr can you rebase and resolve conflicts?
Also please add unit test to avoid regression

pyrr (Issue Creator) on (2024-11-05 04:43:32 UTC): @eladkal done.

romsharon98 on (2024-11-05 11:13:03 UTC): Static checks need to be fixed

pyrr (Issue Creator) on (2024-11-05 14:42:44 UTC): @romsharon98 Fixed extra parameter issue-- should work now but I'm not sure how to run the unit tests on my end without waiting for you to trigger the workflow.

romsharon98 on (2024-11-05 14:50:20 UTC): You can read more about how to run tests locally [here](https://github.com/apache/airflow/blob/main/contributing-docs/testing/unit_tests.rst#airflow-unit-tests)

pyrr (Issue Creator) on (2024-11-05 15:04:09 UTC): Thanks, will fix new error and QA tests on my side this time before requesting review.

pyrr (Issue Creator) on (2024-11-05 17:37:16 UTC): @romsharon98 

Tested locally + squashed the bug fix commits into one, good to retry workflow.

pyrr (Issue Creator) on (2024-11-05 20:26:04 UTC): @o-nikolas 

Thanks for re-running the workflow, I see the tests are still failing. Not sure why since it works when I run the suite using breeze on my machine. Will investigate again.

eladkal on (2024-11-05 20:31:34 UTC): It fails on static checks. You just need to install and enable pre commit. It will automaticly fix it

pyrr (Issue Creator) on (2024-11-05 21:43:08 UTC): Thanks @eladkal , I applied the pre-commit changes and fixed an additional issue with the expected_args.

Also @potiuk @ashb apologies for the code review request-- I committed another file I had modified locally for local testing.

"
2589233303,pull_request,closed,,added MultipleFilesWebHdfsSensor,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

I added `MultipleFilesWebHdfsSensor` class in `providers.apache.hdfs.sensors.web_hdfs`.

The current existing `WebHdfsSensor` can check if one file exists, which requires many tasks to check many files (in my org we had 350+ sensors for a single DAG).

The new `MultipleFilesWebHdfsSensor` can list a whole directory and succeeds only when all the expected files landed in the hdfs.

This is my first contribution so I would greatly appreciate any guidance :)

<!-- Please keep an empty line above the dashes. -->
---


",eilon246810,2024-10-15 16:01:25+00:00,[],2024-10-17 17:17:58+00:00,2024-10-17 14:33:06+00:00,https://github.com/apache/airflow/pull/43045,"[('area:providers', ''), ('provider:apache-hdfs', '')]","[{'comment_id': 2414427309, 'issue_id': 2589233303, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 16, 1, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416017307, 'issue_id': 2589233303, 'author': 'romsharon98', 'body': 'Great first PR!\r\nI added a small comment about the testing and notice your static checks is failing.\r\nyou can read about configuring pre-commit [here](https://github.com/apache/airflow/blob/main/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit)', 'created_at': datetime.datetime(2024, 10, 16, 8, 1, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419723328, 'issue_id': 2589233303, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 17, 14, 33, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419919100, 'issue_id': 2589233303, 'author': 'kaxil', 'body': 'This PR has caused failures both static and tests. I am fixing them in https://github.com/apache/airflow/pull/43122\r\n\r\n\r\n```\r\n=========================== short test summary info ============================\r\nFAILED providers/tests/apache/hdfs/sensors/test_web_hdfs.py::TestMultipleFilesWebHdfsSensor::test_poke - AssertionError: assert \'Files Found in directory: \' in \'\'\r\n +  where \'\' = <_pytest.logging.LogCaptureFixture object at 0x7f40eba6dd30>.text\r\nFAILED providers/tests/apache/hdfs/sensors/test_web_hdfs.py::TestMultipleFilesWebHdfsSensor::test_poke_should_return_false_for_missing_file - assert \'Files Found in directory: \' in ""INFO     airflow.task.operators.airflow.providers.apache.hdfs.sensors.web_hdfs.MultipleFilesWebHdfsSensor:web_hdfs.py:78 There are missing files: {\'static_babynames2\', \'static_babynames3\', \'static_babynames1\'}\\n""\r\n +  where ""INFO     airflow.task.operators.airflow.providers.apache.hdfs.sensors.web_hdfs.MultipleFilesWebHdfsSensor:web_hdfs.py:78 There are missing files: {\'static_babynames2\', \'static_babynames3\', \'static_babynames1\'}\\n"" = <_pytest.logging.LogCaptureFixture object at 0x7f40ebf5ca00>.text\r\n=================== 2 failed, 17 passed, 1 warning in 12.66s ===================\r\n```', 'created_at': datetime.datetime(2024, 10, 17, 15, 52, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420083282, 'issue_id': 2589233303, 'author': 'potiuk', 'body': 'This was an interesting one - seems that for some reason the CI workflow DID NOT run at all - only build image workflow did. that\'s why it was ""green"".', 'created_at': datetime.datetime(2024, 10, 17, 17, 15, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420087778, 'issue_id': 2589233303, 'author': 'potiuk', 'body': 'This is a long known issue with GitHub that I raised to them 3 years ago - unfortunately there is a race condition that makes the PR ""green"" if the workflow have not started at all, or when it is just starting.... Very poor design IMHO for GitHub Actions @kaxil @romsharon98\r\n\r\nThe only way I found to prevent such accidental merges of ""green-but-incomplete"" PRs  is to look at the number of checks that ""passed"". When there are < 10, something is WRONG. But it\'s not really obvious and happened to me more than once to merge such PR.', 'created_at': datetime.datetime(2024, 10, 17, 17, 17, 57, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 16:01:30 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

romsharon98 on (2024-10-16 08:01:26 UTC): Great first PR!
I added a small comment about the testing and notice your static checks is failing.
you can read about configuring pre-commit [here](https://github.com/apache/airflow/blob/main/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit)

boring-cyborg[bot] on (2024-10-17 14:33:09 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

kaxil on (2024-10-17 15:52:10 UTC): This PR has caused failures both static and tests. I am fixing them in https://github.com/apache/airflow/pull/43122


```
=========================== short test summary info ============================
FAILED providers/tests/apache/hdfs/sensors/test_web_hdfs.py::TestMultipleFilesWebHdfsSensor::test_poke - AssertionError: assert 'Files Found in directory: ' in ''
 +  where '' = <_pytest.logging.LogCaptureFixture object at 0x7f40eba6dd30>.text
FAILED providers/tests/apache/hdfs/sensors/test_web_hdfs.py::TestMultipleFilesWebHdfsSensor::test_poke_should_return_false_for_missing_file - assert 'Files Found in directory: ' in ""INFO     airflow.task.operators.airflow.providers.apache.hdfs.sensors.web_hdfs.MultipleFilesWebHdfsSensor:web_hdfs.py:78 There are missing files: {'static_babynames2', 'static_babynames3', 'static_babynames1'}\n""
 +  where ""INFO     airflow.task.operators.airflow.providers.apache.hdfs.sensors.web_hdfs.MultipleFilesWebHdfsSensor:web_hdfs.py:78 There are missing files: {'static_babynames2', 'static_babynames3', 'static_babynames1'}\n"" = <_pytest.logging.LogCaptureFixture object at 0x7f40ebf5ca00>.text
=================== 2 failed, 17 passed, 1 warning in 12.66s ===================
```

potiuk on (2024-10-17 17:15:29 UTC): This was an interesting one - seems that for some reason the CI workflow DID NOT run at all - only build image workflow did. that's why it was ""green"".

potiuk on (2024-10-17 17:17:57 UTC): This is a long known issue with GitHub that I raised to them 3 years ago - unfortunately there is a race condition that makes the PR ""green"" if the workflow have not started at all, or when it is just starting.... Very poor design IMHO for GitHub Actions @kaxil @romsharon98

The only way I found to prevent such accidental merges of ""green-but-incomplete"" PRs  is to look at the number of checks that ""passed"". When there are < 10, something is WRONG. But it's not really obvious and happened to me more than once to merge such PR.

"
2589220159,pull_request,closed,,Add retry on error 502 and 504 (#42994),Back-port of #42994 to v2-10-test,jscheffl,2024-10-15 15:55:48+00:00,[],2024-10-15 19:17:04+00:00,2024-10-15 19:17:04+00:00,https://github.com/apache/airflow/pull/43044,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2589108380,pull_request,closed,,fix path to providers dir for mount sources breeze flag,"After moving providers directory, the `--mount-sources` Breeze flag pointed at the old directory.",mobuchowski,2024-10-15 15:18:05+00:00,[],2024-10-15 21:11:13+00:00,2024-10-15 19:39:22+00:00,https://github.com/apache/airflow/pull/43042,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2414985239, 'issue_id': 2589108380, 'author': 'potiuk', 'body': 'Thanks !', 'created_at': datetime.datetime(2024, 10, 15, 20, 36, 19, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 20:36:19 UTC): Thanks !

"
2589090816,pull_request,closed,,Detect system color theme and add active state to nav button,"Fix the theme config to set the initial theme to system and make sure nav buttons are active when on the appropriate route.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-15 15:12:28+00:00,[],2024-10-15 21:29:11+00:00,2024-10-15 19:05:19+00:00,https://github.com/apache/airflow/pull/43041,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2415200681, 'issue_id': 2589090816, 'author': 'potiuk', 'body': 'NICE! Thank @bbovenzi !', 'created_at': datetime.datetime(2024, 10, 15, 21, 29, 10, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 21:29:10 UTC): NICE! Thank @bbovenzi !

"
2589082053,pull_request,closed,,Masking configuration values irrelevant to DAG author,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Some configurations are irrelevant to DAG authors and hence we need to mask those to avoid it from getting logged unknowingly.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-10-15 15:09:43+00:00,[],2024-11-07 16:58:23+00:00,2024-10-23 15:46:47+00:00,https://github.com/apache/airflow/pull/43040,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2414393724, 'issue_id': 2589082053, 'author': 'potiuk', 'body': ""Just adding a unit test, and I think it's ready to go :)"", 'created_at': datetime.datetime(2024, 10, 15, 15, 46, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415746063, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': 'Struggling with some test related setup. I am running into this as of now:\r\n```\r\n../../tests_common/test_utils/db.py:23: in <module>\r\n    from airflow.models import (\r\n../../airflow/models/__init__.py:78: in __getattr__\r\n    val = import_string(f""{path}.{name}"")\r\n../../airflow/utils/module_loading.py:39: in import_string\r\n    module = import_module(module_path)\r\n/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n../../airflow/models/dag.py:95: in <module>\r\n    from airflow.models.abstractoperator import AbstractOperator, TaskStateChangeCallback\r\n../../airflow/models/abstractoperator.py:33: in <module>\r\n    from airflow.template.templater import Templater\r\n../../airflow/template/templater.py:23: in <module>\r\n    from airflow.io.path import ObjectStoragePath\r\n../../airflow/io/__init__.py:30: in <module>\r\n    from airflow.providers_manager import ProvidersManager\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\n    """"""Manages all providers.""""""\r\n    \r\n    from __future__ import annotations\r\n    \r\n    import fnmatch\r\n    import functools\r\n    import inspect\r\n    import json\r\n    import logging\r\n    import os\r\n    import sys\r\n    import traceback\r\n    import warnings\r\n    from dataclasses import dataclass\r\n    from functools import wraps\r\n    from time import perf_counter\r\n    from typing import TYPE_CHECKING, Any, Callable, MutableMapping, NamedTuple, TypeVar\r\n    \r\n    from packaging.utils import canonicalize_name\r\n    \r\n    from airflow.exceptions import AirflowOptionalProviderFeatureException\r\n>   from airflow.providers.standard.hooks.filesystem import FSHook\r\nE   ModuleNotFoundError: No module named \'airflow.providers.standard.hooks\'\r\n```\r\n\r\nI see some discussions around, does anyone have any suggestions for this? I use Pycharm', 'created_at': datetime.datetime(2024, 10, 16, 5, 9, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416485858, 'issue_id': 2589082053, 'author': 'potiuk', 'body': '> I see some discussions around, does anyone have any suggestions for this? I use Pycharm\r\n\r\nI believe (I have not yet had time to look at it) this requires to use `uv workspace` and the latest `uv` installed - @ashb - are there any instructions for that already somewhere ? \r\n\r\nI guess those should be updated ?\r\n\r\n* https://github.com/apache/airflow/blob/main/contributing-docs/07_local_virtualenv.rst\r\n* https://github.com/apache/airflow/blob/main/contributing-docs/quick-start-ide/contributors_quick_start_pycharm.rst\r\n* https://github.com/apache/airflow/blob/main/contributing-docs/quick-start-ide/contributors_quick_start_vscode.rst', 'created_at': datetime.datetime(2024, 10, 16, 11, 7, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416490112, 'issue_id': 2589082053, 'author': 'potiuk', 'body': 'I think we generally should provide rather comprehensive guide (at least with some links) to our contributors how to setup the venv now (Breeze is covered because it uses workspace installation internally I believe)? Am I right @ashb ?', 'created_at': datetime.datetime(2024, 10, 16, 11, 9, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416534240, 'issue_id': 2589082053, 'author': 'ashb', 'body': ""Breeze is all set up yes. UV workspace isn't 100% required yet (though I don't think anyone tested running tests from inside pycharm), but for pycharm to find imports you need to set up some paths as the right kind of folder in the UI \n\nI'm not a pycharm user, but @kaxil @dstandish can provide some insight."", 'created_at': datetime.datetime(2024, 10, 16, 11, 30, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416563853, 'issue_id': 2589082053, 'author': 'ashb', 'body': 'https://github.com/apache/airflow/pull/42951 should help Pycharm too. Remaining ""manual"" steps as pycharm user are:\r\n\r\n1. We marked `providers/src`  as Source Folder and `providers/src/airflow` as Namespace package.\r\n2. Verify that there is nothing on old provider path: `rm -rf airflow/providers`  :slightly_smiling_face:\r\n3. Trigger Rescan Project Indexes from **File** -> **Repair IDE**.', 'created_at': datetime.datetime(2024, 10, 16, 11, 41, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416662432, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': 'I just pulled in https://github.com/apache/airflow/pull/42951, it doesn\'t seem to fix it for me. I still keep getting\r\n```\r\n\r\n    """"""Manages all providers.""""""\r\n    \r\n    from __future__ import annotations\r\n    \r\n    import fnmatch\r\n    import functools\r\n    import inspect\r\n    import json\r\n    import logging\r\n    import os\r\n    import sys\r\n    import traceback\r\n    import warnings\r\n    from dataclasses import dataclass\r\n    from functools import wraps\r\n    from time import perf_counter\r\n    from typing import TYPE_CHECKING, Any, Callable, MutableMapping, NamedTuple, TypeVar\r\n    \r\n    from packaging.utils import canonicalize_name\r\n    \r\n    from airflow.exceptions import AirflowOptionalProviderFeatureException\r\n>   from airflow.providers.standard.hooks.filesystem import FSHook\r\nE   ModuleNotFoundError: No module named \'airflow.providers.standard\'\r\n```', 'created_at': datetime.datetime(2024, 10, 16, 12, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416852433, 'issue_id': 2589082053, 'author': 'dstandish', 'body': ""> I'm not a pycharm user, but @kaxil @dstandish can provide some insight.\r\n\r\nAnything in particular you wanted me to look at?"", 'created_at': datetime.datetime(2024, 10, 16, 13, 31, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416983638, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': '@ashb @potiuk @kaxil I changed the logic to incorporate what was suggested above. Now I am able to get this result:\r\n```\r\n[2024-10-16, 18:39:13 IST] {logging_mixin.py:190} INFO - environ({\'SHELL\': \'/bin/bash\', \'AIRFLOW__SMTP__SMTP_PORT\': \'587\', \'VERSION_SUFFIX_FOR_PYPI\': \'\', \'NUM_RUNS\': \'\', \'AIRFLOW__CELERY__RESULT_BACKEND\': \'db+***\', \'AIRFLOW_AUTH_MANAGER_CREDENTIAL_DIRECTORY\': \'/files\', \'USE_AIRFLOW_VERSION\': \'\', \'AIRFLOW__SMTP__SMTP_PASSWORD\': \'dummy_smtp_password\', \'AIRFLOW__SMTP__SMTP_USER\': \'dummy_user\', \'DB_RESET\': \'false\', \'TERM_PROGRAM_VERSION\': \'3.3a\', \'CASS_DRIVER_NO_CYTHON\': \'1\', \'DOCKER_IS_ROOTLESS\': \'false\', \'TMUX\': \'/root/.tmux/tmp/tmux-0/default,96,0\', \'DEPENDENCIES_EPOCH_NUMBER\': \'11\', \'HOSTNAME\': \'22a3f86e4c95\', \'COLOR_RESET\': \'\\x1b[0m\', \'AIRFLOW__WEBSERVER__SECRET_KEY_SECRET\': \'***_secret\', \'PYTHON_VERSION\': \'3.9.20\', \'LANGUAGE\': \'C.UTF-8\', \'HOST_USER_ID\': \'20\', \'FASTAPI_API_HOST_PORT\': \'29091\', \'USE_PACKAGES_FROM_DIST\': \'false\', \'COLLECT_ONLY\': \'false\', \'PACKAGE_FORMAT\': \'wheel\', \'AIRFLOW__CORE__PLUGINS_FOLDER\': \'/files/plugins\', \'AIRFLOW_CI_BUILD_EPOCH\': \'10\', \'CHICKEN_EGG_PROVIDERS\': \'\', \'MSSQL_HOST_PORT\': \'21433\', \'SQLALCHEMY_WARN_20\': \'true\', \'CELERY_BROKER_URLS_MAP\': ""{\'rabbitmq\': \'amqp://guest:guest@rabbitmq:5672\', \'redis\': \'redis://redis:6379/0\'}"", \'AIRFLOW_CONSTRAINTS_LOCATION\': \'\', \'DEV_MODE\': \'false\', \'AIRFLOW__CORE__DAGS_FOLDER\': \'/files/dags\', \'COLOR_RED\': \'\\x1b[31m\', \'RUN_SYSTEM_TESTS\': \'false\', \'COLOR_BLUE\': \'\\x1b[34m\', \'AIRFLOW_ENABLE_AIP_44\': \'true\', \'AIRFLOW_CI_IMAGE\': \'ghcr.io/apache/airflow/main/ci/python3.9\', \'TEST_TYPE\': \'\', \'ADDITIONAL_PATH\': \'~/.local/bin\', \'EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS\': \'\', \'PROVIDERS_SKIP_CONSTRAINTS\': \'false\', \'BREEZE_INIT_COMMAND\': \'\', \'PWD\': \'/opt/airflow\', \'AIRFLOW_SKIP_CONSTRAINTS\': \'false\', \'AIRFLOW__CELERY__BROKER_URL\': \'redis://redis:6379/0\', \'REMOVE_ARM_PACKAGES\': \'false\', \'AIRFLOW_VERSION\': \'3.0.0.dev0\', \'ENABLE_COVERAGE\': \'false\', \'VERBOSE_COMMANDS\': \'false\', \'AIRFLOW__CORE__LOAD_EXAMPLES\': \'false\', \'GITHUB_ACTIONS\': \'false\', \'INSTALL_MSSQL_CLIENT\': \'true\', \'CASS_DRIVER_BUILD_CONCURRENCY\': \'8\', \'CI_EVENT_TYPE\': \'pull_request\', \'UPGRADE_IF_NEEDED\': \'--upgrade\', \'INSTALL_MYSQL_CLIENT_TYPE\': \'mariadb\', \'BACKEND\': \'mysql\', \'CI_TARGET_BRANCH\': \'main\', \'PROVIDERS_CONSTRAINTS_MODE\': \'constraints-source-providers\', \'GUNICORN_CMD_ARGS\': \'--worker-tmp-dir /dev/shm/\', \'AIRFLOW_EXTRAS\': \'\', \'LD_PRELOAD\': \'/usr/lib/aarch64-linux-gnu/libstdc++.so.6\', \'PIP_PROGRESS_BAR\': \'on\', \'AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_SECRET\': \'dummy_sql_alchemy_conn\', \'HOME\': \'/root\', \'QUIET\': \'false\', \'UV_NO_CACHE\': \'true\', \'LANG\': \'C.UTF-8\', \'SUSPENDED_PROVIDERS_FOLDERS\': \'\', \'HELM_TEST_PACKAGE\': \'\', \'TMUX_TMPDIR\': \'/root/.tmux/tmp\', \'SQLITE_URL\': \'sqlite:////root/airflow/sqlite/airflow.db\', \'ISSUE_ID\': \'\', \'AIRFLOW_HOME\': \'/root/airflow\', \'MYSQL_VERSION\': \'8.0\', \'AIRFLOW_BREEZE_CONFIG_DIR\': \'/files/airflow-breeze-config\', \'POSTGRES_HOST_PORT\': \'25433\', \'EXTRA_UNINSTALL_FLAGS\': \'--python /usr/local/bin/python\', \'AIRFLOW_VERSION_SPECIFICATION\': \'\', \'GPG_KEY\': \'E3FF2839C048B25C084DEBE9B26995E310250568\', \'AIRFLOW__DATABASE__SQL_ALCHEMY_CONN\': \'***\', \'AIRFLOW_USE_UV\': \'true\', \'AIRFLOW_PRE_CACHED_PIP_PACKAGES\': \'true\', \'ADDITIONAL_DEV_APT_DEPS\': \'bash-completion dumb-init git graphviz krb5-user less libenchant-2-2 libgcc-11-dev libgeos-dev libpq-dev net-tools netcat-openbsd openssh-server postgresql-client software-properties-common rsync tmux unzip vim xxd\', \'COLOR_YELLOW\': \'\\x1b[33m\', \'ONLY_MIN_VERSION_UPDATE\': \'false\', \'AIRFLOW__CELERY__WORKER_CONCURRENCY\': \'8\', \'STANDALONE_DAG_PROCESSOR\': \'false\', \'AIRFLOW__CORE__EXECUTOR\': \'LocalExecutor\', \'INSTALL_SELECTED_PROVIDERS\': \'\', \'USE_XDIST\': \'false\', \'COMMIT_SHA\': \'c03ccfc0716fdbf88eb778c920767b4d3953ac5b\', \'CONSTRAINTS_GITHUB_REPOSITORY\': \'apache/airflow\', \'AIRFLOW__DATABASE__SQL_ALCHEMY_ENGINE_ARGS_SECRET\': \'dummy_sql_engine_args\', \'EXTRA_INSTALL_FLAGS\': \'--python /usr/local/bin/python\', \'AIRFLOW_CI_IMAGE_WITH_TAG\': \'ghcr.io/apache/airflow/main/ci/python3.9:latest\', \'SKIP_SSH_SETUP\': \'false\', \'TMUX_SESSION\': \'Airflow\', \'AIRFLOW_REPO\': \'apache/airflow\', \'DEV_APT_COMMAND\': \'\', \'AIRFLOW__WEBSERVER__SECRET_KEY\': \'***\', \'AIRFLOW_PIP_VERSION\': \'24.2\', \'ADDITIONAL_PIP_INSTALL_FLAGS\': \'\', \'SKIP_ENVIRONMENT_INITIALIZATION\': \'false\', \'ADDITIONAL_DEV_APT_COMMAND\': \'\', \'AIRFLOW_ENV\': \'development\', \'START_AIRFLOW\': \'true\', \'COLOR_GREEN\': \'\\x1b[32m\', \'AIRFLOW_BRANCH\': \'main\', \'CLEAN_AIRFLOW_INSTALLATION\': \'false\', \'FORCE_LOWEST_DEPENDENCIES\': \'false\', \'AIRFLOW__CORE__INTERNAL_API_SECRET_KEY_SECRET\': \'***_secret\', \'HOST_GROUP_ID\': \'20\', \'DEFAULT_BRANCH\': \'main\', \'INIT_SCRIPT_FILE\': \'init.sh\', \'AIRFLOW_CONSTRAINTS_MODE\': \'constraints-source-providers\', \'PYTHONPATH\': \'/opt/airflow\', \'TERM\': \'tmux-256color\', \'UPGRADE_BOTO\': \'false\', \'DOWNGRADE_PENDULUM\': \'false\', \'USER\': \'root\', \'HOST_OS\': \'darwin\', \'USE_UV\': \'true\', \'TMUX_PANE\': \'%1\', \'WEBSERVER_HOST_PORT\': \'28080\', \'AIRFLOW_UV_VERSION\': \'0.4.22\', \'AIRFLOW__CORE__INTERNAL_API_SECRET_KEY\': \'***\', \'INSTALL_POSTGRES_CLIENT\': \'true\', \'COMPOSE_FILE\': \'/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/base.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/docker-socket.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/backend-mysql.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/backend-mysql-port.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/files.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/base-ports.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/local.yml\', \'SHLVL\': \'2\', \'AIRFLOW_CONSTRAINTS_REFERENCE\': \'constraints-main\', \'DEFAULT_CONSTRAINTS_BRANCH\': \'constraints-main\', \'FILES_DIR\': \'/files\', \'CI_BUILD_ID\': \'0\', \'INSTALL_AIRFLOW_VERSION\': \'\', \'LC_MESSAGES\': \'C.UTF-8\', \'SYSTEM_TESTS_ENV_ID\': \'\', \'MOUNT_SOURCES\': \'selected\', \'PYTHONDONTWRITEBYTECODE\': \'true\', \'KUBECONFIG\': \'/files/.kube/config\', \'UPGRADE_INVALIDATION_STRING\': \'\', \'MYSQL_HOST_PORT\': \'23306\', \'LC_CTYPE\': \'C.UTF-8\', \'AIRFLOW_IMAGE_KUBERNETES\': \'ghcr.io/apache/airflow/main/kubernetes/python3.9\', \'ANSWER\': \'\', \'RUN_TESTS\': \'false\', \'LOAD_EXAMPLES\': \'false\', \'_AIRFLOW_SKIP_DB_TESTS\': \'false\', \'DOWNGRADE_SQLALCHEMY\': \'false\', \'AIRFLOW_INSTALLATION_METHOD\': \'.\', \'REDIS_HOST_PORT\': \'26379\', \'LC_ALL\': \'C.UTF-8\', \'CI_TARGET_REPO\': \'apache/airflow\', \'CI_JOB_ID\': \'0\', \'DATABASE_ISOLATION\': \'false\', \'INSTALL_MYSQL_CLIENT\': \'true\', \'SSH_PORT\': \'12322\', \'PATH\': \'/files/bin/:/opt/airflow/scripts/in_container/bin/:/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/airflow\', \'PYTHON_MAJOR_MINOR_VERSION\': \'3.9\', \'_AIRFLOW_RUN_DB_TESTS_ONLY\': \'false\', \'AIRFLOW__CORE__DATASET_MANAGER_KWARGS_SECRET\': \'dummy_dataset_manager_kwargs\', \'UPGRADE_EAGERLY\': \'--upgrade --resolution highest\', \'CELERY_FLOWER\': \'false\', \'INSTALL_AIRFLOW_WITH_CONSTRAINTS\': \'true\', \'CI\': \'false\', \'PACKAGING_TOOL\': \'\', \'PACKAGING_TOOL_CMD\': \'uv pip\', \'LOAD_DEFAULT_CONNECTIONS\': \'false\', \'FLOWER_HOST_PORT\': \'25555\', \'PIP_NO_CACHE_DIR\': \'true\', \'BASE_BRANCH\': \'main\', \'PYTHON_BASE_IMAGE\': \'python:3.9-slim-bookworm\', \'ENABLED_SYSTEMS\': \'\', \'AIRFLOW__LOGGING__REMOTE_TASK_HANDLER_KWARGS_SECRET\': \'dummy_remote_task_handler_kwargs\', \'AIRFLOW__SMTP__SMTP_PASSWORD_SECRET\': \'dummy_smtp_password_secret\', \'UV_HTTP_TIMEOUT\': \'300\', \'BREEZE\': \'true\', \'DRILL_HOST_PORT\': \'28047\', \'BUILD_ID\': \'0\', \'AIRFLOW__SENTRY__SENTRY_DSN_SECRET\': \'dummy_sentry_dsn\', \'AIRFLOW__CORE__FERNET_KEY\': \'***\', \'POSTGRES_VERSION\': \'12\', \'DEBIAN_FRONTEND\': \'noninteractive\', \'EXCLUDED_PROVIDERS\': \'\', \'UV_CONCURRENT_DOWNLOADS\': \'10\', \'OLDPWD\': \'/opt/airflow\', \'AIRFLOW__SMTP__SMTP_SSL\': \'True\', \'AIRFLOW_SOURCES\': \'/opt/airflow\', \'VERBOSE\': \'false\', \'TERM_PROGRAM\': \'tmux\', \'AIRFLOW__SMTP__SMTP_HOST\': \'smtp.dummy.com\', \'REGENERATE_MISSING_DOCS\': \'false\', \'_\': \'/usr/local/bin/airflow\', \'_AIRFLOW_PARSING_CONTEXT_DAG_ID\': \'os-env-variable\', \'_AIRFLOW_PARSING_CONTEXT_TASK_ID\': \'test_me\', \'AIRFLOW_CTX_DAG_OWNER\': \'airflow\', \'AIRFLOW_CTX_DAG_ID\': \'os-env-variable\', \'AIRFLOW_CTX_TASK_ID\': \'test_me\', \'AIRFLOW_CTX_EXECUTION_DATE\': \'2024-10-16T13:09:12.855444+00:00\', \'AIRFLOW_CTX_TRY_NUMBER\': \'1\', \'AIRFLOW_CTX_DAG_RUN_ID\': \'manual__2024-10-16T13:09:12.855444+00:00\'})\r\n```\r\n\r\nFrom my original list, these aren\'t masked:\r\n```\r\n    ""AIRFLOW__SMTP__SMTP_PORT"",\r\n    ""AIRFLOW__SMTP__SMTP_PASSWORD"",\r\n    ""AIRFLOW__SMTP__SMTP_PASSWORD_SECRET"",\r\n    ""AIRFLOW__SMTP__SMTP_USER"",\r\n    ""AIRFLOW__SMTP__SMTP_SSL"",\r\n    ""AIRFLOW__SMTP__SMTP_HOST"",\r\n    ""AIRFLOW__SENTRY__SENTRY_DSN_SECRET"",\r\n    ""AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_SECRET"",\r\n    ""AIRFLOW__DATABASE__SQL_ALCHEMY_ENGINE_ARGS_SECRET"",\r\n    ""AIRFLOW__CORE__DATASET_MANAGER_KWARGS_SECRET"",\r\n    ""AIRFLOW__LOGGING__REMOTE_TASK_HANDLER_KWARGS_SECRET"",\r\n```\r\n\r\nAs per the comments above, looks like `AIRFLOW__SMTP__SMTP_PORT`, `AIRFLOW__SMTP__SMTP_USER` (removed), `AIRFLOW__SMTP__SMTP_PASSWORD` (removed), arent relevant.\r\n\r\nI think:\r\n - AIRFLOW__SMTP__SMTP_USER\r\n - AIRFLOW__SMTP__SMTP_SSL\r\n - AIRFLOW__SMTP__SMTP_HOST\r\n\r\nAre ok to be unmasked. That leaves us with:\r\n```\r\n    ""AIRFLOW__SENTRY__SENTRY_DSN_SECRET"",\r\n    ""AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_SECRET"",\r\n    ""AIRFLOW__DATABASE__SQL_ALCHEMY_ENGINE_ARGS_SECRET"",\r\n    ""AIRFLOW__CORE__DATASET_MANAGER_KWARGS_SECRET"",\r\n    ""AIRFLOW__LOGGING__REMOTE_TASK_HANDLER_KWARGS_SECRET"",\r\n```\r\n\r\nShould these be masked or its alright to keep them unmasked?', 'created_at': datetime.datetime(2024, 10, 16, 14, 17, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417004619, 'issue_id': 2589082053, 'author': 'ashb', 'body': '> Should these be masked or its alright to keep them unmasked?\r\n\r\nhttps://github.com/apache/airflow/pull/43040#discussion_r1802935540', 'created_at': datetime.datetime(2024, 10, 16, 14, 26, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417030435, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': 'Okay, in that case, this should be ok', 'created_at': datetime.datetime(2024, 10, 16, 14, 35, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417078831, 'issue_id': 2589082053, 'author': 'kaxil', 'body': '> I just pulled in #42951, it doesn\'t seem to fix it for me. I still keep getting\r\n> \r\n> ```\r\n> \r\n>     """"""Manages all providers.""""""\r\n>     \r\n>     from __future__ import annotations\r\n>     \r\n>     import fnmatch\r\n>     import functools\r\n>     import inspect\r\n>     import json\r\n>     import logging\r\n>     import os\r\n>     import sys\r\n>     import traceback\r\n>     import warnings\r\n>     from dataclasses import dataclass\r\n>     from functools import wraps\r\n>     from time import perf_counter\r\n>     from typing import TYPE_CHECKING, Any, Callable, MutableMapping, NamedTuple, TypeVar\r\n>     \r\n>     from packaging.utils import canonicalize_name\r\n>     \r\n>     from airflow.exceptions import AirflowOptionalProviderFeatureException\r\n> >   from airflow.providers.standard.hooks.filesystem import FSHook\r\n> E   ModuleNotFoundError: No module named \'airflow.providers.standard\'\r\n> ```\r\n\r\nFixed in https://github.com/apache/airflow/pull/43082', 'created_at': datetime.datetime(2024, 10, 16, 14, 54, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418447412, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': '@potiuk @ashb added a unit test here. Can you take a look at this when you have some time?', 'created_at': datetime.datetime(2024, 10, 17, 3, 58, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2423619261, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': 'Hey @ashb. Left a comment on your last review, can you please take a look when you have some time?', 'created_at': datetime.datetime(2024, 10, 19, 6, 33, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428256843, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': ""@ashb you are right, it didn't work the last time and I landed at circular imports due to a top level import. \r\nIt works now, pushed the new changes. Still assuming your +1 as I handled your review comments.\r\n\r\n@potiuk / @kaxil could you take a look when you have some time?"", 'created_at': datetime.datetime(2024, 10, 22, 4, 57, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429578330, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': '@ashb does it look good to go? Got a green CI', 'created_at': datetime.datetime(2024, 10, 22, 15, 19, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431448058, 'issue_id': 2589082053, 'author': 'potiuk', 'body': 'Looks like all the comments are resolved and address by @amoghrajesh . LGTM. @kaxil @ashb - are you ok with merging it?', 'created_at': datetime.datetime(2024, 10, 23, 9, 22, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432682783, 'issue_id': 2589082053, 'author': 'ashb', 'body': 'Computer says no\n\n![Screenshot_20241023-164334.png](https://github.com/user-attachments/assets/dae4cb8c-160f-4bb6-bf43-4a7a65cdf0e9)\n\nBut yes, good to merge', 'created_at': datetime.datetime(2024, 10, 23, 15, 44, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2433760877, 'issue_id': 2589082053, 'author': 'kaxil', 'body': 'This change has caused the `@suppress_logs_and_warning` decorator to not work for CLI commands and hence CLI commands now show warnings. Example: https://github.com/apache/airflow/pull/43334', 'created_at': datetime.datetime(2024, 10, 23, 23, 20, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2433772398, 'issue_id': 2589082053, 'author': 'kaxil', 'body': 'Fix here: https://github.com/apache/airflow/pull/43335', 'created_at': datetime.datetime(2024, 10, 23, 23, 27, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2434676317, 'issue_id': 2589082053, 'author': 'saurabhb-dev', 'body': ""@amoghrajesh , shouldn't the list of sensitive_config_values be updated with the list of keys that need to redact ? \r\nLine: https://github.com/amoghrajesh/airflow/blob/840ea3efb9533837e9f36b75fa527a0fbafeb23a/airflow/configuration.py#L121"", 'created_at': datetime.datetime(2024, 10, 24, 8, 51, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2434739027, 'issue_id': 2589082053, 'author': 'potiuk', 'body': '> @amoghrajesh , shouldn\'t the list of sensitive_config_values be updated with the list of keys that need to redact ? Line: https://github.com/amoghrajesh/airflow/blob/840ea3efb9533837e9f36b75fa527a0fbafeb23a/airflow/configuration.py#L121\r\n\r\nNot really @saurabhb-dev , It\'s even better to mask values in this case, rather than keys.\r\n\r\nThe secrets_masker works in two modes:\r\n\r\n* for known structures it can mask sensitive key values (for example if a key in connection is ""password"" - it will mask the value when it prints the structure (when it is aware of the structure and acts on it)\r\n\r\n* but this is impossible when you log messages when the structures or values have been already converted to log string - by the time secrets masker in logger (installed as filter) gets the message, the structure is gone already (converted to string representation) and we are not aware that particular key corresponds to particular value. So our secrets masker has the second mode - where it can mask specific values. It will scan the string for all the values that are registered upfront and mask them if it finds any of them in the string.\r\n\r\nThis is what happens here - we retrieve all the secret config values (whether they come by env vars or by other means) and we add values (i.e. actual secrets) to be masked. This way when any secret is printed anywhere where secrets_masker is used, it will automatically mask it - regardless if it is a structure (secrets_masker checks values of dicts for example) or whether it\'s already converted to string.', 'created_at': datetime.datetime(2024, 10, 24, 9, 17, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461273269, 'issue_id': 2589082053, 'author': 'zachliu', 'body': ""figure i'd ask here before creating a new issue\r\n\r\nhttps://github.com/apache/airflow/blob/c99887ec11ce3e1a43f2794fcf36d27555140f00/airflow/configuration.py#L857-L859\r\n\r\n`self.sensitive_config_values` returns both `('database', 'sql_alchemy_conn')` and `('core', 'sql_alchemy_conn')`\r\n\r\nhence the `self.get()` raises a warning:\r\n\r\n```\r\nairflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name\r\n```\r\n\r\nwhich is a bit confusing since i removed all references to `core.sql_alchemy_conn` long ago"", 'created_at': datetime.datetime(2024, 11, 7, 4, 3, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461342176, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': ""@zachliu we do not return ('database', 'sql_alchemy_conn') as part of self.sensitive_config_values. Here are the sensitive values: https://github.com/amoghrajesh/airflow/blob/840ea3efb9533837e9f36b75fa527a0fbafeb23a/airflow/configuration.py#L122-L129\r\n\r\nThe warning comes from configuration.py#919"", 'created_at': datetime.datetime(2024, 11, 7, 5, 20, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462121649, 'issue_id': 2589082053, 'author': 'zachliu', 'body': ""@amoghrajesh i beg to differ\r\n\r\n1. the warning says `configuration.py:859`\r\n2. i tested with a print statement at these locations:\r\n    * `configuration.py:859`\r\n    * `configuration.py:323`\r\n\r\n\r\ni'm on https://github.com/apache/airflow/tree/2.10.3"", 'created_at': datetime.datetime(2024, 11, 7, 12, 32, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462152630, 'issue_id': 2589082053, 'author': 'zachliu', 'body': ""i think i know what's going on here. somehow https://github.com/apache/airflow/commit/7dea23fd23fa347143fded6979879cf5f58fa132 (https://github.com/apache/airflow/pull/42126) didn't make the cut for 2.10.3, which caused the `self.sensitive_config_values` to return both `('database', 'sql_alchemy_conn')` and `('core', 'sql_alchemy_conn')`"", 'created_at': datetime.datetime(2024, 11, 7, 12, 47, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462476012, 'issue_id': 2589082053, 'author': 'amoghrajesh', 'body': '@zachliu from the PR it doesnt look like it was targetted for 2.10.3. \r\nI will leave a comment however', 'created_at': datetime.datetime(2024, 11, 7, 15, 8, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462766582, 'issue_id': 2589082053, 'author': 'zachliu', 'body': 'I created a new issue to track this: https://github.com/apache/airflow/issues/43794', 'created_at': datetime.datetime(2024, 11, 7, 16, 58, 21, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 15:46:48 UTC): Just adding a unit test, and I think it's ready to go :)

amoghrajesh (Issue Creator) on (2024-10-16 05:09:52 UTC): Struggling with some test related setup. I am running into this as of now:
```
../../tests_common/test_utils/db.py:23: in <module>
    from airflow.models import (
../../airflow/models/__init__.py:78: in __getattr__
    val = import_string(f""{path}.{name}"")
../../airflow/utils/module_loading.py:39: in import_string
    module = import_module(module_path)
/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
../../airflow/models/dag.py:95: in <module>
    from airflow.models.abstractoperator import AbstractOperator, TaskStateChangeCallback
../../airflow/models/abstractoperator.py:33: in <module>
    from airflow.template.templater import Templater
../../airflow/template/templater.py:23: in <module>
    from airflow.io.path import ObjectStoragePath
../../airflow/io/__init__.py:30: in <module>
    from airflow.providers_manager import ProvidersManager
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    """"""Manages all providers.""""""
    
    from __future__ import annotations
    
    import fnmatch
    import functools
    import inspect
    import json
    import logging
    import os
    import sys
    import traceback
    import warnings
    from dataclasses import dataclass
    from functools import wraps
    from time import perf_counter
    from typing import TYPE_CHECKING, Any, Callable, MutableMapping, NamedTuple, TypeVar
    
    from packaging.utils import canonicalize_name
    
    from airflow.exceptions import AirflowOptionalProviderFeatureException
E   ModuleNotFoundError: No module named 'airflow.providers.standard.hooks'
```

I see some discussions around, does anyone have any suggestions for this? I use Pycharm

potiuk on (2024-10-16 11:07:23 UTC): I believe (I have not yet had time to look at it) this requires to use `uv workspace` and the latest `uv` installed - @ashb - are there any instructions for that already somewhere ? 

I guess those should be updated ?

* https://github.com/apache/airflow/blob/main/contributing-docs/07_local_virtualenv.rst
* https://github.com/apache/airflow/blob/main/contributing-docs/quick-start-ide/contributors_quick_start_pycharm.rst
* https://github.com/apache/airflow/blob/main/contributing-docs/quick-start-ide/contributors_quick_start_vscode.rst

potiuk on (2024-10-16 11:09:28 UTC): I think we generally should provide rather comprehensive guide (at least with some links) to our contributors how to setup the venv now (Breeze is covered because it uses workspace installation internally I believe)? Am I right @ashb ?

ashb on (2024-10-16 11:30:26 UTC): Breeze is all set up yes. UV workspace isn't 100% required yet (though I don't think anyone tested running tests from inside pycharm), but for pycharm to find imports you need to set up some paths as the right kind of folder in the UI 

I'm not a pycharm user, but @kaxil @dstandish can provide some insight.

ashb on (2024-10-16 11:41:07 UTC): https://github.com/apache/airflow/pull/42951 should help Pycharm too. Remaining ""manual"" steps as pycharm user are:

1. We marked `providers/src`  as Source Folder and `providers/src/airflow` as Namespace package.
2. Verify that there is nothing on old provider path: `rm -rf airflow/providers`  :slightly_smiling_face:
3. Trigger Rescan Project Indexes from **File** -> **Repair IDE**.

amoghrajesh (Issue Creator) on (2024-10-16 12:18:09 UTC): I just pulled in https://github.com/apache/airflow/pull/42951, it doesn't seem to fix it for me. I still keep getting
```

    """"""Manages all providers.""""""
    
    from __future__ import annotations
    
    import fnmatch
    import functools
    import inspect
    import json
    import logging
    import os
    import sys
    import traceback
    import warnings
    from dataclasses import dataclass
    from functools import wraps
    from time import perf_counter
    from typing import TYPE_CHECKING, Any, Callable, MutableMapping, NamedTuple, TypeVar
    
    from packaging.utils import canonicalize_name
    
    from airflow.exceptions import AirflowOptionalProviderFeatureException
E   ModuleNotFoundError: No module named 'airflow.providers.standard'
```

dstandish on (2024-10-16 13:31:54 UTC): Anything in particular you wanted me to look at?

amoghrajesh (Issue Creator) on (2024-10-16 14:17:58 UTC): @ashb @potiuk @kaxil I changed the logic to incorporate what was suggested above. Now I am able to get this result:
```
[2024-10-16, 18:39:13 IST] {logging_mixin.py:190} INFO - environ({'SHELL': '/bin/bash', 'AIRFLOW__SMTP__SMTP_PORT': '587', 'VERSION_SUFFIX_FOR_PYPI': '', 'NUM_RUNS': '', 'AIRFLOW__CELERY__RESULT_BACKEND': 'db+***', 'AIRFLOW_AUTH_MANAGER_CREDENTIAL_DIRECTORY': '/files', 'USE_AIRFLOW_VERSION': '', 'AIRFLOW__SMTP__SMTP_PASSWORD': 'dummy_smtp_password', 'AIRFLOW__SMTP__SMTP_USER': 'dummy_user', 'DB_RESET': 'false', 'TERM_PROGRAM_VERSION': '3.3a', 'CASS_DRIVER_NO_CYTHON': '1', 'DOCKER_IS_ROOTLESS': 'false', 'TMUX': '/root/.tmux/tmp/tmux-0/default,96,0', 'DEPENDENCIES_EPOCH_NUMBER': '11', 'HOSTNAME': '22a3f86e4c95', 'COLOR_RESET': '\x1b[0m', 'AIRFLOW__WEBSERVER__SECRET_KEY_SECRET': '***_secret', 'PYTHON_VERSION': '3.9.20', 'LANGUAGE': 'C.UTF-8', 'HOST_USER_ID': '20', 'FASTAPI_API_HOST_PORT': '29091', 'USE_PACKAGES_FROM_DIST': 'false', 'COLLECT_ONLY': 'false', 'PACKAGE_FORMAT': 'wheel', 'AIRFLOW__CORE__PLUGINS_FOLDER': '/files/plugins', 'AIRFLOW_CI_BUILD_EPOCH': '10', 'CHICKEN_EGG_PROVIDERS': '', 'MSSQL_HOST_PORT': '21433', 'SQLALCHEMY_WARN_20': 'true', 'CELERY_BROKER_URLS_MAP': ""{'rabbitmq': 'amqp://guest:guest@rabbitmq:5672', 'redis': 'redis://redis:6379/0'}"", 'AIRFLOW_CONSTRAINTS_LOCATION': '', 'DEV_MODE': 'false', 'AIRFLOW__CORE__DAGS_FOLDER': '/files/dags', 'COLOR_RED': '\x1b[31m', 'RUN_SYSTEM_TESTS': 'false', 'COLOR_BLUE': '\x1b[34m', 'AIRFLOW_ENABLE_AIP_44': 'true', 'AIRFLOW_CI_IMAGE': 'ghcr.io/apache/airflow/main/ci/python3.9', 'TEST_TYPE': '', 'ADDITIONAL_PATH': '~/.local/bin', 'EAGER_UPGRADE_ADDITIONAL_REQUIREMENTS': '', 'PROVIDERS_SKIP_CONSTRAINTS': 'false', 'BREEZE_INIT_COMMAND': '', 'PWD': '/opt/airflow', 'AIRFLOW_SKIP_CONSTRAINTS': 'false', 'AIRFLOW__CELERY__BROKER_URL': 'redis://redis:6379/0', 'REMOVE_ARM_PACKAGES': 'false', 'AIRFLOW_VERSION': '3.0.0.dev0', 'ENABLE_COVERAGE': 'false', 'VERBOSE_COMMANDS': 'false', 'AIRFLOW__CORE__LOAD_EXAMPLES': 'false', 'GITHUB_ACTIONS': 'false', 'INSTALL_MSSQL_CLIENT': 'true', 'CASS_DRIVER_BUILD_CONCURRENCY': '8', 'CI_EVENT_TYPE': 'pull_request', 'UPGRADE_IF_NEEDED': '--upgrade', 'INSTALL_MYSQL_CLIENT_TYPE': 'mariadb', 'BACKEND': 'mysql', 'CI_TARGET_BRANCH': 'main', 'PROVIDERS_CONSTRAINTS_MODE': 'constraints-source-providers', 'GUNICORN_CMD_ARGS': '--worker-tmp-dir /dev/shm/', 'AIRFLOW_EXTRAS': '', 'LD_PRELOAD': '/usr/lib/aarch64-linux-gnu/libstdc++.so.6', 'PIP_PROGRESS_BAR': 'on', 'AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_SECRET': 'dummy_sql_alchemy_conn', 'HOME': '/root', 'QUIET': 'false', 'UV_NO_CACHE': 'true', 'LANG': 'C.UTF-8', 'SUSPENDED_PROVIDERS_FOLDERS': '', 'HELM_TEST_PACKAGE': '', 'TMUX_TMPDIR': '/root/.tmux/tmp', 'SQLITE_URL': 'sqlite:////root/airflow/sqlite/airflow.db', 'ISSUE_ID': '', 'AIRFLOW_HOME': '/root/airflow', 'MYSQL_VERSION': '8.0', 'AIRFLOW_BREEZE_CONFIG_DIR': '/files/airflow-breeze-config', 'POSTGRES_HOST_PORT': '25433', 'EXTRA_UNINSTALL_FLAGS': '--python /usr/local/bin/python', 'AIRFLOW_VERSION_SPECIFICATION': '', 'GPG_KEY': 'E3FF2839C048B25C084DEBE9B26995E310250568', 'AIRFLOW__DATABASE__SQL_ALCHEMY_CONN': '***', 'AIRFLOW_USE_UV': 'true', 'AIRFLOW_PRE_CACHED_PIP_PACKAGES': 'true', 'ADDITIONAL_DEV_APT_DEPS': 'bash-completion dumb-init git graphviz krb5-user less libenchant-2-2 libgcc-11-dev libgeos-dev libpq-dev net-tools netcat-openbsd openssh-server postgresql-client software-properties-common rsync tmux unzip vim xxd', 'COLOR_YELLOW': '\x1b[33m', 'ONLY_MIN_VERSION_UPDATE': 'false', 'AIRFLOW__CELERY__WORKER_CONCURRENCY': '8', 'STANDALONE_DAG_PROCESSOR': 'false', 'AIRFLOW__CORE__EXECUTOR': 'LocalExecutor', 'INSTALL_SELECTED_PROVIDERS': '', 'USE_XDIST': 'false', 'COMMIT_SHA': 'c03ccfc0716fdbf88eb778c920767b4d3953ac5b', 'CONSTRAINTS_GITHUB_REPOSITORY': 'apache/airflow', 'AIRFLOW__DATABASE__SQL_ALCHEMY_ENGINE_ARGS_SECRET': 'dummy_sql_engine_args', 'EXTRA_INSTALL_FLAGS': '--python /usr/local/bin/python', 'AIRFLOW_CI_IMAGE_WITH_TAG': 'ghcr.io/apache/airflow/main/ci/python3.9:latest', 'SKIP_SSH_SETUP': 'false', 'TMUX_SESSION': 'Airflow', 'AIRFLOW_REPO': 'apache/airflow', 'DEV_APT_COMMAND': '', 'AIRFLOW__WEBSERVER__SECRET_KEY': '***', 'AIRFLOW_PIP_VERSION': '24.2', 'ADDITIONAL_PIP_INSTALL_FLAGS': '', 'SKIP_ENVIRONMENT_INITIALIZATION': 'false', 'ADDITIONAL_DEV_APT_COMMAND': '', 'AIRFLOW_ENV': 'development', 'START_AIRFLOW': 'true', 'COLOR_GREEN': '\x1b[32m', 'AIRFLOW_BRANCH': 'main', 'CLEAN_AIRFLOW_INSTALLATION': 'false', 'FORCE_LOWEST_DEPENDENCIES': 'false', 'AIRFLOW__CORE__INTERNAL_API_SECRET_KEY_SECRET': '***_secret', 'HOST_GROUP_ID': '20', 'DEFAULT_BRANCH': 'main', 'INIT_SCRIPT_FILE': 'init.sh', 'AIRFLOW_CONSTRAINTS_MODE': 'constraints-source-providers', 'PYTHONPATH': '/opt/airflow', 'TERM': 'tmux-256color', 'UPGRADE_BOTO': 'false', 'DOWNGRADE_PENDULUM': 'false', 'USER': 'root', 'HOST_OS': 'darwin', 'USE_UV': 'true', 'TMUX_PANE': '%1', 'WEBSERVER_HOST_PORT': '28080', 'AIRFLOW_UV_VERSION': '0.4.22', 'AIRFLOW__CORE__INTERNAL_API_SECRET_KEY': '***', 'INSTALL_POSTGRES_CLIENT': 'true', 'COMPOSE_FILE': '/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/base.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/docker-socket.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/backend-mysql.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/backend-mysql-port.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/files.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/base-ports.yml:/Users/adesai/Documents/OSS/airflow-repos/airflow/scripts/ci/docker-compose/local.yml', 'SHLVL': '2', 'AIRFLOW_CONSTRAINTS_REFERENCE': 'constraints-main', 'DEFAULT_CONSTRAINTS_BRANCH': 'constraints-main', 'FILES_DIR': '/files', 'CI_BUILD_ID': '0', 'INSTALL_AIRFLOW_VERSION': '', 'LC_MESSAGES': 'C.UTF-8', 'SYSTEM_TESTS_ENV_ID': '', 'MOUNT_SOURCES': 'selected', 'PYTHONDONTWRITEBYTECODE': 'true', 'KUBECONFIG': '/files/.kube/config', 'UPGRADE_INVALIDATION_STRING': '', 'MYSQL_HOST_PORT': '23306', 'LC_CTYPE': 'C.UTF-8', 'AIRFLOW_IMAGE_KUBERNETES': 'ghcr.io/apache/airflow/main/kubernetes/python3.9', 'ANSWER': '', 'RUN_TESTS': 'false', 'LOAD_EXAMPLES': 'false', '_AIRFLOW_SKIP_DB_TESTS': 'false', 'DOWNGRADE_SQLALCHEMY': 'false', 'AIRFLOW_INSTALLATION_METHOD': '.', 'REDIS_HOST_PORT': '26379', 'LC_ALL': 'C.UTF-8', 'CI_TARGET_REPO': 'apache/airflow', 'CI_JOB_ID': '0', 'DATABASE_ISOLATION': 'false', 'INSTALL_MYSQL_CLIENT': 'true', 'SSH_PORT': '12322', 'PATH': '/files/bin/:/opt/airflow/scripts/in_container/bin/:/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/airflow', 'PYTHON_MAJOR_MINOR_VERSION': '3.9', '_AIRFLOW_RUN_DB_TESTS_ONLY': 'false', 'AIRFLOW__CORE__DATASET_MANAGER_KWARGS_SECRET': 'dummy_dataset_manager_kwargs', 'UPGRADE_EAGERLY': '--upgrade --resolution highest', 'CELERY_FLOWER': 'false', 'INSTALL_AIRFLOW_WITH_CONSTRAINTS': 'true', 'CI': 'false', 'PACKAGING_TOOL': '', 'PACKAGING_TOOL_CMD': 'uv pip', 'LOAD_DEFAULT_CONNECTIONS': 'false', 'FLOWER_HOST_PORT': '25555', 'PIP_NO_CACHE_DIR': 'true', 'BASE_BRANCH': 'main', 'PYTHON_BASE_IMAGE': 'python:3.9-slim-bookworm', 'ENABLED_SYSTEMS': '', 'AIRFLOW__LOGGING__REMOTE_TASK_HANDLER_KWARGS_SECRET': 'dummy_remote_task_handler_kwargs', 'AIRFLOW__SMTP__SMTP_PASSWORD_SECRET': 'dummy_smtp_password_secret', 'UV_HTTP_TIMEOUT': '300', 'BREEZE': 'true', 'DRILL_HOST_PORT': '28047', 'BUILD_ID': '0', 'AIRFLOW__SENTRY__SENTRY_DSN_SECRET': 'dummy_sentry_dsn', 'AIRFLOW__CORE__FERNET_KEY': '***', 'POSTGRES_VERSION': '12', 'DEBIAN_FRONTEND': 'noninteractive', 'EXCLUDED_PROVIDERS': '', 'UV_CONCURRENT_DOWNLOADS': '10', 'OLDPWD': '/opt/airflow', 'AIRFLOW__SMTP__SMTP_SSL': 'True', 'AIRFLOW_SOURCES': '/opt/airflow', 'VERBOSE': 'false', 'TERM_PROGRAM': 'tmux', 'AIRFLOW__SMTP__SMTP_HOST': 'smtp.dummy.com', 'REGENERATE_MISSING_DOCS': 'false', '_': '/usr/local/bin/airflow', '_AIRFLOW_PARSING_CONTEXT_DAG_ID': 'os-env-variable', '_AIRFLOW_PARSING_CONTEXT_TASK_ID': 'test_me', 'AIRFLOW_CTX_DAG_OWNER': 'airflow', 'AIRFLOW_CTX_DAG_ID': 'os-env-variable', 'AIRFLOW_CTX_TASK_ID': 'test_me', 'AIRFLOW_CTX_EXECUTION_DATE': '2024-10-16T13:09:12.855444+00:00', 'AIRFLOW_CTX_TRY_NUMBER': '1', 'AIRFLOW_CTX_DAG_RUN_ID': 'manual__2024-10-16T13:09:12.855444+00:00'})
```

From my original list, these aren't masked:
```
    ""AIRFLOW__SMTP__SMTP_PORT"",
    ""AIRFLOW__SMTP__SMTP_PASSWORD"",
    ""AIRFLOW__SMTP__SMTP_PASSWORD_SECRET"",
    ""AIRFLOW__SMTP__SMTP_USER"",
    ""AIRFLOW__SMTP__SMTP_SSL"",
    ""AIRFLOW__SMTP__SMTP_HOST"",
    ""AIRFLOW__SENTRY__SENTRY_DSN_SECRET"",
    ""AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_SECRET"",
    ""AIRFLOW__DATABASE__SQL_ALCHEMY_ENGINE_ARGS_SECRET"",
    ""AIRFLOW__CORE__DATASET_MANAGER_KWARGS_SECRET"",
    ""AIRFLOW__LOGGING__REMOTE_TASK_HANDLER_KWARGS_SECRET"",
```

As per the comments above, looks like `AIRFLOW__SMTP__SMTP_PORT`, `AIRFLOW__SMTP__SMTP_USER` (removed), `AIRFLOW__SMTP__SMTP_PASSWORD` (removed), arent relevant.

I think:
 - AIRFLOW__SMTP__SMTP_USER
 - AIRFLOW__SMTP__SMTP_SSL
 - AIRFLOW__SMTP__SMTP_HOST

Are ok to be unmasked. That leaves us with:
```
    ""AIRFLOW__SENTRY__SENTRY_DSN_SECRET"",
    ""AIRFLOW__DATABASE__SQL_ALCHEMY_CONN_SECRET"",
    ""AIRFLOW__DATABASE__SQL_ALCHEMY_ENGINE_ARGS_SECRET"",
    ""AIRFLOW__CORE__DATASET_MANAGER_KWARGS_SECRET"",
    ""AIRFLOW__LOGGING__REMOTE_TASK_HANDLER_KWARGS_SECRET"",
```

Should these be masked or its alright to keep them unmasked?

ashb on (2024-10-16 14:26:11 UTC): https://github.com/apache/airflow/pull/43040#discussion_r1802935540

amoghrajesh (Issue Creator) on (2024-10-16 14:35:43 UTC): Okay, in that case, this should be ok

kaxil on (2024-10-16 14:54:23 UTC): Fixed in https://github.com/apache/airflow/pull/43082

amoghrajesh (Issue Creator) on (2024-10-17 03:58:06 UTC): @potiuk @ashb added a unit test here. Can you take a look at this when you have some time?

amoghrajesh (Issue Creator) on (2024-10-19 06:33:11 UTC): Hey @ashb. Left a comment on your last review, can you please take a look when you have some time?

amoghrajesh (Issue Creator) on (2024-10-22 04:57:42 UTC): @ashb you are right, it didn't work the last time and I landed at circular imports due to a top level import. 
It works now, pushed the new changes. Still assuming your +1 as I handled your review comments.

@potiuk / @kaxil could you take a look when you have some time?

amoghrajesh (Issue Creator) on (2024-10-22 15:19:56 UTC): @ashb does it look good to go? Got a green CI

potiuk on (2024-10-23 09:22:23 UTC): Looks like all the comments are resolved and address by @amoghrajesh . LGTM. @kaxil @ashb - are you ok with merging it?

ashb on (2024-10-23 15:44:14 UTC): Computer says no

![Screenshot_20241023-164334.png](https://github.com/user-attachments/assets/dae4cb8c-160f-4bb6-bf43-4a7a65cdf0e9)

But yes, good to merge

kaxil on (2024-10-23 23:20:08 UTC): This change has caused the `@suppress_logs_and_warning` decorator to not work for CLI commands and hence CLI commands now show warnings. Example: https://github.com/apache/airflow/pull/43334

kaxil on (2024-10-23 23:27:30 UTC): Fix here: https://github.com/apache/airflow/pull/43335

saurabhb-dev on (2024-10-24 08:51:09 UTC): @amoghrajesh , shouldn't the list of sensitive_config_values be updated with the list of keys that need to redact ? 
Line: https://github.com/amoghrajesh/airflow/blob/840ea3efb9533837e9f36b75fa527a0fbafeb23a/airflow/configuration.py#L121

potiuk on (2024-10-24 09:17:56 UTC): Not really @saurabhb-dev , It's even better to mask values in this case, rather than keys.

The secrets_masker works in two modes:

* for known structures it can mask sensitive key values (for example if a key in connection is ""password"" - it will mask the value when it prints the structure (when it is aware of the structure and acts on it)

* but this is impossible when you log messages when the structures or values have been already converted to log string - by the time secrets masker in logger (installed as filter) gets the message, the structure is gone already (converted to string representation) and we are not aware that particular key corresponds to particular value. So our secrets masker has the second mode - where it can mask specific values. It will scan the string for all the values that are registered upfront and mask them if it finds any of them in the string.

This is what happens here - we retrieve all the secret config values (whether they come by env vars or by other means) and we add values (i.e. actual secrets) to be masked. This way when any secret is printed anywhere where secrets_masker is used, it will automatically mask it - regardless if it is a structure (secrets_masker checks values of dicts for example) or whether it's already converted to string.

zachliu on (2024-11-07 04:03:33 UTC): figure i'd ask here before creating a new issue

https://github.com/apache/airflow/blob/c99887ec11ce3e1a43f2794fcf36d27555140f00/airflow/configuration.py#L857-L859

`self.sensitive_config_values` returns both `('database', 'sql_alchemy_conn')` and `('core', 'sql_alchemy_conn')`

hence the `self.get()` raises a warning:

```
airflow/configuration.py:859 FutureWarning: section/key [core/sql_alchemy_conn] has been deprecated, you should use[database/sql_alchemy_conn] instead. Please update your `conf.get*` call to use the new name
```

which is a bit confusing since i removed all references to `core.sql_alchemy_conn` long ago

amoghrajesh (Issue Creator) on (2024-11-07 05:20:33 UTC): @zachliu we do not return ('database', 'sql_alchemy_conn') as part of self.sensitive_config_values. Here are the sensitive values: https://github.com/amoghrajesh/airflow/blob/840ea3efb9533837e9f36b75fa527a0fbafeb23a/airflow/configuration.py#L122-L129

The warning comes from configuration.py#919

zachliu on (2024-11-07 12:32:06 UTC): @amoghrajesh i beg to differ

1. the warning says `configuration.py:859`
2. i tested with a print statement at these locations:
    * `configuration.py:859`
    * `configuration.py:323`


i'm on https://github.com/apache/airflow/tree/2.10.3

zachliu on (2024-11-07 12:47:01 UTC): i think i know what's going on here. somehow https://github.com/apache/airflow/commit/7dea23fd23fa347143fded6979879cf5f58fa132 (https://github.com/apache/airflow/pull/42126) didn't make the cut for 2.10.3, which caused the `self.sensitive_config_values` to return both `('database', 'sql_alchemy_conn')` and `('core', 'sql_alchemy_conn')`

amoghrajesh (Issue Creator) on (2024-11-07 15:08:28 UTC): @zachliu from the PR it doesnt look like it was targetted for 2.10.3. 
I will leave a comment however

zachliu on (2024-11-07 16:58:21 UTC): I created a new issue to track this: https://github.com/apache/airflow/issues/43794

"
2588908117,pull_request,closed,,require 1.2.1 common.compat for openlineage provider,"https://github.com/apache/airflow/pull/41348 introduced breaking change for OpenLineage provider (importing `from airflow.providers.common.compat.openlineage.utils.utils import translate_airflow_asset`) that was added in the same PR in common.compat provider, but without bumping the required version in OL provider.  ",mobuchowski,2024-10-15 14:09:43+00:00,[],2024-10-15 21:40:51+00:00,2024-10-15 16:48:17+00:00,https://github.com/apache/airflow/pull/43039,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2414526894, 'issue_id': 2588908117, 'author': 'mobuchowski', 'body': 'Failing tests are irrelevant (azure).', 'created_at': datetime.datetime(2024, 10, 15, 16, 48, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415216265, 'issue_id': 2588908117, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 10, 15, 21, 40, 50, tzinfo=datetime.timezone.utc)}]","mobuchowski (Issue Creator) on (2024-10-15 16:48:13 UTC): Failing tests are irrelevant (azure).

potiuk on (2024-10-15 21:40:50 UTC): Nice!

"
2588824775,pull_request,closed,,Add copy_object functionality for wasbhook,"Fixes: #42497 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-10-15 13:42:13+00:00,[],2024-11-01 20:30:03+00:00,2024-11-01 20:30:03+00:00,https://github.com/apache/airflow/pull/43037,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2588778718,pull_request,closed,,Docs: Change CustomSecurityManager method name,"Hi, I modified the webserver-authentication docs.
Customer Security Manager method name changed correctly.",kgw7401,2024-10-15 13:25:31+00:00,[],2024-10-16 00:32:51+00:00,2024-10-15 14:16:08+00:00,https://github.com/apache/airflow/pull/43034,"[('area:providers', ''), ('kind:documentation', ''), ('provider:fab', '')]",[],
2588737636,pull_request,closed,,Bump `uv` to `0.4.21` in other places,"Follow-up of https://github.com/apache/airflow/pull/43032: Bumps `uv` to `0.4.21` (https://pypi.org/project/uv/0.4.21/)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-15 13:10:44+00:00,[],2024-10-15 19:06:20+00:00,2024-10-15 16:26:27+00:00,https://github.com/apache/airflow/pull/43033,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2413902026, 'issue_id': 2588737636, 'author': 'potiuk', 'body': 'Closing in favour of #43032', 'created_at': datetime.datetime(2024, 10, 15, 13, 21, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414176803, 'issue_id': 2588737636, 'author': 'potiuk', 'body': 'Shit. I was supposed to close mine :)', 'created_at': datetime.datetime(2024, 10, 15, 14, 57, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414178278, 'issue_id': 2588737636, 'author': 'potiuk', 'body': 'Can you reopen @kaxil  ?', 'created_at': datetime.datetime(2024, 10, 15, 14, 57, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414180019, 'issue_id': 2588737636, 'author': 'potiuk', 'body': 'Or apply just the `pre-commit + update .py files"" after I merge mine ...', 'created_at': datetime.datetime(2024, 10, 15, 14, 58, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414181159, 'issue_id': 2588737636, 'author': 'potiuk', 'body': 'Sorry for that ... too many things at the same time ...', 'created_at': datetime.datetime(2024, 10, 15, 14, 58, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414186243, 'issue_id': 2588737636, 'author': 'kaxil', 'body': 'Done', 'created_at': datetime.datetime(2024, 10, 15, 15, 0, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414189793, 'issue_id': 2588737636, 'author': 'kaxil', 'body': '@potiuk updated PR title', 'created_at': datetime.datetime(2024, 10, 15, 15, 1, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414565365, 'issue_id': 2588737636, 'author': 'potiuk', 'body': 'Cool. Now we both scored a PR ;)', 'created_at': datetime.datetime(2024, 10, 15, 17, 6, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414800031, 'issue_id': 2588737636, 'author': 'kaxil', 'body': '> Cool. Now we both scored a PR ;)\r\n\r\n🤝', 'created_at': datetime.datetime(2024, 10, 15, 19, 6, 19, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 13:21:12 UTC): Closing in favour of #43032

potiuk on (2024-10-15 14:57:27 UTC): Shit. I was supposed to close mine :)

potiuk on (2024-10-15 14:57:58 UTC): Can you reopen @kaxil  ?

potiuk on (2024-10-15 14:58:37 UTC): Or apply just the `pre-commit + update .py files"" after I merge mine ...

potiuk on (2024-10-15 14:58:52 UTC): Sorry for that ... too many things at the same time ...

kaxil (Issue Creator) on (2024-10-15 15:00:40 UTC): Done

kaxil (Issue Creator) on (2024-10-15 15:01:53 UTC): @potiuk updated PR title

potiuk on (2024-10-15 17:06:25 UTC): Cool. Now we both scored a PR ;)

kaxil (Issue Creator) on (2024-10-15 19:06:19 UTC): 🤝

"
2588723366,pull_request,closed,,Update to 0.4.21 of UV,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-15 13:05:20+00:00,[],2024-10-15 14:59:04+00:00,2024-10-15 14:59:02+00:00,https://github.com/apache/airflow/pull/43032,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2413878351, 'issue_id': 2588723366, 'author': 'kaxil', 'body': 'https://github.com/apache/airflow/pull/43033 :D -- I just created too, the change I have additionally is `dev/breeze/src/airflow_breeze/commands/release_management_commands.py`', 'created_at': datetime.datetime(2024, 10, 15, 13, 11, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413900731, 'issue_id': 2588723366, 'author': 'potiuk', 'body': 'AAAAAAH.. We should .... automate this as well .... Want to take care of it :)', 'created_at': datetime.datetime(2024, 10, 15, 13, 20, 38, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-10-15 13:11:32 UTC): https://github.com/apache/airflow/pull/43033 :D -- I just created too, the change I have additionally is `dev/breeze/src/airflow_breeze/commands/release_management_commands.py`

potiuk (Issue Creator) on (2024-10-15 13:20:38 UTC): AAAAAAH.. We should .... automate this as well .... Want to take care of it :)

"
2588303578,pull_request,closed,,increase backoff_factor and add try/catch in k8s tests (#42940),"
Cherry picked from https://github.com/apache/airflow/commit/15df46590ea13c2e8b71324fad0b77da8eaa7167
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-15 10:15:09+00:00,[],2024-11-02 13:05:05+00:00,2024-10-15 11:44:35+00:00,https://github.com/apache/airflow/pull/43030,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2413481344, 'issue_id': 2588303578, 'author': 'gopidesupavan', 'body': 'This is the last backport for recent improvements on k8s tests :)', 'created_at': datetime.datetime(2024, 10, 15, 10, 16, 20, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-15 10:16:20 UTC): This is the last backport for recent improvements on k8s tests :)

"
2588214454,pull_request,closed,,Clarifying PLUGINS_FOLDER permissions by DAG authors (#43022),"(cherry picked from commit c471c31111958f0a4dde775f559d5c606f3149a8)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-15 09:42:45+00:00,[],2024-10-23 09:02:37+00:00,2024-10-16 17:47:50+00:00,https://github.com/apache/airflow/pull/43029,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2413404132, 'issue_id': 2588214454, 'author': 'potiuk', 'body': 'Backport of #43022', 'created_at': datetime.datetime(2024, 10, 15, 9, 43, 17, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-15 09:43:17 UTC): Backport of #43022

"
2588128726,pull_request,closed,,vertex ai training operators: add display_name to rendered fields,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
closes: #43027 
-->



<!-- Please keep an empty line above the dashes. -->
---
Add display_name and model_display_name to list of rendered fields for Vertex AI operators. 

",WSHoekstra,2024-10-15 09:08:45+00:00,[],2024-10-17 07:43:59+00:00,2024-10-17 07:43:55+00:00,https://github.com/apache/airflow/pull/43028,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2413324622, 'issue_id': 2588128726, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 9, 8, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415192229, 'issue_id': 2588128726, 'author': 'potiuk', 'body': 'For the future - you can add ""Closes: #ISSUE_NUMBER"" to the commit message and it will automatically link the issue you created and it will close it - saves a lot of duplicated effort.\r\n\r\nAlso - for such things we do not **really** need an issue - just open PR and add description what it does - we do not really like overhead and unnecessary `beauracracy` 😄', 'created_at': datetime.datetime(2024, 10, 15, 21, 22, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418803180, 'issue_id': 2588128726, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 17, 7, 43, 58, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 09:08:50 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-15 21:22:50 UTC): For the future - you can add ""Closes: #ISSUE_NUMBER"" to the commit message and it will automatically link the issue you created and it will close it - saves a lot of duplicated effort.

Also - for such things we do not **really** need an issue - just open PR and add description what it does - we do not really like overhead and unnecessary `beauracracy` 😄

boring-cyborg[bot] on (2024-10-17 07:43:58 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2587877151,pull_request,closed,,update k8s tests urllib3 retry config status_forcelist and allowed_me…,"…thods (#42871)

cherry picked from https://github.com/apache/airflow/commit/8a4e7bda845bab4dfe33af0a8b0c9e6fcf0da9f3

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-15 07:22:08+00:00,[],2024-11-02 13:05:08+00:00,2024-10-15 09:25:03+00:00,https://github.com/apache/airflow/pull/43026,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2587863851,pull_request,closed,,Improve startup of K8S tests (#42721),"* loop api request in k8s tests until dag available

* remov un used method

cherry picked from https://github.com/apache/airflow/commit/dedfe9c365c9edb969ca1d780c565fdc39996715

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-15 07:14:58+00:00,[],2024-11-02 13:05:12+00:00,2024-10-15 09:25:26+00:00,https://github.com/apache/airflow/pull/43025,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2587820712,pull_request,closed,,fix(providers/mongo): prevent applying lower method on bool field,"Fixes #42930


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",josix,2024-10-15 06:53:49+00:00,[],2024-11-02 20:58:16+00:00,2024-10-16 18:57:49+00:00,https://github.com/apache/airflow/pull/43024,"[('area:providers', ''), ('provider:mongo', '')]","[{'comment_id': 2415187067, 'issue_id': 2587820712, 'author': 'potiuk', 'body': 'Any chance for a unit test to prevent regression?', 'created_at': datetime.datetime(2024, 10, 15, 21, 19, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416158164, 'issue_id': 2587820712, 'author': 'josix', 'body': ""Sure, I've added one to test if the value is correct boolean, PTAL thanks!"", 'created_at': datetime.datetime(2024, 10, 16, 8, 59, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2453125978, 'issue_id': 2587820712, 'author': 'topherinternational', 'body': 'Nice catch @josix - I think the root cause here was the hook consuming the extra params from the connection was never tested 😅 .', 'created_at': datetime.datetime(2024, 11, 2, 20, 58, 14, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 21:19:07 UTC): Any chance for a unit test to prevent regression?

josix (Issue Creator) on (2024-10-16 08:59:29 UTC): Sure, I've added one to test if the value is correct boolean, PTAL thanks!

topherinternational on (2024-11-02 20:58:14 UTC): Nice catch @josix - I think the root cause here was the hook consuming the extra params from the connection was never tested 😅 .

"
2587813876,pull_request,closed,,remove redundant scheduler_lock column from dag table,"closes: https://github.com/apache/airflow/issues/42258

Remove all scheduler_lock references from the codebase.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",prabhusneha,2024-10-15 06:50:17+00:00,[],2024-10-29 06:41:24+00:00,2024-10-28 15:08:55+00:00,https://github.com/apache/airflow/pull/43023,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2413036043, 'issue_id': 2587813876, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 15, 6, 50, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413091922, 'issue_id': 2587813876, 'author': 'ephraimbuddy', 'body': 'You have some conflicts. This seems like a breaking change even though the column is not used', 'created_at': datetime.datetime(2024, 10, 15, 7, 21, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418946412, 'issue_id': 2587813876, 'author': 'pierrejeambrun', 'body': 'Assigning ~~label~~ labels and restarting the CI.', 'created_at': datetime.datetime(2024, 10, 17, 8, 51, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2425591550, 'issue_id': 2587813876, 'author': 'uranusjr', 'body': 'LGTM. When was this first added, by who, for what? (We can at least answer that with a `git blame`)', 'created_at': datetime.datetime(2024, 10, 21, 5, 0, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426114470, 'issue_id': 2587813876, 'author': 'ashb', 'body': ""This predates airflow 2, and I don't think was ever really used for much"", 'created_at': datetime.datetime(2024, 10, 21, 9, 26, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441860157, 'issue_id': 2587813876, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 28, 15, 8, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441861665, 'issue_id': 2587813876, 'author': 'ephraimbuddy', 'body': 'Congrats on your first PR @prabhusneha 🎉🎉', 'created_at': datetime.datetime(2024, 10, 28, 15, 9, 31, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-15 06:50:21 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

ephraimbuddy on (2024-10-15 07:21:54 UTC): You have some conflicts. This seems like a breaking change even though the column is not used

pierrejeambrun on (2024-10-17 08:51:41 UTC): Assigning ~~label~~ labels and restarting the CI.

uranusjr on (2024-10-21 05:00:59 UTC): LGTM. When was this first added, by who, for what? (We can at least answer that with a `git blame`)

ashb on (2024-10-21 09:26:52 UTC): This predates airflow 2, and I don't think was ever really used for much

boring-cyborg[bot] on (2024-10-28 15:08:58 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

ephraimbuddy on (2024-10-28 15:09:31 UTC): Congrats on your first PR @prabhusneha 🎉🎉

"
2587637249,pull_request,closed,,Clarifying PLUGINS_FOLDER permissions by DAG authors,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Clarifying some things in the security model about PLUGINS_FOLDER write permissions by dag authors

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-10-15 04:54:56+00:00,[],2024-10-23 09:03:01+00:00,2024-10-15 09:40:52+00:00,https://github.com/apache/airflow/pull/43022,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2413406165, 'issue_id': 2587637249, 'author': 'potiuk', 'body': 'Backported in #43029', 'created_at': datetime.datetime(2024, 10, 15, 9, 43, 59, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 09:43:59 UTC): Backported in #43029

"
2587609711,pull_request,closed,,Add upperbound to microsoft-kiota-abstractions,"Currently, [MyPy check is failing](https://github.com/apache/airflow/actions/runs/11338780479/job/31532784299?pr=43020#step:6:122) as we don't have a pin on `microsoft-kiota-abstractions`.

```
roviders/src/airflow/providers/microsoft/azure/hooks/msgraph.py:51: error:
Module ""kiota_abstractions.request_information"" has no attribute ""QueryParams"";
maybe ""QueryParameters""?  [attr-defined]
        from kiota_abstractions.request_information import QueryParams
        ^
providers/src/airflow/providers/microsoft/azure/hooks/msgraph.py:65: error:
""NativeResponseType"" has no attribute ""json""  [attr-defined]
                return response.json()
                       ^~~~~~~~~~~~~
providers/src/airflow/providers/microsoft/azure/hooks/msgraph.py:66: error:
""NativeResponseType"" has no attribute ""content""  [attr-defined]
            content = response.content
                      ^~~~~~~~~~~~~~~~
providers/src/airflow/providers/microsoft/azure/hooks/msgraph.py:68: error:
""NativeResponseType"" has no attribute ""headers""  [attr-defined]
                return {key: value for key, value in response.headers.item...
                                                     ^~~~~~~~~~~~~~~~
providers/src/airflow/providers/microsoft/azure/hooks/msgraph.py:71: error:
Signature of ""handle_response_async"" incompatible with supertype
""ResponseHandler""  [override]
        async def handle_response_async(
        ^
```


They recently released newer minor version which has a breaking change. 



Breaking change.
following module missing: [1.4.0](https://github.com/microsoft/kiota-python/blob/v1.4.0/kiota_abstractions/default_query_parameters.py) . vs [1.3.3](https://github.com/microsoft/kiota-python/blob/v1.3.3/kiota_abstractions/default_query_parameters.py)


They released newer version at Mon, 14 Oct 2024 17:09:01 GMT . Source: https://pypi.org/rss/project/microsoft-kiota-abstractions/releases.xml",rawwar,2024-10-15 04:38:37+00:00,[],2024-10-16 14:24:40+00:00,2024-10-15 19:06:11+00:00,https://github.com/apache/airflow/pull/43021,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2412918381, 'issue_id': 2587609711, 'author': 'eladkal', 'body': ""> They recently released newer version which has a breaking change\r\n\r\nIs there a reason we can't just fix the problem and exclude the problematic release? We limit version only if the fix isn't easy and requires some effort"", 'created_at': datetime.datetime(2024, 10, 15, 5, 16, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412921202, 'issue_id': 2587609711, 'author': 'rawwar', 'body': ""> > They recently released newer version which has a breaking change\r\n> \r\n> Is there a reason we can't just fix the problem and exclude the problematic release? We limit version only if the fix isn't easy and requires some effort\r\n\r\n\r\nThey have entirely removed the module. So, unless we update the provider code, just excluding the specific version won't help. I guess, we can remove the constraint once we fix the provider by removing references to the removed classes/methods"", 'created_at': datetime.datetime(2024, 10, 15, 5, 19, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413529172, 'issue_id': 2587609711, 'author': 'eladkal', 'body': ""> They have entirely removed the module. So, unless we update the provider code, just excluding the specific version won't help. I guess, we can remove the constraint once we fix the provider by removing references to the removed classes/methods\r\n\r\nIf the fix is easy then lets fix :)"", 'created_at': datetime.datetime(2024, 10, 15, 10, 39, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413601753, 'issue_id': 2587609711, 'author': 'rawwar', 'body': ""> If the fix is easy then lets fix :)\r\n\r\nI can definitely take this work, but I don't think it's straightforward. At least not to me, as it's the first time I will be working with this provider. It failed the MyPy checks on the other [PR](https://github.com/apache/airflow/pull/43020) I'm working on. Would it be fine if I created an issue and assigned myself?"", 'created_at': datetime.datetime(2024, 10, 15, 11, 15, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413729529, 'issue_id': 2587609711, 'author': 'eladkal', 'body': ""> I can definitely take this work, but I don't think it's straightforward. At least not to me, as it's the first time I will be working with this provider. It failed the MyPy checks on the other [PR](https://github.com/apache/airflow/pull/43020) I'm working on. Would it be fine if I created an issue and assigned myself?\r\n\r\nyes but please also add comment to the provider yaml and add the link to the issue so we have better tracking of it"", 'created_at': datetime.datetime(2024, 10, 15, 12, 5, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413833889, 'issue_id': 2587609711, 'author': 'potiuk', 'body': 'Yes. Crating an issue and referring to it in the comment just above the dependency (as we do for other cases like that) is the way we do it. This makes it later very easy to check ""has this issue been followed? What is the status? Should we do something with it""? This is all very difficult if we do not know what\'s the reason of upper-binding a dependency, so our rule-of-thumb is that we never upper-bind any dependency without a comment explaining why, what is the condition of removing the binding and linking to appropriate issue.', 'created_at': datetime.datetime(2024, 10, 15, 12, 52, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413843848, 'issue_id': 2587609711, 'author': 'potiuk', 'body': 'Also once you create the issue - we could ask other people who are involved in microsoft provider -  maybe  @ambika-garg  could help with it for example ?', 'created_at': datetime.datetime(2024, 10, 15, 12, 56, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413926719, 'issue_id': 2587609711, 'author': 'ambika-garg', 'body': ""Hey @potiuk ,I'd be happy to assist with this issue."", 'created_at': datetime.datetime(2024, 10, 15, 13, 30, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413971429, 'issue_id': 2587609711, 'author': 'rawwar', 'body': ""> Yes. Crating an issue and referring to it in the comment just above the dependency (as we do for other cases like that) is the way we do it. \r\n\r\nThanks. I've updated the PR.\r\n\r\n@ambika-garg, I just created https://github.com/apache/airflow/issues/43036"", 'created_at': datetime.datetime(2024, 10, 15, 13, 47, 24, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-10-15 05:16:49 UTC): Is there a reason we can't just fix the problem and exclude the problematic release? We limit version only if the fix isn't easy and requires some effort

rawwar (Issue Creator) on (2024-10-15 05:19:35 UTC): They have entirely removed the module. So, unless we update the provider code, just excluding the specific version won't help. I guess, we can remove the constraint once we fix the provider by removing references to the removed classes/methods

eladkal on (2024-10-15 10:39:29 UTC): If the fix is easy then lets fix :)

rawwar (Issue Creator) on (2024-10-15 11:15:22 UTC): I can definitely take this work, but I don't think it's straightforward. At least not to me, as it's the first time I will be working with this provider. It failed the MyPy checks on the other [PR](https://github.com/apache/airflow/pull/43020) I'm working on. Would it be fine if I created an issue and assigned myself?

eladkal on (2024-10-15 12:05:27 UTC): yes but please also add comment to the provider yaml and add the link to the issue so we have better tracking of it

potiuk on (2024-10-15 12:52:44 UTC): Yes. Crating an issue and referring to it in the comment just above the dependency (as we do for other cases like that) is the way we do it. This makes it later very easy to check ""has this issue been followed? What is the status? Should we do something with it""? This is all very difficult if we do not know what's the reason of upper-binding a dependency, so our rule-of-thumb is that we never upper-bind any dependency without a comment explaining why, what is the condition of removing the binding and linking to appropriate issue.

potiuk on (2024-10-15 12:56:58 UTC): Also once you create the issue - we could ask other people who are involved in microsoft provider -  maybe  @ambika-garg  could help with it for example ?

ambika-garg on (2024-10-15 13:30:51 UTC): Hey @potiuk ,I'd be happy to assist with this issue.

rawwar (Issue Creator) on (2024-10-15 13:47:24 UTC): Thanks. I've updated the PR.

@ambika-garg, I just created https://github.com/apache/airflow/issues/43036

"
2587513616,pull_request,closed,,add lowerbound to requests-toolbelt and replace requests_toolbelt  with requests-toolbelt,"related to #42989

I noticed that we included `requests_toolbelt` instead of `requests-toolbelt` in http provider. 

I thought both downloaded different packages. So, i did a `pip download requests_toolbelt --no-cache-dir` and compared its checksum with `pip download requests-toolbelt --no-cache-dir` and both were same.

Not sure if there's no difference between a -(hyphen) and _(underscore) when downloading/installing packages. Officially, its `requests-toolbelt` according to pypi - https://pypi.org/project/requests-toolbelt/",rawwar,2024-10-15 03:17:01+00:00,[],2024-10-16 03:25:43+00:00,2024-10-15 21:04:25+00:00,https://github.com/apache/airflow/pull/43020,"[('area:providers', ''), ('kind:documentation', ''), ('provider:http', '')]","[{'comment_id': 2415148863, 'issue_id': 2587513616, 'author': 'potiuk', 'body': '> Not sure if there\'s no difference between a -(hyphen) and _(underscore) when downloading/installing packages. Officially, its requests-toolbelt according to pypi - https://pypi.org/project/requests-toolbelt\r\n\r\nPackage names are normalized (approved in PEP 503 - https://packaging.python.org/en/latest/specifications/name-normalization/#name-normalization) - see Normalization specification - https://packaging.python.org/en/latest/specifications/name-normalization/#name-normalization \r\n\r\n\r\nThe two names are equivalent  but we want to use the ""normalized"" name, so the change is perfectly fine.', 'created_at': datetime.datetime(2024, 10, 15, 21, 3, 57, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 21:03:57 UTC): Package names are normalized (approved in PEP 503 - https://packaging.python.org/en/latest/specifications/name-normalization/#name-normalization) - see Normalization specification - https://packaging.python.org/en/latest/specifications/name-normalization/#name-normalization 


The two names are equivalent  but we want to use the ""normalized"" name, so the change is perfectly fine.

"
2587380951,pull_request,closed,,Metrics Improvement Project,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #42881 
related: #42881 

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
### Pull Request Description

**Summary:**

This PR introduces the `get_name` method as an abstract method in the base metrics logger class. The `get_name` method has been implemented in both the StatsD and OTel metrics logger classes to handle metric name construction consistently across backends.

**Note:** The PR is not fully finished and it does not close #42881. I'm sending it to PR to see if I can proceed and finish it.  The `get_name` method has been integrated into the `incr` method of the StatsD logger, but I have not applied it to other methods yet. I'm doing this to verify whether it aligns with the proposed functionality before further updates.

**Changes:**
- Added the `get_name` abstract method to the base metrics logger interface.
- Implemented the `get_name` method in the StatsD logger class to concatenate tags with the metric name.
- Implemented the `get_name` method in the OTel logger class to return the metric name directly.
- Updated the `incr` method in the StatsD class to utilize the `get_name` method for constructing metric names.

Please review the changes and provide feedback!

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ArshiaZr,2024-10-15 01:05:18+00:00,[],2024-10-21 16:19:27+00:00,2024-10-21 16:19:26+00:00,https://github.com/apache/airflow/pull/43018,[],"[{'comment_id': 2419980550, 'issue_id': 2587380951, 'author': 'ferruzzi', 'body': '@howardyoo  - Can you have a look when you get time, this is something we discussed a while back.', 'created_at': datetime.datetime(2024, 10, 17, 16, 20, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419998800, 'issue_id': 2587380951, 'author': 'ferruzzi', 'body': ""It's a good start.\r\n\r\n- We need to use get_name in all the other methods as well (`decr()`, `gauge()`, etc) which you already said.\r\n- Please add unit tests to make sure the get_name methods you implemented are returning as expected.\r\n- We still need to run the returned name through self.metrics_validator to see if it is on the allow or block list.  You could perhaps add that to the abstract class and call super() in the implementation classes, or you could add it back where it was in the individual implemented methods (incr, decr, etc)"", 'created_at': datetime.datetime(2024, 10, 17, 16, 29, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420832463, 'issue_id': 2587380951, 'author': 'howardyoo', 'body': '> @howardyoo - Can you have a look when you get time, this is something we discussed a while back.\r\n\r\nHey sorry about the delay. I took a look and the implementation should properly work for both statsd side and otel side.', 'created_at': datetime.datetime(2024, 10, 17, 23, 23, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420833847, 'issue_id': 2587380951, 'author': 'howardyoo', 'body': ""> It's a good start.\r\n> \r\n> * We need to use get_name in all the other methods as well (`decr()`, `gauge()`, etc) which you already said.\r\n> * Please add unit tests to make sure the get_name methods you implemented are returning as expected.\r\n> * We still need to run the returned name through self.metrics_validator to see if it is on the allow or block list.  You could perhaps add that to the abstract class and call super() in the implementation classes, or you could add it back where it was in the individual implemented methods (incr, decr, etc)\r\n\r\nYes, I believe implementing unit test on get_name would be required."", 'created_at': datetime.datetime(2024, 10, 17, 23, 24, 59, tzinfo=datetime.timezone.utc)}]","ferruzzi on (2024-10-17 16:20:24 UTC): @howardyoo  - Can you have a look when you get time, this is something we discussed a while back.

ferruzzi on (2024-10-17 16:29:31 UTC): It's a good start.

- We need to use get_name in all the other methods as well (`decr()`, `gauge()`, etc) which you already said.
- Please add unit tests to make sure the get_name methods you implemented are returning as expected.
- We still need to run the returned name through self.metrics_validator to see if it is on the allow or block list.  You could perhaps add that to the abstract class and call super() in the implementation classes, or you could add it back where it was in the individual implemented methods (incr, decr, etc)

howardyoo on (2024-10-17 23:23:19 UTC): Hey sorry about the delay. I took a look and the implementation should properly work for both statsd side and otel side.

howardyoo on (2024-10-17 23:24:59 UTC): Yes, I believe implementing unit test on get_name would be required.

"
2587282936,pull_request,closed,,Improve k8s test Cherry picked from #42721  #42871 #42940,"

Cherry picked from 
https://github.com/apache/airflow/commit/15df46590ea13c2e8b71324fad0b77da8eaa7167
https://github.com/apache/airflow/commit/8a4e7bda845bab4dfe33af0a8b0c9e6fcf0da9f3
https://github.com/apache/airflow/commit/dedfe9c365c9edb969ca1d780c565fdc39996715
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-14 23:40:36+00:00,[],2024-11-02 13:05:16+00:00,2024-10-15 10:17:56+00:00,https://github.com/apache/airflow/pull/43017,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2412573443, 'issue_id': 2587282936, 'author': 'potiuk', 'body': 'While this is cool, I am not sure if we should group them. We have some tooling for release manager that verifies if all ""marked"" PRs have been cherry-picked to to the release branch and I think it assumes one-pr-per-commit. It would make our automation to show some ""false positives"" or ""false negatives"" if we merge several cherry-picks.\r\n\r\nWe use ""squash and merge"" strategy so PRs are always auto-squashed to single commit.', 'created_at': datetime.datetime(2024, 10, 15, 0, 18, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412575691, 'issue_id': 2587282936, 'author': 'potiuk', 'body': 'Also the original PRs should be marked with ""2.10.3"" Milestone when cherry-picked (for the same reason) - it\'s not been clear so I thought it is worth mentionign :) - also I marked them for all the PRs that you cherry-picked so far and those 3 PRs that need separate cherry-picking.', 'created_at': datetime.datetime(2024, 10, 15, 0, 21, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413083335, 'issue_id': 2587282936, 'author': 'gopidesupavan', 'body': '> While this is cool, I am not sure if we should group them. We have some tooling for release manager that verifies if all ""marked"" PRs have been cherry-picked to to the release branch and I think it assumes one-pr-per-commit. It would make our automation to show some ""false positives"" or ""false negatives"" if we merge several cherry-picks.\r\n> \r\n> We use ""squash and merge"" strategy so PRs are always auto-squashed to single commit.\r\n\r\nAh sure, nice to know this thing, will do separate prs for each commit :)', 'created_at': datetime.datetime(2024, 10, 15, 7, 17, 4, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 00:18:36 UTC): While this is cool, I am not sure if we should group them. We have some tooling for release manager that verifies if all ""marked"" PRs have been cherry-picked to to the release branch and I think it assumes one-pr-per-commit. It would make our automation to show some ""false positives"" or ""false negatives"" if we merge several cherry-picks.

We use ""squash and merge"" strategy so PRs are always auto-squashed to single commit.

potiuk on (2024-10-15 00:21:26 UTC): Also the original PRs should be marked with ""2.10.3"" Milestone when cherry-picked (for the same reason) - it's not been clear so I thought it is worth mentionign :) - also I marked them for all the PRs that you cherry-picked so far and those 3 PRs that need separate cherry-picking.

gopidesupavan (Issue Creator) on (2024-10-15 07:17:04 UTC): Ah sure, nice to know this thing, will do separate prs for each commit :)

"
2587245717,pull_request,closed,,Disable flaky mssql based integration tests (#42811),"* quarantined flaky mssql integration tests

* disable mssql from ci integration checks

cherry-picked from https://github.com/apache/airflow/commit/20f82901f4437b8a6ce2831e4b0f9d245056ce7d

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-14 23:12:17+00:00,[],2024-11-02 13:05:19+00:00,2024-10-15 00:41:58+00:00,https://github.com/apache/airflow/pull/43016,"[('area:dev-tools', '')]",[],
2587239375,pull_request,closed,,"Add simple ""Task Execution API"" server","closes https://github.com/apache/airflow/issues/43009

The Task Execution API is created as a separate FastAPI APP so that it allows us to hook CLI and selectively run the ""Execution API"" with the rest of Airflow API (UI/public). This is so that users can scale the APIs separately if needed as mentioned in https://github.com/apache/airflow/issues/43009

Depends on:
- https://github.com/apache/airflow/pull/43057
- https://github.com/apache/airflow/pull/43062

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-14 23:06:26+00:00,[],2024-10-17 10:44:49+00:00,2024-10-17 10:44:48+00:00,https://github.com/apache/airflow/pull/43015,"[('area:CLI', '')]",[],
2586646306,pull_request,closed,,Removed PR #41531 and added Xcom and Host DNS mapping support  to Swarm Operator,"- removed PR #41531 since it doesn't work on a mutli node environment since inspect_container from the docker sdk will not work if the docker container did run on the node which call the api. This results in a container not found error preventing the Operator from running. The code was since been removed since there is no way to guarantee the placement of the docker container.

- adding Xcom support for docker logs. If do_xcom_push is true (default) the last line of the docker logs will be push to the xcom results. If xcom_all is set to true, all results will be push to xcom.

- adding support for host dns mapping

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",spoutin,2024-10-14 17:32:26+00:00,[],2024-10-20 11:52:54+00:00,2024-10-20 11:52:54+00:00,https://github.com/apache/airflow/pull/43014,"[('area:providers', ''), ('provider:docker', '')]","[{'comment_id': 2415233354, 'issue_id': 2586646306, 'author': 'potiuk', 'body': 'Could you please split this PR - revertion of the original PR should be done with `git revert` and then the two changes should also be separated out - each with unit tests.', 'created_at': datetime.datetime(2024, 10, 15, 21, 54, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417973096, 'issue_id': 2586646306, 'author': 'spoutin', 'body': ""@potiuk I'm not sure I can do a git revert since in the latest commits it looks like the provides directory was moved.  There is no commit history on the docker_swarm.py and docker.py files."", 'created_at': datetime.datetime(2024, 10, 16, 21, 11, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417987351, 'issue_id': 2586646306, 'author': 'potiuk', 'body': ""> @potiuk I'm not sure I can do a git revert since in the latest commits it looks like the provides directory was moved. There is no commit history on the docker_swarm.py and docker.py files.\r\n\r\nI see.  - still splitting it would be great."", 'created_at': datetime.datetime(2024, 10, 16, 21, 20, 43, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 21:54:34 UTC): Could you please split this PR - revertion of the original PR should be done with `git revert` and then the two changes should also be separated out - each with unit tests.

spoutin (Issue Creator) on (2024-10-16 21:11:40 UTC): @potiuk I'm not sure I can do a git revert since in the latest commits it looks like the provides directory was moved.  There is no commit history on the docker_swarm.py and docker.py files.

potiuk on (2024-10-16 21:20:43 UTC): I see.  - still splitting it would be great.

"
2586560528,pull_request,closed,,Minor updates in UI contributing docs,"**Current**:

<img width=""1094"" alt=""image"" src=""https://github.com/user-attachments/assets/e5aa1d2a-6d8d-4bec-b7e2-55c28543fc6d"">

**With changes in this PR**:

<img width=""1118"" alt=""image"" src=""https://github.com/user-attachments/assets/73b85f9f-e1b0-47b2-8dbf-dcbfe6e6427b"">



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-14 16:48:07+00:00,[],2024-10-14 17:10:18+00:00,2024-10-14 17:10:13+00:00,https://github.com/apache/airflow/pull/43013,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2586556582,pull_request,closed,,Flush the session between writing and deletion of RTIF (#42928),"* FLush the session before deleting the RTIF data

Previously, this was how it was done, but now,
a session was used for both the writing and deletion of RTIF, which we suspect caused StaleDataError. The related PR: https://github.com/apache/airflow/pull/38565

This PR brings back the old behaviour of using different sessions for writing/deleting RTIFs

* fixup! Use different sessions in writing and deletion of RTIF

* add test and use flush

(cherry picked from commit ced319fe95a731b745801fe9b15ca7b24ef0e82f)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ephraimbuddy,2024-10-14 16:45:54+00:00,[],2024-10-23 09:10:33+00:00,2024-10-14 17:46:33+00:00,https://github.com/apache/airflow/pull/43012,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2586232559,pull_request,closed,,Create Operators for Google Cloud Vertex AI Context Caching,"Use [context caching](https://cloud.google.com/vertex-ai/generative-ai/docs/context-cache/context-cache-overview) to reduce the cost of requests that contain repeat content with high input token counts. Cached context items, such as a large amount of text, an audio file, or a video file, can be used in prompt requests to the Gemini API to generate output. Requests that use the same cache in the prompt also include text unique to each prompt. For example, each prompt request that composes a chat conversation might include the same context cache that references a video along with unique text that comprises each turn in the chat.

Adding Operators, hooks, docs. Updating provider.yaml.

Can be used as part of a broader Generative AI Operations pipeline.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",CYarros10,2024-10-14 14:34:34+00:00,[],2024-12-09 14:53:59+00:00,2024-10-15 19:42:03+00:00,https://github.com/apache/airflow/pull/43008,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2412713988, 'issue_id': 2586232559, 'author': 'potiuk', 'body': 'Needs rebase.', 'created_at': datetime.datetime(2024, 10, 15, 2, 58, 6, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 02:58:06 UTC): Needs rebase.

"
2586217394,pull_request,closed,,Update json schema pre-commit to have draft7 schema in file (#43005),"We request this file each time the CI is running pre-commit and sometimes it fails with 403 error. This PR adds the draft7 schema file locally for use by pre-commit to avoid this error

(cherry picked from commit 5316e618e0953563b81875677a21b23749817173)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2024-10-14 14:28:27+00:00,['pierrejeambrun'],2024-10-14 16:02:12+00:00,2024-10-14 16:02:12+00:00,https://github.com/apache/airflow/pull/43007,"[('area:dev-tools', '')]",[],
2586170257,pull_request,closed,,"Remove a portion of PR #41531 (retrieve output from swarm), added xcom support for Docker swarm logs","- PR #41531 doesn't work on a mutli node environment since `inspect_container` from the docker sdk will not work if the docker container did run on the node which call the api.  This results in a container not found error preventing the Operator from running.  The code was since been removed since there is no way to guarantee the placement of the docker container.

- adding Xcom support for docker logs.  If do_xcom_push is true (default) the last line of the docker logs will be push to the xcom results.  If xcom_all is set to true, all results will be push to xcom.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",spoutin,2024-10-14 14:09:20+00:00,[],2024-10-14 17:29:25+00:00,2024-10-14 17:28:54+00:00,https://github.com/apache/airflow/pull/43006,"[('area:providers', ''), ('provider:docker', '')]","[{'comment_id': 2411382364, 'issue_id': 2586170257, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 14, 14, 9, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411850858, 'issue_id': 2586170257, 'author': 'spoutin', 'body': 'closing since I bug, will recreate a new pull reqeust.', 'created_at': datetime.datetime(2024, 10, 14, 17, 29, 24, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-14 14:09:25 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

spoutin (Issue Creator) on (2024-10-14 17:29:24 UTC): closing since I bug, will recreate a new pull reqeust.

"
2586023093,pull_request,closed,,Update json schema pre-commit to have draft7 schema in file,"We request this file each time the CI is running pre-commit and sometimes it fails with 403 error. This PR adds the draft7 schema file locally for use by pre-commit to avoid this error

This has failed in several PRs today: 
https://github.com/apache/airflow/actions/runs/11327287271/job/31498424243#step:8:162
https://github.com/apache/airflow/actions/runs/11327287271/job/31498424243#step:8:162",ephraimbuddy,2024-10-14 13:15:54+00:00,[],2024-10-14 16:01:52+00:00,2024-10-14 14:26:05+00:00,https://github.com/apache/airflow/pull/43005,"[('area:dev-tools', '')]","[{'comment_id': 2411359700, 'issue_id': 2586023093, 'author': 'gopidesupavan', 'body': 'backport to v2-10?', 'created_at': datetime.datetime(2024, 10, 14, 14, 0, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411424843, 'issue_id': 2586023093, 'author': 'pierrejeambrun', 'body': 'Merging to resolve CI issues', 'created_at': datetime.datetime(2024, 10, 14, 14, 25, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411433250, 'issue_id': 2586023093, 'author': 'pierrejeambrun', 'body': ""> backport to v2-10?\r\n\r\nI haven't seen v2-10-test PR CI fail yet but I don't see why they would work so I would say yes, here is the backport PR\r\nhttps://github.com/apache/airflow/pull/43007"", 'created_at': datetime.datetime(2024, 10, 14, 14, 29, 20, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-14 14:00:43 UTC): backport to v2-10?

pierrejeambrun on (2024-10-14 14:25:59 UTC): Merging to resolve CI issues

pierrejeambrun on (2024-10-14 14:29:20 UTC): I haven't seen v2-10-test PR CI fail yet but I don't see why they would work so I would say yes, here is the backport PR
https://github.com/apache/airflow/pull/43007

"
2586002095,pull_request,closed,,Add additional named parameters and job parameters support to DatabricksRunNowOperator,"- Changes
  -  Added additional named parameters support to `DatabricksRunNowOperator`: 
      - `dbt_commands`
      - `job_parameters` 
 - How is it tested
   - Updated the tests to check the new changes 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pranshupand-db,2024-10-14 13:08:28+00:00,[],2024-11-04 20:49:57+00:00,2024-11-04 20:48:12+00:00,https://github.com/apache/airflow/pull/43004,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2411212179, 'issue_id': 2586002095, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 14, 13, 8, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2429181712, 'issue_id': 2586002095, 'author': 'pranshupand-db', 'body': 'Please review @potiuk', 'created_at': datetime.datetime(2024, 10, 22, 12, 42, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435226387, 'issue_id': 2586002095, 'author': 'potiuk', 'body': 'Can you please rebase @pranshupand-db -> for some reason the ""ci"" workflow does not start with this one, and it\'s ~ 50 commits behind.', 'created_at': datetime.datetime(2024, 10, 24, 12, 57, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435711123, 'issue_id': 2586002095, 'author': 'pranshupand-db', 'body': '@potiuk done rebasing.', 'created_at': datetime.datetime(2024, 10, 24, 16, 13, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2438542701, 'issue_id': 2586002095, 'author': 'potiuk', 'body': 'There are some errors in generated docs from the docstring', 'created_at': datetime.datetime(2024, 10, 25, 18, 22, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2440090800, 'issue_id': 2586002095, 'author': 'pranshupand-db', 'body': '@potiuk Fixed docs. Please merge', 'created_at': datetime.datetime(2024, 10, 27, 16, 36, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2454231943, 'issue_id': 2586002095, 'author': 'gaborratky-db', 'body': '@potiuk, please let us know if you need any other changes here or if this is ready to be merged. Thanks!', 'created_at': datetime.datetime(2024, 11, 4, 9, 43, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455674658, 'issue_id': 2586002095, 'author': 'potiuk', 'body': '@gaborratky-db -> I could not merge it (checking for mergability for eer), looks like some strange state of the PR - I tried to close/reopen it but then I cannot reopen it as usual. So I think you need to push your changes again and reopen it.', 'created_at': datetime.datetime(2024, 11, 4, 20, 49, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455675089, 'issue_id': 2586002095, 'author': 'potiuk', 'body': 'hello', 'created_at': datetime.datetime(2024, 11, 4, 20, 49, 56, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-14 13:08:33 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

pranshupand-db (Issue Creator) on (2024-10-22 12:42:59 UTC): Please review @potiuk

potiuk on (2024-10-24 12:57:27 UTC): Can you please rebase @pranshupand-db -> for some reason the ""ci"" workflow does not start with this one, and it's ~ 50 commits behind.

pranshupand-db (Issue Creator) on (2024-10-24 16:13:17 UTC): @potiuk done rebasing.

potiuk on (2024-10-25 18:22:27 UTC): There are some errors in generated docs from the docstring

pranshupand-db (Issue Creator) on (2024-10-27 16:36:05 UTC): @potiuk Fixed docs. Please merge

gaborratky-db on (2024-11-04 09:43:51 UTC): @potiuk, please let us know if you need any other changes here or if this is ready to be merged. Thanks!

potiuk on (2024-11-04 20:49:41 UTC): @gaborratky-db -> I could not merge it (checking for mergability for eer), looks like some strange state of the PR - I tried to close/reopen it but then I cannot reopen it as usual. So I think you need to push your changes again and reopen it.

potiuk on (2024-11-04 20:49:56 UTC): hello

"
2585860704,pull_request,closed,,(fix): HybridExecutor tasks of other executor rescheduled in kubernetes executor,"Closes #42151 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pavansharma36,2024-10-14 12:13:05+00:00,[],2024-10-20 04:21:18+00:00,2024-10-20 04:21:18+00:00,https://github.com/apache/airflow/pull/43003,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2411518808, 'issue_id': 2585860704, 'author': 'pavansharma36', 'body': '@o-nikolas  @potiuk \r\nCreated new PR because of rebase issue in 42175', 'created_at': datetime.datetime(2024, 10, 14, 14, 57, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414522186, 'issue_id': 2585860704, 'author': 'o-nikolas', 'body': '#42175 \r\n\r\nLinking to old ticket', 'created_at': datetime.datetime(2024, 10, 15, 16, 46, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420093033, 'issue_id': 2585860704, 'author': 'o-nikolas', 'body': '@pavansharma36 Can you circle back and ensure all the tests are green?', 'created_at': datetime.datetime(2024, 10, 17, 17, 20, 52, tzinfo=datetime.timezone.utc)}]","pavansharma36 (Issue Creator) on (2024-10-14 14:57:18 UTC): @o-nikolas  @potiuk 
Created new PR because of rebase issue in 42175

o-nikolas on (2024-10-15 16:46:03 UTC): #42175 

Linking to old ticket

o-nikolas on (2024-10-17 17:20:52 UTC): @pavansharma36 Can you circle back and ensure all the tests are green?

"
2585821738,pull_request,closed,,CI failure Fix json schema lint hook,"all the builds are failing with json schema lint hook, not able to fetch from the 
`https://json-schema.org/draft-07/schema` getting 
``
requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://json-schema.org/draft-07/schema
``, for it 403 means its access issue, need more investigation on this.


https://github.com/apache/airflow/actions/runs/11322945179/job/31485015966#step:8:162

As a temporary fix we can source point the github source content.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-14 11:58:52+00:00,[],2024-11-02 13:05:23+00:00,2024-10-14 13:56:25+00:00,https://github.com/apache/airflow/pull/43002,"[('area:dev-tools', '')]","[{'comment_id': 2411017179, 'issue_id': 2585821738, 'author': 'gopidesupavan', 'body': 'trying to replicate local, but with https://json-schema.org/draft-07/schema working fine in local', 'created_at': datetime.datetime(2024, 10, 14, 12, 0, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411064601, 'issue_id': 2585821738, 'author': 'pierrejeambrun', 'body': 'Thanks', 'created_at': datetime.datetime(2024, 10, 14, 12, 17, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411073959, 'issue_id': 2585821738, 'author': 'gopidesupavan', 'body': 'Now it is happy with hook , https://github.com/apache/airflow/actions/runs/11327052107/job/31497700057?pr=43002#step:8:147', 'created_at': datetime.datetime(2024, 10, 14, 12, 21, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411099353, 'issue_id': 2585821738, 'author': 'potiuk', 'body': 'Looks like temporary GitHub issues in this build this time :) ..\n\nKinda funny to see it in the change where we try to get stability by switching to GiHub URL.', 'created_at': datetime.datetime(2024, 10, 14, 12, 31, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411102511, 'issue_id': 2585821738, 'author': 'gopidesupavan', 'body': '> Looks like temporary GitHub issues in this build this time :) ..\r\n> \r\n> Kinda funny to see it in the change where we try to get stability by switching to GiHub URL.\r\n\r\nhaha agree.. 😄', 'created_at': datetime.datetime(2024, 10, 14, 12, 33, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411324822, 'issue_id': 2585821738, 'author': 'potiuk', 'body': 'Following the slack conversation - @ephraimbuddy \'s fix #43005 seems a bit more ""resilient"" for the future', 'created_at': datetime.datetime(2024, 10, 14, 13, 47, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411338746, 'issue_id': 2585821738, 'author': 'pierrejeambrun', 'body': 'Should we close this one in favor of https://github.com/apache/airflow/pull/43005 ?', 'created_at': datetime.datetime(2024, 10, 14, 13, 53, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411346872, 'issue_id': 2585821738, 'author': 'gopidesupavan', 'body': 'close this one in favor of #43005', 'created_at': datetime.datetime(2024, 10, 14, 13, 56, 25, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-14 12:00:26 UTC): trying to replicate local, but with https://json-schema.org/draft-07/schema working fine in local

pierrejeambrun on (2024-10-14 12:17:11 UTC): Thanks

gopidesupavan (Issue Creator) on (2024-10-14 12:21:24 UTC): Now it is happy with hook , https://github.com/apache/airflow/actions/runs/11327052107/job/31497700057?pr=43002#step:8:147

potiuk on (2024-10-14 12:31:52 UTC): Looks like temporary GitHub issues in this build this time :) ..

Kinda funny to see it in the change where we try to get stability by switching to GiHub URL.

gopidesupavan (Issue Creator) on (2024-10-14 12:33:17 UTC): haha agree.. 😄

potiuk on (2024-10-14 13:47:33 UTC): Following the slack conversation - @ephraimbuddy 's fix #43005 seems a bit more ""resilient"" for the future

pierrejeambrun on (2024-10-14 13:53:24 UTC): Should we close this one in favor of https://github.com/apache/airflow/pull/43005 ?

gopidesupavan (Issue Creator) on (2024-10-14 13:56:25 UTC): close this one in favor of #43005

"
2585515209,pull_request,closed,,Add lower bound to asgiref in providers,related to #42989,rawwar,2024-10-14 10:11:16+00:00,[],2024-10-15 02:42:42+00:00,2024-10-15 01:47:32+00:00,https://github.com/apache/airflow/pull/43001,"[('area:providers', ''), ('provider:http', ''), ('provider:dbt-cloud', ''), ('provider:apache-livy', '')]","[{'comment_id': 2410794136, 'issue_id': 2585515209, 'author': 'rawwar', 'body': 'Since, `asgiref` already has a lower bound in hatch_build.py, I tried adding them to all providers where `asgiref` was mentioned without any constraint. Seems like that did not help.', 'created_at': datetime.datetime(2024, 10, 14, 10, 37, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410892215, 'issue_id': 2585515209, 'author': 'rawwar', 'body': '@potiuk , Can you please check this PR? I added dependencies for all providers(with missing pins for asgiref) and yet its printing the warning. \r\n\r\nLink to warning - https://github.com/apache/airflow/actions/runs/11325445901/job/31492421131?pr=43001#step:10:601', 'created_at': datetime.datetime(2024, 10, 14, 11, 11, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412632076, 'issue_id': 2585515209, 'author': 'potiuk', 'body': 'Yeah. that\'s expected and it should fix itself when we merge to main (you will be able to see it in `canary` builds):\r\n\r\nThis piece of output is:\r\n\r\n```\r\n  #48 4.743 Installing airflow from main. It is used to cache dependencies\r\n  #48 4.743 \r\n  #48 4.745 + curl -fsSL https://github.com/apache/airflow/archive/main.tar.gz\r\n  #48 4.745 + tar xz -C /tmp/tmp.0VWy67lki1 --strip 1\r\n  #48 6.344 + uv pip install --python /usr/local/bin/python --editable \'/tmp/tmp.0VWy67lki1[devel-ci]\'\r\n```\r\n\r\nIf you look closely - it downloads airlfow from `main` and then uses it to install it locally. This is a ""smart"" way of caching - we are downloading the ""main"" version so that we can pre-install packages without invalidating docker image when dependencies of airflow change.\r\n\r\nThe way how docker layers work makes it difficult to cache dependencies from Python - because you first need to copy the dependency specifications (pyproject.toml, hatch_build.py, provider.yaml files) or airflow sources to the image in order to perform installation:\r\n\r\nAs an example (simplified):\r\n\r\n```\r\n1# COPY pyproject.toml src .\r\n2# uv pip install .\r\n```\r\n\r\nThe thing is that when you copy `pyproject.toml` the `1#` layer gets invalidated (which also invalidates layer `2#` - and it means that EVERY TIME `pyproject.toml` changes, we need to install whole airflow installation from the scratch (becuase the `2#` layer has ""installed airflow"" and it gets invalidated.\r\n\r\nThere are various strategies to cope with it - most of them can use `pip` or `uv` cache, or using cache mounts: https://docs.docker.com/build/cache/optimize/#use-cache-mounts for local builds.\r\n\r\nBut airflow is a BEAST.  The uv cache almost doubles the size of our image (2GB -> 4GB) because the `uv` cache is huge and is not optimized for size but for speed.  The ""cache mounts"" only works for local builds and it takes ~6 minutes or so (less than `pip` but still substantial) to install airflow for the first time locally in the cache - also such local cache has some edge cases when it needs to be invalidated etc. \r\n\r\nInstead we are using remote cache https://docs.docker.com/build/cache/optimize/#use-an-external-cache - basically our images, when they build locally use `--cache-from`) - and our CI builds and uploads cache to ghcr.io (with --cache-to).\r\n\r\nThis way the cache is refreshed every time `main` is green, and anyone who builds breeze image locally will use that cache.\r\n\r\nAnd the ""download main archive + install it"" - will generally prepare a `base` installation. This layer is not invalidated for quite some time (usually it will be when a new python base image is released, or apt-dependencies are changed). But until then it provides a ""base"" cache - layer - and then it is not invalidated after pyproject.toml is added: \r\n\r\n\r\n```\r\n1# curl -fsSL https://github.com/apache/airflow/archive/main.tar.gz &&\r\n  tar xz -C /tmp/tmp.0VWy67lki1 --strip 1 &&\r\n  uv pip install --python /usr/local/bin/python --editable \'/tmp/tmp.0VWy67lki1[devel-ci]\'\r\n2# COPY pyproject.toml src .\r\n3# uv pip install --python /usr/local/bin/python --editable .\r\n```\r\n\r\nIn this scenario:\r\n\r\n* The `1#` layer gets refreshed every few weeks -> when python base image changes. It does not get invalidated when pyproject.toml or src changes. This layer is pulled (rather quickly comparing to installation) from ghcr.io when `--cache-from` is used during `breeze ci-image build`\r\n* The `2#` layer gets invalidated when `pyproject.toml` or `src` change (also `3#` is invalidated as it follows `2#`. Then `uv  pip install` already has **most** packages are installed already in `1#` - so `uv pip install` generally will only incrementally install whatever changed in `pyproject.toml` (and `hatch_build.py` and `provider.yaml` in our case.\r\n\r\nThis means that in most cases rebuilding images is < 1 minute (and in some cases under 20 seconds) when sources or pyproject.toml changes. This saves enormous build time for CI and wait time for developers using breeze.\r\n\r\nThat\'s why currently this step installs still `asgiref` from main. But this will change once we merge this change to main (and we will again install things from main. \r\n\r\nNow - I think the caching is currently slightly broken after the ""providers"" move (that\'s why you see it in the first place) - I am going to take a look at it shortly https://github.com/apache/airflow/issues/42999 (generally you should not normally see ""main"" being run in the Dockerfile in your PR. It should come from the cache.', 'created_at': datetime.datetime(2024, 10, 15, 1, 26, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412633768, 'issue_id': 2585515209, 'author': 'potiuk', 'body': 'cc: @ashb -> detailed explanation about our CI image strategy ^^', 'created_at': datetime.datetime(2024, 10, 15, 1, 28, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412634816, 'issue_id': 2585515209, 'author': 'potiuk', 'body': 'I made it ready for review and merged (the mypy issue is fixed in main). You might take a look in a few ours @rawwar for Canary builds and see if the warning appears there https://github.com/apache/airflow/actions?query=event%3Aschedule', 'created_at': datetime.datetime(2024, 10, 15, 1, 29, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412648928, 'issue_id': 2585515209, 'author': 'potiuk', 'body': ""Let's see :)"", 'created_at': datetime.datetime(2024, 10, 15, 1, 47, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412695384, 'issue_id': 2585515209, 'author': 'rawwar', 'body': ""> Let's see :)\r\n\r\nLocally, i just did a `uv cache clean` and it did remove `asgiref` warning. And, also cleaned 12GB of cache :D"", 'created_at': datetime.datetime(2024, 10, 15, 2, 42, 41, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-14 10:37:41 UTC): Since, `asgiref` already has a lower bound in hatch_build.py, I tried adding them to all providers where `asgiref` was mentioned without any constraint. Seems like that did not help.

rawwar (Issue Creator) on (2024-10-14 11:11:18 UTC): @potiuk , Can you please check this PR? I added dependencies for all providers(with missing pins for asgiref) and yet its printing the warning. 

Link to warning - https://github.com/apache/airflow/actions/runs/11325445901/job/31492421131?pr=43001#step:10:601

potiuk on (2024-10-15 01:26:12 UTC): Yeah. that's expected and it should fix itself when we merge to main (you will be able to see it in `canary` builds):

This piece of output is:

```
  #48 4.743 Installing airflow from main. It is used to cache dependencies
  #48 4.743 
  #48 4.745 + curl -fsSL https://github.com/apache/airflow/archive/main.tar.gz
  #48 4.745 + tar xz -C /tmp/tmp.0VWy67lki1 --strip 1
  #48 6.344 + uv pip install --python /usr/local/bin/python --editable '/tmp/tmp.0VWy67lki1[devel-ci]'
```

If you look closely - it downloads airlfow from `main` and then uses it to install it locally. This is a ""smart"" way of caching - we are downloading the ""main"" version so that we can pre-install packages without invalidating docker image when dependencies of airflow change.

The way how docker layers work makes it difficult to cache dependencies from Python - because you first need to copy the dependency specifications (pyproject.toml, hatch_build.py, provider.yaml files) or airflow sources to the image in order to perform installation:

As an example (simplified):

```
1# COPY pyproject.toml src .
2# uv pip install .
```

The thing is that when you copy `pyproject.toml` the `1#` layer gets invalidated (which also invalidates layer `2#` - and it means that EVERY TIME `pyproject.toml` changes, we need to install whole airflow installation from the scratch (becuase the `2#` layer has ""installed airflow"" and it gets invalidated.

There are various strategies to cope with it - most of them can use `pip` or `uv` cache, or using cache mounts: https://docs.docker.com/build/cache/optimize/#use-cache-mounts for local builds.

But airflow is a BEAST.  The uv cache almost doubles the size of our image (2GB -> 4GB) because the `uv` cache is huge and is not optimized for size but for speed.  The ""cache mounts"" only works for local builds and it takes ~6 minutes or so (less than `pip` but still substantial) to install airflow for the first time locally in the cache - also such local cache has some edge cases when it needs to be invalidated etc. 

Instead we are using remote cache https://docs.docker.com/build/cache/optimize/#use-an-external-cache - basically our images, when they build locally use `--cache-from`) - and our CI builds and uploads cache to ghcr.io (with --cache-to).

This way the cache is refreshed every time `main` is green, and anyone who builds breeze image locally will use that cache.

And the ""download main archive + install it"" - will generally prepare a `base` installation. This layer is not invalidated for quite some time (usually it will be when a new python base image is released, or apt-dependencies are changed). But until then it provides a ""base"" cache - layer - and then it is not invalidated after pyproject.toml is added: 


```
1# curl -fsSL https://github.com/apache/airflow/archive/main.tar.gz &&
  tar xz -C /tmp/tmp.0VWy67lki1 --strip 1 &&
  uv pip install --python /usr/local/bin/python --editable '/tmp/tmp.0VWy67lki1[devel-ci]'
2# COPY pyproject.toml src .
3# uv pip install --python /usr/local/bin/python --editable .
```

In this scenario:

* The `1#` layer gets refreshed every few weeks -> when python base image changes. It does not get invalidated when pyproject.toml or src changes. This layer is pulled (rather quickly comparing to installation) from ghcr.io when `--cache-from` is used during `breeze ci-image build`
* The `2#` layer gets invalidated when `pyproject.toml` or `src` change (also `3#` is invalidated as it follows `2#`. Then `uv  pip install` already has **most** packages are installed already in `1#` - so `uv pip install` generally will only incrementally install whatever changed in `pyproject.toml` (and `hatch_build.py` and `provider.yaml` in our case.

This means that in most cases rebuilding images is < 1 minute (and in some cases under 20 seconds) when sources or pyproject.toml changes. This saves enormous build time for CI and wait time for developers using breeze.

That's why currently this step installs still `asgiref` from main. But this will change once we merge this change to main (and we will again install things from main. 

Now - I think the caching is currently slightly broken after the ""providers"" move (that's why you see it in the first place) - I am going to take a look at it shortly https://github.com/apache/airflow/issues/42999 (generally you should not normally see ""main"" being run in the Dockerfile in your PR. It should come from the cache.

potiuk on (2024-10-15 01:28:25 UTC): cc: @ashb -> detailed explanation about our CI image strategy ^^

potiuk on (2024-10-15 01:29:45 UTC): I made it ready for review and merged (the mypy issue is fixed in main). You might take a look in a few ours @rawwar for Canary builds and see if the warning appears there https://github.com/apache/airflow/actions?query=event%3Aschedule

potiuk on (2024-10-15 01:47:39 UTC): Let's see :)

rawwar (Issue Creator) on (2024-10-15 02:42:41 UTC): Locally, i just did a `uv cache clean` and it did remove `asgiref` warning. And, also cleaned 12GB of cache :D

"
2585498077,pull_request,closed,,Add search by `dag_display_name_pattern` on dag list page.,"refactor search parameter update logic

Refactor SearchBar component and simplify debounce logic in DagsList.

Refactor search input change handling for SearchBar and DagsList components

Update airflow/ui/src/pages/DagsList/DagsList.tsx

Co-authored-by: Brent Bovenzi <brent.bovenzi@gmail.com>

Refactor search parameter handling and improve type consistency

Remove typo

Add `LAST_DAG_RUN_STATE` to `SearchParamsKeys` and update filters

Add LAST_DAG_RUN_STATE to SearchParamsKeys and update filters

Fix missing change for add SearchBar component by removing forwardRef and adding debounced search logic.

minor change for SearchBar and DagsFilters components

Optimize imports and improve formatting across components

refactor: move query options from autogenerated useDagServiceGetDags to DagsList.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",luyangliuable,2024-10-14 10:03:53+00:00,[],2024-10-14 10:16:44+00:00,2024-10-14 10:16:43+00:00,https://github.com/apache/airflow/pull/43000,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2585224605,pull_request,closed,,Mark test_setup_constraint_mapped_task_upstream_removed_and_success as flaky,"Mark test_setup_constraint_mapped_task_upstream_removed_and_success as flaky

closes: #42990 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-14 08:28:44+00:00,[],2024-11-02 13:05:25+00:00,2024-10-14 09:30:38+00:00,https://github.com/apache/airflow/pull/42997,[],"[{'comment_id': 2410581173, 'issue_id': 2585224605, 'author': 'potiuk', 'body': 'Accidental failure of linting.', 'created_at': datetime.datetime(2024, 10, 14, 9, 30, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410652233, 'issue_id': 2585224605, 'author': 'gopidesupavan', 'body': '> Accidental failure of linting.\r\n\r\nyeah main canary also broke with same  https://github.com/apache/airflow/actions/runs/11322945179/job/31485015966#step:8:151', 'created_at': datetime.datetime(2024, 10, 14, 9, 54, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-14 09:30:31 UTC): Accidental failure of linting.

gopidesupavan (Issue Creator) on (2024-10-14 09:54:13 UTC): yeah main canary also broke with same  https://github.com/apache/airflow/actions/runs/11322945179/job/31485015966#step:8:151

"
2585065006,pull_request,closed,,Make google provider pyarrow dependency explicit,"The provider already depends on it directly but it was not listed in provider.yaml, this MR only adds pyarrow to it

Closes: #42924 ",saucoide,2024-10-14 07:29:47+00:00,[],2024-10-15 11:43:54+00:00,2024-10-15 11:43:51+00:00,https://github.com/apache/airflow/pull/42996,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2410273686, 'issue_id': 2585065006, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 14, 7, 29, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412597740, 'issue_id': 2585065006, 'author': 'potiuk', 'body': 'However you also need to run pre-commit on that change - to get the ""provider_dependencies.json"" generated for you.', 'created_at': datetime.datetime(2024, 10, 15, 0, 46, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412764420, 'issue_id': 2585065006, 'author': 'saucoide', 'body': '> However you also need to run pre-commit on that change - to get the ""provider_dependencies.json"" generated for you.\r\n\r\ndone', 'created_at': datetime.datetime(2024, 10, 15, 3, 12, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413683014, 'issue_id': 2585065006, 'author': 'potiuk', 'body': 'the failing check is about kiota new version (same in main) - it will be addressed shortly. Merging.', 'created_at': datetime.datetime(2024, 10, 15, 11, 43, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413683915, 'issue_id': 2585065006, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 15, 11, 43, 53, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-14 07:29:51 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-15 00:46:06 UTC): However you also need to run pre-commit on that change - to get the ""provider_dependencies.json"" generated for you.

saucoide (Issue Creator) on (2024-10-15 03:12:34 UTC): done

potiuk on (2024-10-15 11:43:33 UTC): the failing check is about kiota new version (same in main) - it will be addressed shortly. Merging.

boring-cyborg[bot] on (2024-10-15 11:43:53 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2585022013,pull_request,closed,,Update providers metadata 2024-10-14,,eladkal,2024-10-14 07:12:43+00:00,[],2024-10-14 14:12:34+00:00,2024-10-14 14:12:31+00:00,https://github.com/apache/airflow/pull/42995,[],[],
2584872452,pull_request,closed,,Add retry on error 502 and 504,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
When an application gateway or a Kubernetes ingress cannot find a running instance of a webserver hosting the API 
The edge worker crashes and restarts due to HTTP error 502 and 504 (during webserver startup). To prevent this, the retried errors are extended with ""bad gateway"" and ""gateway timeout"" in the internal api call.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-10-14 06:08:21+00:00,[],2024-10-15 15:50:57+00:00,2024-10-15 15:50:56+00:00,https://github.com/apache/airflow/pull/42994,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2584746721,pull_request,closed,,Fix PythonOperator when DAG has hyphen in name,"Related Issue: #42796
Same fix as in PR: https://github.com/apache/airflow/pull/42902
Backported to the 2.10 branch.

",jason810496,2024-10-14 05:01:54+00:00,[],2024-10-23 09:11:51+00:00,2024-10-14 08:38:43+00:00,https://github.com/apache/airflow/pull/42993,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2584672562,pull_request,closed,,Docs: Add templating info to TaskFlow tutorial (2-10-test backport),This is a backport to 2-10-test of my original PR: https://github.com/apache/airflow/pull/42887,infused-kim,2024-10-14 04:01:28+00:00,[],2024-10-23 09:13:10+00:00,2024-10-14 05:43:47+00:00,https://github.com/apache/airflow/pull/42992,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2584427699,pull_request,open,,helm git-sync only support v4.1+,"### Overview
Dropping support for git-sync v3, only supporting v4.1+.

### Summary of Changes
Following the changes described in https://github.com/kubernetes/git-sync/blob/v4.1.0/v3-to-v4.md, made the following changes:

- Removed chart params `dags.gitSync.branch` and `dags.gitSync.rev`, they are deprecated, [source](https://github.com/kubernetes/git-sync/blob/v4.1.0/v3-to-v4.md#sync-target---branch-and---rev-----ref)
- Removed chart params `dags.gitSync.wait`, also deprecated, [source](https://github.com/kubernetes/git-sync/blob/v4.1.0/v3-to-v4.md#loop---wait-----period)
- Changed all env vars to only start with `GITSYNC_`, not `GIT_SYNC_`, [source](https://github.com/kubernetes/git-sync/blob/v4.1.0/v3-to-v4.md#env-vars)
- Removed env var for `GITSYNC_SSH`, [source](https://github.com/kubernetes/git-sync/blob/v4.1.0/v3-to-v4.md#ssh---ssh-is-optional-after-v400)
  - This makes the minimum version supported be 4.1, not 4.0
- Removed comments about v3 or v4

### Related Issues
closes: #42918

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #42918

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",yehoshuadimarsky,2024-10-14 00:14:38+00:00,[],2024-12-08 15:08:19+00:00,,https://github.com/apache/airflow/pull/42986,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2409678618, 'issue_id': 2584427699, 'author': 'potiuk', 'body': 'That looks like a seriously breaking change for anyone using git-sync. There is nothing wrong with it, but for me it looks like it might be a good reason to bump helm chart to 2.*, add newsfragment, and - POSSIBLY think if we might want to bundle some other breaking changes with it. \r\n\r\n@jedcunningham @ephraimbuddy @utkarsharma2 @eladkal - WDYT?', 'created_at': datetime.datetime(2024, 10, 14, 1, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431307703, 'issue_id': 2584427699, 'author': 'potiuk', 'body': '@jedcunningham @ephraimbuddy @utkarsharma2 @eladkal - WDYT?', 'created_at': datetime.datetime(2024, 10, 23, 8, 34, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432232457, 'issue_id': 2584427699, 'author': 'jedcunningham', 'body': ""I think there are a lot of things we'd want to break in the next major. I was planning to look at that closer to the Airflow 3 release. I'm hesitant to just start doing it with smaller parts of the chart - pretty sure we'd hit double digits on the major pretty quickly that way :)"", 'created_at': datetime.datetime(2024, 10, 23, 13, 39, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525354200, 'issue_id': 2584427699, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 8, 0, 18, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525369664, 'issue_id': 2584427699, 'author': 'yehoshuadimarsky', 'body': 'anyone able to look at this before it goes stale?', 'created_at': datetime.datetime(2024, 12, 8, 1, 22, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2525453246, 'issue_id': 2584427699, 'author': 'potiuk', 'body': 'Might be a good idea to rebase it and resolve conflicts to ""refresh"" it.', 'created_at': datetime.datetime(2024, 12, 8, 6, 56, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-14 01:54:00 UTC): That looks like a seriously breaking change for anyone using git-sync. There is nothing wrong with it, but for me it looks like it might be a good reason to bump helm chart to 2.*, add newsfragment, and - POSSIBLY think if we might want to bundle some other breaking changes with it. 

@jedcunningham @ephraimbuddy @utkarsharma2 @eladkal - WDYT?

potiuk on (2024-10-23 08:34:28 UTC): @jedcunningham @ephraimbuddy @utkarsharma2 @eladkal - WDYT?

jedcunningham on (2024-10-23 13:39:50 UTC): I think there are a lot of things we'd want to break in the next major. I was planning to look at that closer to the Airflow 3 release. I'm hesitant to just start doing it with smaller parts of the chart - pretty sure we'd hit double digits on the major pretty quickly that way :)

github-actions[bot] on (2024-12-08 00:18:14 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

yehoshuadimarsky (Issue Creator) on (2024-12-08 01:22:40 UTC): anyone able to look at this before it goes stale?

potiuk on (2024-12-08 06:56:05 UTC): Might be a good idea to rebase it and resolve conflicts to ""refresh"" it.

"
2584370340,pull_request,closed,,"Move tests_common from ""dev"" to top-level.","Follow-up after #42505 fixing teething problem with tests_common.

Originally in #42505 common test code was moved to ""dev"" folder, but the ""dev"" folder is really dedicated to ""build"" scripts and the problem with moving ""tests_common"" to the folder was that the whole ""dev"" folder is replaced (for non-committer PRs) with the content from the target branch.

This is done for security reasons, because we can accidentally use any of the scripts from dev in the CI build scripts and we might not notice, which will open us to a security issue where a file in ""dev"" coming from PR could be accidentally executed during the ""pull_request_target"" workflow - which would expose our secrets and GitHub Package write permissions to a contributor coming from a fork.

This change moves the files, fixes pre-commit specification and docs, also fixes a number of ""doc"" issues detected by ""ruff"" in the tests_common folder as they were detected after the move. The tests_common folder is added to folders mounted when breeze is executed with local folders mounted (in order to avoid accidental mounting of randomly generated files to inside the breeze container).

All imports for the common tests were updated to reflect this move.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-13 23:23:54+00:00,[],2024-10-15 07:27:54+00:00,2024-10-15 02:43:07+00:00,https://github.com/apache/airflow/pull/42985,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('area:logging', ''), ('area:secrets', ''), ('provider:alibaba', ''), ('provider:atlassian-jira', ''), ('provider:apache-hive', ''), ('provider:apache-spark', ''), ('provider:apache-livy', '')]","[{'comment_id': 2409320716, 'issue_id': 2584370340, 'author': 'potiuk', 'body': 'This fixes the problem attempted to be fixed in #42971 by @gopidesupavan  who experienced this issue in  #42081', 'created_at': datetime.datetime(2024, 10, 13, 23, 25, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409327173, 'issue_id': 2584370340, 'author': 'potiuk', 'body': ""Unfortunately it's huge and we can't do much about it :("", 'created_at': datetime.datetime(2024, 10, 13, 23, 28, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412118669, 'issue_id': 2584370340, 'author': 'potiuk', 'body': '> For easier review... might be better to make some smaller incremental moves w/o any content changes, then git diff is faster to scroll through :-D\r\n\r\nGood point. And really reasonable.\r\n\r\nI tried to make it smaller, but all the necessary changes result from the move (i.e. in pretty much all files import will have to change. And then our pre-commit/formatting also intervenes. The comment from @ashb will likely limit the number of content changes. So in general we won\'t avoid content changes.\r\n\r\nBut  - yes - I could split it to several commits though if you think it help to review it - I will attempt to do it, that will be rather easy. It\'s also a good exercise with some git commands to produce such commits :D so let me exercise my fingers.\r\n\r\nI **could** also separate docstring fixes - dev has different rules than the ""actual"" code - including tests, but I figured that it\'s docstring only and there are not many of those - mostly empty lines and dots and changing to imperative statements in the first line. But I will see if that is easy - if not I would leave them together with the import changes.', 'created_at': datetime.datetime(2024, 10, 14, 20, 12, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412202254, 'issue_id': 2584370340, 'author': 'jscheffl', 'body': '> I **could** also separate docstring fixes - dev has different rules than the ""actual"" code - including tests, but I figured that it\'s docstring only and there are not many of those - mostly empty lines and dots and changing to imperative statements in the first line. But I will see if that is easy - if not I would leave them together with the import changes.\r\n\r\nThat was not meant to be a blocker for the _current_ PR but to have more friends for the next one :-D', 'created_at': datetime.datetime(2024, 10, 14, 20, 30, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412360826, 'issue_id': 2584370340, 'author': 'potiuk', 'body': ""> That was not meant to be a blocker for the current PR but to have more friends for the next one :-D\r\n\r\nI split it REGARDLESS -> There are 3 commits now - move, docs, make it works.  You can re-review now, I 🤞 it's going to pass tests now."", 'created_at': datetime.datetime(2024, 10, 14, 21, 18, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412364822, 'issue_id': 2584370340, 'author': 'potiuk', 'body': 'It\'s actually pretty easy to split such PR if you know a few git tricks\r\n\r\n```bash\r\ngit reset HEAD^ --hard\r\nmv dev/tests_common . \r\ngit add .\r\ngit commit --no-verify -m ""\'Move tests common without changes""\r\ngit cherry-pick <previous branch tip from git reflog>\r\ngit add tests_common\r\ngit commit --no-verify -m ""Fix docstrings in tests_common""\r\ngit add . \r\ngit commit # copy-paste previous commit message\r\n```', 'created_at': datetime.datetime(2024, 10, 14, 21, 22, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412371120, 'issue_id': 2584370340, 'author': 'potiuk', 'body': 'BTW. When you look at it now - it does not necessarily make it easier to review in GH UI, but `git diff HEAD^` is actually pretty reviewable - even if long. (and the first two commits are easily reviewable).', 'created_at': datetime.datetime(2024, 10, 14, 21, 27, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412447401, 'issue_id': 2584370340, 'author': 'potiuk', 'body': ""OK. Looks like we are getting there. There were few other places where there get_test_run had one more empty line.\r\n\r\nBTW. That's the first time I started to like sphinx - this time it actually prevented us from accidental error that would have potentially caused silently slower-running system tests. \r\n\r\n(well @jscheffl to notice it with review but sphinx also guarding it)."", 'created_at': datetime.datetime(2024, 10, 14, 22, 31, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412695899, 'issue_id': 2584370340, 'author': 'potiuk', 'body': 'Green, reviewed, merged.', 'created_at': datetime.datetime(2024, 10, 15, 2, 43, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413102899, 'issue_id': 2584370340, 'author': 'gopidesupavan', 'body': 'cool, Thank you @potiuk 😄', 'created_at': datetime.datetime(2024, 10, 15, 7, 27, 53, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-13 23:25:14 UTC): This fixes the problem attempted to be fixed in #42971 by @gopidesupavan  who experienced this issue in  #42081

potiuk (Issue Creator) on (2024-10-13 23:28:08 UTC): Unfortunately it's huge and we can't do much about it :(

potiuk (Issue Creator) on (2024-10-14 20:12:49 UTC): Good point. And really reasonable.

I tried to make it smaller, but all the necessary changes result from the move (i.e. in pretty much all files import will have to change. And then our pre-commit/formatting also intervenes. The comment from @ashb will likely limit the number of content changes. So in general we won't avoid content changes.

But  - yes - I could split it to several commits though if you think it help to review it - I will attempt to do it, that will be rather easy. It's also a good exercise with some git commands to produce such commits :D so let me exercise my fingers.

I **could** also separate docstring fixes - dev has different rules than the ""actual"" code - including tests, but I figured that it's docstring only and there are not many of those - mostly empty lines and dots and changing to imperative statements in the first line. But I will see if that is easy - if not I would leave them together with the import changes.

jscheffl on (2024-10-14 20:30:52 UTC): That was not meant to be a blocker for the _current_ PR but to have more friends for the next one :-D

potiuk (Issue Creator) on (2024-10-14 21:18:54 UTC): I split it REGARDLESS -> There are 3 commits now - move, docs, make it works.  You can re-review now, I 🤞 it's going to pass tests now.

potiuk (Issue Creator) on (2024-10-14 21:22:08 UTC): It's actually pretty easy to split such PR if you know a few git tricks

```bash
git reset HEAD^ --hard
mv dev/tests_common . 
git add .
git commit --no-verify -m ""'Move tests common without changes""
git cherry-pick <previous branch tip from git reflog>
git add tests_common
git commit --no-verify -m ""Fix docstrings in tests_common""
git add . 
git commit # copy-paste previous commit message
```

potiuk (Issue Creator) on (2024-10-14 21:27:20 UTC): BTW. When you look at it now - it does not necessarily make it easier to review in GH UI, but `git diff HEAD^` is actually pretty reviewable - even if long. (and the first two commits are easily reviewable).

potiuk (Issue Creator) on (2024-10-14 22:31:44 UTC): OK. Looks like we are getting there. There were few other places where there get_test_run had one more empty line.

BTW. That's the first time I started to like sphinx - this time it actually prevented us from accidental error that would have potentially caused silently slower-running system tests. 

(well @jscheffl to notice it with review but sphinx also guarding it).

potiuk (Issue Creator) on (2024-10-15 02:43:19 UTC): Green, reviewed, merged.

gopidesupavan on (2024-10-15 07:27:53 UTC): cool, Thank you @potiuk 😄

"
2584260167,pull_request,closed,,Fix canary build test test_cli_internal_api_background process termination #42781,"Cherry pick from https://github.com/apache/airflow/pull/42781/files#diff-abc2592be6f1f659ce951122b8eba292f3abf716dc8d2e8dda6f997f2dce14b9

Had pre-commit issue in local, so have done this manually. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-13 20:46:42+00:00,[],2024-11-02 13:05:27+00:00,2024-10-14 10:24:52+00:00,https://github.com/apache/airflow/pull/42983,"[('area:CLI', '')]","[{'comment_id': 2410731348, 'issue_id': 2584260167, 'author': 'pierrejeambrun', 'body': 'Is that the fix for the CI errors we saw lately 🤞?', 'created_at': datetime.datetime(2024, 10, 14, 10, 23, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410733948, 'issue_id': 2584260167, 'author': 'pierrejeambrun', 'body': ""Nice idea to explicitly kill both processing instead of relying on the parent monitor process to kill the child, which wasn't working in all cases apparently."", 'created_at': datetime.datetime(2024, 10, 14, 10, 24, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410803257, 'issue_id': 2584260167, 'author': 'gopidesupavan', 'body': '> Is that the fix for the CI errors we saw lately 🤞?\r\n\r\n@pierrejeambrun yes applied same changes in main, we stopped seeing background process failures.\r\nhttps://github.com/apache/airflow/pull/42781', 'created_at': datetime.datetime(2024, 10, 14, 10, 39, 57, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-14 10:23:49 UTC): Is that the fix for the CI errors we saw lately 🤞?

pierrejeambrun on (2024-10-14 10:24:49 UTC): Nice idea to explicitly kill both processing instead of relying on the parent monitor process to kill the child, which wasn't working in all cases apparently.

gopidesupavan (Issue Creator) on (2024-10-14 10:39:57 UTC): @pierrejeambrun yes applied same changes in main, we stopped seeing background process failures.
https://github.com/apache/airflow/pull/42781

"
2584202699,pull_request,closed,,Add early job_id xcom_push for google provider Beam Pipeline operators,"- To let GCP Beam Sensor operators 'sense' the pipeline changes, by having dataflow job_id been xcom_push as soon as it available.

Related issue: https://github.com/apache/airflow/issues/30007.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-10-13 19:21:05+00:00,[],2024-10-14 01:49:35+00:00,2024-10-14 01:49:35+00:00,https://github.com/apache/airflow/pull/42982,"[('area:providers', ''), ('provider:apache-beam', '')]",[],
2584033614,pull_request,closed,,CI failure upgrade trove-classifiers to 2024.10.12,"CI failure upgrade trove-classifiers to 2024.10.12

https://github.com/apache/airflow/actions/runs/11314811150/job/31465240821#step:9:67

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-13 14:56:17+00:00,[],2024-11-02 13:05:29+00:00,2024-10-13 15:12:57+00:00,https://github.com/apache/airflow/pull/42979,[],"[{'comment_id': 2409016393, 'issue_id': 2584033614, 'author': 'potiuk', 'body': 'AGAIN? :)', 'created_at': datetime.datetime(2024, 10, 13, 15, 12, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409017972, 'issue_id': 2584033614, 'author': 'gopidesupavan', 'body': '> AGAIN? :)\r\n\r\nyeah :) three releases in last two days', 'created_at': datetime.datetime(2024, 10, 13, 15, 17, 11, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-13 15:12:48 UTC): AGAIN? :)

gopidesupavan (Issue Creator) on (2024-10-13 15:17:11 UTC): yeah :) three releases in last two days

"
2583915500,pull_request,closed,,Restrict looker-sdk version 24.18.0 and microsoft-kiota-http 1.3.4 (#…,"…42954)

* restrict looker version 24.18.0

* update microsoft provider deps with microsoft-kiota-http

* update gh issue ids to provider yaml files

* ignore type in applfowhook

* ignore type in applfowhook

* ignore type in applfowhook

(cherry picked from commit 7d8ea68bdaae3258bd391b8f6ae0277258a7c437)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-13 11:49:52+00:00,[],2024-10-13 21:12:23+00:00,2024-10-13 21:12:21+00:00,https://github.com/apache/airflow/pull/42977,[],"[{'comment_id': 2408947343, 'issue_id': 2583915500, 'author': 'potiuk', 'body': 'Backport of #42954  in order to make v2-10-test build without errors.', 'created_at': datetime.datetime(2024, 10, 13, 11, 50, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408949083, 'issue_id': 2583915500, 'author': 'gopidesupavan', 'body': '> Backport of #42954 in order to make v2-10-test build without errors.\r\n\r\nah sorry my bad..', 'created_at': datetime.datetime(2024, 10, 13, 11, 56, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408961172, 'issue_id': 2583915500, 'author': 'gopidesupavan', 'body': '@potiuk should we back port the recent prs related flaky and some k8s test updates?', 'created_at': datetime.datetime(2024, 10, 13, 12, 30, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409016719, 'issue_id': 2583915500, 'author': 'potiuk', 'body': '> @potiuk should we back port the recent prs related flaky and some k8s test updates?\r\n\r\nYes. Might be a good idea.', 'created_at': datetime.datetime(2024, 10, 13, 15, 13, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409092831, 'issue_id': 2583915500, 'author': 'potiuk', 'body': '> Yes. Might be a good idea.\r\n\r\nThat is a VERY good idea - I see a huge difference in the stability now main vs. 2-10-test after all the fixes you and others came up with for the stability!', 'created_at': datetime.datetime(2024, 10, 13, 19, 16, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409120030, 'issue_id': 2583915500, 'author': 'gopidesupavan', 'body': '> > Yes. Might be a good idea.\r\n> \r\n> That is a VERY good idea - I see a huge difference in the stability now main vs. 2-10-test after all the fixes you and others came up with for the stability!\r\n\r\nSure will create those prs :)', 'created_at': datetime.datetime(2024, 10, 13, 20, 48, 45, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-13 11:50:53 UTC): Backport of #42954  in order to make v2-10-test build without errors.

gopidesupavan on (2024-10-13 11:56:26 UTC): ah sorry my bad..

gopidesupavan on (2024-10-13 12:30:39 UTC): @potiuk should we back port the recent prs related flaky and some k8s test updates?

potiuk (Issue Creator) on (2024-10-13 15:13:42 UTC): Yes. Might be a good idea.

potiuk (Issue Creator) on (2024-10-13 19:16:12 UTC): That is a VERY good idea - I see a huge difference in the stability now main vs. 2-10-test after all the fixes you and others came up with for the stability!

gopidesupavan on (2024-10-13 20:48:45 UTC): Sure will create those prs :)

"
2583899052,pull_request,closed,,fix mypy check failure on main,"`pre-commit run --all-files` on main results in following error for ""Run mypy for airflow"" 


```
task_sdk/tests/conftest.py:26: error: Incompatible types in assignment
(expression has type ""tuple[()]"", target has type ""Union[str, list[str]]"") 
[assignment]
        config.inicfg[""airflow_deprecations_ignore""] = ()
                                                       ^~
```

I noticed, in other places, assignment for `config.inicfg` has the ignore comment - https://github.com/apache/airflow/blob/07bf0a791b80c26c8ca99a3a4839cf555b531990/tests/conftest.py#L43",rawwar,2024-10-13 11:29:01+00:00,[],2024-10-14 10:28:44+00:00,2024-10-14 09:17:00+00:00,https://github.com/apache/airflow/pull/42976,"[('area:task-sdk', None)]","[{'comment_id': 2409828867, 'issue_id': 2583899052, 'author': 'potiuk', 'body': 'Actually the error you get is CAUSED by using """". It **should** be `[]`\r\n\r\nThe error is caused by this line:\r\n\r\n```\r\n        if isinstance(deprecations_ignore, (str, os.PathLike)):\r\n            self.deprecations_ignore = [deprecations_ignore]\r\n```\r\n\r\nWhich turns the """" into a single-element array with empty string.', 'created_at': datetime.datetime(2024, 10, 14, 2, 46, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410548508, 'issue_id': 2583899052, 'author': 'potiuk', 'body': 'Solved :)', 'created_at': datetime.datetime(2024, 10, 14, 9, 17, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410752117, 'issue_id': 2583899052, 'author': 'kaxil', 'body': 'Nice', 'created_at': datetime.datetime(2024, 10, 14, 10, 28, 43, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-14 02:46:16 UTC): Actually the error you get is CAUSED by using """". It **should** be `[]`

The error is caused by this line:

```
        if isinstance(deprecations_ignore, (str, os.PathLike)):
            self.deprecations_ignore = [deprecations_ignore]
```

Which turns the """" into a single-element array with empty string.

potiuk on (2024-10-14 09:17:22 UTC): Solved :)

kaxil on (2024-10-14 10:28:43 UTC): Nice

"
2583693144,pull_request,closed,,AIP-84 Migrate Clear Dag Run public endpoint to FastAPI ,related to #42701,rawwar,2024-10-13 06:17:27+00:00,[],2024-11-15 08:24:09+00:00,2024-11-15 08:22:37+00:00,https://github.com/apache/airflow/pull/42975,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2453441589, 'issue_id': 2583693144, 'author': 'rawwar', 'body': '@pierrejeambrun , I noticed that in legacy implementation, for clear dag run endpoint with dry_run=True, the response is supposed to be a TaskInstanceCollection. However, the response only includes few attributes of TI. Below is an example response :\r\n\r\n```\r\n{\r\n  ""task_instances"": [\r\n    {\r\n      ""dag_id"": ""example_astronauts"",\r\n      ""dag_run_id"": ""manual__2024-11-03T14:05:08.832062+00:00"",\r\n      ""execution_date"": ""2024-11-03T14:05:08.832062+00:00"",\r\n      ""task_id"": ""print_astronaut_craft""\r\n    },{\r\n      ""dag_id"": ""example_astronauts"",\r\n      ""dag_run_id"": ""manual__2024-11-03T14:05:08.832062+00:00"",\r\n      ""execution_date"": ""2024-11-03T14:05:08.832062+00:00"",\r\n      ""task_id"": ""get_astronauts""\r\n    }\r\n\r\n```\r\nRelated schema: [TaskInstanceReferenceSchema](https://github.com/apache/airflow/blob/861ce4b8c154ea5b557094871677dc1af97b60f2/airflow/api_connexion/schemas/task_instance_schema.py#L231)\r\nShould I keep the same? Or should I return all the details?\r\n\r\nI tried to return all details. But, to do that, it seems I can\'t reuse the methods in the legacy implementation as it is causing the following error. \r\n```\r\nError extracting attribute: DetachedInstanceError: Parent instance <TaskInstance at 0x31af2e880> is not bound to a Session; lazy load operation of attribute \'task_instance_note\' cannot proceed (Background on this error at: https://sqlalche.me/e/14/bhk3) [type=get_attribute_error, input_value=<TaskInstance: example_as....832062+00:00 [success]>, input_type=TaskInstance]\r\n```\r\nI guess, I just need to use joinload. But, thinking if I should update [here](https://github.com/apache/airflow/blob/861ce4b8c154ea5b557094871677dc1af97b60f2/airflow/models/dag.py#L1471) or just rewrite a select query within clear_dag_run method', 'created_at': datetime.datetime(2024, 11, 3, 14, 10, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457134128, 'issue_id': 2583693144, 'author': 'pierrejeambrun', 'body': 'I think we can do the same and return a partial response. There is a way to do that in fastapi specifying the response model. And we need to document it in the swagger with example responses.\r\n\r\nDetachedInstance error is most certainly due to a bad session handling. (session used to fetch objects is closed too early or something similar)', 'created_at': datetime.datetime(2024, 11, 5, 13, 12, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464591555, 'issue_id': 2583693144, 'author': 'rawwar', 'body': '> I think we can do the same and return a partial response. There is a way to do that in fastapi specifying the response model. And we need to document it in the swagger with example responses.\r\n> \r\n\r\nI went with returning the entire object. Is that fine? If not, I can return the partial response. I already looked into how to do it', 'created_at': datetime.datetime(2024, 11, 8, 12, 4, 25, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-03 14:10:26 UTC): @pierrejeambrun , I noticed that in legacy implementation, for clear dag run endpoint with dry_run=True, the response is supposed to be a TaskInstanceCollection. However, the response only includes few attributes of TI. Below is an example response :

```
{
  ""task_instances"": [
    {
      ""dag_id"": ""example_astronauts"",
      ""dag_run_id"": ""manual__2024-11-03T14:05:08.832062+00:00"",
      ""execution_date"": ""2024-11-03T14:05:08.832062+00:00"",
      ""task_id"": ""print_astronaut_craft""
    },{
      ""dag_id"": ""example_astronauts"",
      ""dag_run_id"": ""manual__2024-11-03T14:05:08.832062+00:00"",
      ""execution_date"": ""2024-11-03T14:05:08.832062+00:00"",
      ""task_id"": ""get_astronauts""
    }

```
Related schema: [TaskInstanceReferenceSchema](https://github.com/apache/airflow/blob/861ce4b8c154ea5b557094871677dc1af97b60f2/airflow/api_connexion/schemas/task_instance_schema.py#L231)
Should I keep the same? Or should I return all the details?

I tried to return all details. But, to do that, it seems I can't reuse the methods in the legacy implementation as it is causing the following error. 
```
Error extracting attribute: DetachedInstanceError: Parent instance <TaskInstance at 0x31af2e880> is not bound to a Session; lazy load operation of attribute 'task_instance_note' cannot proceed (Background on this error at: https://sqlalche.me/e/14/bhk3) [type=get_attribute_error, input_value=<TaskInstance: example_as....832062+00:00 [success]>, input_type=TaskInstance]
```
I guess, I just need to use joinload. But, thinking if I should update [here](https://github.com/apache/airflow/blob/861ce4b8c154ea5b557094871677dc1af97b60f2/airflow/models/dag.py#L1471) or just rewrite a select query within clear_dag_run method

pierrejeambrun on (2024-11-05 13:12:57 UTC): I think we can do the same and return a partial response. There is a way to do that in fastapi specifying the response model. And we need to document it in the swagger with example responses.

DetachedInstance error is most certainly due to a bad session handling. (session used to fetch objects is closed too early or something similar)

rawwar (Issue Creator) on (2024-11-08 12:04:25 UTC): I went with returning the entire object. Is that fine? If not, I can return the partial response. I already looked into how to do it

"
2583671223,pull_request,closed,,AIP-84 Migrate Modify Dag Run Note endpoint to FastAPI ,related to https://github.com/apache/airflow/issues/42701,rawwar,2024-10-13 05:39:34+00:00,[],2024-10-30 06:35:30+00:00,2024-10-30 06:35:30+00:00,https://github.com/apache/airflow/pull/42974,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2444664620, 'issue_id': 2583671223, 'author': 'pierrejeambrun', 'body': ""This should be removed in favor of https://github.com/apache/airflow/issues/43476, we don't need both."", 'created_at': datetime.datetime(2024, 10, 29, 15, 45, 32, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-29 15:45:32 UTC): This should be removed in favor of https://github.com/apache/airflow/issues/43476, we don't need both.

"
2583605015,pull_request,closed,,AIP-84 Migrate Modify Dag Run endpoint to FastAPI,related to #42701,rawwar,2024-10-13 03:40:47+00:00,[],2024-10-29 15:43:42+00:00,2024-10-29 15:43:42+00:00,https://github.com/apache/airflow/pull/42973,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2416817409, 'issue_id': 2583605015, 'author': 'kaxil', 'body': 'You will have to rebase and fix conflicts as we change how `fastapi_api` folder is organized here: https://github.com/apache/airflow/pull/43062', 'created_at': datetime.datetime(2024, 10, 16, 13, 17, 53, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-10-16 13:17:53 UTC): You will have to rebase and fix conflicts as we change how `fastapi_api` folder is organized here: https://github.com/apache/airflow/pull/43062

"
2583584691,pull_request,closed,,Mark test_task_workflow_trigger_success as flaky,"This test test_task_workflow_trigger_success is failing frequently, marking it as flaky and re-run 5 times. 

https://github.com/apache/airflow/actions/runs/11302984015/job/31439689894#step:7:7159

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-13 02:51:40+00:00,[],2024-11-23 19:55:02+00:00,2024-10-13 04:36:28+00:00,https://github.com/apache/airflow/pull/42972,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:Triggerer', '')]","[{'comment_id': 2408930740, 'issue_id': 2583584691, 'author': 'potiuk', 'body': 'nice!', 'created_at': datetime.datetime(2024, 10, 13, 10, 58, 34, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-13 10:58:34 UTC): nice!

"
2583581617,pull_request,closed,,Adding temporary python operator imports to compat,"Am trying to add imports in compat file but, ci is replacing these files. so adding temporary imports and once it merged this help tests to run in this https://github.com/apache/airflow/pull/42081.


failing to resolve:
https://github.com/apache/airflow/actions/runs/11307601726/job/31449600261#step:11:2982

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-13 02:41:14+00:00,[],2024-11-23 19:54:58+00:00,2024-11-02 14:54:36+00:00,https://github.com/apache/airflow/pull/42971,"[('area:dev-tools', '')]","[{'comment_id': 2408798513, 'issue_id': 2583581617, 'author': 'potiuk', 'body': 'No. That is generally bad idea to have `tests_common`  in `dev` (and this case shows why).\r\n\r\nDev is indeed replaced in CI when images - in ""checkout target commit"":\r\n\r\n```bash\r\n        echo\r\n        echo -e ""\\033[33m Replace scripts, dev, actions with target branch for non-committer builds!\\033[0m""\r\n        echo\r\n        rm -rfv ""scripts/ci""\r\n        rm -rfv ""dev""\r\n        rm -rfv "".github/actions""\r\n        rm -rfv "".github/workflows""\r\n        mv -v ""target-airflow/scripts/ci"" ""scripts""\r\n        mv -v ""target-airflow/dev"" "".""\r\n        mv -v ""target-airflow/.github/actions"" ""target-airflow/.github/workflows"" "".github""\r\n```\r\n\r\nThis is for security reason, so that any of the ""dev"" scripts that are used during CI and build process are not tampered with when they are modified in the incoming PR.\r\n\r\nThis is a bit of a teething problem after #42505 and you were the unlucky first non-committer who attempted to modify common test code that is shared between providers and airflow.\r\n\r\n@ashb - we will have to find better place for ""tests_common"" than `dev` - because otherwise every non-commiter who wants to make a PR changing the ""common"" code they will get their ""dev/tests_common"" code overwritten.\r\n\r\nGenerally ""dev"" was always supposed to be used for ""build scripts"" but never by ""test code"".\r\n\r\nHow about just ""tests_common"" at the top level of the repository @ashb ?', 'created_at': datetime.datetime(2024, 10, 13, 3, 2, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408799673, 'issue_id': 2583581617, 'author': 'gopidesupavan', 'body': '> No. That is generally bad idea to have `tests_common` in `dev` (and this case shows why).\r\n> \r\n> Dev is indeed replaced in CI when images - in ""checkout target commit"":\r\n> \r\n> ```shell\r\n>         echo\r\n>         echo -e ""\\033[33m Replace scripts, dev, actions with target branch for non-committer builds!\\033[0m""\r\n>         echo\r\n>         rm -rfv ""scripts/ci""\r\n>         rm -rfv ""dev""\r\n>         rm -rfv "".github/actions""\r\n>         rm -rfv "".github/workflows""\r\n>         mv -v ""target-airflow/scripts/ci"" ""scripts""\r\n>         mv -v ""target-airflow/dev"" "".""\r\n>         mv -v ""target-airflow/.github/actions"" ""target-airflow/.github/workflows"" "".github""\r\n> ```\r\n> \r\n> This is for security reason, so that any of the ""dev"" scripts that are used during CI and build process are not tampered with when they are modified in the incoming PR.\r\n> \r\n> This is a bit of a teething problem after #42505 and you were the unlucky first non-committer who attempted to modify common test code that is shared between providers and airflow.\r\n> \r\n> @ashb - we will have to find better place for ""tests_common"" than `dev` - because otherwise every non-commiter who wants to make a PR changing the ""common"" code they will get their ""dev/tests_common"" code overwritten.\r\n> \r\n> Generally ""dev"" was always supposed to be used for ""build scripts"" but never by ""test code"".\r\n> \r\n> How about just ""tests_common"" at the top level of the repository @ashb ?\r\n\r\nThanks jarek I agree , sorry for this :( previously it was in different location. So thought might be because of restructure it moved...', 'created_at': datetime.datetime(2024, 10, 13, 3, 7, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408909838, 'issue_id': 2583581617, 'author': 'gopidesupavan', 'body': 'oops sorry have closed this, conversation is still open here. opening this pr, but merge is not required.', 'created_at': datetime.datetime(2024, 10, 13, 9, 57, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409071905, 'issue_id': 2583581617, 'author': 'ashb', 'body': 'The reason I picked dev/ was cos I was trying to counter/not add to the proliferation of top level folders (there are more than I want/think there should be still). But I see that causes a problem now', 'created_at': datetime.datetime(2024, 10, 13, 18, 9, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409073542, 'issue_id': 2583581617, 'author': 'ashb', 'body': ""In this specific case does the compat import need to be shared between core and provider tests?\n\nI.e. yes dev/tests_common is the wrong place, but I'm not sure if we need import compat in the tests code do we? What is stopping us updating all the imports in tests? @gopidesupavan"", 'created_at': datetime.datetime(2024, 10, 13, 18, 14, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409081873, 'issue_id': 2583581617, 'author': 'ashb', 'body': ""@potiuk could we (safely) change dev/ to dev/breeze/ in that target pr part? I'm not sure what else actually lives in dev folder and am not at my computer right now"", 'created_at': datetime.datetime(2024, 10, 13, 18, 40, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409087469, 'issue_id': 2583581617, 'author': 'potiuk', 'body': '> @potiuk could we (safely) change dev/ to dev/breeze/ in that target pr part? I\'m not sure what else actually lives in dev folder and am not at my computer right now\r\n\r\nNot really - dev is really a bag-of-all-things related to building our software - and it\'s a dangerous thing to only override part of it. There are a number of scripts that are there that are **likely** to be used in CI processes. This is for example why we have ""scripts/ci"" - because there I made sure (and I am reviewing that) that only CI scripts are used there).\r\n\r\nThe current content of `dev` is this (so there are a number of sub-folders - `breeze` is only one of them, and it\'s very likely some other scripts (`provider_packages` for example) are ""potentially dangerous"":\r\n\r\n```\r\nchart\r\nexample_dags\r\nimages\r\nmypy\r\nperf\r\nprovider_packages\r\nstats\r\nsystem_tests\r\ntemplates\r\n__init__.py\r\nairflow-github\r\nairflow-license\r\nassign_cherry_picked_prs_with_milestone.py\r\ncheck_files.py\r\nCHERRY_PICK_SUMMARY.txt.jinja2\r\nget_devel_deps.sh\r\nISSUE_TEMPLATE.md.jinja2\r\nMANUALLY_BUILDING_IMAGES.md\r\nMANUALLY_GENERATING_IMAGE_CACHE_AND_CONSTRAINTS.md\r\nprepare_bulk_issues.py\r\nPROJECT_GUIDELINES.md\r\nPROVIDER_PACKAGE_DETAILS.md\r\nREADME.md\r\nREADME_RELEASE_AIRFLOW.md\r\nREADME_RELEASE_HELM_CHART.md\r\nREADME_RELEASE_PROVIDER_PACKAGES.md\r\nREADME_RELEASE_PYTHON_CLIENT.md\r\nrefresh_images.sh\r\nremove_artifacts.sh\r\nrequirements.txt\r\nretag_docker_images.py\r\nsend_email.py\r\nsign.sh\r\nvalidate_version_added_fields_in_config.py\r\nWHAT_GOES_INTO_THE_NEXT_RELEASE.md\r\n```\r\n\r\nAnd for example ""system_tests"" there is not something that ""system_tests"" use but some ""dev/build scripts"" that are related to system_tests.\r\n\r\nWe already had the issue when accidental typo or mistake cause https://medium.com/apache-airflow/unraveling-the-code-navigating-a-ci-release-security-vulnerability-in-apache-airflow-620214a96297 so I think it\'s better to be safe than sorry and exclude whole ""dev"" and designate it as ""build scripts"". \r\n\r\nConceptually - if we look at that the ""common_tests"" belong to ""application"" not to ""building appplication"".\r\n\r\nIdeally we should have something like that:\r\n\r\n```\r\nairflow_core/src\r\n                airflow.<subpackages>\r\n             tests\r\n                airflow.<subpackages>\r\n             pyproject.toml\r\nairflow_common/\r\n              tests_common.<subpackages>\r\n              pyproject.toml\r\nproviders/\r\n        airbyte/\r\n              src\r\n                 airflow.providers.arbyte.<subpackages> \r\n              tests\r\n                 airflow.providers.arbyte.<subpackages> \r\n              pyproject.toml\r\n``` \r\n\r\nBut it would require the ""heavy"" airflow move. And maybe we can do it eventually after we split providers and go through all other teething problems.\r\n\r\n\r\nBut maybe let\'s do it step-by-step - moving to `tests_common` at top level would be a good intermediate step.', 'created_at': datetime.datetime(2024, 10, 13, 19, 0, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409099348, 'issue_id': 2583581617, 'author': 'ashb', 'body': 'Yeah I thought they was likely the case but wanted to check.\n\nI do plan on eventually moving airflow/ and tests/ into a new ""core"" workspace project, but absolutely one thing at a time.', 'created_at': datetime.datetime(2024, 10, 13, 19, 38, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409102179, 'issue_id': 2583581617, 'author': 'gopidesupavan', 'body': ""> In this specific case does the compat import need to be shared between core and provider tests?\r\n> \r\n> I.e. yes dev/tests_common is the wrong place, but I'm not sure if we need import compat in the tests code do we? What is stopping us updating all the imports in tests? @gopidesupavan\r\n\r\nYeah currently its the pattern i see in the providers tests/ other places. adding imports in compat and using if any compatibility requires. \r\n\r\nAt present i have workaround like this where ever i need to import doing this. \r\n\r\n```\r\ntry:\r\n    from airflow.providers.standard.operators.python import PythonOperator\r\nexcept ImportError:\r\n    from airflow.operators.python import PythonOperator\r\n```\r\n\r\nThis pr update not super important,  as have workaround to proceed python operator :)"", 'created_at': datetime.datetime(2024, 10, 13, 19, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409322877, 'issue_id': 2583581617, 'author': 'potiuk', 'body': 'The PR to move tests_common in #42985.', 'created_at': datetime.datetime(2024, 10, 13, 23, 26, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409665725, 'issue_id': 2583581617, 'author': 'potiuk', 'body': '> try:\r\n>     from airflow.providers.standard.operators.python import PythonOperator\r\n> except ImportError:\r\n>     from airflow.operators.python import PythonOperator\r\n\r\nYeah. that pattern is fine - just ""dev"" override is problematic and hopefully we will fix it soon with #42985', 'created_at': datetime.datetime(2024, 10, 14, 1, 48, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412696625, 'issue_id': 2583581617, 'author': 'potiuk', 'body': 'You should be able to rebase your changes @gopidesupavan now and it **should** work normaly.', 'created_at': datetime.datetime(2024, 10, 15, 2, 44, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2453014787, 'issue_id': 2583581617, 'author': 'gopidesupavan', 'body': 'Closing this one as it resolved  #42985', 'created_at': datetime.datetime(2024, 11, 2, 14, 54, 36, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-13 03:02:10 UTC): No. That is generally bad idea to have `tests_common`  in `dev` (and this case shows why).

Dev is indeed replaced in CI when images - in ""checkout target commit"":

```bash
        echo
        echo -e ""\033[33m Replace scripts, dev, actions with target branch for non-committer builds!\033[0m""
        echo
        rm -rfv ""scripts/ci""
        rm -rfv ""dev""
        rm -rfv "".github/actions""
        rm -rfv "".github/workflows""
        mv -v ""target-airflow/scripts/ci"" ""scripts""
        mv -v ""target-airflow/dev"" "".""
        mv -v ""target-airflow/.github/actions"" ""target-airflow/.github/workflows"" "".github""
```

This is for security reason, so that any of the ""dev"" scripts that are used during CI and build process are not tampered with when they are modified in the incoming PR.

This is a bit of a teething problem after #42505 and you were the unlucky first non-committer who attempted to modify common test code that is shared between providers and airflow.

@ashb - we will have to find better place for ""tests_common"" than `dev` - because otherwise every non-commiter who wants to make a PR changing the ""common"" code they will get their ""dev/tests_common"" code overwritten.

Generally ""dev"" was always supposed to be used for ""build scripts"" but never by ""test code"".

How about just ""tests_common"" at the top level of the repository @ashb ?

gopidesupavan (Issue Creator) on (2024-10-13 03:07:54 UTC): Thanks jarek I agree , sorry for this :( previously it was in different location. So thought might be because of restructure it moved...

gopidesupavan (Issue Creator) on (2024-10-13 09:57:21 UTC): oops sorry have closed this, conversation is still open here. opening this pr, but merge is not required.

ashb on (2024-10-13 18:09:14 UTC): The reason I picked dev/ was cos I was trying to counter/not add to the proliferation of top level folders (there are more than I want/think there should be still). But I see that causes a problem now

ashb on (2024-10-13 18:14:07 UTC): In this specific case does the compat import need to be shared between core and provider tests?

I.e. yes dev/tests_common is the wrong place, but I'm not sure if we need import compat in the tests code do we? What is stopping us updating all the imports in tests? @gopidesupavan

ashb on (2024-10-13 18:40:40 UTC): @potiuk could we (safely) change dev/ to dev/breeze/ in that target pr part? I'm not sure what else actually lives in dev folder and am not at my computer right now

potiuk on (2024-10-13 19:00:04 UTC): Not really - dev is really a bag-of-all-things related to building our software - and it's a dangerous thing to only override part of it. There are a number of scripts that are there that are **likely** to be used in CI processes. This is for example why we have ""scripts/ci"" - because there I made sure (and I am reviewing that) that only CI scripts are used there).

The current content of `dev` is this (so there are a number of sub-folders - `breeze` is only one of them, and it's very likely some other scripts (`provider_packages` for example) are ""potentially dangerous"":

```
chart
example_dags
images
mypy
perf
provider_packages
stats
system_tests
templates
__init__.py
airflow-github
airflow-license
assign_cherry_picked_prs_with_milestone.py
check_files.py
CHERRY_PICK_SUMMARY.txt.jinja2
get_devel_deps.sh
ISSUE_TEMPLATE.md.jinja2
MANUALLY_BUILDING_IMAGES.md
MANUALLY_GENERATING_IMAGE_CACHE_AND_CONSTRAINTS.md
prepare_bulk_issues.py
PROJECT_GUIDELINES.md
PROVIDER_PACKAGE_DETAILS.md
README.md
README_RELEASE_AIRFLOW.md
README_RELEASE_HELM_CHART.md
README_RELEASE_PROVIDER_PACKAGES.md
README_RELEASE_PYTHON_CLIENT.md
refresh_images.sh
remove_artifacts.sh
requirements.txt
retag_docker_images.py
send_email.py
sign.sh
validate_version_added_fields_in_config.py
WHAT_GOES_INTO_THE_NEXT_RELEASE.md
```

And for example ""system_tests"" there is not something that ""system_tests"" use but some ""dev/build scripts"" that are related to system_tests.

We already had the issue when accidental typo or mistake cause https://medium.com/apache-airflow/unraveling-the-code-navigating-a-ci-release-security-vulnerability-in-apache-airflow-620214a96297 so I think it's better to be safe than sorry and exclude whole ""dev"" and designate it as ""build scripts"". 

Conceptually - if we look at that the ""common_tests"" belong to ""application"" not to ""building appplication"".

Ideally we should have something like that:

```
airflow_core/src
                airflow.<subpackages>
             tests
                airflow.<subpackages>
             pyproject.toml
airflow_common/
              tests_common.<subpackages>
              pyproject.toml
providers/
        airbyte/
              src
                 airflow.providers.arbyte.<subpackages> 
              tests
                 airflow.providers.arbyte.<subpackages> 
              pyproject.toml
``` 

But it would require the ""heavy"" airflow move. And maybe we can do it eventually after we split providers and go through all other teething problems.


But maybe let's do it step-by-step - moving to `tests_common` at top level would be a good intermediate step.

ashb on (2024-10-13 19:38:31 UTC): Yeah I thought they was likely the case but wanted to check.

I do plan on eventually moving airflow/ and tests/ into a new ""core"" workspace project, but absolutely one thing at a time.

gopidesupavan (Issue Creator) on (2024-10-13 19:48:50 UTC): Yeah currently its the pattern i see in the providers tests/ other places. adding imports in compat and using if any compatibility requires. 

At present i have workaround like this where ever i need to import doing this. 

```
try:
    from airflow.providers.standard.operators.python import PythonOperator
except ImportError:
    from airflow.operators.python import PythonOperator
```

This pr update not super important,  as have workaround to proceed python operator :)

potiuk on (2024-10-13 23:26:38 UTC): The PR to move tests_common in #42985.

potiuk on (2024-10-14 01:48:11 UTC): Yeah. that pattern is fine - just ""dev"" override is problematic and hopefully we will fix it soon with #42985

potiuk on (2024-10-15 02:44:16 UTC): You should be able to rebase your changes @gopidesupavan now and it **should** work normaly.

gopidesupavan (Issue Creator) on (2024-11-02 14:54:36 UTC): Closing this one as it resolved  #42985

"
2583581278,pull_request,closed,,Removed unicodecsv dependency for providers with Airflow version 2.8.…,"…0 and above (#42765)

(cherry picked from commit 00b8452b7526166b2918976b991aff1124d1a17c)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-13 02:39:54+00:00,[],2024-10-23 09:09:39+00:00,2024-10-15 02:46:50+00:00,https://github.com/apache/airflow/pull/42970,"[('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]","[{'comment_id': 2408793156, 'issue_id': 2583581278, 'author': 'potiuk', 'body': ""Cherry-picking https://github.com/apache/airflow/pull/42765 - unicodecsv is a **really** old dependency that has been removed from few of our providers some time ago and we really should not have it in airflow - but we had to add it for back-compatibility. It's highest time to remove it also in 2.10 branch."", 'created_at': datetime.datetime(2024, 10, 13, 2, 41, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408947552, 'issue_id': 2583581278, 'author': 'potiuk', 'body': 'Should be rebased after #42977 backport for looker/kiota has been merged.', 'created_at': datetime.datetime(2024, 10, 13, 11, 51, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408948064, 'issue_id': 2583581278, 'author': 'potiuk', 'body': 'Also related discussion #42969', 'created_at': datetime.datetime(2024, 10, 13, 11, 53, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409516209, 'issue_id': 2583581278, 'author': 'potiuk', 'body': 'Ready to be merged in v2-10-test', 'created_at': datetime.datetime(2024, 10, 14, 0, 47, 34, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-13 02:41:07 UTC): Cherry-picking https://github.com/apache/airflow/pull/42765 - unicodecsv is a **really** old dependency that has been removed from few of our providers some time ago and we really should not have it in airflow - but we had to add it for back-compatibility. It's highest time to remove it also in 2.10 branch.

potiuk (Issue Creator) on (2024-10-13 11:51:31 UTC): Should be rebased after #42977 backport for looker/kiota has been merged.

potiuk (Issue Creator) on (2024-10-13 11:53:17 UTC): Also related discussion #42969

potiuk (Issue Creator) on (2024-10-14 00:47:34 UTC): Ready to be merged in v2-10-test

"
2583530828,pull_request,closed,,Fix handling removal of dependencies,"There was a problem with CI image builds when cache has been disabled - they still used ""pre-cached"" main version (unlike PROD builds). This PR synchronizes the behaviour between CI and PROD builds.

For removing dependencies, you need to set both:

* `disable docker cache` label
* incerase DEPENDENCIES_EPOCH_NUMBER in `Dockerfile.ci`

Comments and documentation in both places has been updated to reflect it.

Since documentation for labels has been updated,
Part of this PR is to improve the description of possible labels that could be used during the build.
The description grew from a small number of labels to a ""wall of text"" that was difficult to read. This PR reformats it in the form of table that makes it far easier to see actions that the maintainer can do and what labels should be set for each of them.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-13 00:27:44+00:00,[],2024-11-01 13:12:18+00:00,2024-10-13 02:46:16+00:00,https://github.com/apache/airflow/pull/42967,"[('area:dev-tools', ''), ('disable image cache', 'Disables cache when buidling CI images')]","[{'comment_id': 2408766443, 'issue_id': 2583530828, 'author': 'potiuk', 'body': ""This is needed to properly test #42963 - complete package removal did not work properly ('--disable-airflow-repo-cache` and `--docker-cache` flag have not been properly passed."", 'created_at': datetime.datetime(2024, 10, 13, 0, 42, 41, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-13 00:42:41 UTC): This is needed to properly test #42963 - complete package removal did not work properly ('--disable-airflow-repo-cache` and `--docker-cache` flag have not been properly passed.

"
2583437269,pull_request,closed,,Add missed brackets for our dev script for Spell checks,"A nit PR while I was looking at our doc builds

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-12 21:43:40+00:00,[],2024-10-12 22:28:16+00:00,2024-10-12 21:55:27+00:00,https://github.com/apache/airflow/pull/42965,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2408708981, 'issue_id': 2583437269, 'author': 'potiuk', 'body': 'How did it even work :) ? I guess rich has some ""hack"" to make it works .', 'created_at': datetime.datetime(2024, 10, 12, 21, 48, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408710604, 'issue_id': 2583437269, 'author': 'kaxil', 'body': '> How did it even work :) ? I guess rich has some ""hack"" to make it works .\r\n\r\n😄  yeah, basically a no-op\r\n\r\n```python\r\nIn [1]: from rich.console import Console\r\nIn [3]: console = Console(force_terminal=True, color_system=""standard"")\r\nIn [4]: console.print()\r\nIn [5]: console.print\r\nOut[5]: <bound method Console.print of <console width=214 ColorSystem.STANDARD>>\r\n```', 'created_at': datetime.datetime(2024, 10, 12, 21, 55, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408717384, 'issue_id': 2583437269, 'author': 'potiuk', 'body': '> 😄 yeah, basically a no-op\r\n\r\nOh.... nice output that clutters logs.', 'created_at': datetime.datetime(2024, 10, 12, 22, 28, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-12 21:48:10 UTC): How did it even work :) ? I guess rich has some ""hack"" to make it works .

kaxil (Issue Creator) on (2024-10-12 21:55:07 UTC): 😄  yeah, basically a no-op

```python
In [1]: from rich.console import Console
In [3]: console = Console(force_terminal=True, color_system=""standard"")
In [4]: console.print()
In [5]: console.print
Out[5]: <bound method Console.print of <console width=214 ColorSystem.STANDARD>>
```

potiuk on (2024-10-12 22:28:15 UTC): Oh.... nice output that clutters logs.

"
2583284155,pull_request,closed,,Create a User Settings button with light/dark mode toggle as a menu item,"**Fixes Issue:** #42823 

This PR introduces a new **User Settings Menu** that allows users to toggle between light and dark themes, replacing the previous button in the navbar. 

**Overview of Changes:**

- Following the suggestion by @bbovenzi in [this comment](https://github.com/apache/airflow/issues/42823#issuecomment-2406840483), I have implemented a **UserSettingsButton.tsx** component. This new component is basically a menu with a user icon that has an item to change the theme.
- The menu is easily accessible within the navbar.

**Implementation Details:**

```javascript
<Menu placement=""right"">
  <MenuButton
    as={IconButton}
    icon={<FiUser size=""1.75rem"" />}
    {...navButtonProps}
  />
  <MenuList>
    <MenuItem onClick={toggleColorMode}>
      {colorMode === ""light"" ? (
        <>
          <FiMoon size=""1.25rem"" style={{ marginRight: ""8px"" }} />
          Switch to Dark Mode
        </>
      ) : (
        <>
          <FiSun size=""1.25rem"" style={{ marginRight: ""8px"" }} />
          Switch to Light Mode
        </>
      )}
    </MenuItem>
  </MenuList>
</Menu>
```

**Before and After:**

- **Before:** 

https://github.com/user-attachments/assets/23d88be7-a57c-404b-847c-601160800228
  
- **After:**

https://github.com/user-attachments/assets/a8614341-da5d-4d64-bbae-eacd7d5e716d

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",AryanK1511,2024-10-12 17:39:36+00:00,[],2024-10-15 15:12:54+00:00,2024-10-13 10:34:02+00:00,https://github.com/apache/airflow/pull/42964,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2408638990, 'issue_id': 2583284155, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 12, 17, 39, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408711026, 'issue_id': 2583284155, 'author': 'potiuk', 'body': ""Question: do we support `prefers-color-scheme` (as I understand this is the way to set default from system defaults) - many of the websites now choose the default mode based on system preferences (already supported in major OS's)?"", 'created_at': datetime.datetime(2024, 10, 12, 21, 57, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408922262, 'issue_id': 2583284155, 'author': 'jscheffl', 'body': ""> Question: do we support `prefers-color-scheme` (as I understand this is the way to set default from system defaults) - many of the websites now choose the default mode based on system preferences (already supported in major OS's)?\r\n\r\nI believe the auto-selection for furst time opening the UI is a different thing/story. This PR is just moving the settings into a new sub-menu."", 'created_at': datetime.datetime(2024, 10, 13, 10, 32, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408922597, 'issue_id': 2583284155, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 13, 10, 34, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414236519, 'issue_id': 2583284155, 'author': 'bbovenzi', 'body': ""> Question: do we support `prefers-color-scheme` (as I understand this is the way to set default from system defaults) - many of the websites now choose the default mode based on system preferences (already supported in major OS's)?\r\n\r\nPR fix: https://github.com/apache/airflow/pull/43041"", 'created_at': datetime.datetime(2024, 10, 15, 15, 12, 52, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-12 17:39:39 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-12 21:57:37 UTC): Question: do we support `prefers-color-scheme` (as I understand this is the way to set default from system defaults) - many of the websites now choose the default mode based on system preferences (already supported in major OS's)?

jscheffl on (2024-10-13 10:32:56 UTC): I believe the auto-selection for furst time opening the UI is a different thing/story. This PR is just moving the settings into a new sub-menu.

boring-cyborg[bot] on (2024-10-13 10:34:05 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

bbovenzi on (2024-10-15 15:12:52 UTC): PR fix: https://github.com/apache/airflow/pull/43041

"
2583243183,pull_request,closed,,Remove sqlalchemy-redshift dependency from Amazon provider,"`sqlalchemy-redshift` is unused. It is also not compatible with sqlalchemy>2, so good riddance!

Attempt no. 2 of #42830 after it got reverted in #42864
",ashb,2024-10-12 16:36:34+00:00,[],2024-10-25 17:09:45+00:00,2024-10-23 15:30:22+00:00,https://github.com/apache/airflow/pull/42963,"[('area:providers', ''), ('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('disable image cache', 'Disables cache when buidling CI images')]","[{'comment_id': 2408621393, 'issue_id': 2583243183, 'author': 'gopidesupavan', 'body': '@ashb is it possible to trigger full tests on this? The previous pr went through without any issues but later got issues when tests ran in ci. Thoughts?', 'created_at': datetime.datetime(2024, 10, 12, 16, 38, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408626503, 'issue_id': 2583243183, 'author': 'ashb', 'body': ""Yeah, I'm hoping by editing more files it'll trigger full tests. If that didn't work I was going to investigate ways of triggering full tests."", 'created_at': datetime.datetime(2024, 10, 12, 16, 58, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408687315, 'issue_id': 2583243183, 'author': 'potiuk', 'body': '> Yeah, I\'m hoping by editing more files it\'ll trigger full tests. If that didn\'t work I was going to investigate ways of triggering full tests.\r\n\r\nIt\'s a matter of setting ""full tests needed"" label and closing/reopen the PR. I just did it.\r\n\r\nBTW. All the ways maintainers can interact with PRs via labels are described in https://github.com/apache/airflow/blob/main/dev/breeze/doc/ci/07_debugging.md - it explains all the labels you can use and what effect they have.', 'created_at': datetime.datetime(2024, 10, 12, 20, 9, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408794621, 'issue_id': 2583243183, 'author': 'potiuk', 'body': 'Can\'t rebase it myself - but you should rebase now this PR after I merged the fix for ""package removal"" in #42967 and this time I guess it should properly not have the sqlalchemy-redshift installed in CI image .', 'created_at': datetime.datetime(2024, 10, 13, 2, 47, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409109261, 'issue_id': 2583243183, 'author': 'potiuk', 'body': 'Seems that this time it failed on `apt install` of mysql client ... Happens from time to time when cache is disabled - their repo is rather unstable. I re-run it.', 'created_at': datetime.datetime(2024, 10, 13, 20, 11, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409135371, 'issue_id': 2583243183, 'author': 'potiuk', 'body': ""OK. Now we got what we wanted. The PR with caching disabled (i.e. removing the dependency) shows that it is actually used and the tests using it failed - showing that the dependency is actually used in openlineage so actually we need to talk to @mobuchowski and @kacpermuda  and it's likely something related to #41632"", 'created_at': datetime.datetime(2024, 10, 13, 21, 19, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409135971, 'issue_id': 2583243183, 'author': 'potiuk', 'body': 'The root cause seem to be that openlineage uses ""redshift_connector"" as sqlalchemy dialect internally - and while direct import is not present anywhere, it expects the library to be present as it contributes the ""redshift_connector"" dialect.\r\n\r\nThis is why we **think** the dependency is not used, but in fact it is.', 'created_at': datetime.datetime(2024, 10, 13, 21, 21, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409137887, 'issue_id': 2583243183, 'author': 'potiuk', 'body': 'And if you look at the summary of ""Tests"" job, in the CI output, you will see that the redshift connector has been removed:\r\n\r\nhttps://github.com/apache/airflow/actions/runs/11314973292\r\n\r\nFor the future @ashb and others - just click on ""Tests"" in the list of checks and you will see the summary - which contains the diff in dependencies vs. `main` constraints - this is the `diff` vs. the last succesful `main` green build that pushed the constraints.\r\n\r\n<img width=""1135"" alt=""Screenshot 2024-10-13 at 23 25 08"" src=""https://github.com/user-attachments/assets/adfff12f-cae0-43ae-af54-2e81ef012d49"">', 'created_at': datetime.datetime(2024, 10, 13, 21, 27, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410860673, 'issue_id': 2583243183, 'author': 'mobuchowski', 'body': '>The root cause seem to be that openlineage uses ""redshift_connector"" as sqlalchemy dialect internally - and while direct import is not present anywhere, it expects the library to be present as it contributes the ""redshift_connector"" dialect.\r\n\r\n>This is why we think the dependency is not used, but in fact it is.\r\n\r\nExactly, we use it to generate queries fitting the right db. We\'ve migrated to this approach from [earlier approach when we manually slapped SQL together via string concatenation.](https://github.com/OpenLineage/OpenLineage/blob/main/integration/airflow/openlineage/airflow/extractors/dbapi_utils.py#L111)\r\n\r\nIMO what could work is [moving Redshift hook to use Postgres dialect](https://github.com/apache/airflow/blob/857ca4c06c9008593674cabdd28d3c30e3e7f97b/providers/src/airflow/providers/amazon/aws/hooks/redshift_sql.py#L166) - unless there is something breaking using Postgres dialect from working with Redshift now; it was used for this purpose before actual Redshift dialect.\r\n\r\nBTW, IMO the fact that there are no tests other than OL breaking from this means that the `get_sqlalchemy_engine` for Redshift isn\'t tested, not that only OL uses Redshift dialect:\r\n\r\n```\r\n    def get_uri(self) -> str:\r\n        """"""Overridden to use the Redshift dialect as driver name.""""""\r\n        conn_params = self._get_conn_params()\r\n\r\n        if ""user"" in conn_params:\r\n            conn_params[""username""] = conn_params.pop(""user"")\r\n\r\n        # Compatibility: The \'create\' factory method was added in SQLAlchemy 1.4\r\n        # to replace calling the default URL constructor directly.\r\n        create_url = getattr(URL, ""create"", URL)\r\n        return str(create_url(drivername=""redshift+redshift_connector"", **conn_params))\r\n```', 'created_at': datetime.datetime(2024, 10, 14, 10, 57, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416371360, 'issue_id': 2583243183, 'author': 'ashb', 'body': ""@mobuchowski The hook itself doesn't use the SQLa get engine: https://github.com/apache/airflow/blob/e20146d44b340f719f7fb432f93741e011690558/providers/src/airflow/providers/amazon/aws/hooks/redshift_sql.py#L203-L208 (at least if I'm following the code right. Very possibly I'm not)\r\n\r\nSo this is a problem only for the OL integration I think.\r\n\r\nWe need to move away fro this sqla redshift integration as it doesn't support 2.0. Can you please take this on with some urgency please?"", 'created_at': datetime.datetime(2024, 10, 16, 10, 20, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416535141, 'issue_id': 2583243183, 'author': 'mobuchowski', 'body': ""@ashb sure, I'll own that topic."", 'created_at': datetime.datetime(2024, 10, 16, 11, 30, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432632321, 'issue_id': 2583243183, 'author': 'mobuchowski', 'body': 'Merged in https://github.com/apache/airflow/pull/43271', 'created_at': datetime.datetime(2024, 10, 23, 15, 30, 22, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-12 16:38:48 UTC): @ashb is it possible to trigger full tests on this? The previous pr went through without any issues but later got issues when tests ran in ci. Thoughts?

ashb (Issue Creator) on (2024-10-12 16:58:03 UTC): Yeah, I'm hoping by editing more files it'll trigger full tests. If that didn't work I was going to investigate ways of triggering full tests.

potiuk on (2024-10-12 20:09:50 UTC): It's a matter of setting ""full tests needed"" label and closing/reopen the PR. I just did it.

BTW. All the ways maintainers can interact with PRs via labels are described in https://github.com/apache/airflow/blob/main/dev/breeze/doc/ci/07_debugging.md - it explains all the labels you can use and what effect they have.

potiuk on (2024-10-13 02:47:48 UTC): Can't rebase it myself - but you should rebase now this PR after I merged the fix for ""package removal"" in #42967 and this time I guess it should properly not have the sqlalchemy-redshift installed in CI image .

potiuk on (2024-10-13 20:11:17 UTC): Seems that this time it failed on `apt install` of mysql client ... Happens from time to time when cache is disabled - their repo is rather unstable. I re-run it.

potiuk on (2024-10-13 21:19:37 UTC): OK. Now we got what we wanted. The PR with caching disabled (i.e. removing the dependency) shows that it is actually used and the tests using it failed - showing that the dependency is actually used in openlineage so actually we need to talk to @mobuchowski and @kacpermuda  and it's likely something related to #41632

potiuk on (2024-10-13 21:21:25 UTC): The root cause seem to be that openlineage uses ""redshift_connector"" as sqlalchemy dialect internally - and while direct import is not present anywhere, it expects the library to be present as it contributes the ""redshift_connector"" dialect.

This is why we **think** the dependency is not used, but in fact it is.

potiuk on (2024-10-13 21:27:39 UTC): And if you look at the summary of ""Tests"" job, in the CI output, you will see that the redshift connector has been removed:

https://github.com/apache/airflow/actions/runs/11314973292

For the future @ashb and others - just click on ""Tests"" in the list of checks and you will see the summary - which contains the diff in dependencies vs. `main` constraints - this is the `diff` vs. the last succesful `main` green build that pushed the constraints.

<img width=""1135"" alt=""Screenshot 2024-10-13 at 23 25 08"" src=""https://github.com/user-attachments/assets/adfff12f-cae0-43ae-af54-2e81ef012d49"">

mobuchowski on (2024-10-14 10:57:16 UTC): Exactly, we use it to generate queries fitting the right db. We've migrated to this approach from [earlier approach when we manually slapped SQL together via string concatenation.](https://github.com/OpenLineage/OpenLineage/blob/main/integration/airflow/openlineage/airflow/extractors/dbapi_utils.py#L111)

IMO what could work is [moving Redshift hook to use Postgres dialect](https://github.com/apache/airflow/blob/857ca4c06c9008593674cabdd28d3c30e3e7f97b/providers/src/airflow/providers/amazon/aws/hooks/redshift_sql.py#L166) - unless there is something breaking using Postgres dialect from working with Redshift now; it was used for this purpose before actual Redshift dialect.

BTW, IMO the fact that there are no tests other than OL breaking from this means that the `get_sqlalchemy_engine` for Redshift isn't tested, not that only OL uses Redshift dialect:

```
    def get_uri(self) -> str:
        """"""Overridden to use the Redshift dialect as driver name.""""""
        conn_params = self._get_conn_params()

        if ""user"" in conn_params:
            conn_params[""username""] = conn_params.pop(""user"")

        # Compatibility: The 'create' factory method was added in SQLAlchemy 1.4
        # to replace calling the default URL constructor directly.
        create_url = getattr(URL, ""create"", URL)
        return str(create_url(drivername=""redshift+redshift_connector"", **conn_params))
```

ashb (Issue Creator) on (2024-10-16 10:20:04 UTC): @mobuchowski The hook itself doesn't use the SQLa get engine: https://github.com/apache/airflow/blob/e20146d44b340f719f7fb432f93741e011690558/providers/src/airflow/providers/amazon/aws/hooks/redshift_sql.py#L203-L208 (at least if I'm following the code right. Very possibly I'm not)

So this is a problem only for the OL integration I think.

We need to move away fro this sqla redshift integration as it doesn't support 2.0. Can you please take this on with some urgency please?

mobuchowski on (2024-10-16 11:30:50 UTC): @ashb sure, I'll own that topic.

mobuchowski on (2024-10-23 15:30:22 UTC): Merged in https://github.com/apache/airflow/pull/43271

"
2583213558,pull_request,closed,,Upgrade Trove classifier to `2024.10.12`,"Test was failing: https://github.com/apache/airflow/actions/runs/11306055404/job/31446236535

```
pre-commit hook(s) made changes.
If you are seeing this message in CI, reproduce locally with: `pre-commit run --all-files`.
To run `pre-commit` as part of git workflow, use `pre-commit install`.
All changes made by hooks:
diff --git a/pyproject.toml b/pyproject.toml
index 844e1b6..5e9f587 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -30,7 +30,7 @@ requires = [
     ""pluggy==1.5.0"",
     ""smmap==5.0.1"",
     ""tomli==2.0.2; python_version < '3.11'"",
-    ""trove-classifiers==2024.10.11"",
+    ""trove-classifiers==2024.10.12"",
 ]
 build-backend = ""hatchling.build""
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-12 15:53:53+00:00,[],2024-10-12 16:34:00+00:00,2024-10-12 16:33:59+00:00,https://github.com/apache/airflow/pull/42961,[],"[{'comment_id': 2408608534, 'issue_id': 2583213558, 'author': 'kaxil', 'body': 'This should fix failing main', 'created_at': datetime.datetime(2024, 10, 12, 15, 54, 29, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-10-12 15:54:29 UTC): This should fix failing main

"
2582940363,pull_request,closed,,fix: use instance base_container_name to fetch logs on trigger_reentry,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Ensures that self.pod_manager.fetch_container_logs use instance-level self.base_container_name instead of BASE_CONTAINER_NAME.

Revival of https://github.com/apache/airflow/pull/40835

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",peloyeje,2024-10-12 12:28:15+00:00,[],2024-10-12 14:28:31+00:00,2024-10-12 14:28:31+00:00,https://github.com/apache/airflow/pull/42960,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2408555365, 'issue_id': 2582940363, 'author': 'peloyeje', 'body': ""@eladkal @romsharon98 @hussein-awala here's an rebased version of https://github.com/apache/airflow/pull/40835 with fixed tests\r\nApologies for the delay"", 'created_at': datetime.datetime(2024, 10, 12, 12, 55, 53, tzinfo=datetime.timezone.utc)}]","peloyeje (Issue Creator) on (2024-10-12 12:55:53 UTC): @eladkal @romsharon98 @hussein-awala here's an rebased version of https://github.com/apache/airflow/pull/40835 with fixed tests
Apologies for the delay

"
2582483424,pull_request,closed,,AIP-84 | Public list tags API,"
closes: #42713

Migrate from https://github.com/apache/airflow//blob/main/airflow/www/views.py#L1035-L1038 ",jason810496,2024-10-12 04:16:19+00:00,[],2024-10-21 09:23:29+00:00,2024-10-21 09:23:14+00:00,https://github.com/apache/airflow/pull/42959,"[('area:API', ""Airflow's REST/HTTP API""), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2408425067, 'issue_id': 2582483424, 'author': 'jason810496', 'body': 'Hi, this PR should be marked with the `area:API` label instead of `area:UI`. The bot automatically marked it with `area:UI` because the pre-commit process auto-generates the frontend code using OpenAPI. Thanks!', 'created_at': datetime.datetime(2024, 10, 12, 6, 51, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408470999, 'issue_id': 2582483424, 'author': 'jscheffl', 'body': 'Thanks for the contribution! w/o having a full review I assume you should mark the legacy API as being migrated like e.g. in https://github.com/apache/airflow/pull/42798/files#diff-df829fc289eeca0e932974a5110a8f2c21b1962e87db7c3a3b44dacf084f54a1R47 ?', 'created_at': datetime.datetime(2024, 10, 12, 9, 15, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408527674, 'issue_id': 2582483424, 'author': 'jason810496', 'body': ""Hi @jscheffl, since this API is migrated from the home view in `airflow/www/views.py,` and `dag_tags` is just a small part of the home view, I'm not sure if this is the only endpoint that needs to be migrated from the home view. @bbovenzi, do you have any insights on this?"", 'created_at': datetime.datetime(2024, 10, 12, 11, 19, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408925816, 'issue_id': 2582483424, 'author': 'jscheffl', 'body': ""> Hi @jscheffl, since this API is migrated from the home view in `airflow/www/views.py,` and `dag_tags` is just a small part of the home view, I'm not sure if this is the only endpoint that needs to be migrated from the home view. @bbovenzi, do you have any insights on this?\r\n\r\nOkay, then if this is _not_ a migration we should clarify if this really should get to be a public API. I'd think if it is used only in one place in the new UI then we should not make it a new public API. As there are other public APIs to retrieve the sme information (https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_dag_details)"", 'created_at': datetime.datetime(2024, 10, 13, 10, 42, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408934817, 'issue_id': 2582483424, 'author': 'jason810496', 'body': 'Sure, that makes sense. I’ll go ahead and move this endpoint to the UI folder.', 'created_at': datetime.datetime(2024, 10, 13, 11, 11, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411266728, 'issue_id': 2582483424, 'author': 'pierrejeambrun', 'body': ""> Okay, then if this is not a migration we should clarify if this really should get to be a public API. I'd think if it is used only in one place in the new UI then we should not make it a new public API. As there are other public APIs to retrieve the sme information (https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_dag_details)\r\n\r\nI think this is a good addition to the public API because currently there is no way for a user to be able to retrieve all the `tags` available for filtering for instance. This was done in the legacy UI through custom views.\r\n\r\nMeaning that users of the API would have to know in advance tags to effectively filter on them."", 'created_at': datetime.datetime(2024, 10, 14, 13, 24, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411843424, 'issue_id': 2582483424, 'author': 'jason810496', 'body': 'Based on all the above input, I believe the original intention of issue https://github.com/apache/airflow/issues/42713 is to provide an endpoint to retrieve all tags across all DAGs for advanced filtering functionalities. I agree with the last comment by @pierrejeambrun, so this endpoint should remain in the `public` folder. However, I think the response schema should be:\r\n\r\n```json\r\n{\r\n  ""tags"": [""tag_1"", ""tag_2""],\r\n  ""total_entries"": 2\r\n}\r\n```\r\n\r\nAdditionally, the endpoint should support `offset` and `limit` query parameters, as mentioned by @rawwar in the issue. This way, the `get_dag_tags` endpoint can use the same query parameters and a similar response schema as other public endpoints , as well as [`paginated_select`](https://github.com/apache/airflow/blob/b92c66d45d206c670516f192662bfcf8ad34bec8/airflow/api_fastapi/views/public/dags.py#L78) on the backend.\r\n\r\nPlease correct me if I have misunderstood anything. Thanks !', 'created_at': datetime.datetime(2024, 10, 14, 17, 25, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413206051, 'issue_id': 2582483424, 'author': 'pierrejeambrun', 'body': 'I think the response could be:\r\n\r\n```\r\n{\r\n  ""tags"": [{""tag_name: ""tag_1"", ""dag_id"": ""some_dag_id""}, {""tag_name"": ""tag_2"", ""dag_id"": ""some_dag_id""}],\r\n  ""total_entries"": 2\r\n}\r\n```\r\n\r\nBasically we return serialized `DagTag` in the response field.', 'created_at': datetime.datetime(2024, 10, 15, 8, 18, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413780543, 'issue_id': 2582483424, 'author': 'bbovenzi', 'body': '> I think the response could be:\r\n> \r\n> ```\r\n> {\r\n>   ""tags"": [{""tag_name: ""tag_1"", ""dag_id"": ""some_dag_id""}, {""tag_name"": ""tag_2"", ""dag_id"": ""some_dag_id""}],\r\n>   ""total_entries"": 2\r\n> }\r\n> ```\r\n> \r\n> Basically we return serialized `DagTag` in the response field.\r\n\r\nIs `dag_id` actually valuable information though? The whole point is that multiple dags share tags, so only showing a single dag_id doesn\'t help anyone. I actually prefer the list of tag_name strings.', 'created_at': datetime.datetime(2024, 10, 15, 12, 29, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415212522, 'issue_id': 2582483424, 'author': 'pierrejeambrun', 'body': 'I’ll check the db modelling tomorrow, something I might have missesed. I suggested that dag_id was there because that’s how the sqlalchemy model is defined.\r\n\r\nBut indeed from a business point of view this does not make sense. \r\n\r\nBut on the other hand the name is the primary key and unique, so I guess there is something I need to double check.', 'created_at': datetime.datetime(2024, 10, 15, 21, 37, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416657044, 'issue_id': 2582483424, 'author': 'jason810496', 'body': '### Update:\r\n\r\nThe endpoint is placed in the `public` folder and supports the following query parameters:\r\n- `tag_name_pattern`: `_SearchParam`\r\n- `order_by`: `_OrderByParam` \r\n- `limit`: `QueryLimit` \r\n- `offset`: `QueryOffset`\r\n\r\nExample of the response schema:\r\n```json\r\n{\r\n    ""tags"": [""tag_1"", ""tag_2""],\r\n    ""total_entries"": 3\r\n}\r\n```\r\n\r\nFor the SQL statement, the `name` field should still include `DISTINCT` since there may be rows like:\r\n```\r\nsame_tag_name, dag_id_1\r\nsame_tag_name, dag_id_2\r\n```\r\nWhile the `name` field with the `dag_id` field creates a unique pair, the `name` field itself may have duplicates in the query results.\r\n\r\n### Feature: [`_OrderByParam`](https://github.com/apache/airflow/pull/42959/files#diff-277d63472fe1047f168e55a455ce2868415348d0d3afc397a2832e3b3f6ba81eR132) - New query parameter for ordering by a field.\r\n- `order_by`: `asc`, `desc`\r\n- Ordering by a single field (This could be useful for models with only a few fields, where typically sorting by a single field is sufficient.)', 'created_at': datetime.datetime(2024, 10, 16, 12, 16, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2416817655, 'issue_id': 2582483424, 'author': 'kaxil', 'body': 'You will have to rebase and fix conflicts as we change how `fastapi_api` folder is organized here: https://github.com/apache/airflow/pull/43062', 'created_at': datetime.datetime(2024, 10, 16, 13, 17, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422749143, 'issue_id': 2582483424, 'author': 'jason810496', 'body': '### Update:\r\nHi @pierrejeambrun, the `group_by` resolved the issue. Thanks!\r\n\r\n### Refactor: `SortParm`\r\n- Moved `attr_mapping` to the `__init__` parameter (since `SortParm` is used by different endpoints).\r\n- Consolidated `allow_attr` with `attr_mapping` (we can use `attr_mapping` to validate the query parameters).\r\n- Added `default_attr` (for models with multiple primary keys, like `DagTag`, the original `get_primary_key_column` might not be the column we want to sort by. With `default_attr`, we can specify the default field for sorting).', 'created_at': datetime.datetime(2024, 10, 18, 15, 37, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422787004, 'issue_id': 2582483424, 'author': 'pierrejeambrun', 'body': 'Thanks @jason810496, Do you mind putting the refactoring part into its own PR so it does not block this one.', 'created_at': datetime.datetime(2024, 10, 18, 15, 57, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422798215, 'issue_id': 2582483424, 'author': 'jason810496', 'body': '> Thanks @jason810496, Do you mind putting the refactoring part into its own PR so it does not block this one.\r\n\r\n\r\nSure, so I should create a new branch on top of the current commit and rebase the current branch.\r\nAfter the current PR is merged, I will create a PR for refactoring `SortParm` from the new branch.\r\nIs that correct?', 'created_at': datetime.datetime(2024, 10, 18, 16, 4, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422818195, 'issue_id': 2582483424, 'author': 'pierrejeambrun', 'body': 'Yes, you can checkout another branch from here (full with refactoring). Then in this branch you can drop them (the refactoring part)', 'created_at': datetime.datetime(2024, 10, 18, 16, 15, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422882933, 'issue_id': 2582483424, 'author': 'jason810496', 'body': 'Resolved! I have removed the refactoring part.', 'created_at': datetime.datetime(2024, 10, 18, 16, 57, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426106210, 'issue_id': 2582483424, 'author': 'pierrejeambrun', 'body': 'Unrelated CI failure, merging.\r\n\r\nThanks @jason810496', 'created_at': datetime.datetime(2024, 10, 21, 9, 23, 21, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-10-12 06:51:22 UTC): Hi, this PR should be marked with the `area:API` label instead of `area:UI`. The bot automatically marked it with `area:UI` because the pre-commit process auto-generates the frontend code using OpenAPI. Thanks!

jscheffl on (2024-10-12 09:15:51 UTC): Thanks for the contribution! w/o having a full review I assume you should mark the legacy API as being migrated like e.g. in https://github.com/apache/airflow/pull/42798/files#diff-df829fc289eeca0e932974a5110a8f2c21b1962e87db7c3a3b44dacf084f54a1R47 ?

jason810496 (Issue Creator) on (2024-10-12 11:19:58 UTC): Hi @jscheffl, since this API is migrated from the home view in `airflow/www/views.py,` and `dag_tags` is just a small part of the home view, I'm not sure if this is the only endpoint that needs to be migrated from the home view. @bbovenzi, do you have any insights on this?

jscheffl on (2024-10-13 10:42:57 UTC): Okay, then if this is _not_ a migration we should clarify if this really should get to be a public API. I'd think if it is used only in one place in the new UI then we should not make it a new public API. As there are other public APIs to retrieve the sme information (https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_dag_details)

jason810496 (Issue Creator) on (2024-10-13 11:11:10 UTC): Sure, that makes sense. I’ll go ahead and move this endpoint to the UI folder.

pierrejeambrun on (2024-10-14 13:24:15 UTC): I think this is a good addition to the public API because currently there is no way for a user to be able to retrieve all the `tags` available for filtering for instance. This was done in the legacy UI through custom views.

Meaning that users of the API would have to know in advance tags to effectively filter on them.

jason810496 (Issue Creator) on (2024-10-14 17:25:07 UTC): Based on all the above input, I believe the original intention of issue https://github.com/apache/airflow/issues/42713 is to provide an endpoint to retrieve all tags across all DAGs for advanced filtering functionalities. I agree with the last comment by @pierrejeambrun, so this endpoint should remain in the `public` folder. However, I think the response schema should be:

```json
{
  ""tags"": [""tag_1"", ""tag_2""],
  ""total_entries"": 2
}
```

Additionally, the endpoint should support `offset` and `limit` query parameters, as mentioned by @rawwar in the issue. This way, the `get_dag_tags` endpoint can use the same query parameters and a similar response schema as other public endpoints , as well as [`paginated_select`](https://github.com/apache/airflow/blob/b92c66d45d206c670516f192662bfcf8ad34bec8/airflow/api_fastapi/views/public/dags.py#L78) on the backend.

Please correct me if I have misunderstood anything. Thanks !

pierrejeambrun on (2024-10-15 08:18:54 UTC): I think the response could be:

```
{
  ""tags"": [{""tag_name: ""tag_1"", ""dag_id"": ""some_dag_id""}, {""tag_name"": ""tag_2"", ""dag_id"": ""some_dag_id""}],
  ""total_entries"": 2
}
```

Basically we return serialized `DagTag` in the response field.

bbovenzi on (2024-10-15 12:29:29 UTC): Is `dag_id` actually valuable information though? The whole point is that multiple dags share tags, so only showing a single dag_id doesn't help anyone. I actually prefer the list of tag_name strings.

pierrejeambrun on (2024-10-15 21:37:55 UTC): I’ll check the db modelling tomorrow, something I might have missesed. I suggested that dag_id was there because that’s how the sqlalchemy model is defined.

But indeed from a business point of view this does not make sense. 

But on the other hand the name is the primary key and unique, so I guess there is something I need to double check.

jason810496 (Issue Creator) on (2024-10-16 12:16:36 UTC): ### Update:

The endpoint is placed in the `public` folder and supports the following query parameters:
- `tag_name_pattern`: `_SearchParam`
- `order_by`: `_OrderByParam` 
- `limit`: `QueryLimit` 
- `offset`: `QueryOffset`

Example of the response schema:
```json
{
    ""tags"": [""tag_1"", ""tag_2""],
    ""total_entries"": 3
}
```

For the SQL statement, the `name` field should still include `DISTINCT` since there may be rows like:
```
same_tag_name, dag_id_1
same_tag_name, dag_id_2
```
While the `name` field with the `dag_id` field creates a unique pair, the `name` field itself may have duplicates in the query results.

### Feature: [`_OrderByParam`](https://github.com/apache/airflow/pull/42959/files#diff-277d63472fe1047f168e55a455ce2868415348d0d3afc397a2832e3b3f6ba81eR132) - New query parameter for ordering by a field.
- `order_by`: `asc`, `desc`
- Ordering by a single field (This could be useful for models with only a few fields, where typically sorting by a single field is sufficient.)

kaxil on (2024-10-16 13:17:58 UTC): You will have to rebase and fix conflicts as we change how `fastapi_api` folder is organized here: https://github.com/apache/airflow/pull/43062

jason810496 (Issue Creator) on (2024-10-18 15:37:12 UTC): ### Update:
Hi @pierrejeambrun, the `group_by` resolved the issue. Thanks!

### Refactor: `SortParm`
- Moved `attr_mapping` to the `__init__` parameter (since `SortParm` is used by different endpoints).
- Consolidated `allow_attr` with `attr_mapping` (we can use `attr_mapping` to validate the query parameters).
- Added `default_attr` (for models with multiple primary keys, like `DagTag`, the original `get_primary_key_column` might not be the column we want to sort by. With `default_attr`, we can specify the default field for sorting).

pierrejeambrun on (2024-10-18 15:57:55 UTC): Thanks @jason810496, Do you mind putting the refactoring part into its own PR so it does not block this one.

jason810496 (Issue Creator) on (2024-10-18 16:04:27 UTC): Sure, so I should create a new branch on top of the current commit and rebase the current branch.
After the current PR is merged, I will create a PR for refactoring `SortParm` from the new branch.
Is that correct?

pierrejeambrun on (2024-10-18 16:15:38 UTC): Yes, you can checkout another branch from here (full with refactoring). Then in this branch you can drop them (the refactoring part)

jason810496 (Issue Creator) on (2024-10-18 16:57:15 UTC): Resolved! I have removed the refactoring part.

pierrejeambrun on (2024-10-21 09:23:21 UTC): Unrelated CI failure, merging.

Thanks @jason810496

"
2582430497,pull_request,closed,,Fix broken links in Release Management docs,"These links were pointing to the wrong location. This PR fixes it

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-12 02:43:30+00:00,[],2024-10-12 13:43:29+00:00,2024-10-12 05:21:07+00:00,https://github.com/apache/airflow/pull/42958,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2581991708,pull_request,closed,,"Fix broken canary, update trove-classifiers",Fix broken canary in https://github.com/apache/airflow/actions/runs/11293316916/job/31411223490,jscheffl,2024-10-11 18:48:47+00:00,[],2024-10-11 18:49:52+00:00,2024-10-11 18:49:48+00:00,https://github.com/apache/airflow/pull/42956,[],"[{'comment_id': 2407958411, 'issue_id': 2581991708, 'author': 'jscheffl', 'body': 'Duplicate of #42950', 'created_at': datetime.datetime(2024, 10, 11, 18, 49, 48, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-10-11 18:49:48 UTC): Duplicate of #42950

"
2581988719,pull_request,closed,,Make datStats endpoint dag_ids parameter optional,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #41495

Makes the dag_ids parameter optional in the dagStats endpoint. If not provided, the endpoint returns stats for all DAGs in a paginated result set.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",michaeljs-c,2024-10-11 18:46:26+00:00,[],2024-10-13 12:57:55+00:00,2024-10-13 12:57:51+00:00,https://github.com/apache/airflow/pull/42955,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2407953748, 'issue_id': 2581988719, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 11, 18, 46, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408970415, 'issue_id': 2581988719, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 13, 12, 57, 54, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-11 18:46:30 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-13 12:57:54 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2581956346,pull_request,closed,,Restrict looker-sdk version 24.18.0 and microsoft-kiota-http 1.3.4,"The latest looker-sdk version causing import problems in our CI. so restricting 24.18.0 looker-sdk version.

https://github.com/apache/airflow/actions/runs/11295803154/job/31419668010?pr=42950#step:14:1642 

There issue already opened here: https://github.com/looker-open-source/sdk-codegen/issues/1518
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-11 18:27:54+00:00,[],2024-11-23 19:54:44+00:00,2024-10-12 07:47:57+00:00,https://github.com/apache/airflow/pull/42954,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2408062908, 'issue_id': 2581956346, 'author': 'gopidesupavan', 'body': 'microsoft provider tests are failing due to import errors, its because of the latest microsoft-kiota-http release. and in microsoft provider using msgraph_core (this internally uses kiota-http) causing issues.', 'created_at': datetime.datetime(2024, 10, 11, 20, 12, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408077031, 'issue_id': 2581956346, 'author': 'gopidesupavan', 'body': 'Is there any place we can restrict the pip versions which are indirectly installed, in this case kiota-http is using inside msgraph_core, how to restrict pip version?', 'created_at': datetime.datetime(2024, 10, 11, 20, 24, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408100167, 'issue_id': 2581956346, 'author': 'gopidesupavan', 'body': 'not sure whether update microsoft-kiota-http pip version works or not , but i am trying out.', 'created_at': datetime.datetime(2024, 10, 11, 20, 46, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408126334, 'issue_id': 2581956346, 'author': 'potiuk', 'body': '> Is there any place we can restrict the pip versions which are indirectly installed, in this case kiota-http is using inside msgraph_core, how to restrict pip version?\r\n\r\nIt\'s a bit case-by-case.\r\n\r\nUsually it is ok to add such transitive dependency directly to provider as additional dependency - we\'ve done that a number of times in the past - also it is often accompanied by an issue to the upstream project to let them know they have incompatibility and suggest to add similar transitive dependency in their package.  What you\'ve done here is following that and is a valid approach.\r\n\r\nHowever, often it turns out, that such ""transitive dependency"" limit is already added in a newer version of our direct dependency - but only in one of the latest versions and `uv` or `pip` do not resolve the latest version automatically - in such case we can also bump minimum version of such direct dependency. But this is really something that rquires to take a close look at history of changes in dependencies of such dependencies and understanding them.', 'created_at': datetime.datetime(2024, 10, 11, 21, 12, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408126742, 'issue_id': 2581956346, 'author': 'potiuk', 'body': 'Thanks for the fix @gopidesupavan BTW :)', 'created_at': datetime.datetime(2024, 10, 11, 21, 12, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408212713, 'issue_id': 2581956346, 'author': 'gopidesupavan', 'body': 'Thanks @potiuk  😄 , updated the issue ids to provider yaml.', 'created_at': datetime.datetime(2024, 10, 11, 22, 51, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408253134, 'issue_id': 2581956346, 'author': 'gopidesupavan', 'body': 'mypy-provider check for appflow not satisfying, not sure might be cache issue..', 'created_at': datetime.datetime(2024, 10, 12, 0, 5, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408442327, 'issue_id': 2581956346, 'author': 'gopidesupavan', 'body': 'Can this be merged please? One test is failing, it looks like flaky test, will have a look and check-in separate pr', 'created_at': datetime.datetime(2024, 10, 12, 7, 38, 40, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-11 20:12:33 UTC): microsoft provider tests are failing due to import errors, its because of the latest microsoft-kiota-http release. and in microsoft provider using msgraph_core (this internally uses kiota-http) causing issues.

gopidesupavan (Issue Creator) on (2024-10-11 20:24:56 UTC): Is there any place we can restrict the pip versions which are indirectly installed, in this case kiota-http is using inside msgraph_core, how to restrict pip version?

gopidesupavan (Issue Creator) on (2024-10-11 20:46:15 UTC): not sure whether update microsoft-kiota-http pip version works or not , but i am trying out.

potiuk on (2024-10-11 21:12:06 UTC): It's a bit case-by-case.

Usually it is ok to add such transitive dependency directly to provider as additional dependency - we've done that a number of times in the past - also it is often accompanied by an issue to the upstream project to let them know they have incompatibility and suggest to add similar transitive dependency in their package.  What you've done here is following that and is a valid approach.

However, often it turns out, that such ""transitive dependency"" limit is already added in a newer version of our direct dependency - but only in one of the latest versions and `uv` or `pip` do not resolve the latest version automatically - in such case we can also bump minimum version of such direct dependency. But this is really something that rquires to take a close look at history of changes in dependencies of such dependencies and understanding them.

potiuk on (2024-10-11 21:12:34 UTC): Thanks for the fix @gopidesupavan BTW :)

gopidesupavan (Issue Creator) on (2024-10-11 22:51:46 UTC): Thanks @potiuk  😄 , updated the issue ids to provider yaml.

gopidesupavan (Issue Creator) on (2024-10-12 00:05:22 UTC): mypy-provider check for appflow not satisfying, not sure might be cache issue..

gopidesupavan (Issue Creator) on (2024-10-12 07:38:40 UTC): Can this be merged please? One test is failing, it looks like flaky test, will have a look and check-in separate pr

"
2581864866,pull_request,closed,,Max active tasks to be evaluated per dag run,"Pursuant to mailing list vote, this PR changes meaning of DAG.max_active_tasks from ""per dag"" to ""per dag run""

Vote thread: https://lists.apache.org/thread/9o84d3yn934m32gtlpokpwtbbmtxj47l",dstandish,2024-10-11 17:31:00+00:00,[],2024-10-17 21:07:55+00:00,2024-10-17 21:07:54+00:00,https://github.com/apache/airflow/pull/42953,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2420560515, 'issue_id': 2581864866, 'author': 'ephraimbuddy', 'body': 'Should the config change to `max_active_tasks_per_dagrun`?', 'created_at': datetime.datetime(2024, 10, 17, 20, 57, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420574663, 'issue_id': 2581864866, 'author': 'dstandish', 'body': ""> Should the config change to `max_active_tasks_per_dagrun`?\r\n\r\nYou know it was unspecified before, and remains unspecified now.  Personally, I like the brevity of it how it is.  I feel when the params are super long it's harder to understand and worse user experience.\r\n\r\nOf course the question of naming can be revisited between now and 3.0"", 'created_at': datetime.datetime(2024, 10, 17, 21, 6, 28, tzinfo=datetime.timezone.utc)}]","ephraimbuddy on (2024-10-17 20:57:31 UTC): Should the config change to `max_active_tasks_per_dagrun`?

dstandish (Issue Creator) on (2024-10-17 21:06:28 UTC): You know it was unspecified before, and remains unspecified now.  Personally, I like the brevity of it how it is.  I feel when the params are super long it's harder to understand and worse user experience.

Of course the question of naming can be revisited between now and 3.0

"
2581863156,pull_request,closed,,Fix SNOWFLAKE_CONN_ID and DAG_ID in Snowpark system tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fix SNOWFLAKE_CONN_ID and DAG_ID so a dashboard for running snowflake system tests can be built

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sfc-gh-jdu,2024-10-11 17:29:58+00:00,[],2024-10-12 00:41:32+00:00,2024-10-12 00:41:32+00:00,https://github.com/apache/airflow/pull/42952,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]",[],
2581804438,pull_request,closed,,Enable explicit namespaces,"The recent PR to reorganize the package requires a change to explicit namespaces for at least some IDEs (PyCharm for sure, possibly others).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-10-11 16:52:29+00:00,[],2024-10-16 14:33:12+00:00,2024-10-16 11:38:27+00:00,https://github.com/apache/airflow/pull/42951,"[('area:providers', '')]","[{'comment_id': 2408114487, 'issue_id': 2581804438, 'author': 'gopidesupavan', 'body': '@ferruzzi Just wanted to let you know, the lowest direct dependency test failures are in microsoft provider, it is due to recent release of microsoft-kiota-http. imports are not working. am trying to fix these deps on different pr.', 'created_at': datetime.datetime(2024, 10, 11, 21, 0, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408183156, 'issue_id': 2581804438, 'author': 'ferruzzi', 'body': ""I got caught up trying to fix a merge conflict in another PR, I'll get this one sorted out now.  Sorry for the holdup."", 'created_at': datetime.datetime(2024, 10, 11, 22, 11, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408518567, 'issue_id': 2581804438, 'author': 'shahar1', 'body': 'There\'s an error when using `breeze build-docs`:\r\n```\r\n/opt/airflow/docs/apache-airflow-providers-<PROVIDER_NAME>/_api/airflow/providers/index.rst:document isn\'t included in any\r\ntoctree\r\n```\r\n\r\nIt seems that after applying the changes and running this command, it creates an extra `index.rst` for ``airflow/providers/__init__.py``, which is indeed not in use anywhere. \r\n\r\nThis file should be added to the `autoapi_ignore` list in `airflow/docs/conf.py` (i.e., `""*/providers/src/airflow/providers/__init__.py""`).', 'created_at': datetime.datetime(2024, 10, 12, 10, 46, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415076840, 'issue_id': 2581804438, 'author': 'potiuk', 'body': 'You need to rebase @ferruzzi -> all the problems you see in here have been solved in main.', 'created_at': datetime.datetime(2024, 10, 15, 20, 49, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415273364, 'issue_id': 2581804438, 'author': 'ferruzzi', 'body': 'Alright.  This is all green, up-to-date, and typo-free.', 'created_at': datetime.datetime(2024, 10, 15, 22, 23, 8, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-11 21:00:06 UTC): @ferruzzi Just wanted to let you know, the lowest direct dependency test failures are in microsoft provider, it is due to recent release of microsoft-kiota-http. imports are not working. am trying to fix these deps on different pr.

ferruzzi (Issue Creator) on (2024-10-11 22:11:42 UTC): I got caught up trying to fix a merge conflict in another PR, I'll get this one sorted out now.  Sorry for the holdup.

shahar1 on (2024-10-12 10:46:10 UTC): There's an error when using `breeze build-docs`:
```
/opt/airflow/docs/apache-airflow-providers-<PROVIDER_NAME>/_api/airflow/providers/index.rst:document isn't included in any
toctree
```

It seems that after applying the changes and running this command, it creates an extra `index.rst` for ``airflow/providers/__init__.py``, which is indeed not in use anywhere. 

This file should be added to the `autoapi_ignore` list in `airflow/docs/conf.py` (i.e., `""*/providers/src/airflow/providers/__init__.py""`).

potiuk on (2024-10-15 20:49:37 UTC): You need to rebase @ferruzzi -> all the problems you see in here have been solved in main.

ferruzzi (Issue Creator) on (2024-10-15 22:23:08 UTC): Alright.  This is all green, up-to-date, and typo-free.

"
2581748594,pull_request,closed,,CI failure Upgrade to trove-classifiers,"Fixing ci failure upgrade checks.

https://github.com/apache/airflow/actions/runs/11293316916/job/31411223490#step:9:66

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-11 16:19:37+00:00,[],2024-11-23 19:54:48+00:00,2024-10-12 09:49:01+00:00,https://github.com/apache/airflow/pull/42950,[],"[{'comment_id': 2407873230, 'issue_id': 2581748594, 'author': 'gopidesupavan', 'body': 'Strange errors looker_sdk.rtl module error, and static check `check-provider-yaml-valid` errors. ran this in local it works fine. can we re trigger tests once?', 'created_at': datetime.datetime(2024, 10, 11, 17, 46, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407908228, 'issue_id': 2581748594, 'author': 'gopidesupavan', 'body': 'it looks like the latest looker sdk release gone wrong. imports are not working.\r\n\r\nhttps://github.com/looker-open-source/sdk-codegen/issues/1518', 'created_at': datetime.datetime(2024, 10, 11, 18, 12, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407914712, 'issue_id': 2581748594, 'author': 'gopidesupavan', 'body': '@potiuk do you think should we restrict the looker version number?', 'created_at': datetime.datetime(2024, 10, 11, 18, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407932839, 'issue_id': 2581748594, 'author': 'gopidesupavan', 'body': 'added separate pr here https://github.com/apache/airflow/pull/42954', 'created_at': datetime.datetime(2024, 10, 11, 18, 30, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408488724, 'issue_id': 2581748594, 'author': 'gopidesupavan', 'body': 'Thanks @jscheffl ..', 'created_at': datetime.datetime(2024, 10, 12, 9, 49, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408497455, 'issue_id': 2581748594, 'author': 'jscheffl', 'body': 'Thank YOU @gopidesupavan !', 'created_at': datetime.datetime(2024, 10, 12, 9, 52, 48, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-11 17:46:56 UTC): Strange errors looker_sdk.rtl module error, and static check `check-provider-yaml-valid` errors. ran this in local it works fine. can we re trigger tests once?

gopidesupavan (Issue Creator) on (2024-10-11 18:12:09 UTC): it looks like the latest looker sdk release gone wrong. imports are not working.

https://github.com/looker-open-source/sdk-codegen/issues/1518

gopidesupavan (Issue Creator) on (2024-10-11 18:17:00 UTC): @potiuk do you think should we restrict the looker version number?

gopidesupavan (Issue Creator) on (2024-10-11 18:30:31 UTC): added separate pr here https://github.com/apache/airflow/pull/42954

gopidesupavan (Issue Creator) on (2024-10-12 09:49:58 UTC): Thanks @jscheffl ..

jscheffl on (2024-10-12 09:52:48 UTC): Thank YOU @gopidesupavan !

"
2581746409,pull_request,closed,,Refactor FastApi Dag and DagRun endpoints tests,Related to #42866 ,rawwar,2024-10-11 16:18:08+00:00,[],2024-10-14 17:04:55+00:00,2024-10-14 16:58:28+00:00,https://github.com/apache/airflow/pull/42949,"[('area:dev-tools', '')]","[{'comment_id': 2407962177, 'issue_id': 2581746409, 'author': 'rawwar', 'body': '@pierrejeambrun, please review', 'created_at': datetime.datetime(2024, 10, 11, 18, 52, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411337059, 'issue_id': 2581746409, 'author': 'pierrejeambrun', 'body': 'Test failure is unrelated,  we need to wait and rebase on top of https://github.com/apache/airflow/pull/43002', 'created_at': datetime.datetime(2024, 10, 14, 13, 52, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411674885, 'issue_id': 2581746409, 'author': 'rawwar', 'body': '> Test failure is unrelated, we need to wait and rebase on top of #43002\r\n\r\nDone.', 'created_at': datetime.datetime(2024, 10, 14, 16, 3, 1, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-11 18:52:36 UTC): @pierrejeambrun, please review

pierrejeambrun on (2024-10-14 13:52:42 UTC): Test failure is unrelated,  we need to wait and rebase on top of https://github.com/apache/airflow/pull/43002

rawwar (Issue Creator) on (2024-10-14 16:03:01 UTC): Done.

"
2581551693,pull_request,closed,,AIP-84 Post variable,"Related to related to: https://github.com/apache/airflow/issues/42370


Only the last commit is relevant, because based off https://github.com/apache/airflow/pull/42929
",pierrejeambrun,2024-10-11 14:42:19+00:00,['pierrejeambrun'],2024-10-14 19:26:37+00:00,2024-10-14 19:26:35+00:00,https://github.com/apache/airflow/pull/42948,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2581426323,pull_request,closed,,Add sequence insert support to OracleHook,"If Oracle had a sequence column, it could not be entered with existing logic. We received an additional sequence column and sequence name in the existing function so that you could enter it

Closes: #42494",Lee2532,2024-10-11 13:46:31+00:00,[],2024-10-27 05:38:41+00:00,2024-10-26 19:58:55+00:00,https://github.com/apache/airflow/pull/42947,"[('area:providers', ''), ('provider:oracle', '')]","[{'comment_id': 2430956445, 'issue_id': 2581426323, 'author': 'Lee2532', 'body': '@potiuk \r\n\r\nHello\r\nThis is the PR I wrote again because I sent the wrong PR last time. Can you check it? Thank you (related PR : https://github.com/apache/airflow/pull/42778)', 'created_at': datetime.datetime(2024, 10, 23, 5, 39, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439719948, 'issue_id': 2581426323, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 26, 19, 58, 57, tzinfo=datetime.timezone.utc)}]","Lee2532 (Issue Creator) on (2024-10-23 05:39:45 UTC): @potiuk 

Hello
This is the PR I wrote again because I sent the wrong PR last time. Can you check it? Thank you (related PR : https://github.com/apache/airflow/pull/42778)

boring-cyborg[bot] on (2024-10-26 19:58:57 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2581400959,pull_request,closed,,Chart: Fix VCT for scheduler in local and persistent mode,"This is a small PR to fix the same issue with argocd deploy as in #41771 only for scheduler when local executor and persistent logs are enabled.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Aakcht,2024-10-11 13:36:43+00:00,[],2025-02-05 15:52:00+00:00,2024-10-12 14:23:54+00:00,https://github.com/apache/airflow/pull/42946,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2581328777,pull_request,closed,,Fix repair function call,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Fix repair function calling, only repair_dict need to get passed


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gaurav7261,2024-10-11 13:02:28+00:00,[],2024-12-07 00:17:06+00:00,2024-12-07 00:17:06+00:00,https://github.com/apache/airflow/pull/42945,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2409494412, 'issue_id': 2581328777, 'author': 'potiuk', 'body': 'Why? Can you explain? What is source documentation?\r\n\r\nCan you please add a unit test to cover this change?', 'created_at': datetime.datetime(2024, 10, 14, 0, 36, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410225414, 'issue_id': 2581328777, 'author': 'gaurav7261', 'body': 'Hi @potiuk , it seems like typo in my repair run PR, I have tested on our dev, for deferrable, it is working as expected, but in normal, it is failing, you can find error in screenshot below, thanks \r\n\r\n<img width=""1250"" alt=""Screenshot 2024-10-14 at 12 42 51 PM"" src=""https://github.com/user-attachments/assets/2aa88e96-c66c-491c-97ba-1a36e10170ac"">', 'created_at': datetime.datetime(2024, 10, 14, 7, 12, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412456863, 'issue_id': 2581328777, 'author': 'potiuk', 'body': '> Hi @potiuk , it seems like typo in my repair run PR, I have tested on our dev, for deferrable, it is working as expected, but in normal, it is failing, you can find error in screenshot below, thanks\r\n\r\nWhich PR? \r\n\r\nAnd I think in either case - if this is ""correct fix"" - generally speaking we do not accept PRs like that which have no unit test changes - because it means that the ""bad"" functionality did not have a good unit test. If it did, the test would fail after your change and you would have to correct the test as well) - so adding a unit test here is pretty much mandatory.', 'created_at': datetime.datetime(2024, 10, 14, 22, 38, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413034022, 'issue_id': 2581328777, 'author': 'gaurav7261', 'body': 'Hi @potiuk , sure will add a unit test case for the same, in earlier PR, I think unit test case was there, but that covered only the deferrable one, From a functionality point  of view, it is the same, no worries, I will add a test case for this as well', 'created_at': datetime.datetime(2024, 10, 15, 6, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509489660, 'issue_id': 2581328777, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 1, 0, 19, 49, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-14 00:36:55 UTC): Why? Can you explain? What is source documentation?

Can you please add a unit test to cover this change?

gaurav7261 (Issue Creator) on (2024-10-14 07:12:15 UTC): Hi @potiuk , it seems like typo in my repair run PR, I have tested on our dev, for deferrable, it is working as expected, but in normal, it is failing, you can find error in screenshot below, thanks 

<img width=""1250"" alt=""Screenshot 2024-10-14 at 12 42 51 PM"" src=""https://github.com/user-attachments/assets/2aa88e96-c66c-491c-97ba-1a36e10170ac"">

potiuk on (2024-10-14 22:38:40 UTC): Which PR? 

And I think in either case - if this is ""correct fix"" - generally speaking we do not accept PRs like that which have no unit test changes - because it means that the ""bad"" functionality did not have a good unit test. If it did, the test would fail after your change and you would have to correct the test as well) - so adding a unit test here is pretty much mandatory.

gaurav7261 (Issue Creator) on (2024-10-15 06:49:00 UTC): Hi @potiuk , sure will add a unit test case for the same, in earlier PR, I think unit test case was there, but that covered only the deferrable one, From a functionality point  of view, it is the same, no worries, I will add a test case for this as well

github-actions[bot] on (2024-12-01 00:19:49 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2581320234,pull_request,closed,,Consistent python version checks and troubleshooting,"Follow up after #42766 and #42936.

* We do not have to check for minimum Python version for Python 3.9 any more (as we do not support 3.8 any more)
* While Python 3.12 is not yet fully supported by Apache Beam, we should still not allow it for releasing providers, but all other commands should support Python 3.12
* When you had pre-commit installed with Python 3.8 before, various errors might appear when running pre-commit. Troubleshooting was added quoting the errors and explaining what to do.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-11 12:57:55+00:00,[],2024-10-12 19:46:17+00:00,2024-10-11 19:22:05+00:00,https://github.com/apache/airflow/pull/42944,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:apache-beam', '')]","[{'comment_id': 2408622945, 'issue_id': 2581320234, 'author': 'ashb', 'body': ""I still don't understand how _preparing_ the sdist release on Python 3.12 causes any problem? Surely the Py 3.12 issue is a runtime/install time problem?\r\n\r\nFor instance: I removed the 3.12 check and ran:\r\n\r\n```\r\nbreeze release-management prepare-provider-packages --package-format sdist apache.beam --skip-tag-check\r\n```\r\n\r\nWhich generated this file [apache_airflow_providers_apache_beam-5.8.1.tar.gz](https://github.com/user-attachments/files/17350787/apache_airflow_providers_apache_beam-5.8.1.tar.gz)\r\n\r\nIf you compare the files in that to https://dist.apache.org/repos/dist/dev/airflow/providers/apache_airflow_providers_apache_beam-5.8.1.tar.gz it is 100% identical\r\n\r\n\r\nTo repro:\r\n\r\n```\r\ncurl -fSsL https://dist.apache.org/repos/dist/dev/airflow/providers/apache_airflow_providers_apache_beam-5.8.1.tar.gz | tar -xOz - | shasum;\r\ncurl -fSsL https://github.com/user-attachments/files/17350787/apache_airflow_providers_apache_beam-5.8.1.tar.gz | tar -xOz - | shasum;\r\n```\r\n\r\nWhich prints\r\n\r\n```\r\nc160bea03fb1262af731ba25fb3c1d9a2a8a954c  -\r\nc160bea03fb1262af731ba25fb3c1d9a2a8a954c  -\r\n```\r\n\r\n`tar -O` says print all the content to stdout -- i.e. these two tar files contain identical content."", 'created_at': datetime.datetime(2024, 10, 12, 16, 44, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408661730, 'issue_id': 2581320234, 'author': 'potiuk', 'body': 'Good that you checked. The sdist package to wheel conversion did not work before with Python3.12. \n\nAs explained few times before when you asked -this was the reason for having the exclusion. I have not checked if it works now it could be caused by other packages that failed with 3.12.\n\nAnother reason why it might start working -I think - the version of Beam released a week or so  ago could have fixed the sdist failure - because they generally fixed some dependencies in latest version released while I was on vacations.\n\nIf my hypothesis is right - If you want to see how it failed before you can pin the beam package to the previous version and see the failure.\n\nIf you can confirm that it works now - we can remove the limitation.', 'created_at': datetime.datetime(2024, 10, 12, 19, 0, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408681848, 'issue_id': 2581320234, 'author': 'ashb', 'body': ""That def explains why I couldn't see any reason for the check. I'll try with the previous version tomorrow/Monday."", 'created_at': datetime.datetime(2024, 10, 12, 19, 46, 16, tzinfo=datetime.timezone.utc)}]","ashb on (2024-10-12 16:44:46 UTC): I still don't understand how _preparing_ the sdist release on Python 3.12 causes any problem? Surely the Py 3.12 issue is a runtime/install time problem?

For instance: I removed the 3.12 check and ran:

```
breeze release-management prepare-provider-packages --package-format sdist apache.beam --skip-tag-check
```

Which generated this file [apache_airflow_providers_apache_beam-5.8.1.tar.gz](https://github.com/user-attachments/files/17350787/apache_airflow_providers_apache_beam-5.8.1.tar.gz)

If you compare the files in that to https://dist.apache.org/repos/dist/dev/airflow/providers/apache_airflow_providers_apache_beam-5.8.1.tar.gz it is 100% identical


To repro:

```
curl -fSsL https://dist.apache.org/repos/dist/dev/airflow/providers/apache_airflow_providers_apache_beam-5.8.1.tar.gz | tar -xOz - | shasum;
curl -fSsL https://github.com/user-attachments/files/17350787/apache_airflow_providers_apache_beam-5.8.1.tar.gz | tar -xOz - | shasum;
```

Which prints

```
c160bea03fb1262af731ba25fb3c1d9a2a8a954c  -
c160bea03fb1262af731ba25fb3c1d9a2a8a954c  -
```

`tar -O` says print all the content to stdout -- i.e. these two tar files contain identical content.

potiuk (Issue Creator) on (2024-10-12 19:00:00 UTC): Good that you checked. The sdist package to wheel conversion did not work before with Python3.12. 

As explained few times before when you asked -this was the reason for having the exclusion. I have not checked if it works now it could be caused by other packages that failed with 3.12.

Another reason why it might start working -I think - the version of Beam released a week or so  ago could have fixed the sdist failure - because they generally fixed some dependencies in latest version released while I was on vacations.

If my hypothesis is right - If you want to see how it failed before you can pin the beam package to the previous version and see the failure.

If you can confirm that it works now - we can remove the limitation.

ashb on (2024-10-12 19:46:16 UTC): That def explains why I couldn't see any reason for the check. I'll try with the previous version tomorrow/Monday.

"
2581305859,pull_request,closed,,Remove BackfillJobRunner class,"Part of AIP-78

Depends on https://github.com/apache/airflow/pull/42922

After https://github.com/apache/airflow/pull/42922 is merged, we'll have updated the CLI to create backfills in the new way.  Then it mostly easy to remove this class.",dstandish,2024-10-11 12:50:08+00:00,[],2024-10-14 02:00:25+00:00,2024-10-14 01:15:11+00:00,https://github.com/apache/airflow/pull/42943,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2407983200, 'issue_id': 2581305859, 'author': 'potiuk', 'body': '#protm', 'created_at': datetime.datetime(2024, 10, 11, 19, 8, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408182153, 'issue_id': 2581305859, 'author': 'dstandish', 'body': 'rebased and ready to go 🥳', 'created_at': datetime.datetime(2024, 10, 11, 22, 10, 25, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-11 19:08:40 UTC): #protm

dstandish (Issue Creator) on (2024-10-11 22:10:25 UTC): rebased and ready to go 🥳

"
2581302898,pull_request,closed,,Remove the referrer from Webserver to Scarf (#42901),"Backport of https://github.com/apache/airflow/pull/42901 for 2.10

This will make sure we don't receive any information about the Webserver URL sending the info like the number of plugins and such.

(cherry picked from commit 39f8e1d487ab8f1969aaec512fdffacca989813c)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-11 12:48:29+00:00,[],2024-10-23 09:15:28+00:00,2024-10-11 15:35:11+00:00,https://github.com/apache/airflow/pull/42942,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2581246202,pull_request,closed,,Update README.rst,"grammar update for clarity 😄 👍

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",AndreMiranda-dev,2024-10-11 12:17:21+00:00,[],2024-10-15 00:42:42+00:00,2024-10-11 19:39:29+00:00,https://github.com/apache/airflow/pull/42941,"[('kind:documentation', '')]","[{'comment_id': 2407292749, 'issue_id': 2581246202, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 11, 12, 17, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408021618, 'issue_id': 2581246202, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 11, 19, 39, 31, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-11 12:17:26 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-11 19:39:31 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2581197846,pull_request,closed,,Increase backoff_factor and add try/catch in k8s tests,"Recently, a delay was added to wait for the DAG parsing to complete during the Kubernetes tests. During these waits, we call the DAG endpoint, which may reach the maximum retries if the DAG is not yet available. These can be ignored until the parsing is finished.

https://github.com/apache/airflow/actions/runs/11288215065/job/31396688769#step:9:1379

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-11 11:52:15+00:00,[],2024-10-15 00:19:21+00:00,2024-10-11 19:03:42+00:00,https://github.com/apache/airflow/pull/42940,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2581084203,pull_request,closed,,Migrate health info to fastapi,"Migrate /health to fastapi public api under a monitor router

Closes https://github.com/apache/airflow/issues/42937

Part of https://github.com/apache/airflow/issues/42370


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-11 10:58:19+00:00,[],2024-10-15 19:05:41+00:00,2024-10-15 19:05:40+00:00,https://github.com/apache/airflow/pull/42938,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2580984304,pull_request,closed,,Allow python 3.12 for the breeze release commands,"I'm not 100% sure why we added this check in the first place, but it doesn't
seem to be needed anymore (I've tested things locally with this removed and it
all seems to behave itself)
",ashb,2024-10-11 10:07:28+00:00,[],2024-10-12 16:40:39+00:00,2024-10-11 10:11:28+00:00,https://github.com/apache/airflow/pull/42936,"[('area:dev-tools', '')]","[{'comment_id': 2407318919, 'issue_id': 2580984304, 'author': 'potiuk', 'body': ""It's just a matter of looking it up in git blame.\r\n\r\nActually this is not really good idea for now (Provider's release manager's releasing providers should not use Python 3.12). it's all visible in detail in history of those changed lines.\r\n\r\nWhat can **actually** be removed now is the 3.9 check (because we do not use Python 3.8 any more and python 3.8 produced non-reproducible builds as explained in comments and in https://github.com/apache/airflow/pull/37401). \\\r\n\r\nPython 3.12 was excluded (additionally) here https://github.com/apache/airflow/pull/37615 because some of our provider packages did not support 3.12 and as of recently as part of release process we are building .sdist packages and they cannot be build for packages that do not support Python 3.12. Currently apache-beam does not support Python 3.12 yet (mostly because they embedded dill version that breaks our PythonVirtualenvOperator as explained in https://github.com/apache/airflow/pull/41990 and we cannot enabvle it until https://github.com/apache/beam/issues/32617 is fixed.\r\n\r\nBut yeah. It makes no sense to  block 3.12 usage for everyone, it might be enough to remove it for providers release command only. I will correct it."", 'created_at': datetime.datetime(2024, 10, 11, 12, 32, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407406306, 'issue_id': 2580984304, 'author': 'potiuk', 'body': 'Better fix in #42944', 'created_at': datetime.datetime(2024, 10, 11, 13, 22, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408621889, 'issue_id': 2580984304, 'author': 'ashb', 'body': ""> It's just a matter of looking it up in git blame.\r\n\r\nNot really, not to me anyway -- I found the PR https://github.com/apache/airflow/pull/37615 before opening this but that didn't actually give me any further clues as to what the actual problem using Py 3.12 was."", 'created_at': datetime.datetime(2024, 10, 12, 16, 40, 37, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-11 12:32:35 UTC): It's just a matter of looking it up in git blame.

Actually this is not really good idea for now (Provider's release manager's releasing providers should not use Python 3.12). it's all visible in detail in history of those changed lines.

What can **actually** be removed now is the 3.9 check (because we do not use Python 3.8 any more and python 3.8 produced non-reproducible builds as explained in comments and in https://github.com/apache/airflow/pull/37401). \

Python 3.12 was excluded (additionally) here https://github.com/apache/airflow/pull/37615 because some of our provider packages did not support 3.12 and as of recently as part of release process we are building .sdist packages and they cannot be build for packages that do not support Python 3.12. Currently apache-beam does not support Python 3.12 yet (mostly because they embedded dill version that breaks our PythonVirtualenvOperator as explained in https://github.com/apache/airflow/pull/41990 and we cannot enabvle it until https://github.com/apache/beam/issues/32617 is fixed.

But yeah. It makes no sense to  block 3.12 usage for everyone, it might be enough to remove it for providers release command only. I will correct it.

potiuk on (2024-10-11 13:22:03 UTC): Better fix in #42944

ashb (Issue Creator) on (2024-10-12 16:40:37 UTC): Not really, not to me anyway -- I found the PR https://github.com/apache/airflow/pull/37615 before opening this but that didn't actually give me any further clues as to what the actual problem using Py 3.12 was.

"
2580948840,pull_request,closed,,"Allow ""/"" in metrics validator","### **Changes Proposed in this PR**
- Allow '/' in metrics validator, this resolves issues such as

```
airflow.exceptions.InvalidStatsNameException: The stat name (dag_processing.processes,file_path=/mnt/c/Users/user/Documents/GitHub/airflow-dir/test_dag.py,action=finish) has to be composed of ASCII alphabets, numbers, or the underscore, dot, or dash characters.
[2023-04-18T12:21:39.738-0400] {stats.py:245} ERROR - Invalid stat name: dag_processing.processes,file_path=/mnt/c/Users/user/Documents/GitHub/airflow-dir/test_dag.py,action=start.
Traceback (most recent call last):
File ""/mnt/c/Users/user/Documents/GitHub/airflow-dir/venv/lib/python3.9/site-packages/airflow/stats.py"", line 242, in wrapper
stat = handler_stat_name_func(stat)
File ""/mnt/c/Users/user/Documents/GitHub/airflow-dir/venv/lib/python3.9/site-packages/airflow/stats.py"", line 210, in stat_name_default_handler
raise InvalidStatsNameException(
airflow.exceptions.InvalidStatsNameException: The stat name (dag_processing.processes,file_path=/mnt/c/Users/user/Documents/GitHub/airflow-dir/test_dag.py,action=start) has to be composed of ASCII alphabets, numbers, or the underscore, dot, or dash characters.
[2023-04-18T12:21:51.375-0400] {stats.py:245} ERROR - Invalid stat name: dag_processing.processes,file_path=/mnt/c/Users/user/Documents/GitHub/airflow-dir/test_dag.py,action=finish.
```

closes: https://github.com/apache/airflow/issues/30716

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",awdavidson,2024-10-11 09:51:17+00:00,[],2024-11-30 17:18:32+00:00,2024-11-30 15:52:45+00:00,https://github.com/apache/airflow/pull/42934,[],"[{'comment_id': 2409468700, 'issue_id': 2580948840, 'author': 'potiuk', 'body': 'Two asks: \r\n\r\n1) Can you please add a unit test for that\r\n2) This look like a bug-fix - can you please cherry-pick (with -x) this change after I merge it to `v2-10-test` targeted-PR ?', 'created_at': datetime.datetime(2024, 10, 14, 0, 25, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505175691, 'issue_id': 2580948840, 'author': 'potiuk', 'body': 'Some static checks to fix. I recommend installing pre-commit  - it will solve problems for you', 'created_at': datetime.datetime(2024, 11, 28, 3, 4, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509014608, 'issue_id': 2580948840, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 30, 15, 52, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509035224, 'issue_id': 2580948840, 'author': 'shalberd', 'body': 'Very nice indeed, thank you so very much. @potiuk will this be backported and included in 2.10.3 or only in a future Airflow v3?', 'created_at': datetime.datetime(2024, 11, 30, 16, 47, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509078243, 'issue_id': 2580948840, 'author': 'potiuk', 'body': 'Ah ... It should be .. but I forgot to put the label on it... So let me try to cherry-pick it now.', 'created_at': datetime.datetime(2024, 11, 30, 17, 14, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509079282, 'issue_id': 2580948840, 'author': 'potiuk', 'body': 'https://github.com/apache/airflow/pull/44515', 'created_at': datetime.datetime(2024, 11, 30, 17, 18, 31, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-14 00:25:10 UTC): Two asks: 

1) Can you please add a unit test for that
2) This look like a bug-fix - can you please cherry-pick (with -x) this change after I merge it to `v2-10-test` targeted-PR ?

potiuk on (2024-11-28 03:04:12 UTC): Some static checks to fix. I recommend installing pre-commit  - it will solve problems for you

potiuk on (2024-11-30 15:52:42 UTC): Nice!

shalberd on (2024-11-30 16:47:30 UTC): Very nice indeed, thank you so very much. @potiuk will this be backported and included in 2.10.3 or only in a future Airflow v3?

potiuk on (2024-11-30 17:14:44 UTC): Ah ... It should be .. but I forgot to put the label on it... So let me try to cherry-pick it now.

potiuk on (2024-11-30 17:18:31 UTC): https://github.com/apache/airflow/pull/44515

"
2580914310,pull_request,closed,,Remove zombie ti from its executor,"~~More details to come. And tests.~~

When a ti worker goes for too long without a heartbeat, the scheduler would identify it as a zombie, and stop it from running any longer. However, the scheduler does not perform housekeeping correctly, and in some cases the executor (of the ti) would still _think_ the ti is still running.

This PR adds an explicit call to the executor to tell it the ti has been terminated and should be cleaned up.

Some tests were modified to check this cleanup is performing as expected. Those tests were actually not set up correctly, likely due to changes from AIP-61, mocking the wrong attribute and failing to actually assert the behaviour. They have been fixed to mock ExecutorLoader instead, which is the canonical executor source after AIP-61 implementation.",uranusjr,2024-10-11 09:34:45+00:00,['uranusjr'],2024-10-23 09:03:57+00:00,2024-10-16 02:32:58+00:00,https://github.com/apache/airflow/pull/42932,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2413195651, 'issue_id': 2580914310, 'author': 'uranusjr', 'body': 'Alright, things should be good now. I also identified some test setup issues when trying to add checks for this logic, and fixed them in this PR. See (edited) description above.', 'created_at': datetime.datetime(2024, 10, 15, 8, 14, 4, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-10-15 08:14:04 UTC): Alright, things should be good now. I also identified some test setup issues when trying to add checks for this logic, and fixed them in this PR. See (edited) description above.

"
2580830425,pull_request,closed,,AIP-84 Patch Variable,related to: https://github.com/apache/airflow/issues/42370,pierrejeambrun,2024-10-11 08:53:12+00:00,['pierrejeambrun'],2024-10-14 15:08:17+00:00,2024-10-14 15:08:15+00:00,https://github.com/apache/airflow/pull/42929,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2580816802,pull_request,closed,,Commit the session between writing and deletion of RTIF,"Previously, this was how it was done, but now, a session was used for both the writing and deletion of RTIF without committing it, which we suspect caused StaleDataError. The related PR: https://github.com/apache/airflow/pull/38565

This PR brings back the old behaviour of using different sessions for writing/deleting RTIFs

The ERROR:
```
[2024-10-08T14:58:00.817+0000] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/usr/local/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File ""/usr/local/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 3122, in _execute_task_with_callbacks
    _update_rtif(ti=self, rendered_fields=rendered_fields)
  File ""/usr/local/lib/python3.10/site-packages/airflow/api_internal/internal_api_call.py"", line 139, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/airflow/utils/session.py"", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/airflow/models/taskinstance.py"", line 1642, in _update_rtif
    RenderedTaskInstanceFields.delete_old_records(ti.task_id, ti.dag_id, session=session)
  File ""/usr/local/lib/python3.10/site-packages/airflow/utils/session.py"", line 94, in wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.10/site-packages/airflow/models/renderedtifields.py"", line 271, in delete_old_records
    session.flush()
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/session.py"", line 3449, in flush
    self._flush(objects)
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/session.py"", line 3588, in _flush
    with util.safe_reraise():
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/util/langhelpers.py"", line 70, in __exit__
    compat.raise_(
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/util/compat.py"", line 211, in raise_
    raise exception
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/session.py"", line 3549, in _flush
    flush_context.execute()
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py"", line 456, in execute
    rec.execute(self)
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/unitofwork.py"", line 630, in execute
    util.preloaded.orm_persistence.save_obj(
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py"", line 237, in save_obj
    _emit_update_statements(
  File ""/usr/local/lib/python3.10/site-packages/sqlalchemy/orm/persistence.py"", line 1035, in _emit_update_statements
    raise orm_exc.StaleDataError(
sqlalchemy.orm.exc.StaleDataError: UPDATE statement on table 'rendered_task_instance_fields' expected to update 1 row(s); 0 were matched.
```
",ephraimbuddy,2024-10-11 08:47:49+00:00,['ephraimbuddy'],2024-10-23 09:10:54+00:00,2024-10-14 16:00:08+00:00,https://github.com/apache/airflow/pull/42928,"[('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]","[{'comment_id': 2407475914, 'issue_id': 2580816802, 'author': 'dstandish', 'body': '> This PR brings back the old behaviour of using different sessions for writing/deleting RTIFs\r\n\r\nI think has continued to use the same session.  Pretty sure that the difference is pre-AIP-44 we committed in between.\r\n\r\nHere\'s a way to explore:\r\n\r\n```\r\nsession.execute(""create table parent(id int);"");\r\nsession.commit()\r\nsession.execute(""insert into parent (id) values (1),(2),(3);"")\r\nwith create_session() as session2:\r\n    print(session2.execute(""select * from parent"").all())\r\nassert session2 is session\r\n```\r\n\r\nWhy this matters?  \r\n\r\nI feel like it\'s better to commit explicitly so that we _see_ it. Rather than having it done invisibly by the decorator.', 'created_at': datetime.datetime(2024, 10, 11, 13, 58, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407493946, 'issue_id': 2580816802, 'author': 'ephraimbuddy', 'body': '> > This PR brings back the old behaviour of using different sessions for writing/deleting RTIFs\r\n> \r\n> I think has continued to use the same session. Pretty sure that the difference is pre-AIP-44 we committed in between.\r\n> \r\n> Here\'s a way to explore:\r\n> \r\n> ```\r\n> session.execute(""create table parent(id int);"");\r\n> session.commit()\r\n> session.execute(""insert into parent (id) values (1),(2),(3);"")\r\n> with create_session() as session2:\r\n>     print(session2.execute(""select * from parent"").all())\r\n> assert session2 is session\r\n> ```\r\n> \r\n\r\n\r\nYeah, Issuing a commit persists things into the DB, not that the session is different.\r\n\r\n> Why this matters?\r\n> \r\n> I feel like it\'s better to commit explicitly so that we _see_ it. Rather than having it done invisibly by the decorator.\r\n\r\nThe provide session is already doing that? Or you want it removed from the RTIF write method? I feel it\'s a better design to have the provide_session do it than \r\n```\r\nRTIF.write(session)\r\nsession.commit()\r\nRTIF.delete_old_record(session)\r\nsession.commit()\r\n```', 'created_at': datetime.datetime(2024, 10, 11, 14, 7, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407723324, 'issue_id': 2580816802, 'author': 'dstandish', 'body': '> The provide session is already doing that? Or you want it removed from the RTIF write method?\r\n\r\nIt won\'t do it if you provide a session.  So we don\'t necessarily have to remove the decorator, though doesn\'t seem a bad idea if we don\'t need it.\r\n\r\n> I feel it\'s a better design to have the provide_session do it than\r\n\r\nWell, reasonable minds can differ.  But what motivates me is ""prefer explicit over implicit"".  \r\n\r\nDo it as you wish, but I think when we let provide_session do the commits implicitly, it\'s much less obvious what\'s going on (and i think that\'s part of how we got into trouble here).\r\n\r\nCommiting explicitly makes it very clear.  It also affords an opportunity to explain why we commit there.\r\n\r\nAnyway, most of this I think will be changed as part of AIP-72, so this i think is mainly academic, about us sort of just figuring out what\'s the best thing to do in this kind of scenario.', 'created_at': datetime.datetime(2024, 10, 11, 16, 10, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408628028, 'issue_id': 2580816802, 'author': 'ashb', 'body': 'Rather than two commits you can also do `session.flush()` which makes SQLA issue the commands to the DB such that a future select on the same session\xa0sees the same rows, but it keeps it in the same session, such that the total operation is atomic still', 'created_at': datetime.datetime(2024, 10, 12, 17, 3, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408945422, 'issue_id': 2580816802, 'author': 'ephraimbuddy', 'body': '> Rather than two commits you can also do `session.flush()` which makes SQLA issue the commands to the DB such that a future select on the same session\xa0sees the same rows, but it keeps it in the same session, such that the total operation is atomic still\r\n\r\nIf I read this correctly, we would still have the issue: https://docs.sqlalchemy.org/en/20/orm/session_basics.html#flushing. Does this mean there was a flush in the update statement when we called `write` before the delete statement?', 'created_at': datetime.datetime(2024, 10, 13, 11, 44, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409102421, 'issue_id': 2580816802, 'author': 'ashb', 'body': ""We aren't using 2.0 style though, so I think we have to call flush ourselves in 1.4/classic style"", 'created_at': datetime.datetime(2024, 10, 13, 19, 49, 31, tzinfo=datetime.timezone.utc)}]","dstandish on (2024-10-11 13:58:29 UTC): I think has continued to use the same session.  Pretty sure that the difference is pre-AIP-44 we committed in between.

Here's a way to explore:

```
session.execute(""create table parent(id int);"");
session.commit()
session.execute(""insert into parent (id) values (1),(2),(3);"")
with create_session() as session2:
    print(session2.execute(""select * from parent"").all())
assert session2 is session
```

Why this matters?  

I feel like it's better to commit explicitly so that we _see_ it. Rather than having it done invisibly by the decorator.

ephraimbuddy (Issue Creator) on (2024-10-11 14:07:32 UTC): Yeah, Issuing a commit persists things into the DB, not that the session is different.


The provide session is already doing that? Or you want it removed from the RTIF write method? I feel it's a better design to have the provide_session do it than 
```
RTIF.write(session)
session.commit()
RTIF.delete_old_record(session)
session.commit()
```

dstandish on (2024-10-11 16:10:33 UTC): It won't do it if you provide a session.  So we don't necessarily have to remove the decorator, though doesn't seem a bad idea if we don't need it.


Well, reasonable minds can differ.  But what motivates me is ""prefer explicit over implicit"".  

Do it as you wish, but I think when we let provide_session do the commits implicitly, it's much less obvious what's going on (and i think that's part of how we got into trouble here).

Commiting explicitly makes it very clear.  It also affords an opportunity to explain why we commit there.

Anyway, most of this I think will be changed as part of AIP-72, so this i think is mainly academic, about us sort of just figuring out what's the best thing to do in this kind of scenario.

ashb on (2024-10-12 17:03:22 UTC): Rather than two commits you can also do `session.flush()` which makes SQLA issue the commands to the DB such that a future select on the same session sees the same rows, but it keeps it in the same session, such that the total operation is atomic still

ephraimbuddy (Issue Creator) on (2024-10-13 11:44:21 UTC): If I read this correctly, we would still have the issue: https://docs.sqlalchemy.org/en/20/orm/session_basics.html#flushing. Does this mean there was a flush in the update statement when we called `write` before the delete statement?

ashb on (2024-10-13 19:49:31 UTC): We aren't using 2.0 style though, so I think we have to call flush ourselves in 1.4/classic style

"
2580629525,pull_request,closed,,Docs: Change code-block in 03_contributors_quick_start docs,"Hi, It's very minor issue.
I moved the code block to a more appropriate location in my opinion.",kgw7401,2024-10-11 07:18:47+00:00,[],2024-10-13 13:20:32+00:00,2024-10-12 14:37:24+00:00,https://github.com/apache/airflow/pull/42927,"[('area:dev-tools', '')]","[{'comment_id': 2406706693, 'issue_id': 2580629525, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 11, 7, 18, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408587070, 'issue_id': 2580629525, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 12, 14, 37, 27, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-11 07:18:51 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-12 14:37:27 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2580626003,pull_request,closed,,[DO NOT MERGE] Test adding a thing to the plugin…,,uranusjr,2024-10-11 07:16:36+00:00,[],2024-10-11 08:00:06+00:00,2024-10-11 08:00:06+00:00,https://github.com/apache/airflow/pull/42926,"[('area:dev-tools', '')]",[],
2580523835,pull_request,closed,,fix: HttpSensorTrigger to include `method` when serializing,"As of now, the method passed via HttpOperator in deferrable mode is not being serialized. Hence, during the deferrable mode, HttpSensor ends up always making GET requests instead of the method originally intended ",rawwar,2024-10-11 06:11:02+00:00,[],2024-10-11 07:33:37+00:00,2024-10-11 06:57:09+00:00,https://github.com/apache/airflow/pull/42925,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2406625708, 'issue_id': 2580523835, 'author': 'Lee-W', 'body': ""Overall, looks good. Let's change the `TEST_METHOD` in unit tests to non POST method and create one unit test that does not pass method into `__init__`"", 'created_at': datetime.datetime(2024, 10, 11, 6, 15, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406653365, 'issue_id': 2580523835, 'author': 'rawwar', 'body': ""> Overall, looks good. Let's change the `TEST_METHOD` in unit tests to non POST method and create one unit test that does not pass method into `__init__`\r\n\r\nAdded a test that does pass POST and checks if POST is being returned by serializer. Earlier, this test would have failed as method is defaulted to GET."", 'created_at': datetime.datetime(2024, 10, 11, 6, 39, 49, tzinfo=datetime.timezone.utc)}]","Lee-W on (2024-10-11 06:15:48 UTC): Overall, looks good. Let's change the `TEST_METHOD` in unit tests to non POST method and create one unit test that does not pass method into `__init__`

rawwar (Issue Creator) on (2024-10-11 06:39:49 UTC): Added a test that does pass POST and checks if POST is being returned by serializer. Earlier, this test would have failed as method is defaulted to GET.

"
2579991785,pull_request,closed,,"Add a ""backfill create"" command","I create a new command group ""backfill"" for management of backfills.  The first action is ""create"" which creates a backfill.  Some others may follow such as pause / cancel.",dstandish,2024-10-10 22:47:50+00:00,[],2024-10-11 21:38:01+00:00,2024-10-11 21:38:00+00:00,https://github.com/apache/airflow/pull/42922,"[('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2579981827,pull_request,closed,,Check _is_canary_run/pr condition in is_legacy_ui_api_labeled method,"Currently, in CI, if changes are detected in the legacy UI/API files, the build fails with an error.

CI failures: https://github.com/apache/airflow/actions/runs/11275130446/job/31374289057#step:8:271

The `is_legacy_ui_api_labeled` flag uses the changed_files to determine the labels. Currently, the changed_files condition relies on the commit_ref, which is the Git SHA ID. This condition is always true, in my opinion. Here's an example: 

https://github.com/apache/airflow/actions/runs/11275130446/job/31374289057#step:2:15

The logic for changed_files is built as shown here:
https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/commands/ci_commands.py#L257

In the case of canary builds, full tests are triggered, so the `is_legacy_ui_api_labeled` check becomes unnecessary.

I see two possible solutions for fixing this issue:

1. Set changed_files to an empty list during canary builds.
2. Add a condition to check `_is_canary_run`.

I recommend going with the second option, as I'm unsure of the potential side effects of the first.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-10 22:39:48+00:00,[],2024-11-23 19:54:39+00:00,2024-10-11 08:19:38+00:00,https://github.com/apache/airflow/pull/42921,"[('area:dev-tools', '')]","[{'comment_id': 2406162185, 'issue_id': 2579981827, 'author': 'gopidesupavan', 'body': 'cc: @bugraoz93', 'created_at': datetime.datetime(2024, 10, 10, 22, 40, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406245936, 'issue_id': 2579981827, 'author': 'gopidesupavan', 'body': 'Updated the changes after discussing with jarek, to include pr condition check aswell.', 'created_at': datetime.datetime(2024, 10, 10, 23, 55, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406247844, 'issue_id': 2579981827, 'author': 'bugraoz93', 'body': 'Thanks, @gopidesupavan for the PR!', 'created_at': datetime.datetime(2024, 10, 10, 23, 57, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406276261, 'issue_id': 2579981827, 'author': 'bugraoz93', 'body': 'The changes look good! There is a strange static check error thought. It got it while installing the providers. `OSError: [Errno 101] Network is unreachable` while installing Zendesk. It seems like it is unreachable for a short term. I could reach the link process trying to fetch.', 'created_at': datetime.datetime(2024, 10, 11, 0, 21, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406592245, 'issue_id': 2579981827, 'author': 'gopidesupavan', 'body': '> The changes look good! There is a strange static check error thought. It got it while installing the providers. `OSError: [Errno 101] Network is unreachable` while installing Zendesk. It seems like it is unreachable for a short term. I could reach the link process trying to fetch.\r\n\r\nyeah it could be intermittent issue.', 'created_at': datetime.datetime(2024, 10, 11, 5, 41, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406867444, 'issue_id': 2579981827, 'author': 'gopidesupavan', 'body': 'Can we merge this please, it helps next schedule run?', 'created_at': datetime.datetime(2024, 10, 11, 8, 15, 54, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-10 22:40:14 UTC): cc: @bugraoz93

gopidesupavan (Issue Creator) on (2024-10-10 23:55:14 UTC): Updated the changes after discussing with jarek, to include pr condition check aswell.

bugraoz93 on (2024-10-10 23:57:32 UTC): Thanks, @gopidesupavan for the PR!

bugraoz93 on (2024-10-11 00:21:47 UTC): The changes look good! There is a strange static check error thought. It got it while installing the providers. `OSError: [Errno 101] Network is unreachable` while installing Zendesk. It seems like it is unreachable for a short term. I could reach the link process trying to fetch.

gopidesupavan (Issue Creator) on (2024-10-11 05:41:55 UTC): yeah it could be intermittent issue.

gopidesupavan (Issue Creator) on (2024-10-11 08:15:54 UTC): Can we merge this please, it helps next schedule run?

"
2579845875,pull_request,closed,,Fix typo in Breeze,"A couple of minor typos due to newlines

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-10 21:06:28+00:00,[],2024-10-10 22:50:38+00:00,2024-10-10 22:50:36+00:00,https://github.com/apache/airflow/pull/42919,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2579668280,pull_request,closed,,Mark TestGKEStartKueueInsideClusterOperator tests with flaky decorator,"In ci TestGKEStartKueueInsideClusterOperator tests are flagging timeouts, adding flaky decorator with rerun.

https://github.com/apache/airflow/actions/runs/11266046644/job/31329090401#step:7:5094

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-10 19:32:12+00:00,[],2024-11-23 19:54:36+00:00,2024-10-10 20:55:59+00:00,https://github.com/apache/airflow/pull/42916,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2579660223,pull_request,closed,,Improving validation of task retries to handle None values (#42532),"Backport of #42532

closes: #42273",jscheffl,2024-10-10 19:27:10+00:00,[],2025-01-11 19:45:04+00:00,2024-10-10 20:05:57+00:00,https://github.com/apache/airflow/pull/42915,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', '')]",[],
2579641247,pull_request,closed,,Migrate the public endpoint Delete DAG to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #42650
related: #42370

This migrates the Delete DAG API from `api_connexion` to `api_fastapi`, with a supporting test.",omkar-foss,2024-10-10 19:18:44+00:00,[],2024-10-15 09:09:38+00:00,2024-10-15 08:45:51+00:00,https://github.com/apache/airflow/pull/42914,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2407829795, 'issue_id': 2579641247, 'author': 'omkar-foss', 'body': 'Merge conflict resolved, PR is ready for review.', 'created_at': datetime.datetime(2024, 10, 11, 17, 17, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407841200, 'issue_id': 2579641247, 'author': 'omkar-foss', 'body': 'Tests failing after adding migration marker for legacy APIs. Could someone please add the `legacy api` label to this PR? Thanks.', 'created_at': datetime.datetime(2024, 10, 11, 17, 25, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407872646, 'issue_id': 2579641247, 'author': 'pierrejeambrun', 'body': 'Label added :)', 'created_at': datetime.datetime(2024, 10, 11, 17, 46, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407961534, 'issue_id': 2579641247, 'author': 'omkar-foss', 'body': ""The mypy tests for `mark_fastapi_migration_done` had been failing, so have updated it's signature to be more tolerant [here](https://github.com/apache/airflow/pull/42914/files#diff-0540fd6b9fb773735b6a583f8637809d4b53253c6415863c20634ab80e2f1a3bR31). Tests passing now."", 'created_at': datetime.datetime(2024, 10, 11, 18, 52, 8, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-10-11 17:17:56 UTC): Merge conflict resolved, PR is ready for review.

omkar-foss (Issue Creator) on (2024-10-11 17:25:13 UTC): Tests failing after adding migration marker for legacy APIs. Could someone please add the `legacy api` label to this PR? Thanks.

pierrejeambrun on (2024-10-11 17:46:29 UTC): Label added :)

omkar-foss (Issue Creator) on (2024-10-11 18:52:08 UTC): The mypy tests for `mark_fastapi_migration_done` had been failing, so have updated it's signature to be more tolerant [here](https://github.com/apache/airflow/pull/42914/files#diff-0540fd6b9fb773735b6a583f8637809d4b53253c6415863c20634ab80e2f1a3bR31). Tests passing now.

"
2579528657,pull_request,closed,,AIP-65: Add DAG versioning support,"This commit introduces versioning for DAGs.

Changes:
- Introduced DagVersion model to handle versioning of DAGs.
- Added version_name field to DAG for use in tracking the dagversion by users
- Modified DAG execution logic to reference dag_version_id instead of the dag_hash to ensure DAG runs are linked to specific versions.

The table relations:
<img width=""737"" alt=""Screenshot 2024-10-25 at 09 21 19"" src=""https://github.com/user-attachments/assets/15a74c83-c0b5-4800-9413-b53eb5f1d860"">

The versioning is based on the serialized dict changing. If a dag's serialized dict changes, a new serialized dag will be registered based on the hash diference, and consequently, a new dag version and dag code. The link from dag_version to TI is because of TaskInstance clearing. It helps us retain the previous dag version the task ran with.

Closes: #42333, #42334, #42336
",ephraimbuddy,2024-10-10 18:18:21+00:00,[],2024-11-14 19:03:38+00:00,2024-11-05 14:19:25+00:00,https://github.com/apache/airflow/pull/42913,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:db-migrations', 'PRs with DB migration'), ('AIP-65: DAG history in UI', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2430576986, 'issue_id': 2579528657, 'author': 'kaxil', 'body': 'Merge conflicts unfortunately, could you rebase on `main` again please?', 'created_at': datetime.datetime(2024, 10, 23, 0, 49, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2436995270, 'issue_id': 2579528657, 'author': 'ephraimbuddy', 'body': '> Merge conflicts unfortunately, could you rebase on `main` again please?\r\n\r\nResolved', 'created_at': datetime.datetime(2024, 10, 25, 6, 35, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442665905, 'issue_id': 2579528657, 'author': 'dstandish', 'body': ""> The versioning is based on the source code changing. If a dag's source code changes, a new serialized dag will be registered based on the hash diference, and consequently, a new dag version and dag code. The link from dag_version to TI is because of TaskInstance clearing. It helps us retain the previous dag version the task ran with.\r\n\r\nDo you really mean source code? Or do you mean serialized dict?"", 'created_at': datetime.datetime(2024, 10, 28, 21, 27, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2444155329, 'issue_id': 2579528657, 'author': 'ephraimbuddy', 'body': ""> > The versioning is based on the source code changing. If a dag's source code changes, a new serialized dag will be registered based on the hash diference, and consequently, a new dag version and dag code. The link from dag_version to TI is because of TaskInstance clearing. It helps us retain the previous dag version the task ran with.\r\n> \r\n> Do you really mean source code? Or do you mean serialized dict?\r\n\r\nSorry, I meant serialized dict here"", 'created_at': datetime.datetime(2024, 10, 29, 13, 1, 12, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-10-23 00:49:07 UTC): Merge conflicts unfortunately, could you rebase on `main` again please?

ephraimbuddy (Issue Creator) on (2024-10-25 06:35:43 UTC): Resolved

dstandish on (2024-10-28 21:27:55 UTC): Do you really mean source code? Or do you mean serialized dict?

ephraimbuddy (Issue Creator) on (2024-10-29 13:01:12 UTC): Sorry, I meant serialized dict here

"
2579397692,pull_request,closed,,Deprecate session auth backend (backport),"Backport #42909 in `v2-10-test`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-10 17:06:31+00:00,[],2024-10-23 09:08:11+00:00,2024-10-15 13:52:21+00:00,https://github.com/apache/airflow/pull/42911,"[('area:API', ""Airflow's REST/HTTP API""), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]",[],
2579396052,pull_request,closed,,AIP-84 Migrate delete Dag Run endpoint to FastAPI,"related to #42701 

",rawwar,2024-10-10 17:05:32+00:00,[],2024-10-13 10:35:10+00:00,2024-10-13 10:35:10+00:00,https://github.com/apache/airflow/pull/42910,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2408559636, 'issue_id': 2579396052, 'author': 'rawwar', 'body': 'Once PR #42949 is merged, i need to pull the changes and then this PR is good to merge', 'created_at': datetime.datetime(2024, 10, 12, 13, 8, 22, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-12 13:08:22 UTC): Once PR #42949 is merged, i need to pull the changes and then this PR is good to merge

"
2579393402,pull_request,closed,,Deprecate session auth backend,"Follow-up of #42878. Backport PR: #42911.

We cannot remove it in main yet because the old UI is still using it

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-10 17:03:59+00:00,[],2024-10-23 09:08:25+00:00,2024-10-15 13:52:35+00:00,https://github.com/apache/airflow/pull/42909,"[('area:API', ""Airflow's REST/HTTP API""), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:auth', ''), ('provider:fab', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]",[],
2579374057,pull_request,closed,,AIP-84: delete connection endpoint : missing 400 status code,"As per legacy API for delete connection endpoint : [Link](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/delete_connection)

400 is a valid return status code. This PR fixes the FastApi's delete connection endpoint return codes",rawwar,2024-10-10 16:53:41+00:00,[],2024-10-11 04:22:14+00:00,2024-10-11 04:22:14+00:00,https://github.com/apache/airflow/pull/42908,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2406527501, 'issue_id': 2579374057, 'author': 'rawwar', 'body': ""> I don't think there is ever a case in the implementation now that raises a 400 exception, is there ?\r\n\r\nI didn't attempt this previously, but I just attempted to get a 400 now and it doesn't seem possible."", 'created_at': datetime.datetime(2024, 10, 11, 4, 22, 9, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-11 04:22:09 UTC): I didn't attempt this previously, but I just attempted to get a 400 now and it doesn't seem possible.

"
2579336848,pull_request,closed,,Adding support for Kubernetes package version 31.0.0,Adding support for Kubernetes package version 31.0.0,dirrao,2024-10-10 16:37:45+00:00,['dirrao'],2024-10-15 10:09:18+00:00,2024-10-15 10:09:18+00:00,https://github.com/apache/airflow/pull/42907,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2412599146, 'issue_id': 2579336848, 'author': 'potiuk', 'body': 'Mypy check fixed in main. Merging.', 'created_at': datetime.datetime(2024, 10, 15, 0, 47, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412603695, 'issue_id': 2579336848, 'author': 'potiuk', 'body': 'So I guess @dirrao we should close this one.', 'created_at': datetime.datetime(2024, 10, 15, 0, 53, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412819564, 'issue_id': 2579336848, 'author': 'dirrao', 'body': '> So I guess @dirrao we should close this one.\r\n\r\nThe title is mis leading. I have updated it. This PR will add the support for Kubernetes package version 31.0.0 without changing existing min version support.', 'created_at': datetime.datetime(2024, 10, 15, 3, 29, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412844520, 'issue_id': 2579336848, 'author': 'dirrao', 'body': '> Mypy check fixed in main. Merging.\r\n\r\nYah. Checks are braking after PR merge #42539', 'created_at': datetime.datetime(2024, 10, 15, 3, 57, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413462162, 'issue_id': 2579336848, 'author': 'potiuk', 'body': ""> > Mypy check fixed in main. Merging.\r\n> \r\n> Yah. Checks are braking after PR merge #42539\r\n\r\nThey are actually breaking after new release of microsoft's kioto package few hours ago. but yes - that's it."", 'created_at': datetime.datetime(2024, 10, 15, 10, 7, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413466113, 'issue_id': 2579336848, 'author': 'potiuk', 'body': '> The title is mis leading. I have updated it. This PR will add the support for Kubernetes package version 31.0.0 without changing existing min version support.\r\n\r\nRight. Stupid me 🤯 - > but you mislead me with the title so 1:1 😄', 'created_at': datetime.datetime(2024, 10, 15, 10, 9, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 00:47:54 UTC): Mypy check fixed in main. Merging.

potiuk on (2024-10-15 00:53:38 UTC): So I guess @dirrao we should close this one.

dirrao (Issue Creator) on (2024-10-15 03:29:03 UTC): The title is mis leading. I have updated it. This PR will add the support for Kubernetes package version 31.0.0 without changing existing min version support.

dirrao (Issue Creator) on (2024-10-15 03:57:46 UTC): Yah. Checks are braking after PR merge #42539

potiuk on (2024-10-15 10:07:14 UTC): They are actually breaking after new release of microsoft's kioto package few hours ago. but yes - that's it.

potiuk on (2024-10-15 10:09:01 UTC): Right. Stupid me 🤯 - > but you mislead me with the title so 1:1 😄

"
2579285063,pull_request,closed,,Fix main: js/types/api-generated.ts,Main broken due to typescript compilation.,dstandish,2024-10-10 16:09:25+00:00,[],2024-10-10 20:18:33+00:00,2024-10-10 20:18:31+00:00,https://github.com/apache/airflow/pull/42906,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]","[{'comment_id': 2405533091, 'issue_id': 2579285063, 'author': 'ashb', 'body': 'Are we missing some updated rules on breeze selective checks?', 'created_at': datetime.datetime(2024, 10, 10, 16, 13, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405549540, 'issue_id': 2579285063, 'author': 'dstandish', 'body': '> Are we missing some updated rules on breeze selective checks?\r\n\r\ni have a feeling it may have been a sliding windows thing?', 'created_at': datetime.datetime(2024, 10, 10, 16, 21, 43, tzinfo=datetime.timezone.utc)}]","ashb on (2024-10-10 16:13:04 UTC): Are we missing some updated rules on breeze selective checks?

dstandish (Issue Creator) on (2024-10-10 16:21:43 UTC): i have a feeling it may have been a sliding windows thing?

"
2579172885,pull_request,closed,,uv version bump to 0.4.20,uv version bump to 0.4.20,dirrao,2024-10-10 15:21:08+00:00,[],2024-10-15 00:55:16+00:00,2024-10-15 00:55:16+00:00,https://github.com/apache/airflow/pull/42905,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2412604648, 'issue_id': 2579172885, 'author': 'potiuk', 'body': 'UV is a different story thant #42907  @dirrao - this is  ""development/CI"" tool so we should bump it reguarly.', 'created_at': datetime.datetime(2024, 10, 15, 0, 55, 3, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-15 00:55:03 UTC): UV is a different story thant #42907  @dirrao - this is  ""development/CI"" tool so we should bump it reguarly.

"
2579124486,pull_request,closed,,Add skeleton project for task-sdk,"closes https://github.com/apache/airflow/issues/42856 | Part of https://github.com/orgs/apache/projects/405

This PR adds a skeleton project for [AIP-72 Task SDK](https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-72+Task+Execution+Interface+aka+Task+SDK)

It creates this new project, integrates them to breeze & runs it on CI.

The code & tests are just placeholders at this point, we will start adding things needs for DAG Authors in separate PRs.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-10 15:00:02+00:00,[],2024-10-14 01:36:49+00:00,2024-10-12 14:40:10+00:00,https://github.com/apache/airflow/pull/42904,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]","[{'comment_id': 2408935874, 'issue_id': 2579124486, 'author': 'rawwar', 'body': '@kaxil , This change is causing mypy pre-commit check to fail with following error:\r\n\r\n```\r\ntask_sdk/tests/conftest.py:26: error: Incompatible types in assignment\r\n(expression has type ""tuple[()]"", target has type ""Union[str, list[str]]"") \r\n[assignment]\r\n        config.inicfg[""airflow_deprecations_ignore""] = ()\r\n```\r\nShould the value be an empty string?\r\n\r\nOr, I see in other places, we use `# type: ignore[assignment,operator]` comment.\r\n\r\n\r\nEdit: Raised this PR to fix: https://github.com/apache/airflow/pull/42976', 'created_at': datetime.datetime(2024, 10, 13, 11, 14, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409639258, 'issue_id': 2579124486, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 10, 14, 1, 36, 48, tzinfo=datetime.timezone.utc)}]","rawwar on (2024-10-13 11:14:25 UTC): @kaxil , This change is causing mypy pre-commit check to fail with following error:

```
task_sdk/tests/conftest.py:26: error: Incompatible types in assignment
(expression has type ""tuple[()]"", target has type ""Union[str, list[str]]"") 
[assignment]
        config.inicfg[""airflow_deprecations_ignore""] = ()
```
Should the value be an empty string?

Or, I see in other places, we use `# type: ignore[assignment,operator]` comment.


Edit: Raised this PR to fix: https://github.com/apache/airflow/pull/42976

potiuk on (2024-10-14 01:36:48 UTC): Nice!

"
2579080554,pull_request,closed,,Fix main,https://github.com/apache/airflow/pull/42725 got merged with a bad timing compared to https://github.com/apache/airflow/pull/42505,pierrejeambrun,2024-10-10 14:44:45+00:00,['pierrejeambrun'],2024-10-10 15:35:02+00:00,2024-10-10 15:34:59+00:00,https://github.com/apache/airflow/pull/42903,[],[],
2578988289,pull_request,closed,,Fix PythonOperator DAG error when DAG has hyphen in name,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #42796

After reproducing the issue, I found that the generated DAG file looks like this:
```python
import types

unusual_prefix_3f65a6a886883f41209c142108053b32fdfbaf99_my-dag  = types.ModuleType(""unusual_prefix_3f65a6a886883f41209c142108053b32fdfbaf99_my-dag"")

unusual_prefix_3f65a6a886883f41209c142108053b32fdfbaf99_my-dag.callable_virtualenv = callable_virtualenv

sys.modules[""unusual_prefix_3f65a6a886883f41209c142108053b32fdfbaf99_my-dag""] = unusual_prefix_3f65a6a886883f41209c142108053b32fdfbaf99_my-dag

# ...
```
Replace the hyphen with dash in original module name to solve this issue.",jason810496,2024-10-10 14:10:35+00:00,[],2024-10-23 09:12:29+00:00,2024-10-13 01:55:17+00:00,https://github.com/apache/airflow/pull/42902,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2405205907, 'issue_id': 2578988289, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 10, 14, 10, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406531680, 'issue_id': 2578988289, 'author': 'josix', 'body': ""question: I'm wondering if only hyphen character could be causing this issue. Do we have a more general way to prevent this bug from happening?"", 'created_at': datetime.datetime(2024, 10, 11, 4, 27, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406540148, 'issue_id': 2578988289, 'author': 'jason810496', 'body': ""If we directly hash the original module name, it will definitely work.\r\nHowever, I think it's better to convert characters that could be interpreted as Python operators (like `.` or `-`) into underscores.The original module name is derived from the DAG file name by using `rfind` to remove the file extension.\r\nThe original developer probably intended to retain some readability."", 'created_at': datetime.datetime(2024, 10, 11, 4, 38, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408472833, 'issue_id': 2578988289, 'author': 'Lee-W', 'body': 'Looks good to me. Will merge it once CI pass', 'created_at': datetime.datetime(2024, 10, 12, 9, 21, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408781313, 'issue_id': 2578988289, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 13, 1, 55, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408787579, 'issue_id': 2578988289, 'author': 'Lee-W', 'body': '@jason810496 congrate on your first PR 🙂 I think this can be back ported to 2.10.x. Could you please open a PR based on branch `v2-10-test`', 'created_at': datetime.datetime(2024, 10, 13, 2, 13, 50, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-10 14:10:39 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

josix on (2024-10-11 04:27:30 UTC): question: I'm wondering if only hyphen character could be causing this issue. Do we have a more general way to prevent this bug from happening?

jason810496 (Issue Creator) on (2024-10-11 04:38:06 UTC): If we directly hash the original module name, it will definitely work.
However, I think it's better to convert characters that could be interpreted as Python operators (like `.` or `-`) into underscores.The original module name is derived from the DAG file name by using `rfind` to remove the file extension.
The original developer probably intended to retain some readability.

Lee-W on (2024-10-12 09:21:58 UTC): Looks good to me. Will merge it once CI pass

boring-cyborg[bot] on (2024-10-13 01:55:19 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

Lee-W on (2024-10-13 02:13:50 UTC): @jason810496 congrate on your first PR 🙂 I think this can be back ported to 2.10.x. Could you please open a PR based on branch `v2-10-test`

"
2578938438,pull_request,closed,,Remove the referrer from Webserver to Scarf,"This will make sure we don't receive any information about the Webserver URL when sending the info like the number of plugins and such.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-10 13:52:46+00:00,[],2024-10-23 09:15:13+00:00,2024-10-11 12:35:00+00:00,https://github.com/apache/airflow/pull/42901,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2578920794,pull_request,closed,,Make `RedshiftDataOperator`  handle multiple queries,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Updating the `RedshiftDataOperator` to handle returning multiple result sets when more than a single SQL query is passed to the `sql` parameter.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jroachgolf84,2024-10-10 13:46:54+00:00,[],2024-10-15 16:17:11+00:00,2024-10-15 16:17:11+00:00,https://github.com/apache/airflow/pull/42900,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2578663135,pull_request,closed,,Upgrade dependencies to allow us to use SQLAlchemy v2 in Airflow 3.0/main,,ashb,2024-10-10 12:09:59+00:00,[],2024-10-12 16:36:52+00:00,2024-10-12 16:36:49+00:00,https://github.com/apache/airflow/pull/42898,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2404919806, 'issue_id': 2578663135, 'author': 'ashb', 'body': 'This failed before once landed in main https://github.com/apache/airflow/pull/42898 -- but lets try again/more.', 'created_at': datetime.datetime(2024, 10, 10, 12, 10, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406944059, 'issue_id': 2578663135, 'author': 'ashb', 'body': 'How do I get it up update the constrains files using the version in this PR, not the released version of the FAB provider?\r\n\r\n> And because apache-airflow==3.0.0.dev0 depends on sqlalchemy>=2.0,<3.0 and apache-airflow-providers-fab>=1.0.2, we can conclude that apache-airflow==3.0.0.dev0 cannot be used.\r\n>      And because only apache-airflow[all-core]==3.0.0.dev0 is available and you require apache-airflow[all-core], we can conclude that your requirements are unsatisfiable.', 'created_at': datetime.datetime(2024, 10, 11, 8, 52, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408620867, 'issue_id': 2578663135, 'author': 'ashb', 'body': 'Too much in this PR, trying smaller in #42963', 'created_at': datetime.datetime(2024, 10, 12, 16, 36, 49, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-10-10 12:10:18 UTC): This failed before once landed in main https://github.com/apache/airflow/pull/42898 -- but lets try again/more.

ashb (Issue Creator) on (2024-10-11 08:52:37 UTC): How do I get it up update the constrains files using the version in this PR, not the released version of the FAB provider?

ashb (Issue Creator) on (2024-10-12 16:36:49 UTC): Too much in this PR, trying smaller in #42963

"
2578629567,pull_request,closed,,Render errors when getting a list of dags,"Render error messages when getting a list of dags such as if the query params are incorrect:
<img width=""838"" alt=""Screenshot 2024-10-10 at 12 43 22 PM"" src=""https://github.com/user-attachments/assets/fa27bcb1-23d5-48e8-82fd-0e18240eb62f"">
<img width=""772"" alt=""Screenshot 2024-10-10 at 12 43 08 PM"" src=""https://github.com/user-attachments/assets/455dd90f-f14e-40ab-88ed-363705afa85b"">

Closes #42893

I had to do a few things to get this to work:

1. Remove `axios` and switch our codegen to `fetch`. It was much easier to correctly catch the http error.

2. Our opengen treats both error as `unknown` and error.body as `unknown`. [Open GitHub issue on codegen](https://github.com/7nohe/openapi-react-query-codegen/issues/147). Therefore we had to manually assert a lot of the type values, even though they exist in the openapi spec. If there is a new error body type, we will have to manually update this ErrorAlert component.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-10 11:55:17+00:00,[],2024-10-11 12:27:13+00:00,2024-10-11 11:53:26+00:00,https://github.com/apache/airflow/pull/42897,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2406980796, 'issue_id': 2578629567, 'author': 'bbovenzi', 'body': ""> Too bad we can't use axios, lot of boilerplate is done for us. Now we have a bunch of mimetype manual handling and checking.\r\n> \r\n> Do we still have the redirection, to login page on 401 ? (the former interceptor) ?\r\n\r\nActually, it was a bug in our interceptor. I put axios back in and restored our 401 check."", 'created_at': datetime.datetime(2024, 10, 11, 9, 11, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407309729, 'issue_id': 2578629567, 'author': 'pierrejeambrun', 'body': '> Actually, it was a bug in our interceptor. I put axios back in and restored our 401 check.\r\n\r\nNice !', 'created_at': datetime.datetime(2024, 10, 11, 12, 27, 12, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2024-10-11 09:11:14 UTC): Actually, it was a bug in our interceptor. I put axios back in and restored our 401 check.

pierrejeambrun on (2024-10-11 12:27:12 UTC): Nice !

"
2578615771,pull_request,closed,,Add search by dag_display_name_pattern on dag list page with rebase,"New PR after rebase for https://github.com/apache/airflow/pull/42797

https://github.com/user-attachments/assets/3428c9e1-5699-4053-a5a4-d8c7c483afc5

* I have updated the URL to reflect changes in the `dagDisplayNamePattern`. If this is not desirable, I can remove it.
* I created an enum in `searchParams.ts`.

There are a few issues to address:
* The `dagDisplayNamePattern` does not accurately find or include the DAGs when the text matches the tag name exactly. The reason for this is unclear.
* The spinner is not centered. I removed the conditional rendering logic for `DagsList` based on `isLoading`, as it was causing the entire `DagsList` component to re-render every time the data was updated.

[
Closes: https://github.com/apache/airflow/issues/27581
](https://github.com/apache/airflow/issues/42714)",luyangliuable,2024-10-10 11:50:18+00:00,[],2024-10-15 12:30:23+00:00,2024-10-15 12:30:19+00:00,https://github.com/apache/airflow/pull/42896,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2406829124, 'issue_id': 2578615771, 'author': 'bbovenzi', 'body': 'Looks like we need to run `pnpm format` too and that should fix the static checks', 'created_at': datetime.datetime(2024, 10, 11, 8, 5, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407126276, 'issue_id': 2578615771, 'author': 'luyangliuable', 'body': 'Thanks, I ran `pnpm format` and committed the styling updates.', 'created_at': datetime.datetime(2024, 10, 11, 10, 34, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413782500, 'issue_id': 2578615771, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 15, 12, 30, 22, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-10-11 08:05:56 UTC): Looks like we need to run `pnpm format` too and that should fix the static checks

luyangliuable (Issue Creator) on (2024-10-11 10:34:26 UTC): Thanks, I ran `pnpm format` and committed the styling updates.

boring-cyborg[bot] on (2024-10-15 12:30:22 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2578581156,pull_request,closed,,Feature/search by dag display name pattern rebase,Bew PR with rebase for https://github.com/apache/airflow/pull/42797,luyangliuable,2024-10-10 11:37:01+00:00,[],2024-10-10 11:39:14+00:00,2024-10-10 11:39:14+00:00,https://github.com/apache/airflow/pull/42895,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2578326393,pull_request,closed,,Make conn id parameters templated in GenericTransfer and also allow passing hook parameters like in BaseSQLOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Today I've discovered that the conn id parameters (source_conn_id and destination_conn_id) aren't templated in the GenericTransfer. This PR will also allow passing hook parameters like in BaseSQLOperator.  Refactored the get_hook method in BaseOperator so that in the future it can be used in a generic way, added tests to remove backward compatibility code for Airflow 2.8.x once min version of provider is Aiflow 3.0.0 or higher.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-10-10 10:10:23+00:00,[],2024-10-24 11:17:17+00:00,2024-10-24 09:34:57+00:00,https://github.com/apache/airflow/pull/42891,"[('area:providers', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:common-sql', '')]","[{'comment_id': 2409547028, 'issue_id': 2578326393, 'author': 'potiuk', 'body': 'Looks like there is some problem with minimum version of one of microsoft dependencies.  Bringing it down, brings opentelemetry dependency down and this seems to break imports. Unfold the failng test output for microsoft.azure and you will see it:\r\n\r\nhttps://github.com/apache/airflow/actions/runs/11299097052/job/31429704576?pr=42891#step:7:6196', 'created_at': datetime.datetime(2024, 10, 14, 1, 1, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410265134, 'issue_id': 2578326393, 'author': 'dabla', 'body': '> Looks like there is some problem with minimum version of one of microsoft dependencies. Bringing it down, brings opentelemetry dependency down and this seems to break imports. Unfold the failng test output for microsoft.azure and you will see it:\r\n> \r\n> https://github.com/apache/airflow/actions/runs/11299097052/job/31429704576?pr=42891#step:7:6196\r\n\r\nSeems to be fine now after I updated the branch', 'created_at': datetime.datetime(2024, 10, 14, 7, 27, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412477683, 'issue_id': 2578326393, 'author': 'potiuk', 'body': 'There are some compatibility Airflow 3 / Airflow 2 issues that need to be addressed :)', 'created_at': datetime.datetime(2024, 10, 14, 22, 58, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419433389, 'issue_id': 2578326393, 'author': 'dabla', 'body': '> There are some compatibility Airflow 3 / Airflow 2 issues that need to be addressed :)\r\n\r\nAll issues fixed', 'created_at': datetime.datetime(2024, 10, 17, 12, 39, 20, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-14 01:01:23 UTC): Looks like there is some problem with minimum version of one of microsoft dependencies.  Bringing it down, brings opentelemetry dependency down and this seems to break imports. Unfold the failng test output for microsoft.azure and you will see it:

https://github.com/apache/airflow/actions/runs/11299097052/job/31429704576?pr=42891#step:7:6196

dabla (Issue Creator) on (2024-10-14 07:27:31 UTC): Seems to be fine now after I updated the branch

potiuk on (2024-10-14 22:58:38 UTC): There are some compatibility Airflow 3 / Airflow 2 issues that need to be addressed :)

dabla (Issue Creator) on (2024-10-17 12:39:20 UTC): All issues fixed

"
2578184540,pull_request,closed,,add majorosdonat as bosch user,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Added majorosdonatas bosch user

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-10-10 09:14:03+00:00,[],2024-10-10 09:34:18+00:00,2024-10-10 09:34:15+00:00,https://github.com/apache/airflow/pull/42890,[],"[{'comment_id': 2404546494, 'issue_id': 2578184540, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 10, 9, 14, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404588953, 'issue_id': 2578184540, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 10, 9, 34, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-10 09:14:07 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-10 09:34:18 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2577880828,pull_request,closed,,Fix dag warning documentation (#42858),(cherry picked from commit b7c8ebb7d9f0d5a3d1598667371ab69582b4e66a),pierrejeambrun,2024-10-10 07:17:03+00:00,['pierrejeambrun'],2024-10-10 08:09:31+00:00,2024-10-10 08:09:29+00:00,https://github.com/apache/airflow/pull/42888,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2577733967,pull_request,closed,,Docs: Add templating info to TaskFlow tutorial,"Hi everyone,

I had some trouble with templating while I was transitioning from the old operator workflow to the Task Flow API.

So, I decided to write up what I learned in the documentation to make life a little easier for others.

Please let me know if you'd like any changes and I will be happy to rewrite it.",infused-kim,2024-10-10 06:13:15+00:00,[],2024-10-23 09:13:27+00:00,2024-10-11 06:26:51+00:00,https://github.com/apache/airflow/pull/42887,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2406637893, 'issue_id': 2577733967, 'author': 'shahar1', 'body': 'Looks good, thanks!', 'created_at': datetime.datetime(2024, 10, 11, 6, 26, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408609108, 'issue_id': 2577733967, 'author': 'infused-kim', 'body': 'Awesome. Thank you so much for reviewing it so quickly.', 'created_at': datetime.datetime(2024, 10, 12, 15, 56, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409637581, 'issue_id': 2577733967, 'author': 'potiuk', 'body': 'Can you please cherry-pick it (with -x) to v2-10-test and make a ""backport"" PR @infused-kim ? This one looks like a good candidate to include in 2.10.3', 'created_at': datetime.datetime(2024, 10, 14, 1, 36, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409899401, 'issue_id': 2577733967, 'author': 'infused-kim', 'body': '@potiuk sure thing, I just did it here:\r\nhttps://github.com/apache/airflow/pull/42992', 'created_at': datetime.datetime(2024, 10, 14, 4, 2, 28, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-10-11 06:26:44 UTC): Looks good, thanks!

infused-kim (Issue Creator) on (2024-10-12 15:56:58 UTC): Awesome. Thank you so much for reviewing it so quickly.

potiuk on (2024-10-14 01:36:03 UTC): Can you please cherry-pick it (with -x) to v2-10-test and make a ""backport"" PR @infused-kim ? This one looks like a good candidate to include in 2.10.3

infused-kim (Issue Creator) on (2024-10-14 04:02:28 UTC): @potiuk sure thing, I just did it here:
https://github.com/apache/airflow/pull/42992

"
2577588000,pull_request,closed,,Fix broken stat scheduler_loop_duration,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The stat `scheduler_loop_duration` is broken since [this](https://github.com/apache/airflow/commit/0f4884c3ca26c39bc6bd21967c950e718589fcd6#diff-b0491913f69327937706aea8fc77a71efeb979897898e405ade2b162ad862476R1104) change. The nesting of the stats context statement results in it not capturing the full scheduler loop duration. This PR fixes the nesting.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",0vj00,2024-10-10 04:52:05+00:00,[],2024-11-01 08:38:55+00:00,2024-10-17 22:46:36+00:00,https://github.com/apache/airflow/pull/42886,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2404007698, 'issue_id': 2577588000, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 10, 4, 52, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404232444, 'issue_id': 2577588000, 'author': '0vj00', 'body': ""@howardyoo - I'd appreciate if you can review as well, since this follows up on your original PR https://github.com/apache/airflow/pull/40802"", 'created_at': datetime.datetime(2024, 10, 10, 7, 9, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405099300, 'issue_id': 2577588000, 'author': 'howardyoo', 'body': 'Thanks, I’ll take a look!Sent from my iPhoneOn Oct 10, 2024, at 2:09\u202fAM, Venkat VJ ***@***.***> wrote:\ufeff\r\n@howardyoo - Would appreciate if you can review as well, since this follows up on your original PR #40802\r\n\r\n—Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you were mentioned.Message ID: ***@***.***>', 'created_at': datetime.datetime(2024, 10, 10, 13, 29, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409033492, 'issue_id': 2577588000, 'author': 'potiuk', 'body': 'I approved the run - @howardyoo, would be great to get the review. Also - if we could have some unit test for that (can we?) it would be great.', 'created_at': datetime.datetime(2024, 10, 13, 16, 6, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411153262, 'issue_id': 2577588000, 'author': 'howardyoo', 'body': ""> I approved the run - @howardyoo, would be great to get the review. Also - if we could have some unit test for that (can we?) it would be great.\r\n\r\nI don't think this can be unit-tested..?\r\nThe fix seems to be related to some changes that happened outside of Airflow OTEL implementation, but the code change makes sense. So I'd say let's approve and merge it."", 'created_at': datetime.datetime(2024, 10, 14, 12, 53, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420753599, 'issue_id': 2577588000, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 17, 22, 46, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2442924194, 'issue_id': 2577588000, 'author': 'sunchao', 'body': '@potiuk @0vj00 any chance this can be added to Airflow 2.10.3 release? we are seeing the same issue as well', 'created_at': datetime.datetime(2024, 10, 29, 0, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443818236, 'issue_id': 2577588000, 'author': 'potiuk', 'body': ""> @potiuk @0vj00 any chance this can be added to Airflow 2.10.3 release? we are seeing the same issue as well\r\n\r\nNo. Not unless 2.10.3 rc1 is cancelled and we attempt to do 2.10.3rc2 (cc: @utkarsharma2 @ephraimbuddy ) -> I marked it provisionally for 2.10.4 - next time it's a good idea to mention it before we prepare a new release, that things are good candidates and would be great to back-port."", 'created_at': datetime.datetime(2024, 10, 29, 10, 23, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445213001, 'issue_id': 2577588000, 'author': 'sunchao', 'body': 'I see, thanks @potiuk', 'created_at': datetime.datetime(2024, 10, 29, 20, 0, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2449449960, 'issue_id': 2577588000, 'author': 'potiuk', 'body': 'We are going to have rc2 - > backporting that one in #43544', 'created_at': datetime.datetime(2024, 10, 31, 9, 50, 14, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-10 04:52:10 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

0vj00 (Issue Creator) on (2024-10-10 07:09:33 UTC): @howardyoo - I'd appreciate if you can review as well, since this follows up on your original PR https://github.com/apache/airflow/pull/40802

howardyoo on (2024-10-10 13:29:26 UTC): Thanks, I’ll take a look!Sent from my iPhoneOn Oct 10, 2024, at 2:09 AM, Venkat VJ ***@***.***> wrote:﻿
@howardyoo - Would appreciate if you can review as well, since this follows up on your original PR #40802

—Reply to this email directly, view it on GitHub, or unsubscribe.You are receiving this because you were mentioned.Message ID: ***@***.***>

potiuk on (2024-10-13 16:06:12 UTC): I approved the run - @howardyoo, would be great to get the review. Also - if we could have some unit test for that (can we?) it would be great.

howardyoo on (2024-10-14 12:53:46 UTC): I don't think this can be unit-tested..?
The fix seems to be related to some changes that happened outside of Airflow OTEL implementation, but the code change makes sense. So I'd say let's approve and merge it.

boring-cyborg[bot] on (2024-10-17 22:46:38 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

sunchao on (2024-10-29 00:28:00 UTC): @potiuk @0vj00 any chance this can be added to Airflow 2.10.3 release? we are seeing the same issue as well

potiuk on (2024-10-29 10:23:03 UTC): No. Not unless 2.10.3 rc1 is cancelled and we attempt to do 2.10.3rc2 (cc: @utkarsharma2 @ephraimbuddy ) -> I marked it provisionally for 2.10.4 - next time it's a good idea to mention it before we prepare a new release, that things are good candidates and would be great to back-port.

sunchao on (2024-10-29 20:00:17 UTC): I see, thanks @potiuk

potiuk on (2024-10-31 09:50:14 UTC): We are going to have rc2 - > backporting that one in #43544

"
2577361586,pull_request,closed,,Issue 40427,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jroachgolf84,2024-10-10 02:27:54+00:00,[],2024-10-10 03:39:50+00:00,2024-10-10 03:39:50+00:00,https://github.com/apache/airflow/pull/42885,[],[],
2577297783,pull_request,closed,,Fix issue generation for providers,"```

Retrieving 53 PRs  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00
Traceback (most recent call last):
  File ""/Users/eladkal/.local/bin/breeze"", line 8, in <module>
    sys.exit(main())
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/rich_click/rich_command.py"", line 367, in __call__
    return super().__call__(*args, **kwargs)
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/click/core.py"", line 1157, in __call__
    return self.main(*args, **kwargs)
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/rich_click/rich_command.py"", line 152, in main
    rv = self.invoke(ctx)
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/click/core.py"", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/click/core.py"", line 1688, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/click/core.py"", line 1434, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/Users/eladkal/.local/pipx/venvs/apache-airflow-breeze/lib/python3.9/site-packages/click/core.py"", line 783, in invoke
    return __callback(*args, **kwargs)
  File ""/Users/eladkal/PycharmProjects/airflow/dev/breeze/src/airflow_breeze/commands/release_management_commands.py"", line 2127, in generate_issue_content_providers
    (
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.9.18/lib/python3.9/pathlib.py"", line 1266, in read_text
    with self.open(mode='r', encoding=encoding, errors=errors) as f:
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.9.18/lib/python3.9/pathlib.py"", line 1252, in open
    return io.open(self, mode, buffering, encoding, errors, newline,
  File ""/Users/eladkal/.local/share/rtx/installs/python/3.9.18/lib/python3.9/pathlib.py"", line 1120, in _opener
    return self._accessor.open(self, flags, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/Users/eladkal/PycharmProjects/airflow/airflow/providers/amazon/provider.yaml'
```

Fix the location of provider folder in issue generation command after https://github.com/apache/airflow/pull/42505",eladkal,2024-10-10 01:36:03+00:00,[],2024-10-10 08:54:09+00:00,2024-10-10 07:22:24+00:00,https://github.com/apache/airflow/pull/42883,"[('area:dev-tools', '')]",[],
2576911268,pull_request,closed,,Bump `blacken-docs` pre-commit,"Bump `blacken-docs` pre-commit from 1.18.0 -> 1.19.0

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-09 20:41:35+00:00,[],2024-10-09 20:59:38+00:00,2024-10-09 20:59:37+00:00,https://github.com/apache/airflow/pull/42880,"[('area:dev-tools', '')]",[],
2576883606,pull_request,closed,,Move the session auth backend to FAB auth manager,"This is in preparation of deprecating the session auth backend from core Airflow. It should be part of FAB auth manager. By default in Airflow, session will not be used. Authentication will be done by JWT token (see draft in #42634).

I did not deprecate the session auth backend as part of this PR because I intend to backport the PR that adds deprecation warning to `v2-10-test` branch.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-09 20:26:14+00:00,[],2024-10-10 13:06:56+00:00,2024-10-10 13:06:54+00:00,https://github.com/apache/airflow/pull/42878,"[('area:providers', ''), ('provider:fab', '')]",[],
2576846028,pull_request,closed,,"Exclude ""not-ready"" providers when building docs","
This fixes the issue we saw in https://apache-airflow.slack.com/archives/C03G9H97MM2/p1728492002477169

This PR excludes the providers that aren't ready yet for building docs.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-09 20:02:24+00:00,[],2024-10-09 22:02:44+00:00,2024-10-09 22:02:42+00:00,https://github.com/apache/airflow/pull/42873,"[('kind:documentation', '')]",[],
2576717292,pull_request,closed,,Fix deprecated stage names for Pre-commit,"Before
```
❯ pre-commit install
[WARNING] top-level `default_stages` uses deprecated stage names (commit, push) which will be removed in a future version.  run: `pre-commit migrate-config` to automatically fix this.
pre-commit installed at .git/hooks/pre-commit
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-09 19:01:15+00:00,[],2024-10-13 01:15:40+00:00,2024-10-09 20:31:26+00:00,https://github.com/apache/airflow/pull/42872,"[('area:dev-tools', '')]","[{'comment_id': 2408772814, 'issue_id': 2576717292, 'author': 'potiuk', 'body': 'Nice', 'created_at': datetime.datetime(2024, 10, 13, 1, 15, 39, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-13 01:15:39 UTC): Nice

"
2576600605,pull_request,closed,,Fix retry configuration in k8s tests,"Updating the retry configuration with `status_forcelist` and `allowed_methods`.

By default, the retry configuration's `status_forcelist` is set to None, meaning no action is taken when an error response is received.

Additionally, the default `allowed_methods` does not include the PATCH and POST methods. In k8s test, API endpoints use the PATCH and POST methods for the following routes:

`api/v1/dags/{dag_id}`: PATCH
`api/v1/dags/{dag_id}/dagRuns`: POST

https://urllib3.readthedocs.io/en/stable/reference/urllib3.util.html#urllib3.util.Retry

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-09 18:09:16+00:00,[],2024-11-23 19:54:32+00:00,2024-10-09 20:54:20+00:00,https://github.com/apache/airflow/pull/42871,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2576593772,pull_request,closed,,include limit and offset in request body schema for List task instances (batch) endpoint ,"closes #40038 

The endpoint already accepts limit and offset.",rawwar,2024-10-09 18:05:10+00:00,[],2024-11-01 08:49:29+00:00,2024-10-28 12:39:22+00:00,https://github.com/apache/airflow/pull/42870,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2403202101, 'issue_id': 2576593772, 'author': 'ephraimbuddy', 'body': 'You also need to add this: https://github.com/apache/airflow/blob/2eda7376f4c27df82f0cafba7699bcc46c3fcd05/airflow/api_connexion/endpoints/task_instance_endpoint.py#L377-L378 around this place: https://github.com/apache/airflow/blob/2eda7376f4c27df82f0cafba7699bcc46c3fcd05/airflow/api_connexion/endpoints/task_instance_endpoint.py#L451', 'created_at': datetime.datetime(2024, 10, 9, 19, 9, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404026633, 'issue_id': 2576593772, 'author': 'rawwar', 'body': 'Working on writing tests', 'created_at': datetime.datetime(2024, 10, 10, 5, 0, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404389489, 'issue_id': 2576593772, 'author': 'pierrejeambrun', 'body': ""Is this a new feature ? The original endpoint need an extra piece of code in the query to actually handle pagination right ?\r\n\r\nBecause there no 'feature' release left for 2.x and in airflow 3 this piece of code will be deleted. We can still add it for the 'migration effort' to remember that we need to have the pagination here though.\r\n\r\nOr maybe we can consider this a bugfix or miscellaneous and squeeze that in the next 2.x patch release @ephraimbuddy"", 'created_at': datetime.datetime(2024, 10, 10, 8, 11, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404403801, 'issue_id': 2576593772, 'author': 'ephraimbuddy', 'body': ""> Is this a new feature ? The original endpoint need an extra piece of code in the query to actually handle pagination right ?\r\n> \r\n> Because there no 'feature' release left for 2.x and in airflow 3 this piece of code will be deleted. We can still add it for the 'migration effort' to remember that we need to have the pagination here though.\r\n> \r\n> Or maybe we can consider this a bugfix or miscellaneous and squeeze that in the next 2.x patch release @ephraimbuddy\r\n\r\nYes. It's a bug fix. The code already has pagelimit in the schema but that was not exposed. We will release it as part of 2.x when it's merged"", 'created_at': datetime.datetime(2024, 10, 10, 8, 17, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441479533, 'issue_id': 2576593772, 'author': 'ephraimbuddy', 'body': '@rawwar can you backport this to v2-10-test?', 'created_at': datetime.datetime(2024, 10, 28, 12, 40, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2441651242, 'issue_id': 2576593772, 'author': 'rawwar', 'body': ""> @rawwar can you backport this to v2-10-test?\r\n\r\nJust raised a draft PR: https://github.com/apache/airflow/pull/43442\r\n\r\nChanges are a bit different as we haven't removed SLA related code in 2.x."", 'created_at': datetime.datetime(2024, 10, 28, 13, 51, 41, tzinfo=datetime.timezone.utc)}]","ephraimbuddy on (2024-10-09 19:09:07 UTC): You also need to add this: https://github.com/apache/airflow/blob/2eda7376f4c27df82f0cafba7699bcc46c3fcd05/airflow/api_connexion/endpoints/task_instance_endpoint.py#L377-L378 around this place: https://github.com/apache/airflow/blob/2eda7376f4c27df82f0cafba7699bcc46c3fcd05/airflow/api_connexion/endpoints/task_instance_endpoint.py#L451

rawwar (Issue Creator) on (2024-10-10 05:00:32 UTC): Working on writing tests

pierrejeambrun on (2024-10-10 08:11:56 UTC): Is this a new feature ? The original endpoint need an extra piece of code in the query to actually handle pagination right ?

Because there no 'feature' release left for 2.x and in airflow 3 this piece of code will be deleted. We can still add it for the 'migration effort' to remember that we need to have the pagination here though.

Or maybe we can consider this a bugfix or miscellaneous and squeeze that in the next 2.x patch release @ephraimbuddy

ephraimbuddy on (2024-10-10 08:17:25 UTC): Yes. It's a bug fix. The code already has pagelimit in the schema but that was not exposed. We will release it as part of 2.x when it's merged

ephraimbuddy on (2024-10-28 12:40:06 UTC): @rawwar can you backport this to v2-10-test?

rawwar (Issue Creator) on (2024-10-28 13:51:41 UTC): Just raised a draft PR: https://github.com/apache/airflow/pull/43442

Changes are a bit different as we haven't removed SLA related code in 2.x.

"
2576577693,pull_request,closed,,Move user and roles schemas to fab provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-09 17:56:27+00:00,[],2024-10-10 13:08:45+00:00,2024-10-10 13:08:43+00:00,https://github.com/apache/airflow/pull/42869,"[('area:providers', ''), ('provider:fab', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2404982747, 'issue_id': 2576577693, 'author': 'pierrejeambrun', 'body': 'This is targeted for airflow 3 right ? Because I was wondering how core would now depend on latest FAB provider release otherwise.', 'created_at': datetime.datetime(2024, 10, 10, 12, 41, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405049073, 'issue_id': 2576577693, 'author': 'vincbeck', 'body': '> This is targeted for airflow 3 right ? Because I was wondering how core would now depend on latest FAB provider release otherwise.\r\n\r\nTrue and these fails are not used in core Airflow anyway. This is something I missed when working on AIP-56,these files should have been moved back then', 'created_at': datetime.datetime(2024, 10, 10, 13, 8, 40, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-10 12:41:06 UTC): This is targeted for airflow 3 right ? Because I was wondering how core would now depend on latest FAB provider release otherwise.

vincbeck (Issue Creator) on (2024-10-10 13:08:40 UTC): True and these fails are not used in core Airflow anyway. This is something I missed when working on AIP-56,these files should have been moved back then

"
2576456431,pull_request,closed,,Revert Asset to Dataset for Core Extension Doc,"This PR reverts Core Extension doc change (https://airflow.apache.org/docs/apache-airflow-providers/core-extensions/index.html) from https://github.com/apache/airflow/pull/41348

Since those docs only work on Airflow stable, we can only change this after 3.0 as those are cross-references

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-09 16:53:09+00:00,[],2024-10-09 18:46:18+00:00,2024-10-09 18:45:50+00:00,https://github.com/apache/airflow/pull/42867,"[('kind:documentation', '')]","[{'comment_id': 2403068910, 'issue_id': 2576456431, 'author': 'kaxil', 'body': ""Merging regardless of failures since the failure seem to be unrelated to Assets:\r\n\r\n```\r\n############################## Start docs build errors summary ##############################\r\n============================== apache-airflow-providers ==============================\r\n------------------------------ Error   1 --------------------\r\n WARNING: unknown document: 'apache-airflow-providers-edge:configurations-ref'\r\nFile path: /opt/airflow/docs/apache-airflow-providers/<unknown>\r\n------------------------------ Error   2 --------------------\r\n WARNING: unknown document: 'apache-airflow-providers-opensearch:configurations-ref'\r\nFile path: /opt/airflow/docs/apache-airflow-providers/<unknown>\r\n------------------------------ Error   3 --------------------\r\n WARNING: unknown document: 'apache-airflow-providers-opensearch:logging/index'\r\nFile path: /opt/airflow/docs/apache-airflow-providers/<unknown>\r\n------------------------------ Error   4 --------------------\r\n WARNING: unknown document: 'apache-airflow-providers-standard:operators'\r\nFile path: /opt/airflow/docs/apache-airflow-providers/<unknown>\r\n------------------------------ Error   5 --------------------\r\n WARNING: unknown document: 'apache-airflow-providers-snowflake:operators/snowpark'\r\nFile path: /opt/airflow/docs/apache-airflow-providers/<unknown>\r\n############################## End docs build errors summary ##############################\r\n```"", 'created_at': datetime.datetime(2024, 10, 9, 18, 46, 17, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-10-09 18:46:17 UTC): Merging regardless of failures since the failure seem to be unrelated to Assets:

```
############################## Start docs build errors summary ##############################
============================== apache-airflow-providers ==============================
------------------------------ Error   1 --------------------
 WARNING: unknown document: 'apache-airflow-providers-edge:configurations-ref'
File path: /opt/airflow/docs/apache-airflow-providers/<unknown>
------------------------------ Error   2 --------------------
 WARNING: unknown document: 'apache-airflow-providers-opensearch:configurations-ref'
File path: /opt/airflow/docs/apache-airflow-providers/<unknown>
------------------------------ Error   3 --------------------
 WARNING: unknown document: 'apache-airflow-providers-opensearch:logging/index'
File path: /opt/airflow/docs/apache-airflow-providers/<unknown>
------------------------------ Error   4 --------------------
 WARNING: unknown document: 'apache-airflow-providers-standard:operators'
File path: /opt/airflow/docs/apache-airflow-providers/<unknown>
------------------------------ Error   5 --------------------
 WARNING: unknown document: 'apache-airflow-providers-snowflake:operators/snowpark'
File path: /opt/airflow/docs/apache-airflow-providers/<unknown>
############################## End docs build errors summary ##############################
```

"
2576360834,pull_request,closed,,Can specify dag run conf with backfill,"This actually does a little bit more.  It changes the backfill create endpoint to take a json payload instead of just query params.  This is just easier because we can use the backfill schema as the schema of the request body.

One thing that is maybe weird is I add a decorator to translate the request body to the kwargs in the endpoint function.  The main motivator here was for compatibility with the requires_access_dag decorator, which doesn't check request body.
",dstandish,2024-10-09 16:06:11+00:00,[],2024-10-10 15:16:04+00:00,2024-10-10 15:16:02+00:00,https://github.com/apache/airflow/pull/42865,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2576230758,pull_request,closed,,"Revert ""Remove `sqlalchemy-redshift` dependency from Amazon provider""","Reverts apache/airflow#42830 - this breaks tests https://github.com/apache/airflow/actions/runs/11250263626
",mobuchowski,2024-10-09 15:14:06+00:00,[],2024-10-09 15:55:34+00:00,2024-10-09 15:28:07+00:00,https://github.com/apache/airflow/pull/42864,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2402642615, 'issue_id': 2576230758, 'author': 'vincbeck', 'body': 'Too good to be true 😢  But why these tests did not fail in my PR is a mystery', 'created_at': datetime.datetime(2024, 10, 9, 15, 22, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402645790, 'issue_id': 2576230758, 'author': 'gopidesupavan', 'body': '> Too good to be true 😢 But why these tests did not fail in my PR is a mystery\r\n\r\nHad same question when I saw the schedule ci failures..', 'created_at': datetime.datetime(2024, 10, 9, 15, 23, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402717947, 'issue_id': 2576230758, 'author': 'kaxil', 'body': 'Huh interesting', 'created_at': datetime.datetime(2024, 10, 9, 15, 55, 32, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-10-09 15:22:05 UTC): Too good to be true 😢  But why these tests did not fail in my PR is a mystery

gopidesupavan on (2024-10-09 15:23:28 UTC): Had same question when I saw the schedule ci failures..

kaxil on (2024-10-09 15:55:32 UTC): Huh interesting

"
2576210881,pull_request,closed,,AIP-84 Fix dag display name search,"Fix the dag display name search.

I had that property.expression at some point and figured it wasn't necessary anymore because tests were green even when I removed it. Apparently it was still required :)",pierrejeambrun,2024-10-09 15:05:27+00:00,['pierrejeambrun'],2024-10-11 07:31:12+00:00,2024-10-11 07:31:10+00:00,https://github.com/apache/airflow/pull/42863,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2402618397, 'issue_id': 2576210881, 'author': 'pierrejeambrun', 'body': 'Just pushing a test case update that will actually break without that extra piece of code. (dag_dispaly_name is not set, and the porperty is then defaulting to the `dag_id` value)', 'created_at': datetime.datetime(2024, 10, 9, 15, 11, 50, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-10-09 15:11:50 UTC): Just pushing a test case update that will actually break without that extra piece of code. (dag_dispaly_name is not set, and the porperty is then defaulting to the `dag_id` value)

"
2576200217,pull_request,closed,,Prepare docs for Oct 1st adhoc wave of providers,"```
Summary of prepared documentation:

Success: 24

amazon apache.beam apache.kafka apache.spark celery cloudant cncf.kubernetes common.compat common.io common.sql databricks dbt.cloud elasticsearch fab google jdbc microsoft.azure mysql openlineage
opensearch postgres snowflake trino ydb

Skipped on no changes: 67

airbyte alibaba apache.cassandra apache.drill apache.druid apache.flink apache.hdfs apache.hive apache.iceberg apache.impala apache.kylin apache.livy apache.pig apache.pinot apprise arangodb asana
atlassian.jira cohere datadog dingding discord docker exasol facebook ftp github grpc hashicorp http imap influxdb jenkins microsoft.mssql microsoft.psrp microsoft.winrm mongo neo4j odbc openai openfaas
opsgenie oracle pagerduty papermill pgvector pinecone presto qdrant redis salesforce samba segment sendgrid sftp singularity slack smtp sqlite ssh tableau telegram teradata vertica weaviate yandex
zendesk


Successfully prepared documentation for packages!
```",eladkal,2024-10-09 15:01:17+00:00,[],2024-10-09 16:10:50+00:00,2024-10-09 16:10:46+00:00,https://github.com/apache/airflow/pull/42862,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:databricks', ''), ('provider:celery', ''), ('provider:apache-kafka', ''), ('provider:apache-spark', ''), ('provider:apache-beam', ''), ('provider:cloudant', ''), ('provider:common-io', ''), ('provider:common-compat', '')]",[],
2576199933,pull_request,closed,,Change directory used by simple auth manager to store generated passwords,"See [discussion](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1728484901687309?thread_ts=1728483230.037469&cid=C06K9Q5G2UA)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-09 15:01:11+00:00,[],2024-10-17 14:55:07+00:00,2024-10-13 22:06:59+00:00,https://github.com/apache/airflow/pull/42860,[],"[{'comment_id': 2403045985, 'issue_id': 2576199933, 'author': 'vincbeck', 'body': '> Looks good for me.\r\n> \r\n> Would be ""cool"" if not created that upon start via Breeze the default admin/admin is created by Breeze so that after clean checkout it runs out-of-the-box... but not required in this PR...\r\n\r\nA user is created if no user is defined and generate the password for you. The file where the password is saved is now in `/files` so that the password does not change every-time you restart your env. You can also modify the password directly in this file and set it to `admin` if you want', 'created_at': datetime.datetime(2024, 10, 9, 18, 42, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403399704, 'issue_id': 2576199933, 'author': 'potiuk', 'body': 'Maybe we can have a non-specific env variable and define it in BREEZE instead? \r\n\r\nsay `AIRFLOW_AUTH_MANAGER_CREDENTIAL_DIRECTORY` ? Then we will just have to set it in `entrypoint_ci.sh`.', 'created_at': datetime.datetime(2024, 10, 9, 20, 47, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403404780, 'issue_id': 2576199933, 'author': 'kaxil', 'body': '> Maybe we can have a non-specific env variable and define it in BREEZE instead?\r\n> \r\n> say `AIRFLOW_AUTH_MANAGER_CREDENTIAL_DIRECTORY` ? Then we will just have to set it in `entrypoint_ci.sh`.\r\n\r\nYeah, I like that', 'created_at': datetime.datetime(2024, 10, 9, 20, 50, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405624694, 'issue_id': 2576199933, 'author': 'vincbeck', 'body': 'I just did as you suggested :)', 'created_at': datetime.datetime(2024, 10, 10, 17, 0, 39, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-10-09 18:42:09 UTC): A user is created if no user is defined and generate the password for you. The file where the password is saved is now in `/files` so that the password does not change every-time you restart your env. You can also modify the password directly in this file and set it to `admin` if you want

potiuk on (2024-10-09 20:47:10 UTC): Maybe we can have a non-specific env variable and define it in BREEZE instead? 

say `AIRFLOW_AUTH_MANAGER_CREDENTIAL_DIRECTORY` ? Then we will just have to set it in `entrypoint_ci.sh`.

kaxil on (2024-10-09 20:50:33 UTC): Yeah, I like that

vincbeck (Issue Creator) on (2024-10-10 17:00:39 UTC): I just did as you suggested :)

"
2576035121,pull_request,closed,,Fix dag warning documentation,"Fix the documentation that is not in lined with the actual response. `dag_warnings` is returned while the documentation and spec specify `import_errrors`:
![Screenshot 2024-10-09 at 15 59 19](https://github.com/user-attachments/assets/1bce5db8-e787-4675-b685-87cba32c8b3f)
![Screenshot 2024-10-09 at 15 59 48](https://github.com/user-attachments/assets/1d118af7-b9c1-4798-846e-89f94841d4a3)
",pierrejeambrun,2024-10-09 13:59:58+00:00,['pierrejeambrun'],2024-10-10 07:15:44+00:00,2024-10-10 07:15:41+00:00,https://github.com/apache/airflow/pull/42858,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2575995087,pull_request,closed,,Fix spelling; `Airlfow` -> `Airflow`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jbampton,2024-10-09 13:46:25+00:00,[],2024-10-09 14:03:27+00:00,2024-10-09 14:00:11+00:00,https://github.com/apache/airflow/pull/42855,"[('area:providers', ''), ('provider:elasticsearch', '')]",[],
2575945093,pull_request,closed,,Fix ui lint pre-commit interactive mode,Try to fix pre-commit errors caused by interactive mode of pnpm.,pierrejeambrun,2024-10-09 13:28:25+00:00,['pierrejeambrun'],2024-10-09 20:35:07+00:00,2024-10-09 20:32:28+00:00,https://github.com/apache/airflow/pull/42854,"[('area:dev-tools', '')]","[{'comment_id': 2402353669, 'issue_id': 2575945093, 'author': 'pierrejeambrun', 'body': 'cc: @potiuk\r\n\r\nI cannot reproduce locally, I would really appreciate it if you could tell me if this solved it on your end ;)', 'created_at': datetime.datetime(2024, 10, 9, 13, 29, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403377968, 'issue_id': 2575945093, 'author': 'potiuk', 'body': 'Yes. It did ! Thanks!', 'created_at': datetime.datetime(2024, 10, 9, 20, 32, 41, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-10-09 13:29:01 UTC): cc: @potiuk

I cannot reproduce locally, I would really appreciate it if you could tell me if this solved it on your end ;)

potiuk on (2024-10-09 20:32:41 UTC): Yes. It did ! Thanks!

"
2575492823,pull_request,closed,,Catch ApiException from Kubernetes in tasks,"
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",PaulKobow7536,2024-10-09 10:27:47+00:00,[],2025-01-10 00:15:53+00:00,2025-01-10 00:15:53+00:00,https://github.com/apache/airflow/pull/42851,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2401935276, 'issue_id': 2575492823, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 9, 10, 27, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408719747, 'issue_id': 2575492823, 'author': 'potiuk', 'body': 'Can you rebase after the providers move and add unit test to it please?', 'created_at': datetime.datetime(2024, 10, 12, 22, 36, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408720170, 'issue_id': 2575492823, 'author': 'potiuk', 'body': 'Also some meaningful description of the commit describing why you are doing it should be a bit more precise - not what you experiance but more describing what case it addresses and maybe split over few lines rather than fitting it in a single line that is longer than 80 characters and wraps.', 'created_at': datetime.datetime(2024, 10, 12, 22, 38, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2526534185, 'issue_id': 2575492823, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 9, 0, 17, 15, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-09 10:27:52 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-12 22:36:55 UTC): Can you rebase after the providers move and add unit test to it please?

potiuk on (2024-10-12 22:38:34 UTC): Also some meaningful description of the commit describing why you are doing it should be a bit more precise - not what you experiance but more describing what case it addresses and maybe split over few lines rather than fitting it in a single line that is longer than 80 characters and wraps.

github-actions[bot] on (2024-12-09 00:17:15 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2575212006,pull_request,closed,,FIX: Don't raise a warning in ExecutorSafeguard when execute is called from an extended operator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #41470
related: #41470

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The ExecutorSafeguard is wrongly assuming that the execute method is called outside of a TaskInstance when extending an existing Operator and calling the super().execute() method from within the extended operator.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-10-09 08:36:01+00:00,[],2024-11-01 11:28:31+00:00,2024-10-12 22:17:37+00:00,https://github.com/apache/airflow/pull/42849,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2575107977,pull_request,closed,,AIP-84 Migrate the public endpoint Get DAG to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #42652
related: #42370

This migrates the Get DAG API from `api_connexion` to `api_fastapi`, with a supporting test.

Additionally, this replaces `AliasChoices` with a single `AliasGenerator`. The lowest direct dependency resolution tests that were previously failing for `AliasGenerator` will now pass, thanks to the Pydantic min version update in https://github.com/apache/airflow/pull/42694.
",omkar-foss,2024-10-09 07:53:15+00:00,[],2024-10-10 12:01:40+00:00,2024-10-10 07:47:49+00:00,https://github.com/apache/airflow/pull/42848,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2402544096, 'issue_id': 2575107977, 'author': 'pierrejeambrun', 'body': 'Also can you double check that aliases are correctly documented in the specification (generated yaml / swagger). Because I had an issue earlier when experimenting with them.', 'created_at': datetime.datetime(2024, 10, 9, 14, 42, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403308682, 'issue_id': 2575107977, 'author': 'omkar-foss', 'body': '> Also can you double check that aliases are correctly documented in the specification (generated yaml / swagger). Because I had an issue earlier when experimenting with them.\r\n\r\nYes, all 3 aliases seem to be correctly documented in the generated yaml as well as swagger. Line numbers for your quick reference as follows:\r\n- `dag_run_timeout` - [yaml](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/openapi/v1-generated.yaml#L771), [swagger](https://github.com/apache/airflow/blob/main/airflow/ui/openapi-gen/requests/types.gen.ts#L55)\r\n- `last_parsed` - [yaml](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/openapi/v1-generated.yaml#L827), [swagger](https://github.com/apache/airflow/blob/main/airflow/ui/openapi-gen/requests/types.gen.ts#L70)\r\n- `template_search_path` - [yaml](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/openapi/v1-generated.yaml#L815), [swagger](https://github.com/apache/airflow/blob/main/airflow/ui/openapi-gen/requests/types.gen.ts#L68)', 'created_at': datetime.datetime(2024, 10, 9, 19, 49, 26, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-09 14:42:56 UTC): Also can you double check that aliases are correctly documented in the specification (generated yaml / swagger). Because I had an issue earlier when experimenting with them.

omkar-foss (Issue Creator) on (2024-10-09 19:49:26 UTC): Yes, all 3 aliases seem to be correctly documented in the generated yaml as well as swagger. Line numbers for your quick reference as follows:
- `dag_run_timeout` - [yaml](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/openapi/v1-generated.yaml#L771), [swagger](https://github.com/apache/airflow/blob/main/airflow/ui/openapi-gen/requests/types.gen.ts#L55)
- `last_parsed` - [yaml](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/openapi/v1-generated.yaml#L827), [swagger](https://github.com/apache/airflow/blob/main/airflow/ui/openapi-gen/requests/types.gen.ts#L70)
- `template_search_path` - [yaml](https://github.com/apache/airflow/blob/main/airflow/api_fastapi/openapi/v1-generated.yaml#L815), [swagger](https://github.com/apache/airflow/blob/main/airflow/ui/openapi-gen/requests/types.gen.ts#L68)

"
2574817326,pull_request,closed,,Docs: Add Template field related info for python operators,"closes #39584 

This PR adds templating information related to Python operators in How-to Guide",rawwar,2024-10-09 05:40:12+00:00,[],2024-10-09 16:05:42+00:00,2024-10-09 14:32:39+00:00,https://github.com/apache/airflow/pull/42847,"[('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2574617603,pull_request,closed,,Move test of DagRun.update_state to better place,"Previously this lived in test_scheduler_job.py

It only really tested the behavior of DagRun.update_state.

As far as I can tell, it checks that if you null out the state on a TI of a finished dag, and then you call ``update_state``, then the DR will be set to running.
",dstandish,2024-10-09 03:07:35+00:00,[],2024-10-09 15:15:39+00:00,2024-10-09 15:15:37+00:00,https://github.com/apache/airflow/pull/42845,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2574371433,pull_request,closed,,Fix revoke Dag stale permission on airflow < 2.10,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42743

This reported issue was happening on airflow < 2.10 using the old access_control format `dict[str, set]` and it was captured by the test `tests/providers/fab/auth_manager/test_security.py` when run the airflow 2.9.3 with fab 1.4.0:

```
FAILED tests/providers/fab/auth_manager/test_security.py::test_access_control_stale_perms_are_revoked - AttributeError: 'set' object has no attribute 'get'
```

After this fix the same test pass:

```
tests/providers/fab/auth_manager/test_security.py::test_access_control_stale_perms_are_revoked PASSED
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",joaopamaral,2024-10-08 22:54:54+00:00,[],2024-10-25 19:41:24+00:00,2024-10-25 19:41:24+00:00,https://github.com/apache/airflow/pull/42844,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2400963429, 'issue_id': 2574371433, 'author': 'joaopamaral', 'body': 'Tested with airflow 2.9.3:\r\n\r\n- Added a dag with the following access control:\r\n```python\r\n    access_control={\r\n        ""Viewer"": {\'can_read\', \'can_edit\', \'can_delete\'}\r\n    }\r\n```\r\n- The UI shows all the new permissions:\r\n<img width=""1002"" alt=""image"" src=""https://github.com/user-attachments/assets/6f46de35-08b8-4c7e-819b-6779355177c4"">\r\n\r\n- Removed the `can_delete` permission:\r\n```python\r\n    access_control={\r\n        ""Viewer"": {\'can_read\', \'can_edit\'}\r\n    }\r\n```\r\n\r\n- The permission is updated without any error:\r\n<img width=""991"" alt=""image"" src=""https://github.com/user-attachments/assets/bd5ff755-fb50-46cf-a9dd-4cd5536cefb5"">', 'created_at': datetime.datetime(2024, 10, 8, 23, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408715465, 'issue_id': 2574371433, 'author': 'potiuk', 'body': 'Yeah. And it needs to be rebased after providers have been moved to top level.', 'created_at': datetime.datetime(2024, 10, 12, 22, 18, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408715594, 'issue_id': 2574371433, 'author': 'potiuk', 'body': 'Would also be nice if there is a unit test for it.', 'created_at': datetime.datetime(2024, 10, 12, 22, 19, 12, tzinfo=datetime.timezone.utc)}]","joaopamaral (Issue Creator) on (2024-10-08 23:03:00 UTC): Tested with airflow 2.9.3:

- Added a dag with the following access control:
```python
    access_control={
        ""Viewer"": {'can_read', 'can_edit', 'can_delete'}
    }
```
- The UI shows all the new permissions:
<img width=""1002"" alt=""image"" src=""https://github.com/user-attachments/assets/6f46de35-08b8-4c7e-819b-6779355177c4"">

- Removed the `can_delete` permission:
```python
    access_control={
        ""Viewer"": {'can_read', 'can_edit'}
    }
```

- The permission is updated without any error:
<img width=""991"" alt=""image"" src=""https://github.com/user-attachments/assets/bd5ff755-fb50-46cf-a9dd-4cd5536cefb5"">

potiuk on (2024-10-12 22:18:30 UTC): Yeah. And it needs to be rebased after providers have been moved to top level.

potiuk on (2024-10-12 22:19:12 UTC): Would also be nice if there is a unit test for it.

"
2574306248,pull_request,closed,,Added last_dagrun to DAGs list endpoint,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
This PR enhances the DAGs list endpoint by adding the `last_dagrun` field to the response. The changes allow the frontend to display the last DAG run details without having to request additional fields one by one.

### Changes:
- Added the `last_dagrun` field for each DAG in the list, retrieving the most recent DagRun for each DAG.
- Used `__dict__` for dynamic handling of DagRun fields to avoid manually adding individual fields.
- Maintained the original structure of the DAG response, ensuring that no existing data is altered.

---
",ArshiaZr,2024-10-08 22:04:28+00:00,[],2024-10-22 08:19:54+00:00,2024-10-14 12:20:59+00:00,https://github.com/apache/airflow/pull/42843,"[('area:API', ""Airflow's REST/HTTP API""), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2400901041, 'issue_id': 2574306248, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 8, 22, 4, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402160553, 'issue_id': 2574306248, 'author': 'pierrejeambrun', 'body': ""Hello @ArshiaZr,\r\n\r\nThis looks like a new feature, and we most likely won't accept new feature on the legacy api. We plan on having this information on the new API, (FastAPI one, that you can find under `api_fastapi`).\r\n\r\nI'll let other contributors weight in, but I would suggest closing this one as it won't be released in 2.10.x.\r\n\r\nYou can contribute this change to airflow 3.x though via the `api_fastapi` source code :).\r\n\r\nThanks for your suggestion.\r\n\r\n> side note, we don't want to make a for loop to do as many request as retrieved dags. All of that can be retrieved in the same query via a CTE or subquery join."", 'created_at': datetime.datetime(2024, 10, 9, 12, 17, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408720658, 'issue_id': 2574306248, 'author': 'potiuk', 'body': 'Agree. No new features for Airlfow 3.', 'created_at': datetime.datetime(2024, 10, 12, 22, 40, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411072622, 'issue_id': 2574306248, 'author': 'pierrejeambrun', 'body': 'Closing. Feel free to contribute this change to `api_fastapi` folder where the new RestAPI lives for airflow 3. I think @bbovenzi is also working on some way to retrive `last_dag_run` information for the new `get_dags` endpoints.', 'created_at': datetime.datetime(2024, 10, 14, 12, 20, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414252672, 'issue_id': 2574306248, 'author': 'bbovenzi', 'body': ""Thanks @ArshiaZr but sorry if I confused you in #42730. We're not updating the legacy api at `api_connexion` but the new get dags list over at `api_fastapi`"", 'created_at': datetime.datetime(2024, 10, 15, 15, 15, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414319308, 'issue_id': 2574306248, 'author': 'ArshiaZr', 'body': ""@bbovenzi No, it's completely alright. So is there any issue with the new api or there's nothing to be done regarding this issue?"", 'created_at': datetime.datetime(2024, 10, 15, 15, 29, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414475105, 'issue_id': 2574306248, 'author': 'bbovenzi', 'body': ""We need to add last_dagrun to the get /dags request in fastapi. We can filter and sort by last run, but we don't actually have last run on the dag list response"", 'created_at': datetime.datetime(2024, 10, 15, 16, 22, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414494142, 'issue_id': 2574306248, 'author': 'ArshiaZr', 'body': 'Can I work on it?', 'created_at': datetime.datetime(2024, 10, 15, 16, 31, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418862228, 'issue_id': 2574306248, 'author': 'pierrejeambrun', 'body': 'Of course @ArshiaZr, you are welcome to open a PR\r\n\r\nMaybe @bbovenzi will have more information on what is needed exactly but I think the idea is:\r\n- For the public endpoint `get_dags` you can add the `latest_dag_run` which is basically a whole serialized dag_run object\r\n- We need a custom `ui` endpoint to `get_dags` that will also return the X latest dag_run of the dag. So basically a `latest_dag_runs` that is a list of serialized dag_run. Maybe that `X` is a query parameter so I can ask for dags with their 10th dagrun like this `?n_dag_runs=10` or something similar. But maybe that is not needed the query parameter part. You can just start with an hardcoded value.', 'created_at': datetime.datetime(2024, 10, 17, 8, 11, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422801200, 'issue_id': 2574306248, 'author': 'bbovenzi', 'body': ""Yes, let's start with just updating the public get_dags endpoint with a `latest_dagrun: DagRun | None` I updated the description in https://github.com/apache/airflow/issues/42730"", 'created_at': datetime.datetime(2024, 10, 18, 16, 6, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2427308598, 'issue_id': 2574306248, 'author': 'ArshiaZr', 'body': '@bbovenzi \r\n\r\nI encountered the following issues:\r\n\r\n1. I cannot use `DagRun | None` because the `DagRun` class is incompatible with the expected schema for my implementation, resulting in a `PydanticInvalidForJsonSchema` error. Instead, I am using `latest_dagrun: DAGRunResponse | None`.\r\n2. Due to the schema differences, I\'m receiving a UI error during the compilation process:\r\n\r\n   ```\r\n   SyntaxError: ""/Users/arshia/Desktop/w/airflow/airflow/api_fastapi/core_api/openapi/v1-generated.yaml"" is not a valid JSON Schema\r\n   ```\r\n\r\nAs a result, I am unable to commit my changes.', 'created_at': datetime.datetime(2024, 10, 21, 17, 24, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2427398240, 'issue_id': 2574306248, 'author': 'ArshiaZr', 'body': ""I'm getting these errors from pre-commit tool"", 'created_at': datetime.datetime(2024, 10, 21, 18, 11, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428584200, 'issue_id': 2574306248, 'author': 'pierrejeambrun', 'body': 'From your error message above it looks like something is trying to read a json from `v1-generated.yaml`. Hard to tell without more context. Normally pre-commits should just work out of the box. Do you mind pasting more error context for us to understand.\r\n\r\nOtherwise you can always commit with `-n` (not advised but in some rare cases of pre-commit bug, you can still commit by-passing the checks, the CI will run them for you)', 'created_at': datetime.datetime(2024, 10, 22, 8, 19, 17, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-08 22:04:32 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

pierrejeambrun on (2024-10-09 12:17:47 UTC): Hello @ArshiaZr,

This looks like a new feature, and we most likely won't accept new feature on the legacy api. We plan on having this information on the new API, (FastAPI one, that you can find under `api_fastapi`).

I'll let other contributors weight in, but I would suggest closing this one as it won't be released in 2.10.x.

You can contribute this change to airflow 3.x though via the `api_fastapi` source code :).

Thanks for your suggestion.

potiuk on (2024-10-12 22:40:49 UTC): Agree. No new features for Airlfow 3.

pierrejeambrun on (2024-10-14 12:20:59 UTC): Closing. Feel free to contribute this change to `api_fastapi` folder where the new RestAPI lives for airflow 3. I think @bbovenzi is also working on some way to retrive `last_dag_run` information for the new `get_dags` endpoints.

bbovenzi on (2024-10-15 15:15:59 UTC): Thanks @ArshiaZr but sorry if I confused you in #42730. We're not updating the legacy api at `api_connexion` but the new get dags list over at `api_fastapi`

ArshiaZr (Issue Creator) on (2024-10-15 15:29:14 UTC): @bbovenzi No, it's completely alright. So is there any issue with the new api or there's nothing to be done regarding this issue?

bbovenzi on (2024-10-15 16:22:34 UTC): We need to add last_dagrun to the get /dags request in fastapi. We can filter and sort by last run, but we don't actually have last run on the dag list response

ArshiaZr (Issue Creator) on (2024-10-15 16:31:42 UTC): Can I work on it?

pierrejeambrun on (2024-10-17 08:11:55 UTC): Of course @ArshiaZr, you are welcome to open a PR

Maybe @bbovenzi will have more information on what is needed exactly but I think the idea is:
- For the public endpoint `get_dags` you can add the `latest_dag_run` which is basically a whole serialized dag_run object
- We need a custom `ui` endpoint to `get_dags` that will also return the X latest dag_run of the dag. So basically a `latest_dag_runs` that is a list of serialized dag_run. Maybe that `X` is a query parameter so I can ask for dags with their 10th dagrun like this `?n_dag_runs=10` or something similar. But maybe that is not needed the query parameter part. You can just start with an hardcoded value.

bbovenzi on (2024-10-18 16:06:08 UTC): Yes, let's start with just updating the public get_dags endpoint with a `latest_dagrun: DagRun | None` I updated the description in https://github.com/apache/airflow/issues/42730

ArshiaZr (Issue Creator) on (2024-10-21 17:24:09 UTC): @bbovenzi 

I encountered the following issues:

1. I cannot use `DagRun | None` because the `DagRun` class is incompatible with the expected schema for my implementation, resulting in a `PydanticInvalidForJsonSchema` error. Instead, I am using `latest_dagrun: DAGRunResponse | None`.
2. Due to the schema differences, I'm receiving a UI error during the compilation process:

   ```
   SyntaxError: ""/Users/arshia/Desktop/w/airflow/airflow/api_fastapi/core_api/openapi/v1-generated.yaml"" is not a valid JSON Schema
   ```

As a result, I am unable to commit my changes.

ArshiaZr (Issue Creator) on (2024-10-21 18:11:56 UTC): I'm getting these errors from pre-commit tool

pierrejeambrun on (2024-10-22 08:19:17 UTC): From your error message above it looks like something is trying to read a json from `v1-generated.yaml`. Hard to tell without more context. Normally pre-commits should just work out of the box. Do you mind pasting more error context for us to understand.

Otherwise you can always commit with `-n` (not advised but in some rare cases of pre-commit bug, you can still commit by-passing the checks, the CI will run them for you)

"
2574066737,pull_request,closed,,Testing -- ignore me,"- Split providers out of the main ""airflow/"" tree into a UV workspace project
- workflow test
",ashb,2024-10-08 19:46:30+00:00,[],2024-10-09 09:12:44+00:00,2024-10-09 09:12:44+00:00,https://github.com/apache/airflow/pull/42842,"[('area:providers', ''), ('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2574033891,pull_request,closed,,fix PyDocStyle checks,"related: https://github.com/apache/airflow/issues/40567
PT004 | Fixture does not return anything, add leading underscore
Reduces PT004 errors from 345 to 318.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dannyl1u,2024-10-08 19:29:12+00:00,[],2024-10-09 18:42:34+00:00,2024-10-09 18:41:53+00:00,https://github.com/apache/airflow/pull/42841,"[('area:webserver', 'Webserver related Issues')]",[],
2574014299,pull_request,closed,,Simplify code for recent dbt provider change,"Just simplified redundant code from https://github.com/apache/airflow/pull/42737

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-08 19:20:13+00:00,[],2024-10-08 21:55:01+00:00,2024-10-08 21:54:58+00:00,https://github.com/apache/airflow/pull/42840,"[('area:providers', ''), ('provider:dbt-cloud', '')]",[],
2573964821,pull_request,closed,,Update CODEOWNERS to update Kaxil's entry,"I haven't been that active coding or reviewing. Although I am now returning back to focus on Task SDK (AIP-72) so narrowing down my entries in CODEOWNERS.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-08 18:55:47+00:00,[],2024-10-08 18:57:56+00:00,2024-10-08 18:57:53+00:00,https://github.com/apache/airflow/pull/42839,"[('area:dev-tools', '')]",[],
2573849498,pull_request,closed,,Make Scarf details more prominent in 2.10 release notes,"This PR moves Scarf entry in Release notes at top of 2.10.0 entries and also adds URL/IP-address info that is covered by [Scarf's privacy policy](https://about.scarf.sh/privacy-policy).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-10-08 17:55:16+00:00,[],2024-10-08 18:19:45+00:00,2024-10-08 18:19:43+00:00,https://github.com/apache/airflow/pull/42838,"[('kind:documentation', '')]",[],
2573709393,pull_request,closed,,Add test for behavior for paused backfill,Just add test to verify the behavior that new dag runs not started when dag backfill is paused.,dstandish,2024-10-08 16:43:07+00:00,[],2024-10-10 21:40:12+00:00,2024-10-10 21:40:10+00:00,https://github.com/apache/airflow/pull/42837,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2573691643,pull_request,closed,,Switch `kuberenetes_tests` to run with `uv run`,"This is a no-op change right now, but as part of the provider re-org in #42505
this sets us up to be able to load the providers code in the tests

The reason this change is done separately is that changes to breeze code form
forks doesn't take effect, and this small change makes it easier to land on
main without having to re-create that large PR.
",ashb,2024-10-08 16:32:53+00:00,[],2024-10-08 17:14:14+00:00,2024-10-08 17:13:44+00:00,https://github.com/apache/airflow/pull/42836,"[('area:dev-tools', '')]",[],
2573661421,pull_request,closed,,Changed conf property from str to dict in SparkSqlOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

Changes the conf property from str to dict in SparkSqlOperator
closes: https://github.com/apache/airflow/issues/40507

The previous PR was closed due to inactivity, I had time this week to fix it",duhizjame,2024-10-08 16:16:26+00:00,[],2024-10-22 05:38:54+00:00,2024-10-22 05:38:51+00:00,https://github.com/apache/airflow/pull/42835,"[('area:providers', ''), ('provider:apache-spark', '')]","[{'comment_id': 2402478187, 'issue_id': 2573661421, 'author': 'romsharon98', 'body': ""@duhizjame the changes looks good.\r\nbecause it's a breaking change we need to bump the version of the provider (major change) and also add a breaking change caption in the change log.\r\nafter this we can merge this change."", 'created_at': datetime.datetime(2024, 10, 9, 14, 17, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402482778, 'issue_id': 2573661421, 'author': 'romsharon98', 'body': 'also what do you think about supporting both `str` and `dict` and only parse it differently behind the scene', 'created_at': datetime.datetime(2024, 10, 9, 14, 19, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402523552, 'issue_id': 2573661421, 'author': 'duhizjame', 'body': ""@romsharon98 maybe its better that way, so we don't break everyone on versions <= 4.8.2, I will add it to the PR tonight\r\n\r\nregarding version changes:\r\nfrom the contribution docs I cant find who is doing the the version changes; after adding str, we bump only minor version and add a changelog; should I do this or someone from the contributors is doing this after approval?\r\n\r\nthanks for the feedback! :)"", 'created_at': datetime.datetime(2024, 10, 9, 14, 35, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402810698, 'issue_id': 2573661421, 'author': 'romsharon98', 'body': ""> @romsharon98 maybe its better that way, so we don't break everyone on versions <= 4.8.2, I will add it to the PR tonight\n> \n> \n> \n> regarding version changes:\n> \n> from the contribution docs I cant find who is doing the the version changes; after adding str, we bump only minor version and add a changelog; should I do this or someone from the contributors is doing this after approval?\n> \n> \n> \n> thanks for the feedback! :) \n\nI think that for features we need to change nothing belongs to the provider.yml, I think we have a bot that add the documentation according to the PR title/commit and the version will update by the release manager when we releasing the package. \nI am not sure 100%, probably @eladkal will now better 😃"", 'created_at': datetime.datetime(2024, 10, 9, 16, 40, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413851332, 'issue_id': 2573661421, 'author': 'duhizjame', 'body': ""I have no idea why the pipeline fails to build images, I haven't used breeze to dev/test"", 'created_at': datetime.datetime(2024, 10, 15, 13, 0, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414416549, 'issue_id': 2573661421, 'author': 'romsharon98', 'body': ""> I have no idea why the pipeline fails to build images, I haven't used breeze to dev/test\r\n\r\nYou have conflicts that need to be resolved.\r\nAfter you resolve it we will merge."", 'created_at': datetime.datetime(2024, 10, 15, 15, 56, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2428303030, 'issue_id': 2573661421, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 22, 5, 38, 54, tzinfo=datetime.timezone.utc)}]","romsharon98 on (2024-10-09 14:17:20 UTC): @duhizjame the changes looks good.
because it's a breaking change we need to bump the version of the provider (major change) and also add a breaking change caption in the change log.
after this we can merge this change.

romsharon98 on (2024-10-09 14:19:06 UTC): also what do you think about supporting both `str` and `dict` and only parse it differently behind the scene

duhizjame (Issue Creator) on (2024-10-09 14:35:03 UTC): @romsharon98 maybe its better that way, so we don't break everyone on versions <= 4.8.2, I will add it to the PR tonight

regarding version changes:
from the contribution docs I cant find who is doing the the version changes; after adding str, we bump only minor version and add a changelog; should I do this or someone from the contributors is doing this after approval?

thanks for the feedback! :)

romsharon98 on (2024-10-09 16:40:26 UTC): I think that for features we need to change nothing belongs to the provider.yml, I think we have a bot that add the documentation according to the PR title/commit and the version will update by the release manager when we releasing the package. 
I am not sure 100%, probably @eladkal will now better 😃

duhizjame (Issue Creator) on (2024-10-15 13:00:04 UTC): I have no idea why the pipeline fails to build images, I haven't used breeze to dev/test

romsharon98 on (2024-10-15 15:56:32 UTC): You have conflicts that need to be resolved.
After you resolve it we will merge.

boring-cyborg[bot] on (2024-10-22 05:38:54 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2573635773,pull_request,closed,,AIP-84 Get Variable,"Related to: https://github.com/apache/airflow/issues/42370

Add delete_variable endpoint.",pierrejeambrun,2024-10-08 16:07:12+00:00,['pierrejeambrun'],2024-10-09 15:03:57+00:00,2024-10-09 15:03:56+00:00,https://github.com/apache/airflow/pull/42834,"[('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2401781527, 'issue_id': 2573635773, 'author': 'bbovenzi', 'body': ""I know this is just copying the existing REST API. But I don't see any checks to try to hide sensitive variable values. Do we want to add that in?"", 'created_at': datetime.datetime(2024, 10, 9, 9, 14, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402128272, 'issue_id': 2573635773, 'author': 'pierrejeambrun', 'body': ""> I know this is just copying the existing REST API. But I don't see any checks to try to hide sensitive variable values. Do we want to add that in?\r\n\r\nGood idea. I'm trying to see if I can incorporate that real quick, don't know why my test is failing at the moment."", 'created_at': datetime.datetime(2024, 10, 9, 12, 2, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402248275, 'issue_id': 2573635773, 'author': 'pierrejeambrun', 'body': 'Pushed. Test cases were updated.', 'created_at': datetime.datetime(2024, 10, 9, 12, 56, 45, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-10-09 09:14:54 UTC): I know this is just copying the existing REST API. But I don't see any checks to try to hide sensitive variable values. Do we want to add that in?

pierrejeambrun (Issue Creator) on (2024-10-09 12:02:23 UTC): Good idea. I'm trying to see if I can incorporate that real quick, don't know why my test is failing at the moment.

pierrejeambrun (Issue Creator) on (2024-10-09 12:56:45 UTC): Pushed. Test cases were updated.

"
2573590543,pull_request,closed,,better docs can save time,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The [existing documentation](https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/secrets-backends/aws-secrets-manager.html#example-of-storing-google-secrets-in-aws-secrets-manager) on how to set up Google secrets in AWS Secrets Manager is out of date. It led me on a merry chase for hours.

I hereby submit this PR to update the doc. I solemnly swear that the content has been verified using DAG code similar to this

```python
gsheet = GSheetsHook(gcp_conn_id=gcp_conn_id)
values = gsheet.get_values(
    spreadsheet_id=spreadsheet_id,
    range_=f""{sheet_name}!B1:B2"",
)
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",zachliu,2024-10-08 15:47:31+00:00,[],2024-10-12 22:15:02+00:00,2024-10-08 19:37:25+00:00,https://github.com/apache/airflow/pull/42832,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2408714680, 'issue_id': 2573590543, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 10, 12, 22, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-12 22:15:00 UTC): Nice!

"
2573485738,pull_request,closed,,Remove `sqlalchemy-redshift` dependency from Amazon provider,"`sqlalchemy-redshift` is unused. It is also not compatible with sqlalchemy>2, so good riddance!

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-08 15:04:10+00:00,[],2024-10-08 20:33:11+00:00,2024-10-08 20:33:09+00:00,https://github.com/apache/airflow/pull/42830,"[('area:providers', '')]",[],
2573311344,pull_request,closed,,Remove unused ldap3 dependency,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR removes [ldap3](https://pypi.org/project/ldap3/) from the list of optional dependencies of the `ldap` extras group.
A code search shows that this package is unused, and has been for [at least 4 years](https://github.com/apache/airflow/pull/8071).

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",glostis,2024-10-08 14:00:41+00:00,[],2024-10-12 22:14:06+00:00,2024-10-08 19:05:48+00:00,https://github.com/apache/airflow/pull/42829,[],"[{'comment_id': 2399941020, 'issue_id': 2573311344, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 8, 14, 0, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400612736, 'issue_id': 2573311344, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 8, 19, 5, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408714468, 'issue_id': 2573311344, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 10, 12, 22, 14, 5, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-08 14:00:45 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-08 19:05:50 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-10-12 22:14:05 UTC): Nice!

"
2573302817,pull_request,closed,,Fix import sequencing of backfill and dagrun models,"Previously it worked in general, but did not in certain test scenarios where we did not initialize the database.  This is one solution.
",dstandish,2024-10-08 13:58:13+00:00,[],2024-10-08 15:34:45+00:00,2024-10-08 15:34:43+00:00,https://github.com/apache/airflow/pull/42828,"[('area:CLI', '')]",[],
2573238422,pull_request,closed,,Specify asyncio_default_fixture_loop_scope in pytest.ini,"Previously we were getting 'PytestDeprecationWarning: The configuration option ""asyncio_default_fixture_loop_scope"" is unset.'  This sets it to the new default, and makes the warning go away.
",dstandish,2024-10-08 13:37:59+00:00,[],2024-10-08 14:23:12+00:00,2024-10-08 14:23:11+00:00,https://github.com/apache/airflow/pull/42827,[],[],
2573038692,pull_request,closed,,maint(docs): remove redshift references from athena trigger in AWS provider,"Saw a typo here when looking at the code!

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jayceslesar,2024-10-08 12:17:32+00:00,[],2024-11-05 20:06:44+00:00,2024-11-05 20:06:44+00:00,https://github.com/apache/airflow/pull/42826,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2458057358, 'issue_id': 2573038692, 'author': 'gopidesupavan', 'body': 'This has been fixed here #43616, closing this one now.', 'created_at': datetime.datetime(2024, 11, 5, 20, 6, 44, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-05 20:06:44 UTC): This has been fixed here #43616, closing this one now.

"
2572508443,pull_request,closed,,Remove more burdensome eslint rules,"Remove another rule.

This was forcing an ignore on our code, and raising more warnings on new PRs such as https://github.com/apache/airflow/pull/42779/files#diff-66d17c201c22426a3c37398877656f048b04eb7a41d5bfa827a0a2e7a5eb0beaL29

A component can quickly becomes bigger than that leaving that at the discretion of the contributor/",pierrejeambrun,2024-10-08 08:40:50+00:00,['pierrejeambrun'],2024-10-08 11:29:38+00:00,2024-10-08 11:29:37+00:00,https://github.com/apache/airflow/pull/42819,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2572209088,pull_request,closed,,Upgrade Helm Chart dependencies to latest released,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-08 06:25:30+00:00,[],2025-02-05 15:52:00+00:00,2024-10-13 00:31:52+00:00,https://github.com/apache/airflow/pull/42816,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2399890646, 'issue_id': 2572209088, 'author': 'romsharon98', 'body': 'Oh I just missed this PR and merge this one that does the same\n\nhttps://github.com/apache/airflow/pull/42809\n\nLet me know if you want me to revert it', 'created_at': datetime.datetime(2024, 10, 8, 13, 43, 55, tzinfo=datetime.timezone.utc)}]","romsharon98 on (2024-10-08 13:43:55 UTC): Oh I just missed this PR and merge this one that does the same

https://github.com/apache/airflow/pull/42809

Let me know if you want me to revert it

"
2572137881,pull_request,closed,,Fix mark as success when pod fails while fetching log,"closes: https://github.com/apache/airflow/pull/40891
with cherry-picking from: @peloyeje 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-10-08 05:42:43+00:00,[],2024-10-09 12:31:17+00:00,2024-10-09 12:31:17+00:00,https://github.com/apache/airflow/pull/42815,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2571864726,pull_request,closed,,Tweak AssetAlias to match Asset for AIP-74 additions,"~~Depends on #42612 and #42812.~~ Both merged

The `group` field is added. It will work basically the same asset the field on Asset (for UI purposes). The `name` field limit is reduced to 1500 (from 3000) since that is the limit in Asset. This is not technically necessary (unlike Asset), but it's probably to have them match.",uranusjr,2024-10-08 02:01:58+00:00,[],2024-10-16 13:11:15+00:00,2024-10-16 13:11:13+00:00,https://github.com/apache/airflow/pull/42814,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:serialization', ''), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2571861042,pull_request,closed,,Add warning log in`DatabricksTaskBaseOperator`  when task_key>100,"related to #41816 

Adds a warning log to indicate failure if task_key>100.",rawwar,2024-10-08 01:57:33+00:00,[],2024-10-08 16:10:19+00:00,2024-10-08 16:10:19+00:00,https://github.com/apache/airflow/pull/42813,"[('area:providers', ''), ('provider:databricks', '')]",[],
2571844101,pull_request,closed,,Add 'name' and 'group' to public Asset class,"~~Depends on #42612. I also still need to add tests.~~

Dependency merged, tests added. Ready for review.",uranusjr,2024-10-08 01:36:44+00:00,[],2024-10-16 02:23:31+00:00,2024-10-16 02:23:29+00:00,https://github.com/apache/airflow/pull/42812,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:serialization', ''), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2571771029,pull_request,closed,,Disable flaky mssql based integration tests,"Currently in CI these tests are failing with `pymssql.exceptions.OperationalError: ` .  as discussed in slack ci-cd group , disabling these tests.

https://github.com/apache/airflow/actions/runs/11210718014/job/31158453211#step:6:2844

tests/integration/providers/microsoft/mssql/hooks/test_mssql.py::TestMsSqlHook
tests/integration/providers/apache/hive/transfers/test_mssql_to_hive.py::TestMsSqlToHiveTransfer
tests/integration/providers/google/cloud/transfers/test_bigquery_to_mssql.py::TestBigQueryToMsSqlOperator
tests/integration/providers/google/cloud/transfers/test_mssql_to_gcs.py::TestMsSqlToGoogleCloudStorageOperator

hope `@pytest.mark.quarantined` works? 


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-08 00:11:44+00:00,[],2024-11-23 19:53:46+00:00,2024-10-13 22:25:55+00:00,https://github.com/apache/airflow/pull/42811,[],"[{'comment_id': 2399751186, 'issue_id': 2571771029, 'author': 'potiuk', 'body': 'Actualyt now, when I think of it - quarantining is not enough /not needed - what we really need is to not have mssql integration running in CI. \r\n\r\nIf you look at selective checks -> they produce the list of ""testable_integrations"" : https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/utils/selective_checks.py#L1298\r\n\r\nDefined here:\r\n\r\nhttps://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/global_constants.py#L57\r\n\r\nThis list is produced by selective checks here:\r\n\r\nhttps://github.com/apache/airflow/actions/runs/11226083287/job/31205948119?pr=42811#step:8:824\r\n\r\n\r\nAnd used in the workflow that runs integration tests to produce matrix of jobs:\r\n\r\nhttps://github.com/apache/airflow/blob/main/.github/workflows/integration-tests.yml#L67\r\n\r\nSo all we need to do is to remove mssql from the list.\r\n\r\nThis is actually cool - because this way you can still run the tests locally:\r\n\r\n```\r\nbreeze tessting integration-tests --integration mssql \r\n```\r\n\r\nbut they will not run in CI.', 'created_at': datetime.datetime(2024, 10, 8, 12, 46, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400454474, 'issue_id': 2571771029, 'author': 'gopidesupavan', 'body': '> Actualyt now, when I think of it - quarantining is not enough /not needed - what we really need is to not have mssql integration running in CI.\r\n> \r\n> If you look at selective checks -> they produce the list of ""testable_integrations"" : https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/utils/selective_checks.py#L1298\r\n> \r\n> Defined here:\r\n> \r\n> https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/global_constants.py#L57\r\n> \r\n> This list is produced by selective checks here:\r\n> \r\n> https://github.com/apache/airflow/actions/runs/11226083287/job/31205948119?pr=42811#step:8:824\r\n> \r\n> And used in the workflow that runs integration tests to produce matrix of jobs:\r\n> \r\n> https://github.com/apache/airflow/blob/main/.github/workflows/integration-tests.yml#L67\r\n> \r\n> So all we need to do is to remove mssql from the list.\r\n> \r\n> This is actually cool - because this way you can still run the tests locally:\r\n> \r\n> ```\r\n> breeze tessting integration-tests --integration mssql \r\n> ```\r\n> \r\n> but they will not run in CI.\r\n\r\nyeah, your correct. that was great suggestion, let me check and update. thank you', 'created_at': datetime.datetime(2024, 10, 8, 17, 37, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401493081, 'issue_id': 2571771029, 'author': 'gopidesupavan', 'body': '@potiuk if i remove mssql from TESTABLE_INTEGRATIONS and running breeze command in local, its failing , because the command validation failing at `BetterChoice`. \r\n\r\n`option_integration = click.option(\r\n    ""--integration"",\r\n    help=""Integration(s) to enable when running (can be more than one)."",\r\n    type=BetterChoice(AUTOCOMPLETE_INTEGRATIONS),\r\n    multiple=True,\r\n)`\r\n\r\nSo i have added new constant to disable not required integrations. hope that is fine?\r\n\r\n<img width=""1716"" alt=""image"" src=""https://github.com/user-attachments/assets/8bf37abe-c6ea-40db-83e2-0df76928731e"">', 'created_at': datetime.datetime(2024, 10, 9, 6, 59, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409208137, 'issue_id': 2571771029, 'author': 'potiuk', 'body': '@gopidesupavan -> maybe we can cherry-pick that on  to v2-10-test as well.', 'created_at': datetime.datetime(2024, 10, 13, 22, 26, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411097104, 'issue_id': 2571771029, 'author': 'gopidesupavan', 'body': '> @gopidesupavan -> maybe we can cherry-pick that on to v2-10-test as well.\r\n\r\nSure i will get these.', 'created_at': datetime.datetime(2024, 10, 14, 12, 30, 52, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-08 12:46:44 UTC): Actualyt now, when I think of it - quarantining is not enough /not needed - what we really need is to not have mssql integration running in CI. 

If you look at selective checks -> they produce the list of ""testable_integrations"" : https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/utils/selective_checks.py#L1298

Defined here:

https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/global_constants.py#L57

This list is produced by selective checks here:

https://github.com/apache/airflow/actions/runs/11226083287/job/31205948119?pr=42811#step:8:824


And used in the workflow that runs integration tests to produce matrix of jobs:

https://github.com/apache/airflow/blob/main/.github/workflows/integration-tests.yml#L67

So all we need to do is to remove mssql from the list.

This is actually cool - because this way you can still run the tests locally:

```
breeze tessting integration-tests --integration mssql 
```

but they will not run in CI.

gopidesupavan (Issue Creator) on (2024-10-08 17:37:26 UTC): yeah, your correct. that was great suggestion, let me check and update. thank you

gopidesupavan (Issue Creator) on (2024-10-09 06:59:51 UTC): @potiuk if i remove mssql from TESTABLE_INTEGRATIONS and running breeze command in local, its failing , because the command validation failing at `BetterChoice`. 

`option_integration = click.option(
    ""--integration"",
    help=""Integration(s) to enable when running (can be more than one)."",
    type=BetterChoice(AUTOCOMPLETE_INTEGRATIONS),
    multiple=True,
)`

So i have added new constant to disable not required integrations. hope that is fine?

<img width=""1716"" alt=""image"" src=""https://github.com/user-attachments/assets/8bf37abe-c6ea-40db-83e2-0df76928731e"">

potiuk on (2024-10-13 22:26:23 UTC): @gopidesupavan -> maybe we can cherry-pick that on  to v2-10-test as well.

gopidesupavan (Issue Creator) on (2024-10-14 12:30:52 UTC): Sure i will get these.

"
2571750493,pull_request,closed,,Fix TriggerDagRunOperator extra_link when trigger_dag_id is templated,"When `trigger_dag_id` is templated (which is probably a rare, but valid use case), then the `Triggered DAG` extra link needs to be populated from the rendered template values.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",fredthomsen,2024-10-07 23:54:02+00:00,[],2024-11-21 14:30:41+00:00,2024-11-21 14:30:41+00:00,https://github.com/apache/airflow/pull/42810,"[('provider:standard', '')]","[{'comment_id': 2487951706, 'issue_id': 2571750493, 'author': 'eladkal', 'body': 'Can your rebase?\r\nAfter https://github.com/apache/airflow/pull/44053 you need to apply the fix in the path of providers', 'created_at': datetime.datetime(2024, 11, 20, 9, 2, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490108553, 'issue_id': 2571750493, 'author': 'fredthomsen', 'body': '> Can your rebase? After #44053 you need to apply the fix in the path of providers\r\n\r\n@eladkal rebased.', 'created_at': datetime.datetime(2024, 11, 21, 5, 25, 40, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-20 09:02:35 UTC): Can your rebase?
After https://github.com/apache/airflow/pull/44053 you need to apply the fix in the path of providers

fredthomsen (Issue Creator) on (2024-11-21 05:25:40 UTC): @eladkal rebased.

"
2571728157,pull_request,closed,,Updating pre-commit hook and prometheus statsd exporter versions from failed dependency check,"CI step failed at upgrade checks , adding suggested versions.

https://github.com/apache/airflow/actions/runs/11222595609/job/31195410448#step:10:22

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-07 23:38:07+00:00,[],2024-10-12 21:59:44+00:00,2024-10-08 13:42:13+00:00,https://github.com/apache/airflow/pull/42809,"[('area:dev-tools', ''), ('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2408711372, 'issue_id': 2571728157, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 10, 12, 21, 59, 44, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-12 21:59:44 UTC): Nice!

"
2571634512,pull_request,closed,,Follow-up SLA purge,"Follow-up to https://github.com/apache/airflow/pull/42285

@dstandish pointed out that I missed the SlaMiss model and supporting code. This should take care of it


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-10-07 22:32:18+00:00,[],2024-10-16 00:28:02+00:00,2024-10-15 23:53:11+00:00,https://github.com/apache/airflow/pull/42808,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:smtp', ''), ('provider:fab', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2407916189, 'issue_id': 2571634512, 'author': 'ferruzzi', 'body': ""I'm guessing I did something wrong with the merge conflicts, I'll try to get it sorted today"", 'created_at': datetime.datetime(2024, 10, 11, 18, 18, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408210077, 'issue_id': 2571634512, 'author': 'ferruzzi', 'body': 'The remaining failing lowest direct dependency test is unrelated from the MS package and @gopidesupavan is working on the fix for that.', 'created_at': datetime.datetime(2024, 10, 11, 22, 47, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408454681, 'issue_id': 2571634512, 'author': 'gopidesupavan', 'body': '> The remaining failing lowest direct dependency test is unrelated from the MS package and @gopidesupavan is working on the fix for that.\r\n\r\nthis is fixed now.. you may rebase :)', 'created_at': datetime.datetime(2024, 10, 12, 8, 20, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415287616, 'issue_id': 2571634512, 'author': 'ferruzzi', 'body': 'Finally all green.', 'created_at': datetime.datetime(2024, 10, 15, 22, 36, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415357804, 'issue_id': 2571634512, 'author': 'dstandish', 'body': '> Finally all green.\r\n\r\nyee haw!', 'created_at': datetime.datetime(2024, 10, 15, 23, 51, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415358421, 'issue_id': 2571634512, 'author': 'dstandish', 'body': 'let er rip', 'created_at': datetime.datetime(2024, 10, 15, 23, 51, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415392169, 'issue_id': 2571634512, 'author': 'kaxil', 'body': 'Cool 🚀', 'created_at': datetime.datetime(2024, 10, 16, 0, 28, 1, tzinfo=datetime.timezone.utc)}]","ferruzzi (Issue Creator) on (2024-10-11 18:18:07 UTC): I'm guessing I did something wrong with the merge conflicts, I'll try to get it sorted today

ferruzzi (Issue Creator) on (2024-10-11 22:47:30 UTC): The remaining failing lowest direct dependency test is unrelated from the MS package and @gopidesupavan is working on the fix for that.

gopidesupavan on (2024-10-12 08:20:31 UTC): this is fixed now.. you may rebase :)

ferruzzi (Issue Creator) on (2024-10-15 22:36:05 UTC): Finally all green.

dstandish on (2024-10-15 23:51:10 UTC): yee haw!

dstandish on (2024-10-15 23:51:49 UTC): let er rip

kaxil on (2024-10-16 00:28:01 UTC): Cool 🚀

"
2571519241,pull_request,closed,,Follow-up SLA purge,"Follow-up to https://github.com/apache/airflow/pull/42285

@dstandish pointed out that I missed the SlaMiss model and supporting code.  This should take care of it

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2024-10-07 21:30:38+00:00,[],2024-10-07 22:33:08+00:00,2024-10-07 21:40:33+00:00,https://github.com/apache/airflow/pull/42807,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:smtp', ''), ('provider:fab', '')]","[{'comment_id': 2397950934, 'issue_id': 2571519241, 'author': 'ferruzzi', 'body': ""Something's borked.  Closing for now."", 'created_at': datetime.datetime(2024, 10, 7, 21, 40, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398039823, 'issue_id': 2571519241, 'author': 'ferruzzi', 'body': 'Sorry, I over-pruned a bit and missed a unit test that I broke in the process.\r\n\r\n\r\nSuperseded by https://github.com/apache/airflow/pull/42808', 'created_at': datetime.datetime(2024, 10, 7, 22, 33, 7, tzinfo=datetime.timezone.utc)}]","ferruzzi (Issue Creator) on (2024-10-07 21:40:33 UTC): Something's borked.  Closing for now.

ferruzzi (Issue Creator) on (2024-10-07 22:33:07 UTC): Sorry, I over-pruned a bit and missed a unit test that I broke in the process.


Superseded by https://github.com/apache/airflow/pull/42808

"
2571045035,pull_request,closed,,Bump micromatch from 4.0.7 to 4.0.8 in /airflow/ui,"Bumps [micromatch](https://github.com/micromatch/micromatch) from 4.0.7 to 4.0.8.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/micromatch/micromatch/releases"">micromatch's releases</a>.</em></p>
<blockquote>
<h2>4.0.8</h2>
<p>Ultimate release that fixes both CVE-2024-4067 and CVE-2024-4068. We consider the issues low-priority, so even if you see automated scanners saying otherwise, don't be scared.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/micromatch/micromatch/blob/master/CHANGELOG.md"">micromatch's changelog</a>.</em></p>
<blockquote>
<h2>[4.0.8] - 2024-08-22</h2>
<ul>
<li>backported CVE-2024-4067 fix (from v4.0.6) over to 4.x branch</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/micromatch/micromatch/commit/8bd704ec0d9894693d35da425d827819916be920""><code>8bd704e</code></a> 4.0.8</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/a0e68416a44da10f3e4e30845ab95af4fd286d5a""><code>a0e6841</code></a> run verb to generate README documentation</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/4ec288484f6e8cccf597ad3d43529c31d0f7a02a""><code>4ec2884</code></a> Merge branch 'v4' into hauserkristof-feature/v4.0.8</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/03aa8052171e878897eee5d7bb2ae0ae83ec2ade""><code>03aa805</code></a> Merge pull request <a href=""https://redirect.github.com/micromatch/micromatch/issues/266"">#266</a> from hauserkristof/feature/v4.0.8</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/814f5f70efcd100ca9d29198867812a3d6ab91a8""><code>814f5f7</code></a> lint</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/67fcce6a1077c2faf5ad0c5f998fa70202cc5dae""><code>67fcce6</code></a> fix: CHANGELOG about braces &amp; CVE-2024-4068, v4.0.5</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/113f2e3fa7cb30b429eda7c4c38475a8e8ba1b30""><code>113f2e3</code></a> fix: CVE numbers in CHANGELOG</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/d9dbd9a266686f44afb38da26fe016f96d1ec04f""><code>d9dbd9a</code></a> feat: updated CHANGELOG</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/2ab13157f416679f54e3a32b1425e184bd16749e""><code>2ab1315</code></a> fix: use actions/setup-node@v4</li>
<li><a href=""https://github.com/micromatch/micromatch/commit/1406ea38f3e24b29f4d4f46908d5cffcb3e6c4ce""><code>1406ea3</code></a> feat: rework test to work on macos with node 10,12 and 14</li>
<li>Additional commits viewable in <a href=""https://github.com/micromatch/micromatch/compare/4.0.7...4.0.8"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=micromatch&package-manager=npm_and_yarn&previous-version=4.0.7&new-version=4.0.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-10-07 17:32:17+00:00,[],2024-10-07 19:43:51+00:00,2024-10-07 19:09:24+00:00,https://github.com/apache/airflow/pull/42805,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]","[{'comment_id': 2397747230, 'issue_id': 2571045035, 'author': 'vincbeck', 'body': 'Love these PRs created by bots! 🥳', 'created_at': datetime.datetime(2024, 10, 7, 19, 43, 49, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-10-07 19:43:49 UTC): Love these PRs created by bots! 🥳

"
2571044896,pull_request,closed,,Bump rollup from 4.21.0 to 4.24.0 in /airflow/ui,"Bumps [rollup](https://github.com/rollup/rollup) from 4.21.0 to 4.24.0.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/rollup/rollup/releases"">rollup's releases</a>.</em></p>
<blockquote>
<h2>v4.24.0</h2>
<h2>4.24.0</h2>
<p><em>2024-10-02</em></p>
<h3>Features</h3>
<ul>
<li>Support preserving and transpiling JSX syntax (<a href=""https://redirect.github.com/rollup/rollup/issues/5668"">#5668</a>)</li>
</ul>
<h3>Pull Requests</h3>
<ul>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5668"">#5668</a>: Introduce JSX support (<a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>, <a href=""https://github.com/Martin-Idel""><code>@​Martin-Idel</code></a>, <a href=""https://github.com/felixhuttmann""><code>@​felixhuttmann</code></a>, <a href=""https://github.com/AlexDroll""><code>@​AlexDroll</code></a>, <a href=""https://github.com/tiptr""><code>@​tiptr</code></a>)</li>
</ul>
<h2>v4.23.0</h2>
<h2>4.23.0</h2>
<p><em>2024-10-01</em></p>
<h3>Features</h3>
<ul>
<li>Collect all emitted names and originalFileNames for assets (<a href=""https://redirect.github.com/rollup/rollup/issues/5686"">#5686</a>)</li>
</ul>
<h3>Pull Requests</h3>
<ul>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5686"">#5686</a>: Add names and originalFileNames to assets (<a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>)</li>
</ul>
<h2>v4.22.5</h2>
<h2>4.22.5</h2>
<p><em>2024-09-27</em></p>
<h3>Bug Fixes</h3>
<ul>
<li>Allow parsing of certain unicode characters again (<a href=""https://redirect.github.com/rollup/rollup/issues/5674"">#5674</a>)</li>
</ul>
<h3>Pull Requests</h3>
<ul>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5674"">#5674</a>: Fix panic with unicode characters (<a href=""https://github.com/sapphi-red""><code>@​sapphi-red</code></a>, <a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>)</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5675"">#5675</a>: chore(deps): update dependency rollup to v4.22.4 [security] (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5680"">#5680</a>: chore(deps): update dependency <code>@​rollup/plugin-commonjs</code> to v28 (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot], <a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>)</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5681"">#5681</a>: chore(deps): update dependency <code>@​rollup/plugin-replace</code> to v6 (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5682"">#5682</a>: chore(deps): update dependency <code>@​rollup/plugin-typescript</code> to v12 (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5684"">#5684</a>: chore(deps): lock file maintenance minor/patch updates (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
</ul>
<h2>v4.22.4</h2>
<h2>4.22.4</h2>
<p><em>2024-09-21</em></p>
<h3>Bug Fixes</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/rollup/rollup/blob/master/CHANGELOG.md"">rollup's changelog</a>.</em></p>
<blockquote>
<h2>4.24.0</h2>
<p><em>2024-10-02</em></p>
<h3>Features</h3>
<ul>
<li>Support preserving and transpiling JSX syntax (<a href=""https://redirect.github.com/rollup/rollup/issues/5668"">#5668</a>)</li>
</ul>
<h3>Pull Requests</h3>
<ul>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5668"">#5668</a>: Introduce JSX support (<a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>, <a href=""https://github.com/Martin-Idel""><code>@​Martin-Idel</code></a>, <a href=""https://github.com/felixhuttmann""><code>@​felixhuttmann</code></a>, <a href=""https://github.com/AlexDroll""><code>@​AlexDroll</code></a>, <a href=""https://github.com/tiptr""><code>@​tiptr</code></a>)</li>
</ul>
<h2>4.23.0</h2>
<p><em>2024-10-01</em></p>
<h3>Features</h3>
<ul>
<li>Collect all emitted names and originalFileNames for assets (<a href=""https://redirect.github.com/rollup/rollup/issues/5686"">#5686</a>)</li>
</ul>
<h3>Pull Requests</h3>
<ul>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5686"">#5686</a>: Add names and originalFileNames to assets (<a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>)</li>
</ul>
<h2>4.22.5</h2>
<p><em>2024-09-27</em></p>
<h3>Bug Fixes</h3>
<ul>
<li>Allow parsing of certain unicode characters again (<a href=""https://redirect.github.com/rollup/rollup/issues/5674"">#5674</a>)</li>
</ul>
<h3>Pull Requests</h3>
<ul>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5674"">#5674</a>: Fix panic with unicode characters (<a href=""https://github.com/sapphi-red""><code>@​sapphi-red</code></a>, <a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>)</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5675"">#5675</a>: chore(deps): update dependency rollup to v4.22.4 [security] (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5680"">#5680</a>: chore(deps): update dependency <code>@​rollup/plugin-commonjs</code> to v28 (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot], <a href=""https://github.com/lukastaegert""><code>@​lukastaegert</code></a>)</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5681"">#5681</a>: chore(deps): update dependency <code>@​rollup/plugin-replace</code> to v6 (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5682"">#5682</a>: chore(deps): update dependency <code>@​rollup/plugin-typescript</code> to v12 (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
<li><a href=""https://redirect.github.com/rollup/rollup/pull/5684"">#5684</a>: chore(deps): lock file maintenance minor/patch updates (<a href=""https://github.com/renovate""><code>@​renovate</code></a>[bot])</li>
</ul>
<h2>4.22.4</h2>
<p><em>2024-09-21</em></p>
<h3>Bug Fixes</h3>
<ul>
<li>Fix a vulnerability in generated code that affects IIFE, UMD and CJS bundles when run in a browser context (<a href=""https://redirect.github.com/rollup/rollup/issues/5671"">#5671</a>)</li>
</ul>
<h3>Pull Requests</h3>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/rollup/rollup/commit/d3c000f4fd453e39a354299f0cfaa6831f56d7d8""><code>d3c000f</code></a> 4.24.0</li>
<li><a href=""https://github.com/rollup/rollup/commit/ca186eeed8ac570b96d6861dfa0c8a28c961eb65""><code>ca186ee</code></a> Introduce JSX support (<a href=""https://redirect.github.com/rollup/rollup/issues/5668"">#5668</a>)</li>
<li><a href=""https://github.com/rollup/rollup/commit/ed98e0821e6ad064839f0af46ceca061adbe3f14""><code>ed98e08</code></a> 4.23.0</li>
<li><a href=""https://github.com/rollup/rollup/commit/d0eee9cc074a3474b81b08c2bf4a59ef59357640""><code>d0eee9c</code></a> Add names and originalFileNames to assets (<a href=""https://redirect.github.com/rollup/rollup/issues/5686"">#5686</a>)</li>
<li><a href=""https://github.com/rollup/rollup/commit/bc7780c322e134492f40a76bf64afe561670425c""><code>bc7780c</code></a> 4.22.5</li>
<li><a href=""https://github.com/rollup/rollup/commit/ee138d1589a813715389cda09c2a2f7e1ac9a78f""><code>ee138d1</code></a> chore(deps): lock file maintenance minor/patch updates (<a href=""https://redirect.github.com/rollup/rollup/issues/5684"">#5684</a>)</li>
<li><a href=""https://github.com/rollup/rollup/commit/2d59dbcb83e2f04a74cf3345f13f007da3e0063a""><code>2d59dbc</code></a> chore(deps): update dependency <code>@​rollup/plugin-commonjs</code> to v28 (<a href=""https://redirect.github.com/rollup/rollup/issues/5680"">#5680</a>)</li>
<li><a href=""https://github.com/rollup/rollup/commit/524670de7e0ef5bc8aa51e748149e3080156c547""><code>524670d</code></a> Fix panic with unicode characters (<a href=""https://redirect.github.com/rollup/rollup/issues/5674"">#5674</a>)</li>
<li><a href=""https://github.com/rollup/rollup/commit/9c5e34568b60a9e97c4518cb6c3a9708c54908d7""><code>9c5e345</code></a> chore(deps): update dependency <code>@​rollup/plugin-replace</code> to v6 (<a href=""https://redirect.github.com/rollup/rollup/issues/5681"">#5681</a>)</li>
<li><a href=""https://github.com/rollup/rollup/commit/6d75b6d7242da5e69c86a57b2f33c54e9950a1fa""><code>6d75b6d</code></a> chore(deps): update dependency <code>@​rollup/plugin-typescript</code> to v12 (<a href=""https://redirect.github.com/rollup/rollup/issues/5682"">#5682</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/rollup/rollup/compare/v4.21.0...v4.24.0"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rollup&package-manager=npm_and_yarn&previous-version=4.21.0&new-version=4.24.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-10-07 17:32:14+00:00,[],2024-10-07 20:22:07+00:00,2024-10-07 20:21:59+00:00,https://github.com/apache/airflow/pull/42804,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]","[{'comment_id': 2397719768, 'issue_id': 2571044896, 'author': 'shahar1', 'body': '@jscheffl are we ok with the fact that it just updates the lockfile?', 'created_at': datetime.datetime(2024, 10, 7, 19, 29, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397766547, 'issue_id': 2571044896, 'author': 'jscheffl', 'body': ""> @jscheffl are we ok with the fact that it just updates the lockfile?\r\n\r\nIt bumps the version and the hash in the lockfile - just a dependabot upgrade... not an expert and a bit shy to merge... but if after re-base pipeline is green I'll merge..."", 'created_at': datetime.datetime(2024, 10, 7, 19, 53, 38, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-10-07 19:29:22 UTC): @jscheffl are we ok with the fact that it just updates the lockfile?

jscheffl on (2024-10-07 19:53:38 UTC): It bumps the version and the hash in the lockfile - just a dependabot upgrade... not an expert and a bit shy to merge... but if after re-base pipeline is green I'll merge...

"
2571044450,pull_request,closed,,Bump vite from 5.4.4 to 5.4.6 in /airflow/ui,"Bumps [vite](https://github.com/vitejs/vite/tree/HEAD/packages/vite) from 5.4.4 to 5.4.6.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/vitejs/vite/blob/v5.4.6/packages/vite/CHANGELOG.md"">vite's changelog</a>.</em></p>
<blockquote>
<h2><!-- raw HTML omitted -->5.4.6 (2024-09-16)<!-- raw HTML omitted --></h2>
<ul>
<li>fix: avoid DOM Clobbering gadget in <code>getRelativeUrlFromDocument</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18115"">#18115</a>) (<a href=""https://github.com/vitejs/vite/commit/179b17773cf35c73ddb041f9e6c703fd9f3126af"">179b177</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18115"">#18115</a></li>
<li>fix: fs raw query (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18112"">#18112</a>) (<a href=""https://github.com/vitejs/vite/commit/6820bb3b9a54334f3268fc5ee1e967d2e1c0db34"">6820bb3</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18112"">#18112</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.5 (2024-09-13)<!-- raw HTML omitted --></h2>
<ul>
<li>fix(preload): backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18098"">#18098</a>, throw error preloading module as well (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18099"">#18099</a>) (<a href=""https://github.com/vitejs/vite/commit/faa2405e5d1da07a7c7fb6d48e887bf97a2f3dba"">faa2405</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18098"">#18098</a> <a href=""https://redirect.github.com/vitejs/vite/issues/18099"">#18099</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/vitejs/vite/commit/f9691767ad763720065cc7c5c7f369f97b4e7ea8""><code>f969176</code></a> release: v5.4.6</li>
<li><a href=""https://github.com/vitejs/vite/commit/179b17773cf35c73ddb041f9e6c703fd9f3126af""><code>179b177</code></a> fix: avoid DOM Clobbering gadget in <code>getRelativeUrlFromDocument</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18115"">#18115</a>)</li>
<li><a href=""https://github.com/vitejs/vite/commit/6820bb3b9a54334f3268fc5ee1e967d2e1c0db34""><code>6820bb3</code></a> fix: fs raw query (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18112"">#18112</a>)</li>
<li><a href=""https://github.com/vitejs/vite/commit/37881e71980ddbf6a93444c2d21b8ee6c076ad07""><code>37881e7</code></a> release: v5.4.5</li>
<li><a href=""https://github.com/vitejs/vite/commit/faa2405e5d1da07a7c7fb6d48e887bf97a2f3dba""><code>faa2405</code></a> fix(preload): backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18098"">#18098</a>, throw error preloading module as well (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18099"">#18099</a>)</li>
<li>See full diff in <a href=""https://github.com/vitejs/vite/commits/v5.4.6/packages/vite"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=vite&package-manager=npm_and_yarn&previous-version=5.4.4&new-version=5.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-10-07 17:32:03+00:00,[],2024-10-07 20:22:23+00:00,2024-10-07 20:22:15+00:00,https://github.com/apache/airflow/pull/42803,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2570962312,pull_request,closed,,remove docstring D214 and D215 from ignore list,"remove docstring D214 and D215 from ignore list
see #40567 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dannyl1u,2024-10-07 16:48:39+00:00,[],2024-10-07 17:31:18+00:00,2024-10-07 17:31:08+00:00,https://github.com/apache/airflow/pull/42802,[],[],
2570894550,pull_request,closed,,Add DagRunNotePydantic class,"Related to #42725 

In `DAGRunResponse` of the linked PR, I need to return `note`. This PR is for the `note`'s type",rawwar,2024-10-07 16:14:23+00:00,[],2024-10-08 17:10:22+00:00,2024-10-08 17:09:45+00:00,https://github.com/apache/airflow/pull/42800,"[('area:serialization', '')]","[{'comment_id': 2399115993, 'issue_id': 2570894550, 'author': 'pierrejeambrun', 'body': ""Serializers for the RestAPI specific to endpoints are located in `api_fastapi/serializers`. This serialization module is used by other components and I don't think we should update it."", 'created_at': datetime.datetime(2024, 10, 8, 7, 54, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400406318, 'issue_id': 2570894550, 'author': 'rawwar', 'body': ""I'm adding DagRunNotePydantic as part of get_dag_run endpoint PR."", 'created_at': datetime.datetime(2024, 10, 8, 17, 10, 20, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-08 07:54:27 UTC): Serializers for the RestAPI specific to endpoints are located in `api_fastapi/serializers`. This serialization module is used by other components and I don't think we should update it.

rawwar (Issue Creator) on (2024-10-08 17:10:20 UTC): I'm adding DagRunNotePydantic as part of get_dag_run endpoint PR.

"
2570840279,pull_request,closed,,AIP-84 Simplify route definition,Really small PR to simplify how we define routes by using router prefix property,pierrejeambrun,2024-10-07 15:51:09+00:00,['pierrejeambrun'],2024-10-07 17:33:25+00:00,2024-10-07 17:33:20+00:00,https://github.com/apache/airflow/pull/42799,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2570794107,pull_request,closed,,AIP-84 Delete Variable,"Related to: https://github.com/apache/airflow/issues/42370

Add `delete_variable` endpoint.",pierrejeambrun,2024-10-07 15:32:40+00:00,['pierrejeambrun'],2024-10-08 07:16:15+00:00,2024-10-08 07:16:13+00:00,https://github.com/apache/airflow/pull/42798,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2570546204,pull_request,closed,,Add search by `dag_display_name_pattern` on dag list page.,"https://github.com/user-attachments/assets/3428c9e1-5699-4053-a5a4-d8c7c483afc5

* I have updated the URL to reflect changes in the `dagDisplayNamePattern`. If this is not desirable, I can remove it.
* I created an enum in `searchParams.ts`.

There are a few issues to address:
* The `dagDisplayNamePattern` does not accurately find or include the DAGs when the text matches the tag name exactly. The reason for this is unclear.
* The spinner is not centered. I removed the conditional rendering logic for `DagsList` based on `isLoading`, as it was causing the entire `DagsList` component to re-render every time the data was updated.

[
Closes: https://github.com/apache/airflow/issues/27581
](https://github.com/apache/airflow/issues/42714)",luyangliuable,2024-10-07 14:04:20+00:00,[],2024-10-10 12:21:49+00:00,2024-10-10 12:21:49+00:00,https://github.com/apache/airflow/pull/42797,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2397030153, 'issue_id': 2570546204, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 7, 14, 4, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402605958, 'issue_id': 2570546204, 'author': 'pierrejeambrun', 'body': ""> Also, @pierrejeambrun we might need to adjust the pattern search query, with a on the backend since I couldn't get it to work, even with curl. Looks like we might not be setting the attribute right in our search parameters class\r\n\r\nIndeed something's off.\r\n\r\nPR here https://github.com/apache/airflow/pull/42863, let me know if this is better. (works on my end)"", 'created_at': datetime.datetime(2024, 10, 9, 15, 6, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404437911, 'issue_id': 2570546204, 'author': 'bbovenzi', 'body': 'Looking good. Add the wildcard key, rebase and run `pnpm lint:fix` and we should be just about ready to merge.', 'created_at': datetime.datetime(2024, 10, 10, 8, 27, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404884971, 'issue_id': 2570546204, 'author': 'luyangliuable', 'body': 'Hi @bbovenzi , I rebased and created a new PR https://github.com/apache/airflow/pull/42896 that fixed these:\r\n* Add the wildcard key.\r\n* Rebase.\r\n* Run pnpm lint:fix with no errors.\r\n\r\nnew PR: https://github.com/apache/airflow/pull/42896', 'created_at': datetime.datetime(2024, 10, 10, 11, 53, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404942644, 'issue_id': 2570546204, 'author': 'bbovenzi', 'body': 'Closed in favor of https://github.com/apache/airflow/pull/42896', 'created_at': datetime.datetime(2024, 10, 10, 12, 21, 49, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-07 14:04:26 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

pierrejeambrun on (2024-10-09 15:06:48 UTC): Indeed something's off.

PR here https://github.com/apache/airflow/pull/42863, let me know if this is better. (works on my end)

bbovenzi on (2024-10-10 08:27:01 UTC): Looking good. Add the wildcard key, rebase and run `pnpm lint:fix` and we should be just about ready to merge.

luyangliuable (Issue Creator) on (2024-10-10 11:53:03 UTC): Hi @bbovenzi , I rebased and created a new PR https://github.com/apache/airflow/pull/42896 that fixed these:
* Add the wildcard key.
* Rebase.
* Run pnpm lint:fix with no errors.

new PR: https://github.com/apache/airflow/pull/42896

bbovenzi on (2024-10-10 12:21:49 UTC): Closed in favor of https://github.com/apache/airflow/pull/42896

"
2570429185,pull_request,closed,,Remove burdensome eslint rules,"Remove three eslint rules that proved to be too prescriptive. Based on discussion over at https://github.com/apache/airflow/pull/42711#discussion_r1787630877

- `jsx-no-bind` forces premature use of `useCallback`, which itself can lead to performance issues. Maintainers should still try to encourage defining functions outside of the component.
- `complexity` quite subjective. Maintainers should use discretion.
- `max-lines-per-function` also very subjective. Maintainers should use direction.

Other changes:
- make sure that `coverage` reports are ignored by eslint and prettier
- Add eslint-ignore for the test mocks that use null. If we have to do this a lot outside of mocks, we can revisit changing that rule too.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-07 13:20:19+00:00,[],2024-10-07 14:31:02+00:00,2024-10-07 14:31:00+00:00,https://github.com/apache/airflow/pull/42795,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2569635155,pull_request,closed,,Move Hooks to Standard provider,"We have reverted this #42659 , due to standard provider not getting installed , causing failures in tests.

Now standard provider has been added to chicken-eggs list. it should install now and works fine.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-07 07:46:24+00:00,[],2024-11-23 19:54:26+00:00,2024-10-10 05:50:43+00:00,https://github.com/apache/airflow/pull/42794,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]",[],
2569424931,pull_request,closed,,Add possibility to override the conn type for Druid,"This PR is based on a previous PR that was approved but not merged, because not all unit tests were passing: https://github.com/apache/airflow/pull/39897 
Which was in its turn based on another PR proposition: https://github.com/apache/airflow/issues/27581 

I fixed a few unit tests that were not passing last time, and I think it should be good this time.

To quote the previous description from the first PR: 

> Minor fix, which allows to use the schema which are specified in the schema rather than http as default. In the same time it doesn't change the logic as any conn_type can be selected. Intuitevely it's expected that anything specified in schema field will actually take precedence in building the desired url.

Let me know if any improvement are required. Thanks!

Closes: https://github.com/apache/airflow/issues/27581
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Rasnar,2024-10-07 06:11:27+00:00,[],2024-10-11 06:37:17+00:00,2024-10-11 06:37:14+00:00,https://github.com/apache/airflow/pull/42793,"[('area:providers', ''), ('provider:apache-druid', '')]","[{'comment_id': 2406649955, 'issue_id': 2569424931, 'author': 'shahar1', 'body': 'Looks good, thanks!', 'created_at': datetime.datetime(2024, 10, 11, 6, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406650271, 'issue_id': 2569424931, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 11, 6, 37, 16, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-10-11 06:37:00 UTC): Looks good, thanks!

boring-cyborg[bot] on (2024-10-11 06:37:16 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2569248903,pull_request,closed,,update _OwnersFilter to do an exact match,closes #42790 ,rawwar,2024-10-07 04:13:49+00:00,[],2024-11-04 10:15:41+00:00,2024-11-04 10:15:40+00:00,https://github.com/apache/airflow/pull/42792,[],"[{'comment_id': 2395952318, 'issue_id': 2569248903, 'author': 'rawwar', 'body': 'I started writing tests and then realised it\'s not straightforward. \r\n\r\nWe allow the owner field to be a string. On UI, we do a basic comma split to show owners. \r\n\r\nHere\'s an example:\r\n\r\n```\r\ndefault_args = {\r\n    \'owner\': \'Admin\',\r\n    \'depends_on_past\': False,\r\n    \'email_on_failure\': False,\r\n    \'email_on_retry\': False,\r\n    \'retries\': 1,\r\n    \'retry_delay\': timedelta(minutes=5),\r\n}\r\n\r\n# DAG A\r\ndag_a = DAG(\r\n    \'dag_owner_admin\',\r\n    default_args=default_args,\r\n    description=\'A DAG owned by Admin\',\r\n    schedule=\'@daily\',\r\n    start_date=datetime(2023, 7, 10),\r\n    catchup=False,\r\n    tags=[\'example\', \'owner_admin\'],\r\n)\r\n\r\nwith dag_a:\r\n    task_a1 = BashOperator(\r\n        task_id=\'print_date\',\r\n        bash_command=\'date\',\r\n        owner=""devops,""u,pstr$eam\',\r\n    )\r\n\r\n    task_a2 = BashOperator(\r\n        task_id=\'echo_hello\',\r\n        bash_command=\'echo ""Hello from Admin DAG""\',\r\n    )\r\n\r\n    task_a1 >> task_a2\r\n\r\n```\r\n\r\nAbove DAG will create the following entry in DB:\r\n![image](https://github.com/user-attachments/assets/23990774-f580-4fe2-a0a7-c9ad94c7ecc2)\r\n\r\nOn UI:\r\n![image](https://github.com/user-attachments/assets/84ab04e9-9a79-4833-9e71-2d9f2e5cf735)\r\n\r\n\r\nA question here: Do we want to allow users to filter by individual users or the entire owner string? Or maybe simply call allow users to filter by a owner pattern?', 'created_at': datetime.datetime(2024, 10, 7, 5, 39, 52, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-07 05:39:52 UTC): I started writing tests and then realised it's not straightforward. 

We allow the owner field to be a string. On UI, we do a basic comma split to show owners. 

Here's an example:

```
default_args = {
    'owner': 'Admin',
    'depends_on_past': False,
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# DAG A
dag_a = DAG(
    'dag_owner_admin',
    default_args=default_args,
    description='A DAG owned by Admin',
    schedule='@daily',
    start_date=datetime(2023, 7, 10),
    catchup=False,
    tags=['example', 'owner_admin'],
)

with dag_a:
    task_a1 = BashOperator(
        task_id='print_date',
        bash_command='date',
        owner=""devops,""u,pstr$eam',
    )

    task_a2 = BashOperator(
        task_id='echo_hello',
        bash_command='echo ""Hello from Admin DAG""',
    )

    task_a1 >> task_a2

```

Above DAG will create the following entry in DB:
![image](https://github.com/user-attachments/assets/23990774-f580-4fe2-a0a7-c9ad94c7ecc2)

On UI:
![image](https://github.com/user-attachments/assets/84ab04e9-9a79-4833-9e71-2d9f2e5cf735)


A question here: Do we want to allow users to filter by individual users or the entire owner string? Or maybe simply call allow users to filter by a owner pattern?

"
2569100178,pull_request,closed,,Fix: update Breeze to print correct FastAPI API port,"It currently prints webserver port. Update it to print the correct FastAPI API port.

With this fix, It will print:
![image](https://github.com/user-attachments/assets/6285bc1e-2381-4348-9810-148b838e622a)
",rawwar,2024-10-07 02:00:53+00:00,[],2024-10-07 03:07:39+00:00,2024-10-07 03:06:22+00:00,https://github.com/apache/airflow/pull/42791,"[('area:dev-tools', '')]","[{'comment_id': 2395748395, 'issue_id': 2569100178, 'author': 'rawwar', 'body': '@pierrejeambrun, please review.', 'created_at': datetime.datetime(2024, 10, 7, 2, 3, 56, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-07 02:03:56 UTC): @pierrejeambrun, please review.

"
2568931302,pull_request,closed,,On kill option for dag runs fixed branch 2 (Testing),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MRLab12,2024-10-06 22:02:33+00:00,[],2024-10-06 22:03:48+00:00,2024-10-06 22:03:44+00:00,https://github.com/apache/airflow/pull/42789,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API"")]",[],
2568914355,pull_request,open,,Drop python3.8 support core and providers - v2.10 backport,"Back-port of #42766 for v2-10

as lazy consensus as in https://lists.apache.org/thread/8wcx310km11poox5rc4pz24ttgsdllw9 passed... preparing this for Airflow 2.11",jscheffl,2024-10-06 21:34:30+00:00,[],2025-01-12 13:11:35+00:00,,https://github.com/apache/airflow/pull/42788,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:logging', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:openlineage', 'AIP-53'), ('provider:cloudant', ''), ('provider:common-io', '')]","[{'comment_id': 2397568051, 'issue_id': 2568914355, 'author': 'jscheffl', 'body': 'Mis-understood the docs/apache-airflow/installation/supported-versions.rst:55 - no backport...', 'created_at': datetime.datetime(2024, 10, 7, 18, 6, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402856926, 'issue_id': 2568914355, 'author': 'jscheffl', 'body': '@potiuk for getting this into 2.11... in `dev/README_AIRFLOW3_DEV.md` there is no definition... which target merge branch to be used as ""parking lot"" for 2.11? Is `v2-10-test`correct? There is no v2-11-test and no v2-test....', 'created_at': datetime.datetime(2024, 10, 9, 17, 5, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402859883, 'issue_id': 2568914355, 'author': 'jscheffl', 'body': 'Note before merge: Last 3 commits from PR #42766 are not on this back-port (yet). Backport was cut before review completed.', 'created_at': datetime.datetime(2024, 10, 9, 17, 6, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2424223058, 'issue_id': 2568914355, 'author': 'jscheffl', 'body': '> Note before merge: Last 3 commits from PR #42766 are not on this back-port (yet). Backport was cut before review completed.\r\n\r\nDONE.', 'created_at': datetime.datetime(2024, 10, 19, 21, 36, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432109020, 'issue_id': 2568914355, 'author': 'potiuk', 'body': 'Just as a comment to remind in the future - python version in the check_python_version script from #43282 (back-ported in #43310) will also need to be updated before we merge it', 'created_at': datetime.datetime(2024, 10, 23, 13, 7, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2433476385, 'issue_id': 2568914355, 'author': 'jscheffl', 'body': '> Just as a comment to remind in the future - python version in the check_python_version script from #43282 (back-ported in #43310) will also need to be updated before we merge it\r\n\r\nThanks fr the hint, added this in this PR in last commit. DONE', 'created_at': datetime.datetime(2024, 10, 23, 21, 14, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439739937, 'issue_id': 2568914355, 'author': 'potiuk', 'body': 'Will have to wait for the 2.11 cut-off I guess.', 'created_at': datetime.datetime(2024, 10, 26, 21, 20, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2548737055, 'issue_id': 2568914355, 'author': 'kaxil', 'body': '@jscheffl  Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.', 'created_at': datetime.datetime(2024, 12, 17, 15, 19, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549309079, 'issue_id': 2568914355, 'author': 'jscheffl', 'body': ""> @jscheffl Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.\r\n\r\nUuf, I think I can do this later. But if you want to force-push to v2-10-test I see no problem. I need to re-base this PR anyway. Just go ahead and I'll re-base and check later. (Anyway I assume it is a bit of a moving target until 2.11 is not on the table and blocks this PR from being merged)"", 'created_at': datetime.datetime(2024, 12, 17, 18, 41, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549317405, 'issue_id': 2568914355, 'author': 'kaxil', 'body': ""> > @jscheffl Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.\r\n> \r\n> Uuf, I think I can do this later. But if you want to force-push to v2-10-test I see no problem. I need to re-base this PR anyway. Just go ahead and I'll re-base and check later. (Anyway I assume it is a bit of a moving target until 2.11 is not on the table and blocks this PR from being merged)\r\n\r\nI have done that already :) and rebased your PR too"", 'created_at': datetime.datetime(2024, 12, 17, 18, 44, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585729370, 'issue_id': 2568914355, 'author': 'potiuk', 'body': 'Hey @jscheffl -> I rebased this one on top of the ""no pull-request-target"" v2-10-test.', 'created_at': datetime.datetime(2025, 1, 12, 13, 11, 33, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-10-07 18:06:13 UTC): Mis-understood the docs/apache-airflow/installation/supported-versions.rst:55 - no backport...

jscheffl (Issue Creator) on (2024-10-09 17:05:11 UTC): @potiuk for getting this into 2.11... in `dev/README_AIRFLOW3_DEV.md` there is no definition... which target merge branch to be used as ""parking lot"" for 2.11? Is `v2-10-test`correct? There is no v2-11-test and no v2-test....

jscheffl (Issue Creator) on (2024-10-09 17:06:45 UTC): Note before merge: Last 3 commits from PR #42766 are not on this back-port (yet). Backport was cut before review completed.

jscheffl (Issue Creator) on (2024-10-19 21:36:28 UTC): DONE.

potiuk on (2024-10-23 13:07:41 UTC): Just as a comment to remind in the future - python version in the check_python_version script from #43282 (back-ported in #43310) will also need to be updated before we merge it

jscheffl (Issue Creator) on (2024-10-23 21:14:25 UTC): Thanks fr the hint, added this in this PR in last commit. DONE

potiuk on (2024-10-26 21:20:33 UTC): Will have to wait for the 2.11 cut-off I guess.

kaxil on (2024-12-17 15:19:42 UTC): @jscheffl  Could you verify your changes again -- I needed to force-push on v2-10-test to sync it back with v2-10-stable.

jscheffl (Issue Creator) on (2024-12-17 18:41:42 UTC): Uuf, I think I can do this later. But if you want to force-push to v2-10-test I see no problem. I need to re-base this PR anyway. Just go ahead and I'll re-base and check later. (Anyway I assume it is a bit of a moving target until 2.11 is not on the table and blocks this PR from being merged)

kaxil on (2024-12-17 18:44:50 UTC): I have done that already :) and rebased your PR too

potiuk on (2025-01-12 13:11:33 UTC): Hey @jscheffl -> I rebased this one on top of the ""no pull-request-target"" v2-10-test.

"
2568902387,pull_request,closed,,Fix import sequencing in skip-db-tests,"If we do not initializing the database (due to skip db tests) then we need to ensure Backfill is defined before DagRun otherwise we get error 'sqlalchemy.exc.InvalidRequestError: When initializing mapper mapped class...'.
",dstandish,2024-10-06 21:09:10+00:00,[],2024-10-08 13:57:05+00:00,2024-10-06 22:22:27+00:00,https://github.com/apache/airflow/pull/42787,[],"[{'comment_id': 2395596097, 'issue_id': 2568902387, 'author': 'dstandish', 'body': '> Mhm, when I run `breeze testing non-db-tests --parallel-test-types ""Always CLI""` I still have failures.\r\n\r\nseems to work in ci at least', 'created_at': datetime.datetime(2024, 10, 6, 21, 45, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395604367, 'issue_id': 2568902387, 'author': 'jscheffl', 'body': '> > Mhm, when I run `breeze testing non-db-tests --parallel-test-types ""Always CLI""` I still have failures.\r\n> \r\n> seems to work in ci at least\r\n\r\nInterestig... interesting. Seems xdist/Pytest paraellism generates locally always a different amount of failures, also depending on which `--parallelism` I set. But locally I am not able to get it green :-(', 'created_at': datetime.datetime(2024, 10, 6, 22, 12, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395607052, 'issue_id': 2568902387, 'author': 'dstandish', 'body': '> > > Mhm, when I run `breeze testing non-db-tests --parallel-test-types ""Always CLI""` I still have failures.\r\n> > \r\n> > \r\n> > seems to work in ci at least\r\n> \r\n> Interestig... interesting. Seems xdist/Pytest paraellism generates locally always a different amount of failures, also depending on which `--parallelism` I set. But locally I am not able to get it green :-(\r\n\r\nI\'ll merge it now anyway, since seems to allow CI to run', 'created_at': datetime.datetime(2024, 10, 6, 22, 22, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398856954, 'issue_id': 2568902387, 'author': 'rawwar', 'body': ""Tests are failing on CI. I just added `from airflow.models.backfill import Backfill` at the top level in `conftest.py` and it makes the tests pass. I guess, this means `initialize_airflow_tests` isn't invoked."", 'created_at': datetime.datetime(2024, 10, 8, 5, 15, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399801411, 'issue_id': 2568902387, 'author': 'dstandish', 'body': ""> Tests are failing on CI. I just added `from airflow.models.backfill import Backfill` at the top level in `conftest.py` and it makes the tests pass. I guess, this means `initialize_airflow_tests` isn't invoked.\r\n\r\ndid you figure it out?"", 'created_at': datetime.datetime(2024, 10, 8, 13, 8, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399918578, 'issue_id': 2568902387, 'author': 'rawwar', 'body': '> did you figure it out?\r\n\r\nSorry, No.  But, the only way I was able to make it work was to import `Backfill` at top level in conftest.py.', 'created_at': datetime.datetime(2024, 10, 8, 13, 54, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399925698, 'issue_id': 2568902387, 'author': 'dstandish', 'body': '> > did you figure it out?\r\n> \r\n> Sorry, No. But, the only way I was able to make it work was to import `Backfill` at top level in conftest.py.\r\n\r\npr forthcoming', 'created_at': datetime.datetime(2024, 10, 8, 13, 57, 3, tzinfo=datetime.timezone.utc)}]","dstandish (Issue Creator) on (2024-10-06 21:45:16 UTC): seems to work in ci at least

jscheffl on (2024-10-06 22:12:47 UTC): Interestig... interesting. Seems xdist/Pytest paraellism generates locally always a different amount of failures, also depending on which `--parallelism` I set. But locally I am not able to get it green :-(

dstandish (Issue Creator) on (2024-10-06 22:22:21 UTC): I'll merge it now anyway, since seems to allow CI to run

rawwar on (2024-10-08 05:15:06 UTC): Tests are failing on CI. I just added `from airflow.models.backfill import Backfill` at the top level in `conftest.py` and it makes the tests pass. I guess, this means `initialize_airflow_tests` isn't invoked.

dstandish (Issue Creator) on (2024-10-08 13:08:21 UTC): did you figure it out?

rawwar on (2024-10-08 13:54:29 UTC): Sorry, No.  But, the only way I was able to make it work was to import `Backfill` at top level in conftest.py.

dstandish (Issue Creator) on (2024-10-08 13:57:03 UTC): pr forthcoming

"
2568812439,pull_request,closed,,Add kubernetes_conn_id  to templated fields,"As per issue, user has working `kubernetes_conn_id` with jinja fields with 2.5.3 version. I don't have this version to re produce. so not sure entirely how its getting resolved on this versions.

Am able to produce this on the latest versions `kubernetes_conn_id` connection id is not resolving when jinja fields provided, IMO it should be added to templated fields. 

closes: #42546
 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-06 18:28:35+00:00,[],2024-11-02 13:05:02+00:00,2024-10-16 19:27:58+00:00,https://github.com/apache/airflow/pull/42786,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2397515199, 'issue_id': 2568812439, 'author': 'gopidesupavan', 'body': 'Verified the failure tests are not related to this.', 'created_at': datetime.datetime(2024, 10, 7, 17, 36, 45, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-07 17:36:45 UTC): Verified the failure tests are not related to this.

"
2568744860,pull_request,closed,,Use url_from_endpoint inside HttpHook.,"`url_from_endpoint` was removed at https://github.com/apache/airflow/pull/37696 and returned back later at https://github.com/apache/airflow/pull/37738. Is there any reason to not use the `url_from_endpoint` inside HttpHook? That way it can be overriden in other hooks based on HttpHook to enhance URL building logic. In my case, I would like to append api key to the end of the url as query parameter.",simi,2024-10-06 16:30:24+00:00,[],2024-10-10 22:22:40+00:00,2024-10-10 22:21:50+00:00,https://github.com/apache/airflow/pull/42785,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2395571633, 'issue_id': 2568744860, 'author': 'simi', 'body': '🤔 CI seems not related (I see similar errors on other PR).', 'created_at': datetime.datetime(2024, 10, 6, 20, 17, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396383444, 'issue_id': 2568744860, 'author': 'simi', 'body': ':information_source: squashed and rebased @potiuk', 'created_at': datetime.datetime(2024, 10, 7, 9, 21, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405909511, 'issue_id': 2568744860, 'author': 'simi', 'body': '@potiuk CI is happy after latest rebase.', 'created_at': datetime.datetime(2024, 10, 10, 19, 47, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406144453, 'issue_id': 2568744860, 'author': 'simi', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 10, 10, 22, 22, 39, tzinfo=datetime.timezone.utc)}]","simi (Issue Creator) on (2024-10-06 20:17:10 UTC): 🤔 CI seems not related (I see similar errors on other PR).

simi (Issue Creator) on (2024-10-07 09:21:35 UTC): :information_source: squashed and rebased @potiuk

simi (Issue Creator) on (2024-10-10 19:47:25 UTC): @potiuk CI is happy after latest rebase.

simi (Issue Creator) on (2024-10-10 22:22:39 UTC): Thanks!

"
2568732623,pull_request,closed,,BashOperator: Execute templated bash script as file,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


This PR change the behavior of the BashOperator: When executing a `.sh` file with Jinja templating enabled (without the space -- `.sh `), the rendered script is written back into a temporary file, and then executed. Instead of being directly executed as inline command.

![Pasted image](https://github.com/user-attachments/assets/46e5dbc6-1d21-417c-b9b6-ee3440dca052)

*Note*: No changes / side-effect when executing a inline command or a script without Jinja templating ( `.sh ` with space).

### Why ?
When using templated bash command, the rendered string can be longer than the maximum argument length. This causes [`""Argument list too long""`](https://stackoverflow.com/questions/57251024/exact-limit-to-avoid-argument-list-too-long) error.

Without this PR, currently, the bash command is passed as argument into `[""bash"", ""-c"", command]`. The `command` cannot be longer than the max length of the system.

With this PR, the user can write his command into a bash file. The file is jinja-rendered and executed as a file, which bypass the maximum argument length limit.

### Breaking change
The BashOperator writes the rendered file to the disk. By default, it's in a temporary directory (`/tmp`) where Airflow has *write* access (in a common Linux system). However, if the user specify a `cwd` directory where Airflow cannot write, task will fail.

Backport #43191 warns the user when permissions are missing, and fallback to executing the script as inline command.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Joffreybvn,2024-10-06 16:02:23+00:00,[],2024-10-24 08:54:54+00:00,2024-10-24 00:26:17+00:00,https://github.com/apache/airflow/pull/42783,"[('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2395695661, 'issue_id': 2568732623, 'author': 'eladkal', 'body': ""> ### Breaking change\r\n> The BashOperator writes the rendered file to the disk. By default, it's in a temporary directory (`/tmp`) where Airflow has _write_ access (in a common Linux system). However, if the user specify a `cwd` directory where Airflow cannot write, task will fail.\r\n> \r\n> IMO this will affect only a small portion of users. Should I add a flag to control the behavior of the Operator ? Or maybe another PR with a warning that behavior will change in the future ?\r\n\r\n\r\nWe need newsfragment in the PR that explains the change.\r\nWe need a new PR against v 2.10 test branch that adds the warnning and allow users to migrate to the new functionality. We show warning only if user can do something about it"", 'created_at': datetime.datetime(2024, 10, 7, 0, 54, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2424721534, 'issue_id': 2568732623, 'author': 'Joffreybvn', 'body': 'Created a new PR #43191, which implements this feature with a fallback to the former behaviour in case of permission issue; and a warning for the user to fix it.', 'created_at': datetime.datetime(2024, 10, 20, 8, 13, 23, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-10-07 00:54:01 UTC): We need newsfragment in the PR that explains the change.
We need a new PR against v 2.10 test branch that adds the warnning and allow users to migrate to the new functionality. We show warning only if user can do something about it

Joffreybvn (Issue Creator) on (2024-10-20 08:13:23 UTC): Created a new PR #43191, which implements this feature with a fallback to the former behaviour in case of permission issue; and a warning for the user to fix it.

"
2568701684,pull_request,closed,,AIP-84 Migrate get connections to FastAPI API #42571,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: https://github.com/apache/airflow/issues/42591


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-10-06 14:54:07+00:00,[],2024-10-15 17:24:08+00:00,2024-10-15 16:05:58+00:00,https://github.com/apache/airflow/pull/42782,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2395470010, 'issue_id': 2568701684, 'author': 'bugraoz93', 'body': 'Could someone please include `legacy api` label, I have got into the special checks merged from here #42758 :)', 'created_at': datetime.datetime(2024, 10, 6, 14, 59, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395585897, 'issue_id': 2568701684, 'author': 'gopidesupavan', 'body': '> Could someone please include `legacy api` label, I have got into the special checks merged from here #42758 :)\r\n\r\ndone..', 'created_at': datetime.datetime(2024, 10, 6, 21, 8, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414177174, 'issue_id': 2568701684, 'author': 'pierrejeambrun', 'body': 'I just rebased the branch and resolved merge conflicts. I think we are good to go.', 'created_at': datetime.datetime(2024, 10, 15, 14, 57, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414437664, 'issue_id': 2568701684, 'author': 'pierrejeambrun', 'body': 'Merging because we need that for other PRs. (dynamic order_by).\r\n\r\nWe can adjust with following PR if needed.', 'created_at': datetime.datetime(2024, 10, 15, 16, 5, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414600611, 'issue_id': 2568701684, 'author': 'bugraoz93', 'body': ""> Merging because we need that for other PRs. (dynamic order_by).\r\n> \r\n> We can adjust with following PR if needed.\r\n\r\nMake sense! I don't want to block anyone in the development flow. At least, you have already driven it and finalised the work so that it didn't block anyone for a long time. \r\nFor sure, I don't have any comments on the SortParam part. It looks great. I think one of the methods (`get_primary_key_of_given_model_string`) of the SortParam hasn't been used anywhere since the bespoke part was removed. I will remove the unused method in my next MR. I have started working on the next one  PATCH a Connection already."", 'created_at': datetime.datetime(2024, 10, 15, 17, 24, 7, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-10-06 14:59:13 UTC): Could someone please include `legacy api` label, I have got into the special checks merged from here #42758 :)

gopidesupavan on (2024-10-06 21:08:12 UTC): done..

pierrejeambrun on (2024-10-15 14:57:34 UTC): I just rebased the branch and resolved merge conflicts. I think we are good to go.

pierrejeambrun on (2024-10-15 16:05:55 UTC): Merging because we need that for other PRs. (dynamic order_by).

We can adjust with following PR if needed.

bugraoz93 (Issue Creator) on (2024-10-15 17:24:07 UTC): Make sense! I don't want to block anyone in the development flow. At least, you have already driven it and finalised the work so that it didn't block anyone for a long time. 
For sure, I don't have any comments on the SortParam part. It looks great. I think one of the methods (`get_primary_key_of_given_model_string`) of the SortParam hasn't been used anywhere since the bespoke part was removed. I will remove the unused method in my next MR. I have started working on the next one  PATCH a Connection already.

"
2568610991,pull_request,closed,,Fix canary build test test_cli_fastapi_api_background process termination,"Applying similar fix  #42773 to fast api

Moved terminate process to common cli classes.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-06 11:29:38+00:00,[],2024-11-23 19:54:07+00:00,2024-10-06 12:52:13+00:00,https://github.com/apache/airflow/pull/42781,"[('area:CLI', '')]","[{'comment_id': 2395429500, 'issue_id': 2568610991, 'author': 'jscheffl', 'body': 'Failed Non-DB Tests are unrelated to this improvement, merging', 'created_at': datetime.datetime(2024, 10, 6, 12, 52, 6, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-06 12:52:06 UTC): Failed Non-DB Tests are unrelated to this improvement, merging

"
2568485639,pull_request,closed,,Add support to filter by last dagrun state in UI.,"closes: #42715
related: #42715

Add filter state on change to ""lastrun"" URL parameter which is used in legacy UI too and pass the state to dags list API.
",tirkarthi,2024-10-06 06:12:38+00:00,[],2024-10-09 08:15:15+00:00,2024-10-09 08:15:15+00:00,https://github.com/apache/airflow/pull/42779,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2395369187, 'issue_id': 2568485639, 'author': 'tirkarthi', 'body': 'I am trying to run `pnpm lint:fix` which seems to give a different output compared to the errors in CI. Is there something missing in my local setup?\r\n\r\n```\r\n$ /home/karthikeyan/.local/share/pnpm/pnpm lint:fix\r\n\r\n> ui@0.0.0 lint:fix /home/karthikeyan/stuff/python/airflow/airflow/ui\r\n> eslint --fix && tsc --p tsconfig.app.json\r\n\r\n\r\n/home/karthikeyan/stuff/python/airflow/airflow/ui/src/App.test.tsx\r\n  35:20  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  43:21  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  45:21  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  54:18  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  55:23  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  64:20  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  72:21  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  74:21  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  83:18  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n  84:23  warning  Use `undefined` instead of `null`  unicorn/no-null\r\n\r\n/home/karthikeyan/stuff/python/airflow/airflow/ui/src/pages/DagsList/DagsFilters.tsx\r\n  30:28  warning  Arrow function has too many statements (12). Maximum allowed is 10  max-statements\r\n\r\n/home/karthikeyan/stuff/python/airflow/airflow/ui/src/utils/index.tsx\r\n  20:1   error  Expected a function expression                                                                             func-style\r\n  27:10  error  Unexpected nullable string value in conditional. Please handle the nullish/empty cases explicitly          @typescript-eslint/strict-boolean-expressions\r\n  27:39  error  Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator  @typescript-eslint/prefer-nullish-coalescing\r\n\r\n✖ 14 problems (3 errors, 11 warnings)\r\n\r\n\u2009ELIFECYCLE\u2009 Command failed with exit code 1.\r\n\r\n```', 'created_at': datetime.datetime(2024, 10, 6, 9, 38, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396210341, 'issue_id': 2568485639, 'author': 'pierrejeambrun', 'body': '@tirkarthi\r\n\r\nOn my end, running `pnpm lint:fix` on your branch shows the same errors that the CI mentions.\r\n\r\nIt looks like your `eslint` is showing errors, where as the CI has no error on `eslint` part and shows errors from typescript only.\r\n\r\nCan you verify your pnpm, eslint and node versions? You can find more information about supported versions in https://github.com/apache/airflow/blob/main/contributing-docs/14_node_environment_setup.rst', 'created_at': datetime.datetime(2024, 10, 7, 8, 7, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396717911, 'issue_id': 2568485639, 'author': 'bbovenzi', 'body': 'Yes, sometimes I need to make sure my local environment has the right version of node by running\r\n`nvm install 20 && nvm use 20`', 'created_at': datetime.datetime(2024, 10, 7, 11, 54, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399022875, 'issue_id': 2568485639, 'author': 'tirkarthi', 'body': 'Thanks @pierrejeambrun  and @bbovenzi . I had an uncommitted file with eslint error at `src/utils/index.tsx`. Removing it helped in fixing the issue. \r\n\r\nTypeScript was complaining about typecasting the query parameter which was a string to type DagRunState. I did a typecast using ""as"". Googling around recommends using const with array of string but would be helpful to know if there is a similar pattern check in the existing code for reuse. The issue would be around passing invalid lastrun value that will be passed to API and 422 will be returned resulting in empty page.\r\n\r\n```\r\ntype DagRunState = ""queued"" | ""running"" | ""success"" | ""failed"";\r\n```\r\n\r\nhttps://stackoverflow.com/questions/36836011/checking-validity-of-string-literal-union-type-at-runtime', 'created_at': datetime.datetime(2024, 10, 8, 7, 9, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399179753, 'issue_id': 2568485639, 'author': 'bbovenzi', 'body': ""> https://stackoverflow.com/questions/36836011/checking-validity-of-string-literal-union-type-at-runtime\r\n\r\nWe don't have an example of that yet. But I imagine we'll need a util like that. In the stackoverflow link. I would definitely lean towards a version of option 3."", 'created_at': datetime.datetime(2024, 10, 8, 8, 21, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399244767, 'issue_id': 2568485639, 'author': 'tirkarthi', 'body': ""> > https://stackoverflow.com/questions/36836011/checking-validity-of-string-literal-union-type-at-runtime\r\n> \r\n> We don't have an example of that yet. But I imagine we'll need a util like that. In the stackoverflow link. I would definitely lean towards a version of option 3.\r\n\r\n@bbovenzi  Quoting from the answer this needs the dag run states to be an array of strings. Since it's a type using union syntax I guess it's tricky. Please add in if I missed something or to change something since the part seems to be auto generated.\r\n\r\n> In all cases you will need to store the strings in an object that is available at runtime (e.g. an array)."", 'created_at': datetime.datetime(2024, 10, 8, 8, 49, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399278313, 'issue_id': 2568485639, 'author': 'tirkarthi', 'body': ""Thanks @pierrejeambrun and @bbovenzi , made the suggested changes and rebased with latest main branch. \r\n\r\nSlightly off-topic but I see PRs with only new UI folder changes running tests for databases like mysql, postgres and sqlite which takes 20 minutes each along with integration tests, docs builds (--docs-only and spellcheck take 20+ mins) which I also guess is not required. Skipping them can speed up UI PRs build time and also reduce CI load. I tried to figure out how to skip them which should probably be done in selective_check function in ci_commands.py but couldn't figure out the exact conditional and logic.\r\n\r\nhttps://github.com/apache/airflow/actions/runs/11229469726/job/31215226666 (20 minutes per database)\r\nhttps://github.com/apache/airflow/actions/runs/11229469726/job/31215228586 (integration tests)"", 'created_at': datetime.datetime(2024, 10, 8, 9, 3, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399284174, 'issue_id': 2568485639, 'author': 'bbovenzi', 'body': ""> > > https://stackoverflow.com/questions/36836011/checking-validity-of-string-literal-union-type-at-runtime\r\n> > \r\n> > \r\n> > We don't have an example of that yet. But I imagine we'll need a util like that. In the stackoverflow link. I would definitely lean towards a version of option 3.\r\n> \r\n> @bbovenzi Quoting from the answer this needs the dag run states to be an array of strings. Since it's a type using union syntax I guess it's tricky. Please add in if I missed something or to change something since the part seems to be auto generated.\r\n> \r\n> > In all cases you will need to store the strings in an object that is available at runtime (e.g. an array).\r\n\r\nPerhaps something like this: https://stackoverflow.com/a/70694878"", 'created_at': datetime.datetime(2024, 10, 8, 9, 5, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399309048, 'issue_id': 2568485639, 'author': 'tirkarthi', 'body': ""> > > > https://stackoverflow.com/questions/36836011/checking-validity-of-string-literal-union-type-at-runtime\r\n> > > \r\n> > > \r\n> > > We don't have an example of that yet. But I imagine we'll need a util like that. In the stackoverflow link. I would definitely lean towards a version of option 3.\r\n> > \r\n> > \r\n> > @bbovenzi Quoting from the answer this needs the dag run states to be an array of strings. Since it's a type using union syntax I guess it's tricky. Please add in if I missed something or to change something since the part seems to be auto generated.\r\n> > > In all cases you will need to store the strings in an object that is available at runtime (e.g. an array).\r\n> \r\n> Perhaps something like this: https://stackoverflow.com/a/70694878\r\n\r\nIt seems it still needs specifying all union type values to be passed again to the util function as per the comment. I will leave it to another PR/issue to unblock this PR since the query parameter cannot be invalid from UI events unless user edits the URL intentionally or has a typo. It looks like a common request. Thanks for the pointers @bbovenzi ."", 'created_at': datetime.datetime(2024, 10, 8, 9, 16, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399326165, 'issue_id': 2568485639, 'author': 'pierrejeambrun', 'body': ""> Slightly off-topic but I see PRs with only new UI folder changes running tests for databases like mysql, postgres and sqlite which takes 20 minutes each along with integration tests, docs builds (--docs-only and spellcheck take 20+ mins) which I also guess is not required. Skipping them can speed up UI PRs build time and also reduce CI load. I tried to figure out how to skip them which should probably be done in selective_check function in ci_commands.py but couldn't figure out the exact conditional and logic.\r\n\r\n\r\nI believe those are part of 'default' tests. For instance if we check the `tests-sqlite`, we see that they require `run-tests` and this is basically:\r\n```python\r\n    @cached_property\r\n    def run_tests(self) -> bool:\r\n        return self._should_be_run(FileGroupForCi.ALL_SOURCE_FILES)\r\n```\r\n\r\nSo they will run every time.\r\n\r\nMaybe the CI team has an idea on how we can improve that, and do different 'default tests' depending on the Front-end and backend. (if front files are touch run default front-end, if `.py` file are run -> run default pytest)"", 'created_at': datetime.datetime(2024, 10, 8, 9, 23, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399334592, 'issue_id': 2568485639, 'author': 'pierrejeambrun', 'body': 'cc: @potiuk Just in case you have an idea.', 'created_at': datetime.datetime(2024, 10, 8, 9, 27, 34, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-10-06 09:38:51 UTC): I am trying to run `pnpm lint:fix` which seems to give a different output compared to the errors in CI. Is there something missing in my local setup?

```
$ /home/karthikeyan/.local/share/pnpm/pnpm lint:fix



/home/karthikeyan/stuff/python/airflow/airflow/ui/src/App.test.tsx
  35:20  warning  Use `undefined` instead of `null`  unicorn/no-null
  43:21  warning  Use `undefined` instead of `null`  unicorn/no-null
  45:21  warning  Use `undefined` instead of `null`  unicorn/no-null
  54:18  warning  Use `undefined` instead of `null`  unicorn/no-null
  55:23  warning  Use `undefined` instead of `null`  unicorn/no-null
  64:20  warning  Use `undefined` instead of `null`  unicorn/no-null
  72:21  warning  Use `undefined` instead of `null`  unicorn/no-null
  74:21  warning  Use `undefined` instead of `null`  unicorn/no-null
  83:18  warning  Use `undefined` instead of `null`  unicorn/no-null
  84:23  warning  Use `undefined` instead of `null`  unicorn/no-null

/home/karthikeyan/stuff/python/airflow/airflow/ui/src/pages/DagsList/DagsFilters.tsx
  30:28  warning  Arrow function has too many statements (12). Maximum allowed is 10  max-statements

/home/karthikeyan/stuff/python/airflow/airflow/ui/src/utils/index.tsx
  20:1   error  Expected a function expression                                                                             func-style
  27:10  error  Unexpected nullable string value in conditional. Please handle the nullish/empty cases explicitly          @typescript-eslint/strict-boolean-expressions
  27:39  error  Prefer using nullish coalescing operator (`??`) instead of a logical or (`||`), as it is a safer operator  @typescript-eslint/prefer-nullish-coalescing

✖ 14 problems (3 errors, 11 warnings)

 ELIFECYCLE  Command failed with exit code 1.

```

pierrejeambrun on (2024-10-07 08:07:04 UTC): @tirkarthi

On my end, running `pnpm lint:fix` on your branch shows the same errors that the CI mentions.

It looks like your `eslint` is showing errors, where as the CI has no error on `eslint` part and shows errors from typescript only.

Can you verify your pnpm, eslint and node versions? You can find more information about supported versions in https://github.com/apache/airflow/blob/main/contributing-docs/14_node_environment_setup.rst

bbovenzi on (2024-10-07 11:54:02 UTC): Yes, sometimes I need to make sure my local environment has the right version of node by running
`nvm install 20 && nvm use 20`

tirkarthi (Issue Creator) on (2024-10-08 07:09:30 UTC): Thanks @pierrejeambrun  and @bbovenzi . I had an uncommitted file with eslint error at `src/utils/index.tsx`. Removing it helped in fixing the issue. 

TypeScript was complaining about typecasting the query parameter which was a string to type DagRunState. I did a typecast using ""as"". Googling around recommends using const with array of string but would be helpful to know if there is a similar pattern check in the existing code for reuse. The issue would be around passing invalid lastrun value that will be passed to API and 422 will be returned resulting in empty page.

```
type DagRunState = ""queued"" | ""running"" | ""success"" | ""failed"";
```

https://stackoverflow.com/questions/36836011/checking-validity-of-string-literal-union-type-at-runtime

bbovenzi on (2024-10-08 08:21:19 UTC): We don't have an example of that yet. But I imagine we'll need a util like that. In the stackoverflow link. I would definitely lean towards a version of option 3.

tirkarthi (Issue Creator) on (2024-10-08 08:49:06 UTC): @bbovenzi  Quoting from the answer this needs the dag run states to be an array of strings. Since it's a type using union syntax I guess it's tricky. Please add in if I missed something or to change something since the part seems to be auto generated.

tirkarthi (Issue Creator) on (2024-10-08 09:03:14 UTC): Thanks @pierrejeambrun and @bbovenzi , made the suggested changes and rebased with latest main branch. 

Slightly off-topic but I see PRs with only new UI folder changes running tests for databases like mysql, postgres and sqlite which takes 20 minutes each along with integration tests, docs builds (--docs-only and spellcheck take 20+ mins) which I also guess is not required. Skipping them can speed up UI PRs build time and also reduce CI load. I tried to figure out how to skip them which should probably be done in selective_check function in ci_commands.py but couldn't figure out the exact conditional and logic.

https://github.com/apache/airflow/actions/runs/11229469726/job/31215226666 (20 minutes per database)
https://github.com/apache/airflow/actions/runs/11229469726/job/31215228586 (integration tests)

bbovenzi on (2024-10-08 09:05:42 UTC): Perhaps something like this: https://stackoverflow.com/a/70694878

tirkarthi (Issue Creator) on (2024-10-08 09:16:28 UTC): It seems it still needs specifying all union type values to be passed again to the util function as per the comment. I will leave it to another PR/issue to unblock this PR since the query parameter cannot be invalid from UI events unless user edits the URL intentionally or has a typo. It looks like a common request. Thanks for the pointers @bbovenzi .

pierrejeambrun on (2024-10-08 09:23:53 UTC): I believe those are part of 'default' tests. For instance if we check the `tests-sqlite`, we see that they require `run-tests` and this is basically:
```python
    @cached_property
    def run_tests(self) -> bool:
        return self._should_be_run(FileGroupForCi.ALL_SOURCE_FILES)
```

So they will run every time.

Maybe the CI team has an idea on how we can improve that, and do different 'default tests' depending on the Front-end and backend. (if front files are touch run default front-end, if `.py` file are run -> run default pytest)

pierrejeambrun on (2024-10-08 09:27:34 UTC): cc: @potiuk Just in case you have an idea.

"
2568474841,pull_request,closed,,Add sequence insert support to OracleHook,"If Oracle had a sequence column, it could not be entered with existing logic. We received an additional sequence column and sequence name in the existing function so that you could enter it

issue : https://github.com/apache/airflow/issues/42494",Lee2532,2024-10-06 05:36:41+00:00,[],2024-10-11 13:15:59+00:00,2024-10-11 13:13:58+00:00,https://github.com/apache/airflow/pull/42778,"[('area:providers', ''), ('provider:oracle', '')]","[{'comment_id': 2396162535, 'issue_id': 2568474841, 'author': 'Lee2532', 'body': ""I don't think this test code fail is not my fault"", 'created_at': datetime.datetime(2024, 10, 7, 7, 43, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405107131, 'issue_id': 2568474841, 'author': 'Lee2532', 'body': 'Is there anything I need to modify? cc @potiuk', 'created_at': datetime.datetime(2024, 10, 10, 13, 32, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407354541, 'issue_id': 2568474841, 'author': 'potiuk', 'body': 'You have conflicts to solve after rebasing the PR', 'created_at': datetime.datetime(2024, 10, 11, 12, 53, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407395000, 'issue_id': 2568474841, 'author': 'Lee2532', 'body': ""I made the wrong commit to git.\r\nI'll edit it again and send out PR\r\nsorry"", 'created_at': datetime.datetime(2024, 10, 11, 13, 15, 48, tzinfo=datetime.timezone.utc)}]","Lee2532 (Issue Creator) on (2024-10-07 07:43:39 UTC): I don't think this test code fail is not my fault

Lee2532 (Issue Creator) on (2024-10-10 13:32:18 UTC): Is there anything I need to modify? cc @potiuk

potiuk on (2024-10-11 12:53:43 UTC): You have conflicts to solve after rebasing the PR

Lee2532 (Issue Creator) on (2024-10-11 13:15:48 UTC): I made the wrong commit to git.
I'll edit it again and send out PR
sorry

"
2568467136,pull_request,closed,,The spark hook resolve_kerberos_principal function code update when airflow version 2.8.0 and above,The spark hook resolve_kerberos_principal function code refactored when airflow version 2.8.0 and above,dirrao,2024-10-06 05:08:01+00:00,['dirrao'],2024-10-07 16:42:36+00:00,2024-10-07 16:42:36+00:00,https://github.com/apache/airflow/pull/42777,"[('area:providers', ''), ('provider:apache-spark', '')]","[{'comment_id': 2395465898, 'issue_id': 2568467136, 'author': 'dirrao', 'body': '@potiuk / @dstandish \r\nUnrelated tests are failing. Probably the tests are broken after PR #42686 merge.', 'created_at': datetime.datetime(2024, 10, 6, 14, 45, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396283052, 'issue_id': 2568467136, 'author': 'dirrao', 'body': 'Unrelated tests are failing. Most likely related to #42642', 'created_at': datetime.datetime(2024, 10, 7, 8, 39, 14, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-10-06 14:45:19 UTC): @potiuk / @dstandish 
Unrelated tests are failing. Probably the tests are broken after PR #42686 merge.

dirrao (Issue Creator) on (2024-10-07 08:39:14 UTC): Unrelated tests are failing. Most likely related to #42642

"
2568452330,pull_request,closed,,Removed deprecated Chainable type from BaseOperator,Removed deprecated Chainable type from BaseOperator,dirrao,2024-10-06 04:16:56+00:00,['dirrao'],2024-10-15 00:56:04+00:00,2024-10-15 00:56:04+00:00,https://github.com/apache/airflow/pull/42776,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2395982077, 'issue_id': 2568452330, 'author': 'uranusjr', 'body': 'We should also remove this word from `spelling_wordlist.txt`.\r\n\r\nAlso, apparently we forgot to actually deprecate this, so we’ll need an additional PR to add the deprecation warning to the 2.x branch.', 'created_at': datetime.datetime(2024, 10, 7, 6, 6, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396210803, 'issue_id': 2568452330, 'author': 'dirrao', 'body': '> We should also remove this word from `spelling_wordlist.txt`.\r\n\r\nDone\r\n\r\n> Also, apparently we forgot to actually deprecate this, so we’ll need an additional PR to add the deprecation warning to the 2.x branch.\r\n\r\nMake sense. we will create new PR for the same.', 'created_at': datetime.datetime(2024, 10, 7, 8, 7, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402417695, 'issue_id': 2568452330, 'author': 'dirrao', 'body': '> Breaking change, please add a newsfragment :)\r\n\r\nDone.', 'created_at': datetime.datetime(2024, 10, 9, 13, 54, 12, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-10-07 06:06:14 UTC): We should also remove this word from `spelling_wordlist.txt`.

Also, apparently we forgot to actually deprecate this, so we’ll need an additional PR to add the deprecation warning to the 2.x branch.

dirrao (Issue Creator) on (2024-10-07 08:07:16 UTC): Done


Make sense. we will create new PR for the same.

dirrao (Issue Creator) on (2024-10-09 13:54:12 UTC): Done.

"
2568446816,pull_request,closed,,Deprecated raw configuration view has been removed,Deprecated raw configuration view has been removed,dirrao,2024-10-06 03:59:51+00:00,['dirrao'],2024-11-28 00:16:18+00:00,2024-11-28 00:16:18+00:00,https://github.com/apache/airflow/pull/42775,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:webserver', 'Webserver related Issues'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2395290673, 'issue_id': 2568446816, 'author': 'dirrao', 'body': 'Unrelated tests are failing related to backfill.', 'created_at': datetime.datetime(2024, 10, 6, 4, 36, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395329764, 'issue_id': 2568446816, 'author': 'jscheffl', 'body': 'I am not sure whether we should ""touch"" this part, the UI and the whole views.py will be deleted prior Airflow 3.0 I assume.\r\nOtherwise if we want to make the house clean, then you might delete the whole `/configuration` Flash route', 'created_at': datetime.datetime(2024, 10, 6, 7, 26, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396217616, 'issue_id': 2568446816, 'author': 'dirrao', 'body': '> I am not sure whether we should ""touch"" this part, the UI and the whole views.py will be deleted prior Airflow 3.0 I assume.\r\n> Otherwise if we want to make the house clean, then you might delete the whole `/configuration` Flash route\r\n\r\nNot sure. \r\n\r\n@potiuk / @bbovenzi\r\nCan some one confirm the same?', 'created_at': datetime.datetime(2024, 10, 7, 8, 10, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397193126, 'issue_id': 2568446816, 'author': 'vincbeck', 'body': ""I would say dont bother, we'll remove `views.py` all together but if you want to do it, we cannot stop you :)"", 'created_at': datetime.datetime(2024, 10, 7, 15, 5, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492612574, 'issue_id': 2568446816, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 22, 0, 16, 22, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-10-06 04:36:33 UTC): Unrelated tests are failing related to backfill.

jscheffl on (2024-10-06 07:26:56 UTC): I am not sure whether we should ""touch"" this part, the UI and the whole views.py will be deleted prior Airflow 3.0 I assume.
Otherwise if we want to make the house clean, then you might delete the whole `/configuration` Flash route

dirrao (Issue Creator) on (2024-10-07 08:10:21 UTC): Not sure. 

@potiuk / @bbovenzi
Can some one confirm the same?

vincbeck on (2024-10-07 15:05:38 UTC): I would say dont bother, we'll remove `views.py` all together but if you want to do it, we cannot stop you :)

github-actions[bot] on (2024-11-22 00:16:22 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2568340697,pull_request,closed,,Fix canary build test test_cli_internal_api_background process termination,"Canary build failed for test_cli_internal_api_background 
https://github.com/apache/airflow/actions/runs/11195761491/job/31123900258#step:7:3096

Adding small fix to terminate both monitor and api pids.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-05 21:57:04+00:00,[],2024-11-23 19:54:06+00:00,2024-10-06 10:15:26+00:00,https://github.com/apache/airflow/pull/42773,"[('area:CLI', '')]",[],
2568238713,pull_request,closed,,Fix failing tests for test log handler attempt 3,"#42769 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-05 17:52:03+00:00,[],2024-11-02 13:05:34+00:00,2024-10-05 19:09:57+00:00,https://github.com/apache/airflow/pull/42772,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:celery', '')]",[],
2568187610,pull_request,closed,,fix error: AttributeError: 'bool' object has no attribute 'lower' by:…,"since I found the problem when using **MongoDB To Amazon S3 transfer operator**

Then, connection provider with MongoDB give me fix extra values

{
  ""srv"": false,
  ""ssl"": false,
  ""allow_insecure"": false
}

Which all the values string. But the part of checking if allow_insecure is to receive string and .lower()

The error looks likes:
```
File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/mongo/hooks/mongo.py"", line 139, in __init__
    self.allow_insecure = self.extras.pop(""allow_insecure"", ""false"").lower() == ""true""
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'bool' object has no attribute 'lower'
```

If there are other solutions, I am happy for the contribution

ref: https://airflow.apache.org/docs/apache-airflow-providers-amazon/stable/transfer/mongo_to_s3.html",navamongkolabacusdigital,2024-10-05 15:37:46+00:00,[],2024-11-11 08:47:14+00:00,2024-11-11 08:47:13+00:00,https://github.com/apache/airflow/pull/42771,"[('area:providers', ''), ('provider:mongo', '')]","[{'comment_id': 2395095574, 'issue_id': 2568187610, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 5, 15, 37, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395540155, 'issue_id': 2568187610, 'author': 'romsharon98', 'body': 'Your solution will work.\r\nI think better solution will be to change the connection to get `allow_insecure` as a property and not in extra and it will be with type bool and default False.', 'created_at': datetime.datetime(2024, 10, 6, 18, 42, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2451793874, 'issue_id': 2568187610, 'author': 'topherinternational', 'body': 'This problem definitely needed to be fixed, but I think this got covered by #42930/#43024.', 'created_at': datetime.datetime(2024, 11, 1, 12, 27, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467561594, 'issue_id': 2568187610, 'author': 'eladkal', 'body': 'Closing as suppressed by https://github.com/apache/airflow/issues/42930/ and https://github.com/apache/airflow/pull/43024.', 'created_at': datetime.datetime(2024, 11, 11, 8, 47, 13, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-05 15:37:50 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

romsharon98 on (2024-10-06 18:42:34 UTC): Your solution will work.
I think better solution will be to change the connection to get `allow_insecure` as a property and not in extra and it will be with type bool and default False.

topherinternational on (2024-11-01 12:27:06 UTC): This problem definitely needed to be fixed, but I think this got covered by #42930/#43024.

eladkal on (2024-11-11 08:47:13 UTC): Closing as suppressed by https://github.com/apache/airflow/issues/42930/ and https://github.com/apache/airflow/pull/43024.

"
2568039355,pull_request,closed,,fix for Running db.resetdb() (e.g. in test suite) modifies logging.root.level,"- Fixes #42432
- Added a unit test

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-10-05 13:20:06+00:00,[],2024-10-09 00:30:46+00:00,2024-10-09 00:09:27+00:00,https://github.com/apache/airflow/pull/42770,[],"[{'comment_id': 2395993937, 'issue_id': 2568039355, 'author': 'potiuk', 'body': 'Tests failing :(', 'created_at': datetime.datetime(2024, 10, 7, 6, 15, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397737954, 'issue_id': 2568039355, 'author': 'harjeevanmaan', 'body': 'What mistake was I making? 😅', 'created_at': datetime.datetime(2024, 10, 7, 19, 38, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401021446, 'issue_id': 2568039355, 'author': 'potiuk', 'body': 'Not sure. Works now :)', 'created_at': datetime.datetime(2024, 10, 9, 0, 9, 22, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-07 06:15:04 UTC): Tests failing :(

harjeevanmaan (Issue Creator) on (2024-10-07 19:38:53 UTC): What mistake was I making? 😅

potiuk on (2024-10-09 00:09:22 UTC): Not sure. Works now :)

"
2567934140,pull_request,closed,,Fix failing tests for test log handler,"Unable to push to #42762 branch, therefore attempt to fix in parallel:

The https://github.com/apache/airflow/pull/42751 removed airflow_version from k8s log handler and apparently some tests in tests_utils still use kubernetes provider and k8s test handler. Also it turned out some other tests used Celery Executor as well.

Fixed the tests and move them to K8S / Celery provider respectively.",jscheffl,2024-10-05 12:05:04+00:00,[],2024-10-05 19:10:20+00:00,2024-10-05 19:10:20+00:00,https://github.com/apache/airflow/pull/42769,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:celery', '')]","[{'comment_id': 2395161365, 'issue_id': 2567934140, 'author': 'jscheffl', 'body': 'Fixed by https://github.com/apache/airflow/pull/42772', 'created_at': datetime.datetime(2024, 10, 5, 19, 10, 20, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-10-05 19:10:20 UTC): Fixed by https://github.com/apache/airflow/pull/42772

"
2567750065,pull_request,closed,,CI providers discovery update when airflow min 2.7.0,CI providers discovery update when airflow min 2.7.0,dirrao,2024-10-05 09:08:14+00:00,[],2024-10-08 18:14:42+00:00,2024-10-08 18:14:42+00:00,https://github.com/apache/airflow/pull/42767,"[('area:dev-tools', '')]",[],
2567714932,pull_request,closed,,Drop python3.8 support core and providers,"As Python 3.8 is getting out-of support, this PR removes support from Airflow providers and code.

See Python release schedule: https://peps.python.org/pep-0569/

Continuation of PR #42742 from apache repo",jscheffl,2024-10-05 07:31:48+00:00,[],2024-10-09 17:03:49+00:00,2024-10-08 10:00:12+00:00,https://github.com/apache/airflow/pull/42766,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:logging', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:openlineage', 'AIP-53'), ('provider:cloudant', ''), ('provider:common-io', '')]","[{'comment_id': 2395429966, 'issue_id': 2567714932, 'author': 'jscheffl', 'body': 'So.. green.Now we can wait until 2024-10-14, rebase and merge...', 'created_at': datetime.datetime(2024, 10, 6, 12, 53, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395945698, 'issue_id': 2567714932, 'author': 'potiuk', 'body': '> So.. green.Now we can wait until 2024-10-14, rebase and merge...\r\n\r\nWooohooo. Let me also review more closely and look at the jobs running.\r\nI am a bit suspicious on things like that ""just working"" - I guess there is a catch somewhere :)', 'created_at': datetime.datetime(2024, 10, 7, 5, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397567116, 'issue_id': 2567714932, 'author': 'jscheffl', 'body': '> Few comments - mostly about support for Python 3.8 in 2.10 (and potentially 2.11) - I think according to our rules 2.10.3+ should still support Python 3.8 (because also we promise ""smoothest possible"" migration in patchlevel releases.\r\n> \r\n> Likely 2.11.0 should also be Python 3.8 compliant - but this is something we can discuss later, we might very well tell our users that if they want to migrate to Airflow 3 using 2.11 that they should migrate their Python version to 3.9+ if they want to move to Airflow 3 via 2.11.\r\n\r\n...but this also means that users might get an update of core but no update of providers when staying with Python 3.8 post merging? (As we are not maintaining minor versions of providers in separate branches...)', 'created_at': datetime.datetime(2024, 10, 7, 18, 5, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397769650, 'issue_id': 2567714932, 'author': 'jscheffl', 'body': '> > So.. green.Now we can wait until 2024-10-14, rebase and merge...\r\n> \r\n> Wooohooo. Let me also review more closely and look at the jobs running. I am a bit suspicious on things like that ""just working"" - I guess there is a catch somewhere :)\r\n\r\nYeah, this requires proper review - such a large change set there will be probably still some glitch be hidden... tried my best in multiple ways to look-up... hunt for the secret!!', 'created_at': datetime.datetime(2024, 10, 7, 19, 55, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397984617, 'issue_id': 2567714932, 'author': 'jscheffl', 'body': 'If CI is green... LGTM? I am going to bed and leave this for the ""late shift"" == US time zone :-D', 'created_at': datetime.datetime(2024, 10, 7, 21, 53, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398798055, 'issue_id': 2567714932, 'author': 'uranusjr', 'body': ""I don't think 2.11 needs to support 3.8. The release is a bridge to 3.0, and there’s no point upgrading to it if you intend to stay on 3.8. Conversely, if you want to upgrade to 3.0, you must upgrade Python first, so it’s reasonable to expect users to do that first before upgrading to 2.11."", 'created_at': datetime.datetime(2024, 10, 8, 4, 23, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402216674, 'issue_id': 2567714932, 'author': 'potiuk', 'body': "">  I don't think 2.11 needs to support 3.8. The release is a bridge to 3.0, and there’s no point upgrading to it if you intend to stay on 3.8. Conversely, if you want to upgrade to 3.0, you must upgrade Python first, so it’s reasonable to expect users to do that first before upgrading to 2.11.\r\n\r\nAgreed. The 2.10.* should support 3.8 but 2.11 should not. Which means that we should cherry-pick that one to the v2-test branch when we prepare for 2.11 release - in the meantime 2.10.3/4 will be released from that branch with 3.8 support, so we should not cherry-pick it **yet**."", 'created_at': datetime.datetime(2024, 10, 9, 12, 42, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402217406, 'issue_id': 2567714932, 'author': 'potiuk', 'body': 'I updated milestone to 2.11.0.', 'created_at': datetime.datetime(2024, 10, 9, 12, 42, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402849477, 'issue_id': 2567714932, 'author': 'jscheffl', 'body': '> Agreed. The 2.10.* should support 3.8 but 2.11 should not. Which means that we should cherry-pick that one to the v2-test branch when we prepare for 2.11 release - in the meantime 2.10.3/4 will be released from that branch with 3.8 support, so we should not cherry-pick it **yet**.\r\n\r\nNo ""easy"" cherry-pick as main has diverged in many details already. I started a v2-10 backport PR already in https://github.com/apache/airflow/pull/42788 and it took ~3h of my lifetime to merge and find differences.\r\n\r\nBranch was deleted but from PR/commit can be created again and made green.\r\n\r\nLet\'s discuss tomorrow... after the initial removal I\'d assume it takes another couple of hours again once we cut v2.11, so we should have an agreement on removal not to waste efforts... (again :-D)', 'created_at': datetime.datetime(2024, 10, 9, 17, 1, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402854172, 'issue_id': 2567714932, 'author': 'kaxil', 'body': 'Hopefully those changes are small, but some of these might be unavoidable I think', 'created_at': datetime.datetime(2024, 10, 9, 17, 3, 47, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-10-06 12:53:40 UTC): So.. green.Now we can wait until 2024-10-14, rebase and merge...

potiuk on (2024-10-07 05:33:00 UTC): Wooohooo. Let me also review more closely and look at the jobs running.
I am a bit suspicious on things like that ""just working"" - I guess there is a catch somewhere :)

jscheffl (Issue Creator) on (2024-10-07 18:05:37 UTC): ...but this also means that users might get an update of core but no update of providers when staying with Python 3.8 post merging? (As we are not maintaining minor versions of providers in separate branches...)

jscheffl (Issue Creator) on (2024-10-07 19:55:21 UTC): Yeah, this requires proper review - such a large change set there will be probably still some glitch be hidden... tried my best in multiple ways to look-up... hunt for the secret!!

jscheffl (Issue Creator) on (2024-10-07 21:53:24 UTC): If CI is green... LGTM? I am going to bed and leave this for the ""late shift"" == US time zone :-D

uranusjr on (2024-10-08 04:23:18 UTC): I don't think 2.11 needs to support 3.8. The release is a bridge to 3.0, and there’s no point upgrading to it if you intend to stay on 3.8. Conversely, if you want to upgrade to 3.0, you must upgrade Python first, so it’s reasonable to expect users to do that first before upgrading to 2.11.

potiuk on (2024-10-09 12:42:11 UTC): Agreed. The 2.10.* should support 3.8 but 2.11 should not. Which means that we should cherry-pick that one to the v2-test branch when we prepare for 2.11 release - in the meantime 2.10.3/4 will be released from that branch with 3.8 support, so we should not cherry-pick it **yet**.

potiuk on (2024-10-09 12:42:33 UTC): I updated milestone to 2.11.0.

jscheffl (Issue Creator) on (2024-10-09 17:01:28 UTC): No ""easy"" cherry-pick as main has diverged in many details already. I started a v2-10 backport PR already in https://github.com/apache/airflow/pull/42788 and it took ~3h of my lifetime to merge and find differences.

Branch was deleted but from PR/commit can be created again and made green.

Let's discuss tomorrow... after the initial removal I'd assume it takes another couple of hours again once we cut v2.11, so we should have an agreement on removal not to waste efforts... (again :-D)

kaxil on (2024-10-09 17:03:47 UTC): Hopefully those changes are small, but some of these might be unavoidable I think

"
2567708393,pull_request,closed,,Removed unicodecsv dependency for providers with Airflow version 2.8.0,Removed unicodecsv dependency for providers with Airflow version 2.8.0 and above,dirrao,2024-10-05 07:13:29+00:00,['dirrao'],2024-10-23 09:09:24+00:00,2024-10-07 05:08:52+00:00,https://github.com/apache/airflow/pull/42765,"[('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]",[],
2567670694,pull_request,closed,,Removed conditional check for task context logging in airflow version 2.8.0 and above,Removed conditional check for task context logging in airflow version 2.8.0 and above,dirrao,2024-10-05 05:30:09+00:00,['dirrao'],2024-10-06 08:15:38+00:00,2024-10-06 08:15:38+00:00,https://github.com/apache/airflow/pull/42764,"[('provider:google', 'Google (including GCP) related issues'), ('provider:microsoft-azure', 'Azure-related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:logging', ''), ('provider:elasticsearch', ''), ('provider:opensearch', '')]",[],
2567669773,pull_request,closed,,Add copy object functionality for wasbhook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-10-05 05:27:13+00:00,[],2024-10-15 13:42:40+00:00,2024-10-15 13:42:40+00:00,https://github.com/apache/airflow/pull/42763,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2394956908, 'issue_id': 2567669773, 'author': 'gopidesupavan', 'body': 'you may convert this to draft? as it is in WIP', 'created_at': datetime.datetime(2024, 10, 5, 7, 1, 3, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-05 07:01:03 UTC): you may convert this to draft? as it is in WIP

"
2567615217,pull_request,closed,,Fix failing log test handler tests,"The #42751 removed airflow_version from k8s log handler and apparently some tests in tests_utils still use kubernetes provider and k8s test handler. Also it turned out some other tests used Celery Executor as well.

Fixed the tests and move them to K8S / Celery provider respectively.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-05 03:00:08+00:00,[],2024-10-05 19:10:37+00:00,2024-10-05 19:10:36+00:00,https://github.com/apache/airflow/pull/42762,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', '')]","[{'comment_id': 2395090323, 'issue_id': 2567615217, 'author': 'jscheffl', 'body': 'Was unable to push additional fixes here, opened another PR https://github.com/apache/airflow/pull/42769 ... hope this is getting green... @eladkal if you can approve there as well or @potiuk if you cherry-pick this? :-D', 'created_at': datetime.datetime(2024, 10, 5, 15, 19, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395161447, 'issue_id': 2567615217, 'author': 'jscheffl', 'body': 'Fixed by https://github.com/apache/airflow/pull/42772', 'created_at': datetime.datetime(2024, 10, 5, 19, 10, 37, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-05 15:19:08 UTC): Was unable to push additional fixes here, opened another PR https://github.com/apache/airflow/pull/42769 ... hope this is getting green... @eladkal if you can approve there as well or @potiuk if you cherry-pick this? :-D

jscheffl on (2024-10-05 19:10:37 UTC): Fixed by https://github.com/apache/airflow/pull/42772

"
2567580020,pull_request,closed,,Remove dag.run() method,"This method uses Backfill internally.  Before we can remove BackfillJobRunner, we need to remove DAG.run.  But before we can remove DAG.run, we need to update some old tests that use it.  So this is the first step towards removing BackflilJobRunner.

There were some very old tests that came from airflow github issue 1225.  These appeared to test the scheduler but really they tested the backfill job runner.  Just to be cautious, I kept most of them rather than remove (which probably would have been fine since they essentially tested code that we'll be removing).  As appropriate I either changed them to run on dag.test or scheduler.  The ones dealing with ignore first depends on past will have to be added back when that functionality is implemented in new backfill.",dstandish,2024-10-05 01:15:00+00:00,['dstandish'],2024-10-10 21:39:35+00:00,2024-10-10 21:39:34+00:00,https://github.com/apache/airflow/pull/42761,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2394846575, 'issue_id': 2567580020, 'author': 'potiuk', 'body': '🧛', 'created_at': datetime.datetime(2024, 10, 5, 1, 18, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-05 01:18:15 UTC): 🧛

"
2567556410,pull_request,closed,,Add standard provider to chicken-egg-providers,"Standard provider should be added to chicken-egg-providers as it has not yet been officially released, so we need  to add it.

This can only be done via ""apache"" PR as it is needed in build-images workflow. This is needed to unblock #42252

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-05 00:22:35+00:00,[],2024-11-01 13:12:20+00:00,2024-10-07 06:24:24+00:00,https://github.com/apache/airflow/pull/42760,"[('area:dev-tools', '')]","[{'comment_id': 2394823454, 'issue_id': 2567556410, 'author': 'gopidesupavan', 'body': 'one test failing may be provider needs to be added also here prod_image_installed_providers.txt ?', 'created_at': datetime.datetime(2024, 10, 5, 0, 42, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394843843, 'issue_id': 2567556410, 'author': 'potiuk', 'body': '> one test failing may be provider needs to be added also here prod_image_installed_providers.txt ?\r\n\r\nCorrect :D', 'created_at': datetime.datetime(2024, 10, 5, 1, 10, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394956273, 'issue_id': 2567556410, 'author': 'gopidesupavan', 'body': '> What about ""edge""? This one LGTM\r\n\r\nYes amogh, edge has no dependency on CI and other providers.\r\n\r\nhttps://lists.apache.org/thread/1gshy5cjmp9wz5v8dozyh64jj3dyn5s4', 'created_at': datetime.datetime(2024, 10, 5, 6, 58, 39, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-05 00:42:03 UTC): one test failing may be provider needs to be added also here prod_image_installed_providers.txt ?

potiuk (Issue Creator) on (2024-10-05 01:10:52 UTC): Correct :D

gopidesupavan on (2024-10-05 06:58:39 UTC): Yes amogh, edge has no dependency on CI and other providers.

https://lists.apache.org/thread/1gshy5cjmp9wz5v8dozyh64jj3dyn5s4

"
2567555229,pull_request,closed,,Add standard provider to chicken-egg-providers,"Standard provider should be added to chicken-egg-providers as it has not yet been officially released, so we need  to add it.

This can only be done via ""apache"" PR as it is needed in build-images workflow. This is needed to unblock #42252

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-05 00:20:20+00:00,[],2024-10-05 00:22:02+00:00,2024-10-05 00:22:02+00:00,https://github.com/apache/airflow/pull/42759,"[('area:dev-tools', '')]","[{'comment_id': 2394813249, 'issue_id': 2567555229, 'author': 'potiuk', 'body': 'cc: @gopidesupavan', 'created_at': datetime.datetime(2024, 10, 5, 0, 21, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394813611, 'issue_id': 2567555229, 'author': 'potiuk', 'body': 'Ah ... should be in APACHE.', 'created_at': datetime.datetime(2024, 10, 5, 0, 21, 56, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-05 00:21:20 UTC): cc: @gopidesupavan

potiuk (Issue Creator) on (2024-10-05 00:21:56 UTC): Ah ... should be in APACHE.

"
2567544293,pull_request,closed,,Include Selective Check to Ping Maintainer about Legacy WWW and API Changes,"
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Closes: #42031
Include new check in selective_checks.py for checking PR labels to ping maintainers about updating legacy ui or legacy api code piece

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-10-04 23:59:41+00:00,[],2024-10-06 01:04:48+00:00,2024-10-05 01:08:19+00:00,https://github.com/apache/airflow/pull/42758,"[('area:dev-tools', '')]","[{'comment_id': 2394842813, 'issue_id': 2567544293, 'author': 'potiuk', 'body': 'I added labels.\r\n\r\n![Screenshot 2024-10-04 at 18 08 06](https://github.com/user-attachments/assets/d38432a5-76e3-4e1e-8120-df1318597d36)', 'created_at': datetime.datetime(2024, 10, 5, 1, 8, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394843111, 'issue_id': 2567544293, 'author': 'potiuk', 'body': 'BTW. @bugraoz93 -> one more small change could be to add a unit test for that -> we have a number of tests in selective checks - so maybe that case could also be unit-tested.', 'created_at': datetime.datetime(2024, 10, 5, 1, 9, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395246753, 'issue_id': 2567544293, 'author': 'bugraoz93', 'body': 'Thanks @potiuk! I missed the unit test part. :sweat_smile: I created a task to follow up from there. I will include them soon :)', 'created_at': datetime.datetime(2024, 10, 6, 1, 4, 47, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-05 01:08:44 UTC): I added labels.

![Screenshot 2024-10-04 at 18 08 06](https://github.com/user-attachments/assets/d38432a5-76e3-4e1e-8120-df1318597d36)

potiuk on (2024-10-05 01:09:22 UTC): BTW. @bugraoz93 -> one more small change could be to add a unit test for that -> we have a number of tests in selective checks - so maybe that case could also be unit-tested.

bugraoz93 (Issue Creator) on (2024-10-06 01:04:47 UTC): Thanks @potiuk! I missed the unit test part. :sweat_smile: I created a task to follow up from there. I will include them soon :)

"
2567489482,pull_request,closed,,Fix broken compat test after PR 42740 attempt 2,"The PR https://github.com/apache/airflow/pull/42740 seems to break backcompat-tests as Plugin Manager can not be correctly mock-ed again.

I was too stupid to compare versions.

related: https://github.com/apache/airflow/pull/42740",jscheffl,2024-10-04 22:27:03+00:00,[],2024-10-04 22:27:50+00:00,2024-10-04 22:27:50+00:00,https://github.com/apache/airflow/pull/42755,[],[],
2567489153,pull_request,closed,,Add documentation for the PowerBIDatasetRefresh Operator.,"This PR intends to add the documentation like Connection types, Operators for the Power BI Dataset Refresh Operator in Apache Airflow Site.
Refer to: https://airflow.apache.org/docs/apache-airflow-providers-microsoft-azure/10.5.0/_api/airflow/providers/microsoft/azure/operators/powerbi/index.html

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ambika-garg,2024-10-04 22:26:37+00:00,[],2024-10-24 19:50:00+00:00,2024-10-24 19:10:46+00:00,https://github.com/apache/airflow/pull/42754,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2394867117, 'issue_id': 2567489153, 'author': 'potiuk', 'body': 'static checks failing - there is some inconistency in the provider.yaml', 'created_at': datetime.datetime(2024, 10, 5, 2, 25, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397930242, 'issue_id': 2567489153, 'author': 'ambika-garg', 'body': ""I've resolved the static checks. Could you please review it."", 'created_at': datetime.datetime(2024, 10, 7, 21, 26, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407069479, 'issue_id': 2567489153, 'author': 'Lee-W', 'body': ""I think we'll need to resolve conflict again due to newly merged PR"", 'created_at': datetime.datetime(2024, 10, 11, 10, 1, 4, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-05 02:25:56 UTC): static checks failing - there is some inconistency in the provider.yaml

ambika-garg (Issue Creator) on (2024-10-07 21:26:56 UTC): I've resolved the static checks. Could you please review it.

Lee-W on (2024-10-11 10:01:04 UTC): I think we'll need to resolve conflict again due to newly merged PR

"
2567486305,pull_request,closed,,"Add ""tests/test_utils"" folder to the list of files triggering full tests","The TEST_UTILS CI selection has been using ""tests/utils"" as a trigger to trigger full tests, but it turned out that there is another shared test folder ""tests/test_utils"" that also should do it (i.e. trigger all tests after a shared test utilties have been updated)

Before we unify the two folder (which I guess we should) as a simple fix - just adding the folder to list of TEST_UTILS should help with avoiding breaking main as it was in case of #42750

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-04 22:22:47+00:00,[],2024-10-05 07:21:05+00:00,2024-10-05 07:21:05+00:00,https://github.com/apache/airflow/pull/42752,"[('area:dev-tools', '')]",[],
2567468366,pull_request,closed,,Remove airflow_version from k8s executor pod selector,"When there is a task running and upgrade in flight then there will be version mismatch.  So we should not include the airflow version in the selector.
",dstandish,2024-10-04 22:00:39+00:00,[],2024-10-07 16:41:29+00:00,2024-10-05 00:45:57+00:00,https://github.com/apache/airflow/pull/42751,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2567413399,pull_request,closed,,Fix broken compat test after PR 42740,"The PR #42740 seems to break backcompat-tests as Plugin Manager can not be correctly mock-ed again.

related: #42740
",jscheffl,2024-10-04 21:14:13+00:00,[],2024-10-05 06:55:18+00:00,2024-10-04 21:55:46+00:00,https://github.com/apache/airflow/pull/42750,"[('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2394955535, 'issue_id': 2567413399, 'author': 'pierrejeambrun', 'body': 'Thanks !', 'created_at': datetime.datetime(2024, 10, 5, 6, 55, 18, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-05 06:55:18 UTC): Thanks !

"
2567230389,pull_request,closed,,AIP-84 Migrate DagWarning public endpoint to FastAPI,closes #42748 ,rawwar,2024-10-04 19:54:35+00:00,[],2024-11-04 14:25:36+00:00,2024-11-04 14:25:36+00:00,https://github.com/apache/airflow/pull/42749,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2567051978,pull_request,closed,,Clean up auth manager model,"Many things do no quite make sense today in auth managers:

- `is_authorized_dag(""GET"")` means ""is the user authorized to access all DAGs"". After discussion with Ash [here](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1728054131890969), I realized it should mean ""is the user authorized to list DAGs"". We should not care whether the user has access to all DAGs.

- `get_permitted_dag_ids` takes a list of methods as parameter. Example: `auth_manager.get_permitted_dag_ids(methods=[""GET"", ""PUT""])` would return the list of DAGs the user can read or edit. We need either one of the other but not both.

This PR creates breaking change in the auth manage interface.

This is a draft PR for now to confirm the direction, if agreed, I'll create a news fragment, update tests and handle the backward compatibility between core Airflow and providers.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-04 18:34:53+00:00,[],2024-12-30 00:16:17+00:00,2024-12-30 00:16:17+00:00,https://github.com/apache/airflow/pull/42747,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2560459445, 'issue_id': 2567051978, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 24, 0, 15, 34, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-24 00:15:34 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2566913414,pull_request,closed,,Added SailPoint to the list of companies using apache airflow,Added SailPoint to INTHEWILD.md,andrew-stein-sp,2024-10-04 17:36:25+00:00,[],2024-10-09 16:39:42+00:00,2024-10-04 20:55:19+00:00,https://github.com/apache/airflow/pull/42746,[],[],
2566735177,pull_request,closed,,Fix main Branch Test Failures,"
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Fix main failures and adjust test names and file names according to changes in dataset -> asset.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-10-04 16:23:51+00:00,[],2024-10-06 23:31:35+00:00,2024-10-04 18:42:43+00:00,https://github.com/apache/airflow/pull/42744,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2394077016, 'issue_id': 2566735177, 'author': 'bugraoz93', 'body': ""Doesn't it depend on whether these changes have already been backported? #42579"", 'created_at': datetime.datetime(2024, 10, 4, 16, 35, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394084712, 'issue_id': 2566735177, 'author': 'bugraoz93', 'body': 'I have seen it neither in `v2-10-test` nor `2.10.2`. So I assume it should be good if I am not missing somethings :slightly_smiling_face:', 'created_at': datetime.datetime(2024, 10, 4, 16, 39, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394145385, 'issue_id': 2566735177, 'author': 'jscheffl', 'body': '> I have seen it neither in `v2-10-test` nor `2.10.2`. So I assume it should be good if I am not missing somethings 🙂\r\n\r\nThe renaming Dataset->Asset is a breaking change that is only for Airflow 3 line. All providers (and I assume also pytests of providers) need to be compatible with Airflow 2 and 3 line.\r\n\r\n@uranusjr @Lee-W Do you have any idea/guidance? If FAB needs to support ""both worlds"" would pytests then need to have a ""skipif"" and carry both back-end implementations?', 'created_at': datetime.datetime(2024, 10, 4, 17, 2, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394269656, 'issue_id': 2566735177, 'author': 'vincbeck', 'body': 'These tests are already skipped if Airflow < 3', 'created_at': datetime.datetime(2024, 10, 4, 17, 47, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395642963, 'issue_id': 2566735177, 'author': 'Lee-W', 'body': ""Thanks @bugraoz93 !  Missed this one 🤦\u200d♂️\r\n\r\n@jscheffl I think we already have the compat code in FAB. the permission side should be fine, but asset endpoints won't exist in <3.0 so they should be skipped for <3.0"", 'created_at': datetime.datetime(2024, 10, 6, 23, 31, 34, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-10-04 16:35:34 UTC): Doesn't it depend on whether these changes have already been backported? #42579

bugraoz93 (Issue Creator) on (2024-10-04 16:39:16 UTC): I have seen it neither in `v2-10-test` nor `2.10.2`. So I assume it should be good if I am not missing somethings :slightly_smiling_face:

jscheffl on (2024-10-04 17:02:04 UTC): The renaming Dataset->Asset is a breaking change that is only for Airflow 3 line. All providers (and I assume also pytests of providers) need to be compatible with Airflow 2 and 3 line.

@uranusjr @Lee-W Do you have any idea/guidance? If FAB needs to support ""both worlds"" would pytests then need to have a ""skipif"" and carry both back-end implementations?

vincbeck on (2024-10-04 17:47:55 UTC): These tests are already skipped if Airflow < 3

Lee-W on (2024-10-06 23:31:34 UTC): Thanks @bugraoz93 !  Missed this one 🤦‍♂️

@jscheffl I think we already have the compat code in FAB. the permission side should be fine, but asset endpoints won't exist in <3.0 so they should be skipped for <3.0

"
2566680673,pull_request,closed,,Drop python3.8 support core and providers,"As Python 3.8 is getting out-of support, this PR removes support from Airflow providers and code.

See Python release schedule: https://peps.python.org/pep-0569/

Note: As I got a head-ache thinking about how to un-bundle the removal w/o 4-5PRs this is a combination with to commits from PR #42738 and #42739 - Maybe both is needed to make CI in Airflow v2-10 branch happy anyway.",jscheffl,2024-10-04 15:49:57+00:00,[],2024-10-05 07:32:11+00:00,2024-10-05 07:32:10+00:00,https://github.com/apache/airflow/pull/42742,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:logging', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:openlineage', 'AIP-53'), ('provider:cloudant', ''), ('provider:common-io', '')]","[{'comment_id': 2394820188, 'issue_id': 2566680673, 'author': 'potiuk', 'body': '> Note: As I got a head-ache thinking about how to un-bundle the removal w/o 4-5PRs this is a combination with to commits from PR https://github.com/apache/airflow/pull/42738 and https://github.com/apache/airflow/pull/42739 - Maybe both is needed to make CI in Airflow v2-10 branch happy anyway.\r\n\r\nAh yeah. This is indeed needed to be done in a single PR', 'created_at': datetime.datetime(2024, 10, 5, 0, 34, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394823719, 'issue_id': 2566680673, 'author': 'potiuk', 'body': 'Additionally ... This one should be done as a PR from `apache` repository - not from your fork. The reason is that ""Build images"" workflow uses ""pull_request_target"" workflow type and for that one - we need to make sure all the build scripts are taken from ""target"" branch (i.e. ""main"" branch in this case) - because otherwise anyone who modifies the build scripts in the PR will be able to run their code in ""pull_request_target"" workflow - with access to our secrets and write permissions.\r\n\r\nSo you will need to close that PR and re-open it by pushing your branch to the ""apache"" repository and open PR from there.  When you will do it, the ""pull_request_target"" workflow will not be used at all - instead images will be built in the ""Tests"" workflow - and pushed to registry. This is because only PRS from the ""main"" repository can have write permissions (in this case ""packages:write""). By default ""pull_request"" workflows have no ""write"" permissions and they would not be able to push the images to our registry - that\'s why for the ""Fork"" pull requests we need to build and push images in ""pull_request_target"" workflow - because it can have write permissions - but we have to make sure that this workflow uses only ""approved"" workflows and scripts from the ""main"" branch - rather than those that the PR is modifying.\r\n\r\nWhat happens in ""pull_request_target"" is that we check-out the PR from the fork, and before we run any scripts in our workflows, we override workflows, actions and scripts/ci folder with the version from `main` - this way the ""PR modified"" code cannot modify workflows and scripts used during the ""pull_request_target"".', 'created_at': datetime.datetime(2024, 10, 5, 0, 42, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394965279, 'issue_id': 2566680673, 'author': 'jscheffl', 'body': '> So you will need to close that PR and re-open it by pushing your branch to the ""apache"" repository\r\n\r\nOh, wow. New learning. Did not know that with my committer power I actually could do...\r\n\r\nContinued in #42766', 'created_at': datetime.datetime(2024, 10, 5, 7, 32, 10, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-05 00:34:45 UTC): Ah yeah. This is indeed needed to be done in a single PR

potiuk on (2024-10-05 00:42:35 UTC): Additionally ... This one should be done as a PR from `apache` repository - not from your fork. The reason is that ""Build images"" workflow uses ""pull_request_target"" workflow type and for that one - we need to make sure all the build scripts are taken from ""target"" branch (i.e. ""main"" branch in this case) - because otherwise anyone who modifies the build scripts in the PR will be able to run their code in ""pull_request_target"" workflow - with access to our secrets and write permissions.

So you will need to close that PR and re-open it by pushing your branch to the ""apache"" repository and open PR from there.  When you will do it, the ""pull_request_target"" workflow will not be used at all - instead images will be built in the ""Tests"" workflow - and pushed to registry. This is because only PRS from the ""main"" repository can have write permissions (in this case ""packages:write""). By default ""pull_request"" workflows have no ""write"" permissions and they would not be able to push the images to our registry - that's why for the ""Fork"" pull requests we need to build and push images in ""pull_request_target"" workflow - because it can have write permissions - but we have to make sure that this workflow uses only ""approved"" workflows and scripts from the ""main"" branch - rather than those that the PR is modifying.

What happens in ""pull_request_target"" is that we check-out the PR from the fork, and before we run any scripts in our workflows, we override workflows, actions and scripts/ci folder with the version from `main` - this way the ""PR modified"" code cannot modify workflows and scripts used during the ""pull_request_target"".

jscheffl (Issue Creator) on (2024-10-05 07:32:10 UTC): Oh, wow. New learning. Did not know that with my committer power I actually could do...

Continued in #42766

"
2566628318,pull_request,closed,,Update celery_executor.rst,"Fix typo.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",tampal,2024-10-04 15:20:32+00:00,[],2024-10-05 08:46:13+00:00,2024-10-05 08:46:09+00:00,https://github.com/apache/airflow/pull/42741,"[('area:providers', ''), ('kind:documentation', ''), ('provider:celery', '')]","[{'comment_id': 2393948073, 'issue_id': 2566628318, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 4, 15, 20, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394984362, 'issue_id': 2566628318, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 5, 8, 46, 11, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-04 15:20:37 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-05 08:46:11 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2566514543,pull_request,closed,,API-84 Add fastapi subapps to plugin system,"Closes: https://github.com/apache/airflow/issues/42696

Add support for FastAPI plugins to extend the capabilities of the new Rest API.

<img width=""1499"" alt=""Screenshot 2024-10-04 at 16 17 12"" src=""https://github.com/user-attachments/assets/62624828-2b9d-4a72-8afa-1d96ef89589f"">
",pierrejeambrun,2024-10-04 14:24:19+00:00,['pierrejeambrun'],2024-10-04 21:02:55+00:00,2024-10-04 19:12:51+00:00,https://github.com/apache/airflow/pull/42740,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:plugins', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2394596052, 'issue_id': 2566514543, 'author': 'jscheffl', 'body': 'Ups, we are not very lucky with FAB and parallel breaking changes on core modules - another regression as of changes in FAB break the compat tests on main :-( \r\nhttps://github.com/apache/airflow/actions/runs/11185831901/job/31099830900', 'created_at': datetime.datetime(2024, 10, 4, 21, 2, 54, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-04 21:02:54 UTC): Ups, we are not very lucky with FAB and parallel breaking changes on core modules - another regression as of changes in FAB break the compat tests on main :-( 
https://github.com/apache/airflow/actions/runs/11185831901/job/31099830900

"
2566450765,pull_request,closed,,Drop Python 3.8 support in core,"As Python 3.8 is getting out-of support, this PR removes support from Airflow providers.

See Python release schedule: https://peps.python.org/pep-0569/

Note: This PR is core-only. Providers are in #42738",jscheffl,2024-10-04 13:56:58+00:00,[],2024-10-05 07:28:43+00:00,2024-10-05 07:28:43+00:00,https://github.com/apache/airflow/pull/42739,"[('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:logging', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2394802313, 'issue_id': 2566450765, 'author': 'potiuk', 'body': 'As discussed in #42742 - you need to implement changes in provider together because ""default"" version of image (lowest supported Python version) is built in most PRs and used to run tests.', 'created_at': datetime.datetime(2024, 10, 5, 0, 1, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394964405, 'issue_id': 2566450765, 'author': 'jscheffl', 'body': 'Close to proceed with #42742', 'created_at': datetime.datetime(2024, 10, 5, 7, 28, 43, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-05 00:01:32 UTC): As discussed in #42742 - you need to implement changes in provider together because ""default"" version of image (lowest supported Python version) is built in most PRs and used to run tests.

jscheffl (Issue Creator) on (2024-10-05 07:28:43 UTC): Close to proceed with #42742

"
2566409845,pull_request,closed,,Drop Python 3.8 support in provider packages,"As Python 3.8 is getting out-of support, this PR removes support from Airflow providers.

See Python release schedule: https://peps.python.org/pep-0569/

Note: This PR is provider-only.",jscheffl,2024-10-04 13:41:14+00:00,[],2024-10-05 07:28:31+00:00,2024-10-05 07:28:31+00:00,https://github.com/apache/airflow/pull/42738,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:openlineage', 'AIP-53'), ('provider:cloudant', ''), ('provider:common-io', '')]","[{'comment_id': 2394801132, 'issue_id': 2566409845, 'author': 'potiuk', 'body': 'This is not a good idea. We have to remove Python 3.8 and move to Python 3.9 for the whole repo. The thing is that for tests in most PRs CI image is only built for ""default"" Python version and tests are run only for that version (to save on build time). This means that you won\'t be able to install providers for tests if you only bump minimum version of providers, without bumping the default to 3.9 because tests will attempt to run but image will not be available.', 'created_at': datetime.datetime(2024, 10, 4, 23, 59, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394964337, 'issue_id': 2566409845, 'author': 'jscheffl', 'body': 'Close in favor of progressing in #42742', 'created_at': datetime.datetime(2024, 10, 5, 7, 28, 27, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-04 23:59:47 UTC): This is not a good idea. We have to remove Python 3.8 and move to Python 3.9 for the whole repo. The thing is that for tests in most PRs CI image is only built for ""default"" Python version and tests are run only for that version (to save on build time). This means that you won't be able to install providers for tests if you only bump minimum version of providers, without bumping the default to 3.9 because tests will attempt to run but image will not be available.

jscheffl (Issue Creator) on (2024-10-05 07:28:27 UTC): Close in favor of progressing in #42742

"
2566321976,pull_request,closed,,Add ability to provide proxy for dbt Cloud connection,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Adding the ability to define proxy settings when connecting to dbt Cloud. This can be useful for people setting up IP restrictions on dbt Cloud, allowing only some IPs to connect.

This is my first contribution to Airflow, so feel free to let me know if I need to do anything else.

I update the code for the hooks and added some documentation.

I didn't add tests as I am not too sure of how I could do it in that case, but I am happy to do so with a bit of pointers/guidance.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",b-per,2024-10-04 12:59:33+00:00,[],2024-10-08 18:31:29+00:00,2024-10-08 18:31:25+00:00,https://github.com/apache/airflow/pull/42737,"[('area:providers', ''), ('kind:documentation', ''), ('provider:dbt-cloud', '')]","[{'comment_id': 2393654355, 'issue_id': 2566321976, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 4, 12, 59, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394799649, 'issue_id': 2566321976, 'author': 'potiuk', 'body': 'Needs unit tests.', 'created_at': datetime.datetime(2024, 10, 4, 23, 56, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395097755, 'issue_id': 2566321976, 'author': 'b-per', 'body': ""Happy to add some, but I am not able run the existing ones. Hence why I was wondering if there was any pointer or guidance.\r\n\r\nIf I do a `pytest tests/providers/dbt/cloud/` in my hatch env I get a `ModuleNotFoundError: No module named 'sqlalchemy'` but `sqlalchemy` is indeed installed"", 'created_at': datetime.datetime(2024, 10, 5, 15, 45, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397283709, 'issue_id': 2566321976, 'author': 'b-per', 'body': 'I actually managed to run the tests with `breeze testing tests --test-type ""Providers[dbt.cloud]""`.\r\n\r\nI have updated them so that they pass again and I have added an extra test with the proxy.\r\n\r\nLet me know if instead of creating a new test you prefer if I update all the `pytest.mark.parametrize` to include the connection with a proxy.\r\n\r\nMy rationale for adding a new test for the proxy rather than as a parameter for all tests is that most people using the providers won\'t need the proxy.', 'created_at': datetime.datetime(2024, 10, 7, 15, 42, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400546420, 'issue_id': 2566321976, 'author': 'potiuk', 'body': '> If I do a pytest tests/providers/dbt/cloud/ in my hatch env I get a ModuleNotFoundError: No module named \'sqlalchemy\' but sqlalchemy is indeed installed\r\n\r\nBTW. Re venv - you should be able to run the test in venv created with `pip install -e "".[dbt.cloud,devel-tests]"" - that should install all what is needed to run the tests.', 'created_at': datetime.datetime(2024, 10, 8, 18, 28, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400551022, 'issue_id': 2566321976, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 8, 18, 31, 28, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-04 12:59:37 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-04 23:56:13 UTC): Needs unit tests.

b-per (Issue Creator) on (2024-10-05 15:45:46 UTC): Happy to add some, but I am not able run the existing ones. Hence why I was wondering if there was any pointer or guidance.

If I do a `pytest tests/providers/dbt/cloud/` in my hatch env I get a `ModuleNotFoundError: No module named 'sqlalchemy'` but `sqlalchemy` is indeed installed

b-per (Issue Creator) on (2024-10-07 15:42:46 UTC): I actually managed to run the tests with `breeze testing tests --test-type ""Providers[dbt.cloud]""`.

I have updated them so that they pass again and I have added an extra test with the proxy.

Let me know if instead of creating a new test you prefer if I update all the `pytest.mark.parametrize` to include the connection with a proxy.

My rationale for adding a new test for the proxy rather than as a parameter for all tests is that most people using the providers won't need the proxy.

potiuk on (2024-10-08 18:28:59 UTC): BTW. Re venv - you should be able to run the test in venv created with `pip install -e "".[dbt.cloud,devel-tests]"" - that should install all what is needed to run the tests.

boring-cyborg[bot] on (2024-10-08 18:31:28 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2566256821,pull_request,closed,,feat(providers/common/sql): add warning to connection setter,"## Why
Users might not expect a setter that does nothing.

## What
Add a warning if user is trying to assign a value different from the _connection

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-04 12:26:31+00:00,[],2024-10-04 23:53:50+00:00,2024-10-04 23:53:50+00:00,https://github.com/apache/airflow/pull/42736,"[('area:providers', ''), ('provider:common-sql', '')]",[],
2566232211,pull_request,closed,,fix(assets/managers): fix error handling file loc when asset alias resolved into new assets,"## Why
Detailed in https://github.com/apache/airflow/issues/42704. values should be list of dict instead of dict

## What
Pass a list of file locations as a dictionary for DAG priority parsing request when asset aliases are resolved into new assets.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-04 12:14:24+00:00,['Lee-W'],2024-10-09 06:48:11+00:00,2024-10-08 04:16:27+00:00,https://github.com/apache/airflow/pull/42735,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:datasets', 'Issues related to the datasets feature'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]",[],
2566222321,pull_request,closed,, fix(datasets/managers): fix error handling file loc when dataset alias resolved into new datasets,"## Why
Detailed in https://github.com/apache/airflow/issues/42704. values should be list of dict instead of dict

## What
Pass a list of file locations as a dictionary for DAG priority parsing request when dataset aliases are resolved into new datasets.


Closes: #42704 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-04 12:09:11+00:00,['Lee-W'],2024-10-09 06:48:26+00:00,2024-10-08 04:25:17+00:00,https://github.com/apache/airflow/pull/42733,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:datasets', 'Issues related to the datasets feature')]","[{'comment_id': 2398206771, 'issue_id': 2566222321, 'author': 'uranusjr', 'body': 'Changing the milestone since this one is the backport PR.', 'created_at': datetime.datetime(2024, 10, 7, 23, 53, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398317770, 'issue_id': 2566222321, 'author': 'Lee-W', 'body': 'removing airflow-3-candidate. this one is only for v2-10-test. airflow-3 is another pr', 'created_at': datetime.datetime(2024, 10, 8, 0, 43, 49, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-10-07 23:53:58 UTC): Changing the milestone since this one is the backport PR.

Lee-W (Issue Creator) on (2024-10-08 00:43:49 UTC): removing airflow-3-candidate. this one is only for v2-10-test. airflow-3 is another pr

"
2566217684,pull_request,closed,,fix(datasets/managers): fix error handling fileloc when datasetalias resolved into new datasets,"## Why
Detailed in https://github.com/apache/airflow/issues/42704. values should be list of dict instead of dict

## What
Pass a list of file locations as a dictionary for DAG priority parsing request when dataset aliases are resolved into new datasets.


Closes: #42704 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-04 12:06:48+00:00,[],2024-10-04 12:07:45+00:00,2024-10-04 12:07:45+00:00,https://github.com/apache/airflow/pull/42731,[],[],
2565930622,pull_request,closed,,Add sequence insert support to OracleHook,"If Oracle had a sequence column, it could not be entered with existing logic. We received an additional sequence column and sequence name in the existing function so that you could enter it

Closes: https://github.com/apache/airflow/issues/42494",Lee2532,2024-10-04 09:35:58+00:00,[],2024-10-06 05:34:53+00:00,2024-10-06 05:34:27+00:00,https://github.com/apache/airflow/pull/42728,"[('area:providers', ''), ('provider:oracle', '')]","[{'comment_id': 2395301569, 'issue_id': 2565930622, 'author': 'Lee2532', 'body': 'I will create PR again due to my mistake', 'created_at': datetime.datetime(2024, 10, 6, 5, 34, 52, tzinfo=datetime.timezone.utc)}]","Lee2532 (Issue Creator) on (2024-10-06 05:34:52 UTC): I will create PR again due to my mistake

"
2565926930,pull_request,closed,,Typo correction in 07_local_virtualenv.rst,"Corrected typo from ""hat"" to ""hatch"" in the documentation file of 07_local_virtualenv.rst",nitesh-dubey-samsung,2024-10-04 09:34:13+00:00,[],2024-10-04 10:12:46+00:00,2024-10-04 10:11:32+00:00,https://github.com/apache/airflow/pull/42727,"[('area:dev-tools', '')]","[{'comment_id': 2393279493, 'issue_id': 2565926930, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 4, 9, 34, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393349500, 'issue_id': 2565926930, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 4, 10, 11, 35, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-04 09:34:17 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-04 10:11:35 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2565754824,pull_request,closed,,Missing Error Handling for Docker Swarm,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This pull request resolves the “Missing Error Handling for Docker Swarm Requirements” issue. It adds error handling mechanisms to various methods to improve the robustness and stability of the code when dealing with Docker Swarm and Kubernetes operations. The lack of error handling previously led to unhandled exceptions and potential system crashes, which this update aims to prevent.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamvk03,2024-10-04 08:12:07+00:00,[],2024-12-02 00:17:18+00:00,2024-12-02 00:17:18+00:00,https://github.com/apache/airflow/pull/42726,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2393105983, 'issue_id': 2565754824, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 4, 8, 12, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393149951, 'issue_id': 2565754824, 'author': 'shubhamvk03', 'body': '@apache Could you please review this PR when you get a chance? Thanks!', 'created_at': datetime.datetime(2024, 10, 4, 8, 35, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393150779, 'issue_id': 2565754824, 'author': 'shubhamvk03', 'body': '@apache Could you please review this PR when you get a chance? Thanks!', 'created_at': datetime.datetime(2024, 10, 4, 8, 35, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393151486, 'issue_id': 2565754824, 'author': 'shubhamvk03', 'body': '@apache/airflow\r\n Could you please review this PR when you get a chance? Thanks!', 'created_at': datetime.datetime(2024, 10, 4, 8, 35, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408725445, 'issue_id': 2565754824, 'author': 'potiuk', 'body': 'Could you please rebase with conflict resolving and add unit test when you have time ?', 'created_at': datetime.datetime(2024, 10, 12, 22, 55, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2502320955, 'issue_id': 2565754824, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 27, 0, 16, 12, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-04 08:12:11 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

shubhamvk03 (Issue Creator) on (2024-10-04 08:35:05 UTC): @apache Could you please review this PR when you get a chance? Thanks!

shubhamvk03 (Issue Creator) on (2024-10-04 08:35:31 UTC): @apache Could you please review this PR when you get a chance? Thanks!

shubhamvk03 (Issue Creator) on (2024-10-04 08:35:51 UTC): @apache/airflow
 Could you please review this PR when you get a chance? Thanks!

potiuk on (2024-10-12 22:55:04 UTC): Could you please rebase with conflict resolving and add unit test when you have time ?

github-actions[bot] on (2024-11-27 00:16:12 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2565460512,pull_request,closed,,AIP-84 Migrate GET Dag Run endpoint to FastAPI,"related to: #42701 

",rawwar,2024-10-04 05:10:17+00:00,[],2024-10-10 08:03:45+00:00,2024-10-10 08:03:45+00:00,https://github.com/apache/airflow/pull/42725,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2400526690, 'issue_id': 2565460512, 'author': 'rawwar', 'body': '@pierrejeambrun , @bbovenzi , Can. you please add ""legacy api"" label to this PR', 'created_at': datetime.datetime(2024, 10, 8, 18, 17, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402763463, 'issue_id': 2565460512, 'author': 'rawwar', 'body': ""> Let me know when you added the 404 tests. Looking good overall, minor suggestion.\r\n\r\nI've added a test for 404."", 'created_at': datetime.datetime(2024, 10, 9, 16, 17, 40, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-10-08 18:17:56 UTC): @pierrejeambrun , @bbovenzi , Can. you please add ""legacy api"" label to this PR

rawwar (Issue Creator) on (2024-10-09 16:17:40 UTC): I've added a test for 404.

"
2565347002,pull_request,closed,,Do Not Merge,Testing mypy tests with a dummy change,r-richmond,2024-10-04 03:17:50+00:00,[],2024-10-04 03:32:06+00:00,2024-10-04 03:32:04+00:00,https://github.com/apache/airflow/pull/42724,[],[],
2565058216,pull_request,closed,,feat: Add handling for stuck Jenkins jobs in queue with enhanced logging and test coverage,"- Added method `extract_queue_info` to fetch detailed information of all jobs in Jenkins queue.
- It extracts task, stuck, why, blocked and build info from the Jenkins queue.
- Enhanced logging to detect and warn if a job is stuck in the queue.
- Included a verbose option to log detailed job information.
- Added a new unit test `test_poll_job_in_queue_stuck_job` to validate the behavior when a job is stuck in the Jenkins queue.
- The TODO was: Use get_queue_info once it will be available in python-jenkins (v > 0.4.15)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-10-03 21:49:23+00:00,[],2024-12-16 00:17:31+00:00,2024-12-16 00:17:31+00:00,https://github.com/apache/airflow/pull/42722,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:jenkins', '')]","[{'comment_id': 2392645612, 'issue_id': 2565058216, 'author': 'potiuk', 'body': 'The tests are failing', 'created_at': datetime.datetime(2024, 10, 4, 2, 0, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393657766, 'issue_id': 2565058216, 'author': 'harjeevanmaan', 'body': '@potiuk Working on it!', 'created_at': datetime.datetime(2024, 10, 4, 13, 1, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2439656149, 'issue_id': 2565058216, 'author': 'eladkal', 'body': '@harjeevanmaan can you rebase and resolve conflicts?', 'created_at': datetime.datetime(2024, 10, 26, 17, 1, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533326111, 'issue_id': 2565058216, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 11, 0, 16, 44, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-04 02:00:43 UTC): The tests are failing

harjeevanmaan (Issue Creator) on (2024-10-04 13:01:27 UTC): @potiuk Working on it!

eladkal on (2024-10-26 17:01:13 UTC): @harjeevanmaan can you rebase and resolve conflicts?

github-actions[bot] on (2024-12-11 00:16:44 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2565050595,pull_request,closed,,Improve startup of K8S tests,"Loop api request until dag response receives 200, max attempts 10.

closes: #42718 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-03 21:43:18+00:00,[],2024-11-02 13:05:36+00:00,2024-10-04 01:31:28+00:00,https://github.com/apache/airflow/pull/42721,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2564767419,pull_request,closed,,Fixes: SnowflakeSqlApiOperator not resolving parameters in SQL,"- Snowflake does not currently support variable binding in multi-statement SQL requests.

- Added warning for multi-statement query bindings in Snowflake hook 
- Test: added unit test for multi-statement bindings warning

Related: #42033

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-10-03 18:45:32+00:00,[],2024-10-04 12:59:06+00:00,2024-10-04 01:33:48+00:00,https://github.com/apache/airflow/pull/42719,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]","[{'comment_id': 2392622636, 'issue_id': 2564767419, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 10, 4, 1, 33, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393653404, 'issue_id': 2564767419, 'author': 'harjeevanmaan', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 10, 4, 12, 59, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-04 01:33:58 UTC): Nice!

harjeevanmaan (Issue Creator) on (2024-10-04 12:59:05 UTC): Thanks!

"
2564392324,pull_request,closed,,Add ability to switch between table and card views for listing items,"Add a card list component to oru shared table component to allow toggling between a regular table view or a card list.

<img width=""1330"" alt=""Screenshot 2024-10-03 at 5 44 44 PM"" src=""https://github.com/user-attachments/assets/375ca2c2-d334-41ed-b109-199bb975f007"">
<img width=""1326"" alt=""Screenshot 2024-10-03 at 5 44 50 PM"" src=""https://github.com/user-attachments/assets/ea18b25f-4dd0-45c8-92c2-d333753ec033"">

Closes #42698 and #42734


Also, added loading states:
<img width=""1195"" alt=""Screenshot 2024-10-04 at 11 10 50 AM"" src=""https://github.com/user-attachments/assets/ca25c22a-614c-4549-a64e-95a1f50c37e8"">
<img width=""1199"" alt=""Screenshot 2024-10-04 at 11 10 57 AM"" src=""https://github.com/user-attachments/assets/4c85239d-d477-4c46-a0ae-3663de5ea0e0"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-03 15:47:06+00:00,[],2024-10-08 10:08:15+00:00,2024-10-08 10:08:13+00:00,https://github.com/apache/airflow/pull/42711,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2393852629, 'issue_id': 2564392324, 'author': 'jscheffl', 'body': 'Oh nooo - all application UIs who call themself modern introduce card layouts... and I never understood what the benefit of this would be especially if you don\'t have thumbnails (e.g. like an image gallery) - So the new UI is now on the same level? Do we really ""need"" a card layout? I would have imagined we have more basic critical features to be added first :-D', 'created_at': datetime.datetime(2024, 10, 4, 14, 31, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394838953, 'issue_id': 2564392324, 'author': 'potiuk', 'body': ""> and I never understood what the benefit of this would be especially if you don't have thumbnails (e.g. like an image gallery) \r\n\r\nHow about ... Peoople love it and feel they are using something modern? That's a very good reason. 😛"", 'created_at': datetime.datetime(2024, 10, 5, 1, 0, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394967284, 'issue_id': 2564392324, 'author': 'jscheffl', 'body': ""> > and I never understood what the benefit of this would be especially if you don't have thumbnails (e.g. like an image gallery)\r\n> \r\n> How about ... Peoople love it and feel they are using something modern? That's a very good reason. 😛\r\n\r\nYeah that might be :-D Welcome CardLayout! (I hope it is of any use :-D besides feeling modern)"", 'created_at': datetime.datetime(2024, 10, 5, 7, 39, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396370836, 'issue_id': 2564392324, 'author': 'bbovenzi', 'body': ""> > > and I never understood what the benefit of this would be especially if you don't have thumbnails (e.g. like an image gallery)\r\n> > \r\n> > \r\n> > How about ... Peoople love it and feel they are using something modern? That's a very good reason. 😛\r\n> \r\n> Yeah that might be :-D Welcome CardLayout! (I hope it is of any use :-D besides feeling modern)\r\n\r\nThere will be quite a lot of tables in the Airflow UI. I consider this foundational UI work to make a good component for us to reuse everywhere. For complex objects, a customize card view can display all the information better than having to horizontally scroll for a dozen+ columns.\r\n\r\nWhile we have a lot of API work to do. I wanted to flesh out the UI more too, to test out all our styling rules and give other contributors more examples to refer to."", 'created_at': datetime.datetime(2024, 10, 7, 9, 16, 2, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-04 14:31:27 UTC): Oh nooo - all application UIs who call themself modern introduce card layouts... and I never understood what the benefit of this would be especially if you don't have thumbnails (e.g. like an image gallery) - So the new UI is now on the same level? Do we really ""need"" a card layout? I would have imagined we have more basic critical features to be added first :-D

potiuk on (2024-10-05 01:00:00 UTC): How about ... Peoople love it and feel they are using something modern? That's a very good reason. 😛

jscheffl on (2024-10-05 07:39:47 UTC): Yeah that might be :-D Welcome CardLayout! (I hope it is of any use :-D besides feeling modern)

bbovenzi (Issue Creator) on (2024-10-07 09:16:02 UTC): There will be quite a lot of tables in the Airflow UI. I consider this foundational UI work to make a good component for us to reuse everywhere. For complex objects, a customize card view can display all the information better than having to horizontally scroll for a dozen+ columns.

While we have a lot of API work to do. I wanted to flesh out the UI more too, to test out all our styling rules and give other contributors more examples to refer to.

"
2564129525,pull_request,closed,,Mention in simple auth manager doc how to read/update passwords directly form file,"

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-03 13:52:03+00:00,[],2024-11-06 20:16:56+00:00,2024-10-03 17:37:43+00:00,https://github.com/apache/airflow/pull/42710,"[('kind:documentation', '')]",[],
2564114650,pull_request,closed,,"fix(shell_params): prevent generating `apache-airflow[,celery]` when there is no other extra items","I encounter the following error with the command `breeze start-airflow --executor CeleryExecutor   --use-airflow-version 2.10.0`, so I added one condition to check if the `current_extras` is empty string, if yes, directly add celery into the airflow_extras instead of appending it to one new list.

Error Message:
```bash
Running command: /usr/local/bin/uv pip install --python /usr/local/bin/python 'apache-airflow[,celery]==2.10.0' --constraint https://raw.githubusercontent.com/apache/airflow/constraints-2.10.0/constraints-source-providers-3.8.txt
error: Failed to parse: `apache-airflow[,celery]==2.10.0`
  Caused by: Expected either alphanumerical character (starting the extra name) or `]` (ending the extras section), found `,`
apache-airflow[,celery]==2.10.0
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",josix,2024-10-03 13:45:46+00:00,[],2024-10-03 17:36:21+00:00,2024-10-03 17:36:21+00:00,https://github.com/apache/airflow/pull/42709,"[('area:dev-tools', '')]","[{'comment_id': 2391964194, 'issue_id': 2564114650, 'author': 'potiuk', 'body': 'nice!', 'created_at': datetime.datetime(2024, 10, 3, 17, 35, 55, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-03 17:35:55 UTC): nice!

"
2563990921,pull_request,closed,,Update tensorflow image uris for VertexAI system tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have updated tensorflow image uris for VertexAI system tests.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-10-03 12:53:34+00:00,[],2024-10-03 19:49:46+00:00,2024-10-03 19:49:46+00:00,https://github.com/apache/airflow/pull/42707,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2563946525,pull_request,closed,,FIX: Only pass connection to sqlalchemy engine in JdbcHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #42664
related: #42664

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

As mentioned in issue [42644](https://github.com/apache/airflow/issues/42664), the connection should only be passed to create the sqlalchemy engine for the JdbcHook, and not in a generic way in the DbApiHook, so that mixed usage of sqlalchemy engine and database connections is still possible (e.g. odbc with pymssql for example).

closes: #42664

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).",dabla,2024-10-03 12:35:34+00:00,[],2024-10-07 15:30:27+00:00,2024-10-07 15:30:27+00:00,https://github.com/apache/airflow/pull/42705,"[('area:providers', ''), ('provider:common-sql', ''), ('provider:jdbc', '')]",[],
2563823307,pull_request,closed,,Add 'retry_if_resource_not_ready' logic for DataprocCreateClusterOperator and DataprocCreateBatchOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have added a logic for retrying a cluster creation request in case when Dataproc returns an error with `The resource 'projects/PROJECT/regions/REGION/subnetworks/default' is not ready` message.

More information about this error here: https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-vm-creation#simultaneous_resource_mutation_or_creation_operations

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-10-03 11:33:37+00:00,[],2024-10-05 01:03:59+00:00,2024-10-05 01:03:59+00:00,https://github.com/apache/airflow/pull/42703,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2563440501,pull_request,closed,,Correctly select task in DAG Graph View when clicking on its name,"Cherry pick #38782

---------

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-03 08:30:29+00:00,[],2024-10-23 09:17:29+00:00,2024-10-03 14:38:12+00:00,https://github.com/apache/airflow/pull/42697,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2391024528, 'issue_id': 2563440501, 'author': 'eladkal', 'body': '> Cherry pick [#38782](https://github.com/astronomer/airflow/issues/38782)\r\n\r\nIs this the right link?\r\nThe link is for private astronomer repo', 'created_at': datetime.datetime(2024, 10, 3, 10, 9, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391388741, 'issue_id': 2563440501, 'author': 'bbovenzi', 'body': '> > Cherry pick [#38782](https://github.com/astronomer/airflow/issues/38782)\r\n> \r\n> Is this the right link? The link is for private astronomer repo\r\n\r\nOops! Fixed', 'created_at': datetime.datetime(2024, 10, 3, 13, 12, 6, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-10-03 10:09:11 UTC): Is this the right link?
The link is for private astronomer repo

bbovenzi (Issue Creator) on (2024-10-03 13:12:06 UTC): Oops! Fixed

"
2563263915,pull_request,closed,,Update min version of Pydantic to 2.6.4,"Pydantic 2.6.4 fixes problem with AliasGenerator to throw error when generating schema - see an issue in Pydantic repository https://github.com/pydantic/pydantic/issues/8768

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-03 06:50:54+00:00,[],2024-10-03 17:26:31+00:00,2024-10-03 10:00:54+00:00,https://github.com/apache/airflow/pull/42694,"[('area:providers', '')]","[{'comment_id': 2390654721, 'issue_id': 2563263915, 'author': 'potiuk', 'body': 'cc: @omkar-foss', 'created_at': datetime.datetime(2024, 10, 3, 6, 51, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390655594, 'issue_id': 2563263915, 'author': 'potiuk', 'body': 'See https://github.com/apache/airflow/issues/42370#issuecomment-2390639349 for more context.', 'created_at': datetime.datetime(2024, 10, 3, 6, 52, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390938928, 'issue_id': 2563263915, 'author': 'pierrejeambrun', 'body': 'Restarted the failed Job, 🤞', 'created_at': datetime.datetime(2024, 10, 3, 9, 25, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391007716, 'issue_id': 2563263915, 'author': 'pierrejeambrun', 'body': 'Green 🎉', 'created_at': datetime.datetime(2024, 10, 3, 10, 0, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391049526, 'issue_id': 2563263915, 'author': 'omkar-foss', 'body': ""Great! Now that Pydantic min version is updated, I'll reintroduce`AliasGenerator` in the next PR (for this issue: https://github.com/apache/airflow/issues/42652)."", 'created_at': datetime.datetime(2024, 10, 3, 10, 21, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391946541, 'issue_id': 2563263915, 'author': 'potiuk', 'body': ""> Great! Now that Pydantic min version is updated, I'll reintroduce`AliasGenerator` in the next PR (for this issue: #42652).\r\n\r\nCool"", 'created_at': datetime.datetime(2024, 10, 3, 17, 26, 29, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-03 06:51:44 UTC): cc: @omkar-foss

potiuk (Issue Creator) on (2024-10-03 06:52:21 UTC): See https://github.com/apache/airflow/issues/42370#issuecomment-2390639349 for more context.

pierrejeambrun on (2024-10-03 09:25:51 UTC): Restarted the failed Job, 🤞

pierrejeambrun on (2024-10-03 10:00:49 UTC): Green 🎉

omkar-foss on (2024-10-03 10:21:51 UTC): Great! Now that Pydantic min version is updated, I'll reintroduce`AliasGenerator` in the next PR (for this issue: https://github.com/apache/airflow/issues/42652).

potiuk (Issue Creator) on (2024-10-03 17:26:29 UTC): Cool

"
2562911360,pull_request,closed,,Check pool_slots on partial task import instead of execution (#39724),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

Backport pool_slots check for mapped tasks upon import
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",karenbraganz,2024-10-03 01:00:16+00:00,[],2024-11-27 10:55:37+00:00,2024-11-27 10:55:37+00:00,https://github.com/apache/airflow/pull/42693,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2392643706, 'issue_id': 2562911360, 'author': 'eladkal', 'body': '@uranusjr @ephraimbuddy the milestone on the original PR is 2.11 is that right? If so we cant merge this PR to 2.10 test branch till we no longer release 2.10.x series', 'created_at': datetime.datetime(2024, 10, 4, 1, 59, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482366073, 'issue_id': 2562911360, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 18, 9, 13, 35, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-10-04 01:59:02 UTC): @uranusjr @ephraimbuddy the milestone on the original PR is 2.11 is that right? If so we cant merge this PR to 2.10 test branch till we no longer release 2.10.x series

github-actions[bot] on (2024-11-18 09:13:35 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2562733733,pull_request,closed,,AIP-65: Track the serialized DAG across DagRun & TaskInstance,"Depends on #42547 
This helps to track the serialized DAG version the task instance ran
with, by establishing a relationship between the entities instead of using
the dag_hash.

Only the last commit is relevant",ephraimbuddy,2024-10-02 22:28:04+00:00,[],2024-10-15 13:03:46+00:00,2024-10-15 13:03:45+00:00,https://github.com/apache/airflow/pull/42690,"[('area:serialization', ''), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2413860031, 'issue_id': 2562733733, 'author': 'ephraimbuddy', 'body': 'Closing in preference of #42913', 'created_at': datetime.datetime(2024, 10, 15, 13, 3, 45, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-10-15 13:03:45 UTC): Closing in preference of #42913

"
2562721106,pull_request,closed,,Add basic support for git and local dag bundles,"This is a first pass at git and local dag bundles, and the bundle interface. These will certainly be expanded on (e.g. to support non-public repos).

Related: #42286
Closes: #42287 
Closes: #42288",jedcunningham,2024-10-02 22:15:23+00:00,[],2024-11-08 20:20:29+00:00,2024-11-08 20:20:27+00:00,https://github.com/apache/airflow/pull/42689,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2562681754,pull_request,closed,,Limit branches for pull request target workflow (#42635),"(cherry picked from commit e3fdb7e729781fccf02d9ab257d4382226c5b6c8)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-02 21:39:19+00:00,[],2024-10-02 21:40:55+00:00,2024-10-02 21:40:53+00:00,https://github.com/apache/airflow/pull/42688,"[('area:dev-tools', '')]",[],
2562673614,pull_request,closed,,Location of tutorial dag,"Sorry, this looks like a ticket, but it's an edit with explanation...

After spinning up Airflow using docker, a reference to the ""example_dags"" folder doesn't make sense.  It's not clear how to create your first dag.  The docker docs reference the web UI, but there's no way in the UI to create or edit a dag.  At least there's no docs on that.

Documentation on docker shows that ""dags"" is volume mounted.  So does this mean I should create ""airflow/dags/example_dags/tutorial.py"" or just ""airflow/dags/tutorial.py"".

The folder names are not lining up.

Is it possible to create ""dags/example/tutorial.py""?  I'm new to Airflow, but I'm guessing over some time there will be dozens of python scripts and some folder structure makes sense.  If so, the tutorial should tell the user to create a folder in the dags folder and put the tutorial.py file there.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",openbrian,2024-10-02 21:32:13+00:00,[],2024-10-02 22:11:48+00:00,2024-10-02 22:11:48+00:00,https://github.com/apache/airflow/pull/42687,"[('invalid', ''), ('kind:documentation', '')]","[{'comment_id': 2389731661, 'issue_id': 2562673614, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 2, 21, 32, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389778649, 'issue_id': 2562673614, 'author': 'potiuk', 'body': 'No. It\'s wrong. Documentation will stop building. The tutorial refers to ""example_dags"" folder in airflow sources not in your DAG folder - they are part of Airflow source code https://github.com/apache/airflow/tree/main/airflow/example_dags. And no - you cannot create DAGs in UI - you need to manually create then in your DAG folder.', 'created_at': datetime.datetime(2024, 10, 2, 22, 11, 46, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-02 21:32:17 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-02 22:11:46 UTC): No. It's wrong. Documentation will stop building. The tutorial refers to ""example_dags"" folder in airflow sources not in your DAG folder - they are part of Airflow source code https://github.com/apache/airflow/tree/main/airflow/example_dags. And no - you cannot create DAGs in UI - you need to manually create then in your DAG folder.

"
2562671236,pull_request,closed,,Schedule backfills in the scheduler,"(cherry picked from commit 2a581abc99988ea9d3efa67311d04716696ccca4)
",dstandish,2024-10-02 21:30:20+00:00,[],2024-10-06 20:40:29+00:00,2024-10-05 13:34:11+00:00,https://github.com/apache/airflow/pull/42686,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2395379787, 'issue_id': 2562671236, 'author': 'jscheffl', 'body': 'It seems that this PR broke the ""Non DB"" tests for Always and CLI in https://github.com/apache/airflow/actions/runs/11200846409/job/31135117858?pr=42773 and on main.\r\n\r\nAny idea on how to fix this (easily) w/o reversion?', 'created_at': datetime.datetime(2024, 10, 6, 10, 13, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395454887, 'issue_id': 2562671236, 'author': 'dstandish', 'body': '> It seems that this PR broke the ""Non DB"" tests for Always and CLI in https://github.com/apache/airflow/actions/runs/11200846409/job/31135117858?pr=42773 and on main.\r\n> \r\n> Any idea on how to fix this (easily) w/o reversion?\r\n\r\nI took a quick look but cannot reproduce locally.\r\n\r\nI am unavailable most of today.', 'created_at': datetime.datetime(2024, 10, 6, 14, 9, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395492789, 'issue_id': 2562671236, 'author': 'jscheffl', 'body': '> > It seems that this PR broke the ""Non DB"" tests for Always and CLI in https://github.com/apache/airflow/actions/runs/11200846409/job/31135117858?pr=42773 and on main.\r\n> > Any idea on how to fix this (easily) w/o reversion?\r\n> \r\n> I took a quick look but cannot reproduce locally.\r\n> \r\n> I am unavailable most of today.\r\n\r\nThanks for checking. I saw it on multiple PRs and might be it is related to non DB tests and threading?\r\nOn my Laptop I can re-produce via:\r\n```\r\ngit checkout main\r\ngit pull\r\nbreeze ci-image build --python 3.8  # ensure this is up-to-date\r\nbreeze testing non-db-tests --parallel-test-types ""Always CLI""\r\n```\r\n\r\nWhereas interesting that it does not show-up in canary tests :-( I don\'t understand why, checked with different parallelism and not able to get this green locally.', 'created_at': datetime.datetime(2024, 10, 6, 16, 10, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395578157, 'issue_id': 2562671236, 'author': 'dstandish', 'body': ""i'll look now"", 'created_at': datetime.datetime(2024, 10, 6, 20, 40, 28, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-06 10:13:21 UTC): It seems that this PR broke the ""Non DB"" tests for Always and CLI in https://github.com/apache/airflow/actions/runs/11200846409/job/31135117858?pr=42773 and on main.

Any idea on how to fix this (easily) w/o reversion?

dstandish (Issue Creator) on (2024-10-06 14:09:46 UTC): I took a quick look but cannot reproduce locally.

I am unavailable most of today.

jscheffl on (2024-10-06 16:10:03 UTC): Thanks for checking. I saw it on multiple PRs and might be it is related to non DB tests and threading?
On my Laptop I can re-produce via:
```
git checkout main
git pull
breeze ci-image build --python 3.8  # ensure this is up-to-date
breeze testing non-db-tests --parallel-test-types ""Always CLI""
```

Whereas interesting that it does not show-up in canary tests :-( I don't understand why, checked with different parallelism and not able to get this green locally.

dstandish (Issue Creator) on (2024-10-06 20:40:28 UTC): i'll look now

"
2562670517,pull_request,closed,,"Revert ""Temporarily disable branch protection for older v2-* branches…","… (#42680)""

This reverts commit 6a397ca2c16872d223255c8491c9e025a9c140cd.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-02 21:29:46+00:00,[],2024-10-02 21:30:43+00:00,2024-10-02 21:30:41+00:00,https://github.com/apache/airflow/pull/42685,"[('area:dev-tools', '')]",[],
2562665413,pull_request,closed,,Exclude backfill dag runs in active_runs_of_dags counts,"In the areas where this is used, we don't want to include backfill runs in the counts. Rather than rename the function to reflect the change, I add a parameter.

(cherry picked from commit 5cbc941f5101c5605486323c826c3980b3cc9499)

",dstandish,2024-10-02 21:25:48+00:00,[],2024-10-17 20:23:10+00:00,2024-10-17 20:23:07+00:00,https://github.com/apache/airflow/pull/42684,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2562664866,pull_request,closed,,Add logic to mark backfills as complete,"Check periodically for backfills that are now complete.

---

~depends on https://github.com/apache/airflow/pull/42686~",dstandish,2024-10-02 21:25:19+00:00,[],2024-10-14 02:41:37+00:00,2024-10-14 02:40:48+00:00,https://github.com/apache/airflow/pull/42683,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2409691525, 'issue_id': 2562664866, 'author': 'jedcunningham', 'body': 'I do wonder if it\'d be better to check when setting the dagrun state instead of adding to the EventScheduler. But the ""best"" option is probably situational, so I\'m fine with it this way.', 'created_at': datetime.datetime(2024, 10, 14, 1, 59, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409824430, 'issue_id': 2562664866, 'author': 'dstandish', 'body': '> I do wonder if it\'d be better to check when setting the dagrun state instead of adding to the EventScheduler. But the ""best"" option is probably situational, so I\'m fine with it this way.\r\n\r\nYeah, reasonable.  I would be fine either way.  And, we could change it later to be that way since it\'s not user-facing code.', 'created_at': datetime.datetime(2024, 10, 14, 2, 41, 35, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2024-10-14 01:59:12 UTC): I do wonder if it'd be better to check when setting the dagrun state instead of adding to the EventScheduler. But the ""best"" option is probably situational, so I'm fine with it this way.

dstandish (Issue Creator) on (2024-10-14 02:41:35 UTC): Yeah, reasonable.  I would be fine either way.  And, we could change it later to be that way since it's not user-facing code.

"
2562664120,pull_request,closed,,Remove DagRunNotBackfillDep,"(cherry picked from commit 411aeae2c19bb54de87ad70214c446e112b6bc94)
",dstandish,2024-10-02 21:24:43+00:00,[],2024-10-02 22:19:59+00:00,2024-10-02 22:19:59+00:00,https://github.com/apache/airflow/pull/42682,[],"[{'comment_id': 2389787163, 'issue_id': 2562664120, 'author': 'dstandish', 'body': 'duplicate of https://github.com/apache/airflow/pull/42552', 'created_at': datetime.datetime(2024, 10, 2, 22, 19, 59, tzinfo=datetime.timezone.utc)}]","dstandish (Issue Creator) on (2024-10-02 22:19:59 UTC): duplicate of https://github.com/apache/airflow/pull/42552

"
2562663553,pull_request,closed,,Update exec-date-after-start-date dep to allow backfill,"This will bypass this dep when the run type is backfill.

(cherry picked from commit 877708b27e9bc4db93a3954f8cb8b2061ef91a61)
",dstandish,2024-10-02 21:24:17+00:00,[],2024-11-28 00:16:20+00:00,2024-11-28 00:16:20+00:00,https://github.com/apache/airflow/pull/42681,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2492612607, 'issue_id': 2562663553, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 22, 0, 16, 24, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-22 00:16:24 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2562662987,pull_request,closed,,Temporarily disable branch protection for older v2-* branches,"We have to do some maintenance and temporarily disabling branch protection is the easiest way to do it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-02 21:23:51+00:00,[],2024-10-02 21:26:36+00:00,2024-10-02 21:26:35+00:00,https://github.com/apache/airflow/pull/42680,"[('area:dev-tools', '')]",[],
2562627150,pull_request,closed,,Remove special handling of backfills in scheduler,"Before airflow 3.0, scheduler would completely ignore all backfill runs.  This PR gets rid of that logic so that backfill runs are treated the same as non-backfill.  This is a baby step on the way to adding scheduling of backfill dag runs into the scheduler.",dstandish,2024-10-02 20:57:10+00:00,[],2024-10-03 02:31:08+00:00,2024-10-03 02:31:05+00:00,https://github.com/apache/airflow/pull/42678,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2562530686,pull_request,closed,,AIP-84 Migrate the public endpoint Get Connections to FastAPI ,"closes #42591 

Migrate the 'GET' connections to Fast API.
",rawwar,2024-10-02 19:59:18+00:00,[],2024-10-04 10:54:43+00:00,2024-10-03 09:32:44+00:00,https://github.com/apache/airflow/pull/42677,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2562502670,pull_request,closed,,Add standard provider to preinstalled providers.,"Standard provider should be preinstalled when airflow is installed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-02 19:41:09+00:00,[],2024-10-03 07:22:05+00:00,2024-10-03 07:22:04+00:00,https://github.com/apache/airflow/pull/42676,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2389548554, 'issue_id': 2562502670, 'author': 'potiuk', 'body': 'This might or might not work, because we have not yet released standard provider - so some part of the CI (when released PyPI packages are used) might fail. It might require from us to release a pre-release version of the ""standard"" provider in PyPI.\r\n\r\nThis will work nicely because pre-release version will be installed by `pip` (as I understand it) - when no ""released"" version is available and we use it as dependency (@uranusjr ? - am I right?) - but regular users will not see it as released in PyPI and we do not have to worry about release process for standard, we can just prepare the package and upload it to PyPI as dev0, dev1 etc.', 'created_at': datetime.datetime(2024, 10, 2, 19, 46, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389641045, 'issue_id': 2562502670, 'author': 'gopidesupavan', 'body': ""Thanks @potiuk  for raising this and the proposal to release standard provider. This will definitely helps on the other pr's. :)"", 'created_at': datetime.datetime(2024, 10, 2, 20, 29, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389661060, 'issue_id': 2562502670, 'author': 'potiuk', 'body': '> Thanks @potiuk for raising this and the proposal to release standard provider. This will definitely helps on the other pr\'s. :)\r\n\r\nYep. For posterity - here is the devlist discussion where I proposed the ""manual"" approach https://lists.apache.org/thread/1gshy5cjmp9wz5v8dozyh64jj3dyn5s4', 'created_at': datetime.datetime(2024, 10, 2, 20, 42, 7, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-02 19:46:41 UTC): This might or might not work, because we have not yet released standard provider - so some part of the CI (when released PyPI packages are used) might fail. It might require from us to release a pre-release version of the ""standard"" provider in PyPI.

This will work nicely because pre-release version will be installed by `pip` (as I understand it) - when no ""released"" version is available and we use it as dependency (@uranusjr ? - am I right?) - but regular users will not see it as released in PyPI and we do not have to worry about release process for standard, we can just prepare the package and upload it to PyPI as dev0, dev1 etc.

gopidesupavan on (2024-10-02 20:29:44 UTC): Thanks @potiuk  for raising this and the proposal to release standard provider. This will definitely helps on the other pr's. :)

potiuk (Issue Creator) on (2024-10-02 20:42:07 UTC): Yep. For posterity - here is the devlist discussion where I proposed the ""manual"" approach https://lists.apache.org/thread/1gshy5cjmp9wz5v8dozyh64jj3dyn5s4

"
2562417857,pull_request,closed,,AIP-84 Migrate GET connection to FastAPI API,"closes #42590 

Migrate the 'GET' connection to Fast API.

",rawwar,2024-10-02 18:48:02+00:00,[],2024-10-04 07:26:36+00:00,2024-10-04 07:26:36+00:00,https://github.com/apache/airflow/pull/42674,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('provider:standard', '')]",[],
2562329022,pull_request,closed,,feat: allow customizing podManagementPolicy,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
I as a user of StatefulSets in Airflow, would like to preserving workload uniqueness and identity guarantees, but allow scalling up and down without waiting for termination grace period.

This is useful when termination grace period is very high. In such cases, scaling up and down gets fully stuck while waiting for long running tasks. 
",EvertonSA,2024-10-02 18:06:37+00:00,[],2024-10-09 14:22:02+00:00,2024-10-08 14:32:23+00:00,https://github.com/apache/airflow/pull/42673,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2392148368, 'issue_id': 2562329022, 'author': 'EvertonSA', 'body': 'thank you so much for the help here @eladkal, at my organization, we recently pushed celery to production and at the moment we are having issues on scaling due to high termination grace period.', 'created_at': datetime.datetime(2024, 10, 3, 19, 16, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392640998, 'issue_id': 2562329022, 'author': 'potiuk', 'body': 'cc: @jedcunningham for cross-check', 'created_at': datetime.datetime(2024, 10, 4, 1, 55, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400032113, 'issue_id': 2562329022, 'author': 'romsharon98', 'body': 'Already merged but it will be nice if you add a UT for this 🙂', 'created_at': datetime.datetime(2024, 10, 8, 14, 34, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400077389, 'issue_id': 2562329022, 'author': 'EvertonSA', 'body': 'hi @romsharon98 , I beg your pardon, what is a UT? I will add it', 'created_at': datetime.datetime(2024, 10, 8, 14, 52, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402490319, 'issue_id': 2562329022, 'author': 'romsharon98', 'body': '> hi @romsharon98 , I beg your pardon, what is a UT? I will add it\r\n\r\nin UT I ment unit tests.\r\nwe have a unit tests documentation about the helm chart [here](https://github.com/apache/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst).\r\nthe test should check if the worker deployment is statefulset and has podManagementPolicy, we added it to the yaml.', 'created_at': datetime.datetime(2024, 10, 9, 14, 22, tzinfo=datetime.timezone.utc)}]","EvertonSA (Issue Creator) on (2024-10-03 19:16:22 UTC): thank you so much for the help here @eladkal, at my organization, we recently pushed celery to production and at the moment we are having issues on scaling due to high termination grace period.

potiuk on (2024-10-04 01:55:58 UTC): cc: @jedcunningham for cross-check

romsharon98 on (2024-10-08 14:34:52 UTC): Already merged but it will be nice if you add a UT for this 🙂

EvertonSA (Issue Creator) on (2024-10-08 14:52:26 UTC): hi @romsharon98 , I beg your pardon, what is a UT? I will add it

romsharon98 on (2024-10-09 14:22:00 UTC): in UT I ment unit tests.
we have a unit tests documentation about the helm chart [here](https://github.com/apache/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst).
the test should check if the worker deployment is statefulset and has podManagementPolicy, we added it to the yaml.

"
2562096982,pull_request,closed,,Upgrade build dependencies to latest (tomli),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-02 16:10:29+00:00,[],2024-10-02 19:09:38+00:00,2024-10-02 19:09:36+00:00,https://github.com/apache/airflow/pull/42672,[],[],
2562077930,pull_request,closed,,Fix gcp_conn_id in PubsubPullTrigger,"Currently the values gcp_conn_id, impersonation_chain, project_id not using in PubsubPullTrigger. 
This fix is to use provided values from sensor and create connection hook in PubsubPullTrigger.

closes: #42160 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-10-02 16:00:18+00:00,[],2024-11-02 13:05:39+00:00,2024-10-03 20:36:09+00:00,https://github.com/apache/airflow/pull/42671,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2562064327,pull_request,closed,,Point users at `db migrate` if there are outstanding migrations,"Before:
```
You still have unapplied migrations. You may need to upgrade the database by running `airflow db upgrade`.  Make sure the 
command is run using Airflow version 3.0.0.dev0.
```

After:
```
You still have unapplied migrations. You may need to migrate the database by running `airflow db migrate`.  Make sure the 
command is run using Airflow version 3.0.0.dev0.
```",jedcunningham,2024-10-02 15:53:40+00:00,[],2024-10-03 20:17:18+00:00,2024-10-02 23:44:08+00:00,https://github.com/apache/airflow/pull/42670,[],[],
2562061427,pull_request,closed,,Update AWS system test `example_emr_serverless`,"If the EMR job finishes before the task `wait_for_job` starts, then the task is waiting forever.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-02 15:52:16+00:00,[],2024-10-02 17:14:10+00:00,2024-10-02 17:14:08+00:00,https://github.com/apache/airflow/pull/42669,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2561875740,pull_request,closed,,Add on_kill  equivalent to Databricks SQL Hook to cancel timed out queries,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

related: #42115 

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The Databricks Provider did not implement a mechanism to cancel SQL queries submitted by DatabricksSqlHook. This led to data quality issues, where Airflow would report a cancellation due to timeout; however, the corresponding SQL query would continue to run on Databricks.

This PR uses threading to cancel SQL queries submitted by DatabricksSqlHook.run() once the timeout is exceeded.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",R7L208,2024-10-02 14:42:56+00:00,[],2024-11-13 03:50:56+00:00,2024-11-13 03:50:56+00:00,https://github.com/apache/airflow/pull/42668,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2394759760, 'issue_id': 2561875740, 'author': 'R7L208', 'body': '@Lee-W - Could you help me understand why the new exceptions are not being found in `airflow/exceptions.py` for jobs:\r\n- Tests / Provider checks / Compat 2.8.4:P3.8 provider check (pull_request)\r\n- Tests / Provider checks / Compat 2.9.3:P3.8 provider check (pull_request) \r\n- Tests / Provider checks / Compat 2.10.1:P3.8 provider check (pull_request)\r\n\r\nThe exceptions are present in the file and are able to be successfully imported locally when I run `breeze testing tests --test-type ""Providers[databricks]""`, so I\'m struggling to understand why they would cause an import error here, specifically from `/usr/local/lib/python3.8/site-packages/airflow/exceptions.py`.\r\n\r\n```\r\n__ ERROR collecting tests/providers/databricks/sensors/test_databricks_sql.py __\r\nImportError while importing test module \'/opt/airflow/tests/providers/databricks/sensors/test_databricks_sql.py\'.\r\nHint: make sure your test modules/packages have valid Python names.\r\nTraceback:\r\n/usr/local/lib/python3.8/importlib/__init__.py:127: in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\ntests/providers/databricks/sensors/test_databricks_sql.py:28: in <module>\r\n    from airflow.providers.databricks.sensors.databricks_sql import DatabricksSqlSensor\r\n/usr/local/lib/python3.8/site-packages/airflow/providers/databricks/sensors/databricks_sql.py:28: in <module>\r\n    from airflow.providers.databricks.hooks.databricks_sql import DatabricksSqlHook\r\n/usr/local/lib/python3.8/site-packages/airflow/providers/databricks/hooks/databricks_sql.py:41: in <module>\r\n    from airflow.exceptions import (\r\nE   ImportError: cannot import name \'AirflowTaskExecutionError\' from \'airflow.exceptions\' (/usr/local/lib/python3.8/site-packages/airflow/exceptions.py)\r\n-- generated xml file: /files/test_result-providers_-amazon_google-sqlite.xml --\r\n```\r\n\r\n\r\nAlso, the DB tests seem to be failing because of tests unrelated to my changes, or I\'m missing how they are connected.', 'created_at': datetime.datetime(2024, 10, 4, 22, 44, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395650521, 'issue_id': 2561875740, 'author': 'Lee-W', 'body': '> @Lee-W - Could you help me understand why the new exceptions are not being found in `airflow/exceptions.py` for jobs:\r\n> \r\n>     * Tests / Provider checks / Compat 2.8.4:P3.8 provider check (pull_request)\r\n> \r\n>     * Tests / Provider checks / Compat 2.9.3:P3.8 provider check (pull_request)\r\n> \r\n>     * Tests / Provider checks / Compat 2.10.1:P3.8 provider check (pull_request)\r\n> \r\n> \r\n> The exceptions are present in the file and are able to be successfully imported locally when I run `breeze testing tests --test-type ""Providers[databricks]""`, so I\'m struggling to understand why they would cause an import error here, specifically from `/usr/local/lib/python3.8/site-packages/airflow/exceptions.py`.\r\n> \r\n> ```\r\n> __ ERROR collecting tests/providers/databricks/sensors/test_databricks_sql.py __\r\n> ImportError while importing test module \'/opt/airflow/tests/providers/databricks/sensors/test_databricks_sql.py\'.\r\n> Hint: make sure your test modules/packages have valid Python names.\r\n> Traceback:\r\n> /usr/local/lib/python3.8/importlib/__init__.py:127: in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n> tests/providers/databricks/sensors/test_databricks_sql.py:28: in <module>\r\n>     from airflow.providers.databricks.sensors.databricks_sql import DatabricksSqlSensor\r\n> /usr/local/lib/python3.8/site-packages/airflow/providers/databricks/sensors/databricks_sql.py:28: in <module>\r\n>     from airflow.providers.databricks.hooks.databricks_sql import DatabricksSqlHook\r\n> /usr/local/lib/python3.8/site-packages/airflow/providers/databricks/hooks/databricks_sql.py:41: in <module>\r\n>     from airflow.exceptions import (\r\n> E   ImportError: cannot import name \'AirflowTaskExecutionError\' from \'airflow.exceptions\' (/usr/local/lib/python3.8/site-packages/airflow/exceptions.py)\r\n> -- generated xml file: /files/test_result-providers_-amazon_google-sqlite.xml --\r\n> ```\r\n> \r\n> Also, the DB tests seem to be failing because of tests unrelated to my changes, or I\'m missing how they are connected.\r\n\r\nSure. These exception should not be added in `airflow.execptions` but somewhere inside this databricks providers. Airflow core and airflow providers are released separately and that\'s why we have such tests to test providers with older airflow version', 'created_at': datetime.datetime(2024, 10, 6, 23, 35, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400163451, 'issue_id': 2561875740, 'author': 'R7L208', 'body': '@Lee-W @uranusjr - Apologies for all of the back-and-forth on testing, but could you help me understand why this test is failing `Tests / Non-DB tests / Non-DB::3.8: Always Providers[common.sql,databricks] (pull_request) Failing after 2m`? Looking at the logs the failed tests seemed unrelated, and I\'ve been having trouble getting the logs to appear for the GH job.\r\n\r\nI\'m unable to reproduce the failing tests running `breeze testing tests --test-type ""Providers[common.sql,databricks]""`. Is there a better breeze command that would mirror this test locally?', 'created_at': datetime.datetime(2024, 10, 8, 15, 25, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400186008, 'issue_id': 2561875740, 'author': 'dstandish', 'body': '> @Lee-W @uranusjr - Apologies for all of the back-and-forth on testing, but could you help me understand why this test is failing `Tests / Non-DB tests / Non-DB::3.8: Always Providers[common.sql,databricks] (pull_request) Failing after 2m`? Looking at the logs the failed tests seemed unrelated, and I\'ve been having trouble getting the logs to appear for the GH job.\r\n> \r\n> I\'m unable to reproduce the failing tests running `breeze testing tests --test-type ""Providers[common.sql,databricks]""`. Is there a better breeze command that would mirror this test locally?\r\n\r\nRebase to get fix from https://github.com/apache/airflow/pull/42828', 'created_at': datetime.datetime(2024, 10, 8, 15, 35, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401093400, 'issue_id': 2561875740, 'author': 'Lee-W', 'body': 'Mostly good from my end, left a few nitpicks', 'created_at': datetime.datetime(2024, 10, 9, 1, 29, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2420701350, 'issue_id': 2561875740, 'author': 'potiuk', 'body': 'A LOT of conflicts. We moved providers to another directory, you need to resolve the conflicts/move your changes.', 'created_at': datetime.datetime(2024, 10, 17, 22, 14, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432610347, 'issue_id': 2561875740, 'author': 'R7L208', 'body': '@uranusjr @Lee-W - any additional feedback or is this ok to get merged?', 'created_at': datetime.datetime(2024, 10, 23, 15, 23, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2440807716, 'issue_id': 2561875740, 'author': 'Lee-W', 'body': 'LGTM', 'created_at': datetime.datetime(2024, 10, 28, 8, 3, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2450815760, 'issue_id': 2561875740, 'author': 'R7L208', 'body': 'hey @uranusjr - Can you please review as your requested changes should be addressed now? 🙏', 'created_at': datetime.datetime(2024, 10, 31, 21, 6, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460808827, 'issue_id': 2561875740, 'author': 'R7L208', 'body': 'Wanted to nudge on this again. @uranusjr - Is there any timeline for when you could re-review?', 'created_at': datetime.datetime(2024, 11, 6, 21, 21, 41, tzinfo=datetime.timezone.utc)}]","R7L208 (Issue Creator) on (2024-10-04 22:44:51 UTC): @Lee-W - Could you help me understand why the new exceptions are not being found in `airflow/exceptions.py` for jobs:
- Tests / Provider checks / Compat 2.8.4:P3.8 provider check (pull_request)
- Tests / Provider checks / Compat 2.9.3:P3.8 provider check (pull_request) 
- Tests / Provider checks / Compat 2.10.1:P3.8 provider check (pull_request)

The exceptions are present in the file and are able to be successfully imported locally when I run `breeze testing tests --test-type ""Providers[databricks]""`, so I'm struggling to understand why they would cause an import error here, specifically from `/usr/local/lib/python3.8/site-packages/airflow/exceptions.py`.

```
__ ERROR collecting tests/providers/databricks/sensors/test_databricks_sql.py __
ImportError while importing test module '/opt/airflow/tests/providers/databricks/sensors/test_databricks_sql.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/usr/local/lib/python3.8/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/providers/databricks/sensors/test_databricks_sql.py:28: in <module>
    from airflow.providers.databricks.sensors.databricks_sql import DatabricksSqlSensor
/usr/local/lib/python3.8/site-packages/airflow/providers/databricks/sensors/databricks_sql.py:28: in <module>
    from airflow.providers.databricks.hooks.databricks_sql import DatabricksSqlHook
/usr/local/lib/python3.8/site-packages/airflow/providers/databricks/hooks/databricks_sql.py:41: in <module>
    from airflow.exceptions import (
E   ImportError: cannot import name 'AirflowTaskExecutionError' from 'airflow.exceptions' (/usr/local/lib/python3.8/site-packages/airflow/exceptions.py)
-- generated xml file: /files/test_result-providers_-amazon_google-sqlite.xml --
```


Also, the DB tests seem to be failing because of tests unrelated to my changes, or I'm missing how they are connected.

Lee-W on (2024-10-06 23:35:44 UTC): Sure. These exception should not be added in `airflow.execptions` but somewhere inside this databricks providers. Airflow core and airflow providers are released separately and that's why we have such tests to test providers with older airflow version

R7L208 (Issue Creator) on (2024-10-08 15:25:52 UTC): @Lee-W @uranusjr - Apologies for all of the back-and-forth on testing, but could you help me understand why this test is failing `Tests / Non-DB tests / Non-DB::3.8: Always Providers[common.sql,databricks] (pull_request) Failing after 2m`? Looking at the logs the failed tests seemed unrelated, and I've been having trouble getting the logs to appear for the GH job.

I'm unable to reproduce the failing tests running `breeze testing tests --test-type ""Providers[common.sql,databricks]""`. Is there a better breeze command that would mirror this test locally?

dstandish on (2024-10-08 15:35:12 UTC): Rebase to get fix from https://github.com/apache/airflow/pull/42828

Lee-W on (2024-10-09 01:29:03 UTC): Mostly good from my end, left a few nitpicks

potiuk on (2024-10-17 22:14:54 UTC): A LOT of conflicts. We moved providers to another directory, you need to resolve the conflicts/move your changes.

R7L208 (Issue Creator) on (2024-10-23 15:23:08 UTC): @uranusjr @Lee-W - any additional feedback or is this ok to get merged?

Lee-W on (2024-10-28 08:03:39 UTC): LGTM

R7L208 (Issue Creator) on (2024-10-31 21:06:16 UTC): hey @uranusjr - Can you please review as your requested changes should be addressed now? 🙏

R7L208 (Issue Creator) on (2024-11-06 21:21:41 UTC): Wanted to nudge on this again. @uranusjr - Is there any timeline for when you could re-review?

"
2561827772,pull_request,closed,,Rename wrongly named test,"Miss from #42627

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-02 14:23:00+00:00,[],2024-10-02 17:14:22+00:00,2024-10-02 17:14:20+00:00,https://github.com/apache/airflow/pull/42667,"[('area:dev-tools', '')]",[],
2561822277,pull_request,closed,,"Remove ""project"" from log path in callback docs","Airflow doesn't have the concept of a ""project"", unless DAG authors add that layer themselves.",jedcunningham,2024-10-02 14:20:33+00:00,[],2024-10-02 14:38:39+00:00,2024-10-02 14:38:37+00:00,https://github.com/apache/airflow/pull/42666,"[('kind:documentation', '')]",[],
2561747199,pull_request,closed,,AIP-84 Serve new UI from FastAPI API,"Serve the new UI from the new FastAPI API. Up to now it was served by the legacy webserver.

Closes [#42695](https://github.com/apache/airflow/issues/42695)",pierrejeambrun,2024-10-02 13:48:22+00:00,['pierrejeambrun'],2024-10-04 14:26:14+00:00,2024-10-03 16:50:30+00:00,https://github.com/apache/airflow/pull/42663,"[('area:webserver', 'Webserver related Issues'), ('area:dev-tools', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2391869463, 'issue_id': 2561747199, 'author': 'jscheffl', 'body': 'I just realized - in my local setup the button ""Return to legacy UI"" is not working anymore. Local artefact or a bug?', 'created_at': datetime.datetime(2024, 10, 3, 16, 44, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391881515, 'issue_id': 2561747199, 'author': 'bbovenzi', 'body': '> I just realized - in my local setup the button ""Return to legacy UI"" is not working anymore. Local artefact or a bug?\r\n\r\nCheck the new .env.example', 'created_at': datetime.datetime(2024, 10, 3, 16, 50, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392095895, 'issue_id': 2561747199, 'author': 'jscheffl', 'body': '> > I just realized - in my local setup the button ""Return to legacy UI"" is not working anymore. Local artefact or a bug?\r\n> \r\n> Check the new .env.example\r\n\r\nI checked and still not working. or I am too stupid. Copied the `airflow/ui/.env.example` to `airflow/ui/.env.local` and still button not working. Might be good as if you advertise people trying the new UI this is broken and not configured by breeze automatically.', 'created_at': datetime.datetime(2024, 10, 3, 18, 47, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393026336, 'issue_id': 2561747199, 'author': 'pierrejeambrun', 'body': 'Are you using breeze to start your airflow instance ? Running it in dev-mode or not, both should work, I just tried it:\r\n```\r\nbreeze start-airflow --python 3.8 --backend postgres --dev-mode\r\n# or\r\nbreeze start-airflow --python 3.8 --backend postgres\r\n```\r\n\r\nIf you inspect the button in the front-end what ref does it have ?\r\n\r\nI assume this is a build / not up-to-date bundle. Also, you need to restart breeze if you just copied/updated the env file.\r\n\r\n![Screenshot 2024-10-04 at 09 32 32](https://github.com/user-attachments/assets/ad93ed77-63b4-4497-9e47-0991d52a1aad)', 'created_at': datetime.datetime(2024, 10, 4, 7, 33, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393841730, 'issue_id': 2561747199, 'author': 'jscheffl', 'body': ""> Are you using breeze to start your airflow instance ? Running it in dev-mode or not, both should work, I just tried it:\r\n> \r\n> ```\r\n> breeze start-airflow --python 3.8 --backend postgres --dev-mode\r\n> # or\r\n> breeze start-airflow --python 3.8 --backend postgres\r\n> ```\r\n\r\nActually I don't know why... atried it multiple times, adding the `.env.local` in multiple places and gave up. Then two starts via breeze later it was working. I was attempting befoer in dev-mode as well without. So for me it is at the moment resolved but I fear others (non experts) might get impacted in a fresh devenv. Hope it is only transitional."", 'created_at': datetime.datetime(2024, 10, 4, 14, 26, 13, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-03 16:44:47 UTC): I just realized - in my local setup the button ""Return to legacy UI"" is not working anymore. Local artefact or a bug?

bbovenzi on (2024-10-03 16:50:57 UTC): Check the new .env.example

jscheffl on (2024-10-03 18:47:56 UTC): I checked and still not working. or I am too stupid. Copied the `airflow/ui/.env.example` to `airflow/ui/.env.local` and still button not working. Might be good as if you advertise people trying the new UI this is broken and not configured by breeze automatically.

pierrejeambrun (Issue Creator) on (2024-10-04 07:33:12 UTC): Are you using breeze to start your airflow instance ? Running it in dev-mode or not, both should work, I just tried it:
```
breeze start-airflow --python 3.8 --backend postgres --dev-mode
# or
breeze start-airflow --python 3.8 --backend postgres
```

If you inspect the button in the front-end what ref does it have ?

I assume this is a build / not up-to-date bundle. Also, you need to restart breeze if you just copied/updated the env file.

![Screenshot 2024-10-04 at 09 32 32](https://github.com/user-attachments/assets/ad93ed77-63b4-4497-9e47-0991d52a1aad)

jscheffl on (2024-10-04 14:26:13 UTC): Actually I don't know why... atried it multiple times, adding the `.env.local` in multiple places and gave up. Then two starts via breeze later it was working. I was attempting befoer in dev-mode as well without. So for me it is at the moment resolved but I fear others (non experts) might get impacted in a fresh devenv. Hope it is only transitional.

"
2561430729,pull_request,closed,,Add debug logs to print Request/Response data in  Databricks provider,"This PR intends to add additional debug logging around Requests/Responses to/from Databricks API. 

",rawwar,2024-10-02 12:08:34+00:00,[],2024-10-02 21:54:08+00:00,2024-10-02 21:54:08+00:00,https://github.com/apache/airflow/pull/42662,"[('area:providers', ''), ('provider:databricks', '')]",[],
2561347547,pull_request,closed,,Added task_instance_mutation_hook for mapped operator index 0,"During working with the task instance mutation hook feature I found an Issue with the execution of the hook and the mapped operator. The Hook was only executed for the expanded tasks index > 0 and the Index 0 was not executed with the hook.

This PR adds call of task_instance_mutation_hook if the index 0 does not exists in the DB.",AutomationDev85,2024-10-02 11:36:57+00:00,['jscheffl'],2024-10-23 09:01:49+00:00,2024-10-16 16:47:32+00:00,https://github.com/apache/airflow/pull/42661,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2561272400,pull_request,closed,,Removed deprecated concurrency field from dag details schema,Removed deprecated concurrency field from dag details schema,dirrao,2024-10-02 11:03:29+00:00,['dirrao'],2024-10-03 01:10:50+00:00,2024-10-03 01:10:49+00:00,https://github.com/apache/airflow/pull/42660,"[('area:API', ""Airflow's REST/HTTP API""), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2561176769,pull_request,closed,,"Revert ""Move FSHook/PackageIndexHook/SubprocessHook to standard provider""",Reverts apache/airflow#42506,gopidesupavan,2024-10-02 10:10:30+00:00,[],2024-11-02 13:05:42+00:00,2024-10-02 11:48:12+00:00,https://github.com/apache/airflow/pull/42659,"[('area:providers', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2388281622, 'issue_id': 2561176769, 'author': 'gopidesupavan', 'body': 'Reverting this due to standard provider not installing in default providers list. As this have changes in bash operator, the bash operator is imported in celery executor, causing import failures, so basically this impacts , docker, k8s tests. \r\n\r\nWaiting for this comment https://github.com/apache/airflow/pull/42252#discussion_r1774435228', 'created_at': datetime.datetime(2024, 10, 2, 10, 16, 35, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-10-02 10:16:35 UTC): Reverting this due to standard provider not installing in default providers list. As this have changes in bash operator, the bash operator is imported in celery executor, causing import failures, so basically this impacts , docker, k8s tests. 

Waiting for this comment https://github.com/apache/airflow/pull/42252#discussion_r1774435228

"
2561174261,pull_request,closed,,Changing dag_id to a positional argument in the 'dags list-runs' CLI command,Changing dag_id to a positional argument in the 'dags list-runs' CLI command,dirrao,2024-10-02 10:09:37+00:00,['dirrao'],2024-11-21 15:40:47+00:00,2024-10-04 01:52:43+00:00,https://github.com/apache/airflow/pull/42658,"[('area:CLI', ''), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2486940708, 'issue_id': 2561174261, 'author': 'dstandish', 'body': 'Can anyone comment on why we are doing this?', 'created_at': datetime.datetime(2024, 11, 19, 23, 14, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486949399, 'issue_id': 2561174261, 'author': 'vikramkoka', 'body': '@dirrao Why did we make a breaking change here?', 'created_at': datetime.datetime(2024, 11, 19, 23, 17, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487481341, 'issue_id': 2561174261, 'author': 'dirrao', 'body': '> @dirrao Why did we make a breaking change here?\r\n\r\n@vikramkoka This breaking change has been intentionally planned for Airflow 3.0.', 'created_at': datetime.datetime(2024, 11, 20, 5, 24, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488328646, 'issue_id': 2561174261, 'author': 'ashb', 'body': '@dirrao why? Was there a mailing list discussion about it?\r\n\r\nIn future please include the ""why"" and the context in the PR descriptions. Right now we are in the dark as to the reason for this change! \r\n\r\nReviwers @potiuk @o-nikolas @vincbeck: Please can we be better about enforcing what we say we want out of PRs: https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst\r\n\r\n> * Adhere to guidelines for commit messages described in this [article](https://cbea.ms/git-commit/). This makes the lives of those who come after you (and your future self) a lot easier.', 'created_at': datetime.datetime(2024, 11, 20, 11, 27, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489946007, 'issue_id': 2561174261, 'author': 'potiuk', 'body': ""> Reviwers @potiuk @o-nikolas @vincbeck: Please can we be better about enforcing what we say we want out of PRs:\r\n\r\nSure, I am all for it. and usually do. But when you review 1000 PRs, sometimes one or two slip through. When you review almost none, it's far less easy to make such mistake for sure.\r\n\r\nThings like that happen especially when you review many PRs and I hope we can get a fair share of those reviewed by everyone. \r\n\r\nIf that is a consistent problem rather than one time problem, it's indeed good to address it. But (unless there is some data about it) I think we are good in pointing out whys to be perfectly honest.\r\n\r\n@ashb  do you think we have a consistent problem with it (what?) and that we should do some change rather than pointing three people in single PR that exhibited that behaviour?"", 'created_at': datetime.datetime(2024, 11, 21, 2, 38, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489959330, 'issue_id': 2561174261, 'author': 'potiuk', 'body': ""> @dstandish\r\n> Can anyone comment on why we are doing this?\r\n> @vikramkoka\r\n> @dirrao Why did we make a breaking change here?\r\n\r\n@vikramkoka @dirrao I made a very quick check now and quick git blame on that #TODO shows it was added by @jedcunningham here https://github.com/apache/airflow/pull/26357 explaining why the #TODO was there and mentions previous attempt of doing it https://github.com/apache/airflow/pull/25978  - and I also suggest to look for those things when you look for sources, because we are all humans and make mistakes and it only takes a very little (took me about 2 minutes). search through our repository if we accidentally missed that newsfragment here - without unnecesary raising the tone of the discussion and finger-pointing people. I think it's a good thing that we collaborate here, and cover each-others' back when we make mistake rather than point at them. \r\n\r\nAnd yes, if it is still legitimate (@jedcunningham ?) It should be included in newsfragment (and this is what we all forgot to ask @dirrao to do here - althought in probably other 500 of those we did not).\r\n\r\nI simply thing collaboration and gentle - possibly even humorous - way of pointing out mistakes rather than fingerpointing is a better way to build collaboration spirit."", 'created_at': datetime.datetime(2024, 11, 21, 2, 52, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489963113, 'issue_id': 2561174261, 'author': 'potiuk', 'body': ""BTW. Pretty much always when I fix someone's mistake (including mine) I say PR #XYZ introduced the problem that I found and fixed. I pretty much never write **this person here** made a mistake. Highly recommend that approach as well"", 'created_at': datetime.datetime(2024, 11, 21, 2, 56, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491339591, 'issue_id': 2561174261, 'author': 'dirrao', 'body': '> @dirrao why? Was there a mailing list discussion about it?\r\n> \r\n> In future please include the ""why"" and the context in the PR descriptions. Right now we are in the dark as to the reason for this change!\r\n> \r\n> > * Adhere to guidelines for commit messages described in this [article](https://cbea.ms/git-commit/). This makes the lives of those who come after you (and your future self) a lot easier.\r\n\r\nThank you for the feedback, and I completely understand the concern about the lack of context in the PR description.\r\n\r\nTo clarify, this change was made based on the comment in the code:\r\n`TODO: convert this to a positional arg in Airflow 3.`\r\n\r\nMoving forward, future PRs will include detailed explanations of the ""why"" and any relevant context. Please let me know if there’s anything I might have missed or any additional action required on my side.\r\n\r\nThank you for highlighting this.', 'created_at': datetime.datetime(2024, 11, 21, 14, 19, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491574985, 'issue_id': 2561174261, 'author': 'jedcunningham', 'body': 'I think we should be critical of all ""TODOs"" etc that were tagged for Airflow 3. We should view them as ideas for potential changes, not hard commitments, especially when breaking changes are involved. We\'ve been pretty lax at throwing ""in AF3"" around in the past (which is good imo, dream big).\r\n\r\nIn this specific case, I came in and reverted a breaking change that was already merged. Then I left a breadcrumb that we should consider doing the switch when we are doing breaking changes.\r\n\r\nIf I were writing it from scratch? Positional. Is it worth a breaking change for users? Maybe? But we\'ve been more breaking-change-adverse than I imagined we would be 2 years ago, so maybe not.', 'created_at': datetime.datetime(2024, 11, 21, 15, 40, 45, tzinfo=datetime.timezone.utc)}]","dstandish on (2024-11-19 23:14:01 UTC): Can anyone comment on why we are doing this?

vikramkoka on (2024-11-19 23:17:51 UTC): @dirrao Why did we make a breaking change here?

dirrao (Issue Creator) on (2024-11-20 05:24:37 UTC): @vikramkoka This breaking change has been intentionally planned for Airflow 3.0.

ashb on (2024-11-20 11:27:46 UTC): @dirrao why? Was there a mailing list discussion about it?

In future please include the ""why"" and the context in the PR descriptions. Right now we are in the dark as to the reason for this change! 

Reviwers @potiuk @o-nikolas @vincbeck: Please can we be better about enforcing what we say we want out of PRs: https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst

potiuk on (2024-11-21 02:38:23 UTC): Sure, I am all for it. and usually do. But when you review 1000 PRs, sometimes one or two slip through. When you review almost none, it's far less easy to make such mistake for sure.

Things like that happen especially when you review many PRs and I hope we can get a fair share of those reviewed by everyone. 

If that is a consistent problem rather than one time problem, it's indeed good to address it. But (unless there is some data about it) I think we are good in pointing out whys to be perfectly honest.

@ashb  do you think we have a consistent problem with it (what?) and that we should do some change rather than pointing three people in single PR that exhibited that behaviour?

potiuk on (2024-11-21 02:52:32 UTC): @vikramkoka @dirrao I made a very quick check now and quick git blame on that #TODO shows it was added by @jedcunningham here https://github.com/apache/airflow/pull/26357 explaining why the #TODO was there and mentions previous attempt of doing it https://github.com/apache/airflow/pull/25978  - and I also suggest to look for those things when you look for sources, because we are all humans and make mistakes and it only takes a very little (took me about 2 minutes). search through our repository if we accidentally missed that newsfragment here - without unnecesary raising the tone of the discussion and finger-pointing people. I think it's a good thing that we collaborate here, and cover each-others' back when we make mistake rather than point at them. 

And yes, if it is still legitimate (@jedcunningham ?) It should be included in newsfragment (and this is what we all forgot to ask @dirrao to do here - althought in probably other 500 of those we did not).

I simply thing collaboration and gentle - possibly even humorous - way of pointing out mistakes rather than fingerpointing is a better way to build collaboration spirit.

potiuk on (2024-11-21 02:56:20 UTC): BTW. Pretty much always when I fix someone's mistake (including mine) I say PR #XYZ introduced the problem that I found and fixed. I pretty much never write **this person here** made a mistake. Highly recommend that approach as well

dirrao (Issue Creator) on (2024-11-21 14:19:07 UTC): Thank you for the feedback, and I completely understand the concern about the lack of context in the PR description.

To clarify, this change was made based on the comment in the code:
`TODO: convert this to a positional arg in Airflow 3.`

Moving forward, future PRs will include detailed explanations of the ""why"" and any relevant context. Please let me know if there’s anything I might have missed or any additional action required on my side.

Thank you for highlighting this.

jedcunningham on (2024-11-21 15:40:45 UTC): I think we should be critical of all ""TODOs"" etc that were tagged for Airflow 3. We should view them as ideas for potential changes, not hard commitments, especially when breaking changes are involved. We've been pretty lax at throwing ""in AF3"" around in the past (which is good imo, dream big).

In this specific case, I came in and reverted a breaking change that was already merged. Then I left a breadcrumb that we should consider doing the switch when we are doing breaking changes.

If I were writing it from scratch? Positional. Is it worth a breaking change for users? Maybe? But we've been more breaking-change-adverse than I imagined we would be 2 years ago, so maybe not.

"
2560990789,pull_request,closed,,Ignore peformance directory in mypy-airflow pre-commit,"When running the `mypy-airflow` pre-commit with breeze locally, it fails due to the failed checks in the new `performance` directory that it shouldn't cover. This PR excludes it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-10-02 08:46:12+00:00,[],2024-10-02 20:29:59+00:00,2024-10-02 20:29:58+00:00,https://github.com/apache/airflow/pull/42657,"[('area:dev-tools', '')]",[],
2560890289,pull_request,closed,,Fix type-ignore comment for typing changes,"#41429 changed the attribute to be Optional, but did not change the ignore comment correctly to cover this new possibility.",uranusjr,2024-10-02 07:54:09+00:00,[],2024-10-02 08:35:45+00:00,2024-10-02 08:35:44+00:00,https://github.com/apache/airflow/pull/42656,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2560883384,pull_request,closed,,Fix invalid path in lineage.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-10-02 07:49:59+00:00,[],2024-10-02 17:44:46+00:00,2024-10-02 16:07:31+00:00,https://github.com/apache/airflow/pull/42655,"[('kind:documentation', ''), ('area:lineage', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2560851719,pull_request,closed,,ci(basic-tests): add missing standard provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-10-02 07:30:47+00:00,[],2024-10-02 20:33:47+00:00,2024-10-02 11:48:09+00:00,https://github.com/apache/airflow/pull/42654,"[('area:dev-tools', '')]","[{'comment_id': 2387864313, 'issue_id': 2560851719, 'author': 'gopidesupavan', 'body': 'Ah ryt I have added this into bash operator there were tests failing in the pr due to standard procedure not installing, the pr is in review.', 'created_at': datetime.datetime(2024, 10, 2, 8, 4, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387959775, 'issue_id': 2560851719, 'author': 'gopidesupavan', 'body': '#42506 this  has changes to provider manager and bash operator changes, in my opinion it breaks k8s tests also as there is import being used in celery executor utils . Because standard provider not getting installing in the container. It would be better to revert the changes ? \r\nCc: @romsharon98', 'created_at': datetime.datetime(2024, 10, 2, 8, 55, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387973217, 'issue_id': 2560851719, 'author': 'Lee-W', 'body': 'for short term solution, we probably could go with this one. for long term, we will need to add it as fab dep and wait for its release', 'created_at': datetime.datetime(2024, 10, 2, 9, 1, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387979305, 'issue_id': 2560851719, 'author': 'gopidesupavan', 'body': ""https://github.com/apache/airflow/blob/0c911a9d36936d2d0ef1937e33560a30907f30ad/airflow/providers/celery/executors/celery_executor_utils.py#L114 here when bash operator gets imported this would fail because bash operator has imports related to hook? It's like dead lock."", 'created_at': datetime.datetime(2024, 10, 2, 9, 4, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387981658, 'issue_id': 2560851719, 'author': 'gopidesupavan', 'body': '> for short term solution, we probably could go with this one. for long term, we will need to add it as fab dep and wait for its release\r\n\r\nAgree. API client works with this change , but my hunch is on k8s test might fail.', 'created_at': datetime.datetime(2024, 10, 2, 9, 5, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387999058, 'issue_id': 2560851719, 'author': 'gopidesupavan', 'body': ""And docker tests as well... As a workaround I have added skipif here https://github.com/apache/airflow/pull/42252. But don't like skipping these tests not good. It would be better to release the standard provider basic version and installing it default provider lists."", 'created_at': datetime.datetime(2024, 10, 2, 9, 13, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2388286940, 'issue_id': 2560851719, 'author': 'gopidesupavan', 'body': 'Created revert pr https://github.com/apache/airflow/pull/42659', 'created_at': datetime.datetime(2024, 10, 2, 10, 17, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2388446600, 'issue_id': 2560851719, 'author': 'Lee-W', 'body': ""Ok, then let's use the revert commit and close this one. Thanks @gopidesupavan !"", 'created_at': datetime.datetime(2024, 10, 2, 11, 48, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389644726, 'issue_id': 2560851719, 'author': 'potiuk', 'body': 'See the discussion in https://lists.apache.org/thread/1gshy5cjmp9wz5v8dozyh64jj3dyn5s4 - I think we should start releasing "".dev*"" standard provider to PyPI manually to overcome some of the chicken-egg problems experienced here and avoiding the neeed for ""skip-if""', 'created_at': datetime.datetime(2024, 10, 2, 20, 32, 1, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-02 08:04:35 UTC): Ah ryt I have added this into bash operator there were tests failing in the pr due to standard procedure not installing, the pr is in review.

gopidesupavan on (2024-10-02 08:55:03 UTC): #42506 this  has changes to provider manager and bash operator changes, in my opinion it breaks k8s tests also as there is import being used in celery executor utils . Because standard provider not getting installing in the container. It would be better to revert the changes ? 
Cc: @romsharon98

Lee-W (Issue Creator) on (2024-10-02 09:01:44 UTC): for short term solution, we probably could go with this one. for long term, we will need to add it as fab dep and wait for its release

gopidesupavan on (2024-10-02 09:04:11 UTC): https://github.com/apache/airflow/blob/0c911a9d36936d2d0ef1937e33560a30907f30ad/airflow/providers/celery/executors/celery_executor_utils.py#L114 here when bash operator gets imported this would fail because bash operator has imports related to hook? It's like dead lock.

gopidesupavan on (2024-10-02 09:05:17 UTC): Agree. API client works with this change , but my hunch is on k8s test might fail.

gopidesupavan on (2024-10-02 09:13:58 UTC): And docker tests as well... As a workaround I have added skipif here https://github.com/apache/airflow/pull/42252. But don't like skipping these tests not good. It would be better to release the standard provider basic version and installing it default provider lists.

gopidesupavan on (2024-10-02 10:17:49 UTC): Created revert pr https://github.com/apache/airflow/pull/42659

Lee-W (Issue Creator) on (2024-10-02 11:48:09 UTC): Ok, then let's use the revert commit and close this one. Thanks @gopidesupavan !

potiuk on (2024-10-02 20:32:01 UTC): See the discussion in https://lists.apache.org/thread/1gshy5cjmp9wz5v8dozyh64jj3dyn5s4 - I think we should start releasing "".dev*"" standard provider to PyPI manually to overcome some of the chicken-egg problems experienced here and avoiding the neeed for ""skip-if""

"
2560818360,pull_request,closed,,Add/fix druid connector HTTPS tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

TBD

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Rasnar,2024-10-02 07:08:32+00:00,[],2024-10-02 07:39:36+00:00,2024-10-02 07:39:36+00:00,https://github.com/apache/airflow/pull/42653,"[('area:providers', ''), ('provider:apache-druid', '')]","[{'comment_id': 2387772006, 'issue_id': 2560818360, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 2, 7, 8, 36, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-02 07:08:36 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2560796681,pull_request,closed,,[BACKPORT] Add retry logic in the scheduler for updating trigger timeouts in case of deadlocks. (#41429),"backports: #41429

(cherry picked from commit 00589cf8fe8faffa6f994e9b85717cb2babc1631)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-10-02 06:54:03+00:00,[],2024-10-23 09:18:18+00:00,2024-10-02 17:44:29+00:00,https://github.com/apache/airflow/pull/42651,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2387819995, 'issue_id': 2560796681, 'author': 'shahar1', 'body': 'Checking regarding the mypy errors.\r\nEdit: backporting #42656 should fix it.', 'created_at': datetime.datetime(2024, 10, 2, 7, 39, 13, tzinfo=datetime.timezone.utc)}]","shahar1 (Issue Creator) on (2024-10-02 07:39:13 UTC): Checking regarding the mypy errors.
Edit: backporting #42656 should fix it.

"
2560707724,pull_request,closed,,Make `private_key_content` a sensitive field  in Snowflake connection,"closes #42496 

updates private_key_content of Snowflake connection to  be a sensitive field by using  `BS3PasswordFieldWidget` and `PasswordField` ",rawwar,2024-10-02 05:34:42+00:00,[],2024-10-02 20:29:31+00:00,2024-10-02 20:29:31+00:00,https://github.com/apache/airflow/pull/42649,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]",[],
2560651587,pull_request,closed,,Removed deprectaed extras dict from hatch build,Removed deprectaed extras dict from hatch build,dirrao,2024-10-02 04:29:35+00:00,['dirrao'],2024-10-06 08:12:39+00:00,2024-10-06 08:12:39+00:00,https://github.com/apache/airflow/pull/42647,"[('airflow3.0:candidate', 'Potential candidates for Airflow 3.0'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2391893233, 'issue_id': 2560651587, 'author': 'vincbeck', 'body': 'Do we need a newsfragment?', 'created_at': datetime.datetime(2024, 10, 3, 16, 56, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392626472, 'issue_id': 2560651587, 'author': 'potiuk', 'body': '> Do we need a newsfragment?\r\n\r\nYeah. Good point.', 'created_at': datetime.datetime(2024, 10, 4, 1, 38, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394870036, 'issue_id': 2560651587, 'author': 'dirrao', 'body': '> newsfragment missing.\r\n\r\nDone.', 'created_at': datetime.datetime(2024, 10, 5, 2, 35, 28, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-10-03 16:56:46 UTC): Do we need a newsfragment?

potiuk on (2024-10-04 01:38:53 UTC): Yeah. Good point.

dirrao (Issue Creator) on (2024-10-05 02:35:28 UTC): Done.

"
2560586210,pull_request,closed,,"Revert ""Fix the order of tasks during serialization (#42219)""","This reverts commit adb9466bd7ce1c92e51f11a90d39fd557c99dc5b a.k.a. PR #42219, which was causing tests to fail.
",dstandish,2024-10-02 03:08:32+00:00,[],2024-10-02 12:58:05+00:00,2024-10-02 04:35:14+00:00,https://github.com/apache/airflow/pull/42646,"[('area:serialization', '')]","[{'comment_id': 2387759168, 'issue_id': 2560586210, 'author': 'millin', 'body': '@dstandish Hi! which test failed?', 'created_at': datetime.datetime(2024, 10, 2, 7, 0, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2388582944, 'issue_id': 2560586210, 'author': 'dstandish', 'body': '@millin this one tests/api_connexion/endpoints/test_task_instance_endpoint.py', 'created_at': datetime.datetime(2024, 10, 2, 12, 58, 4, tzinfo=datetime.timezone.utc)}]","millin on (2024-10-02 07:00:22 UTC): @dstandish Hi! which test failed?

dstandish (Issue Creator) on (2024-10-02 12:58:04 UTC): @millin this one tests/api_connexion/endpoints/test_task_instance_endpoint.py

"
2560566764,pull_request,closed,,Add support for PostgreSQL 17 in Breeze,,jedcunningham,2024-10-02 02:47:16+00:00,[],2024-10-02 16:36:30+00:00,2024-10-02 16:36:30+00:00,https://github.com/apache/airflow/pull/42644,"[('area:dev-tools', '')]",[],
2560549823,pull_request,closed,,Removed deprecated k8s rendering methods from task instance module,Removed deprecated k8s rendering methods from task instance module,dirrao,2024-10-02 02:26:22+00:00,['dirrao'],2024-10-07 05:10:02+00:00,2024-10-07 05:10:02+00:00,https://github.com/apache/airflow/pull/42641,[],"[{'comment_id': 2387680123, 'issue_id': 2560549823, 'author': 'dirrao', 'body': 'The test is passing locally but failing in this environment. Can someone assist with troubleshooting this issue?', 'created_at': datetime.datetime(2024, 10, 2, 5, 50, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390305618, 'issue_id': 2560549823, 'author': 'potiuk', 'body': 'Tests are failing :(', 'created_at': datetime.datetime(2024, 10, 3, 1, 10, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395292015, 'issue_id': 2560549823, 'author': 'dirrao', 'body': '> Tests are failing :(\r\n\r\nDone', 'created_at': datetime.datetime(2024, 10, 6, 4, 43, 51, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-10-02 05:50:47 UTC): The test is passing locally but failing in this environment. Can someone assist with troubleshooting this issue?

potiuk on (2024-10-03 01:10:09 UTC): Tests are failing :(

dirrao (Issue Creator) on (2024-10-06 04:43:51 UTC): Done

"
2560539798,pull_request,closed,,Removed unused and deprecated custom dag dependancy detector from serialization,Removed unused and deprecated custom dag dependancy detector from serialization,dirrao,2024-10-02 02:14:31+00:00,['dirrao'],2024-10-04 07:29:29+00:00,2024-10-04 07:29:29+00:00,https://github.com/apache/airflow/pull/42640,"[('area:serialization', '')]","[{'comment_id': 2390335527, 'issue_id': 2560539798, 'author': 'potiuk', 'body': 'Needs a newsfragment', 'created_at': datetime.datetime(2024, 10, 3, 1, 47, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392879876, 'issue_id': 2560539798, 'author': 'dirrao', 'body': '> Needs a newsfragment\r\n\r\nAdded...', 'created_at': datetime.datetime(2024, 10, 4, 5, 56, 29, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-03 01:47:10 UTC): Needs a newsfragment

dirrao (Issue Creator) on (2024-10-04 05:56:29 UTC): Added...

"
2560310083,pull_request,closed,,Limit branches for pull request target workflow,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-01 22:16:38+00:00,[],2024-10-02 08:50:13+00:00,2024-10-02 08:50:12+00:00,https://github.com/apache/airflow/pull/42635,"[('area:dev-tools', '')]",[],
2560253244,pull_request,closed,,Set up JWT token authentication in Fast APIs,"## Goal

Set-up authentication using JWT token in UI API. The UI API should be protected hy authentication using JWT token. This PR creates the logic behind JWT token authentication.

## What is done?

- Authentication logic using JWT token

## What has been done but is not in this PR?

- Authentication done for the 2 endpoints in `airflow/api_fastapi/views/public/dags.py`. I am aware this is the public API and not the UI API but this is just for testing.
- Manual testing using these 2 endpoints

The reason why I did not include these changes in the PR is we need first the UI to pass down the token to the API. Otherwise all APIs will fail. I'll create follow-up PRs once the new UI handle the token.

## What is not done?

The actual JWT auth-backend. This can be done in a separate PR once this one is merged so for the sake of keeping a PR as small as possible, I'll do it in a separate PR

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-01 21:34:03+00:00,[],2024-11-19 19:57:18+00:00,2024-11-19 19:57:15+00:00,https://github.com/apache/airflow/pull/42634,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2388715207, 'issue_id': 2560253244, 'author': 'vincbeck', 'body': 'I think we want to deprecate and then remove the session auth backend?', 'created_at': datetime.datetime(2024, 10, 2, 13, 57, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399872797, 'issue_id': 2560253244, 'author': 'pierrejeambrun', 'body': ""> UI API use JWT token authentication only (no way to configure it from the user)?\r\nPublic API uses the auth backends specify in [auth_backends](https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/auth-manager/api-authentication.html)? We want to add JWT token as possible auth backend (separate PR)\r\n\r\nI would say yes. The front end uses `JWT Token` for accessing both `Public` and `Private` API. (because the front-end will call both APIs, so basically JWT should always be in the `auth.backends` at least for the UI to work, otherwise it can be modified but the front-end using JWT won't work.\r\n\r\nYes public API can specify additional backends if needed by the user. (But the front-end is always using the JWT one). This will be for custom front-end or API calls made by other clients that desieres an other authentication schema.\r\n\r\nTo summarize my idea:\r\n- Public API takes 'auth_backends` iterates on it and check if one of them has auth (similar to what we have for the legacy one)\r\n- Private/Public API only needs to support JWT auth backend (but making a difference between public and private might actually be more work, doing the same as what we have for the public one might be easier, but is not required)\r\n- Front end only uses JWT security schema to communicate with the backend for both public and UI API\r\n- Other clients of the API uses any configured auth schema to authenticate to the public API.\r\n\r\n\r\nIf that's too much work, we can at first only support JWT Oauth for the new API (both public and UI). And add more backends in 3.x. I don't know how critical it is to have that in the initial airflow 3 release."", 'created_at': datetime.datetime(2024, 10, 8, 13, 36, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415232610, 'issue_id': 2560253244, 'author': 'vincbeck', 'body': '@ashb @potiuk Question for you. Since we want to create a new major version of FAB provider that would only be compatible with Airflow 3, I do not need to work on the compat tests failures right? They are failing because I introduced some breaking changes in the auth manager interface so the FAB auth manager is no longer compatible with the auth manager interface from Airflow 2.X', 'created_at': datetime.datetime(2024, 10, 15, 21, 53, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2415232832, 'issue_id': 2560253244, 'author': 'vincbeck', 'body': 'Ready for review @pierrejeambrun', 'created_at': datetime.datetime(2024, 10, 15, 21, 54, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419963588, 'issue_id': 2560253244, 'author': 'vincbeck', 'body': ""> If that's too much work, we can at first only support JWT Oauth for the new API (both public and UI). And add more backends in 3.x. I don't know how critical it is to have that in the initial airflow 3 release.\r\n\r\nI have been trying and experimenting to support auth backends in the public API in FastApi and I am still unsure it is possible to support them in FastApi. `session`, `basic_auth` and `kerberos` are heavily dependent on Flask and require a Flask application created in order to work. So I am wondering if JWT should not be the only way to authenticate to UI and public API.\r\n\r\nIf we go that direction we would have to create an API to create a token. Here is an example of flow:\r\n\r\n- As a user, I want to use the public API, to do that I need a JWT token\r\n- I call an api like `POST /public/token` with authentication information as part of the body (e.g. username and password)\r\n- If the authentication succeeds, the API returns the JWT token\r\n- With this token I can call the public API"", 'created_at': datetime.datetime(2024, 10, 17, 16, 12, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419992578, 'issue_id': 2560253244, 'author': 'pierrejeambrun', 'body': 'Yes, we can use a flask server as our airflow `authentication` server. FastAPI or any other service that want to auth on airflow can use it.\r\n\r\nIt will also be useful at first to still have a flask server somewhere for old plugins backward compatibility.', 'created_at': datetime.datetime(2024, 10, 17, 16, 26, 13, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-10-02 13:57:33 UTC): I think we want to deprecate and then remove the session auth backend?

pierrejeambrun on (2024-10-08 13:36:46 UTC): Public API uses the auth backends specify in [auth_backends](https://airflow.apache.org/docs/apache-airflow-providers-fab/stable/auth-manager/api-authentication.html)? We want to add JWT token as possible auth backend (separate PR)

I would say yes. The front end uses `JWT Token` for accessing both `Public` and `Private` API. (because the front-end will call both APIs, so basically JWT should always be in the `auth.backends` at least for the UI to work, otherwise it can be modified but the front-end using JWT won't work.

Yes public API can specify additional backends if needed by the user. (But the front-end is always using the JWT one). This will be for custom front-end or API calls made by other clients that desieres an other authentication schema.

To summarize my idea:
- Public API takes 'auth_backends` iterates on it and check if one of them has auth (similar to what we have for the legacy one)
- Private/Public API only needs to support JWT auth backend (but making a difference between public and private might actually be more work, doing the same as what we have for the public one might be easier, but is not required)
- Front end only uses JWT security schema to communicate with the backend for both public and UI API
- Other clients of the API uses any configured auth schema to authenticate to the public API.


If that's too much work, we can at first only support JWT Oauth for the new API (both public and UI). And add more backends in 3.x. I don't know how critical it is to have that in the initial airflow 3 release.

vincbeck (Issue Creator) on (2024-10-15 21:53:52 UTC): @ashb @potiuk Question for you. Since we want to create a new major version of FAB provider that would only be compatible with Airflow 3, I do not need to work on the compat tests failures right? They are failing because I introduced some breaking changes in the auth manager interface so the FAB auth manager is no longer compatible with the auth manager interface from Airflow 2.X

vincbeck (Issue Creator) on (2024-10-15 21:54:05 UTC): Ready for review @pierrejeambrun

vincbeck (Issue Creator) on (2024-10-17 16:12:28 UTC): I have been trying and experimenting to support auth backends in the public API in FastApi and I am still unsure it is possible to support them in FastApi. `session`, `basic_auth` and `kerberos` are heavily dependent on Flask and require a Flask application created in order to work. So I am wondering if JWT should not be the only way to authenticate to UI and public API.

If we go that direction we would have to create an API to create a token. Here is an example of flow:

- As a user, I want to use the public API, to do that I need a JWT token
- I call an api like `POST /public/token` with authentication information as part of the body (e.g. username and password)
- If the authentication succeeds, the API returns the JWT token
- With this token I can call the public API

pierrejeambrun on (2024-10-17 16:26:13 UTC): Yes, we can use a flask server as our airflow `authentication` server. FastAPI or any other service that want to auth on airflow can use it.

It will also be useful at first to still have a flask server somewhere for old plugins backward compatibility.

"
2560191741,pull_request,closed,,Spot clean try_number references to use ti.try_number,"Some tasks in airflow 2.10.2 are being launched with try number 0. However, the webserver is looking for logs starting with try number 1. Upon further investigation, I suspect that `{try_number}` and `{ti.try_number}` are diverging leading to this. 

This is an attempt to cleanup references to `{try_number}`

related: #42549, #39336
",dheerajturaga,2024-10-01 20:53:06+00:00,[],2024-11-16 04:20:11+00:00,2024-11-16 04:19:54+00:00,https://github.com/apache/airflow/pull/42633,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2387159846, 'issue_id': 2560191741, 'author': 'dstandish', 'body': 'These two values should be the same.  Do you have repro steps to demonstrate that they differ?  Or perhaps a test?', 'created_at': datetime.datetime(2024, 10, 1, 22, 7, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387221041, 'issue_id': 2560191741, 'author': 'dheerajturaga', 'body': '> These two values should be the same. Do you have repro steps to demonstrate that they differ? Or perhaps a test?\r\n\r\nLet me see if I can catch this somehow.', 'created_at': datetime.datetime(2024, 10, 1, 22, 51, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480193801, 'issue_id': 2560191741, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 16, 0, 15, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480391272, 'issue_id': 2560191741, 'author': 'dstandish', 'body': 'Author noted in https://github.com/apache/airflow/issues/42549#issuecomment-2414831492 that this is a false alarm.', 'created_at': datetime.datetime(2024, 11, 16, 4, 19, 54, tzinfo=datetime.timezone.utc)}]","dstandish on (2024-10-01 22:07:08 UTC): These two values should be the same.  Do you have repro steps to demonstrate that they differ?  Or perhaps a test?

dheerajturaga (Issue Creator) on (2024-10-01 22:51:17 UTC): Let me see if I can catch this somehow.

github-actions[bot] on (2024-11-16 00:15:36 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

dstandish on (2024-11-16 04:19:54 UTC): Author noted in https://github.com/apache/airflow/issues/42549#issuecomment-2414831492 that this is a false alarm.

"
2560130698,pull_request,closed,,AIP-84 Migrate the public endpoint DAG Details to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

Closes: #42453 
Related: #42370 

This migrates the Get DAG Details API from `api_connexion` to `api_fastapi`.",omkar-foss,2024-10-01 20:14:50+00:00,[],2024-10-09 07:43:06+00:00,2024-10-03 08:38:01+00:00,https://github.com/apache/airflow/pull/42631,"[('area:API', ""Airflow's REST/HTTP API""), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2389822096, 'issue_id': 2560130698, 'author': 'omkar-foss', 'body': ""> Thanks for the PR! A few suggestions but overall code looks good :)\r\n\r\nThank you for the review! I've updated the PR as per your comments. All checks have passed and PR is ready for (re-)review."", 'created_at': datetime.datetime(2024, 10, 2, 22, 48, 31, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-10-02 22:48:31 UTC): Thank you for the review! I've updated the PR as per your comments. All checks have passed and PR is ready for (re-)review.

"
2560094742,pull_request,closed,,send notification to internal-ci-cd channel,"related: https://github.com/apache/airflow/pull/42394
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-10-01 19:57:12+00:00,[],2024-10-01 21:49:57+00:00,2024-10-01 20:05:46+00:00,https://github.com/apache/airflow/pull/42630,"[('area:dev-tools', '')]","[{'comment_id': 2387138713, 'issue_id': 2560094742, 'author': 'potiuk', 'body': 'Cool.', 'created_at': datetime.datetime(2024, 10, 1, 21, 49, 56, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-01 21:49:56 UTC): Cool.

"
2560046941,pull_request,closed,,AIP-84 Migrate views /object/historical_metrics_data to Fast API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Closes: #42623


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-10-01 19:37:20+00:00,[],2024-10-09 08:09:40+00:00,2024-10-09 08:09:40+00:00,https://github.com/apache/airflow/pull/42629,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2390731253, 'issue_id': 2560046941, 'author': 'bbovenzi', 'body': ""One nit after looking at the autogenerated code. Let's drop the word `data`. Just `historical_metrics`"", 'created_at': datetime.datetime(2024, 10, 3, 7, 39, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396122046, 'issue_id': 2560046941, 'author': 'pierrejeambrun', 'body': '@bugraoz93 can you rebase the branch before I merge please, it is quite behind main. Thanks :)', 'created_at': datetime.datetime(2024, 10, 7, 7, 22, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397478961, 'issue_id': 2560046941, 'author': 'bugraoz93', 'body': 'For sure, @pierrejeambrun, I rebased it. Thanks! :)', 'created_at': datetime.datetime(2024, 10, 7, 17, 17, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397538733, 'issue_id': 2560046941, 'author': 'bugraoz93', 'body': 'Okay, merges after my rebase caused conflicts. Solving them and rebasing again :)', 'created_at': datetime.datetime(2024, 10, 7, 17, 49, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399323316, 'issue_id': 2560046941, 'author': 'bbovenzi', 'body': 'Looks like we need another rebase and then running pre-commit for the auto-generated files.', 'created_at': datetime.datetime(2024, 10, 8, 9, 22, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401043183, 'issue_id': 2560046941, 'author': 'bugraoz93', 'body': 'Rebased and run the hooks.', 'created_at': datetime.datetime(2024, 10, 9, 0, 31, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401043784, 'issue_id': 2560046941, 'author': 'bugraoz93', 'body': 'While running the hooks, a new PR merged. I rebased again just in case. The speed of the development :rocket: :)', 'created_at': datetime.datetime(2024, 10, 9, 0, 32, 13, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-10-03 07:39:25 UTC): One nit after looking at the autogenerated code. Let's drop the word `data`. Just `historical_metrics`

pierrejeambrun on (2024-10-07 07:22:57 UTC): @bugraoz93 can you rebase the branch before I merge please, it is quite behind main. Thanks :)

bugraoz93 (Issue Creator) on (2024-10-07 17:17:13 UTC): For sure, @pierrejeambrun, I rebased it. Thanks! :)

bugraoz93 (Issue Creator) on (2024-10-07 17:49:50 UTC): Okay, merges after my rebase caused conflicts. Solving them and rebasing again :)

bbovenzi on (2024-10-08 09:22:39 UTC): Looks like we need another rebase and then running pre-commit for the auto-generated files.

bugraoz93 (Issue Creator) on (2024-10-09 00:31:33 UTC): Rebased and run the hooks.

bugraoz93 (Issue Creator) on (2024-10-09 00:32:13 UTC): While running the hooks, a new PR merged. I rebased again just in case. The speed of the development :rocket: :)

"
2560018909,pull_request,closed,,Prevent redirect loop on /home with tags/lastrun filters (#42607) (#42609),Backport of #42609 to v2 line,jscheffl,2024-10-01 19:25:46+00:00,[],2024-10-23 09:18:54+00:00,2024-10-02 08:03:41+00:00,https://github.com/apache/airflow/pull/42628,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2559827872,pull_request,closed,,Remove `AIRFLOW_V_2_7_PLUS` constant,"Min airflow version in providers is 2.8, thus this constant is no longer used.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-01 17:37:50+00:00,[],2024-10-02 13:49:25+00:00,2024-10-01 19:37:19+00:00,https://github.com/apache/airflow/pull/42627,"[('area:dev-tools', '')]",[],
2559800989,pull_request,closed,,Upgrade databricks provider dependency databricks-sql-connector to support version >= 3.0,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Updated the dependency constraint for databricks-sql-connector for databricks provider. It updates the databricks-sql-connector dependency to support version >= 3.0 which is released on Nov 17, 2023. 
Upgrading to version >= 3.0 is crucial for compatibility with other packages, especially dbt, and resolves a blocker impacting many users' workflows.
closes: https://github.com/apache/airflow/issues/39274



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rubanolha,2024-10-01 17:21:14+00:00,[],2024-11-26 18:40:19+00:00,2024-11-26 18:40:19+00:00,https://github.com/apache/airflow/pull/42626,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2386560226, 'issue_id': 2559800989, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 1, 17, 21, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2386736303, 'issue_id': 2559800989, 'author': 'rubanolha', 'body': 'As sqlalchemy is [optional](https://github.com/databricks/databricks-sql-python/blame/main/pyproject.toml#L26-L26C55) for databricks-sql-connector starting from v3.0.0, the expectation that it will not be blocked by [deprecations](https://github.com/apache/airflow/issues/28723) of SQLAlchemy 2.', 'created_at': datetime.datetime(2024, 10, 1, 18, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408772646, 'issue_id': 2559800989, 'author': 'potiuk', 'body': 'Checks are failing', 'created_at': datetime.datetime(2024, 10, 13, 1, 14, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435099803, 'issue_id': 2559800989, 'author': 'potiuk', 'body': 'You need to rebase, and fix static checks that are resulting from switching to the new databricks provider.', 'created_at': datetime.datetime(2024, 10, 24, 12, 5, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501673863, 'issue_id': 2559800989, 'author': 'eladkal', 'body': 'Solved in https://github.com/apache/airflow/pull/43272', 'created_at': datetime.datetime(2024, 11, 26, 18, 40, 19, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-01 17:21:18 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

rubanolha (Issue Creator) on (2024-10-01 18:56:00 UTC): As sqlalchemy is [optional](https://github.com/databricks/databricks-sql-python/blame/main/pyproject.toml#L26-L26C55) for databricks-sql-connector starting from v3.0.0, the expectation that it will not be blocked by [deprecations](https://github.com/apache/airflow/issues/28723) of SQLAlchemy 2.

potiuk on (2024-10-13 01:14:39 UTC): Checks are failing

potiuk on (2024-10-24 12:05:57 UTC): You need to rebase, and fix static checks that are resulting from switching to the new databricks provider.

eladkal on (2024-11-26 18:40:19 UTC): Solved in https://github.com/apache/airflow/pull/43272

"
2559647964,pull_request,closed,,option to enable ipv6 ipaddress resolve support for statsd host,"
---
Currently we are using Ipv6 only Kubernetes Cluster. When we step up statsd exporter, we experienced issue with metrics unable to be delivered to Prometheus. with some digging, we notice the statsdclient has ipv6 disabled by default: https://github.com/jsocol/pystatsd/blob/main/statsd/client/udp.py#L31. 

we want to add an config parameter to enable ipv6 for statsd resolving. 

",kongdewen,2024-10-01 15:56:38+00:00,[],2024-10-04 01:49:20+00:00,2024-10-04 01:49:19+00:00,https://github.com/apache/airflow/pull/42625,"[('area:helm-chart', 'Airflow Helm Chart'), ('kind:documentation', '')]",[],
2559635055,pull_request,closed,,[KubernetesExecutor] Don't skip succeeded status,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR implements the fix proposed in #41436 and guards against duplicated success messages by having `_change_state()` in the KubernetesExecutor only emit to the `event_buffer` if the task is in `self.running`,
as proposed by @jedcunningham in #40516.

closes: #40516, closes #41436

<!-- Please keep an empty line above the dashes. 
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
-->",vlieven,2024-10-01 15:50:17+00:00,[],2024-10-11 15:12:38+00:00,2024-10-11 15:12:35+00:00,https://github.com/apache/airflow/pull/42624,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2386381137, 'issue_id': 2559635055, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 1, 15, 50, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2396858936, 'issue_id': 2559635055, 'author': 'vlieven', 'body': 'Sorry about that! I removed the broken test, and added a new one to check that no event is emitted when the task key is not present in `running`.', 'created_at': datetime.datetime(2024, 10, 7, 12, 57, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403620283, 'issue_id': 2559635055, 'author': 'RNHTTR', 'body': ""@vlieven can you please resolve the merge conflicts? I believe this is caused by providers being moved to the root of the project. We'll probably also want a backport PR."", 'created_at': datetime.datetime(2024, 10, 9, 23, 34, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404632551, 'issue_id': 2559635055, 'author': 'vlieven', 'body': 'Hi @RNHTTR, I rebased the changes, should be good again now.\r\nCould you point me to what is expected as backport PR?', 'created_at': datetime.datetime(2024, 10, 10, 9, 55, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407427319, 'issue_id': 2559635055, 'author': 'RNHTTR', 'body': '> Hi @RNHTTR, I rebased the changes, should be good again now. Could you point me to what is expected as backport PR?\r\n\r\nI believe you just need to create a new branch against `v2-10-test` (not `main`), run `git cherry-pick <commit>` (you can find the commit ID in the PR where it says “merge commit <commit> into main”), and creating a new PR with thie new branch.', 'created_at': datetime.datetime(2024, 10, 11, 13, 33, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407472989, 'issue_id': 2559635055, 'author': 'eladkal', 'body': '> > Hi @RNHTTR, I rebased the changes, should be good again now. Could you point me to what is expected as backport PR?\r\n> \r\n> I believe you just need to create a new branch against `v2-10-test` (not `main`), run `git cherry-pick <commit>` (you can find the commit ID in the PR where it says “merge commit into main”), and creating a new PR with thie new branch.\r\n\r\nWhy? This is provider only change. PR is against main branch and that is how it should be.', 'created_at': datetime.datetime(2024, 10, 11, 13, 56, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407598000, 'issue_id': 2559635055, 'author': 'RNHTTR', 'body': '> > > Hi @RNHTTR, I rebased the changes, should be good again now. Could you point me to what is expected as backport PR?\r\n> > \r\n> > \r\n> > I believe you just need to create a new branch against `v2-10-test` (not `main`), run `git cherry-pick <commit>` (you can find the commit ID in the PR where it says “merge commit into main”), and creating a new PR with thie new branch.\r\n> \r\n> Why? This is provider only change. PR is against main branch and that is how it should be.\r\n\r\nOh, duh, sorry about that.', 'created_at': datetime.datetime(2024, 10, 11, 15, 0, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407621445, 'issue_id': 2559635055, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 11, 15, 12, 37, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-01 15:50:23 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

vlieven (Issue Creator) on (2024-10-07 12:57:43 UTC): Sorry about that! I removed the broken test, and added a new one to check that no event is emitted when the task key is not present in `running`.

RNHTTR on (2024-10-09 23:34:42 UTC): @vlieven can you please resolve the merge conflicts? I believe this is caused by providers being moved to the root of the project. We'll probably also want a backport PR.

vlieven (Issue Creator) on (2024-10-10 09:55:11 UTC): Hi @RNHTTR, I rebased the changes, should be good again now.
Could you point me to what is expected as backport PR?

RNHTTR on (2024-10-11 13:33:26 UTC): I believe you just need to create a new branch against `v2-10-test` (not `main`), run `git cherry-pick <commit>` (you can find the commit ID in the PR where it says “merge commit <commit> into main”), and creating a new PR with thie new branch.

eladkal on (2024-10-11 13:56:53 UTC): Why? This is provider only change. PR is against main branch and that is how it should be.

RNHTTR on (2024-10-11 15:00:08 UTC): Oh, duh, sorry about that.

boring-cyborg[bot] on (2024-10-11 15:12:37 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2559404431,pull_request,closed,,Use FAB auth manager in `test_google_openid`,"The auth backend Google OpenID relies on FAB auth manager. As such, explicitly set in `test_google_openid` to use the FAB auth manager. This is part of the effort of not assuming FAB auth manager is the default one.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-10-01 14:23:25+00:00,[],2024-10-02 13:48:35+00:00,2024-10-02 13:48:33+00:00,https://github.com/apache/airflow/pull/42622,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2559241352,pull_request,closed,,Add is_paused toggle,"Add switch to toggle DAGs paused and unpaused. I decided to use ""enabled"" and ""disabled"" nomenclature as discussed in https://github.com/apache/airflow/issues/41519, but happy to adjust this.

Also had to add a fix to an outdated eslint rule.

<img width=""654"" alt=""Screenshot 2024-10-01 at 3 24 08 PM"" src=""https://github.com/user-attachments/assets/8670f9dc-720a-4604-8a03-3aa87c18fae6"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-10-01 13:26:41+00:00,[],2024-10-02 09:08:55+00:00,2024-10-02 09:08:53+00:00,https://github.com/apache/airflow/pull/42621,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2387934403, 'issue_id': 2559241352, 'author': 'pierrejeambrun', 'body': ""Code looks good and is working as expected.\r\n\r\nI'm fine with both `enabled/etcc` or `unpaused/etc...`, leaving that up to you guys :)"", 'created_at': datetime.datetime(2024, 10, 2, 8, 41, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387988783, 'issue_id': 2559241352, 'author': 'bbovenzi', 'body': ""> Code looks good and is working as expected.\r\n> \r\n> I'm fine with both `enabled/etcc` or `unpaused/etc...`, leaving that up to you guys :)\r\n\r\nGoing to merge so we have examples of PATCH requests in the UI. We can always update the naming scheme later."", 'created_at': datetime.datetime(2024, 10, 2, 9, 8, 49, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-10-02 08:41:37 UTC): Code looks good and is working as expected.

I'm fine with both `enabled/etcc` or `unpaused/etc...`, leaving that up to you guys :)

bbovenzi (Issue Creator) on (2024-10-02 09:08:49 UTC): Going to merge so we have examples of PATCH requests in the UI. We can always update the naming scheme later.

"
2559085297,pull_request,closed,,"Show ""Task Tries"" items after rerun","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:



How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42357


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-10-01 12:30:51+00:00,[],2024-10-03 08:59:24+00:00,2024-10-01 14:06:35+00:00,https://github.com/apache/airflow/pull/42620,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2559022894,pull_request,closed,,[DatabricksHook] Respect connection settings,"Avoids hard-coding URL schema and port while allowed to be edited in the Connections dialog. Allows utilizing the hooks against (local) mock servers with less of complications.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",xitep,2024-10-01 12:03:28+00:00,[],2024-10-21 18:22:48+00:00,2024-10-21 13:08:06+00:00,https://github.com/apache/airflow/pull/42618,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2425122726, 'issue_id': 2559022894, 'author': 'romsharon98', 'body': 'Can you add ut?', 'created_at': datetime.datetime(2024, 10, 20, 17, 0, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2425128125, 'issue_id': 2559022894, 'author': 'xitep', 'body': '""ut""?', 'created_at': datetime.datetime(2024, 10, 20, 17, 7, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2425131435, 'issue_id': 2559022894, 'author': 'romsharon98', 'body': '> ""ut""?\n\nUnit tests 😄', 'created_at': datetime.datetime(2024, 10, 20, 17, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426075094, 'issue_id': 2559022894, 'author': 'xitep', 'body': ""i'm a bit lost with this [failing check](https://github.com/apache/airflow/actions/runs/11436392514/job/31814800750). any help would be appreciated."", 'created_at': datetime.datetime(2024, 10, 21, 9, 10, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426199346, 'issue_id': 2559022894, 'author': 'romsharon98', 'body': ""> i'm a bit lost with this [failing check](https://github.com/apache/airflow/actions/runs/11436392514/job/31814800750). any help would be appreciated.\r\n\r\nit's not your fault.\r\nthere is an open issue about it.\r\n\r\nhttps://github.com/pallets-eco/wtforms/issues/861"", 'created_at': datetime.datetime(2024, 10, 21, 9, 57, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2426695150, 'issue_id': 2559022894, 'author': 'xitep', 'body': 'merci beaucoup for your support @romsharon98 !', 'created_at': datetime.datetime(2024, 10, 21, 13, 31, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2427418958, 'issue_id': 2559022894, 'author': 'romsharon98', 'body': ""> merci beaucoup for your support @romsharon98 !\n\nYou're welcome! Glad I could assist."", 'created_at': datetime.datetime(2024, 10, 21, 18, 22, 46, tzinfo=datetime.timezone.utc)}]","romsharon98 on (2024-10-20 17:00:56 UTC): Can you add ut?

xitep (Issue Creator) on (2024-10-20 17:07:07 UTC): ""ut""?

romsharon98 on (2024-10-20 17:09:38 UTC): Unit tests 😄

xitep (Issue Creator) on (2024-10-21 09:10:06 UTC): i'm a bit lost with this [failing check](https://github.com/apache/airflow/actions/runs/11436392514/job/31814800750). any help would be appreciated.

romsharon98 on (2024-10-21 09:57:55 UTC): it's not your fault.
there is an open issue about it.

https://github.com/pallets-eco/wtforms/issues/861

xitep (Issue Creator) on (2024-10-21 13:31:08 UTC): merci beaucoup for your support @romsharon98 !

romsharon98 on (2024-10-21 18:22:46 UTC): You're welcome! Glad I could assist.

"
2558736086,pull_request,closed,,Small fixes for Google provider's system tests,"This PR removes prefix 'example_' from DAG name to follow name convention, adds comments and define 'default' ENV_ID if not provided.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-10-01 09:50:36+00:00,[],2024-10-03 09:08:54+00:00,2024-10-03 09:08:54+00:00,https://github.com/apache/airflow/pull/42614,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2558647915,pull_request,closed,,Minor changes in the SparkKubernetesOperator documentation.,"1. Update the spark operator user guide link.
2. minor typo.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",damjad,2024-10-01 09:15:15+00:00,[],2024-10-05 07:09:42+00:00,2024-10-05 07:09:38+00:00,https://github.com/apache/airflow/pull/42613,"[('area:providers', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2385247640, 'issue_id': 2558647915, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 1, 9, 15, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394959544, 'issue_id': 2558647915, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 5, 7, 9, 40, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-01 09:15:20 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-10-05 07:09:40 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2558635759,pull_request,closed,,Add AssetActive model,"This tracks asset orphaning like the old is_orphaned flag (but in the other direction, as the name suggests). The difference is that this table also serves as a unique constraint on both the name and URI used by the user is unique across a DAG deployment. This is different from the unique constraint on Asset, which only ensures the name-URI combination is unique.

I also took the chance to also change AssetAlias’s `name` length limit to 1500 to match Asset’s. Not necessary at all, but this probably removes some possibility to confusion? I can remove it if people feel otherwise.",uranusjr,2024-10-01 09:09:55+00:00,[],2024-10-15 03:29:42+00:00,2024-10-15 03:29:40+00:00,https://github.com/apache/airflow/pull/42612,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:serialization', ''), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2386866754, 'issue_id': 2558635759, 'author': 'jscheffl', 'body': ""I don't understandwhy we need another table for this function. Seems to be adding too much complexity. Why not just adding the unique index and a flag for active (potentially with an index on active flag)?"", 'created_at': datetime.datetime(2024, 10, 1, 19, 41, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387268041, 'issue_id': 2558635759, 'author': 'uranusjr', 'body': 'The addition of `name` to Asset makes the unique constraint more complex because we want to keep history of different name-URI combinations. For example, if you have two assets (in the history of the Airflow deployment) at the same S3 location, but used for different purposes, we want to keep the two distinct for history purposes. Conversely, if an asset name is linked to different URIs, we want to keep thw entries distinct too. This means the unique constraint on Asset should be against the `(name, uri)` combination.\r\n\r\nHowever, during one DAG-processing round, we also want to keep one name only used once—otherwise it would be extremely confusing if the user accidentally uses the same name to represent different assets in different DAGs. So we also need to have a unique constraint _only on name if an asset is active_. This is possible with Postgres with `create unique index ... on asset (name) WHERE (is_orphaned = false)`, but not anywhere else. This is what the new table is for—when an asset is in use, it has an entry in AssetActive, and that table enforces uniqueness on `name` (and `uri`, same problem) individually. This essentially also replaces `is_orphaned` (an orphaned asset will not have a corresponding entry in AssetActive), so `is_orphaned` is removed.', 'created_at': datetime.datetime(2024, 10, 1, 23, 38, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389536514, 'issue_id': 2558635759, 'author': 'jscheffl', 'body': '> The addition of `name` to Asset makes the unique constraint more complex because we want to keep history of different name-URI combinations. For example, if you have two assets (in the history of the Airflow deployment) at the same S3 location, but used for different purposes, we want to keep the two distinct for history purposes. Conversely, if an asset name is linked to different URIs, we want to keep thw entries distinct too. This means the unique constraint on Asset should be against the `(name, uri)` combination.\r\n> \r\n> However, during one DAG-processing round, we also want to keep one name only used once—otherwise it would be extremely confusing if the user accidentally uses the same name to represent different assets in different DAGs. So we also need to have a unique constraint _only on name if an asset is active_. This is possible with Postgres with `create unique index ... on asset (name) WHERE (is_orphaned = false)`, but not anywhere else. This is what the new table is for—when an asset is in use, it has an entry in AssetActive, and that table enforces uniqueness on `name` (and `uri`, same problem) individually. This essentially also replaces `is_orphaned` (an orphaned asset will not have a corresponding entry in AssetActive), so `is_orphaned` is removed.\r\n\r\nMhm, okay. But adding the table complexity just because of DB limitations... still I\'d feel a handling on app level is ""cheaper"" than adding an additional shadow table just to push down the constraint handling to DB. That also adds a lot of potential inconsistency and redundancy on DB level.\r\n\r\nNot a fan but if others are OK with I don\'t want to block this. I just ""hurts my eyes"" as a former DBA to see the model.\r\n\r\nOther questions: Is the requirement of the history needed like this or could also the history implemented in another way w/o the need of non-uniqueness?', 'created_at': datetime.datetime(2024, 10, 2, 19, 38, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389797811, 'issue_id': 2558635759, 'author': 'uranusjr', 'body': 'The problem is we can’t do this at the app side. DAG processing may be done in multiple processes, in which cases there’s no single process that has access to know if a name or URI is unique, and the database is the last line to keep the input sane. I guess we can choose to not do the extra table, and always just use `session.scalar(...)` to get _one_ (whichever) object and hope things are somewhat consistent, but I’m not quite sure if that’d be simpler, to be honest.', 'created_at': datetime.datetime(2024, 10, 2, 22, 30, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2398032604, 'issue_id': 2558635759, 'author': 'uranusjr', 'body': 'Oh hey, I managed to fix everything!', 'created_at': datetime.datetime(2024, 10, 7, 22, 27, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412820374, 'issue_id': 2558635759, 'author': 'uranusjr', 'body': 'I made the list comprehension anyway (and rebased).', 'created_at': datetime.datetime(2024, 10, 15, 3, 29, 36, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-10-01 19:41:21 UTC): I don't understandwhy we need another table for this function. Seems to be adding too much complexity. Why not just adding the unique index and a flag for active (potentially with an index on active flag)?

uranusjr (Issue Creator) on (2024-10-01 23:38:56 UTC): The addition of `name` to Asset makes the unique constraint more complex because we want to keep history of different name-URI combinations. For example, if you have two assets (in the history of the Airflow deployment) at the same S3 location, but used for different purposes, we want to keep the two distinct for history purposes. Conversely, if an asset name is linked to different URIs, we want to keep thw entries distinct too. This means the unique constraint on Asset should be against the `(name, uri)` combination.

However, during one DAG-processing round, we also want to keep one name only used once—otherwise it would be extremely confusing if the user accidentally uses the same name to represent different assets in different DAGs. So we also need to have a unique constraint _only on name if an asset is active_. This is possible with Postgres with `create unique index ... on asset (name) WHERE (is_orphaned = false)`, but not anywhere else. This is what the new table is for—when an asset is in use, it has an entry in AssetActive, and that table enforces uniqueness on `name` (and `uri`, same problem) individually. This essentially also replaces `is_orphaned` (an orphaned asset will not have a corresponding entry in AssetActive), so `is_orphaned` is removed.

jscheffl on (2024-10-02 19:38:42 UTC): Mhm, okay. But adding the table complexity just because of DB limitations... still I'd feel a handling on app level is ""cheaper"" than adding an additional shadow table just to push down the constraint handling to DB. That also adds a lot of potential inconsistency and redundancy on DB level.

Not a fan but if others are OK with I don't want to block this. I just ""hurts my eyes"" as a former DBA to see the model.

Other questions: Is the requirement of the history needed like this or could also the history implemented in another way w/o the need of non-uniqueness?

uranusjr (Issue Creator) on (2024-10-02 22:30:51 UTC): The problem is we can’t do this at the app side. DAG processing may be done in multiple processes, in which cases there’s no single process that has access to know if a name or URI is unique, and the database is the last line to keep the input sane. I guess we can choose to not do the extra table, and always just use `session.scalar(...)` to get _one_ (whichever) object and hope things are somewhat consistent, but I’m not quite sure if that’d be simpler, to be honest.

uranusjr (Issue Creator) on (2024-10-07 22:27:33 UTC): Oh hey, I managed to fix everything!

uranusjr (Issue Creator) on (2024-10-15 03:29:36 UTC): I made the list comprehension anyway (and rebased).

"
2558631719,pull_request,closed,,Update providers metadata 2024-10-01,,eladkal,2024-10-01 09:08:06+00:00,[],2024-10-01 15:31:21+00:00,2024-10-01 15:31:17+00:00,https://github.com/apache/airflow/pull/42611,[],[],
2558512802,pull_request,closed,,Prevent redirect loop on /home with tags/lastrun filters (#42607),"See #42607 for details.

closes: #42607
",jmaicher,2024-10-01 08:17:39+00:00,[],2024-10-01 19:23:41+00:00,2024-10-01 19:23:41+00:00,https://github.com/apache/airflow/pull/42609,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2558495458,pull_request,closed,,Update .coveragerc,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-01 08:11:38+00:00,[],2024-10-01 08:16:49+00:00,2024-10-01 08:16:49+00:00,https://github.com/apache/airflow/pull/42608,[],[],
2558486749,pull_request,closed,,Fix oracle bulk insert issue when leftover chunk is empty,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

---
In bulk_insert_rows method of oracle hook, if number of rows is equal to chunk size, then leftover of chunk is 0, and code will fail, I've just checked the size of leftover before executing query.


",mfatemipour,2024-10-01 08:07:20+00:00,[],2024-11-29 15:01:34+00:00,2024-10-29 16:06:50+00:00,https://github.com/apache/airflow/pull/42606,"[('area:providers', ''), ('provider:oracle', '')]","[{'comment_id': 2385075729, 'issue_id': 2558486749, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 10, 1, 8, 7, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387525190, 'issue_id': 2558486749, 'author': 'potiuk', 'body': 'Could you please add unit test for that one?', 'created_at': datetime.datetime(2024, 10, 2, 2, 44, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2440139105, 'issue_id': 2558486749, 'author': 'romsharon98', 'body': 'From what I looked, `row_chunk` can be empty only if `rows` is empty and that cannot happen because an exception will be raised.\r\n\r\nSo this if statement has no effect.', 'created_at': datetime.datetime(2024, 10, 27, 19, 4, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443460141, 'issue_id': 2558486749, 'author': 'mfatemipour', 'body': 'Here if **size of rows is equal to (or a multiple of) commit_every**, then on the last iteration of the loop,`if` statement will be executed and row_chunk will get empty.\r\n```python\r\n        row_count = 0\r\n        # Chunk the rows\r\n        row_chunk = []\r\n        for row in rows:\r\n            row_chunk.append(row)\r\n            row_count += 1\r\n            if row_count % commit_every == 0:\r\n                cursor.prepare(prepared_stm)\r\n                cursor.executemany(None, row_chunk)\r\n                conn.commit()  # type: ignore[attr-defined]\r\n                self.log.info(""[%s] inserted %s rows"", table, row_count)\r\n                # Empty chunk\r\n                row_chunk = []\r\n```', 'created_at': datetime.datetime(2024, 10, 29, 7, 35, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2443871545, 'issue_id': 2558486749, 'author': 'romsharon98', 'body': '> Here if **size of rows is equal to (or a multiple of) commit_every**, then on the last iteration of the loop,`if` statement will be executed and row_chunk will get empty.\r\n> \r\n> ```python\r\n>         row_count = 0\r\n>         # Chunk the rows\r\n>         row_chunk = []\r\n>         for row in rows:\r\n>             row_chunk.append(row)\r\n>             row_count += 1\r\n>             if row_count % commit_every == 0:\r\n>                 cursor.prepare(prepared_stm)\r\n>                 cursor.executemany(None, row_chunk)\r\n>                 conn.commit()  # type: ignore[attr-defined]\r\n>                 self.log.info(""[%s] inserted %s rows"", table, row_count)\r\n>                 # Empty chunk\r\n>                 row_chunk = []\r\n> ```\r\n\r\nOh I missed this, thanks!\r\nI added a tests to this PR with cherry-pick from your commit so it can be merged.\r\nhttps://github.com/apache/airflow/pull/43467', 'created_at': datetime.datetime(2024, 10, 29, 10, 47, 45, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-10-01 08:07:26 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-10-02 02:44:40 UTC): Could you please add unit test for that one?

romsharon98 on (2024-10-27 19:04:46 UTC): From what I looked, `row_chunk` can be empty only if `rows` is empty and that cannot happen because an exception will be raised.

So this if statement has no effect.

mfatemipour (Issue Creator) on (2024-10-29 07:35:31 UTC): Here if **size of rows is equal to (or a multiple of) commit_every**, then on the last iteration of the loop,`if` statement will be executed and row_chunk will get empty.
```python
        row_count = 0
        # Chunk the rows
        row_chunk = []
        for row in rows:
            row_chunk.append(row)
            row_count += 1
            if row_count % commit_every == 0:
                cursor.prepare(prepared_stm)
                cursor.executemany(None, row_chunk)
                conn.commit()  # type: ignore[attr-defined]
                self.log.info(""[%s] inserted %s rows"", table, row_count)
                # Empty chunk
                row_chunk = []
```

romsharon98 on (2024-10-29 10:47:45 UTC): Oh I missed this, thanks!
I added a tests to this PR with cherry-pick from your commit so it can be merged.
https://github.com/apache/airflow/pull/43467

"
2558481364,pull_request,closed,,Update .coveragerc,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-01 08:04:37+00:00,[],2024-10-01 08:12:26+00:00,2024-10-01 08:09:49+00:00,https://github.com/apache/airflow/pull/42605,[],[],
2558367263,pull_request,closed,,Support of host.name in OTEL metrics and usage of OTEL_RESOURCE_ATTRI…,"…BUTES in metrics (#42428)

* fixes: 42425, and 42424

* fixed static type check failure

(cherry picked from commit db06cb8e893addeef4d49479beb1f2387fa63993)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-01 07:05:12+00:00,[],2024-10-23 09:37:57+00:00,2024-10-01 13:07:34+00:00,https://github.com/apache/airflow/pull/42604,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2384961169, 'issue_id': 2558367263, 'author': 'potiuk', 'body': 'Backport of #42428', 'created_at': datetime.datetime(2024, 10, 1, 7, 5, 36, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-01 07:05:36 UTC): Backport of #42428

"
2558314697,pull_request,closed,,Doc update - Airflow local settings no longer importable from dags folder (apache#42231),"Doc update - Airflow local settings no longer importable from dags folder

Co-authored-by: Jishan Garg <jigarg@expediagroup.com>
(cherry picked from commit https://github.com/potiuk/airflow/commit/f4f38f15fe4e6c32614686ceb3b5991dd91ef7ee)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-01 06:34:52+00:00,[],2024-10-23 09:22:35+00:00,2024-10-01 08:01:57+00:00,https://github.com/apache/airflow/pull/42603,"[('area:CLI', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes'), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2384962373, 'issue_id': 2558314697, 'author': 'potiuk', 'body': 'Backport of #42231', 'created_at': datetime.datetime(2024, 10, 1, 7, 6, 20, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-10-01 07:06:20 UTC): Backport of #42231

"
2558314452,pull_request,closed,,add gopidesupavan to triage team,"
cc: @gopidesupavan
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-10-01 06:34:45+00:00,[],2024-10-09 20:16:51+00:00,2024-10-02 20:43:41+00:00,https://github.com/apache/airflow/pull/42602,"[('area:dev-tools', '')]","[{'comment_id': 2384946707, 'issue_id': 2558314452, 'author': 'gopidesupavan', 'body': 'Thank you so much 😄', 'created_at': datetime.datetime(2024, 10, 1, 6, 56, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397697364, 'issue_id': 2558314452, 'author': 'shahar1', 'body': '> Thank you so much 😄\r\n\r\nYou well deserve it - thank you for your contribution!', 'created_at': datetime.datetime(2024, 10, 7, 19, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403352250, 'issue_id': 2558314452, 'author': 'gopidesupavan', 'body': ""> > Thank you so much 😄\r\n> \r\n> You well deserve it - thank you for your contribution!\r\n\r\nI'm really enjoying contributing to Airflow. I'm grateful for all the great support from everyone! 😄 Thank you.."", 'created_at': datetime.datetime(2024, 10, 9, 20, 16, 49, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-10-01 06:56:13 UTC): Thank you so much 😄

shahar1 on (2024-10-07 19:17:00 UTC): You well deserve it - thank you for your contribution!

gopidesupavan on (2024-10-09 20:16:49 UTC): I'm really enjoying contributing to Airflow. I'm grateful for all the great support from everyone! 😄 Thank you..

"
2558166533,pull_request,closed,,Limit build-images workflow to main and v2-10 branches,"There is no need to run image builds for PRs to old branches.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-10-01 04:44:07+00:00,[],2024-10-01 08:02:40+00:00,2024-10-01 08:02:38+00:00,https://github.com/apache/airflow/pull/42601,"[('area:dev-tools', '')]",[],
2557811006,pull_request,closed,,Add dag_id to RemovedInAirflow3 warnings,"# What this does

1. It adds the dag_id in the warnings when a removedInAirflow3Warning is warned.

# Why

1. It makes it much easier to find the dogs impacted by these conditions when their id is included in the warning.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",r-richmond,2024-09-30 23:13:40+00:00,[],2024-10-14 04:04:46+00:00,2024-10-10 03:02:15+00:00,https://github.com/apache/airflow/pull/42599,[],"[{'comment_id': 2384520712, 'issue_id': 2557811006, 'author': 'r-richmond', 'body': 'Mypy check is failing on something unrelated to my changes\r\n\r\none example\r\n\r\n```\r\nairflow/template/templater.py:125: error: Cannot determine type of\r\n""render_template_as_native_obj""  [has-type]\r\n            if dag and dag.render_template_as_native_obj:\r\n```', 'created_at': datetime.datetime(2024, 10, 1, 0, 0, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389973226, 'issue_id': 2557811006, 'author': 'potiuk', 'body': 'Did you cherry-pick it from PR in main? We have the rule that things should be cherry-picked to v2-10-test from main rather than having pulll requests directly to v2-10-test.\r\n\r\nRe: mypy error - likely some other PR needs to be cherry-picked to fix that one, but we will worry about it after this one is confirmed to be merged in `main` first.', 'created_at': datetime.datetime(2024, 10, 2, 23, 26, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390489918, 'issue_id': 2557811006, 'author': 'r-richmond', 'body': ""@potiuk \n\nThe code I'm modifying doesn't exist in main anymore. So at Jed's [suggestion](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1727737690215069?thread_ts=1727737452.143039&channel=C06K9Q5G2UA&message_ts=1727737690.215069) I made it directly to v2-10-test instead."", 'created_at': datetime.datetime(2024, 10, 3, 4, 26, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390521534, 'issue_id': 2557811006, 'author': 'potiuk', 'body': 'Ah. OK then', 'created_at': datetime.datetime(2024, 10, 3, 5, 0, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390700962, 'issue_id': 2557811006, 'author': 'potiuk', 'body': ""BTW. Looks like mypy is confused with types of fields in DAG. I am not sure if that's the best guess but maybe it is caused by using {var=} syntax in f-strings in your PR. While this is added in Python 3.8, it might be that mypy version we are using currently is not yet able to properly parse a file with those f-strings (but this is a wild guess)."", 'created_at': datetime.datetime(2024, 10, 3, 7, 20, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391954190, 'issue_id': 2557811006, 'author': 'r-richmond', 'body': ""F-string = was added in python 3.8\n\nhttps://docs.python.org/3/whatsnew/3.8.html#f-strings-support-for-self-documenting-expressions-and-debugging\n\nAnd the mypy errors are on files this pr hasn't touched.\n\nCan we merge this? Without this logging it's very hard to track down these conditions in an airflow deployment"", 'created_at': datetime.datetime(2024, 10, 3, 17, 30, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391975104, 'issue_id': 2557811006, 'author': 'potiuk', 'body': '> F-string = was added in python 3.8\r\n> https://docs.python.org/3/whatsnew/3.8.html#f-strings-support-for-self-documenting-expressions-and-debugging\r\n\r\nYes I know. I wrete about it above. My guess is that (let me repeat it) maybe MyPy does not handle it way. \r\n\r\nMy GUESS is that this is what causes the issue - becuase while the changes are not in the file you touched they are referring to it (dag).\r\n\r\nNo - we absolutely cannot merge it, because there is a risk it will break main and all other PRs. Surely you would not like it.\r\n\r\n So I recommend to experiment with it a bit and see if my guess is right  - and use pre-3.8 syntax.', 'created_at': datetime.datetime(2024, 10, 3, 17, 41, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391978808, 'issue_id': 2557811006, 'author': 'potiuk', 'body': ""Yeah - I wrote 3.9 but that was a typo. Yep. I checked it was available in 3.8. But ....\r\n\r\n> In theory, practice is the same as theory but in practice it is not\r\n\r\nSo not everything that is done according to standards works and sometimes you need to workaround other people's mistakes."", 'created_at': datetime.datetime(2024, 10, 3, 17, 43, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394871201, 'issue_id': 2557811006, 'author': 'potiuk', 'body': 'Looks it was a bad guess 🤷', 'created_at': datetime.datetime(2024, 10, 5, 2, 40, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394871798, 'issue_id': 2557811006, 'author': 'potiuk', 'body': 'No slightest idea why it fails :)', 'created_at': datetime.datetime(2024, 10, 5, 2, 43, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403843205, 'issue_id': 2557811006, 'author': 'r-richmond', 'body': ""Closing this pr as it isn't worth the squeeze / reduce the pr noise. Ty for taking a look / the theory regardless."", 'created_at': datetime.datetime(2024, 10, 10, 3, 2, 3, tzinfo=datetime.timezone.utc)}]","r-richmond (Issue Creator) on (2024-10-01 00:00:44 UTC): Mypy check is failing on something unrelated to my changes

one example

```
airflow/template/templater.py:125: error: Cannot determine type of
""render_template_as_native_obj""  [has-type]
            if dag and dag.render_template_as_native_obj:
```

potiuk on (2024-10-02 23:26:41 UTC): Did you cherry-pick it from PR in main? We have the rule that things should be cherry-picked to v2-10-test from main rather than having pulll requests directly to v2-10-test.

Re: mypy error - likely some other PR needs to be cherry-picked to fix that one, but we will worry about it after this one is confirmed to be merged in `main` first.

r-richmond (Issue Creator) on (2024-10-03 04:26:17 UTC): @potiuk 

The code I'm modifying doesn't exist in main anymore. So at Jed's [suggestion](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1727737690215069?thread_ts=1727737452.143039&channel=C06K9Q5G2UA&message_ts=1727737690.215069) I made it directly to v2-10-test instead.

potiuk on (2024-10-03 05:00:48 UTC): Ah. OK then

potiuk on (2024-10-03 07:20:24 UTC): BTW. Looks like mypy is confused with types of fields in DAG. I am not sure if that's the best guess but maybe it is caused by using {var=} syntax in f-strings in your PR. While this is added in Python 3.8, it might be that mypy version we are using currently is not yet able to properly parse a file with those f-strings (but this is a wild guess).

r-richmond (Issue Creator) on (2024-10-03 17:30:23 UTC): F-string = was added in python 3.8

https://docs.python.org/3/whatsnew/3.8.html#f-strings-support-for-self-documenting-expressions-and-debugging

And the mypy errors are on files this pr hasn't touched.

Can we merge this? Without this logging it's very hard to track down these conditions in an airflow deployment

potiuk on (2024-10-03 17:41:41 UTC): Yes I know. I wrete about it above. My guess is that (let me repeat it) maybe MyPy does not handle it way. 

My GUESS is that this is what causes the issue - becuase while the changes are not in the file you touched they are referring to it (dag).

No - we absolutely cannot merge it, because there is a risk it will break main and all other PRs. Surely you would not like it.

 So I recommend to experiment with it a bit and see if my guess is right  - and use pre-3.8 syntax.

potiuk on (2024-10-03 17:43:41 UTC): Yeah - I wrote 3.9 but that was a typo. Yep. I checked it was available in 3.8. But ....


So not everything that is done according to standards works and sometimes you need to workaround other people's mistakes.

potiuk on (2024-10-05 02:40:38 UTC): Looks it was a bad guess 🤷

potiuk on (2024-10-05 02:43:02 UTC): No slightest idea why it fails :)

r-richmond (Issue Creator) on (2024-10-10 03:02:03 UTC): Closing this pr as it isn't worth the squeeze / reduce the pr noise. Ty for taking a look / the theory regardless.

"
2557794918,pull_request,closed,,Add dag_id in deprecation warnings in dag.py,"# What this does

1. It adds the dag_id in the warnings when a removedInAirflow3Warning is warned.

# Why

1. It makes it much easier to find the dogs impacted by these conditions when their id is included in the warning.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",r-richmond,2024-09-30 23:03:37+00:00,[],2024-09-30 23:09:51+00:00,2024-09-30 23:09:51+00:00,https://github.com/apache/airflow/pull/42598,[],[],
2557430570,pull_request,closed,,DO NOT REVIEW. Try to do security right for backfill endpoint,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-09-30 18:58:57+00:00,[],2024-11-06 20:17:13+00:00,2024-09-30 18:59:00+00:00,https://github.com/apache/airflow/pull/42597,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', '')]",[],
2557395851,pull_request,closed,,Backport TI updated_at column from 2.5.0,"New column name will be useful to query tasks stuck in scheduled state.
https://github.com/apache/airflow/pull/26252",luisglft,2024-09-30 18:39:09+00:00,[],2024-09-30 22:39:05+00:00,2024-09-30 21:56:04+00:00,https://github.com/apache/airflow/pull/42596,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2383908229, 'issue_id': 2557395851, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 9, 30, 18, 39, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383932889, 'issue_id': 2557395851, 'author': 'jscheffl', 'body': 'Uuups, something went totally wrong in re-basing your PR?', 'created_at': datetime.datetime(2024, 9, 30, 18, 53, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384236056, 'issue_id': 2557395851, 'author': 'jedcunningham', 'body': ""Pretty sure this wasn't meant for the Apache repo @luisglft, but an (internal) fork? I'm going to close this. But please open another PR if I've interpreted this incorrectly."", 'created_at': datetime.datetime(2024, 9, 30, 21, 56, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384300481, 'issue_id': 2557395851, 'author': 'luisglft', 'body': ""> Pretty sure this wasn't meant for the Apache repo @luisglft, but an (internal) fork? I'm going to close this. But please open another PR if I've interpreted this incorrectly.\r\n\r\nyes you're right, sorry about that"", 'created_at': datetime.datetime(2024, 9, 30, 22, 39, 3, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-30 18:39:14 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jscheffl on (2024-09-30 18:53:57 UTC): Uuups, something went totally wrong in re-basing your PR?

jedcunningham on (2024-09-30 21:56:04 UTC): Pretty sure this wasn't meant for the Apache repo @luisglft, but an (internal) fork? I'm going to close this. But please open another PR if I've interpreted this incorrectly.

luisglft (Issue Creator) on (2024-09-30 22:39:03 UTC): yes you're right, sorry about that

"
2557147525,pull_request,closed,,Speed up boring cyborg consistency pre-commit check,"This is typically the slowest pre-commit besides mypy, and it runs every time. Previously it loaded all filenames into memory and ran glob filter on that. It seems faster to apply glob against the file system directly. This makes pre-commit much faster.  Previously took around 4 seconds, now about a half a second.
",dstandish,2024-09-30 16:31:26+00:00,[],2024-10-01 22:08:40+00:00,2024-09-30 19:58:32+00:00,https://github.com/apache/airflow/pull/42589,"[('area:dev-tools', '')]","[{'comment_id': 2387161932, 'issue_id': 2557147525, 'author': 'potiuk', 'body': 'Nice', 'created_at': datetime.datetime(2024, 10, 1, 22, 8, 39, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-01 22:08:39 UTC): Nice

"
2557128338,pull_request,closed,,Update fastapi operation ids,"Based of Brent change in this PR: 
https://github.com/apache/airflow/pull/42585

This automatically fills the `operation_id` of backend routes, this way generated code on the front-end has appropriate shorter names. ",pierrejeambrun,2024-09-30 16:21:26+00:00,['pierrejeambrun'],2024-10-01 07:42:39+00:00,2024-10-01 07:42:37+00:00,https://github.com/apache/airflow/pull/42588,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2557096969,pull_request,closed,,Handle RequestTimeoutException when trying to fetch ECS task logs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #42521 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pgieser,2024-09-30 16:07:17+00:00,[],2025-01-05 00:17:01+00:00,2025-01-05 00:17:01+00:00,https://github.com/apache/airflow/pull/42587,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2383613256, 'issue_id': 2557096969, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 9, 30, 16, 7, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400316479, 'issue_id': 2557096969, 'author': 'pgieser', 'body': ""> Could you add a unit test for it?\r\n\r\nI took a look at adding one, but there is no existing coverage for this error handling code and it wasn't obvious to me how to write it due to the async nature of the feature embedded in a private method."", 'created_at': datetime.datetime(2024, 10, 8, 16, 21, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2453360811, 'issue_id': 2557096969, 'author': 'eladkal', 'body': ""> > Could you add a unit test for it?\r\n> \r\n> I took a look at adding one, but there is no existing coverage for this error handling code and it wasn't obvious to me how to write it due to the async nature of the feature embedded in a private method.\r\n\r\nDid you check https://github.com/apache/airflow/blob/857ca4c06c9008593674cabdd28d3c30e3e7f97b/providers/tests/amazon/aws/triggers/test_ecs.py#L37 ?"", 'created_at': datetime.datetime(2024, 11, 3, 9, 38, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477554923, 'issue_id': 2557096969, 'author': 'o-nikolas', 'body': ""> > > Could you add a unit test for it?\r\n> > \r\n> > \r\n> > I took a look at adding one, but there is no existing coverage for this error handling code and it wasn't obvious to me how to write it due to the async nature of the feature embedded in a private method.\r\n> \r\n> Did you check\r\n> \r\n> https://github.com/apache/airflow/blob/857ca4c06c9008593674cabdd28d3c30e3e7f97b/providers/tests/amazon/aws/triggers/test_ecs.py#L37\r\n> ?\r\n\r\nAgreed with @vincbeck and @eladkal \r\n\r\nYou can start with the test class that Elad linked. The logs hook is already being mocked, you just need to update the return value of the call to get logs to return your exception that you're handling."", 'created_at': datetime.datetime(2024, 11, 14, 22, 43, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564879998, 'issue_id': 2557096969, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 30, 0, 16, 18, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-30 16:07:23 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

pgieser (Issue Creator) on (2024-10-08 16:21:55 UTC): I took a look at adding one, but there is no existing coverage for this error handling code and it wasn't obvious to me how to write it due to the async nature of the feature embedded in a private method.

eladkal on (2024-11-03 09:38:12 UTC): Did you check https://github.com/apache/airflow/blob/857ca4c06c9008593674cabdd28d3c30e3e7f97b/providers/tests/amazon/aws/triggers/test_ecs.py#L37 ?

o-nikolas on (2024-11-14 22:43:32 UTC): Agreed with @vincbeck and @eladkal 

You can start with the test class that Elad linked. The logs hook is already being mocked, you just need to update the return value of the call to get logs to return your exception that you're handling.

github-actions[bot] on (2024-12-30 00:16:18 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2557095918,pull_request,closed,,Add Docs button to Nav,"1. Remove hardcoded API url and define it in an env var.

2. Add a Docs menu button to the Nav

<img width=""360"" alt=""Screenshot 2024-09-30 at 6 02 28 PM"" src=""https://github.com/user-attachments/assets/9c430040-7028-4673-9489-28337d9416f8"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-09-30 16:06:48+00:00,[],2024-10-01 15:25:22+00:00,2024-10-01 15:25:18+00:00,https://github.com/apache/airflow/pull/42586,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2557037803,pull_request,closed,,Simplify autogenerated API function names in FastAPI + UI,"Use `operation_id` to reduce the autogenerated query and mutation function names used in the UI

Before: `useDagServiceGetDagsPublicDagsGet()`
After: `useDagServiceGetDags()`


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-09-30 15:40:16+00:00,[],2024-10-01 07:25:52+00:00,2024-10-01 07:25:52+00:00,https://github.com/apache/airflow/pull/42585,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2556799542,pull_request,closed,,Reduce eyestrain in dark mode with reduced contrast and saturation (#…,"…42567)

* reduce eyestrain in dark mode with reduced contrast and saturation

* feat: readjusted saturation

---------

Co-authored-by: Curtis Bangert <bangert.curtis+git@gmail.com>
(cherry picked from commit 97c7d2c23d73985b2f7956160f00b879b90ef6d8)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2024-09-30 14:05:51+00:00,[],2024-10-23 09:35:21+00:00,2024-09-30 15:37:46+00:00,https://github.com/apache/airflow/pull/42583,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2556516829,pull_request,closed,,fix schedule_downstream_tasks bug,"closes: https://github.com/apache/airflow/issues/42581
### Problem Description
![image](https://github.com/user-attachments/assets/acd6da8b-c1d8-4ac1-b1e2-4899195f1c78)
The trigger_rule of `task_one_success` is `one_success`. When the upstream node of `task_one_success` has not yet run, `task_one_success` is skipped. According to the semantics of `one_success`, `task_one_success` should be able to run.

In this scenario, Airflow turns on the `schedule_after_task_execution` parameter, which means that after the upstream node finishes running, it will try to schedule the downstream node in the current worker.

This problem may occur when `task_1` runs faster than `task_run`. More specifically, it occurs when `task_1` finishes running and successfully schedules downstream tasks in the current worker.

### Related Code
Below is the code in question
![image](https://github.com/user-attachments/assets/07adfa4f-ce38-4e37-ac02-42a000fb107c)
![image](https://github.com/user-attachments/assets/2a9bc36c-f431-4650-821e-044a471c713a)
When `task_1` is finished, it will try to schedule downstream tasks. First, a partial dag will be generated.
```python
partial_dag = task.dag.partial_subset(
                task.downstream_task_ids,
                include_downstream=True,
                include_upstream=False,
                include_direct_upstream=True,
            )
```
`task => ""task_1""`
`task.downstream_task_ids => ""task_2""`

`include_downstream=True => [""task_2""]`
`include_upstream=False => [""task_2""]`
`include_direct_upstream=True => [""task_2"", ""task_skip"", ""task_one_success"", ""task_1""]`

So the final `partial_dag` is `[""task_2"", ""task_skip"", ""task_one_success"", ""task_1""]`
![image](https://github.com/user-attachments/assets/73f2bc6a-d790-4a29-9256-a70c8968f30b)
![image](https://github.com/user-attachments/assets/789cedfb-8d62-420d-b74b-3deedaf4ea30)


This partial_dag is incomplete because `task_one_success`'s other upstream node `task_run` is not in it.Specifically, the `include_upstream` parameter should not be false

### Solution
The correct subgraph division should be as follows, `include_upstream=True`:
```python
partial_dag = task.dag.partial_subset(
                task.downstream_task_ids,
                include_downstream=True,
                include_upstream=True,
                include_direct_upstream=True,
            )
```
`task => ""task_1""`
`task.downstream_task_ids => ""task_2""`

`include_downstream=True => [""task_2""]`
`include_upstream=True =>[""task_2"", ""task_skip"", ""task_one_success"", ""task_1"", ""task_run"", ""branch""]`
`include_direct_upstream=True => [""task_2"", ""task_skip"", ""task_one_success"", ""task_1"", ""task_run"", ""branch""]`

So the final partial_dag is `[""task_2"", ""task_skip"", ""task_one_success"", ""task_1"", ""task_run"", ""branch""]`

The final partial_dag should be as follows:
![image](https://github.com/user-attachments/assets/7832ea16-2eeb-4e0c-bcb2-9b1b84a7ac7b)
![image](https://github.com/user-attachments/assets/5092f9f4-9093-43de-98d8-c6980fef2757)


Subgraph pruning will only be performed when the `schedule_after_task_execution` parameter is turned on. Normal scheduler scheduling will not have this problem.",luoyuliuyin,2024-09-30 12:32:23+00:00,[],2025-01-10 07:30:22+00:00,2024-10-23 08:35:24+00:00,https://github.com/apache/airflow/pull/42582,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', '')]","[{'comment_id': 2383256975, 'issue_id': 2556516829, 'author': 'romsharon98', 'body': 'Can you add test that prevent regression?', 'created_at': datetime.datetime(2024, 9, 30, 13, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383716994, 'issue_id': 2556516829, 'author': 'luoyuliuyin', 'body': ""> Can you add test that prevent regression?\r\n\r\nThank you for the suggestion. I've added test to prevent regression. Please check the latest commit."", 'created_at': datetime.datetime(2024, 9, 30, 16, 58, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2404646732, 'issue_id': 2556516829, 'author': 'luoyuliuyin', 'body': 'Adding `include_upstream=True` is still unsafe. Here is a bad case where `task_one_success` is ignored again. Given that `partial_subset` has little impact on performance, I recommend removing `partial_subset` completely.\r\n\r\n![image](https://github.com/user-attachments/assets/67fceabc-3270-48c3-ab25-9b046e0a0bc2)\r\ntask => ""task_0""\r\ntask.downstream_task_ids => ""task_1""\r\n\r\ninclude_downstream=True => [""task_1"", ""task_2""]\r\ninclude_upstream=True =>[""task_0"", ""task_1"", ""task_2""]\r\ninclude_direct_upstream=True => [""task_0"", ""task_1"", ""task_2"", ""task_one_success"", ""task_skip""]\r\n\r\nSo the final partial_dag is [""task_0"", ""task_1"", ""task_2"", ""task_one_success"", ""task_skip""]', 'created_at': datetime.datetime(2024, 10, 10, 10, 1, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406628170, 'issue_id': 2556516829, 'author': 'shahar1', 'body': 'Also, DB tests currently fail', 'created_at': datetime.datetime(2024, 10, 11, 6, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409586532, 'issue_id': 2556516829, 'author': 'potiuk', 'body': 'I have completely no problem. The use of `partial_subset` caused  problems with serialization already for a number of users so removing it seems like a good idaa, and performance-wise it should not be problematic.\r\n\r\n@ashb  @uranusjr ? Do You have any objections?', 'created_at': datetime.datetime(2024, 10, 14, 1, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581629780, 'issue_id': 2556516829, 'author': 'lzf12', 'body': '![0B813AE6-4AFB-4072-BDB4-27FEB0ECCE06](https://github.com/user-attachments/assets/f9286ab2-3952-4454-8ffb-92667ac2eefc)\r\n\r\n![EB2103E2-832C-487f-A2AD-39298FC716B9](https://github.com/user-attachments/assets/28366772-a490-4597-8736-53605d002bba)\r\n\r\n0 downstream tasks scheduled from follow-on schedule check, Actually, my downstream tasks can be scheduled, Production problems have labor to help see, This problem occurs occasionally, the upstream node succeeds, but the downstream node is not scheduled', 'created_at': datetime.datetime(2025, 1, 10, 2, 43, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581959181, 'issue_id': 2556516829, 'author': 'shahar1', 'body': '> ![0B813AE6-4AFB-4072-BDB4-27FEB0ECCE06](https://private-user-images.githubusercontent.com/45095259/401783251-f9286ab2-3952-4454-8ffb-92667ac2eefc.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY0OTQzODEsIm5iZiI6MTczNjQ5NDA4MSwicGF0aCI6Ii80NTA5NTI1OS80MDE3ODMyNTEtZjkyODZhYjItMzk1Mi00NDU0LThmZmItOTI2NjdhYzJlZWZjLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTEwVDA3MjgwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWUxZGU0ZDNmM2NjNDcwZTIzYjJhOGIwNzQ1ZDg5ZDllMWViZDAwYzEzZGI0MTEzZDlkNmNlYWYzNTNiNjkzYzImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.w53LmnrCy4X5K-4xX8JpIsazoyRXkmBtXOQ4095E6iE)\r\n> \r\n> ![EB2103E2-832C-487f-A2AD-39298FC716B9](https://private-user-images.githubusercontent.com/45095259/401785673-28366772-a490-4597-8736-53605d002bba.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY0OTQzODEsIm5iZiI6MTczNjQ5NDA4MSwicGF0aCI6Ii80NTA5NTI1OS80MDE3ODU2NzMtMjgzNjY3NzItYTQ5MC00NTk3LTg3MzYtNTM2MDVkMDAyYmJhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTEwVDA3MjgwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTc5ZjUxMmQyN2IzMzA5YjdkZGFlNzZhODU4ZjQ4MjQ3MzgxMWFmMjI3NDQ4NGUwZTIyYWI3ZTA4YzFlNWYxMjkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.MLB9Z9pTHBO9DtSmO29krUaEeo-s9m6emP4iX29I2jI)\r\n> \r\n> 0 downstream tasks scheduled from follow-on schedule check, Actually, my downstream tasks can be scheduled, Production problems have labor to help see, This problem occurs occasionally, the upstream node succeeds, but the downstream node is not scheduled\r\n\r\nThanks for reporting! Could you please create a [GitHub issue](https://github.com/apache/airflow/issues/new?assignees=&labels=kind%3Abug%2Carea%3Acore%2Cneeds-triage&projects=&template=airflow_bug_report.yml) with a minimal example to reproduce it (considering the latest Airflow version)?', 'created_at': datetime.datetime(2025, 1, 10, 7, 29, 59, tzinfo=datetime.timezone.utc)}]","romsharon98 on (2024-09-30 13:51:00 UTC): Can you add test that prevent regression?

luoyuliuyin (Issue Creator) on (2024-09-30 16:58:45 UTC): Thank you for the suggestion. I've added test to prevent regression. Please check the latest commit.

luoyuliuyin (Issue Creator) on (2024-10-10 10:01:53 UTC): Adding `include_upstream=True` is still unsafe. Here is a bad case where `task_one_success` is ignored again. Given that `partial_subset` has little impact on performance, I recommend removing `partial_subset` completely.

![image](https://github.com/user-attachments/assets/67fceabc-3270-48c3-ab25-9b046e0a0bc2)
task => ""task_0""
task.downstream_task_ids => ""task_1""

include_downstream=True => [""task_1"", ""task_2""]
include_upstream=True =>[""task_0"", ""task_1"", ""task_2""]
include_direct_upstream=True => [""task_0"", ""task_1"", ""task_2"", ""task_one_success"", ""task_skip""]

So the final partial_dag is [""task_0"", ""task_1"", ""task_2"", ""task_one_success"", ""task_skip""]

shahar1 on (2024-10-11 06:18:09 UTC): Also, DB tests currently fail

potiuk on (2024-10-14 01:19:00 UTC): I have completely no problem. The use of `partial_subset` caused  problems with serialization already for a number of users so removing it seems like a good idaa, and performance-wise it should not be problematic.

@ashb  @uranusjr ? Do You have any objections?

lzf12 on (2025-01-10 02:43:14 UTC): ![0B813AE6-4AFB-4072-BDB4-27FEB0ECCE06](https://github.com/user-attachments/assets/f9286ab2-3952-4454-8ffb-92667ac2eefc)

![EB2103E2-832C-487f-A2AD-39298FC716B9](https://github.com/user-attachments/assets/28366772-a490-4597-8736-53605d002bba)

0 downstream tasks scheduled from follow-on schedule check, Actually, my downstream tasks can be scheduled, Production problems have labor to help see, This problem occurs occasionally, the upstream node succeeds, but the downstream node is not scheduled

shahar1 on (2025-01-10 07:29:59 UTC): Thanks for reporting! Could you please create a [GitHub issue](https://github.com/apache/airflow/issues/new?assignees=&labels=kind%3Abug%2Carea%3Acore%2Cneeds-triage&projects=&template=airflow_bug_report.yml) with a minimal example to reproduce it (considering the latest Airflow version)?

"
2555394191,pull_request,closed,,Rename dataset endpoints as asset endpoints,"* Rename dataset endpoints as asset endpoints
  * Rename ``/datasets`` as ``/assets``
  * Rename ``/datasets/{uri}`` as ``/assets/{uri}``
  * Rename ``/datasets/events`` as ``/assets/events``
  * Rename ``/datasets/queuedEvent/{uri}`` as ``/ui/next_run_assets/upstream``
  * Rename ``/dags/{dag_id}/dagRuns/{dag_run_id}/upstreamDatasetEvents`` as ``/ui/next_run_assets/upstream``
  * Rename ``/dags/{dag_id}/datasets/queuedEvent/{uri}`` as ``/ui/next_run_assets/upstream``
  * Rename ``/dags/{dag_id}/datasets/queuedEvent`` as ``/ui/next_run_assets/upstream``
  * Rename ``/ui/next_run_datasets/upstream`` as ``/ui/next_run_assets/upstream``
* Rename dataset schema as asset endpoints
  * Rename ``AssetCollection.datasets`` as ``AssetCollection.assets``
  * Rename ``AssetEventCollection.dataset_events`` as ``AssetEventCollection.asset_events``
  * Rename ``AssetEventCollectionSchema.dataset_events`` as ``AssetEventCollectionSchema.asset_events``
  * Rename ``CreateAssetEventSchema.dataset_uri`` as ``CreateAssetEventSchema.asset_uri``

---

Some of the names are still kept as Dataset due to the database not being changed. will be handled in https://github.com/apache/airflow/pull/42023

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-09-30 02:35:52+00:00,[],2024-10-04 14:20:09+00:00,2024-10-03 23:57:51+00:00,https://github.com/apache/airflow/pull/42579,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:API', ""Airflow's REST/HTTP API""), ('AIP-74', 'Dataset -> Asset')]","[{'comment_id': 2391018117, 'issue_id': 2555394191, 'author': 'Lee-W', 'body': '> Functionality lgtm\r\n> \r\n> There\'s still variable names and places in the UI that use the name ""dataset"". But it is all deprecated so that\'s fine by me. Once we upgrade the db columns, let\'s make sure no mention of dataset finds its way into `/api_fastapi` and `/ui` directories.\r\n\r\nSure! The next PR I\'ll work on is the DB one. once that\'s merged, I think we can get rid of the dataset in `/api_fastapi` and `/ui`. After that, I\'ll work on the rest of the UI thing, and everything has not yet changed', 'created_at': datetime.datetime(2024, 10, 3, 10, 5, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2393829231, 'issue_id': 2555394191, 'author': 'jscheffl', 'body': 'Assuming post-merge this PR broke canary tests on main - can you take a look for fixing? https://github.com/apache/airflow/actions/runs/11175856695/job/31068286744', 'created_at': datetime.datetime(2024, 10, 4, 14, 20, 8, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-10-03 10:05:58 UTC): Sure! The next PR I'll work on is the DB one. once that's merged, I think we can get rid of the dataset in `/api_fastapi` and `/ui`. After that, I'll work on the rest of the UI thing, and everything has not yet changed

jscheffl on (2024-10-04 14:20:08 UTC): Assuming post-merge this PR broke canary tests on main - can you take a look for fixing? https://github.com/apache/airflow/actions/runs/11175856695/job/31068286744

"
2555371844,pull_request,closed,,Update Dependency Detector to handle DAG dependencies set via partial,"The DAG dependency view shows dependencies for DAGs that are available at DAG parsing/serialization time.  Dynamically mapped tasks that trigger (via `TriggerDagRunOperator`) or wait for (via `ExternalTaskSensor`) external DAGs are now listed as DAG dependencies provided that those dependencies are set via `partial`, and not dynamically expanded.

Tested with the following:
```
@dag()
def triggering_dag():
    """"""
    DAG that is doing the triggering.
    """"""
    t = TriggerDagRunOperator.partial(
        trigger_dag_id=""triggered_dag"",
        task_id=""triggering_task"",
        reset_dag_run=True,
    ).expand(trigger_run_id=[""trigger_run_id1__{{ ts }}"", ""trigger_run_id2__{{ ts }}""])

    t


@dag()
def unmapped_triggering_dag():
    """"""
    DAG that is doing the triggering.
    """"""
    t = TriggerDagRunOperator(
        trigger_dag_id=""triggered_dag"",
        task_id=""triggering_task"",
        reset_dag_run=True,
        trigger_run_id=""unmapped_trigger_run_id1__{{ ts }}"",
    )

    t


@dag()
def triggered_dag():
    """"""
    DAG that is getting triggered.
    """"""

    @task()
    def empty_task() -> int:
        return 0

    empty_task()

triggering_dag()
triggered_dag()
unmapped_triggering_dag()

@dag(
    schedule=""*/5 * * * *"",
    start_date=pendulum.datetime(2024, 1, 1),
    catchup=False,
)
def mapped_sensor_dag():
    """"""
    DAG that is doing the waiting/sensing.
    """"""
    t = ExternalTaskSensor.partial(
        task_id=""wait"",
        external_dag_id=""waited_on_dag"",
        deferrable=True,
        check_existence=True,
    ).expand(external_task_id=[""empty_task"", ""another_empty_task""])

    t


@dag(
    schedule=""*/5 * * * *"",
    start_date=pendulum.datetime(2024, 1, 1),
    catchup=False,
)
def unmapped_sensor_dag():
    """"""
    DAG that is doing the waiting/sensing.
    """"""
    t = ExternalTaskSensor(
        task_id=""wait"",
        external_dag_id=""waited_on_dag"",
        external_task_id=""empty_task"",
        deferrable=True,
        check_existence=True,
    )

    t


@dag(
    schedule=""*/5 * * * *"",
    start_date=pendulum.datetime(2024, 1, 1),
    catchup=False,
)
def waited_on_dag():
    """"""
    DAG that is getting waited on.
    """"""

    @task()
    def empty_task() -> int:
        return 0

    @task()
    def another_empty_task() -> int:
        return 1

    @task()
    def yet_another_empty_task() -> int:
        return 2


    empty_task()
    another_empty_task()
    yet_another_empty_task()

waited_on_dag()
unmapped_sensor_dag()
mapped_sensor_dag()
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",fredthomsen,2024-09-30 02:11:32+00:00,[],2024-11-28 03:19:30+00:00,2024-11-28 03:19:30+00:00,https://github.com/apache/airflow/pull/42578,"[('area:serialization', '')]","[{'comment_id': 2477675435, 'issue_id': 2555371844, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 15, 0, 16, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481604625, 'issue_id': 2555371844, 'author': 'fredthomsen', 'body': 'Rebased to resolve conflicts in unit test and drop 3.8 compatibility commit.', 'created_at': datetime.datetime(2024, 11, 17, 21, 33, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484738761, 'issue_id': 2555371844, 'author': 'fredthomsen', 'body': '@ashb curious if you had any thoughts here and if this would qualify as a bug fix?', 'created_at': datetime.datetime(2024, 11, 19, 5, 26, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2501628347, 'issue_id': 2555371844, 'author': 'fredthomsen', 'body': '@eladkal you know who I can ping to get this PR merged in?', 'created_at': datetime.datetime(2024, 11, 26, 18, 14, 1, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-15 00:16:09 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

fredthomsen (Issue Creator) on (2024-11-17 21:33:39 UTC): Rebased to resolve conflicts in unit test and drop 3.8 compatibility commit.

fredthomsen (Issue Creator) on (2024-11-19 05:26:55 UTC): @ashb curious if you had any thoughts here and if this would qualify as a bug fix?

fredthomsen (Issue Creator) on (2024-11-26 18:14:01 UTC): @eladkal you know who I can ping to get this PR merged in?

"
2555177455,pull_request,closed,,Update documentation to add rebase is optional for Github commit,"Updating documentation to include notes to show rebase is optional for committing change to Github.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Srabasti,2024-09-29 21:46:03+00:00,[],2024-11-21 13:14:59+00:00,2024-11-21 13:14:59+00:00,https://github.com/apache/airflow/pull/42577,"[('area:dev-tools', '')]","[{'comment_id': 2381726017, 'issue_id': 2555177455, 'author': 'Lee-W', 'body': ""I'm not sure whether we would like to include it. Even though rebasing is optional, it's highly recommended."", 'created_at': datetime.datetime(2024, 9, 30, 0, 24, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390522852, 'issue_id': 2555177455, 'author': 'potiuk', 'body': 'Same thought', 'created_at': datetime.datetime(2024, 10, 3, 5, 2, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2425414099, 'issue_id': 2555177455, 'author': 'Srabasti', 'body': ""> I'm not sure whether we would like to include it. Even though rebasing is optional, it's highly recommended.\r\n\r\n\r\n\r\n> Same thought\r\n\r\nCan we all agree to update comments educating code contributors the advantages of Rebasing? Currently, one can commit without rebasing. If we are encouraging users to rebase, even though they can avoid it, better to mention as good standard coding practice to follow.\r\n\r\nSuggestion is to at least add a one-liner as follows below.\r\nRebasing is highly recommended as a good software practice. Suggested reading to understand advantages of rebasing: https://softwareengineering.stackexchange.com/questions/218801/why-do-so-many-projects-prefer-git-rebase-over-git-merge\r\n\r\nPlease feel free to suggest anything else you would like to add. \r\nThanks in advance!"", 'created_at': datetime.datetime(2024, 10, 21, 2, 10, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435435085, 'issue_id': 2555177455, 'author': 'potiuk', 'body': '> Please feel free to suggest anything else you would like to add.\r\n\r\nSure - feel free to rebase (!) and propose a new, updated version.', 'created_at': datetime.datetime(2024, 10, 24, 14, 21, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491118627, 'issue_id': 2555177455, 'author': 'potiuk', 'body': ""It's better now"", 'created_at': datetime.datetime(2024, 11, 21, 13, 14, 34, tzinfo=datetime.timezone.utc)}]","Lee-W on (2024-09-30 00:24:27 UTC): I'm not sure whether we would like to include it. Even though rebasing is optional, it's highly recommended.

potiuk on (2024-10-03 05:02:17 UTC): Same thought

Srabasti (Issue Creator) on (2024-10-21 02:10:17 UTC): Can we all agree to update comments educating code contributors the advantages of Rebasing? Currently, one can commit without rebasing. If we are encouraging users to rebase, even though they can avoid it, better to mention as good standard coding practice to follow.

Suggestion is to at least add a one-liner as follows below.
Rebasing is highly recommended as a good software practice. Suggested reading to understand advantages of rebasing: https://softwareengineering.stackexchange.com/questions/218801/why-do-so-many-projects-prefer-git-rebase-over-git-merge

Please feel free to suggest anything else you would like to add. 
Thanks in advance!

potiuk on (2024-10-24 14:21:30 UTC): Sure - feel free to rebase (!) and propose a new, updated version.

potiuk on (2024-11-21 13:14:34 UTC): It's better now

"
2555131332,pull_request,closed,,Bugfix/42575 workaround pin azure kusto data,"Fix broken main:
Workaround for #42575 - exclude pin of azure kusto data
related: #42575
",jscheffl,2024-09-29 20:02:41+00:00,[],2024-10-15 04:14:05+00:00,2024-09-29 21:02:07+00:00,https://github.com/apache/airflow/pull/42576,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2381601783, 'issue_id': 2555131332, 'author': 'jscheffl', 'body': 'Merging as static and provider tests are green now', 'created_at': datetime.datetime(2024, 9, 29, 21, 1, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412854224, 'issue_id': 2555131332, 'author': 'rawwar', 'body': ""@jscheffl  Looks like they released 4.6.1 and now that's breaking mypy checks on main. Should we set upperbound to 4.5.x? \r\n\r\nhttps://github.com/apache/airflow/actions/runs/11338780479/job/31532784299?pr=43020#step:6:120\r\n\r\n\r\nEDIT1: I guess I'm wrong. 4.6.1 was released a while ago. something else might have broken the checks\r\n\r\nEDIT2: I should have read the package name properly. Its `microsoft-kiota-serialization-json`"", 'created_at': datetime.datetime(2024, 10, 15, 4, 8, 10, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-09-29 21:01:59 UTC): Merging as static and provider tests are green now

rawwar on (2024-10-15 04:08:10 UTC): @jscheffl  Looks like they released 4.6.1 and now that's breaking mypy checks on main. Should we set upperbound to 4.5.x? 

https://github.com/apache/airflow/actions/runs/11338780479/job/31532784299?pr=43020#step:6:120


EDIT1: I guess I'm wrong. 4.6.1 was released a while ago. something else might have broken the checks

EDIT2: I should have read the package name properly. Its `microsoft-kiota-serialization-json`

"
2555117485,pull_request,closed,,Bump uv to 0.4.17,"#42274 had to stop at 0.4.7 due to https://github.com/astral-sh/uv/issues/7680 (a regression of https://github.com/astral-sh/uv/issues/4136 / https://github.com/astral-sh/uv/pull/4149).

Now that https://github.com/astral-sh/uv/pull/7683 is merged and released in 0.4.17, we should be able to upgrade again.
",topherinternational,2024-09-29 19:29:06+00:00,[],2024-09-30 07:10:53+00:00,2024-09-30 00:21:11+00:00,https://github.com/apache/airflow/pull/42574,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2555054730,pull_request,closed,,Fix EmrCreateJobFlowOperator using deferrable mode with wait_for_completion,"# Summary of Changes
Closes: #40966 by updating the `EmrCreateJobFlowOperator` logic to ensure that the deferral trigger is activated only when `wait_for_completion` is set to `True`. Previously, the deferral trigger was applied regardless of the `wait_for_completion` setting, causing unintended behavior.

# Changes Made:
- **Modified `EmrCreateJobFlowOperator` logic:**
  - Now checks both `deferrable` and `wait_for_completion` flags before activating the deferral trigger.
  
- **Added a new unit test case `TestEmrCreateJobFlowOperatorExtended`:**
  - Verifies the new logic where the deferral trigger is only set when both `deferrable` and `wait_for_completion` are `True`.
  - Confirms the `defer` method is called with the correct parameters.

- **Modified existing test `test_create_job_flow_deferrable`:**
  - Ensures a `TaskDeferred` exception is raised when the operator runs in deferrable mode.
  - Verifies that the trigger is created with the correct parameters.





Please review the changes, and let me know if further adjustments are needed.
",laksh-krishna-sharma,2024-09-29 18:09:10+00:00,[],2024-12-01 21:09:55+00:00,2024-12-01 21:09:54+00:00,https://github.com/apache/airflow/pull/42573,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2381448240, 'issue_id': 2555054730, 'author': 'laksh-krishna-sharma', 'body': 'Apologies for the inconvenience caused by closing the previous PR due to an issue.', 'created_at': datetime.datetime(2024, 9, 29, 18, 9, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383433168, 'issue_id': 2555054730, 'author': 'vincbeck', 'body': 'Static checks are failing, could you please fix them?', 'created_at': datetime.datetime(2024, 9, 30, 14, 50, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407182542, 'issue_id': 2555054730, 'author': 'laksh-krishna-sharma', 'body': 'i had run `pre-commit run --all-files`  command as mentioned in error details \r\nbut getting :                 \r\n![Screenshot from 2024-10-11 16-37-23](https://github.com/user-attachments/assets/cd6e5df6-b56d-42fc-80d4-c9db3c166fdc)', 'created_at': datetime.datetime(2024, 10, 11, 11, 10, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407184158, 'issue_id': 2555054730, 'author': 'laksh-krishna-sharma', 'body': 'and on running `breeze down --cleanup-mypy-cache` getting:\r\n![Screenshot from 2024-10-11 16-39-07](https://github.com/user-attachments/assets/2c95607a-588e-4f60-8e17-eb90d8f6787c)', 'created_at': datetime.datetime(2024, 10, 11, 11, 11, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413729953, 'issue_id': 2555054730, 'author': 'laksh-krishna-sharma', 'body': '@vincbeck Sir please review the updates', 'created_at': datetime.datetime(2024, 10, 15, 12, 5, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414015809, 'issue_id': 2555054730, 'author': 'vincbeck', 'body': 'Maybe you can try with breeze: `breeze static-checks --last-commit`. This will run static checks against the last commit (which are your changes)', 'created_at': datetime.datetime(2024, 10, 15, 14, 3, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414694629, 'issue_id': 2555054730, 'author': 'laksh-krishna-sharma', 'body': 'Thanks @vincbeck  sir, on running `breeze static-checks --last-commit` command i am getting :\r\n![Screenshot from 2024-10-15 23-39-02](https://github.com/user-attachments/assets/a97e4880-07a4-457e-9bb8-d13d68183274)\r\nand this:\r\n![Screenshot from 2024-10-15 23-41-03](https://github.com/user-attachments/assets/acfcbba0-3059-497e-a143-71be86584351)', 'created_at': datetime.datetime(2024, 10, 15, 18, 11, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2414778135, 'issue_id': 2555054730, 'author': 'vincbeck', 'body': '> Thanks @vincbeck sir, on running `breeze static-checks --last-commit` command i am getting : ![Screenshot from 2024-10-15 23-39-02](https://private-user-images.githubusercontent.com/144571294/376736898-a97e4880-07a4-457e-9bb8-d13d68183274.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjkwMTg3NDgsIm5iZiI6MTcyOTAxODQ0OCwicGF0aCI6Ii8xNDQ1NzEyOTQvMzc2NzM2ODk4LWE5N2U0ODgwLTA3YTQtNDU3ZS05YmI4LWQxM2Q2ODE4MzI3NC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMDE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTAxNVQxODU0MDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1hNjdlZjgxZmVmYmNjMDQ0NmU5ZDM2MjRmMDVmYzEyYTE1NzM2MTNjZTM5NWI3M2UyYzI5ODliM2Y4MDZhYzEzJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.dgbKor-xIm6J1eI6z0H5yqEsPdEfoHfojktRHGFEBbA) and this: ![Screenshot from 2024-10-15 23-41-03](https://private-user-images.githubusercontent.com/144571294/376737150-acfcbba0-3059-497e-a143-71be86584351.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjkwMTg3NDgsIm5iZiI6MTcyOTAxODQ0OCwicGF0aCI6Ii8xNDQ1NzEyOTQvMzc2NzM3MTUwLWFjZmNiYmEwLTMwNTktNDk3ZS1hMTQzLTcxYmU4NjU4NDM1MS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQxMDE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MTAxNVQxODU0MDhaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00YTczMzBlYjNkNjA2NGUyYjAxYzUyOTU1YTJhMmNjNWJiYzkyMTRiMWZkMWYxYTY5MGRlZDM2YzBhODBjZTdiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.dN8qU7XVhpD3_FyywJJ-pBC5HmJWZTutTxcvU6VtHYE)\r\n\r\nFrom the errors returned by the script you should be able to fix them', 'created_at': datetime.datetime(2024, 10, 15, 18, 54, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461531952, 'issue_id': 2555054730, 'author': 'eladkal', 'body': '@laksh-krishna-sharma can you fix the errors?', 'created_at': datetime.datetime(2024, 11, 7, 7, 45, tzinfo=datetime.timezone.utc)}]","laksh-krishna-sharma (Issue Creator) on (2024-09-29 18:09:50 UTC): Apologies for the inconvenience caused by closing the previous PR due to an issue.

vincbeck on (2024-09-30 14:50:51 UTC): Static checks are failing, could you please fix them?

laksh-krishna-sharma (Issue Creator) on (2024-10-11 11:10:09 UTC): i had run `pre-commit run --all-files`  command as mentioned in error details 
but getting :                 
![Screenshot from 2024-10-11 16-37-23](https://github.com/user-attachments/assets/cd6e5df6-b56d-42fc-80d4-c9db3c166fdc)

laksh-krishna-sharma (Issue Creator) on (2024-10-11 11:11:10 UTC): and on running `breeze down --cleanup-mypy-cache` getting:
![Screenshot from 2024-10-11 16-39-07](https://github.com/user-attachments/assets/2c95607a-588e-4f60-8e17-eb90d8f6787c)

laksh-krishna-sharma (Issue Creator) on (2024-10-15 12:05:41 UTC): @vincbeck Sir please review the updates

vincbeck on (2024-10-15 14:03:46 UTC): Maybe you can try with breeze: `breeze static-checks --last-commit`. This will run static checks against the last commit (which are your changes)

laksh-krishna-sharma (Issue Creator) on (2024-10-15 18:11:20 UTC): Thanks @vincbeck  sir, on running `breeze static-checks --last-commit` command i am getting :
![Screenshot from 2024-10-15 23-39-02](https://github.com/user-attachments/assets/a97e4880-07a4-457e-9bb8-d13d68183274)
and this:
![Screenshot from 2024-10-15 23-41-03](https://github.com/user-attachments/assets/acfcbba0-3059-497e-a143-71be86584351)

vincbeck on (2024-10-15 18:54:44 UTC): From the errors returned by the script you should be able to fix them

eladkal on (2024-11-07 07:45:00 UTC): @laksh-krishna-sharma can you fix the errors?

"
2555038849,pull_request,open,,Implemented IterableOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

As proposed on the [devlist](https://lists.apache.org/thread/bx2w6dpr3ynvnq06n4v62n7g8dodt2rt) I've implemented a new oprator called the ""IterableOperator"".  Of course I don't know if this is a good name, but I'll explain what I wanted to achieve within Airflow 2.x.

At our company we have some DAG's that have to process a lot of paged results, which are returned as indexed XCom's.
If those indexed XCom's aren't that many, it's easily possible to process those using the MappedOperator with the partial and expand functionality.  But once you have like more than 1k indexed XComs, processing those becomes very hard (unless maybe you have a beefy Postgres database behind it due to the high number of dynamic task being created).

We are using the KubernetesExecutor, which means that each taskinstance runs on a dedicated worker, and of course you can use parallelism to process multiple tasks at once, but when there are too many dynamic tasks for one operator, this become's more a problem than a solution.   Processing is actually slower and the UI has also trouble monitoring all those dynamic tasks (see screenshot which shows difference in execution time between expand and iterate).  As you can see, the difference in performance is huge when you compare the expand vs iterate solution.

![image](https://github.com/user-attachments/assets/79cee79e-6d33-47e2-a790-f68954183d33)

So to bypass those issues, I've thought of an operator which instead of expanding all mapped arguments, ""streams"" them. 
The reason why I call it stream (and implemented it as a IterableOperator) is because I inspired this solution from the Java 8 stream API, which allows you to process a list or an iterable in a lazy way, and if wanted, apply parallelism to it.  Here of course it's not completely the same, but the idea behind it is.  The advantage of this is that for Airflow, all mapped arguments which are translated to multiple task instances, are actually processed as one within one operator, the IterableOperatorthat is.
You could see this solution as some kind of a conccurent for loop within an operator for mapped parameters.

But as opposed to the MappedOperator, the IterableOperatorwill execute the partial operator within the same operator and task instance using asynchronous code and a semaphore, the later one is being used to limit to number of threads being used simultaneously.  This can be done by specifying the 'max_active_tis_per_dag' parameter, but if not specified it will use the number of cpu's available withing that worker.  If you don't want parallelism, you can set it to 1 so that each task gets executed sequentially. Sometimes this can be handy if you don't want to ""DDOS"" a REST endpoint and so avoid being throttled.  I a tasks fail, it will use the do same as with dynamic tasks mapping an retry it until it's number of retries are exceeded.  Also the retry_delay will work the same way, of course only failed tasks will be retried.  You will notice that most of the code is actually re-used code from Airflow, except the async part execution and the complete evaluation of all values in the ExpandInput instance is new code.

Also async operators, which use a trigger, will be executed that way, so all processing happens asynchronously within the same operator and thus task instance and thus worker.  Of course this can be perceived a bit as hackish code to achieve this way of working within Airflow, but this allowed me to easily patch our own Airflow installation and allowed me to ""easily"" add this functionality.  This functionality could also be implemented as an alternative strategy within the expand method using a parameter to decide which one to use, still I personally found a dedicated stream method more elegant.

Of course the code could still use some refactoring, but I tried to implement it as clean as possible.  This is still a draft, so I still need to add some unit tests, which shouldn't be that big of a challenge. It would also be a solution of the question asked [here](https://github.com/apache/airflow/discussions/26093) without the need of custom code.

Here a simple example of a DAG using the iterate functionality:

```
with DAG(
    ""streamed_operator_performance_test"",
    default_args=DEFAULT_ARGS,
    schedule_interval=timedelta(hours=24),
    max_active_runs=5,
    concurrency=5,
    catchup=False,
) as dag:
    distinct_users_ids_task = SQLExecuteQueryOperator(
        task_id=""distinct_users_ids"",
        conn_id=""odbc_dev"",
        sql=""SELECT TOP 1000 ID FROM USERS"",
        dag=dag,
    )
 
    user_registered_devices_task = MSGraphAsyncOperator.partial(
        task_id=""user_registered_devices"",
        conn_id=""msgraph_api"",
        url=""users/{userId}/registeredDevices"",
        retry_delay=60,
        dag=dag,
    ).iterate(path_parameters=distinct_users_ids_task.output.map(lambda u: {""userId"": u[0]}))
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-09-29 17:29:30+00:00,[],2025-02-06 07:38:47+00:00,,https://github.com/apache/airflow/pull/42572,[],"[{'comment_id': 2381617030, 'issue_id': 2555038849, 'author': 'raphaelauv', 'body': 'Airlfow is not a processing tool ( stream or batch )\r\n\r\nbut if you still want to run and control batching manually in airflow then ;\r\n\r\nater your first task add an intermediary task that create N batch and make your `show_user_id` task accept a batch of values to loop sequentially on', 'created_at': datetime.datetime(2024, 9, 29, 21, 31, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2382257675, 'issue_id': 2555038849, 'author': 'dabla', 'body': '> Airlfow is not a processing tool ( stream or batch )\r\n> \r\n> but if you still want to run and control batching manually in airflow then ;\r\n> \r\n> ater your first task add an intermediary task that create N batch and make your `show_user_id` task accept a batch of values to loop sequentially on\r\n\r\nWhat if the second operator is also a native (async) operator?  Then your proposition won’t be possible', 'created_at': datetime.datetime(2024, 9, 30, 6, 53, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2382276855, 'issue_id': 2555038849, 'author': 'raphaelauv', 'body': 'I don\'t understand.\n\nThe second operator I\'m talking about is just a PythonOperator splitting a list of ""work"" in N sublists', 'created_at': datetime.datetime(2024, 9, 30, 7, 4, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2382367274, 'issue_id': 2555038849, 'author': 'dabla', 'body': '> I don\'t understand.\r\n> \r\n> The second operator I\'m talking about is just a PythonOperator splitting a list of ""work"" in N sublists\r\n\r\nI\'ve updated the example DAG is PR description using the MSGraphAsyncOperator instead of PythonOperator, this is how we use it now at our company to bypass issues when using expand. Now you\'ll understand that the MSGraphAsyncOperator won\'t accept a batch of values, nor will any operator except the PythonOpertor (or a decorated @task method) because that one involves custom python code, which you cannot do with any other operator, you have to use it as it is, hence why expand was invented and why I introduced iterate to achieve the same but in another more efficient way if there are to many inputs to iterate over.', 'created_at': datetime.datetime(2024, 9, 30, 7, 51, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2382568299, 'issue_id': 2555038849, 'author': 'raphaelauv', 'body': '`after your first task add an intermediary task that create N batch`\r\n\r\n\r\n```python\r\nwith DAG(\r\n        ""a"",\r\n        default_args=DEFAULT_ARGS,\r\n        schedule_interval=timedelta(hours=24),\r\n):\r\n    distinct_users_ids_task = SQLExecuteQueryOperator(\r\n        task_id=""distinct_users_ids"",\r\n        conn_id=""odbc_dev"",\r\n        sql=""SELECT TOP 1000 ID FROM USERS"",\r\n    )\r\n\r\n    def split_fn(work_to_split,nb_chunks):\r\n        pass\r\n\r\n    split_work_task = PythonOperator(\r\n        task_id=""split_work"",\r\n        python_callable=split_fn,\r\n        op_kwargs={""work_to_split"": distinct_users_ids_task.output, ""nb_chunks"": 5})  # 5 could be a dynamic value\r\n\r\n    user_registered_devices_task = MSGraphAsyncOperator.partial(\r\n        task_id=""user_registered_devices"",\r\n        conn_id=""msgraph_api"",\r\n        url=""users/{userId}/registeredDevices"",\r\n        retry_delay=60,\r\n    ).expand(path_parameters=split_work_task.output)\r\n\r\n```\r\n\r\nyou can do this if splitting logic is simple but don\'t reinvent the wheel ( use a specialize data processing tool/framework for more advanced cases )', 'created_at': datetime.datetime(2024, 9, 30, 9, 11, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2382626992, 'issue_id': 2555038849, 'author': 'dabla', 'body': '> `after your first task add an intermediary task that create N batch`\r\n> \r\n> ```python\r\n> with DAG(\r\n>         ""a"",\r\n>         default_args=DEFAULT_ARGS,\r\n>         schedule_interval=timedelta(hours=24),\r\n> ):\r\n>     distinct_users_ids_task = SQLExecuteQueryOperator(\r\n>         task_id=""distinct_users_ids"",\r\n>         conn_id=""odbc_dev"",\r\n>         sql=""SELECT TOP 1000 ID FROM USERS"",\r\n>     )\r\n> \r\n>     def split_fn(work_to_split,nb_chunks):\r\n>         pass\r\n> \r\n>     split_work_task = PythonOperator(\r\n>         task_id=""split_work"",\r\n>         python_callable=split_fn,\r\n>         op_kwargs={""work_to_split"": distinct_users_ids_task.output, ""nb_chunks"": 5})  # 5 could be a dynamic value\r\n> \r\n>     user_registered_devices_task = MSGraphAsyncOperator.partial(\r\n>         task_id=""user_registered_devices"",\r\n>         conn_id=""msgraph_api"",\r\n>         url=""users/{userId}/registeredDevices"",\r\n>         retry_delay=60,\r\n>     ).expand(path_parameters=split_work_task.output)\r\n> ```\r\n> \r\n> you can do this if splitting logic is simple but don\'t reinvent the wheel ( use a specialize data processing tool/framework for more advanced cases )\r\n\r\nAgreed on the specialized framework, but how do you intend to use the Airflow operator there? You won’t be able too. Also, why introduce custom python code to avoid the problem with expand if Airflow would allow you to do it natively?  The example above is how we load our data into our bronze layer, then once done, we use a specialized tool to process those json files.  But if we would want to re do this all in the specialized tool, that would involve a lot more custom python code, which means more maintenance and thus more possible bugs. Using it this way in Airflow, you have a standard non-custom solution purely using operators, no custom code needed, nor workaround needed by fiddling with chunks, which at some point, will again start to fail if there is too much to process.\r\n\r\nYou could also make the same argument regarding the HttpOperator or even the HttpHook. Why is it in Airflow?  You can do the same with a PythonOperator using the requests or httpx library...  I would then answer: ease of use and integration, no custom code required, Airflow handles it for you in a convenient way.', 'created_at': datetime.datetime(2024, 9, 30, 9, 38, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514122611, 'issue_id': 2555038849, 'author': 'ashb', 'body': ""I'll go back to the list with this feedback, but this implementation is tantamount to a parallel scheduler, executor and triggerer implementation so is very unlikely to be accepted in to core."", 'created_at': datetime.datetime(2024, 12, 3, 10, 17, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514123475, 'issue_id': 2555038849, 'author': 'ashb', 'body': '> Airlfow is not a processing tool ( stream or batch )\r\n\r\nI very strongly disagree with this statement.', 'created_at': datetime.datetime(2024, 12, 3, 10, 17, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514182293, 'issue_id': 2555038849, 'author': 'potiuk', 'body': '> I\'ll go back to the list with this feedback, but this implementation is tantamount to a parallel scheduler, executor and triggerer implementation so is very unlikely to be accepted in to core.\r\n\r\nLooking forward to the discussion :).  \r\n\r\nI am not strong for / against this kind of operators, but I see a class of use cases - which might be very interesting in the near future. I.e. runnig a independent ""airlfow"" tasks on the same machine, using the fact that those independent tasks could store the data they are working on in-memory. Leveraging things like Apache Arrow to enable 0-data-copy optimizations and the fact that many existing tools and libraries already support it. \r\n\r\nAnd It seems that it very nicely fits into the case where multiple tasks might be using different libraries to run complex - and sometimes parallel but on the same machine - worfklows using that data loadded in CPU and GPU. This has been mentioned multiple times in the past in various forms (but ""task affinity"" is one that seems like best fitting the need there) - and I think streamed Operator as defined now is not really implementing it in the way that is best, but I would not exclude we will get something there sooner or later.\r\n\r\nIMHO, we are at the verge on users looking at very aggressive optimizations in this space - and while it all could be done by writing task flow tasks, there is a value in being able to see, observe have dependencies and parallelise those tasks via Airflow mechanisms. I am not sure if ""streamed operator"" is the right abstraction for it and maybe we could make decision this is **not** interesting for the community, I think we should definitely discuss it and see if we can do something there beyond Airflow 3.\r\n\r\n>>  Airlfow is not a processing tool ( stream or batch )\r\n\r\n> I very strongly disagree with this statement.\r\n\r\nMe too.', 'created_at': datetime.datetime(2024, 12, 3, 10, 41, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2518245561, 'issue_id': 2555038849, 'author': 'dabla', 'body': ""> I'll go back to the list with this feedback, but this implementation is tantamount to a parallel scheduler, executor and triggerer implementation so is very unlikely to be accepted in to core.\r\n\r\nYes, that's because you just can't simply execute multiple deferrable operator within a loop by calling their execute method.  Maybe we could think of some kind of interface/expansion mechanism to the PartialOperator that you could enhance with additional functionalities, like here the iterate method which returns an IterableOperator instead of a MappedOperator.  Then we could define this functionality into a provider, then it doesn't have to be part of the core for example if this would be the ultimate issue.  Anyway I've started drafting an AIP with @Joffreybvn where we describe what we want to solve here and also trying to summarize everything we've discussed so far here, in slack and devlists."", 'created_at': datetime.datetime(2024, 12, 4, 18, 36, 48, tzinfo=datetime.timezone.utc)}]","raphaelauv on (2024-09-29 21:31:54 UTC): Airlfow is not a processing tool ( stream or batch )

but if you still want to run and control batching manually in airflow then ;

ater your first task add an intermediary task that create N batch and make your `show_user_id` task accept a batch of values to loop sequentially on

dabla (Issue Creator) on (2024-09-30 06:53:09 UTC): What if the second operator is also a native (async) operator?  Then your proposition won’t be possible

raphaelauv on (2024-09-30 07:04:40 UTC): I don't understand.

The second operator I'm talking about is just a PythonOperator splitting a list of ""work"" in N sublists

dabla (Issue Creator) on (2024-09-30 07:51:46 UTC): I've updated the example DAG is PR description using the MSGraphAsyncOperator instead of PythonOperator, this is how we use it now at our company to bypass issues when using expand. Now you'll understand that the MSGraphAsyncOperator won't accept a batch of values, nor will any operator except the PythonOpertor (or a decorated @task method) because that one involves custom python code, which you cannot do with any other operator, you have to use it as it is, hence why expand was invented and why I introduced iterate to achieve the same but in another more efficient way if there are to many inputs to iterate over.

raphaelauv on (2024-09-30 09:11:46 UTC): `after your first task add an intermediary task that create N batch`


```python
with DAG(
        ""a"",
        default_args=DEFAULT_ARGS,
        schedule_interval=timedelta(hours=24),
):
    distinct_users_ids_task = SQLExecuteQueryOperator(
        task_id=""distinct_users_ids"",
        conn_id=""odbc_dev"",
        sql=""SELECT TOP 1000 ID FROM USERS"",
    )

    def split_fn(work_to_split,nb_chunks):
        pass

    split_work_task = PythonOperator(
        task_id=""split_work"",
        python_callable=split_fn,
        op_kwargs={""work_to_split"": distinct_users_ids_task.output, ""nb_chunks"": 5})  # 5 could be a dynamic value

    user_registered_devices_task = MSGraphAsyncOperator.partial(
        task_id=""user_registered_devices"",
        conn_id=""msgraph_api"",
        url=""users/{userId}/registeredDevices"",
        retry_delay=60,
    ).expand(path_parameters=split_work_task.output)

```

you can do this if splitting logic is simple but don't reinvent the wheel ( use a specialize data processing tool/framework for more advanced cases )

dabla (Issue Creator) on (2024-09-30 09:38:41 UTC): Agreed on the specialized framework, but how do you intend to use the Airflow operator there? You won’t be able too. Also, why introduce custom python code to avoid the problem with expand if Airflow would allow you to do it natively?  The example above is how we load our data into our bronze layer, then once done, we use a specialized tool to process those json files.  But if we would want to re do this all in the specialized tool, that would involve a lot more custom python code, which means more maintenance and thus more possible bugs. Using it this way in Airflow, you have a standard non-custom solution purely using operators, no custom code needed, nor workaround needed by fiddling with chunks, which at some point, will again start to fail if there is too much to process.

You could also make the same argument regarding the HttpOperator or even the HttpHook. Why is it in Airflow?  You can do the same with a PythonOperator using the requests or httpx library...  I would then answer: ease of use and integration, no custom code required, Airflow handles it for you in a convenient way.

ashb on (2024-12-03 10:17:04 UTC): I'll go back to the list with this feedback, but this implementation is tantamount to a parallel scheduler, executor and triggerer implementation so is very unlikely to be accepted in to core.

ashb on (2024-12-03 10:17:26 UTC): I very strongly disagree with this statement.

potiuk on (2024-12-03 10:41:33 UTC): Looking forward to the discussion :).  

I am not strong for / against this kind of operators, but I see a class of use cases - which might be very interesting in the near future. I.e. runnig a independent ""airlfow"" tasks on the same machine, using the fact that those independent tasks could store the data they are working on in-memory. Leveraging things like Apache Arrow to enable 0-data-copy optimizations and the fact that many existing tools and libraries already support it. 

And It seems that it very nicely fits into the case where multiple tasks might be using different libraries to run complex - and sometimes parallel but on the same machine - worfklows using that data loadded in CPU and GPU. This has been mentioned multiple times in the past in various forms (but ""task affinity"" is one that seems like best fitting the need there) - and I think streamed Operator as defined now is not really implementing it in the way that is best, but I would not exclude we will get something there sooner or later.

IMHO, we are at the verge on users looking at very aggressive optimizations in this space - and while it all could be done by writing task flow tasks, there is a value in being able to see, observe have dependencies and parallelise those tasks via Airflow mechanisms. I am not sure if ""streamed operator"" is the right abstraction for it and maybe we could make decision this is **not** interesting for the community, I think we should definitely discuss it and see if we can do something there beyond Airflow 3.



Me too.

dabla (Issue Creator) on (2024-12-04 18:36:48 UTC): Yes, that's because you just can't simply execute multiple deferrable operator within a loop by calling their execute method.  Maybe we could think of some kind of interface/expansion mechanism to the PartialOperator that you could enhance with additional functionalities, like here the iterate method which returns an IterableOperator instead of a MappedOperator.  Then we could define this functionality into a provider, then it doesn't have to be part of the core for example if this would be the ultimate issue.  Anyway I've started drafting an AIP with @Joffreybvn where we describe what we want to solve here and also trying to summarize everything we've discussed so far here, in slack and devlists.

"
2555025855,pull_request,closed,,AIP-84 Migrate delete a connection to FastAPI API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42559


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-09-29 16:56:11+00:00,[],2024-10-02 08:48:07+00:00,2024-10-02 08:47:56+00:00,https://github.com/apache/airflow/pull/42571,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2383704615, 'issue_id': 2555025855, 'author': 'bugraoz93', 'body': '> Nice 👍.\r\n> \r\n> A couple of really minor nits / suggestions, but that is already in a mergeable state :)\r\n\r\nThanks for all of your comments! :) All are valuable :pray:', 'created_at': datetime.datetime(2024, 9, 30, 16, 51, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2385073522, 'issue_id': 2555025855, 'author': 'pierrejeambrun', 'body': 'Thanks. Can you rebase the PR, we just merged a new change that updates the `operationId` generated in the openapi spec, this way the front-end generated code has shorter, more meaningful names instead of the current really long ones that are generated.\r\n\r\nBasically you need to use the `AirflowRouter` instead of the `fastapi.APIRouter` (this way the `operationId` is inferred based on the function name of the operation), then regenerate the openapi spec and the frontend code with the pre-commit hooks :)\r\n\r\nI think it might also solves the conflicts.', 'created_at': datetime.datetime(2024, 10, 1, 8, 6, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2386411487, 'issue_id': 2555025855, 'author': 'bugraoz93', 'body': 'I fixed the conflict and generated files again. Great addition, thanks! Indeed, they were quite long :)', 'created_at': datetime.datetime(2024, 10, 1, 16, 3, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387946104, 'issue_id': 2555025855, 'author': 'pierrejeambrun', 'body': 'Thanks @bugraoz93', 'created_at': datetime.datetime(2024, 10, 2, 8, 47, 53, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-09-30 16:51:45 UTC): Thanks for all of your comments! :) All are valuable :pray:

pierrejeambrun on (2024-10-01 08:06:22 UTC): Thanks. Can you rebase the PR, we just merged a new change that updates the `operationId` generated in the openapi spec, this way the front-end generated code has shorter, more meaningful names instead of the current really long ones that are generated.

Basically you need to use the `AirflowRouter` instead of the `fastapi.APIRouter` (this way the `operationId` is inferred based on the function name of the operation), then regenerate the openapi spec and the frontend code with the pre-commit hooks :)

I think it might also solves the conflicts.

bugraoz93 (Issue Creator) on (2024-10-01 16:03:39 UTC): I fixed the conflict and generated files again. Great addition, thanks! Indeed, they were quite long :)

pierrejeambrun on (2024-10-02 08:47:53 UTC): Thanks @bugraoz93

"
2555009676,pull_request,closed,,Permanent fix for Running db.resetdb() (e.g. in test suite) modifies logging.root.level,"- Fixes #42432
- Added a unit test

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-09-29 16:16:07+00:00,[],2024-10-05 13:01:04+00:00,2024-10-04 20:59:01+00:00,https://github.com/apache/airflow/pull/42570,[],"[{'comment_id': 2387463324, 'issue_id': 2555009676, 'author': 'potiuk', 'body': 'Please use try/finally or context manager for that - this will make it into a pemanent fix.', 'created_at': datetime.datetime(2024, 10, 2, 1, 31, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392649604, 'issue_id': 2555009676, 'author': 'potiuk', 'body': 'Some nasty transactional error :)', 'created_at': datetime.datetime(2024, 10, 4, 2, 4, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394580888, 'issue_id': 2555009676, 'author': 'harjeevanmaan', 'body': ""@potiuk I will revert to the original commit and apply the fix temporarily. I'll close this PR and open a new one.\r\nPlease let me know if you have any suggestions"", 'created_at': datetime.datetime(2024, 10, 4, 20, 59, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-02 01:31:52 UTC): Please use try/finally or context manager for that - this will make it into a pemanent fix.

potiuk on (2024-10-04 02:04:35 UTC): Some nasty transactional error :)

harjeevanmaan (Issue Creator) on (2024-10-04 20:59:01 UTC): @potiuk I will revert to the original commit and apply the fix temporarily. I'll close this PR and open a new one.
Please let me know if you have any suggestions

"
2554995249,pull_request,closed,,feat: Add batch_create_links method for creating cross-references between objects,"- handles both `list `and `DataFrame `data
- Added proper validation and error messages for `collection_name`, `from_property`, `from_uuid`, and `to_uuid `fields.
- Ensure fields are present and of the correct type before attempting to add cross-references.
- Retry logic with Retrying mechanism

test: Unit test for batch_create_links method

- Covered scenarios for both `list `and `DataFrame `data input.
- Validated the correct number of reference creations using mock object.

Fixes: #42568

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-09-29 15:42:09+00:00,[],2024-11-28 00:16:21+00:00,2024-11-28 00:16:21+00:00,https://github.com/apache/airflow/pull/42569,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:weaviate', '')]","[{'comment_id': 2394712994, 'issue_id': 2554995249, 'author': 'harjeevanmaan', 'body': '@Lee-W @utkarsharma2 Any updates on this?', 'created_at': datetime.datetime(2024, 10, 4, 21, 47, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2395643685, 'issue_id': 2554995249, 'author': 'Lee-W', 'body': '> @Lee-W @utkarsharma2 Any updates on this?\r\n\r\nWill take a deeper look today', 'created_at': datetime.datetime(2024, 10, 6, 23, 31, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397722770, 'issue_id': 2554995249, 'author': 'harjeevanmaan', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 10, 7, 19, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495134208, 'issue_id': 2554995249, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 23, 0, 16, 15, tzinfo=datetime.timezone.utc)}]","harjeevanmaan (Issue Creator) on (2024-10-04 21:47:08 UTC): @Lee-W @utkarsharma2 Any updates on this?

Lee-W on (2024-10-06 23:31:49 UTC): Will take a deeper look today

harjeevanmaan (Issue Creator) on (2024-10-07 19:31:00 UTC): Thanks!

github-actions[bot] on (2024-11-23 00:16:15 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2554972388,pull_request,closed,,reduce eyestrain in dark mode with reduced contrast and saturation,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

While the new dark mode is very appreciated, the inversion and 180 degree hue rotation creates a harsh contrast that some people find a bit extreme and uncomfortable.  This change simply lowers the saturation and contrast to soften the overall appearance, potentially reducing eyestrain for people with eyes that are sensitive to such high contrast.

Adjusting the contrast also emphasizes the styling between alternating rows in the DAG list. 

Open to suggestions to better tweak it for a broader audience.  

Before:
![airflowbefore](https://github.com/user-attachments/assets/72f9646a-c62a-4f46-891d-f06cd8976145)
![airflowbefore](https://github.com/user-attachments/assets/cafda562-15b6-4cd2-bf91-05794b317a61)


After:
![image](https://github.com/user-attachments/assets/a58a7678-39d5-48d2-823e-5a1d3815c419)
![airflowafter](https://github.com/user-attachments/assets/b334609b-8618-4b14-96fb-02793f75f988)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",codecae,2024-09-29 14:49:15+00:00,[],2024-10-23 09:35:45+00:00,2024-09-30 14:01:36+00:00,https://github.com/apache/airflow/pull/42567,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2381386223, 'issue_id': 2554972388, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 9, 29, 14, 49, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2381412387, 'issue_id': 2554972388, 'author': 'jscheffl', 'body': 'Can you (please) add a screenshot to the description to before and after for the reviewers?\r\n\r\nNote that actually the UI is currently re-workerd and gets a totally different dark-mode in Airflow 3.0. In Airflow 2 we actually only want to make bug fixes. No new features. So we would need to classify this as bug fix? @bbovenzi WDYT?', 'created_at': datetime.datetime(2024, 9, 29, 16, 10, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2381965479, 'issue_id': 2554972388, 'author': 'codecae', 'body': ""> Can you (please) add a screenshot to the description to before and after for the reviewers?\r\n> \r\n> Note that actually the UI is currently re-workerd and gets a totally different dark-mode in Airflow 3.0. In Airflow 2 we actually only want to make bug fixes. No new features. So we would need to classify this as bug fix? @bbovenzi WDYT?\r\n\r\nUnderstand that this is considered an experimental feature and likely will be be deprecated up the next major release.  Until then, I figured that there might be some teams out there that would appreciate this subtle, yet effective styling update.\r\n\r\nI've added screenshots to the description."", 'created_at': datetime.datetime(2024, 9, 30, 4, 7, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2382979813, 'issue_id': 2554972388, 'author': 'codecae', 'body': 'Thanks for the approval @bbovenzi !\r\n\r\nSpeaking of 3.0 UI updates -- Does anyone know if #35301 will be addressed in 3.0? It makes the graph view pretty much a rats nest on large dags.', 'created_at': datetime.datetime(2024, 9, 30, 11, 54, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383291867, 'issue_id': 2554972388, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 30, 14, 1, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387504578, 'issue_id': 2554972388, 'author': 'potiuk', 'body': 'Nice. That was also bothering me.', 'created_at': datetime.datetime(2024, 10, 2, 2, 19, 20, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-29 14:49:20 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jscheffl on (2024-09-29 16:10:56 UTC): Can you (please) add a screenshot to the description to before and after for the reviewers?

Note that actually the UI is currently re-workerd and gets a totally different dark-mode in Airflow 3.0. In Airflow 2 we actually only want to make bug fixes. No new features. So we would need to classify this as bug fix? @bbovenzi WDYT?

codecae (Issue Creator) on (2024-09-30 04:07:54 UTC): Understand that this is considered an experimental feature and likely will be be deprecated up the next major release.  Until then, I figured that there might be some teams out there that would appreciate this subtle, yet effective styling update.

I've added screenshots to the description.

codecae (Issue Creator) on (2024-09-30 11:54:59 UTC): Thanks for the approval @bbovenzi !

Speaking of 3.0 UI updates -- Does anyone know if #35301 will be addressed in 3.0? It makes the graph view pretty much a rats nest on large dags.

boring-cyborg[bot] on (2024-09-30 14:01:39 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-10-02 02:19:20 UTC): Nice. That was also bothering me.

"
2554949020,pull_request,closed,,Added delete_by_property method,"- Delete collections by specifying one or more properties.
- Use optional filters (`contains_any` or `contains_all`) to  allow deletion of objects that match a set of criteria.
-  Fixes #42565

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-09-29 13:56:22+00:00,[],2024-10-23 20:11:29+00:00,2024-10-23 20:11:29+00:00,https://github.com/apache/airflow/pull/42566,"[('area:providers', ''), ('provider:weaviate', '')]","[{'comment_id': 2399811382, 'issue_id': 2554949020, 'author': 'harjeevanmaan', 'body': 'Thanks for your guidance', 'created_at': datetime.datetime(2024, 10, 8, 13, 12, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401045247, 'issue_id': 2554949020, 'author': 'harjeevanmaan', 'body': 'Looking into the test fails', 'created_at': datetime.datetime(2024, 10, 9, 0, 33, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2421598442, 'issue_id': 2554949020, 'author': 'Lee-W', 'body': ""We'll need to resolve conflicts before the next round of reviewing :)"", 'created_at': datetime.datetime(2024, 10, 18, 7, 4, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2433341452, 'issue_id': 2554949020, 'author': 'harjeevanmaan', 'body': 'I agree', 'created_at': datetime.datetime(2024, 10, 23, 20, 10, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2433343690, 'issue_id': 2554949020, 'author': 'harjeevanmaan', 'body': ""I'm sorry to everyone who got notified. It was a mistake on my end"", 'created_at': datetime.datetime(2024, 10, 23, 20, 11, 29, tzinfo=datetime.timezone.utc)}]","harjeevanmaan (Issue Creator) on (2024-10-08 13:12:32 UTC): Thanks for your guidance

harjeevanmaan (Issue Creator) on (2024-10-09 00:33:55 UTC): Looking into the test fails

Lee-W on (2024-10-18 07:04:48 UTC): We'll need to resolve conflicts before the next round of reviewing :)

harjeevanmaan (Issue Creator) on (2024-10-23 20:10:10 UTC): I agree

harjeevanmaan (Issue Creator) on (2024-10-23 20:11:29 UTC): I'm sorry to everyone who got notified. It was a mistake on my end

"
2554722601,pull_request,closed,,Documentation change to highlight difference in usage between params and parameters attributes in SQLExecuteQueryOperator for Postgres,"Closes #42344 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-09-29 05:54:40+00:00,[],2024-10-02 19:46:57+00:00,2024-09-29 16:25:21+00:00,https://github.com/apache/airflow/pull/42564,"[('area:providers', ''), ('kind:documentation', ''), ('provider:postgres', '')]","[{'comment_id': 2381416740, 'issue_id': 2554722601, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 29, 16, 25, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2388856090, 'issue_id': 2554722601, 'author': 'kunaljubce', 'body': ""@jscheffl I still don't see these changes reflected in the [documentation](https://airflow.apache.org/docs/apache-airflow-providers-postgres/stable/operators/postgres_operator_howto_guide.html#passing-parameters-into-sqlexecutequeryoperator-for-postgres). \r\n\r\nIs this because the doc build has been done yet? Sorry I am probably asking a very basic question, getting used to the ways of working here."", 'created_at': datetime.datetime(2024, 10, 2, 14, 47, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389548985, 'issue_id': 2554722601, 'author': 'jscheffl', 'body': 'No worry. Documentation is published once we cut the next minor release version. It is not reflecting latest main.', 'created_at': datetime.datetime(2024, 10, 2, 19, 46, 56, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-29 16:25:23 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

kunaljubce (Issue Creator) on (2024-10-02 14:47:37 UTC): @jscheffl I still don't see these changes reflected in the [documentation](https://airflow.apache.org/docs/apache-airflow-providers-postgres/stable/operators/postgres_operator_howto_guide.html#passing-parameters-into-sqlexecutequeryoperator-for-postgres). 

Is this because the doc build has been done yet? Sorry I am probably asking a very basic question, getting used to the ways of working here.

jscheffl on (2024-10-02 19:46:56 UTC): No worry. Documentation is published once we cut the next minor release version. It is not reflecting latest main.

"
2554596673,pull_request,closed,,partial kwargs deserialized MappedOperator set on unmapped Operator,"Forwarding the partial kwargs to the underlying operator is done in the standard (non-serialization) case and thus it should be done here as well for things in the webserver that rely on these fixed attributes.

An example is the `Triggered DAG` link for the `TriggerDagRunOperator`.

Tested w/the following DAG:
```
from airflow.decorators import dag, task
from airflow.operators.trigger_dagrun import TriggerDagRunOperator


@dag()
def triggering_dag():
    """"""
    DAG that is doing the triggering.
    """"""
    t = TriggerDagRunOperator.partial(
        trigger_dag_id=""triggered_dag"",
        task_id=""triggering_task"",
        reset_dag_run=True,
    ).expand(trigger_run_id=[""trigger_run_id1__{{ ts }}"", ""trigger_run_id2__{{ ts }}""])

    t

@dag()
def triggered_dag():
    """"""
    DAG that is getting triggered.
    """"""

    @task()
    def empty_task() -> int:
        return 0

    empty_task()

triggering_dag()
triggered_dag()
```

closes: #41145
closes: #32150



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #41145
closes: #32150

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",fredthomsen,2024-09-29 01:24:15+00:00,[],2024-11-18 07:08:45+00:00,2024-11-18 07:08:45+00:00,https://github.com/apache/airflow/pull/42563,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2381127282, 'issue_id': 2554596673, 'author': 'fredthomsen', 'body': 'I was wondering how `test_operator_expand_deserialized_unmap` was working prior and I see that `BaseOperator.__eq__` only compares against a certain subset of attributes, thus using that in the assertion for this test is not valid.', 'created_at': datetime.datetime(2024, 9, 29, 6, 24, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475083815, 'issue_id': 2554596673, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 14, 0, 14, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481581401, 'issue_id': 2554596673, 'author': 'fredthomsen', 'body': '@uranusjr do I need to request a review from anyone else here?', 'created_at': datetime.datetime(2024, 11, 17, 21, 20, 11, tzinfo=datetime.timezone.utc)}]","fredthomsen (Issue Creator) on (2024-09-29 06:24:28 UTC): I was wondering how `test_operator_expand_deserialized_unmap` was working prior and I see that `BaseOperator.__eq__` only compares against a certain subset of attributes, thus using that in the assertion for this test is not valid.

github-actions[bot] on (2024-11-14 00:14:57 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

fredthomsen (Issue Creator) on (2024-11-17 21:20:11 UTC): @uranusjr do I need to request a review from anyone else here?

"
2553880856,pull_request,closed,,fix PyDocStyle checks,"related: #40567 
PT004 | Fixture does not return anything, add leading underscore
Reduces PT004 errors from 332 to 327.
Submitting changes in multiple small PR's as requested in #40567 .

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dannyl1u,2024-09-27 23:32:03+00:00,[],2024-09-29 15:34:24+00:00,2024-09-29 11:42:01+00:00,https://github.com/apache/airflow/pull/42557,"[('area:webserver', 'Webserver related Issues')]",[],
2553730843,pull_request,closed,,Remove callable functions parameter from kafka operator template_fields,"closes: #42502
 
The Kafka ConsumeFromTopicOperator and ProduceToTopicOperator are failing to resolve callable template fields. For a callable to work with template functions, it must accept both the context and jinja_env.

If we include `producer_function` and `apply_function` in the template fields, all current users will need to modify their scripts to accept both `context` and `jinja_env`. and some minor updates require in kafka operator.

I also tested another scenario where the function does accept context and jinja_env, but in the UI template field, it appears as a generated type object(please check below screenshot). Since there isn’t much value in displaying this field as a generated type object, I believe it's better to remove these from the template fields altogether.

Any other suggestion please?


<img width=""1345"" alt=""image"" src=""https://github.com/user-attachments/assets/c957818c-81e7-4d56-bbbc-303270287b4a"">





Removed the fields and executed kafka system test.


![image](https://github.com/user-attachments/assets/1d593b8f-9b1f-4557-8130-8f7d7edd9754)


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-09-27 21:01:53+00:00,[],2024-11-02 13:05:49+00:00,2024-09-29 11:40:37+00:00,https://github.com/apache/airflow/pull/42555,"[('area:providers', ''), ('provider:apache-kafka', '')]","[{'comment_id': 2380880382, 'issue_id': 2553730843, 'author': 'raphaelauv', 'body': 'Yes I did the same for https://github.com/apache/airflow/pull/39948\n\nThat was the only callable that was in the templated_fields of the operator that I detected thanks to a unit test breaking', 'created_at': datetime.datetime(2024, 9, 28, 19, 59, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2380880904, 'issue_id': 2553730843, 'author': 'gopidesupavan', 'body': ""> I'm not entirely sure that removing these parameters is the right way to deal with it (then you'll break compatibility with older Airflow versions where it works). @uranusjr / @raphaelauv - I would be happy for your feedback.\r\n\r\nThanks for the review. Yes i completely agree. but IMHO keeping these parameters also cause problems here. https://github.com/apache/airflow/blob/main/airflow/models/abstractoperator.py#L768 \r\n\r\nhere the callable value args has only context and jinja_env, if the function does accepts more arguments this would fail ?.\r\n\r\nHappy for any other suggestions :)"", 'created_at': datetime.datetime(2024, 9, 28, 20, 1, 26, tzinfo=datetime.timezone.utc)}]","raphaelauv on (2024-09-28 19:59:19 UTC): Yes I did the same for https://github.com/apache/airflow/pull/39948

That was the only callable that was in the templated_fields of the operator that I detected thanks to a unit test breaking

gopidesupavan (Issue Creator) on (2024-09-28 20:01:26 UTC): Thanks for the review. Yes i completely agree. but IMHO keeping these parameters also cause problems here. https://github.com/apache/airflow/blob/main/airflow/models/abstractoperator.py#L768 

here the callable value args has only context and jinja_env, if the function does accepts more arguments this would fail ?.

Happy for any other suggestions :)

"
2553710398,pull_request,closed,,openlineage: add unit test for listener hooks on dag run state changes and task instance failure,"Recent fix in https://github.com/apache/airflow/pull/42448 revealed missing tests for emission of events in several cases.
This PR aims to increase the coverage.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JDarDagran,2024-09-27 20:44:46+00:00,[],2024-10-01 12:16:03+00:00,2024-10-01 12:16:03+00:00,https://github.com/apache/airflow/pull/42554,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2553665391,pull_request,closed,,Remove DagRunNotBackfillDep,"This is part of AIP-78.  It is a dep that is designed to make tasks not run if they are in a backfill dag run.  No longer needed.
",dstandish,2024-09-27 20:13:52+00:00,[],2024-10-03 02:31:42+00:00,2024-10-03 02:31:41+00:00,https://github.com/apache/airflow/pull/42552,[],"[{'comment_id': 2381117403, 'issue_id': 2553665391, 'author': 'uranusjr', 'body': 'I guess instead of asking why this is no longer needed, why was this ever needed?', 'created_at': datetime.datetime(2024, 9, 29, 5, 45, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2383574845, 'issue_id': 2553665391, 'author': 'dstandish', 'body': '> I guess instead of asking why this is no longer needed, why was this ever needed?\r\n\r\nIt was part of the set of `SCHEDULER_QUEUED_DEPS`\r\n\r\nIts effect was to prevent backfill dag run TIs from being queued by the scheduler.', 'created_at': datetime.datetime(2024, 9, 30, 15, 50, 8, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-09-29 05:45:01 UTC): I guess instead of asking why this is no longer needed, why was this ever needed?

dstandish (Issue Creator) on (2024-09-30 15:50:08 UTC): It was part of the set of `SCHEDULER_QUEUED_DEPS`

Its effect was to prevent backfill dag run TIs from being queued by the scheduler.

"
2553643421,pull_request,closed,,Attempt to correct dependency for Slack notification for canary build,"Follow-up of #42394

...as the Slack notifier is not working, attempt to my best knowledge to adjust the dependency of the task to run behind all others.
Picking up all named stated which have no follow-up dependency",jscheffl,2024-09-27 19:58:17+00:00,[],2024-09-28 07:34:19+00:00,2024-09-28 07:34:19+00:00,https://github.com/apache/airflow/pull/42551,"[('area:dev-tools', '')]",[],
2553460355,pull_request,closed,,Remove DagRun.is_backfill attribute,"This attribute is only used in one place and is not very useful.
",dstandish,2024-09-27 18:01:08+00:00,[],2024-09-27 20:25:21+00:00,2024-09-27 20:25:19+00:00,https://github.com/apache/airflow/pull/42548,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2553218428,pull_request,closed,,AIP-65: Add versioning to the SerializedDagModel ,"Depends on #42517
This commit adds versioning to the serializedDagModel.

Changes:
Added new columns, id, and version_number to the SDM and made id the
primary key.

Updated the write_dag method of the SDM to add the SDs correctly.

Updated the queries so the scheduler/webserver runs with the latest SDM 

The version_number was added to help us track the evolution of a DAG.
Suppose a DAG with dag_hash AB is changed, and the dag_hash becomes CD.
If the change is reverted, we will have a dag_hash of AB again. In this
case, the version_number would still increment, letting us know that the
DAG was changed three times. I feel it's a meaningful way to track the changes,
independent of the id column, which is database internals.


",ephraimbuddy,2024-09-27 15:31:46+00:00,[],2024-10-15 13:04:45+00:00,2024-10-15 13:04:44+00:00,https://github.com/apache/airflow/pull/42547,"[('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2413862377, 'issue_id': 2553218428, 'author': 'ephraimbuddy', 'body': 'Closing in preference of #42913', 'created_at': datetime.datetime(2024, 10, 15, 13, 4, 44, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-10-15 13:04:44 UTC): Closing in preference of #42913

"
2553115773,pull_request,closed,,AIP-84 Migrate patch dags to FastAPI API,Closes: https://github.com/apache/airflow/issues/42544,pierrejeambrun,2024-09-27 14:43:45+00:00,['pierrejeambrun'],2024-09-30 15:04:27+00:00,2024-09-30 15:04:25+00:00,https://github.com/apache/airflow/pull/42545,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2379975209, 'issue_id': 2553115773, 'author': 'jscheffl', 'body': 'need to fiy pytest before merge but else good... lgtm!', 'created_at': datetime.datetime(2024, 9, 27, 20, 6, 59, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-09-27 20:06:59 UTC): need to fiy pytest before merge but else good... lgtm!

"
2552713259,pull_request,closed,,Fix incorrect operator name in FileTransferOperator example,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Small typo fix

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dan-js,2024-09-27 11:40:25+00:00,[],2024-09-27 14:58:25+00:00,2024-09-27 12:56:48+00:00,https://github.com/apache/airflow/pull/42543,"[('area:providers', ''), ('kind:documentation', ''), ('provider:common-io', '')]","[{'comment_id': 2379078391, 'issue_id': 2552713259, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 9, 27, 11, 40, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2379221534, 'issue_id': 2552713259, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 9, 27, 12, 56, 50, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-27 11:40:29 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-09-27 12:56:50 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2552559156,pull_request,closed,,Undo partition exclusion from the table name when splitting a full BigQuery table name,"Undo partition exclusion from the table name when splitting a full BigQuery table name. 

Relates to https://github.com/apache/airflow/pull/42130",moiseenkov,2024-09-27 10:17:15+00:00,[],2024-10-24 16:08:19+00:00,2024-09-27 10:57:14+00:00,https://github.com/apache/airflow/pull/42541,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2402060280, 'issue_id': 2552559156, 'author': 'kev-datams', 'body': 'hello @moiseenkov, no need to change [this line](https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/hooks/bigquery.py#L3338) also ?', 'created_at': datetime.datetime(2024, 10, 9, 11, 30, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410726943, 'issue_id': 2552559156, 'author': 'moiseenkov', 'body': '> hello @moiseenkov, no need to change [this line](https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/hooks/bigquery.py#L3338) also ?\r\n\r\nHi, Sorry for the late response.\r\nIf the question is still relevant, should you please update the link? It gives me 404 error.', 'created_at': datetime.datetime(2024, 10, 14, 10, 22, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2435699930, 'issue_id': 2552559156, 'author': 'kev-datams', 'body': '> > hello @moiseenkov, no need to change [this line](https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/hooks/bigquery.py#L3338) also ?\r\n> \r\n> Hi, Sorry for the late response. If the question is still relevant, should you please update the link? It gives me 404 error.\r\n\r\nHi @moiseenkov , this is the updated link : https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/google/cloud/hooks/bigquery.py#L3338', 'created_at': datetime.datetime(2024, 10, 24, 16, 8, 17, tzinfo=datetime.timezone.utc)}]","kev-datams on (2024-10-09 11:30:08 UTC): hello @moiseenkov, no need to change [this line](https://github.com/apache/airflow/blob/main/airflow/providers/google/cloud/hooks/bigquery.py#L3338) also ?

moiseenkov (Issue Creator) on (2024-10-14 10:22:05 UTC): Hi, Sorry for the late response.
If the question is still relevant, should you please update the link? It gives me 404 error.

kev-datams on (2024-10-24 16:08:17 UTC): Hi @moiseenkov , this is the updated link : https://github.com/apache/airflow/blob/main/providers/src/airflow/providers/google/cloud/hooks/bigquery.py#L3338

"
2552448189,pull_request,closed,,Feature: Added event_handler parameter in MSGraphAsyncOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Added an event_handler parameter in MSGraphAsyncOperator which allows you to override the default implementation when needed.  This can be handy when you want to handle certain failed event types returned by the triggerer.  Also added a unit test for this new feature and updated docstring.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-09-27 09:25:35+00:00,[],2024-10-15 07:35:31+00:00,2024-10-15 00:41:36+00:00,https://github.com/apache/airflow/pull/42539,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2396739294, 'issue_id': 2552448189, 'author': 'dabla', 'body': 'Dunno why following tests keeps failing, it succeeds locally:\r\n\r\n```\r\nFAILED tests/providers/microsoft/azure/operators/test_data_factory.py::TestAzureDataFactoryRunPipelineOperator::test_execute_wait_for_termination[Canceling-timeout] - AssertionError: assert 2 == 4\r\n +  where 2 = <MagicMock name=\'get_pipeline_run\' id=\'139745815447776\'>.call_count\r\n=========== 1 failed, 6661 passed, 60 skipped in 1235.68s (0:20:35) ============\r\n/usr/local/lib/python3.8/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option ""asyncio_default_fixture_loop_scope"" is unset.\r\nThe event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: ""function"", ""class"", ""module"", ""package"", ""session""\r\n```', 'created_at': datetime.datetime(2024, 10, 7, 12, 4, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397932069, 'issue_id': 2552448189, 'author': 'potiuk', 'body': ""Did you try reproducing it with upgraded boto:\r\n\r\nIf you unfold the failed output you will see this:\r\n\r\n```bash\r\n  Upgrading boto3, botocore to latest version to run Amazon tests with them\r\n  \r\n  Uninstalled 4 packages in 395ms\r\n   - aiobotocore==2.15.1\r\n   - opensearch-py==2.7.1\r\n   - s3fs==2024.9.0\r\n   - yandexcloud==0.320.0\r\n  + uv pip install --python /usr/local/bin/python --upgrade boto3 botocore 'oss2>=2.14.0' 'cryptography<43.0.0' 'requests!=2.32.*,<3.0.0,>=2.24.0'\r\n  Resolved 19 packages in 2.87s\r\n  Prepared 3 packages in 438ms\r\n  Uninstalled 3 packages in 882ms\r\n  Installed 3 packages in 139ms\r\n   - boto3==1.35.23\r\n   + boto3==1.35.34\r\n   - botocore==1.35.23\r\n   + botocore==1.35.34\r\n   - requests==2.32.3\r\n   + requests==2.31.0\r\n```\r\n\r\nWhich can be locally reproduced with:\r\n\r\n```\r\nbreeze shell --upgrade-botot\r\n```\r\n\r\n\r\nAnd then rerunning the tests."", 'created_at': datetime.datetime(2024, 10, 7, 21, 28, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2397933097, 'issue_id': 2552448189, 'author': 'potiuk', 'body': '(It might also be transitive / accidental side effect)', 'created_at': datetime.datetime(2024, 10, 7, 21, 28, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2399388705, 'issue_id': 2552448189, 'author': 'dabla', 'body': '> (It might also be transitive / accidental side effect)\r\n\r\nApparently it was, it failed for days even after updates now it passes :)', 'created_at': datetime.datetime(2024, 10, 8, 9, 51, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2409538800, 'issue_id': 2552448189, 'author': 'potiuk', 'body': 'It looks that there were some changes in looker/kiota packages recently. Can you please rebase again and resolve conflicts and see where it is and ping me if you still see errors ?', 'created_at': datetime.datetime(2024, 10, 14, 0, 58, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410140138, 'issue_id': 2552448189, 'author': 'dabla', 'body': '> It looks that there were some changes in looker/kiota packages recently. Can you please rebase again and resolve conflicts and see where it is and ping me if you still see errors ?\r\n\r\nResolved conflicts, will see how the build behaves.', 'created_at': datetime.datetime(2024, 10, 14, 6, 26, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410268045, 'issue_id': 2552448189, 'author': 'dabla', 'body': '> It looks that there were some changes in looker/kiota packages recently. Can you please rebase again and resolve conflicts and see where it is and ping me if you still see errors ?\r\n\r\nEverything is fine now after update and conflict resolution', 'created_at': datetime.datetime(2024, 10, 14, 7, 28, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412594725, 'issue_id': 2552448189, 'author': 'potiuk', 'body': 'Woooohooo!', 'created_at': datetime.datetime(2024, 10, 15, 0, 41, 46, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2024-10-07 12:04:03 UTC): Dunno why following tests keeps failing, it succeeds locally:

```
FAILED tests/providers/microsoft/azure/operators/test_data_factory.py::TestAzureDataFactoryRunPipelineOperator::test_execute_wait_for_termination[Canceling-timeout] - AssertionError: assert 2 == 4
 +  where 2 = <MagicMock name='get_pipeline_run' id='139745815447776'>.call_count
=========== 1 failed, 6661 passed, 60 skipped in 1235.68s (0:20:35) ============
/usr/local/lib/python3.8/site-packages/pytest_asyncio/plugin.py:208: PytestDeprecationWarning: The configuration option ""asyncio_default_fixture_loop_scope"" is unset.
The event loop scope for asynchronous fixtures will default to the fixture caching scope. Future versions of pytest-asyncio will default the loop scope for asynchronous fixtures to function scope. Set the default fixture loop scope explicitly in order to avoid unexpected behavior in the future. Valid fixture loop scopes are: ""function"", ""class"", ""module"", ""package"", ""session""
```

potiuk on (2024-10-07 21:28:06 UTC): Did you try reproducing it with upgraded boto:

If you unfold the failed output you will see this:

```bash
  Upgrading boto3, botocore to latest version to run Amazon tests with them
  
  Uninstalled 4 packages in 395ms
   - aiobotocore==2.15.1
   - opensearch-py==2.7.1
   - s3fs==2024.9.0
   - yandexcloud==0.320.0
  + uv pip install --python /usr/local/bin/python --upgrade boto3 botocore 'oss2>=2.14.0' 'cryptography<43.0.0' 'requests!=2.32.*,<3.0.0,>=2.24.0'
  Resolved 19 packages in 2.87s
  Prepared 3 packages in 438ms
  Uninstalled 3 packages in 882ms
  Installed 3 packages in 139ms
   - boto3==1.35.23
   + boto3==1.35.34
   - botocore==1.35.23
   + botocore==1.35.34
   - requests==2.32.3
   + requests==2.31.0
```

Which can be locally reproduced with:

```
breeze shell --upgrade-botot
```


And then rerunning the tests.

potiuk on (2024-10-07 21:28:47 UTC): (It might also be transitive / accidental side effect)

dabla (Issue Creator) on (2024-10-08 09:51:33 UTC): Apparently it was, it failed for days even after updates now it passes :)

potiuk on (2024-10-14 00:58:02 UTC): It looks that there were some changes in looker/kiota packages recently. Can you please rebase again and resolve conflicts and see where it is and ping me if you still see errors ?

dabla (Issue Creator) on (2024-10-14 06:26:59 UTC): Resolved conflicts, will see how the build behaves.

dabla (Issue Creator) on (2024-10-14 07:28:24 UTC): Everything is fine now after update and conflict resolution

potiuk on (2024-10-15 00:41:46 UTC): Woooohooo!

"
2552373641,pull_request,closed,,Fix broken main re generated api typescript comment (#42500),"(cherry picked from commit 73dd6c17bd10ddda63a1682ac2174b0d206590dd)

Necessary because the test branch CI is broken at the moment:
https://github.com/apache/airflow/actions/runs/11067168068/job/30750105430?pr=42535

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2024-09-27 08:48:23+00:00,[],2024-09-27 09:31:12+00:00,2024-09-27 09:31:10+00:00,https://github.com/apache/airflow/pull/42537,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2552361787,pull_request,closed,,Update code owners,Just to be sure that community PRs on that new components are not left with no reviewers.,pierrejeambrun,2024-09-27 08:42:16+00:00,[],2024-09-27 08:52:32+00:00,2024-09-27 08:52:30+00:00,https://github.com/apache/airflow/pull/42536,"[('area:dev-tools', '')]",[],
2552325837,pull_request,closed,,Handle ENTER key correctly in trigger form and allow manual JSON (#42…,(cherry picked from commit https://github.com/apache/airflow/commit/3ef29a641a852c076da7a9611c325669e8485368),pierrejeambrun,2024-09-27 08:23:51+00:00,[],2024-09-27 08:46:43+00:00,2024-09-27 08:46:43+00:00,https://github.com/apache/airflow/pull/42535,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2552180771,pull_request,closed,,skip_archive should actually skip archive in db clean command,"Closes: #42003
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pratik-m,2024-09-27 07:10:59+00:00,[],2024-11-24 00:17:29+00:00,2024-11-24 00:17:29+00:00,https://github.com/apache/airflow/pull/42533,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2378558632, 'issue_id': 2552180771, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 9, 27, 7, 11, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2378704395, 'issue_id': 2552180771, 'author': 'shahar1', 'body': 'Could you please add some details / link to related issue? Thanks!', 'created_at': datetime.datetime(2024, 9, 27, 8, 13, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2380204669, 'issue_id': 2552180771, 'author': 'pratik-m', 'body': ""Hi @shahar1 - This is related to the issue #42003 skip_archive should actually skip archive in db clean command \r\nCurrently the delete process uses the archive table in the process of deletion. But we should refactor this so it doesn't need this and actually not create the archive table at all when user specifies this option.\r\n\r\nEarlier, the data used to be backed up in an archive table and was then joined with the main table to delete the data. I've refactored the code to separate these two steps. The delete happens independently of the archival. \r\n\r\n**Changes done:** \r\nGenerated a delete statement based on the conditions/filters used to create the select statement. This was done as we cannot generate the delete statement out of the select. Also, there is a specific condition which does a left outer join to a subquery which cannot be directly translated to a delete statement. \r\n\r\nSelect statement generated: \r\n`SELECT base.* FROM dag_run AS base LEFT OUTER JOIN (SELECT dag_id, max(dag_run.start_date) AS max_date_per_group FROM dag_run WHERE external_trigger = false GROUP BY dag_id) AS latest ON base.dag_id = latest.dag_id AND base.start_date = max_date_per_group WHERE base.start_date < :start_date_1 AND max_date_per_group IS NULL;`\r\n\r\nDelete statement generated: \r\nDELETE FROM dag_run AS base WHERE NOT (EXISTS (SELECT latest.dag_id, latest.max_date_per_group\r\nFROM (SELECT dag_id, max(dag_run.start_date) AS max_date_per_group\r\nFROM dag_run\r\nWHERE external_trigger = false GROUP BY dag_id) AS latest\r\nWHERE base.dag_id = latest.dag_id AND base.start_date = max_date_per_group)) AND base.start_date < :start_date_1"", 'created_at': datetime.datetime(2024, 9, 27, 22, 14, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2387217615, 'issue_id': 2552180771, 'author': 'dstandish', 'body': 'OK so, first off, great work on this and thanks for your effort.\r\n\r\nWhen reviewing the sql i noticed a few things.\r\n\r\n1. Previously we archive first and then delete rows from the archive table by id.  This ensures nothing is deleted unless we\'re sure we have an archived copy of it.    Before, we would move all the delete candidates to a table and delete only those records by matching pk.  But now, we use two separate queries right?  What I think we need to do is (a) if skipping archive, then this is a non-issue -- just delete the rows according to the filter.  But (b) if archiving, i think we need to keep the existing logic where we archive first then delete using the archive table.  However (c) I realized that at least for postgres, there is an optimization available to us.  Specifically, we can just do the delete, then redirect the rows to a second table at the same time.  Here is sample code to demonstrate this on postgres.\r\n```\r\nDROP TABLE IF EXISTS t1;\r\ncreate table t1\r\n(\r\n    id  int,\r\n    val varchar(100)\r\n);\r\ninsert into t1\r\nvalues (1, \'a\'),\r\n       (2, \'a\'),\r\n       (3, \'a\'),\r\n       (4, \'a\'),\r\n       (5, \'a\'),\r\n       (6, \'a\'),\r\n       (7, \'a\');\r\n\r\ncreate table t2 (like t1);\r\n\r\nwith deleted_rows as (\r\n    delete\r\n    from t1\r\n    where t1.id in (2, 3)\r\n    returning *\r\n)\r\ninsert into t2\r\nSELECT *\r\nFROM deleted_rows;\r\n```\r\nMysql doesn\'t have this capability it seems so we will have to continue to do a 2-step process i think.\r\n\r\n2. when looking at the ""last"" record for dag run (since there\'s logic to keep the last one), for some reason we are using start_date instead of execution_date; we should not be.  The point of this feature is to keep the latest run *from a scheduling perspective*, so the next run is what it should be.  I think the easiest and most explicit way to deal with this is to add column `keep_last_recency_column` to the _TableConfig class and use that in generating the query (and set it to be execution_date).  This is certainly a separate PR but it should be done and you may be interested and if so I\'m happy to review.\r\n\r\n3. I think that to have confidence about these changes, I think it would really be best to do two separate PRs -- one where we add the sql output to the tests, and then follow up with the PR that implements the changes in the archive behavior.  I think that we need to improve the tests so that we see the full sequence of sql statements for both mysql and postges for the main scenarios (archive or no, and keep last or no).   May seem like overkill but what we\'re dealing with here is destructive operations so we need to proceed with due care.  For caputring the sql statements, I experimented with using the events API to selectively record them.  Here\'s an example of how you can do (just drop this in the test file)\r\n\r\n```\r\nfrom sqlalchemy import event\r\nfrom sqlalchemy.engine import Engine\r\n\r\nsql_statements = []\r\n\r\n\r\n@pytest.fixture(autouse=True)\r\ndef clear_statements():\r\n    sql_statements.clear()\r\n\r\n\r\n@event.listens_for(Session, ""after_begin"")\r\ndef session_on_after_begin(session, transaction, connection):\r\n    if ""in-test"" in session.info:\r\n        connection.info[""in-test""] = session.info[""in-test""]\r\n\r\n\r\n@event.listens_for(Engine, ""before_cursor_execute"", retval=True)\r\ndef capture_sql_statements(conn, cursor, statement, parameters, context, executemany):\r\n    if ""in-test"" in conn.info:\r\n        sql_statements.append(statement)\r\n    return statement, parameters\r\n```\r\n\r\nThen you can trigger capturing of statements by adding `session.info[""in-test""] = True` and stop capture with `del session.info[""in-test""]`.\r\n\r\nThen you can make asserts about the statements and show the exact sequence of statements that are emitted in the important scenarios. \r\n\r\nThanks a bunch', 'created_at': datetime.datetime(2024, 10, 1, 22, 48, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389423329, 'issue_id': 2552180771, 'author': 'pratik-m', 'body': ""Thanks for the comment! I'll work and share the new/update PR !"", 'created_at': datetime.datetime(2024, 10, 2, 18, 30, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2390600704, 'issue_id': 2552180771, 'author': 'pratik-m', 'body': ""Hi @dstandish - I've read through your comments and here's the summary: \r\n\r\nThere are three issues that we need to focus on and a separate PR needs to be created for each of them\r\n1. **recency column change for dag_run**: The recency column already exists in `TableConfig` called as `recency_column_name` . Instead of `start_date` it needs to be `execution_date`. \r\n2. **Improve test cases**: Need to include additional test cases for the sql generated for postgres and myself \r\n3. **Archival behavior**: Update the archival behavior to skip archive if option selected (this PR). \r\n\r\nLet me know if I missed any point. I'll create two additional PR for 1 and 2 and share the details once done. \r\n\r\nThanks!"", 'created_at': datetime.datetime(2024, 10, 3, 6, 10, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481696821, 'issue_id': 2552180771, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 18, 0, 16, 45, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-27 07:11:02 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

shahar1 on (2024-09-27 08:13:02 UTC): Could you please add some details / link to related issue? Thanks!

pratik-m (Issue Creator) on (2024-09-27 22:14:06 UTC): Hi @shahar1 - This is related to the issue #42003 skip_archive should actually skip archive in db clean command 
Currently the delete process uses the archive table in the process of deletion. But we should refactor this so it doesn't need this and actually not create the archive table at all when user specifies this option.

Earlier, the data used to be backed up in an archive table and was then joined with the main table to delete the data. I've refactored the code to separate these two steps. The delete happens independently of the archival. 

**Changes done:** 
Generated a delete statement based on the conditions/filters used to create the select statement. This was done as we cannot generate the delete statement out of the select. Also, there is a specific condition which does a left outer join to a subquery which cannot be directly translated to a delete statement. 

Select statement generated: 
`SELECT base.* FROM dag_run AS base LEFT OUTER JOIN (SELECT dag_id, max(dag_run.start_date) AS max_date_per_group FROM dag_run WHERE external_trigger = false GROUP BY dag_id) AS latest ON base.dag_id = latest.dag_id AND base.start_date = max_date_per_group WHERE base.start_date < :start_date_1 AND max_date_per_group IS NULL;`

Delete statement generated: 
DELETE FROM dag_run AS base WHERE NOT (EXISTS (SELECT latest.dag_id, latest.max_date_per_group
FROM (SELECT dag_id, max(dag_run.start_date) AS max_date_per_group
FROM dag_run
WHERE external_trigger = false GROUP BY dag_id) AS latest
WHERE base.dag_id = latest.dag_id AND base.start_date = max_date_per_group)) AND base.start_date < :start_date_1

dstandish on (2024-10-01 22:48:05 UTC): OK so, first off, great work on this and thanks for your effort.

When reviewing the sql i noticed a few things.

1. Previously we archive first and then delete rows from the archive table by id.  This ensures nothing is deleted unless we're sure we have an archived copy of it.    Before, we would move all the delete candidates to a table and delete only those records by matching pk.  But now, we use two separate queries right?  What I think we need to do is (a) if skipping archive, then this is a non-issue -- just delete the rows according to the filter.  But (b) if archiving, i think we need to keep the existing logic where we archive first then delete using the archive table.  However (c) I realized that at least for postgres, there is an optimization available to us.  Specifically, we can just do the delete, then redirect the rows to a second table at the same time.  Here is sample code to demonstrate this on postgres.
```
DROP TABLE IF EXISTS t1;
create table t1
(
    id  int,
    val varchar(100)
);
insert into t1
values (1, 'a'),
       (2, 'a'),
       (3, 'a'),
       (4, 'a'),
       (5, 'a'),
       (6, 'a'),
       (7, 'a');

create table t2 (like t1);

with deleted_rows as (
    delete
    from t1
    where t1.id in (2, 3)
    returning *
)
insert into t2
SELECT *
FROM deleted_rows;
```
Mysql doesn't have this capability it seems so we will have to continue to do a 2-step process i think.

2. when looking at the ""last"" record for dag run (since there's logic to keep the last one), for some reason we are using start_date instead of execution_date; we should not be.  The point of this feature is to keep the latest run *from a scheduling perspective*, so the next run is what it should be.  I think the easiest and most explicit way to deal with this is to add column `keep_last_recency_column` to the _TableConfig class and use that in generating the query (and set it to be execution_date).  This is certainly a separate PR but it should be done and you may be interested and if so I'm happy to review.

3. I think that to have confidence about these changes, I think it would really be best to do two separate PRs -- one where we add the sql output to the tests, and then follow up with the PR that implements the changes in the archive behavior.  I think that we need to improve the tests so that we see the full sequence of sql statements for both mysql and postges for the main scenarios (archive or no, and keep last or no).   May seem like overkill but what we're dealing with here is destructive operations so we need to proceed with due care.  For caputring the sql statements, I experimented with using the events API to selectively record them.  Here's an example of how you can do (just drop this in the test file)

```
from sqlalchemy import event
from sqlalchemy.engine import Engine

sql_statements = []


@pytest.fixture(autouse=True)
def clear_statements():
    sql_statements.clear()


@event.listens_for(Session, ""after_begin"")
def session_on_after_begin(session, transaction, connection):
    if ""in-test"" in session.info:
        connection.info[""in-test""] = session.info[""in-test""]


@event.listens_for(Engine, ""before_cursor_execute"", retval=True)
def capture_sql_statements(conn, cursor, statement, parameters, context, executemany):
    if ""in-test"" in conn.info:
        sql_statements.append(statement)
    return statement, parameters
```

Then you can trigger capturing of statements by adding `session.info[""in-test""] = True` and stop capture with `del session.info[""in-test""]`.

Then you can make asserts about the statements and show the exact sequence of statements that are emitted in the important scenarios. 

Thanks a bunch

pratik-m (Issue Creator) on (2024-10-02 18:30:20 UTC): Thanks for the comment! I'll work and share the new/update PR !

pratik-m (Issue Creator) on (2024-10-03 06:10:39 UTC): Hi @dstandish - I've read through your comments and here's the summary: 

There are three issues that we need to focus on and a separate PR needs to be created for each of them
1. **recency column change for dag_run**: The recency column already exists in `TableConfig` called as `recency_column_name` . Instead of `start_date` it needs to be `execution_date`. 
2. **Improve test cases**: Need to include additional test cases for the sql generated for postgres and myself 
3. **Archival behavior**: Update the archival behavior to skip archive if option selected (this PR). 

Let me know if I missed any point. I'll create two additional PR for 1 and 2 and share the details once done. 

Thanks!

github-actions[bot] on (2024-11-18 00:16:45 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2552113146,pull_request,closed,,Improving validation of task retries to handle None values,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

This PR fixes issue #42273 which causes an error when retries is set to None at task level

The issue has been fixed by improving the validation of task retries to handle None values.


**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sonu4578,2024-09-27 06:30:33+00:00,[],2024-10-10 19:26:20+00:00,2024-10-09 20:03:40+00:00,https://github.com/apache/airflow/pull/42532,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', '')]","[{'comment_id': 2378499720, 'issue_id': 2552113146, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 9, 27, 6, 30, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2381264117, 'issue_id': 2552113146, 'author': 'uranusjr', 'body': 'Would it be better if `task.retries` always returns an int instead? We can fix this in BaseOperator.', 'created_at': datetime.datetime(2024, 9, 29, 8, 37, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394919591, 'issue_id': 2552113146, 'author': 'sonu4578', 'body': '@uranusjr Thank you for the suggestion. I have added a change in BaseOperator for handling the None value to return a zero', 'created_at': datetime.datetime(2024, 10, 5, 4, 24, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403331258, 'issue_id': 2552113146, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 10, 9, 20, 3, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2405873713, 'issue_id': 2552113146, 'author': 'jscheffl', 'body': ""Let's back-port this to 2.10!\r\n\r\ncloses: #42273"", 'created_at': datetime.datetime(2024, 10, 10, 19, 24, 2, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-09-27 06:30:36 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

uranusjr on (2024-09-29 08:37:30 UTC): Would it be better if `task.retries` always returns an int instead? We can fix this in BaseOperator.

sonu4578 (Issue Creator) on (2024-10-05 04:24:58 UTC): @uranusjr Thank you for the suggestion. I have added a change in BaseOperator for handling the None value to return a zero

boring-cyborg[bot] on (2024-10-09 20:03:43 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

jscheffl on (2024-10-10 19:24:02 UTC): Let's back-port this to 2.10!

closes: #42273

"
2551804296,pull_request,closed,,Add backfill cancellation logic,**NOTE:** Depends on https://github.com/apache/airflow/pull/42529 which must be merged first,dstandish,2024-09-27 01:24:39+00:00,[],2024-10-02 12:59:17+00:00,2024-10-02 12:59:14+00:00,https://github.com/apache/airflow/pull/42530,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2551803898,pull_request,closed,,Add dag run creation logic for backfill,"Add basic backfill creation logic.  This will be refined, but we're trying to be incremental here.",dstandish,2024-09-27 01:24:05+00:00,[],2024-10-02 02:07:49+00:00,2024-10-02 01:54:15+00:00,https://github.com/apache/airflow/pull/42529,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2551654422,pull_request,closed,,WIP try to add DagAccessEntity and resource for backfill,,dstandish,2024-09-26 22:46:12+00:00,[],2024-11-04 17:10:29+00:00,2024-11-04 17:10:29+00:00,https://github.com/apache/airflow/pull/42527,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', '')]","[{'comment_id': 2383941651, 'issue_id': 2551654422, 'author': 'vincbeck', 'body': 'See https://github.com/apache/airflow/pull/42597/commits/2ff1d70cebe56aa6b50fd8551ec5b339e718aaf7. That should unblock you', 'created_at': datetime.datetime(2024, 9, 30, 18, 59, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455258885, 'issue_id': 2551654422, 'author': 'dstandish', 'body': 'I am closing this since i migrated to fast API and the security stuff is not implemented over there yet.', 'created_at': datetime.datetime(2024, 11, 4, 17, 9, 32, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-09-30 18:59:18 UTC): See https://github.com/apache/airflow/pull/42597/commits/2ff1d70cebe56aa6b50fd8551ec5b339e718aaf7. That should unblock you

dstandish (Issue Creator) on (2024-11-04 17:09:32 UTC): I am closing this since i migrated to fast API and the security stuff is not implemented over there yet.

"
2551584702,pull_request,closed,,Handle ENTER key correctly in trigger form and allow manual JSON,"Follow-up of #42487

related: #42157

Unfortunately a bit more JavaScript is needed but this enables:
- Handling of press of ENTER in input fields and ensure that JSON form is submitted and correct value is sent
- Handling of manual changes of JSON dict (fix before: was always over-writing JSON)

@dannyl1u - can you confirm from your side?",jscheffl,2024-09-26 21:49:07+00:00,[],2024-09-27 08:25:05+00:00,2024-09-27 08:21:29+00:00,https://github.com/apache/airflow/pull/42525,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2378010297, 'issue_id': 2551584702, 'author': 'dannyl1u', 'body': '> Follow-up of #42487\r\n> \r\n> related: #42157\r\n> \r\n> Unfortunately a bit more JavaScript is needed but this enables:\r\n> \r\n> * Handling of press of ENTER in input fields and ensure that JSON form is submitted and correct value is sent\r\n> * Handling of manual changes of JSON dict (fix before: was always over-writing JSON)\r\n> \r\n> @dannyl1u - can you confirm from your side?\r\n\r\nTaking a look', 'created_at': datetime.datetime(2024, 9, 26, 21, 58, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2378023837, 'issue_id': 2551584702, 'author': 'dannyl1u', 'body': '@jscheffl tested your branch locally, works good for me. Thank you!', 'created_at': datetime.datetime(2024, 9, 26, 22, 10, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2378730580, 'issue_id': 2551584702, 'author': 'pierrejeambrun', 'body': 'Thanks, cherrypick PR is here https://github.com/apache/airflow/pull/42535', 'created_at': datetime.datetime(2024, 9, 27, 8, 25, 3, tzinfo=datetime.timezone.utc)}]","dannyl1u on (2024-09-26 21:58:06 UTC): Taking a look

dannyl1u on (2024-09-26 22:10:02 UTC): @jscheffl tested your branch locally, works good for me. Thank you!

pierrejeambrun on (2024-09-27 08:25:03 UTC): Thanks, cherrypick PR is here https://github.com/apache/airflow/pull/42535

"
2551527732,pull_request,closed,,Update Rest API tests to no longer rely on FAB auth manager. Move tests specific to FAB permissions to FAB provider,"Many tests in `tests/api_connexion/endpoints/` rely on FAB permission model. Since we want to get rid of FAB, we need to make these tests agnostic from FAB. In this PR, they are now using simple auth manager.

I did two things:
- Any test that do not need granular permissions, keep them in `tests/api_connexion/endpoints/` and make them agnostic from FAB
- Any test using granular permissions, move them to FAB provider

This PR is quite big but I could not find a way to make it smaller. Here are some tips for a quicker review:
- Code change in `tests/api_connexion/endpoints/` is removing tests that use granular permissions
- Code change in `tests/providers/fab/auth_manager/api_endpoints/` is tests being copy pasted from `tests/api_connexion/endpoints/` that use granular permissions (the ones that are removed in the previous step)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-09-26 21:03:38+00:00,[],2024-10-01 22:07:35+00:00,2024-10-01 13:59:11+00:00,https://github.com/apache/airflow/pull/42523,"[('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', '')]","[{'comment_id': 2387160444, 'issue_id': 2551527732, 'author': 'potiuk', 'body': 'WHOA! Fantastic.', 'created_at': datetime.datetime(2024, 10, 1, 22, 7, 34, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-10-01 22:07:34 UTC): WHOA! Fantastic.

"
2551471412,pull_request,closed,,Fix DB utils for Airflow Backwards compatability tests - import not existing,"Fix broken main/canary in https://github.com/apache/airflow/actions/runs/11058948895/job/30726378646
...as of merge #42455

Moving import into function preventing non existing import from utils

```
ImportError while importing test module '/opt/airflow/tests/providers/google/cloud/log/test_gcs_task_handler.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
/usr/local/lib/python3.8/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
tests/providers/google/cloud/log/test_gcs_task_handler.py:31: in <module>
    from tests.test_utils.db import clear_db_dags, clear_db_runs
tests/test_utils/db.py:38: in <module>
    from airflow.models.backfill import Backfill, BackfillDagRun
E   ModuleNotFoundError: No module named 'airflow.models.backfill'
```",jscheffl,2024-09-26 20:24:32+00:00,[],2024-09-26 21:44:20+00:00,2024-09-26 21:44:20+00:00,https://github.com/apache/airflow/pull/42522,[],[],
2551191260,pull_request,closed,,Prepare docs for Sep 2nd adhoc wave of providers,openlinage + common.sql,eladkal,2024-09-26 17:43:13+00:00,[],2024-09-27 01:40:57+00:00,2024-09-27 01:40:54+00:00,https://github.com/apache/airflow/pull/42519,"[('area:providers', ''), ('kind:documentation', ''), ('provider:common-sql', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2378239453, 'issue_id': 2551191260, 'author': 'eladkal', 'body': 'failures are not related. merging', 'created_at': datetime.datetime(2024, 9, 27, 1, 40, 47, tzinfo=datetime.timezone.utc)}]","eladkal (Issue Creator) on (2024-09-27 01:40:47 UTC): failures are not related. merging

"
2551176363,pull_request,closed,,Fix AWS system test `example_batch`,"When removing deprecations from Amazon provider package, I renamed a parameter using the wrong one. This is the reason why [the system test is failing currently](https://aws-mwaa.github.io/#/open-source/system-tests/dashboard.html)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-09-26 17:35:34+00:00,[],2024-10-02 17:43:47+00:00,2024-09-27 09:43:55+00:00,https://github.com/apache/airflow/pull/42518,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2551034644,pull_request,closed,,Ensure consistent Seriailized DAG hashing ,"The serialized DAG dictionary is not ordered correctly when creating hashes, and that causes inconsistent hashes, leading to
frequent update of the serialized DAG table.

Changes:

Implemented sorting for serialized DAG dictionaries and nested structures to ensure consistent and predictable serialization order for hashing. Using `sort_keys` in `json.dumps` is not enough to sort the nested structures in the serialized DAG.

Added serialize and deserialize methods for DagParam and ArgNotSet to allow for more structured serialization.

Updated serialize_template_field to handle objects that implement the serialize method. This was done because of DagParam and ArgNotSet in the template fields. Previously, it produced an object, but with this change, it now serialises to a consistent object.

",ephraimbuddy,2024-09-26 16:18:11+00:00,[],2024-09-30 11:10:25+00:00,2024-09-30 11:10:23+00:00,https://github.com/apache/airflow/pull/42517,"[('area:serialization', '')]",[],
2550992892,pull_request,closed,,AIP-84 Add HTTPException openapi documentation,"![Screenshot 2024-09-26 at 17 59 56](https://github.com/user-attachments/assets/3b2a8d8a-9168-434e-b731-5b6719640800)
",pierrejeambrun,2024-09-26 15:58:46+00:00,['pierrejeambrun'],2024-09-27 12:27:29+00:00,2024-09-27 12:27:28+00:00,https://github.com/apache/airflow/pull/42508,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2377364966, 'issue_id': 2550992892, 'author': 'pierrejeambrun', 'body': 'cc: @jscheffl This will take care of adding the necessary documentation of possible errors to the openapi spec.', 'created_at': datetime.datetime(2024, 9, 26, 15, 59, 21, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-09-26 15:59:21 UTC): cc: @jscheffl This will take care of adding the necessary documentation of possible errors to the openapi spec.

"
2550954133,pull_request,closed,,feat: add Hook Level Lineage support for GCSHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Adding hook level lineage support for GCS Hook. Similar PR for S3 Hook: #40819 

Also, Google provider needed some adjustments after Dataset has been renamed to Asset so I've done that as well.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-09-26 15:41:11+00:00,[],2024-10-24 08:43:27+00:00,2024-10-23 15:21:56+00:00,https://github.com/apache/airflow/pull/42507,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2378719891, 'issue_id': 2550954133, 'author': 'shahar1', 'body': 'Static checks and `LowestDeps` tests currently fail', 'created_at': datetime.datetime(2024, 9, 27, 8, 19, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2378983508, 'issue_id': 2550954133, 'author': 'kacpermuda', 'body': ""Yes, I'm working on fix and also adding tests to my changes. I'll switch to draft before i push it."", 'created_at': datetime.datetime(2024, 9, 27, 10, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431481000, 'issue_id': 2550954133, 'author': 'kacpermuda', 'body': '@shahar1 It should work well now, adjusted the GCSHook and the whole provider to work with Asset naming instead of Dataset.', 'created_at': datetime.datetime(2024, 10, 23, 9, 30, 55, tzinfo=datetime.timezone.utc)}]","shahar1 on (2024-09-27 08:19:14 UTC): Static checks and `LowestDeps` tests currently fail

kacpermuda (Issue Creator) on (2024-09-27 10:42:00 UTC): Yes, I'm working on fix and also adding tests to my changes. I'll switch to draft before i push it.

kacpermuda (Issue Creator) on (2024-10-23 09:30:55 UTC): @shahar1 It should work well now, adjusted the GCSHook and the whole provider to work with Asset naming instead of Dataset.

"
2550834333,pull_request,closed,,Move FSHook/PackageIndexHook/SubprocessHook to standard provider,"Moving FSHook, PackageIndexHook, SubprocessHook to standard provider
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-09-26 14:51:25+00:00,[],2024-10-02 09:22:15+00:00,2024-10-01 20:00:30+00:00,https://github.com/apache/airflow/pull/42506,"[('area:providers', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2377270008, 'issue_id': 2550834333, 'author': 'gopidesupavan', 'body': 'oh few tests are failing, looking at now.', 'created_at': datetime.datetime(2024, 9, 26, 15, 18, 41, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-09-26 15:18:41 UTC): oh few tests are failing, looking at now.

"
2550826549,pull_request,closed,,"Split providers out of the main ""airflow/"" tree into a UV workspace project","closes https://github.com/apache/airflow/issues/42857

As discussed https://lists.apache.org/thread/dyv5jhvt65xs6l5o2byc2b67f4wlwf6r, this is the first part of the new layout.


This is only a partial split so far. It moves all the code and tests, but the provider release generation code hasn't moved yet as it's a few weeks until the next batch, and I wan't to try and keep this already huge PR as small as possible. Likewise the creation of `core/` will be a follow on PR


In addition to the straight file rename the other changes I had to make here are:
- Some mypy/typing fixes.

  Mypy can be fragile about what it picks up when, so maybe some of those
  changes were caused by that. But the typing changes aren't large.

- Improve typing in common.sql type stub

  Again, likely a mypy file oddity, but the types should be safe

- Removed the `check-providers-init-file-missing` check

  This isn't needed now that airflow/providers shouldn't exist at all in the
  main tree.

- Create a ""dev.tests_common"" package that contains helper files and common
  pytest fixtures

  Since the provider tests are no longer under tests/ they don't automatically
  share the fixtures from the parent `tests/conftest.py` so they needed
  extracted.

  Ditto for `tests.test_utils` -- they can't be easily imported in provider
  tests anymore, so they are moved to a more explicit shared location.

In future we should switch how the CI image is built to make better use of UV caching than our own approach as that would remvoe a lot of custom code.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-09-26 14:49:20+00:00,[],2024-10-29 21:39:14+00:00,2024-10-09 19:24:53+00:00,https://github.com/apache/airflow/pull/42505,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2377223532, 'issue_id': 2550826549, 'author': 'ashb', 'body': ""Oh, prepare provider packages is failing for prod image build. I guess that's going to have to be in this PR then"", 'created_at': datetime.datetime(2024, 9, 26, 14, 59, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384806721, 'issue_id': 2550826549, 'author': 'potiuk', 'body': 'Smalll comment (I am returning back from holidays) and slowly going through the two week\'s history.\r\n\r\n> In future we should switch how the CI image is built to make better use of UV caching than our own approach as that would remvoe a lot of custom code.\r\n\r\nI tried various things before (including `uv` caching and local cache mounts) and I could not find better solution. With all the other approaches I tried, our approach is way more efficient for size and time and especially shines because with the current approach you have a single remote cache layer in ghcr.io that is used even if dependencies change, and you do not have cache duplication.\r\n\r\nThere are two problems with using uv cache:\r\n\r\n1) Enabling UV cache (I tested it having similar hope when UV was released) makes our image 4 GB instead of 2GB (can\'t remember exactly but it was almost 2x factor). also it does not work with docker layer caching. It\'s very time-efficient to keep the UV cache but yoy pay a huge price of used space. Note that UV will cache not only the actual packages that it downloads but also the packages it considers as candidates - which in case of significant backtracking might mean that you keep multiple versions of the same package in the cache - this adds up very quickly and uv cache is really huge.\r\n\r\nUV cache benefits from the fact that the same cache is potentially reused by multiple projects you have installed on the same machine. The UV cache is stored in  HOME dir and reused between all venvs used in the same machine - so in docker it\'s nearly useless because it multiplies the space used for both - installed and cached files but cached files are not reusable in any way for other venvs (because we have only one venv in docker container). And since layers in docker image cannot be removed, even if we delete the cache after final installation step - the cache will remain in the docker image layer additionally to installed packages - increasing significantly size of the final image.\r\n\r\nOf course - you could potentially use locally mounted cache volumes in docker to keep the UV cache on,  in order to not pollute docke image, but that would only be useful after you build your image locally once and you won\'t be able to use remotely cached layers which are currently used when you build the image. \r\n\r\nUsing remote cache in the way we do it now, is much nicer, because the cache is actually the same as most installed packages (with the exception of the new/ updated packages change after the original cached layer is created.  This has the nice property that every time new patchlevel base image is released by python (every two-three weeks or so) the cache is rebuit from scratch, and we get a new ""fresh"" main cache with latest package versions. \r\n\r\n2) Another problem is that you will not avoid the problem that you need to have all the ""source"" dependency files copied to the image layer in order to run `uv pip install` command.  \r\n\r\nWhatever that command will produce as cache will be invalidated the moment the source dependency files (pyproject.toml, hatch_build.py, provider.yaml files, generated/provider_dependencies.json) - so if you want to effectively use cache, you need to build it BEFORE you copy any of those files into the new image. This is precisely what ""our"" caching is doing - it does not use any ""local file"" and does not copy them to the image, but uses ""https://github"" URL to install the dependencies for the first time - which means that next time that layer will not be invalidated when pyproject.toml or hatch_build.py or any other files that decide about dependencies will change.\r\n\r\nNow - I\'d love to make it simpler, but so far all the attempts to find a better solution failed because the one we have is the only one that has good ""caching"" properties.', 'created_at': datetime.datetime(2024, 10, 1, 5, 14, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384807690, 'issue_id': 2550826549, 'author': 'potiuk', 'body': 'But maybe you can come up with a better approach that I have not thought about and tried already, of course :)', 'created_at': datetime.datetime(2024, 10, 1, 5, 15, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2385210879, 'issue_id': 2550826549, 'author': 'ashb', 'body': 'Yeah, that comment was mostly a note to myself, and not something I plan on even looking at as part of this work.', 'created_at': datetime.datetime(2024, 10, 1, 8, 58, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2389004556, 'issue_id': 2550826549, 'author': 'ashb', 'body': ""I think I'm getting closer now 🤞🏻 .\r\n\r\nOddly enough a lot of the time the er diagram static check is failing in CI , even though I've run `breeze static-checks -a update-er-diagram` and it says pass.\r\n\r\nEdit: this turned out to be a (purposefully) untracked file in the migrations folder in my local checkout."", 'created_at': datetime.datetime(2024, 10, 2, 15, 41, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2400174226, 'issue_id': 2550826549, 'author': 'ashb', 'body': ""Something is failing with the kube tests, it's not picking up the providers for running tests, however running the same command locally passes 🤔"", 'created_at': datetime.datetime(2024, 10, 8, 15, 30, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402036831, 'issue_id': 2550826549, 'author': 'ashb', 'body': ""3030 files are renamed without changes:\r\n\r\n```\r\ngit di HEAD origin/main --stat | grep -F '|    0' | wc -l\r\n    3030\r\n```"", 'created_at': datetime.datetime(2024, 10, 9, 11, 17, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2403427124, 'issue_id': 2550826549, 'author': 'potiuk', 'body': '> (Cherry-picking to v2-10 after this structure change will be a nightmare though :-D )\r\n\r\nNot really :D - we are not cherry-picking providers. And git actually is able to follow renames when cherry-picking.', 'created_at': datetime.datetime(2024, 10, 9, 21, 4, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2407097770, 'issue_id': 2550826549, 'author': 'ashb', 'body': 'For anyone coming to this PR after the fact, yes we know there are still a few rough edges as a result of this.\r\n\r\nCurrently known issues:\r\n\r\n- [x] Pycharm doesn\'t like resolving the imports of `airflow.providers.x` (Something to do with the content of the main `airflow/__init__.py` that means it doesn\'t think it\'s a namespace package?)\r\n- [x] `breeze testing tests provider/tests/x.py` currently fails. (Temp workaround: `breeze shell` then run `pytest provider/tests/x.py` directly. Bug is that the `testing test` command includes `tests` in the pytest command even when another file is specified, leading to pytest loading tests/conftest.py and providers/tests/conftest.py which it doesn\'t like as they are both ""top level"")', 'created_at': datetime.datetime(2024, 10, 11, 10, 17, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2423325855, 'issue_id': 2550826549, 'author': 'dstandish', 'body': '#protm', 'created_at': datetime.datetime(2024, 10, 18, 22, 31, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445377814, 'issue_id': 2550826549, 'author': 'potiuk', 'body': '> breeze testing tests provider/tests/x.py currently fails. (Temp workaround: breeze shell then run pytest provider/tests/x.py directly. Bug is that the testing test command includes tests in the pytest command even when another file is specified, leading to pytest loading tests/conftest.py and providers/tests/conftest.py which it doesn\'t like as they are both ""top level"")\r\n\r\nThis was never supposed to work. the parameters that you can pass to ""testing tests"" is really ""extra pytest paramaters"" you can pass - and it\'s not really inteded to use ""pytest files"" there. That\'s why for example the extra parameters are not autocomplete\'able with files/paths. The ""tests"" command is really meant to run the whole ""test type"" and you can easily use it now. \r\n\r\nFor example running all airbyte tests can be achieved by:\r\n\r\n```bash\r\nbreeze testing tests --test-type ""Providers[airbyte]""\r\n```\r\n\r\nAnd it nicely works now.', 'created_at': datetime.datetime(2024, 10, 29, 21, 38, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2445378948, 'issue_id': 2550826549, 'author': 'potiuk', 'body': '(so I think indeed all known ""teething"" problems"" are solved - and i can try to attempt to split out individual providers).', 'created_at': datetime.datetime(2024, 10, 29, 21, 39, 13, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-09-26 14:59:41 UTC): Oh, prepare provider packages is failing for prod image build. I guess that's going to have to be in this PR then

potiuk on (2024-10-01 05:14:44 UTC): Smalll comment (I am returning back from holidays) and slowly going through the two week's history.


I tried various things before (including `uv` caching and local cache mounts) and I could not find better solution. With all the other approaches I tried, our approach is way more efficient for size and time and especially shines because with the current approach you have a single remote cache layer in ghcr.io that is used even if dependencies change, and you do not have cache duplication.

There are two problems with using uv cache:

1) Enabling UV cache (I tested it having similar hope when UV was released) makes our image 4 GB instead of 2GB (can't remember exactly but it was almost 2x factor). also it does not work with docker layer caching. It's very time-efficient to keep the UV cache but yoy pay a huge price of used space. Note that UV will cache not only the actual packages that it downloads but also the packages it considers as candidates - which in case of significant backtracking might mean that you keep multiple versions of the same package in the cache - this adds up very quickly and uv cache is really huge.

UV cache benefits from the fact that the same cache is potentially reused by multiple projects you have installed on the same machine. The UV cache is stored in  HOME dir and reused between all venvs used in the same machine - so in docker it's nearly useless because it multiplies the space used for both - installed and cached files but cached files are not reusable in any way for other venvs (because we have only one venv in docker container). And since layers in docker image cannot be removed, even if we delete the cache after final installation step - the cache will remain in the docker image layer additionally to installed packages - increasing significantly size of the final image.

Of course - you could potentially use locally mounted cache volumes in docker to keep the UV cache on,  in order to not pollute docke image, but that would only be useful after you build your image locally once and you won't be able to use remotely cached layers which are currently used when you build the image. 

Using remote cache in the way we do it now, is much nicer, because the cache is actually the same as most installed packages (with the exception of the new/ updated packages change after the original cached layer is created.  This has the nice property that every time new patchlevel base image is released by python (every two-three weeks or so) the cache is rebuit from scratch, and we get a new ""fresh"" main cache with latest package versions. 

2) Another problem is that you will not avoid the problem that you need to have all the ""source"" dependency files copied to the image layer in order to run `uv pip install` command.  

Whatever that command will produce as cache will be invalidated the moment the source dependency files (pyproject.toml, hatch_build.py, provider.yaml files, generated/provider_dependencies.json) - so if you want to effectively use cache, you need to build it BEFORE you copy any of those files into the new image. This is precisely what ""our"" caching is doing - it does not use any ""local file"" and does not copy them to the image, but uses ""https://github"" URL to install the dependencies for the first time - which means that next time that layer will not be invalidated when pyproject.toml or hatch_build.py or any other files that decide about dependencies will change.

Now - I'd love to make it simpler, but so far all the attempts to find a better solution failed because the one we have is the only one that has good ""caching"" properties.

potiuk on (2024-10-01 05:15:44 UTC): But maybe you can come up with a better approach that I have not thought about and tried already, of course :)

ashb (Issue Creator) on (2024-10-01 08:58:43 UTC): Yeah, that comment was mostly a note to myself, and not something I plan on even looking at as part of this work.

ashb (Issue Creator) on (2024-10-02 15:41:31 UTC): I think I'm getting closer now 🤞🏻 .

Oddly enough a lot of the time the er diagram static check is failing in CI , even though I've run `breeze static-checks -a update-er-diagram` and it says pass.

Edit: this turned out to be a (purposefully) untracked file in the migrations folder in my local checkout.

ashb (Issue Creator) on (2024-10-08 15:30:23 UTC): Something is failing with the kube tests, it's not picking up the providers for running tests, however running the same command locally passes 🤔

ashb (Issue Creator) on (2024-10-09 11:17:28 UTC): 3030 files are renamed without changes:

```
git di HEAD origin/main --stat | grep -F '|    0' | wc -l
    3030
```

potiuk on (2024-10-09 21:04:45 UTC): Not really :D - we are not cherry-picking providers. And git actually is able to follow renames when cherry-picking.

ashb (Issue Creator) on (2024-10-11 10:17:15 UTC): For anyone coming to this PR after the fact, yes we know there are still a few rough edges as a result of this.

Currently known issues:

- [x] Pycharm doesn't like resolving the imports of `airflow.providers.x` (Something to do with the content of the main `airflow/__init__.py` that means it doesn't think it's a namespace package?)
- [x] `breeze testing tests provider/tests/x.py` currently fails. (Temp workaround: `breeze shell` then run `pytest provider/tests/x.py` directly. Bug is that the `testing test` command includes `tests` in the pytest command even when another file is specified, leading to pytest loading tests/conftest.py and providers/tests/conftest.py which it doesn't like as they are both ""top level"")

dstandish on (2024-10-18 22:31:04 UTC): #protm

potiuk on (2024-10-29 21:38:21 UTC): This was never supposed to work. the parameters that you can pass to ""testing tests"" is really ""extra pytest paramaters"" you can pass - and it's not really inteded to use ""pytest files"" there. That's why for example the extra parameters are not autocomplete'able with files/paths. The ""tests"" command is really meant to run the whole ""test type"" and you can easily use it now. 

For example running all airbyte tests can be achieved by:

```bash
breeze testing tests --test-type ""Providers[airbyte]""
```

And it nicely works now.

potiuk on (2024-10-29 21:39:13 UTC): (so I think indeed all known ""teething"" problems"" are solved - and i can try to attempt to split out individual providers).

"
2550775857,pull_request,closed,,Added unit tests and restructred `await_xcom_sidecar_container_start` method.,"Related: #42132
- The `await_xcom_sidecar_container_start` method in `PodManager` checks if the xcom sidecar container has started running before executing `do_xcom_push`.
- The function logs the status periodically and raises an `AirflowException` if the container does not start within the specified timeout.
- Added two unit tests:
  - `test_await_xcom_sidecar_container_timeout`: Verifies that an `AirflowException` is raised if the sidecar container fails to start within the timeout.
  - `test_await_xcom_sidecar_container_starts`: Confirms the method successfully exits when the sidecar container starts.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",harjeevanmaan,2024-09-26 14:30:41+00:00,[],2024-10-04 02:04:06+00:00,2024-10-04 02:02:54+00:00,https://github.com/apache/airflow/pull/42504,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2392434527, 'issue_id': 2550775857, 'author': 'harjeevanmaan', 'body': 'Fixed the failing tests', 'created_at': datetime.datetime(2024, 10, 3, 22, 17, 7, tzinfo=datetime.timezone.utc)}]","harjeevanmaan (Issue Creator) on (2024-10-03 22:17:07 UTC): Fixed the failing tests

"
2550677542,pull_request,closed,,Add in backport of astunparse where needed in static checks,"`ast.unparse` is only avaialble from Python 3.9 and up.

Even though 3.8 is almost unsupported, for now it's simpler to use this backport until we change the min required python version for main.
",ashb,2024-09-26 13:59:17+00:00,[],2024-09-26 14:48:25+00:00,2024-09-26 14:48:23+00:00,https://github.com/apache/airflow/pull/42503,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2550460561,pull_request,closed,,Fix broken main re generated api typescript comment,,dstandish,2024-09-26 12:37:03+00:00,[],2024-09-27 08:49:06+00:00,2024-09-26 13:39:47+00:00,https://github.com/apache/airflow/pull/42500,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2377053713, 'issue_id': 2550460561, 'author': 'pierrejeambrun', 'body': ""I do not understand why the hook was 'skipped' in the original PR. file detection looks correct in the hook configuration.\r\nhttps://github.com/apache/airflow/actions/runs/10974274062/job/30472669861?pr=42388\r\n\r\nAnd running `pre-commit run ts-compile-format-lint-www` on the commit diff `663da777f9` works as expected 🤔"", 'created_at': datetime.datetime(2024, 9, 26, 13, 56, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2377057411, 'issue_id': 2550460561, 'author': 'pierrejeambrun', 'body': 'Also we might want to cherry pick that to `v2-10-test`\r\n\r\ndone: PR here https://github.com/apache/airflow/pull/42537', 'created_at': datetime.datetime(2024, 9, 26, 13, 58, 13, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-09-26 13:56:56 UTC): I do not understand why the hook was 'skipped' in the original PR. file detection looks correct in the hook configuration.
https://github.com/apache/airflow/actions/runs/10974274062/job/30472669861?pr=42388

And running `pre-commit run ts-compile-format-lint-www` on the commit diff `663da777f9` works as expected 🤔

pierrejeambrun on (2024-09-26 13:58:13 UTC): Also we might want to cherry pick that to `v2-10-test`

done: PR here https://github.com/apache/airflow/pull/42537

"
2550310698,pull_request,closed,,fix: ensure DAG trigger form submits with updated parameters upon key…,"…board submit (#42487)

(cherry picked from commit https://github.com/apache/airflow/commit/5af74639503df4cc723e5663b4abb99ba8022147)
",pierrejeambrun,2024-09-26 11:31:20+00:00,[],2024-09-26 13:27:45+00:00,2024-09-26 13:27:43+00:00,https://github.com/apache/airflow/pull/42499,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2549537902,pull_request,closed,,Add GCSListObjectsOperator to operators listed in documentation in Google Provider for GCS,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Srabasti,2024-09-26 05:16:13+00:00,[],2024-11-21 04:59:45+00:00,2024-11-21 00:16:04+00:00,https://github.com/apache/airflow/pull/42491,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2480193854, 'issue_id': 2549537902, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 11, 16, 0, 15, 38, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-16 00:15:38 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
