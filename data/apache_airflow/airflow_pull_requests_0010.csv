id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2450376940,pull_request,closed,,Fix dataset page cannot correctly load triggered dag runs due to lack of dagId,"## Why
TriggeredDagRuns is used in both `/dags/{dagId}/grid` and `/datasets?uri` while the later can't get `dagId` and fallback to `__DAG_ID__`

## What

Replace `__DAG_ID__` to generate the correct triggered dag runs link for `/datasets?uri`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-06 09:16:47+00:00,[],2024-08-09 05:43:24+00:00,2024-08-06 14:33:01+00:00,https://github.com/apache/airflow/pull/41279,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2450243359,pull_request,closed,,Fix tests/operators/test_bash.py and branch_operator.py for Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Next one:
Fixing test_bash.py and test_branch_operator.py",jscheffl,2024-08-06 08:14:52+00:00,[],2024-08-06 17:59:38+00:00,2024-08-06 17:59:38+00:00,https://github.com/apache/airflow/pull/41277,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2450187027,pull_request,closed,,"Change inserted airflow version of ""update-migration-references"" command from airflow_version='...' to airflow_version=""...""","## Why
When running `pre-commit run update-migration-references --all-files`, it inserts `airflow_version='...'` instead of `airflow_version=""...""`, which will not pass the ruff check.

## What
Change the format from airflow_verion=**'**...**'** to airflow_version=**""**...**""**

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-06 07:45:29+00:00,[],2024-08-06 13:51:54+00:00,2024-08-06 13:51:52+00:00,https://github.com/apache/airflow/pull/41275,"[('area:dev-tools', '')]",[],
2450052146,pull_request,closed,,Fix tests/operators/test_email.py for Database Isolation Tests,"Related: https://github.com/apache/airflow/pull/41067

Fix EmailOperator Tests for datbase isolation mode.
Note that the setup method was adding complexity for a single test, with dag_maker made it all to the single test body.",jscheffl,2024-08-06 06:26:56+00:00,[],2024-08-06 06:42:23+00:00,2024-08-06 06:42:23+00:00,https://github.com/apache/airflow/pull/41274,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2449623674,pull_request,closed,,Fix check served logs logic,"**Background:**

In #31101, I added logic to check for served logs when we did not find either local or remote logs.

In #32561, contributor @khrol observed that for a task with multiple tries, if the user was looking at the logs for a non-running try, the UI would show an erroneous and potentially confusing 404 error.  @khrol attempted a fix that would suppress this error message.

In #39177, contributor @kahlstrm reported a bug introduced by #32562 and attempted to fix it.

The bug was reportedly that â€œnon-running task try logs werenâ€™t shown in the UI for running tasksâ€.  This I think refers to when you are looking at the logs for a failed attempt. The contributor added, â€œThis is due to us storing the logs on the worker with a Persistent Volumeâ€.  I assume this means that we did not check served logs in that case.

One question: why couldnâ€™t the webserver access the PV?  In #39496 same user added more conditions.

**Problem:** 

We can't see logs served from triggerer when task deferred.

**This PR:**

This PR essentially restores the behavior to what it was prior to #32561.  So we undo the enhancement in #32561, the first attempted fix #39177, and the second attempted fix #39496.

This means that while a task is in running state, if you look at logs for prior failed attempts, you may see a ""checked served logs and did not find any"" message.  This can be mildly confusing but it's more important to restore access to logs.
",dstandish,2024-08-05 23:12:42+00:00,[],2024-08-06 09:37:26+00:00,2024-08-06 01:29:51+00:00,https://github.com/apache/airflow/pull/41272,"[('area:logging', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2270128034, 'issue_id': 2449623674, 'author': 'kahlstrm', 'body': '> One question: why couldnâ€™t the webserver access the PV? In https://github.com/apache/airflow/pull/39496 same user added more conditions.\r\n\r\nThe PV was only mounted to the worker and not on the webserver, hence the need for the the served logs for old attempts to be fetched from the served logs instead from the webserver. This could have been fixed on our end by adding a mount for the PV to the webserver, but instead trying to fix the bug introduced in upstream was chosen.', 'created_at': datetime.datetime(2024, 8, 6, 0, 8, 21, tzinfo=datetime.timezone.utc)}]","kahlstrm on (2024-08-06 00:08:21 UTC): The PV was only mounted to the worker and not on the webserver, hence the need for the the served logs for old attempts to be fetched from the served logs instead from the webserver. This could have been fixed on our end by adding a mount for the PV to the webserver, but instead trying to fix the bug introduced in upstream was chosen.

"
2449564478,pull_request,closed,,Fix DateTimeOperator tests in Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Fix DateTimeOperator Tests for datbase isolation mode",jscheffl,2024-08-05 22:12:25+00:00,[],2024-08-06 07:17:09+00:00,2024-08-06 07:17:09+00:00,https://github.com/apache/airflow/pull/41271,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2448815853,pull_request,closed,,fix: return empty data instead of None when OpenLineage on_start method is missing,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
When DefaultExtractor is used, so the operator has OpenLineage methods implemented (at least one of: on_start, on_complete) we are logging a WARNING each time there is no on_start method. This happens because we are validating OL metadata returned by extractor, [here](https://github.com/apache/airflow/blob/d6bc1f69a36dd0ee08f02fb6e6f0388342f5fb1b/airflow/providers/openlineage/extractors/manager.py#L105). This validation makes sense and we should keep it, but imho the default extractor should return empty data when there is no on_start method defined, because it means that the on_complete method will be called. 

There is no need to return None ourselves and then log a warning because we found a None ðŸ˜„ 

Some logs of current behaviour:
```
[2024-08-05, 15:04:30 UTC] {listener.py:383} DEBUG - Executing OpenLineage process - on_running - pid 376
[2024-08-05, 15:04:30 UTC] {manager.py:149} DEBUG - extractor for CustomOperator is <class 'airflow.providers.openlineage.extractors.base.DefaultExtractor'>
[2024-08-05, 15:04:30 UTC] {manager.py:98} DEBUG - Using extractor DefaultExtractor task_type=CustomOperator airflow_dag_id=dag task_id=task airflow_run_id=manual__2024-08-05T15:04:29.761674+00:00 
[2024-08-05, 15:04:30 UTC] {base.py:101} DEBUG - Trying to execute `get_openlineage_facets_on_start` for CustomOperator.
[2024-08-05, 15:04:30 UTC] {base.py:112} DEBUG - Operator CustomOperator does not have the get_openlineage_facets_on_start method.
[2024-08-05, 15:04:30 UTC] {manager.py:104} DEBUG - Found task metadata for operation task: None
[2024-08-05, 15:04:30 UTC] {manager.py:267} WARNING - Extractor returns non-valid metadata: None
```

After the change, we would get rid of this warning. We would still get the information that there is no on_start method and metadata found would be `OperatorLineage()`

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-05 15:16:40+00:00,[],2024-08-06 07:28:26+00:00,2024-08-05 16:41:03+00:00,https://github.com/apache/airflow/pull/41268,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2448664903,pull_request,closed,,Fix latest botocore tests conflicting dependencies,"The ""latest botocore"" tests have conflicting dependencies for latest yandexcloud provider - their ""requests"" support conflicts with apache.beam and latest botocore.

For now we remove yandexcloud for those tests hoping that soon apache.beam will support higher requests versions.

And issue has been created in apache.beam to remove the limitation as the root cause seems to be already fixed.

See https://github.com/apache/beam/issues/32080

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-05 14:11:12+00:00,[],2024-08-06 09:38:30+00:00,2024-08-05 21:30:10+00:00,https://github.com/apache/airflow/pull/41267,"[('area:providers', ''), ('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:yandex', '')]",[],
2448511274,pull_request,closed,,"Disable most irrelevant ""core"" tests in database isolation mode","A lot of the ""core"" tests are not relevant for database isolation mode and they should be skipped.

Related: #41067 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-05 13:03:36+00:00,[],2024-08-05 17:49:39+00:00,2024-08-05 17:49:30+00:00,https://github.com/apache/airflow/pull/41266,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2269595231, 'issue_id': 2448511274, 'author': 'potiuk', 'body': '> Perhaps we meant to link #41067 in the PR description instead of #41607 (does not exist yet :) ?\r\n\r\nRight :)', 'created_at': datetime.datetime(2024, 8, 5, 17, 49, 39, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-05 17:49:39 UTC): Right :)

"
2448307647,pull_request,closed,,Add DatasetDagRunQueue to all the consuming DAGs of a dataset alias,"## Why
Ever since https://github.com/apache/airflow/pull/40693, we have been able to schedule a DAG based on DatasetAlias. When a dataset alias is resolved in a producer DAG for the first time, a consumer DAG that depends on that dataset alias will have to wait for the next round of DAG parsing to realize its dependency on the resolved datasets. Consequently, the consumer DAG will need to wait for the second run of the producer DAG to be triggered.

## What
This PR created DDRQ for the consuming dags of dataset alias as well. So after the consumer DAG is updated after DAG parsing, it will have DDRQ which might triggers it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-05 11:23:58+00:00,[],2024-08-09 05:49:46+00:00,2024-08-07 02:15:01+00:00,https://github.com/apache/airflow/pull/41264,"[('type:new-feature', 'Changelog: New Features'), ('area:db-migrations', 'PRs with DB migration')]",[],
2448091928,pull_request,closed,,added nested task groups to task_group.group_id in OL event,"Closes: #41261 

I have used task_id to extract the suffix and get the nested task group name.

delimiting using "".group_id."" if nested task groups are present

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rahul-madaan,2024-08-05 09:38:17+00:00,[],2024-08-05 17:34:01+00:00,2024-08-05 17:34:01+00:00,https://github.com/apache/airflow/pull/41263,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2268631772, 'issue_id': 2448091928, 'author': 'rahul-madaan', 'body': 'FYI @kacpermuda', 'created_at': datetime.datetime(2024, 8, 5, 9, 38, 57, tzinfo=datetime.timezone.utc)}]","rahul-madaan (Issue Creator) on (2024-08-05 09:38:57 UTC): FYI @kacpermuda

"
2448082198,pull_request,closed,,Upgrade package gcloud-aio-auth>=5.2.0,"This PR upgrades the `gcloud-aio-auth` package constraints up to `>=5.2.0`.

As it was requested in the `provider.yaml` this PR overrides the following methods for the `_CredentialsToken` class:
- refresh()
- ensure_token() - this method is overridden in order to satisfy the unit test `tests/providers/google/common/hooks/test_base_google.py::TestCredentialsToken::test_get `

I also tested these changes with multiple system tests with deferrable mode, and they succeed.",moiseenkov,2024-08-05 09:33:54+00:00,[],2024-08-06 12:15:44+00:00,2024-08-06 12:15:44+00:00,https://github.com/apache/airflow/pull/41262,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2271049094, 'issue_id': 2448082198, 'author': 'moiseenkov', 'body': 'Hi @potiuk , @ashb ,\r\nI made some changes in the scripts/docker/entrypoint_ci.sh to fix the CI. PTAL.', 'created_at': datetime.datetime(2024, 8, 6, 11, 20, 9, tzinfo=datetime.timezone.utc)}]","moiseenkov (Issue Creator) on (2024-08-06 11:20:09 UTC): Hi @potiuk , @ashb ,
I made some changes in the scripts/docker/entrypoint_ci.sh to fix the CI. PTAL.

"
2447940866,pull_request,closed,,Swallow exception when mini-scheduling raises an exception,"When mini-scheduler raises an exception, it has a bit weird side effect - the task succeeds but it is seen as failed and scheduler gets confused. Also flower celery worker in this case shows an error.

This happens for example when DAG contains non-serializable tasks.

This PR swallows any exceptions raised in mini-scheduler and simply logs them as error rather than fail the process. Mini-scheduler is generally optional and we are also already sometimes skipping it already so occasional skipping is not a big problem.

Fixes: #39717

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-05 08:31:02+00:00,[],2024-11-25 09:33:58+00:00,2024-08-06 17:00:12+00:00,https://github.com/apache/airflow/pull/41260,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2497138881, 'issue_id': 2447940866, 'author': 'boris-tumbev', 'body': 'Hey Team, we had the problem that is suppose to be fixed in this PR, however recently on airflow 2.10.2 we had this:\r\n![image](https://github.com/user-attachments/assets/56d921f6-d178-45d3-be65-6e5451e44da5)\r\nTask was success then marked as failed twice, can it be connected to the same problem ? From the UI i can see the log only for the second try :thinking:', 'created_at': datetime.datetime(2024, 11, 25, 7, 54, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2497412418, 'issue_id': 2447940866, 'author': 'potiuk', 'body': 'Likely unrelated. I suggest to start separate Github discussion an describe it there in details, explaining your deployment and circumstances what exactly happened.', 'created_at': datetime.datetime(2024, 11, 25, 9, 33, 57, tzinfo=datetime.timezone.utc)}]","boris-tumbev on (2024-11-25 07:54:46 UTC): Hey Team, we had the problem that is suppose to be fixed in this PR, however recently on airflow 2.10.2 we had this:
![image](https://github.com/user-attachments/assets/56d921f6-d178-45d3-be65-6e5451e44da5)
Task was success then marked as failed twice, can it be connected to the same problem ? From the UI i can see the log only for the second try :thinking:

potiuk (Issue Creator) on (2024-11-25 09:33:57 UTC): Likely unrelated. I suggest to start separate Github discussion an describe it there in details, explaining your deployment and circumstances what exactly happened.

"
2447855487,pull_request,closed,,refactor how triggered dag run url is replaced,"## Why

https://github.com/apache/airflow/pull/41166 works as a hotfix but might break in some cases that `splitGridUrl[2]` is not `dagId`.

## What
This PR loads the `dagId` and uses that to replace it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-05 07:47:00+00:00,[],2024-08-06 09:40:24+00:00,2024-08-05 13:50:01+00:00,https://github.com/apache/airflow/pull/41259,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2268403685, 'issue_id': 2447855487, 'author': 'Lee-W', 'body': 'Thanks @bbovenzi for guiding!', 'created_at': datetime.datetime(2024, 8, 5, 7, 50, 7, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-08-05 07:50:07 UTC): Thanks @bbovenzi for guiding!

"
2447314230,pull_request,closed,,Disable DAG Stats API Endpoint test in Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

DAG Stats API fails in DB Isolation Tests - but this is only executed on Webserver, thus a test with isolation is not needed. Also failure are in FAB initialization.",jscheffl,2024-08-04 22:06:21+00:00,[],2024-08-04 22:54:51+00:00,2024-08-04 22:54:51+00:00,https://github.com/apache/airflow/pull/41258,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2447310661,pull_request,closed,,Bugfix/41067 fix tests operators test python,"Related: https://github.com/apache/airflow/pull/41067

Attempt to fix all or most of tests/operators/test_python.py code.

With this to make a success, Internal API also was changed to return AirflowException as Exception class, previously this raised HTTP 500 Internal Server Error. But there are valid use cases where AirflowException is raised by the backend.",jscheffl,2024-08-04 21:54:26+00:00,[],2024-08-06 11:35:41+00:00,2024-08-05 06:16:12+00:00,https://github.com/apache/airflow/pull/41257,"[('area:serialization', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2447295954,pull_request,closed,,Issue-41243 Unpin the moto dependency,"The exception should be `ExportTaskNotFound` (and not `ExportTaskNotFoundFault`) as recorded here:
https://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_DescribeExportTasks.html

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

closes: #41243



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vikramaditya91,2024-08-04 21:05:05+00:00,[],2024-08-19 14:19:12+00:00,2024-08-13 23:51:11+00:00,https://github.com/apache/airflow/pull/41256,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2268592629, 'issue_id': 2447295954, 'author': 'potiuk', 'body': 'The tests should also be made compatible with older versions of Airflow / moto constraints - as we are running the same tests with older versions of Airflow as well, so I guess checking for both variants should solve it.', 'created_at': datetime.datetime(2024, 8, 5, 9, 23, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269015300, 'issue_id': 2447295954, 'author': 'vikramaditya91', 'body': '> The tests should also be made compatible with older versions of Airflow / moto constraints - as we are running the same tests with older versions of Airflow as well, so I guess checking for both variants should solve it.\r\n\r\nI see. Fixed it accordingly', 'created_at': datetime.datetime(2024, 8, 5, 12, 57, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269035935, 'issue_id': 2447295954, 'author': 'potiuk', 'body': 'You need to rebase and:\r\n\r\n```\r\nbreeze static-checks --type update-providers-dependencies --all-files \r\n```', 'created_at': datetime.datetime(2024, 8, 5, 13, 7, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274239745, 'issue_id': 2447295954, 'author': 'vincbeck', 'body': 'Tests are still failing, did you run `breeze static-checks --type update-providers-dependencies --all-files`?', 'created_at': datetime.datetime(2024, 8, 7, 19, 54, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274243360, 'issue_id': 2447295954, 'author': 'vikramaditya91', 'body': 'I ran them, but they formatted the files as \r\n```patch\r\n@@ -46,7 +46,7 @@\r\n     ""devel-deps"": [\r\n       ""aiobotocore>=2.13.0"",\r\n       ""aws_xray_sdk>=2.12.0"",\r\n-      ""moto[cloudformation,glue]>=5.0.0"",\r\n+      ""moto[cloudformation,glue]>=5.0.0,"",\r\n       ""mypy-boto3-appflow>=1.34.0"",\r\n```\r\n\r\nNot really sure, why it puts that comma after the `5.0.0`.\r\n\r\nChecking why that actually happens\r\n\r\nEDIT: Nevermind. There was a stupid error there. Fixed it', 'created_at': datetime.datetime(2024, 8, 7, 19, 56, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2274439956, 'issue_id': 2447295954, 'author': 'vikramaditya91', 'body': 'Looks like some unrelated tests are failing...:(', 'created_at': datetime.datetime(2024, 8, 7, 22, 14, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287410940, 'issue_id': 2447295954, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 13, 23, 51, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-05 09:23:02 UTC): The tests should also be made compatible with older versions of Airflow / moto constraints - as we are running the same tests with older versions of Airflow as well, so I guess checking for both variants should solve it.

vikramaditya91 (Issue Creator) on (2024-08-05 12:57:42 UTC): I see. Fixed it accordingly

potiuk on (2024-08-05 13:07:09 UTC): You need to rebase and:

```
breeze static-checks --type update-providers-dependencies --all-files 
```

vincbeck on (2024-08-07 19:54:31 UTC): Tests are still failing, did you run `breeze static-checks --type update-providers-dependencies --all-files`?

vikramaditya91 (Issue Creator) on (2024-08-07 19:56:42 UTC): I ran them, but they formatted the files as 
```patch
@@ -46,7 +46,7 @@
     ""devel-deps"": [
       ""aiobotocore>=2.13.0"",
       ""aws_xray_sdk>=2.12.0"",
-      ""moto[cloudformation,glue]>=5.0.0"",
+      ""moto[cloudformation,glue]>=5.0.0,"",
       ""mypy-boto3-appflow>=1.34.0"",
```

Not really sure, why it puts that comma after the `5.0.0`.

Checking why that actually happens

EDIT: Nevermind. There was a stupid error there. Fixed it

vikramaditya91 (Issue Creator) on (2024-08-07 22:14:37 UTC): Looks like some unrelated tests are failing...:(

boring-cyborg[bot] on (2024-08-13 23:51:13 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2447257383,pull_request,closed,,Fix manually deleted pod behaviour in SparkKubernetesOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The problem might be related to when there is no `state` in `spark_job_info` since the pod is deleted manually or externally from the Kubernetes environment, the default always went into SUBMITTED even though the keys don't exist in the spark_job_info.
I still haven't fully tested yet if it solves the issue. I will test and make the MR ready.

----
Update, I am suspecting from a broad issue. Waiting for an answer.

closes: #41212

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-08-04 18:58:30+00:00,[],2024-08-19 23:45:11+00:00,2024-08-19 23:45:11+00:00,https://github.com/apache/airflow/pull/41255,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2297703885, 'issue_id': 2447257383, 'author': 'bugraoz93', 'body': 'Closing because issue not reproduced', 'created_at': datetime.datetime(2024, 8, 19, 23, 45, 11, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-08-19 23:45:11 UTC): Closing because issue not reproduced

"
2447234939,pull_request,closed,,Add exporting of dependency information from SBOM to CSV file,"This new sbom command uses the SBOM we have generated for Airflow and exports information about all our dependencies, enhanced by using various sources of information about them.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-04 17:50:41+00:00,[],2024-08-05 10:27:54+00:00,2024-08-05 06:01:39+00:00,https://github.com/apache/airflow/pull/41254,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2447121320,pull_request,closed,,Fix all AWS provider tests for database isolation,"Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-04 12:48:00+00:00,[],2024-08-04 14:40:00+00:00,2024-08-04 14:39:59+00:00,https://github.com/apache/airflow/pull/41253,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2447120285,pull_request,closed,,Add missing serializations found during provider tests fixing,"During AWS provider tests fixing for database isolation, two problems have been found:

* Trigger object did not have TriggerPydantic corresponding pydantic object which did not allow the Trigger object to get serialized for Trigger processing

* Variable and connection accessors were not restored when Context got deserialized.

Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-04 12:45:24+00:00,[],2024-08-06 09:44:15+00:00,2024-08-04 14:40:12+00:00,https://github.com/apache/airflow/pull/41252,"[('area:serialization', ''), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:Triggerer', '')]",[],
2447067350,pull_request,closed,,Fix all smaller providers to work with DB isolation mode,"Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-04 10:16:50+00:00,[],2024-08-04 12:36:22+00:00,2024-08-04 12:36:21+00:00,https://github.com/apache/airflow/pull/41251,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:arangodb', ''), ('provider:asana', ''), ('provider:apache-druid', ''), ('provider:apache-spark', ''), ('provider:apache-livy', ''), ('provider:apache-kylin', '')]",[],
2447040190,pull_request,closed,,Make all google provider tests pass Database Isolation mode tests,"Some of the tests are skipped, if they are only relevant for webserver (auth tests) - the remaining tests are fixed.

Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-04 09:48:53+00:00,[],2024-08-04 10:13:07+00:00,2024-08-04 10:13:06+00:00,https://github.com/apache/airflow/pull/41250,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2447005703,pull_request,closed,,Allow empty list in triggerDagrun failed_state,"closes: https://github.com/apache/airflow/issues/41229
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-04 09:18:12+00:00,['romsharon98'],2024-08-05 10:28:52+00:00,2024-08-04 19:52:14+00:00,https://github.com/apache/airflow/pull/41249,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2446584387,pull_request,closed,,Fix after 41238: Left 2 print statements in code,"Related: https://github.com/apache/airflow/pull/41067

As a follow-up uups, I realized that I left two print() statements in PR #41238 - sorry. THis PR cleans-up.",jscheffl,2024-08-03 20:33:52+00:00,[],2024-08-06 09:44:48+00:00,2024-08-03 20:39:18+00:00,https://github.com/apache/airflow/pull/41245,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2446582740,pull_request,closed,,Limit moto temporarily - 5.0.12 is breaking our tests,"Tracked in https://github.com/apache/airflow/issues/41243

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-03 20:30:38+00:00,[],2024-08-03 21:05:40+00:00,2024-08-03 21:05:39+00:00,https://github.com/apache/airflow/pull/41244,"[('area:providers', '')]",[],
2446543595,pull_request,closed,,Fix all provider tests for database isolation mode,"Related: https://github.com/apache/airflow/pull/41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-03 18:38:38+00:00,[],2024-08-03 19:15:31+00:00,2024-08-03 19:15:30+00:00,https://github.com/apache/airflow/pull/41242,"[('provider:google', 'Google (including GCP) related issues'), ('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:logging', ''), ('provider:databricks', ''), ('provider:airbyte', ''), ('provider:alibaba', ''), ('provider:apache-druid', '')]","[{'comment_id': 2267098548, 'issue_id': 2446543595, 'author': 'potiuk', 'body': 'Yeah - a lot of those were about not commmited task instance where ""render_template"" was used', 'created_at': datetime.datetime(2024, 8, 3, 18, 43, 25, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-03 18:43:25 UTC): Yeah - a lot of those were about not commmited task instance where ""render_template"" was used

"
2446543304,pull_request,closed,,Clean up the exception handler when run_as_user is the airflow user ,"closes: #38726
with cherry-picking from @squingo44

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-03 18:37:29+00:00,[],2024-08-04 07:50:30+00:00,2024-08-04 07:50:30+00:00,https://github.com/apache/airflow/pull/41241,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2446542641,pull_request,closed,,Exclude testing pydantic serialization from DB isolation mode,"Related: https://github.com/apache/airflow/pull/41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-03 18:35:10+00:00,[],2024-08-03 19:11:44+00:00,2024-08-03 19:11:42+00:00,https://github.com/apache/airflow/pull/41240,"[('area:serialization', '')]","[{'comment_id': 2267098715, 'issue_id': 2446542641, 'author': 'jscheffl', 'body': 'Ah, this is a lean version of my https://github.com/apache/airflow/pull/41238', 'created_at': datetime.datetime(2024, 8, 3, 18, 44, 14, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-03 18:44:14 UTC): Ah, this is a lean version of my https://github.com/apache/airflow/pull/41238

"
2446541882,pull_request,closed,,Improve serialization for Database Isolation Mode,"This contains two fixes to serialization code:

* TaskInstanceKey is a Named Tuple and it was serialized as regular tuple

* macros were serialized as strings in Context. With this PR macros are recreated after deserializing the context

Related: #41067
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-03 18:32:35+00:00,[],2024-08-06 09:46:14+00:00,2024-08-03 19:11:55+00:00,https://github.com/apache/airflow/pull/41239,"[('area:serialization', ''), ('type:improvement', 'Changelog: Improvements')]",[],
2446499660,pull_request,closed,,Fix pydantic dataset serialization test in Database Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Some pytests need specific DB access which is not covered by current Traceback mechanism. Therefore added a specific ""hook"" allowing temporary DB access for setup of mock data for testing... and fixed serialization tests with this.

@potiuk  Is this acceptable? Or should we re-model the mock or traceback-detection?",jscheffl,2024-08-03 16:56:13+00:00,[],2024-08-06 09:47:03+00:00,2024-08-03 18:49:59+00:00,https://github.com/apache/airflow/pull/41238,"[('area:serialization', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2267098909, 'issue_id': 2446499660, 'author': 'potiuk', 'body': 'Nice one.', 'created_at': datetime.datetime(2024, 8, 3, 18, 45, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-03 18:45:13 UTC): Nice one.

"
2446408098,pull_request,closed,,Disable internal RPC API tests in isolation mode,"Related: https://github.com/apache/airflow/pull/41067

Sounds a bit strange but in the RPC API tests the pytest spawns its own internal flask server which conflicts with the separate started by pytest.
As long as we do not have only/exclusive internal API tests, we must disable these in isolation mode.

I tried to make them working but also if the internal API server is started in pytest, a DB access is needed which heavily conflicts with the traceback session mode. Main conflict is within `minimal_app_for_internal_api()` mock",jscheffl,2024-08-03 15:25:35+00:00,[],2024-08-03 16:23:35+00:00,2024-08-03 16:23:35+00:00,https://github.com/apache/airflow/pull/41236,[],[],
2446348559,pull_request,closed,,Disable processor tests in internal DB test set which have code-under-test that makes direct DB access,"Related: https://github.com/apache/airflow/pull/41067

I checked the failed tests in `test_processor.py` but all logic under test needs direct DB access to work. I disabled the tests which fail because of this.
I'm not fully sure if this affects the function of the DAG file processor if running in isolation mode... if yes then a set of additional internal API methods must be cut to make callback handling working in DB isolation mode.",jscheffl,2024-08-03 13:13:06+00:00,[],2024-08-14 07:18:53+00:00,2024-08-14 07:18:53+00:00,https://github.com/apache/airflow/pull/41235,[],"[{'comment_id': 2268605679, 'issue_id': 2446348559, 'author': 'potiuk', 'body': 'I will want to take a look at those', 'created_at': datetime.datetime(2024, 8, 5, 9, 28, 17, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-05 09:28:17 UTC): I will want to take a look at those

"
2446316494,pull_request,closed,,Fix tests/always/test_secrets_backends.py by adding test_utils/db.py to accepted DB access for Dataset Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Some tests are calling tests/test_utils/db.py to clean the DB, permit this in unit tests with database isolation
",jscheffl,2024-08-03 11:52:34+00:00,[],2024-08-06 09:47:28+00:00,2024-08-03 14:28:32+00:00,https://github.com/apache/airflow/pull/41234,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2266689628, 'issue_id': 2446316494, 'author': 'jscheffl', 'body': 'Probably this also fixes tests in tests/dag_processing/test_processor.py', 'created_at': datetime.datetime(2024, 8, 3, 12, 0, 39, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-08-03 12:00:39 UTC): Probably this also fixes tests in tests/dag_processing/test_processor.py

"
2446303783,pull_request,closed,,Fix Example DAGs Test by adding one more internal API method for DatasetAlias resolution,"Related: https://github.com/apache/airflow/pull/41067

Fixes the one test for dataset alias resolution, an additional internal API call for this method was missing",jscheffl,2024-08-03 11:19:21+00:00,[],2024-08-06 09:48:04+00:00,2024-08-03 14:27:53+00:00,https://github.com/apache/airflow/pull/41233,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2446177818,pull_request,closed,,fix: The remote task tracked by the trigger failed due to the reassignment of the trigger task,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
### Apache Airflow version

Other Airflow 2 version (please specify below)

### If ""Other Airflow 2 version"" selected, which one?

2.7.2

### What happened?

The trigger instance handled by triggerer-2 was canceled due to reassignment to triggerer-1.
As a result, triggerer-2 cleaned up the local trigger instance, which terminated the remote job using its ID.
The trigger instance in triggerer-2 keep polling the status of remote job with the same id, but detected that the remote job was killed, so completed its run, and exited.
Consequently, the remote job failed due to the reassignment.

Production log summarized by time sequence
```
Time: 2024-07-11, 00:00:12 -07
Event: Start to run on worker
Runtime: worker
Log: {task_command.py:416} INFO - Running <TaskInstance: f67fb155-6ff2-4fde-bbb2-6f0ef16af05e.91fade50-a3da-4966-a0ff-44c24d59303a scheduled__2024-07-11T06:00:00+00:00 [running]> on host worker-host-3
----------------------------------

Time: 2024-07-11, 00:00:14 -07
Event: Defer to trigger
Runtime: worker
Log: Pausing task as DEFERRED. dag_id=f67fb155-6ff2-4fde-bbb2-6f0ef16af05e, task_id=91fade50-a3da-4966-a0ff-44c24d59303a, execution_date=20240711T060000, start_date=20240711T070011
----------------------------------

Time: 2024-07-11T00:00:54.788-0700
Event: Trigger instance-1 started
Runtime: triggerer-2
Log: {triggerer_job_runner.py:595} INFO - trigger f67fb155-6ff2-4fde-bbb2-6f0ef16af05e/scheduled__2024-07-11T06:00:00+00:00/91fade50-a3da-4966-a0ff-44c24d59303a/-1/1 (ID 78297) starting
----------------------------------

Time: 2024-07-11T00:00:54.788-0700
Event: Trigger instance-1 check job status
Runtime: triggerer-2
Log: {datax_trigger.py:26} INFO - Check if job finished.
----------------------------------

Time: 2024-07-11T00:00:54.823-0700
Event: Trigger instance-1 get job running
Runtime: triggerer-2
Log: {datax_trigger.py:32} INFO - {""code"":""0000"",""message"":""success"",""result"":{""dagRunId"":""manual__2024-07-11T07:00:43.473585+00:00"",""startTime"":""2024-07-11T00:00:14+00:00"",""endTime"":null,""status"":""RUNNING"",""extraInfo"":{""dagId"":""f67fb155-6ff2-4fde-bbb2-6f0ef16af05e-61566"",""status"":""<strong style=\""color:blue;\"">RUNNING</strong>""}}}
----------------------------------

Time: 2024-07-11T00:01:00.503-0700
Event: Triggerer-2 cancel trigger due to find the trigger has been occupied by another triggerer process
Runetime: triggerer-2
Log: {triggerer_job_runner.py:607} ERROR - Trigger cancelled; message=
----------------------------------

Time: 2024-07-11, 00:01:00 -07
Event: Kyuubi Trigger cleanup called
Runtime: triggerer-2
Log: {datax_trigger.py:51} INFO - Trigger is cancelled, clean up now.
----------------------------------

Time: 2024-07-11T00:01:00.977-0700
Event: Trigger instance-1 cleanup
Runeimte: triggerer-2
Log: {triggerer_job_runner.py:621} INFO - trigger f67fb155-6ff2-4fde-bbb2-6f0ef16af05e/scheduled__2024-07-11T06:00:00+00:00/91fade50-a3da-4966-a0ff-44c24d59303a/-1/1 (ID 78297) completed
----------------------------------

Time: 2024-07-11, 00:02:00 -07
Event: Trigger check if job success
Runtime: triggerer-1
Log: {datax_trigger.py:26} INFO - Check if job finished.
----------------------------------

Time: 2024-07-11, 00:02:00 -07
Event: check job status
Runtime: triggerer-1
Log: {datax_trigger.py:32} INFO - {""code"":""0000"",""message"":""success"",""result"":{""dagRunId"":""manual__2024-07-11T07:00:43.473585+00:00"",""startTime"":""2024-07-11T00:00:14+00:00"",""endTime"":null,""status"":""FAILED"",""extraInfo"":{""executionLogAddress"":""<a target=\""_blank\"" href=\""https://host/api/v1/logs?JobId=79028\"">Execution Log</a>"",""dagId"":""f67fb155-6ff2-4fde-bbb2-6f0ef16af05e-61566"",""status"":""<strong style=\""color:red;\"">FAILED</strong>""}}}
----------------------------------
```

### What you think should happen instead?

Triggers will be canceled and cleaned up by the current triggerer process if the current triggerer finds that those running trigger instances have been reassigned to other triggerers.
However, if the cleanup is called prematurely while the trigger is still in an active state, it could impact the same trigger when reassigned to another triggerer process.
Therefore, introducing the capability to disable this cleanup behavior in such scenarios.

### How to reproduce

1. Set the triggerer_health_check_threshold to a small number like 3(s).
2. Make triggerer instances at least 2.
3. Use blocking io like http request in the trigger's run method.
4. Trigger multiple deferred tasks(for our cases: 100+ trigger jobs) in the same time. 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",TakawaAkirayo,2024-08-03 06:43:49+00:00,[],2024-10-09 00:15:09+00:00,2024-10-09 00:15:09+00:00,https://github.com/apache/airflow/pull/41232,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Triggerer', '')]","[{'comment_id': 2266538936, 'issue_id': 2446177818, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 3, 6, 43, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2268150420, 'issue_id': 2446177818, 'author': 'TakawaAkirayo', 'body': ""CC @potiuk If there are any other suggested solutions for this, our use case is as follows:\r\n\r\n1.Submit a job to Apache Kyuubi in the worker, which will return a remote job ID and the remote job executed in Kyuubi side.\r\n2.Defer the task by creating a trigger and pass the remote job ID to the trigger.\r\n3.The trigger will continuously check the status of the remote job in the run method and yield an event once the job succeeds or fails.\r\n4.In the trigger's cleanup method, we terminate the remote job if the remote job ID exists.\r\n\r\nThe problem is that the cleanup method could called when a task is canceled or the trigger is reassigned to another triggerer. The issue arises when the cleanup method is called during reassignment, which terminates the remote job. As a result, once reassigned to another triggerer, the remote job fails.\r\n\r\nTo avoid making the trigger heavier, we chose not to move step 1 (submitting the job and receiving the remote job ID) into the trigger's run method. This decision is based on the need to handle many preparations, such as authentication setup and local file propagation, which could burden the trigger process. Instead, we perform these preparations in the worker and delegate only the status check to the trigger."", 'created_at': datetime.datetime(2024, 8, 5, 4, 30, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288312445, 'issue_id': 2446177818, 'author': 'uranusjr', 'body': 'Also, please consider to configure pre-commit locally to verify the code before you push. This will save a lot of time waiting for CI checking simple formatting errors.\r\n\r\nYou can find guides on this in `contributing-docs`.', 'created_at': datetime.datetime(2024, 8, 14, 9, 44, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2292648881, 'issue_id': 2446177818, 'author': 'TakawaAkirayo', 'body': 'Many thanks for the valuable suggestions from @uranusjr @dstandish ! Just a follow-up on the PR process. What are the next action items? Please let me know, thanks!', 'created_at': datetime.datetime(2024, 8, 16, 3, 8, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384537393, 'issue_id': 2446177818, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 10, 1, 0, 17, 11, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-03 06:43:53 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

TakawaAkirayo (Issue Creator) on (2024-08-05 04:30:04 UTC): CC @potiuk If there are any other suggested solutions for this, our use case is as follows:

1.Submit a job to Apache Kyuubi in the worker, which will return a remote job ID and the remote job executed in Kyuubi side.
2.Defer the task by creating a trigger and pass the remote job ID to the trigger.
3.The trigger will continuously check the status of the remote job in the run method and yield an event once the job succeeds or fails.
4.In the trigger's cleanup method, we terminate the remote job if the remote job ID exists.

The problem is that the cleanup method could called when a task is canceled or the trigger is reassigned to another triggerer. The issue arises when the cleanup method is called during reassignment, which terminates the remote job. As a result, once reassigned to another triggerer, the remote job fails.

To avoid making the trigger heavier, we chose not to move step 1 (submitting the job and receiving the remote job ID) into the trigger's run method. This decision is based on the need to handle many preparations, such as authentication setup and local file propagation, which could burden the trigger process. Instead, we perform these preparations in the worker and delegate only the status check to the trigger.

uranusjr on (2024-08-14 09:44:13 UTC): Also, please consider to configure pre-commit locally to verify the code before you push. This will save a lot of time waiting for CI checking simple formatting errors.

You can find guides on this in `contributing-docs`.

TakawaAkirayo (Issue Creator) on (2024-08-16 03:08:51 UTC): Many thanks for the valuable suggestions from @uranusjr @dstandish ! Just a follow-up on the PR process. What are the next action items? Please let me know, thanks!

github-actions[bot] on (2024-10-01 00:17:11 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2446146963,pull_request,closed,,Prepare docs for Aug 1st wave of providers,,eladkal,2024-08-03 06:07:41+00:00,[],2024-08-03 14:36:07+00:00,2024-08-03 14:36:03+00:00,https://github.com/apache/airflow/pull/41230,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', ''), ('provider:apprise', ''), ('provider:atlassian-jira', ''), ('provider:apache-kafka', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-livy', ''), ('provider:apache-drill', ''), ('provider:apache-hdfs', ''), ('provider:apache-kylin', ''), ('provider:apache-pig', ''), ('provider:apache-pinot', ''), ('provider:apache-impala', ''), ('provider:apache-iceberg', '')]",[],
2445729488,pull_request,closed,,Upgrade UV to 0.2.33,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-02 20:36:14+00:00,[],2024-08-02 21:36:37+00:00,2024-08-02 21:36:35+00:00,https://github.com/apache/airflow/pull/41228,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2445705222,pull_request,closed,,Fix Callback Test for Dataset Isolation Mode,"Related: https://github.com/apache/airflow/pull/41067

Fixes the problems in `tests/callbacks/test_callback_requests.py`.
Using dag maker and peroperly serializing the mock to DB fixes the test - actually no problem in underlying code, just pytest.",jscheffl,2024-08-02 20:15:48+00:00,[],2024-08-02 20:51:15+00:00,2024-08-02 20:51:15+00:00,https://github.com/apache/airflow/pull/41227,[],[],
2445623716,pull_request,closed,,Improve docs build speed in canary runs,"Self-hosted runners on ASF are SLOW to build docs (much slower than
regular public runners) but they have more disk space which is needed
to publish documentation. This PR splits docs building process to two
steps:

* First step that builds docs and uploads them as artifacts run on
  public runners

* Publish step that downloads the artifact and publishes them to
  S3 (this one needs more space and runs on ASF self-hosted runners)

This has the nice side effect that docs built in PR are available
as artifacts in PRs and main build.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-02 19:20:45+00:00,[],2024-10-01 08:12:49+00:00,2024-08-02 22:18:25+00:00,https://github.com/apache/airflow/pull/41226,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]","[{'comment_id': 2266079412, 'issue_id': 2445623716, 'author': 'potiuk', 'body': 'Right. :)', 'created_at': datetime.datetime(2024, 8, 2, 20, 13, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266164234, 'issue_id': 2445623716, 'author': 'shahar1', 'body': 'Hmm, looks like it fails here:\r\nhttps://github.com/apache/airflow/actions/runs/10221485186/job/28285050003?pr=41226', 'created_at': datetime.datetime(2024, 8, 2, 21, 26, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266172099, 'issue_id': 2445623716, 'author': 'potiuk', 'body': '> Hmm, looks like it fails here: https://github.com/apache/airflow/actions/runs/10221485186/job/28285050003?pr=41226\r\n\r\nYep. Just corrected it.', 'created_at': datetime.datetime(2024, 8, 2, 21, 35, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266208840, 'issue_id': 2445623716, 'author': 'potiuk', 'body': 'It works now :)', 'created_at': datetime.datetime(2024, 8, 2, 22, 18, 32, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-08-02 20:13:26 UTC): Right. :)

shahar1 on (2024-08-02 21:26:59 UTC): Hmm, looks like it fails here:
https://github.com/apache/airflow/actions/runs/10221485186/job/28285050003?pr=41226

potiuk (Issue Creator) on (2024-08-02 21:35:23 UTC): Yep. Just corrected it.

potiuk (Issue Creator) on (2024-08-02 22:18:32 UTC): It works now :)

"
2445117224,pull_request,closed,,Skip highlighting lines that contain log group markers.,"Skip highlighting lines that contain log group markers since they already contain html markup which causes issues. The group is automatically expanded and not clickable. We found this since we had a log group to display exception traceback from other systems and named it exception log.

Before : (Note log group named exception is highlighted by red which we used internally to display exception log from external tasks)

![image](https://github.com/user-attachments/assets/996c069d-b80c-4d58-af51-35acbae889ca)

After : 

![image](https://github.com/user-attachments/assets/f91ca95d-d55d-4a24-a671-f95594986800)

Sample dag : 

```python
from datetime import datetime, timedelta

from airflow import DAG
from airflow.decorators import task


with DAG(
    dag_id=""error_color"",
    start_date=datetime(2024, 1, 1),
    catchup=False,
    schedule_interval=""@once"",
) as dag:

    @task
    def empty():
        try:
            print(""::group::exception"")
            1 / 0
        except Exception as e:
            print(e)
        finally:
            print(""::endgroup::"")


    empty()

```",tirkarthi,2024-08-02 14:43:05+00:00,[],2024-08-06 18:47:05+00:00,2024-08-06 18:47:05+00:00,https://github.com/apache/airflow/pull/41222,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('affected_version:2.9', 'Issues Reported for 2.9')]","[{'comment_id': 2265565930, 'issue_id': 2445117224, 'author': 'tirkarthi', 'body': 'cc: @jscheffl', 'created_at': datetime.datetime(2024, 8, 2, 14, 43, 58, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-08-02 14:43:58 UTC): cc: @jscheffl

"
2445076621,pull_request,closed,,kubernetes executor cleanup_stuck_queued_tasks optimization,"Problem: Airflow running the cleanup_stuck_queued_tasks function on a certain frequency. When we run the airflow on a large Kube cluster (pods more than > 5K). Internally the cleanup_stuck_queued_tasks function loops through each queued task (when they breach task queued timeout) and checks the corresponding worker pod existence in the Kube cluster. Right now, this existence check using list pods Kube API. The API is taking more than 1s. if there are 120 queued tasks, then it will take ~ 120 seconds (1s * 120). So, this leads the scheduler to spend most of its time in this function rather than scheduling the tasks. It leads to none of the jobs being scheduled or degraded scheduler performance.

Solution: Use single k8 list pods batch api call to get all the worker pod owned by scheduler. Prepare the set of searchable strings using pod annotations. Use this set data structure and identify whether the task associated pod exists or not. This reduces the number kube api sever calls significantly. 

set elements string format:
(dag_id=<dag_id>,task_id=<task_id>,[,map_index=<map_index>],[run_id=<run_id>]

Note: Switch the worker pod and task comparison from labels to annotations to avoid extra processing (make_safe_label_value) and ensure more accurate comparisons, as annotations have no value restrictions.",dirrao,2024-08-02 14:25:57+00:00,['dirrao'],2024-10-07 15:22:42+00:00,2024-10-07 15:22:41+00:00,https://github.com/apache/airflow/pull/41220,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2270991658, 'issue_id': 2445076621, 'author': 'dirrao', 'body': '@jedcunningham / @hussein-awala \r\nCan you review it whenever you are free?', 'created_at': datetime.datetime(2024, 8, 6, 10, 54, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2279851640, 'issue_id': 2445076621, 'author': 'dirrao', 'body': '@jedcunningham / @hussein-awala\r\nCan you review it whenever you are free?', 'created_at': datetime.datetime(2024, 8, 10, 7, 0, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2290616177, 'issue_id': 2445076621, 'author': 'dirrao', 'body': '@potiuk / @eladkal \r\nCan someone review this MR?', 'created_at': datetime.datetime(2024, 8, 15, 4, 59, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2301917787, 'issue_id': 2445076621, 'author': 'potiuk', 'body': ""@dirrao  I have very little knowiedge of those but maybe look at the history of the releavant code and ping someone who was actively implementing it before? That's the best way to find who might be good to review it rather rather than putting  that on my and @eladkal  shoulders?"", 'created_at': datetime.datetime(2024, 8, 21, 12, 20, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306377884, 'issue_id': 2445076621, 'author': 'jedcunningham', 'body': ""@dirrao can you add some details in the description? Just repeating the commit message/title isn't very useful, and having to go grok 100+ lines of change to know what the goal is isn't great for reviewing now nor next year when someone is doing git blame :)\r\n\r\ne.g. things like what is done now, what you are doing instead, expected impact."", 'created_at': datetime.datetime(2024, 8, 23, 6, 24, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2306646157, 'issue_id': 2445076621, 'author': 'dirrao', 'body': ""> @dirrao can you add some details in the description? Just repeating the commit message/title isn't very useful, and having to go grok 100+ lines of change to know what the goal is isn't great for reviewing now nor next year when someone is doing git blame :)\r\n> \r\n> e.g. things like what is done now, what you are doing instead, expected impact.\r\n\r\nSorry for not putting the details around the problem. I have updated the details in description of the PR."", 'created_at': datetime.datetime(2024, 8, 23, 9, 7, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392667234, 'issue_id': 2445076621, 'author': 'eladkal', 'body': '@dirrao can you rebase and resolve conflicts?', 'created_at': datetime.datetime(2024, 10, 4, 2, 28, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392875097, 'issue_id': 2445076621, 'author': 'dirrao', 'body': '> @dirrao can you rebase and resolve conflicts?\r\n\r\nDone.', 'created_at': datetime.datetime(2024, 10, 4, 5, 52, tzinfo=datetime.timezone.utc)}]","dirrao (Issue Creator) on (2024-08-06 10:54:23 UTC): @jedcunningham / @hussein-awala 
Can you review it whenever you are free?

dirrao (Issue Creator) on (2024-08-10 07:00:46 UTC): @jedcunningham / @hussein-awala
Can you review it whenever you are free?

dirrao (Issue Creator) on (2024-08-15 04:59:46 UTC): @potiuk / @eladkal 
Can someone review this MR?

potiuk on (2024-08-21 12:20:41 UTC): @dirrao  I have very little knowiedge of those but maybe look at the history of the releavant code and ping someone who was actively implementing it before? That's the best way to find who might be good to review it rather rather than putting  that on my and @eladkal  shoulders?

jedcunningham on (2024-08-23 06:24:54 UTC): @dirrao can you add some details in the description? Just repeating the commit message/title isn't very useful, and having to go grok 100+ lines of change to know what the goal is isn't great for reviewing now nor next year when someone is doing git blame :)

e.g. things like what is done now, what you are doing instead, expected impact.

dirrao (Issue Creator) on (2024-08-23 09:07:29 UTC): Sorry for not putting the details around the problem. I have updated the details in description of the PR.

eladkal on (2024-10-04 02:28:28 UTC): @dirrao can you rebase and resolve conflicts?

dirrao (Issue Creator) on (2024-10-04 05:52:00 UTC): Done.

"
2444840714,pull_request,closed,,Adjust gantt width based on task history dates,"Reopening with changes from #41192, which had failing static checks once merged into main.",jedcunningham,2024-08-02 12:19:47+00:00,[],2024-08-06 09:50:46+00:00,2024-08-02 18:19:43+00:00,https://github.com/apache/airflow/pull/41218,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2444825183,pull_request,closed,,feat: [openlineage] add debug facet to all events,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
## Problem
Whenever we are trying to debug issues related to OpenLineage coming from users, we usually require information about versions of other providers used in the process, for reproducing purposes. It would be great to have that information in the events already to reduce the time and effort needed for debugging, but only when some flag is turned on explicitly on the user side (f.e. airflow log level is set to debug). This PR adds a DebugRun facet to Airflow, that contains information about all packages and their versions. In the future, we could possibly extend that facet with other useful information.

### Questions:

- I'm not sure, if we should add this facet to all events (current implementation), or only add it to some specific events (which?).
- Can we rely on the Airflow logging level when deciding whether or not to attach this facet? I wanted to avoid creating another flag, that would basically had to be set together with DEBUG logging level. (Whenever debugging user issues, we are asking for debug logs anyway)


## Background:
Initially, I aimed to include package information in the producer field for specific facets but wanted to keep it hassle-free for both users and developers. I created some POC for each solution, but this debug facet seems the best for now.

We could automatically track where a facet is created and assign the producer, but the complexity and maintenance effort are not worth it for such a simple feature.

I also considered resetting the producer for facets after creation using a decorator or function in common.compat provider, but this would require additional code from developers when adding OL support for operators. With hook level lineage coming, it could become even more complex. This is something we might revisit in the future, as having the producer field identify the actual provider of the facet at all times is beneficial (regardless of OL configuration, logging level, etc.).

For now, the simple debug facet should suffice.

Please let me know your thoughts.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-02 12:10:28+00:00,[],2024-08-12 09:52:01+00:00,2024-08-12 09:30:49+00:00,https://github.com/apache/airflow/pull/41217,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2268685779, 'issue_id': 2444825183, 'author': 'potiuk', 'body': 'I like it. I think also it would be useful to get some way of temporarily enabling it (via API?). Also I am not sure we want to add it continuously - because this one will have basically - the same information in all events right? \r\n\r\nSo maybe just emit it with some min frequency (i.e. max once per 10 minutes) ? So that we are not changing the behaviour of the system by observing it too much ? \r\n\r\nThis could also be controllable via API / configuration I guess.', 'created_at': datetime.datetime(2024, 8, 5, 10, 2, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2268743259, 'issue_id': 2444825183, 'author': 'kacpermuda', 'body': ""> Also I am not sure we want to add it continuously - because this one will have basically - the same information in all events right?\r\n\r\nYes, it would contain the same information across all events when it comes to the list of installed packages. In the future, we might want to extend this facet with more state-specific information, but for now, it's simple.\r\n\r\n> So maybe just emit it with some min frequency (i.e. max once per 10 minutes) ? \r\n\r\nI considered limiting it in some way (including it in only some of the events like START/COMPLETE, TASK/DAG), but my thinking was that this debug facet should only be used when something goes wrong. When that happens, we might only have a subset of events due to an error. If we limit the emittance in any way, we might end up not having it where we need it. However, Iâ€™m open to the ideaâ€”maybe thereâ€™s a better way of doing it that I havenâ€™t thought of.\r\n\r\n>  I think also it would be useful to get some way of temporarily enabling it (via API?). \r\n> \r\n> This could also be controllable via API / configuration I guess.\r\n\r\nI was hoping we could avoid introducing an additional OL configuration flag here. Itâ€™s easy to add them, but it can quickly lead to having so many that it becomes hard to manage. My thinking was: if Iâ€™m debugging an error, Iâ€™m already using debug logs, so I shouldnâ€™t need to set separate variables to fully debug my issue. Rarely do I want the debug facet to appear without the debug logs enabled. Not sure what you mean by the API here, do you have any examples in mind?\r\n\r\n> So that we are not changing the behaviour of the system by observing it too much ?\r\n\r\nIâ€™m not sure I understand this fully. Are you concerned that this debug facet might consume too many resources and thereby affect the systemâ€™s performance? If you could explain your concerns in more detail, I can address them more effectively."", 'created_at': datetime.datetime(2024, 8, 5, 10, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2268878951, 'issue_id': 2444825183, 'author': 'potiuk', 'body': 'Yeah. No strong concerns here -> just wondered how much extra overhead it will add to retrieve that information - generally speaking the problem with such debugging information is that it might change the behaviour of the system (like adding or avoiding race conditions - introducing things call ""heisenbugs"" - the more you look at the problem, the less likely it is to occur. So generrally speaking - as low overhead as possible in this kind of debugging facility - the better.\r\n\r\nIn this sense - connecting it to airflow ""debug"" log level is not necessarily a good idea - because Airflow in debug log generates a loooooot of debugging information and this **might** impact how airflow behaves. \r\n\r\nSo my concern here is to:\r\n\r\na) limit the overhead when it is enabled (this can be done as well by caching the information - so maybe that will be enough to cache the facet. JUST retrieving all installed package information is pretty heavy, and we should do it once per interpreter run ideally.\r\n\r\nb) I **think** there should be a way to enable this logging independently from Airflow logs, because it might well be that just enabling debug logs will have other side effects.', 'created_at': datetime.datetime(2024, 8, 5, 11, 46, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2278030917, 'issue_id': 2444825183, 'author': 'kacpermuda', 'body': '> a) limit the overhead when it is enabled (this can be done as well by caching the information - so maybe that will be enough to cache the facet. JUST retrieving all installed package information is pretty heavy, and we should do it once per interpreter run ideally.\r\n>\r\n> b) I **think** there should be a way to enable this logging independently from Airflow logs, because it might well be that just enabling debug logs will have other side effects.\r\n\r\nI added caching for the package information and introduced a new flag called `debug_mode`, which controls whether this facet is created and added. Now, it should run only once in the scheduler and once per task on the worker, but only when the `debug_mode` flag is explicitly enabled by the user. I also updated the documentation to inform users about the useful information they can provide to us when debugging.', 'created_at': datetime.datetime(2024, 8, 9, 14, 6, 42, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-05 10:02:08 UTC): I like it. I think also it would be useful to get some way of temporarily enabling it (via API?). Also I am not sure we want to add it continuously - because this one will have basically - the same information in all events right? 

So maybe just emit it with some min frequency (i.e. max once per 10 minutes) ? So that we are not changing the behaviour of the system by observing it too much ? 

This could also be controllable via API / configuration I guess.

kacpermuda (Issue Creator) on (2024-08-05 10:32:00 UTC): Yes, it would contain the same information across all events when it comes to the list of installed packages. In the future, we might want to extend this facet with more state-specific information, but for now, it's simple.


I considered limiting it in some way (including it in only some of the events like START/COMPLETE, TASK/DAG), but my thinking was that this debug facet should only be used when something goes wrong. When that happens, we might only have a subset of events due to an error. If we limit the emittance in any way, we might end up not having it where we need it. However, Iâ€™m open to the ideaâ€”maybe thereâ€™s a better way of doing it that I havenâ€™t thought of.


I was hoping we could avoid introducing an additional OL configuration flag here. Itâ€™s easy to add them, but it can quickly lead to having so many that it becomes hard to manage. My thinking was: if Iâ€™m debugging an error, Iâ€™m already using debug logs, so I shouldnâ€™t need to set separate variables to fully debug my issue. Rarely do I want the debug facet to appear without the debug logs enabled. Not sure what you mean by the API here, do you have any examples in mind?


Iâ€™m not sure I understand this fully. Are you concerned that this debug facet might consume too many resources and thereby affect the systemâ€™s performance? If you could explain your concerns in more detail, I can address them more effectively.

potiuk on (2024-08-05 11:46:09 UTC): Yeah. No strong concerns here -> just wondered how much extra overhead it will add to retrieve that information - generally speaking the problem with such debugging information is that it might change the behaviour of the system (like adding or avoiding race conditions - introducing things call ""heisenbugs"" - the more you look at the problem, the less likely it is to occur. So generrally speaking - as low overhead as possible in this kind of debugging facility - the better.

In this sense - connecting it to airflow ""debug"" log level is not necessarily a good idea - because Airflow in debug log generates a loooooot of debugging information and this **might** impact how airflow behaves. 

So my concern here is to:

a) limit the overhead when it is enabled (this can be done as well by caching the information - so maybe that will be enough to cache the facet. JUST retrieving all installed package information is pretty heavy, and we should do it once per interpreter run ideally.

b) I **think** there should be a way to enable this logging independently from Airflow logs, because it might well be that just enabling debug logs will have other side effects.

kacpermuda (Issue Creator) on (2024-08-09 14:06:42 UTC): I added caching for the package information and introduced a new flag called `debug_mode`, which controls whether this facet is created and added. Now, it should run only once in the scheduler and once per task on the worker, but only when the `debug_mode` flag is explicitly enabled by the user. I also updated the documentation to inform users about the useful information they can provide to us when debugging.

"
2444785229,pull_request,closed,,"Revert ""Adjust gantt width based on task history dates (#41192)""","This reverts commit a9baf71304650bf3ed45187ac65ff7647bdedf74.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-02 11:45:48+00:00,[],2024-08-06 09:50:52+00:00,2024-08-02 12:11:36+00:00,https://github.com/apache/airflow/pull/41216,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2444622226,pull_request,closed,,Fix the right affected provider version,"The #41205 incorrectly stated version of FAB provider. This one fixes it

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-02 10:11:11+00:00,[],2024-08-02 14:38:55+00:00,2024-08-02 11:28:25+00:00,https://github.com/apache/airflow/pull/41215,"[('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('type:doc-only', 'Changelog: Doc Only')]",[],
2444571651,pull_request,closed,,collapse DAG docs by one click,"closes: https://github.com/apache/airflow/issues/39589
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-08-02 09:50:08+00:00,[],2024-08-03 07:39:09+00:00,2024-08-03 07:39:09+00:00,https://github.com/apache/airflow/pull/41214,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2444485399,pull_request,closed,,Fixing a bug in marking a commit as MISC while releasing providers,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

There was a bug in the `prepare-provider-documentation` command where marking a change as `misc` initially failed with a lookup error. Fixing the bug. Result looks like this:
```
âžœ  airflow git:(fixMarkingAsMisc) âœ— breeze release-management prepare-provider-documentation apache.drill
Good version of Docker: 27.0.3.
Good version of docker-compose: 2.28.1
Executable permissions on entrypoints are OK
Fetching full history and tags from remote.
This might override your local tags!
From https://github.com/apache/airflow
 * [new branch]            31851                                              -> apache-https-for-providers/31851
 * [new branch]            RNHTTR-patch-1                                     -> apache-https-for-providers/RNHTTR-patch-1
 * [new branch]            add-missing-conf-ol-value                          -> apache-https-for-providers/add-missing-conf-ol-value
 * [new branch]            add-missing-input-in-special-tests                 -> apache-https-for-providers/add-missing-input-in-special-tests
 * [new branch]            add-zlib1g-dev-package-to-image                    -> apache-https-for-providers/add-zlib1g-dev-package-to-image
 * [new branch]            aip-62/common-compat                               -> apache-https-for-providers/aip-62/common-compat
 * [new branch]            aip-62/common-io-file                              -> apache-https-for-providers/aip-62/common-io-file
 * [new branch]            aip-62/object-storage                              -> apache-https-for-providers/aip-62/object-storage
 * [new branch]            aip-62/s3                                          -> apache-https-for-providers/aip-62/s3
 * [new branch]            aip-62/s3hook                                      -> apache-https-for-providers/aip-62/s3hook
 * [new branch]            amoghrajesh-patch-1                                -> apache-https-for-providers/amoghrajesh-patch-1
 * [new branch]            another-remove-backcompat-gcs                      -> apache-https-for-providers/another-remove-backcompat-gcs
 * [new branch]            better-cleanup-for-ci                              -> apache-https-for-providers/better-cleanup-for-ci
 * [new branch]            bring-back-arm-image-building                      -> apache-https-for-providers/bring-back-arm-image-building
 * [new branch]            bump-mq-version                                    -> apache-https-for-providers/bump-mq-version
 * [new branch]            cleanup-runs-on-in-workflows                       -> apache-https-for-providers/cleanup-runs-on-in-workflows
 * [new branch]            cncf-kubernetes-4.4.1-rc                           -> apache-https-for-providers/cncf-kubernetes-4.4.1-rc
 * [new branch]            consistent-approach-for-runs-on-usage              -> apache-https-for-providers/consistent-approach-for-runs-on-usage
 * [new branch]            constraints-1-10                                   -> apache-https-for-providers/constraints-1-10
 * [new branch]            constraints-2-0                                    -> apache-https-for-providers/constraints-2-0
 * [new branch]            constraints-2-1                                    -> apache-https-for-providers/constraints-2-1
 * [new branch]            constraints-2-1-fixed                              -> apache-https-for-providers/constraints-2-1-fixed
 * [new branch]            constraints-2-10                                   -> apache-https-for-providers/constraints-2-10
 * [new branch]            constraints-2-2                                    -> apache-https-for-providers/constraints-2-2
 * [new branch]            constraints-2-2-2-fixed                            -> apache-https-for-providers/constraints-2-2-2-fixed
 * [new branch]            constraints-2-2-3-fixed                            -> apache-https-for-providers/constraints-2-2-3-fixed
 * [new branch]            constraints-2-3                                    -> apache-https-for-providers/constraints-2-3
 * [new branch]            constraints-2-4                                    -> apache-https-for-providers/constraints-2-4
 * [new branch]            constraints-2-5                                    -> apache-https-for-providers/constraints-2-5
 * [new branch]            constraints-2-5-2-fixed                            -> apache-https-for-providers/constraints-2-5-2-fixed
 * [new branch]            constraints-2-6                                    -> apache-https-for-providers/constraints-2-6
 * [new branch]            constraints-2-7                                    -> apache-https-for-providers/constraints-2-7
 * [new branch]            constraints-2-8                                    -> apache-https-for-providers/constraints-2-8
 * [new branch]            constraints-2-9                                    -> apache-https-for-providers/constraints-2-9
 * [new branch]            constraints-2.0.0-fix                              -> apache-https-for-providers/constraints-2.0.0-fix
 * [new branch]            constraints-2.0.1-fix                              -> apache-https-for-providers/constraints-2.0.1-fix
 * [new branch]            constraints-2.0.2-fix                              -> apache-https-for-providers/constraints-2.0.2-fix
 * [new branch]            constraints-2.1.0-fix                              -> apache-https-for-providers/constraints-2.1.0-fix
 * [new branch]            constraints-2.1.1-fix                              -> apache-https-for-providers/constraints-2.1.1-fix
 * [new branch]            constraints-2.1.2-fix                              -> apache-https-for-providers/constraints-2.1.2-fix
 * [new branch]            constraints-2.1.3-fix                              -> apache-https-for-providers/constraints-2.1.3-fix
 * [new branch]            constraints-2.1.4-fix                              -> apache-https-for-providers/constraints-2.1.4-fix
 * [new branch]            constraints-2.2.0-fix                              -> apache-https-for-providers/constraints-2.2.0-fix
 * [new branch]            constraints-2.2.1-fix                              -> apache-https-for-providers/constraints-2.2.1-fix
 * [new branch]            constraints-2.2.2-fix                              -> apache-https-for-providers/constraints-2.2.2-fix
 * [new branch]            constraints-2.2.3-fix                              -> apache-https-for-providers/constraints-2.2.3-fix
 * [new branch]            constraints-2.2.4-fix                              -> apache-https-for-providers/constraints-2.2.4-fix
 * [new branch]            constraints-2.2.5-fix                              -> apache-https-for-providers/constraints-2.2.5-fix
 * [new branch]            constraints-2.3.0-fix                              -> apache-https-for-providers/constraints-2.3.0-fix
 * [new branch]            constraints-2.3.0-fixed                            -> apache-https-for-providers/constraints-2.3.0-fixed
 * [new branch]            constraints-2.3.1-fix                              -> apache-https-for-providers/constraints-2.3.1-fix
 * [new branch]            constraints-2.3.1-fixed                            -> apache-https-for-providers/constraints-2.3.1-fixed
 * [new branch]            constraints-2.3.2-fix                              -> apache-https-for-providers/constraints-2.3.2-fix
 * [new branch]            constraints-2.3.2-fixed                            -> apache-https-for-providers/constraints-2.3.2-fixed
 * [new branch]            constraints-2.3.3-fix                              -> apache-https-for-providers/constraints-2.3.3-fix
 * [new branch]            constraints-2.3.4-fix                              -> apache-https-for-providers/constraints-2.3.4-fix
 * [new branch]            constraints-2.4.0-fix                              -> apache-https-for-providers/constraints-2.4.0-fix
 * [new branch]            constraints-2.4.1-fix                              -> apache-https-for-providers/constraints-2.4.1-fix
 * [new branch]            constraints-2.4.2-fix                              -> apache-https-for-providers/constraints-2.4.2-fix
 * [new branch]            constraints-2.4.3-fix                              -> apache-https-for-providers/constraints-2.4.3-fix
 * [new branch]            constraints-2.5.0-fix                              -> apache-https-for-providers/constraints-2.5.0-fix
 * [new branch]            constraints-2.5.1-fix                              -> apache-https-for-providers/constraints-2.5.1-fix
 * [new branch]            constraints-2.5.2-fix                              -> apache-https-for-providers/constraints-2.5.2-fix
 * [new branch]            constraints-2.5.3-fix                              -> apache-https-for-providers/constraints-2.5.3-fix
 * [new branch]            constraints-2.6.0-fix                              -> apache-https-for-providers/constraints-2.6.0-fix
 * [new branch]            constraints-2.6.1-fix                              -> apache-https-for-providers/constraints-2.6.1-fix
 * [new branch]            constraints-2.6.2-fix                              -> apache-https-for-providers/constraints-2.6.2-fix
 * [new branch]            constraints-2.6.3-fix                              -> apache-https-for-providers/constraints-2.6.3-fix
 * [new branch]            constraints-2.7.1-fix                              -> apache-https-for-providers/constraints-2.7.1-fix
 * [new branch]            constraints-2.7.2-fix                              -> apache-https-for-providers/constraints-2.7.2-fix
 * [new branch]            constraints-2.7.3-fix                              -> apache-https-for-providers/constraints-2.7.3-fix
 * [new branch]            constraints-2.8.1-fix                              -> apache-https-for-providers/constraints-2.8.1-fix
 * [new branch]            constraints-2.8.2-fix                              -> apache-https-for-providers/constraints-2.8.2-fix
 * [new branch]            constraints-2.9.3-fix                              -> apache-https-for-providers/constraints-2.9.3-fix
 * [new branch]            constraints-mai                                    -> apache-https-for-providers/constraints-mai
 * [new branch]            constraints-main                                   -> apache-https-for-providers/constraints-main
 * [new branch]            correct-casing-of-python-in-ci.yml                 -> apache-https-for-providers/correct-casing-of-python-in-ci.yml
 * [new branch]            disable-pushing-cache-temporarily                  -> apache-https-for-providers/disable-pushing-cache-temporarily
 * [new branch]            dont-get-dag-we-already-have-it                    -> apache-https-for-providers/dont-get-dag-we-already-have-it
 * [new branch]            extract-basic-tests-to-separate-workflow           -> apache-https-for-providers/extract-basic-tests-to-separate-workflow
 * [new branch]            extract-docs-to-separate-workflow                  -> apache-https-for-providers/extract-docs-to-separate-workflow
 * [new branch]            extract-early-image-checks-workflow                -> apache-https-for-providers/extract-early-image-checks-workflow
 * [new branch]            extract-finalization-of-tests-to-separate-workflow -> apache-https-for-providers/extract-finalization-of-tests-to-separate-workflow
 * [new branch]            feat/max_active_tis_per_dagrun                     -> apache-https-for-providers/feat/max_active_tis_per_dagrun
 * [new branch]            fix-broken-compatibility-check                     -> apache-https-for-providers/fix-broken-compatibility-check
 * [new branch]            fix-canary-run-check                               -> apache-https-for-providers/fix-canary-run-check
 * [new branch]            fix-docker-cache-input-name                        -> apache-https-for-providers/fix-docker-cache-input-name
 * [new branch]            fix-image-cache                                    -> apache-https-for-providers/fix-image-cache
 * [new branch]            fix-image-cache-2                                  -> apache-https-for-providers/fix-image-cache-2
 * [new branch]            fix-missing-condition-on-image-push                -> apache-https-for-providers/fix-missing-condition-on-image-push
 * [new branch]            fix-openlineage-tests                              -> apache-https-for-providers/fix-openlineage-tests
 * [new branch]            fix-parser-test-whitespace                         -> apache-https-for-providers/fix-parser-test-whitespace
 * [new branch]            fix_prev_dagrun_dep_for_dynamic_tasks              -> apache-https-for-providers/fix_prev_dagrun_dep_for_dynamic_tasks
 * [new branch]            hooks-lineage                                      -> apache-https-for-providers/hooks-lineage
 * [new branch]            improve-test-finalization                          -> apache-https-for-providers/improve-test-finalization
 * [new branch]            main                                               -> apache-https-for-providers/main
 * [new branch]            mlnsharma/main                                     -> apache-https-for-providers/mlnsharma/main
 * [new branch]            move-cleanup-docker-to-bash-script                 -> apache-https-for-providers/move-cleanup-docker-to-bash-script
 * [new branch]            move-ol-config-to-local-file                       -> apache-https-for-providers/move-ol-config-to-local-file
 * [new branch]            ol-include-additional-info                         -> apache-https-for-providers/ol-include-additional-info
 * [new branch]            ol-use-getboolean                                  -> apache-https-for-providers/ol-use-getboolean
 * [new branch]            openlineage-bigquery-operation                     -> apache-https-for-providers/openlineage-bigquery-operation
 * [new branch]            openlineage-do-not-submit-busyjobs                 -> apache-https-for-providers/openlineage-do-not-submit-busyjobs
 * [new branch]            openlineage-gcs-operator                           -> apache-https-for-providers/openlineage-gcs-operator
 * [new branch]            openlineage-processexecution                       -> apache-https-for-providers/openlineage-processexecution
 * [new branch]            openlineage-sagemaker-operators                    -> apache-https-for-providers/openlineage-sagemaker-operators
 * [new branch]            openlineage-sftp-operator                          -> apache-https-for-providers/openlineage-sftp-operator
 * [new branch]            openlineage-system-tests                           -> apache-https-for-providers/openlineage-system-tests
 * [new branch]            optimize-cache-building-workflow                   -> apache-https-for-providers/optimize-cache-building-workflow
 * [new branch]            optimize-caching-workflows                         -> apache-https-for-providers/optimize-caching-workflows
 * [new branch]            optimize-package-preparation-for-prod-builds       -> apache-https-for-providers/optimize-package-preparation-for-prod-builds
 * [new branch]            optimize-tests-when-ci-scripts-change              -> apache-https-for-providers/optimize-tests-when-ci-scripts-change
 * [new branch]            potiuk-patch-1                                     -> apache-https-for-providers/potiuk-patch-1
 * [new branch]            provider-cncf-kubernetes/v4-4                      -> apache-https-for-providers/provider-cncf-kubernetes/v4-4
 * [new branch]            remove-canary-typo                                 -> apache-https-for-providers/remove-canary-typo
 * [new branch]            remove-fab-from-chicken-egg-providers              -> apache-https-for-providers/remove-fab-from-chicken-egg-providers
 * [new branch]            restore-test-airflow-release-commands              -> apache-https-for-providers/restore-test-airflow-release-commands
 * [new branch]            revert-38054-onikolas/aip-61/db_migration          -> apache-https-for-providers/revert-38054-onikolas/aip-61/db_migration
 * [new branch]            revert-40153-add-databricks-plugin                 -> apache-https-for-providers/revert-40153-add-databricks-plugin
 * [new branch]            separate-cache-workflow                            -> apache-https-for-providers/separate-cache-workflow
 * [new branch]            simplify-provider-state                            -> apache-https-for-providers/simplify-provider-state
 * [new branch]            switch-cache-building-to-public-macos-runners      -> apache-https-for-providers/switch-cache-building-to-public-macos-runners
 * [new branch]            test-cache-refreshing                              -> apache-https-for-providers/test-cache-refreshing
 * [new branch]            test-image-cache                                   -> apache-https-for-providers/test-image-cache
 * [new branch]            turn-optional-dependencies-in-dynamic-metadata     -> apache-https-for-providers/turn-optional-dependencies-in-dynamic-metadata
 * [new branch]            use-common-image-workflows-in-pull-request-target  -> apache-https-for-providers/use-common-image-workflows-in-pull-request-target
 * [new branch]            v1-10-stable                                       -> apache-https-for-providers/v1-10-stable
 * [new branch]            v1-10-test                                         -> apache-https-for-providers/v1-10-test
 * [new branch]            v1-8-stable                                        -> apache-https-for-providers/v1-8-stable
 * [new branch]            v1-8-test                                          -> apache-https-for-providers/v1-8-test
 * [new branch]            v1-9-stable                                        -> apache-https-for-providers/v1-9-stable
 * [new branch]            v1-9-test                                          -> apache-https-for-providers/v1-9-test
 * [new branch]            v2-0-stable                                        -> apache-https-for-providers/v2-0-stable
 * [new branch]            v2-1-stable                                        -> apache-https-for-providers/v2-1-stable
 * [new branch]            v2-1-test                                          -> apache-https-for-providers/v2-1-test
 * [new branch]            v2-10-stable                                       -> apache-https-for-providers/v2-10-stable
 * [new branch]            v2-10-test                                         -> apache-https-for-providers/v2-10-test
 * [new branch]            v2-2-stable                                        -> apache-https-for-providers/v2-2-stable
 * [new branch]            v2-2-test                                          -> apache-https-for-providers/v2-2-test
 * [new branch]            v2-3-stable                                        -> apache-https-for-providers/v2-3-stable
 * [new branch]            v2-3-test                                          -> apache-https-for-providers/v2-3-test
 * [new branch]            v2-4-stable                                        -> apache-https-for-providers/v2-4-stable
 * [new branch]            v2-5-stable                                        -> apache-https-for-providers/v2-5-stable
 * [new branch]            v2-5-test                                          -> apache-https-for-providers/v2-5-test
 * [new branch]            v2-6-stable                                        -> apache-https-for-providers/v2-6-stable
 * [new branch]            v2-6-test                                          -> apache-https-for-providers/v2-6-test
 * [new branch]            v2-7-stable                                        -> apache-https-for-providers/v2-7-stable
 * [new branch]            v2-8-stable                                        -> apache-https-for-providers/v2-8-stable
 * [new branch]            v2-8-test                                          -> apache-https-for-providers/v2-8-test
 * [new branch]            v2-9-stable                                        -> apache-https-for-providers/v2-9-stable
 * [new branch]            v2-9-test                                          -> apache-https-for-providers/v2-9-test
 * [new branch]            xdist-tests-distribution                           -> apache-https-for-providers/xdist-tests-distribution
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Update release notes for package 'apache.drill'

Updating documentation for the latest release version.
The provider apache.drill has 1 changes since last release

Provider: apache.drill



NEXT VERSION AFTER + 2.7.2
..........................

Latest change: 2024-07-19

=================================================================================================  ===========  ============================================================
Commit                                                                                             Committed    Subject
=================================================================================================  ===========  ============================================================
`bef82d6ab3 <https://github.com/apache/airflow/commit/bef82d6ab38d627dc1b42981c90b9f8d36852f4c>`_  2024-07-19   ``Clean up remaining getattr connection DbApiHook (#40665)``
=================================================================================================  ===========  ============================================================

Does the provider: apache.drill have any changes apart from 'doc-only'?
Press y/N/q: y

Define the type of change for `Clean up remaining getattr connection DbApiHook (https://github.com/apache/airflow/pull/40665)` by referring to the above table
Type of change (b)ugfix, (f)eature, (x)breaking change, (m)misc, (s)kip, (q)uit ? m

The version will be bumped because of TypeOfChange.MISC kind of change
Provider apache.drill has been classified as:

Miscellaneous changes - bump in PATCHLEVEL version needed

The provider apache.drill has 1 changes since last release

Provider: apache.drill
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-08-02 09:12:43+00:00,[],2024-08-02 14:22:32+00:00,2024-08-02 14:22:32+00:00,https://github.com/apache/airflow/pull/41213,"[('area:dev-tools', '')]",[],
2444018835,pull_request,closed,,Don't reserialize DAG if no revision's applied,"This saves some resource and helps avoid issues in dynamic DAG generation from the user.

Close #40082.",uranusjr,2024-08-02 04:34:54+00:00,[],2024-08-28 05:33:33+00:00,2024-08-06 17:08:01+00:00,https://github.com/apache/airflow/pull/41207,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2443953606,pull_request,closed,,Fix RedshiftDataOperator not running in deferred mode when it should,"# Problems
- When a `RedshiftDataOperator` task is configured with `deferrable=True` and `wait_for_completion=True` (the default), it doesn't go in `deferred` state. Instead it stays in `running` state until the statement completes.
- Also, if `wait_for_completion=False` and `deferrable=True`, after the statement is submitted, the task will still go into `deferred` mode and wait for the statement to complete.

# Reasons
- Currently, if `deferrable=True`, `self.wait_for_completion` is set to `False` in `execute()`, but never used after.
- `execute` does not check whether the task should wait for completion, only if it should be deferred.

# Solution
- Overwrite `wait_for_completion` instead of `self.wait_for_completion` when deferrable. Also, remove redundant condition on `self.wait_for_completion`
- Before going into deferrable mode, also check that the task is supposed to wait for completion.

# How I tested
Checked with this simple DAG that the operator now behaves as expected, for all 4 combinations:
```python
from airflow.decorators import dag
from airflow.providers.amazon.aws.operators.redshift_data import RedshiftDataOperator

@dag(
    ""Foo"",
)
def _():
    for task_id, config in {
        ""wait_defer"": {""deferrable"": True, ""wait_for_completion"": True},
        ""wait_no_defer"": {""deferrable"": False, ""wait_for_completion"": True},
        ""no_wait_defer"": {""deferrable"": True, ""wait_for_completion"": False},
        ""no_wait_no_defer"": {""deferrable"": False, ""wait_for_completion"": False},
    }.items():
        RedshiftDataOperator(
            task_id=task_id,
            aws_conn_id=""redshift_data"",
            cluster_identifier=""data-warehouse"",
            db_user=""airflow"",
            database=""bar"",
            sql=""""""CREATE TEMPORARY TABLE tmp_foo AS
            SELECT *
            FROM some.big_table
            LIMIT 10;"""""",
            deferrable=config[""deferrable""],
            wait_for_completion=config[""wait_for_completion""],
        )

_()
```

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",borismo,2024-08-02 03:55:45+00:00,[],2024-08-07 11:35:06+00:00,2024-08-07 11:35:03+00:00,https://github.com/apache/airflow/pull/41206,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2264476773, 'issue_id': 2443953606, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 2, 3, 55, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264509664, 'issue_id': 2443953606, 'author': 'eladkal', 'body': ""Wasn't this already fixed in https://github.com/apache/airflow/pull/41191 ?"", 'created_at': datetime.datetime(2024, 8, 2, 4, 17, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264611236, 'issue_id': 2443953606, 'author': 'borismo', 'body': ""At first I thought too, but it's a different ~operator. `RedshiftDataOperator` vs. `RedshiftCreateClusterOperator`.~ module: `airflow/providers/amazon/aws/operators/redshift_cluster.py` vs. `airflow/providers/amazon/aws/operators/redshift_data.py`."", 'created_at': datetime.datetime(2024, 8, 2, 5, 51, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264827800, 'issue_id': 2443953606, 'author': 'eladkal', 'body': 'Ah OK.\r\nCan you please add unit test to avoid regression?', 'created_at': datetime.datetime(2024, 8, 2, 8, 15, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266648312, 'issue_id': 2443953606, 'author': 'borismo', 'body': ""Here's what I did:\r\n- tweaked the existing `deferrable_operator` fixture so it waits for completion. The `test_execute_defer` test was failing with my fix. I think this test should use an operator configured to wait.\r\n- added a test which verifies that if we don't want to wait for completion, the operator should not check whether the statement has completed and also shouldn't enter deferred mode.\r\n\r\nNot sure if it's a good idea to iterate over `deferrable`. I did so to keep it DRY, since if separate, the 2 two tests would be almost identical. And I intend the test to really emphasize on the fact that the `deferrable` value doesn't matter.\r\n\r\n> [!WARNING]  \r\n> I realize now that this fix will change the operator's behavior: for folks who have been using it with `deferrable = True` and `wait_for_completion = False` to make it go into deferrable mode (a workaround IMO), the task instance will now immediately be marked as success without waiting. Could break downstream tasks that expect the statement to be completed."", 'created_at': datetime.datetime(2024, 8, 3, 9, 8, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2271430140, 'issue_id': 2443953606, 'author': 'vincbeck', 'body': ""> I realize now that this fix will change the operator's behavior: for folks who have been using it with `deferrable = True` and `wait_for_completion = False` to make it go into deferrable mode (a workaround IMO), the task instance will now immediately be marked as success without waiting. Could break downstream tasks that expect the statement to be completed.\r\n\r\nYou are correct but this is a bug fix. The previous behavior was wrong so to me we should go ahead with that change"", 'created_at': datetime.datetime(2024, 8, 6, 14, 25, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2271625537, 'issue_id': 2443953606, 'author': 'eladkal', 'body': 'Can you add to the provider changelog a block of\r\n\r\n```\r\nMain\r\n......\r\n\r\n.. warning::\r\n\r\n\r\n```\r\nto the changelog where you explain how to mitigate the change. It needs to have 2-4 sentenses that just users would understand what was change and how to mitigate this.\r\n\r\nExample:\r\n\r\nhttps://github.com/apache/airflow/blob/main/airflow/providers/amazon/CHANGELOG.rst#870', 'created_at': datetime.datetime(2024, 8, 6, 15, 55, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2273260584, 'issue_id': 2443953606, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 7, 11, 35, 6, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-02 03:55:49 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-08-02 04:17:19 UTC): Wasn't this already fixed in https://github.com/apache/airflow/pull/41191 ?

borismo (Issue Creator) on (2024-08-02 05:51:11 UTC): At first I thought too, but it's a different ~operator. `RedshiftDataOperator` vs. `RedshiftCreateClusterOperator`.~ module: `airflow/providers/amazon/aws/operators/redshift_cluster.py` vs. `airflow/providers/amazon/aws/operators/redshift_data.py`.

eladkal on (2024-08-02 08:15:04 UTC): Ah OK.
Can you please add unit test to avoid regression?

borismo (Issue Creator) on (2024-08-03 09:08:11 UTC): Here's what I did:
- tweaked the existing `deferrable_operator` fixture so it waits for completion. The `test_execute_defer` test was failing with my fix. I think this test should use an operator configured to wait.
- added a test which verifies that if we don't want to wait for completion, the operator should not check whether the statement has completed and also shouldn't enter deferred mode.

Not sure if it's a good idea to iterate over `deferrable`. I did so to keep it DRY, since if separate, the 2 two tests would be almost identical. And I intend the test to really emphasize on the fact that the `deferrable` value doesn't matter.

vincbeck on (2024-08-06 14:25:35 UTC): You are correct but this is a bug fix. The previous behavior was wrong so to me we should go ahead with that change

eladkal on (2024-08-06 15:55:40 UTC): Can you add to the provider changelog a block of

```
Main
......

.. warning::


```
to the changelog where you explain how to mitigate the change. It needs to have 2-4 sentenses that just users would understand what was change and how to mitigate this.

Example:

https://github.com/apache/airflow/blob/main/airflow/providers/amazon/CHANGELOG.rst#870

boring-cyborg[bot] on (2024-08-07 11:35:06 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2443705684,pull_request,closed,,Add description in docker image changelog about upgraded FAB,"That also includes reverting the order of changes to
""most recent first""

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-01 23:55:00+00:00,[],2024-08-02 10:17:26+00:00,2024-08-02 01:13:39+00:00,https://github.com/apache/airflow/pull/41205,"[('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2443435318,pull_request,closed,,Time zone is not taken into account in run_id and execution_date,"Hi,

We noticed that time zone from config (""default_timezone = Europe/Moscow"") is not taken into account when generating ""run_id"". 
Also ""execution_date"" field is always shown in UTC in Airflow UI, see my screenshots.

I created this patch to generate ""run_id"" and to display ""execution_date"" in specified default time zone (get ""default_timezone"" option from configuration). 
Moreover I call ""coerce_datetime()"" function in api, thus links to task instances will have ""execution_date"" parameter with correct time zone in UI.

See other discussion:
https://github.com/apache/airflow/discussions/27471

![Screenshot from 2024-08-01 23-28-24](https://github.com/user-attachments/assets/00b56ff0-b80f-47ed-9a1d-9af5ed18a016)
![Screenshot from 2024-08-01 23-29-42](https://github.com/user-attachments/assets/5f0894f4-112f-4ae6-84a2-961deec78eed)
",werzerbb,2024-08-01 21:03:39+00:00,[],2024-09-24 18:39:55+00:00,2024-09-24 18:39:55+00:00,https://github.com/apache/airflow/pull/41203,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2263988669, 'issue_id': 2443435318, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 8, 1, 21, 3, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354247157, 'issue_id': 2443435318, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 17, 0, 12, 17, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-08-01 21:03:43 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2024-09-17 00:12:17 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2443378779,pull_request,closed,,Automatically expand `Post task execution logs` log group,"This change automatically expands the `Post task execution logs` log group to make debugging easier.

See issue https://github.com/apache/airflow/issues/41198

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",mjohansenwork,2024-08-01 20:42:46+00:00,[],2024-08-23 15:30:58+00:00,2024-08-23 15:30:58+00:00,https://github.com/apache/airflow/pull/41201,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2288058264, 'issue_id': 2443378779, 'author': 'jscheffl', 'body': 'Thanks for the PR ... but I actually dis-like it. The log grouping is a feature to make log view less polluted especially with internal logs from Airflow. Therefore opening the log group by default is actually reverting the feature. Please do not statically un-fold the group.\r\nWhat maybe you did not notice but the folding state is ""kept"" if you navigate around in the grid view. This is a real feature. So if you un-fold in one log and navigate to another, log groups with the same ""name/label"" also will be un-grouped.', 'created_at': datetime.datetime(2024, 8, 14, 7, 38, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288059906, 'issue_id': 2443378779, 'author': 'jscheffl', 'body': 'Additionally to note, if an exception is made and an exception trace is logged, from Airflow 2.10 onwards the Exception log is made BEFORE the log group, so the exception will be visible with 2.10 per default w/o the need to un-fold.', 'created_at': datetime.datetime(2024, 8, 14, 7, 39, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288061145, 'issue_id': 2443378779, 'author': 'jscheffl', 'body': 'See: https://github.com/apache/airflow/pull/40146', 'created_at': datetime.datetime(2024, 8, 14, 7, 40, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288382485, 'issue_id': 2443378779, 'author': 'potiuk', 'body': '> Please don\'t merge, this would be a step backwards and make if worse\r\n\r\nQuite agree. When you need to debug comparing to looking at ""regular"" output You already need to go ""deeper"" - this is what it does and #40146 addresses the case when you get an actual exception.\r\n\r\nAlternative option that could be acceptable is to check if there are any error/warning logs printed in the folded post task execution logs and only auto-expand it then. That might be actually useful', 'created_at': datetime.datetime(2024, 8, 14, 10, 20, 38, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-08-14 07:38:43 UTC): Thanks for the PR ... but I actually dis-like it. The log grouping is a feature to make log view less polluted especially with internal logs from Airflow. Therefore opening the log group by default is actually reverting the feature. Please do not statically un-fold the group.
What maybe you did not notice but the folding state is ""kept"" if you navigate around in the grid view. This is a real feature. So if you un-fold in one log and navigate to another, log groups with the same ""name/label"" also will be un-grouped.

jscheffl on (2024-08-14 07:39:36 UTC): Additionally to note, if an exception is made and an exception trace is logged, from Airflow 2.10 onwards the Exception log is made BEFORE the log group, so the exception will be visible with 2.10 per default w/o the need to un-fold.

jscheffl on (2024-08-14 07:40:18 UTC): See: https://github.com/apache/airflow/pull/40146

potiuk on (2024-08-14 10:20:38 UTC): Quite agree. When you need to debug comparing to looking at ""regular"" output You already need to go ""deeper"" - this is what it does and #40146 addresses the case when you get an actual exception.

Alternative option that could be acceptable is to check if there are any error/warning logs printed in the folded post task execution logs and only auto-expand it then. That might be actually useful

"
2443270017,pull_request,closed,,Add button to toggle datasets on/off in dag graph,"Closes https://github.com/apache/airflow/issues/41003

We will want to improve the dataset dependency graph at some point to do the inverse, but thats a different feature.

<img width=""869"" alt=""Screenshot 2024-08-01 at 3 42 04â€¯PM"" src=""https://github.com/user-attachments/assets/ec91a440-8686-4df2-bc38-3a357a52e4f5"">

<img width=""866"" alt=""Screenshot 2024-08-01 at 3 42 09â€¯PM"" src=""https://github.com/user-attachments/assets/13741e76-75b2-4a19-8b33-e98f57bf6f77"">


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-01 19:41:16+00:00,[],2024-08-06 09:39:25+00:00,2024-08-05 13:52:52+00:00,https://github.com/apache/airflow/pull/41200,"[('area:webserver', 'Webserver related Issues'), ('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2266375231, 'issue_id': 2443270017, 'author': 'eladkal', 'body': '@bbovenzi The issue is marked as 3.0 candidate yet the PR is closing the issue for 2.10 is this right?\r\ndo we need to split the issue into 2.10 and 3.0?', 'created_at': datetime.datetime(2024, 8, 3, 5, 3, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2268339180, 'issue_id': 2443270017, 'author': 'uranusjr', 'body': 'The 3.0 candidate flag was added during the issue triaging effort. If this is ready for 2.10 I donâ€™t see why we need to keep it out (there are not compatibility issues).', 'created_at': datetime.datetime(2024, 8, 5, 7, 12, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2269135174, 'issue_id': 2443270017, 'author': 'bbovenzi', 'body': 'Nothing prevents it from being 2.10. I just removed that flag from the original issue.', 'created_at': datetime.datetime(2024, 8, 5, 13, 52, 42, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-03 05:03:45 UTC): @bbovenzi The issue is marked as 3.0 candidate yet the PR is closing the issue for 2.10 is this right?
do we need to split the issue into 2.10 and 3.0?

uranusjr on (2024-08-05 07:12:43 UTC): The 3.0 candidate flag was added during the issue triaging effort. If this is ready for 2.10 I donâ€™t see why we need to keep it out (there are not compatibility issues).

bbovenzi (Issue Creator) on (2024-08-05 13:52:42 UTC): Nothing prevents it from being 2.10. I just removed that flag from the original issue.

"
2443229325,pull_request,closed,,Improve docs build speed in canary runs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-01 19:18:55+00:00,[],2024-08-02 19:20:22+00:00,2024-08-02 19:20:22+00:00,https://github.com/apache/airflow/pull/41199,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]",[],
2443164869,pull_request,closed,,Remove API/CLI commends from db isolation mode tests,"Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-01 18:46:12+00:00,[],2024-08-01 19:20:49+00:00,2024-08-01 19:20:47+00:00,https://github.com/apache/airflow/pull/41197,"[('area:CLI', ''), ('area:plugins', ''), ('area:Triggerer', '')]",[],
2443084005,pull_request,closed,,Use Task Tries rest API and not views.py endpoint,"Have the UI use the REST API for task tries instead of the ti_history endpoint from views.py and delete the redundant endpoint.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-01 18:13:08+00:00,[],2024-08-06 09:53:01+00:00,2024-08-01 19:08:55+00:00,https://github.com/apache/airflow/pull/41196,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2443008287,pull_request,closed,,Update `is_called_from_test_code`,"Related #41067.

The way I see it is, if the stacktrace where the session has been created contains one test file, it means the session has been created in tests?

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-01 17:36:27+00:00,[],2024-08-01 17:58:53+00:00,2024-08-01 17:56:44+00:00,https://github.com/apache/airflow/pull/41193,[],"[{'comment_id': 2263632090, 'issue_id': 2443008287, 'author': 'potiuk', 'body': '> The way I see it is, if the stacktrace where the session has been created contains one test file, it means the session has been created in tests?\r\n\r\nNot really - the difficulty is that ""all"" tested code is called from tests. Say we want to do \r\n\r\n```\r\ndef test_something:\r\n     # some setup here (here we want to use DB calls\r\n     db.clean()\r\n     # actual test here (here we want to use internal API\r\n     ti.run()\r\n```\r\n\r\nAnd we need to guess when we have the second case (i.e. when we are not yet running ""tested"" code - but ""test setup"".\r\n\r\nWhen you use fixtures to setup code - it\'s easy - we do it by checking `conftest.py` in the stacktrace, but if someone mixes tests and setup code in test method, we can only guess. There are cases like baseoperator.run() which is used only in CLI and tests and until you go to ""_run_raw_task"", it should use DB, but after that internal api calls (we already handle that by the special  clause. We could potentially extend the list of calls that we consider as ""test setup"" when called directly from tests. But in general - the whole detection is rather brittle.', 'created_at': datetime.datetime(2024, 8, 1, 17, 51, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263644129, 'issue_id': 2443008287, 'author': 'vincbeck', 'body': 'I see! Makes sense, I tried :)', 'created_at': datetime.datetime(2024, 8, 1, 17, 56, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263647590, 'issue_id': 2443008287, 'author': 'potiuk', 'body': 'However - I have an idea how we can improve this a bit and make better guesses.', 'created_at': datetime.datetime(2024, 8, 1, 17, 58, 52, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-08-01 17:51:31 UTC): Not really - the difficulty is that ""all"" tested code is called from tests. Say we want to do 

```
def test_something:
     # some setup here (here we want to use DB calls
     db.clean()
     # actual test here (here we want to use internal API
     ti.run()
```

And we need to guess when we have the second case (i.e. when we are not yet running ""tested"" code - but ""test setup"".

When you use fixtures to setup code - it's easy - we do it by checking `conftest.py` in the stacktrace, but if someone mixes tests and setup code in test method, we can only guess. There are cases like baseoperator.run() which is used only in CLI and tests and until you go to ""_run_raw_task"", it should use DB, but after that internal api calls (we already handle that by the special  clause. We could potentially extend the list of calls that we consider as ""test setup"" when called directly from tests. But in general - the whole detection is rather brittle.

vincbeck (Issue Creator) on (2024-08-01 17:56:44 UTC): I see! Makes sense, I tried :)

potiuk on (2024-08-01 17:58:52 UTC): However - I have an idea how we can improve this a bit and make better guesses.

"
2443001727,pull_request,closed,,Adjust gantt width based on task history dates,"We adjust the gantt chart start and end dates based on the task instances rendered, but we weren't doing that for Task Try History. Sometimes, that led to tries being out-of-bound and not rendering in the gantt chart. This PR fixes that.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-01 17:33:15+00:00,[],2024-08-06 09:52:03+00:00,2024-08-02 04:40:03+00:00,https://github.com/apache/airflow/pull/41192,"[('area:webserver', 'Webserver related Issues'), ('type:improvement', 'Changelog: Improvements'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2442891906,pull_request,closed,,Fix AWS Redshift operators and sensors,"Some Redshift operators assume that when `deferrable` is `True`, it means the operator should wait. This is wrong. This is usually a flag `wait_for_completion` that set this behavior. I also updated some default values in operators/sensors depending on the underlying API called

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-08-01 16:34:12+00:00,[],2024-08-01 17:54:16+00:00,2024-08-01 17:54:15+00:00,https://github.com/apache/airflow/pull/41191,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2442828802,pull_request,closed,,Move Create Dataset Event button above tabs,"We moved the datasets view into a tab layout. The button to manually create a dataset event was only under the Dataset Details tab. Now it is moved to be on the same level as the breadcrumb when a dataset is selected. Now you can create a new dataset event from any tab and have to click back-and-forth.

<img width=""371"" alt=""Screenshot 2024-08-01 at 11 15 23â€¯AM"" src=""https://github.com/user-attachments/assets/6f770c60-075a-4760-aafb-6a136e5d2086"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-08-01 16:00:53+00:00,[],2024-08-07 04:21:55+00:00,2024-08-07 04:21:55+00:00,https://github.com/apache/airflow/pull/41190,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2442563911,pull_request,closed,,Enable scrolling on legend with high number of tasks.,"In the task duration page across all tasks the legend can overlap with the chart when there are more tasks in the dag. Enable scrolling to ensure the legend doesn't enter chart

Current : 

![image](https://github.com/user-attachments/assets/fd566540-8f5e-4a23-be2b-dd0ac6786827)

With PR : 

![image](https://github.com/user-attachments/assets/1a20dcc7-df74-4d49-a4f3-5ad6bacb3c18)
",tirkarthi,2024-08-01 14:01:18+00:00,[],2024-08-06 09:53:32+00:00,2024-08-01 15:05:53+00:00,https://github.com/apache/airflow/pull/41187,"[('area:webserver', 'Webserver related Issues'), ('type:improvement', 'Changelog: Improvements'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2263219348, 'issue_id': 2442563911, 'author': 'tirkarthi', 'body': 'CI failed due to unrelated error where upload to codecov timed out. Rebased PR to trigger a new run.', 'created_at': datetime.datetime(2024, 8, 1, 14, 27, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263310660, 'issue_id': 2442563911, 'author': 'tirkarthi', 'body': 'Thanks @bbovenzi', 'created_at': datetime.datetime(2024, 8, 1, 15, 7, 10, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-08-01 14:27:49 UTC): CI failed due to unrelated error where upload to codecov timed out. Rebased PR to trigger a new run.

tirkarthi (Issue Creator) on (2024-08-01 15:07:10 UTC): Thanks @bbovenzi

"
2442438085,pull_request,closed,,K8s Executor: failing the task in case the watcher receives an event with the reason ProviderFailed,In certain scenarios (k8s executor) we see pods are stuck with the provider failed reason. We need to mark those tasks as failed.,dirrao,2024-08-01 13:17:28+00:00,[],2024-08-23 06:14:02+00:00,2024-08-23 06:14:02+00:00,https://github.com/apache/airflow/pull/41186,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2265754222, 'issue_id': 2442438085, 'author': 'eladkal', 'body': 'tests are failing', 'created_at': datetime.datetime(2024, 8, 2, 16, 30, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2266653139, 'issue_id': 2442438085, 'author': 'dirrao', 'body': '> tests are failing\r\n\r\nNow test cases are passing.', 'created_at': datetime.datetime(2024, 8, 3, 9, 30, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270992198, 'issue_id': 2442438085, 'author': 'dirrao', 'body': '@jedcunningham / @hussein-awala \r\nCan you review it whenever you are free?', 'created_at': datetime.datetime(2024, 8, 6, 10, 54, 42, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-08-02 16:30:33 UTC): tests are failing

dirrao (Issue Creator) on (2024-08-03 09:30:05 UTC): Now test cases are passing.

dirrao (Issue Creator) on (2024-08-06 10:54:42 UTC): @jedcunningham / @hussein-awala 
Can you review it whenever you are free?

"
2442215662,pull_request,closed,,Sync v2-10-stable with v2-10-test to release 2.10.0b2,Time for 2.10.0b2!,utkarsharma2,2024-08-01 11:31:30+00:00,[],2024-08-06 13:05:51+00:00,2024-08-01 17:53:33+00:00,https://github.com/apache/airflow/pull/41184,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2263699246, 'issue_id': 2442215662, 'author': 'jedcunningham', 'body': 'I came in a bit late on the review, but we should do another pass or 2 on the release notes before we cut the release.', 'created_at': datetime.datetime(2024, 8, 1, 18, 26, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263706739, 'issue_id': 2442215662, 'author': 'ephraimbuddy', 'body': '> I came in a bit late on the review, but we should do another pass or 2 on the release notes before we cut the release.\r\n\r\nSorry, we were kind of in haste. We will still move the branch again for RC2 and will fix those', 'created_at': datetime.datetime(2024, 8, 1, 18, 30, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2263716565, 'issue_id': 2442215662, 'author': 'jedcunningham', 'body': 'Yep, no problem at all ðŸ‘', 'created_at': datetime.datetime(2024, 8, 1, 18, 34, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2271248014, 'issue_id': 2442215662, 'author': 'utkarsharma2', 'body': 'Hey @jedcunningham, thanks for the review. I have updated the new sync [PR](https://github.com/apache/airflow/pull/41280) according to your suggestions. PTAL.', 'created_at': datetime.datetime(2024, 8, 6, 13, 5, 50, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2024-08-01 18:26:46 UTC): I came in a bit late on the review, but we should do another pass or 2 on the release notes before we cut the release.

ephraimbuddy on (2024-08-01 18:30:04 UTC): Sorry, we were kind of in haste. We will still move the branch again for RC2 and will fix those

jedcunningham on (2024-08-01 18:34:46 UTC): Yep, no problem at all ðŸ‘

utkarsharma2 (Issue Creator) on (2024-08-06 13:05:50 UTC): Hey @jedcunningham, thanks for the review. I have updated the new sync [PR](https://github.com/apache/airflow/pull/41280) according to your suggestions. PTAL.

"
2442193962,pull_request,closed,,openlineage: fix duplicate naming in docs with list of supported operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
When multiple operators have the same name (like AzureBlobStorageToGCSOperator), we can unintentionally overwrite the OL supported operator with OL unsupported one, as we used class name when building class registry. This PR changes that to use full import path, it should fix the problem.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-08-01 11:20:02+00:00,[],2024-08-01 12:12:26+00:00,2024-08-01 11:53:02+00:00,https://github.com/apache/airflow/pull/41183,"[('kind:documentation', '')]","[{'comment_id': 2262847673, 'issue_id': 2442193962, 'author': 'mobuchowski', 'body': '> When multiple operators have the same name (like AzureBlobStorageToGCSOperator),\r\n\r\nðŸ˜ž', 'created_at': datetime.datetime(2024, 8, 1, 11, 51, 47, tzinfo=datetime.timezone.utc)}]","mobuchowski on (2024-08-01 11:51:47 UTC): ðŸ˜ž

"
2442029800,pull_request,closed,,"Allowing DateTimeSensorAsync, FileSensor and TimeSensorAsync to start execution from trigger during dynamic task mapping","Adding argument `trigger_kwargs` to DateTimeSensorAsync, FileSensor, and TimeSensorAsync allows them to start execution from trigger during dynamic task mapping. This PR also rewords and adds more detail to the start execution from the trigger during the dynamic task mapping section and reorders the paragraphs on that page.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-01 09:59:24+00:00,[],2024-08-01 13:45:11+00:00,2024-08-01 13:20:47+00:00,https://github.com/apache/airflow/pull/41182,"[('kind:documentation', ''), ('type:improvement', 'Changelog: Improvements'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2441999655,pull_request,closed,,Add common-compat to boring-cyborg.yml,,eladkal,2024-08-01 09:45:20+00:00,[],2024-08-02 03:21:23+00:00,2024-08-02 03:21:19+00:00,https://github.com/apache/airflow/pull/41180,"[('area:dev-tools', '')]",[],
2441882580,pull_request,closed,,fix: Fixing Helm chart flower ingress service reference,"closes #41175

### What happened

We are sub charting the official airflow chart and for this reason we need to use `fullnameOverride: ""airflow""` settings to achieve the desired k8s resource names. However when we are using it the flower ingress becomes invalid because it want's to connect to non existing service name. Root cause are in the ingress.yaml. The webserver ingress can handle it with no problem.

Incorrect code section

`flower-ingress.yaml` - [code section](https://github.com/apache/airflow/blob/daccc75b064c735636027b20f3edb82da69ffab1/chart/templates/flower/flower-ingress.yaml#L75)
```yaml
spec:
  rules:
    - http:
        paths:
          - backend:
              service:
                name: {{ $.Release.Name }}-flower
                port:
                  name: flower-ui
```

While in the correct code section

`webserver-ingress.yaml` - [code section](https://github.com/apache/airflow/blob/daccc75b064c735636027b20f3edb82da69ffab1/chart/templates/webserver/webserver-ingress.yaml#L83)

```yaml
spec:
  rules:
    - http:
        paths:
          - backend:
              service:
                name: {{ $fullname }}-webserver
                port:
                  name: airflow-ui
```


To overcome this issue we need to run this command on every deployment
```bash
kubectl patch ingress airflow-flower-ingress \
    --namespace ""airflow"" \
    --type='json' \
    -p='[{""op"": ""replace"", ""path"": ""/spec/rules/0/http/paths/0/backend/service/name"", ""value"":""airflow-flower""}]'
```

### What you think should happen instead

The following code should be updated to match how webserver ingress works
`flower-ingress.yaml` - [code section](https://github.com/apache/airflow/blob/daccc75b064c735636027b20f3edb82da69ffab1/chart/templates/flower/flower-ingress.yaml#L75)
```yaml
spec:
  rules:
    - http:
        paths:
          - backend:
              service:
                name: {{ $fullname }}-flower
                port:
                  name: flower-ui
```

",andormarkus,2024-08-01 08:56:44+00:00,[],2024-09-25 16:15:50+00:00,2024-09-25 10:39:06+00:00,https://github.com/apache/airflow/pull/41179,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2262647209, 'issue_id': 2441882580, 'author': 'andormarkus', 'body': 'Can someone help my why this test failing?\r\n[https://github.com/apache/airflow/actions/runs/10195595534/job/28204650305?pr=41179](https://github.com/apache/airflow/actions/runs/10195595534/job/28204650305?pr=41179)', 'created_at': datetime.datetime(2024, 8, 1, 10, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264911838, 'issue_id': 2441882580, 'author': 'romsharon98', 'body': '> Can someone help my why this test failing? https://github.com/apache/airflow/actions/runs/10195595534/job/28204650305?pr=41179\r\n\r\nrebase solved it ðŸ˜„', 'created_at': datetime.datetime(2024, 8, 2, 9, 1, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2264978663, 'issue_id': 2441882580, 'author': 'andormarkus', 'body': ""Hi @romsharon98 \r\n\r\nI'm happy to add helm test for the modified ingress object, however the helm test framework is fully missing from the helm chart and we need to add the automated test runs to the CI/CD pipelines as well.\r\n\r\nHelm testing [documentation](https://helm.sh/docs/topics/chart_tests/),"", 'created_at': datetime.datetime(2024, 8, 2, 9, 38, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265016260, 'issue_id': 2441882580, 'author': 'romsharon98', 'body': 'You can add your tests [here](https://github.com/apache/airflow/blob/main/helm_tests/other/test_flower.py)\r\nYou can see more in [helm unit tests docs](https://github.com/apache/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst)', 'created_at': datetime.datetime(2024, 8, 2, 9, 59, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2343275404, 'issue_id': 2441882580, 'author': 'andormarkus', 'body': 'Hi @romsharon98 \r\n\r\nSorry for the late reply I was on extended vacation.\r\n\r\nI have run into to a problem when I added the `""fullnameOverride"": ""test-basic""` it looks like the `chart/templates/_helpers.yaml` is not executed when I run the tests.\r\n\r\nHere are my tests\r\n`helm_tests/webserver/test_ingress_web.py`\r\n```python\r\n    def test_backend_service_name(self):\r\n        docs = render_chart(\r\n            values={""ingress"": {""web"": {""enabled"": True}}},\r\n            show_only=[""templates/webserver/webserver-ingress.yaml""],\r\n        )\r\n\r\n        assert ""release-name-webserver"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n\r\n    def test_backend_service_name_with_fullname_override(self):\r\n        docs = render_chart(\r\n            values={""fullnameOverride"": ""test-basic"",\r\n                    ""ingress"": {""web"": {""enabled"": True}}},\r\n            show_only=[""templates/webserver/webserver-ingress.yaml""],\r\n\r\n        )\r\n\r\n        assert ""test-basic-webserver"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n```\r\n\r\n\r\n`helm_tests/webserver/test_ingress_flower.py`\r\n\r\n```python\r\n    def test_backend_service_name(self):\r\n        docs = render_chart(\r\n            values={""ingress"": {""enabled"": True}, ""flower"": {""enabled"": True}},\r\n            show_only=[""templates/flower/flower-ingress.yaml""],\r\n        )\r\n\r\n        assert ""release-name-flower"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n\r\n    def test_backend_service_name_with_fullname_override(self):\r\n        docs = render_chart(\r\n            values={""fullnameOverride"": ""test-basic"",\r\n                    ""ingress"": {""enabled"": True}, ""flower"": {""enabled"": True}},\r\n            show_only=[""templates/flower/flower-ingress.yaml""],\r\n\r\n        )\r\n\r\n        assert ""test-basic-flower"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n\r\n```\r\n\r\n\r\nI run the test using the following command\r\n\r\n```shell\r\n breeze testing helm-tests --helm-test-package webserver  \r\n```\r\n\r\n```shell\r\nFAILED helm_tests/webserver/test_ingress_flower.py::TestIngressFlower::test_backend_service_name_with_fullname_override - AssertionError: assert equals failed\r\n  \'test-basic-flower\'    \'release-name-flower\'\r\nFAILED helm_tests/webserver/test_ingress_web.py::TestIngressWeb::test_backend_service_name_with_fullname_override - AssertionError: assert equals failed\r\n  \'test-basic-webserver\'    \'release-name-webserver\'\r\n```\r\n\r\n\r\n```', 'created_at': datetime.datetime(2024, 9, 11, 10, 36, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2349915115, 'issue_id': 2441882580, 'author': 'romsharon98', 'body': '> Hi @romsharon98\r\n> \r\n> Sorry for the late reply I was on extended vacation.\r\n> \r\n> I have run into to a problem when I added the `""fullnameOverride"": ""test-basic""` it looks like the `chart/templates/_helpers.yaml` is not executed when I run the tests.\r\n> \r\n> Here are my tests `helm_tests/webserver/test_ingress_web.py`\r\n> \r\n> ```python\r\n>     def test_backend_service_name(self):\r\n>         docs = render_chart(\r\n>             values={""ingress"": {""web"": {""enabled"": True}}},\r\n>             show_only=[""templates/webserver/webserver-ingress.yaml""],\r\n>         )\r\n> \r\n>         assert ""release-name-webserver"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n> \r\n>     def test_backend_service_name_with_fullname_override(self):\r\n>         docs = render_chart(\r\n>             values={""fullnameOverride"": ""test-basic"",\r\n>                     ""ingress"": {""web"": {""enabled"": True}}},\r\n>             show_only=[""templates/webserver/webserver-ingress.yaml""],\r\n> \r\n>         )\r\n> \r\n>         assert ""test-basic-webserver"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n> ```\r\n> \r\n> `helm_tests/webserver/test_ingress_flower.py`\r\n> \r\n> ```python\r\n>     def test_backend_service_name(self):\r\n>         docs = render_chart(\r\n>             values={""ingress"": {""enabled"": True}, ""flower"": {""enabled"": True}},\r\n>             show_only=[""templates/flower/flower-ingress.yaml""],\r\n>         )\r\n> \r\n>         assert ""release-name-flower"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n> \r\n>     def test_backend_service_name_with_fullname_override(self):\r\n>         docs = render_chart(\r\n>             values={""fullnameOverride"": ""test-basic"",\r\n>                     ""ingress"": {""enabled"": True}, ""flower"": {""enabled"": True}},\r\n>             show_only=[""templates/flower/flower-ingress.yaml""],\r\n> \r\n>         )\r\n> \r\n>         assert ""test-basic-flower"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])\r\n> ```\r\n> \r\n> I run the test using the following command\r\n> \r\n> ```shell\r\n>  breeze testing helm-tests --helm-test-package webserver  \r\n> ```\r\n> \r\n> ```shell\r\n> FAILED helm_tests/webserver/test_ingress_flower.py::TestIngressFlower::test_backend_service_name_with_fullname_override - AssertionError: assert equals failed\r\n>   \'test-basic-flower\'    \'release-name-flower\'\r\n> FAILED helm_tests/webserver/test_ingress_web.py::TestIngressWeb::test_backend_service_name_with_fullname_override - AssertionError: assert equals failed\r\n>   \'test-basic-webserver\'    \'release-name-webserver\'\r\n> ```\r\n\r\nfor this to be applied you need to set `useStandardNaming` to be `true`', 'created_at': datetime.datetime(2024, 9, 13, 18, 56, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2350272360, 'issue_id': 2441882580, 'author': 'andormarkus', 'body': 'Hi @romsharon98\r\n\r\nThank you so much the help. Now my tests are passing.\r\nPlease let me know If I need to more test of where to adjust the code?\r\n\r\nThanks,\r\nAndor', 'created_at': datetime.datetime(2024, 9, 13, 21, 23, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2350811178, 'issue_id': 2441882580, 'author': 'romsharon98', 'body': '> Hi @romsharon98\n> \n> \n> \n> Thank you so much the help. Now my tests are passing.\n> \n> Please let me know If I need to more test of where to adjust the code?\n> \n> \n> \n> Thanks,\n> \n> Andor\n\nYou have static checks fail.\nBetter work with pre commit to see those errors before you commit.\n\nYou can see how to install it here\n\nhttps://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#installing-pre-commit-hooks', 'created_at': datetime.datetime(2024, 9, 14, 3, 25, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2351167355, 'issue_id': 2441882580, 'author': 'andormarkus', 'body': 'Hi @romsharon98\r\nAll checks are now passing.\r\n\r\nThanks,\r\nAndor', 'created_at': datetime.datetime(2024, 9, 14, 21, 42, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2373732178, 'issue_id': 2441882580, 'author': 'andormarkus', 'body': 'Hi @romsharon98 \r\n\r\nWhen is the helm chart  1.16.0 scheduled for release?\r\n\r\nThanks,\r\nAndor', 'created_at': datetime.datetime(2024, 9, 25, 10, 45, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2373801674, 'issue_id': 2441882580, 'author': 'romsharon98', 'body': '> Hi @romsharon98 \n> \n> \n> \n> When is the helm chart  1.16.0 scheduled for release?\n> \n> \n> \n> Thanks,\n> \n> Andor\n\nI think @jedcunningham will know better', 'created_at': datetime.datetime(2024, 9, 25, 11, 20, 19, tzinfo=datetime.timezone.utc)}]","andormarkus (Issue Creator) on (2024-08-01 10:02:00 UTC): Can someone help my why this test failing?
[https://github.com/apache/airflow/actions/runs/10195595534/job/28204650305?pr=41179](https://github.com/apache/airflow/actions/runs/10195595534/job/28204650305?pr=41179)

romsharon98 on (2024-08-02 09:01:59 UTC): rebase solved it ðŸ˜„

andormarkus (Issue Creator) on (2024-08-02 09:38:50 UTC): Hi @romsharon98 

I'm happy to add helm test for the modified ingress object, however the helm test framework is fully missing from the helm chart and we need to add the automated test runs to the CI/CD pipelines as well.

Helm testing [documentation](https://helm.sh/docs/topics/chart_tests/),

romsharon98 on (2024-08-02 09:59:37 UTC): You can add your tests [here](https://github.com/apache/airflow/blob/main/helm_tests/other/test_flower.py)
You can see more in [helm unit tests docs](https://github.com/apache/airflow/blob/main/contributing-docs/testing/helm_unit_tests.rst)

andormarkus (Issue Creator) on (2024-09-11 10:36:54 UTC): Hi @romsharon98 

Sorry for the late reply I was on extended vacation.

I have run into to a problem when I added the `""fullnameOverride"": ""test-basic""` it looks like the `chart/templates/_helpers.yaml` is not executed when I run the tests.

Here are my tests
`helm_tests/webserver/test_ingress_web.py`
```python
    def test_backend_service_name(self):
        docs = render_chart(
            values={""ingress"": {""web"": {""enabled"": True}}},
            show_only=[""templates/webserver/webserver-ingress.yaml""],
        )

        assert ""release-name-webserver"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])

    def test_backend_service_name_with_fullname_override(self):
        docs = render_chart(
            values={""fullnameOverride"": ""test-basic"",
                    ""ingress"": {""web"": {""enabled"": True}}},
            show_only=[""templates/webserver/webserver-ingress.yaml""],

        )

        assert ""test-basic-webserver"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])
```


`helm_tests/webserver/test_ingress_flower.py`

```python
    def test_backend_service_name(self):
        docs = render_chart(
            values={""ingress"": {""enabled"": True}, ""flower"": {""enabled"": True}},
            show_only=[""templates/flower/flower-ingress.yaml""],
        )

        assert ""release-name-flower"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])

    def test_backend_service_name_with_fullname_override(self):
        docs = render_chart(
            values={""fullnameOverride"": ""test-basic"",
                    ""ingress"": {""enabled"": True}, ""flower"": {""enabled"": True}},
            show_only=[""templates/flower/flower-ingress.yaml""],

        )

        assert ""test-basic-flower"" == jmespath.search(""spec.rules[0].http.paths[0].backend.service.name"", docs[0])

```


I run the test using the following command

```shell
 breeze testing helm-tests --helm-test-package webserver  
```

```shell
FAILED helm_tests/webserver/test_ingress_flower.py::TestIngressFlower::test_backend_service_name_with_fullname_override - AssertionError: assert equals failed
  'test-basic-flower'    'release-name-flower'
FAILED helm_tests/webserver/test_ingress_web.py::TestIngressWeb::test_backend_service_name_with_fullname_override - AssertionError: assert equals failed
  'test-basic-webserver'    'release-name-webserver'
```


```

romsharon98 on (2024-09-13 18:56:52 UTC): for this to be applied you need to set `useStandardNaming` to be `true`

andormarkus (Issue Creator) on (2024-09-13 21:23:24 UTC): Hi @romsharon98

Thank you so much the help. Now my tests are passing.
Please let me know If I need to more test of where to adjust the code?

Thanks,
Andor

romsharon98 on (2024-09-14 03:25:23 UTC): You have static checks fail.
Better work with pre commit to see those errors before you commit.

You can see how to install it here

https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#installing-pre-commit-hooks

andormarkus (Issue Creator) on (2024-09-14 21:42:01 UTC): Hi @romsharon98
All checks are now passing.

Thanks,
Andor

andormarkus (Issue Creator) on (2024-09-25 10:45:27 UTC): Hi @romsharon98 

When is the helm chart  1.16.0 scheduled for release?

Thanks,
Andor

romsharon98 on (2024-09-25 11:20:19 UTC): I think @jedcunningham will know better

"
2441866433,pull_request,closed,,Pass content of kube/config file to triggerer as a dictionary,"The idea of passing content of .kube/config file as a dictionary to Triggerer was introduced with the first implementation of deferrable mode in https://github.com/apache/airflow/pull/29017.
Later, due to security concerns related to storing the config file in trigger table this change was reverted.
With the following change https://github.com/apache/airflow/pull/38233 that concern has been mitigated and the change (of passing config as a map to the trigger) can be reapplied.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2024-08-01 08:50:24+00:00,[],2024-08-02 14:22:01+00:00,2024-08-02 14:22:01+00:00,https://github.com/apache/airflow/pull/41178,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2441846711,pull_request,closed,,Return string representation if XComArgs existing during resolving and include_xcom is set to False,"This is only used when trying to map an operator with start_from_trigger support

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-01 08:42:32+00:00,[],2024-08-01 13:38:10+00:00,2024-08-01 13:19:32+00:00,https://github.com/apache/airflow/pull/41177,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2441827956,pull_request,closed,,Bugfix and refactoring of failing and flaky system tests,"Fixed failing and flaky system tests:
1. bigquery_to_mssql
1. bigquery_to_postgres
1. cloud_compute
1. cloud_compute_igm
1. cloud_compute_ssh
2. cloud_compute_ssh_os_login
3. cloud_compute_ssh_parallel

Refactored system tests:
1. bigquery_to_mysql
2. cloudsql_query
3. cloudsql_query_ssl
4. dataprep
5. calendar_to_gcs
6. gcs_to_gdrive
7. gcs_to_sheets
8. gdrive_to_gcs_with_gdrive_sensor
9. mysql_to_gcs
10. sheets_gcs
11. sheets_to_gcs
12. sql_to_sheets
13. gdrive_to_local
14. postgres_to_gcs
15. google_analytics_admin
16. local_to_drive",moiseenkov,2024-08-01 08:34:07+00:00,[],2024-08-01 09:14:40+00:00,2024-08-01 09:14:39+00:00,https://github.com/apache/airflow/pull/41176,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:system-tests', '')]",[],
2441824387,pull_request,closed,,Skip cli tests from database isolation tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-01 08:32:18+00:00,[],2024-08-01 14:18:38+00:00,2024-08-01 14:18:36+00:00,https://github.com/apache/airflow/pull/41174,"[('area:CLI', '')]",[],
2441816169,pull_request,closed,,Fix 120 or so test_python tests in db_isolation mode,"Serialized dags are needed in a number of places where DB isolation mode needs to work. This one adds seialization to test_python tests to make them work.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-01 08:28:07+00:00,[],2024-08-01 12:49:29+00:00,2024-08-01 12:49:29+00:00,https://github.com/apache/airflow/pull/41173,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2441678362,pull_request,closed,,Install AWS CLI for docs build on self-hosted ASF runners,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-08-01 07:16:56+00:00,[],2024-08-01 14:19:00+00:00,2024-08-01 14:18:58+00:00,https://github.com/apache/airflow/pull/41168,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]",[],
2441336957,pull_request,closed,,fix(TriggeredDagRuns): fix wrong link in triggered dag run,"Currently, the link of triggered dag runs won't be able to link the created dag runs. It was due to that `__DAG_ID__` is not correctly replaced 

<img width=""1439"" alt=""Screenshot 2024-08-01 at 10 59 20â€¯AM"" src=""https://github.com/user-attachments/assets/0366a8d5-0145-46ea-befd-ad4c10ef988e"">
<img width=""1446"" alt=""åœ–ç‰‡"" src=""https://github.com/user-attachments/assets/e8d13fe6-0cc4-4574-9c0b-9350fca180b0"">


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-08-01 02:57:58+00:00,[],2024-08-01 05:35:34+00:00,2024-08-01 05:35:32+00:00,https://github.com/apache/airflow/pull/41166,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2262076056, 'issue_id': 2441336957, 'author': 'vatsrahul1001', 'body': '@Lee-W tested. LGTM !!', 'created_at': datetime.datetime(2024, 8, 1, 5, 33, 56, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 on (2024-08-01 05:33:56 UTC): @Lee-W tested. LGTM !!

"
2440432684,pull_request,closed,,feat: support polars serde,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

`polars` has an advantage over `pandas` when dealing with large amounts of data.
Serializing `polars` can be supported in much the same way as `pandas`. 

However, rather than supporting `polars` objects, it may be better to convert them to `pandas` objects.
A `polars` can be converted to a zero-copy `pandas` frame in the following way
```python
pd_frame = frame.to_pandas(use_pyarrow_extension_array=True)
```
(but, I have not verified that deserializing to a `pandas` object and then converting to a `polars` object is efficient.)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",phi-friday,2024-07-31 16:18:46+00:00,[],2024-08-01 01:24:33+00:00,2024-08-01 01:24:33+00:00,https://github.com/apache/airflow/pull/41161,"[('area:serialization', '')]",[],
2440186505,pull_request,closed,,Update providers metadata 2024-07-31,,eladkal,2024-07-31 14:20:36+00:00,[],2024-07-31 14:42:28+00:00,2024-07-31 14:42:25+00:00,https://github.com/apache/airflow/pull/41159,[],[],
2440110140,pull_request,closed,,Deprecate `SageMakerTrainingPrintLogTrigger`,"This trigger is supposed to do the same job as `SageMakerTrigger` but with printing logs. The reasons to deprecate it:
- Printing logs in a trigger does not add much value to the DAG author since logs go to the triggerer and not task logs
- The trigger `SageMakerTrainingPrintLogTrigger` contains some bugs since the operator `SageMakerTrainingOperator` does not work when created with `deferrable=True` and `print_log=True`. The trigger wait indefinitely for the job to complete
- Having two different triggers to achieve the same thing with the only difference one is pushing more logs than the other does not make a lot of sense

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-07-31 13:47:57+00:00,[],2024-07-31 16:59:05+00:00,2024-07-31 16:59:03+00:00,https://github.com/apache/airflow/pull/41158,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2440084513,pull_request,closed,,Skip tests in DB isolation mode in `tests/providers/amazon/aws/sensors/test_base_aws.py`,"Relates #41067

These tests expect deprecation warning which happens on the internal API side in DB isolation mode. No need to test that in DB isolation mode.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-07-31 13:36:41+00:00,[],2024-08-13 15:00:40+00:00,2024-07-31 15:51:18+00:00,https://github.com/apache/airflow/pull/41157,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2440065942,pull_request,closed,,Skip tests in DB isolation mode in `tests/providers/amazon/aws/operators/test_base_aws.py`,"Relates #41067

These tests expect deprecation warning which happens on the internal API side in DB isolation mode. No need to test that in DB isolation mode.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-07-31 13:28:09+00:00,[],2024-07-31 15:07:25+00:00,2024-07-31 15:07:23+00:00,https://github.com/apache/airflow/pull/41156,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2439981440,pull_request,closed,,fix cleaning xcom in defferal task,"closes: https://github.com/apache/airflow/issues/41098
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-07-31 12:49:13+00:00,[],2024-08-02 07:55:43+00:00,2024-08-02 07:55:43+00:00,https://github.com/apache/airflow/pull/41155,[],[],
2439937935,pull_request,closed,,Make task.run work with DB isolation,"This PR adds possibility to handle tests that perform task.run call in DB isolation mode. This call is treated specially - i.e. it will be possible for the run() method to use the DB directly. to set up the task but then when _run_raw_task below will use the DB, there will be an error raised.

That allows to fix the `test_core.py` and likely a number of other tests that rely on the run() method to run the tests.

This required to improve the _set_ti_attrs method to handle dag_run inside the task instance pydantic to task instance mapping - because we are actually using TaskInstance for those tests not TaskInstancePydantic under the hood.

Related: #41067

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-07-31 12:28:09+00:00,[],2024-08-01 10:25:05+00:00,2024-08-01 07:22:19+00:00,https://github.com/apache/airflow/pull/41154,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2261260376, 'issue_id': 2439937935, 'author': 'vincbeck', 'body': 'Good job working out these tests!', 'created_at': datetime.datetime(2024, 7, 31, 19, 21, 8, tzinfo=datetime.timezone.utc)}]","vincbeck on (2024-07-31 19:21:08 UTC): Good job working out these tests!

"
2439900950,pull_request,closed,,Publish Dataproc Serverless Batch link after it starts if batch_id was provided,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Currently the link to Dataproc Serverless Batch is only available after its successful execution.
To improve user experience publish a link right after the batch starts execution if `batch_id` was provided. It makes it easier to observe the progress and find batch logs when it fails.
The only drawback is that if batch creation fails before it starts execution, the link will point to nowhere, but I think it is acceptable considering the gains.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",rafalh,2024-07-31 12:12:17+00:00,[],2024-10-08 12:17:53+00:00,2024-10-04 20:49:09+00:00,https://github.com/apache/airflow/pull/41153,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2351239595, 'issue_id': 2439900950, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 9, 15, 0, 16, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2351240892, 'issue_id': 2439900950, 'author': 'rafalh', 'body': '> This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.\r\n\r\nPlease unstale. Hopefully in thousand years someone will look into it...', 'created_at': datetime.datetime(2024, 9, 15, 0, 18, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392668049, 'issue_id': 2439900950, 'author': 'eladkal', 'body': '@rafalh can you address comments and resolve conflicts?', 'created_at': datetime.datetime(2024, 10, 4, 2, 29, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2394097601, 'issue_id': 2439900950, 'author': 'rafalh', 'body': 'Sorry for the delay. I resolved the conflicts and I think it is ready for re-review.', 'created_at': datetime.datetime(2024, 10, 4, 16, 45, 53, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-09-15 00:16:19 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

rafalh (Issue Creator) on (2024-09-15 00:18:48 UTC): Please unstale. Hopefully in thousand years someone will look into it...

eladkal on (2024-10-04 02:29:26 UTC): @rafalh can you address comments and resolve conflicts?

rafalh (Issue Creator) on (2024-10-04 16:45:53 UTC): Sorry for the delay. I resolved the conflicts and I think it is ready for re-review.

"
2439748000,pull_request,closed,,docs(dataset): illustrate when dataset aliases are resolved,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-07-31 10:52:39+00:00,[],2024-08-01 10:25:29+00:00,2024-08-01 08:20:56+00:00,https://github.com/apache/airflow/pull/41152,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2439699459,pull_request,closed,,Fix: Pass hook parameters to SnowflakeSqlApiHook and prep them for APâ€¦,"This PR is a resolution to the given issue #39622. The main bug here was that the hook parameters were not properly given to the SnowflakeSqlAPIHook and then they were not properly assigned. The query execution method of the hook statically assigned configuration from Airflow connection. In this PR it is changed so that:
1. hook_params from SnowflakeSqlApiOperator object is passed into the hook object through unpacking the variable.
2. In SnowflakeSqlApiHook, for each of the parameter (database, role, schema, warehouse) there is a check performed for whether they were provided in the parameters (in their parent class SnowflakeHook, they are initialized to None, hence the if self.database|schema|role|warehouse) and if not, they are taken from connection definition.

closes: #39622 

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",BTeclaw,2024-07-31 10:28:14+00:00,[],2024-08-15 11:14:32+00:00,2024-08-15 11:14:27+00:00,https://github.com/apache/airflow/pull/41150,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]","[{'comment_id': 2260190154, 'issue_id': 2439699459, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 7, 31, 10, 28, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2265585287, 'issue_id': 2439699459, 'author': 'potiuk', 'body': 'Can you please add/modify a unit test for this?', 'created_at': datetime.datetime(2024, 8, 2, 14, 54, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2276982158, 'issue_id': 2439699459, 'author': 'eladkal', 'body': '@BTeclaw reminder about adding tests', 'created_at': datetime.datetime(2024, 8, 9, 1, 25, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2277724791, 'issue_id': 2439699459, 'author': 'BTeclaw', 'body': ""Pushed unit test for parametrization of the API call, haven't really written any unit tests like that before so feedback is welcome! Thanks"", 'created_at': datetime.datetime(2024, 8, 9, 11, 19, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291058816, 'issue_id': 2439699459, 'author': 'BTeclaw', 'body': '@Lee-W applied suggested changes - thank you!', 'created_at': datetime.datetime(2024, 8, 15, 10, 47, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2291091372, 'issue_id': 2439699459, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 15, 11, 14, 31, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-07-31 10:28:18 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-08-02 14:54:18 UTC): Can you please add/modify a unit test for this?

eladkal on (2024-08-09 01:25:43 UTC): @BTeclaw reminder about adding tests

BTeclaw (Issue Creator) on (2024-08-09 11:19:37 UTC): Pushed unit test for parametrization of the API call, haven't really written any unit tests like that before so feedback is welcome! Thanks

BTeclaw (Issue Creator) on (2024-08-15 10:47:05 UTC): @Lee-W applied suggested changes - thank you!

boring-cyborg[bot] on (2024-08-15 11:14:31 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2439648787,pull_request,closed,,Bugfix query count statistics when parsing DAG file,"This PR fixes a bug in counting queries during a DAG file parsing (the feature was implemented in #40323).

A context manager `count_queries` was implemented previously, and it is responsible for counting queries within its scope. The reason why it was missing some queries and misreporting statistics is that its scope wasn't covering all steps of parsing the DAG file. This PR moves a `count_queries` invocation higher to the level of `DagFileProcessor.process_file()` method, which ensures that all the queries are counted.

Relates to: #40916",moiseenkov,2024-07-31 10:02:58+00:00,[],2024-08-06 09:51:37+00:00,2024-08-02 07:58:32+00:00,https://github.com/apache/airflow/pull/41149,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2262782583, 'issue_id': 2439648787, 'author': 'moiseenkov', 'body': '@jedcunningham , @ephraimbuddy , @potiuk , hi,\r\nCould you please take a look at this PR?', 'created_at': datetime.datetime(2024, 8, 1, 11, 14, 27, tzinfo=datetime.timezone.utc)}]","moiseenkov (Issue Creator) on (2024-08-01 11:14:27 UTC): @jedcunningham , @ephraimbuddy , @potiuk , hi,
Could you please take a look at this PR?

"
2438837449,pull_request,closed,,Field Deletion Warning when editing Connections,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The issue mentions that fields backed by the BS3TextFieldWidget cannot be deleted once populated. To delete those fields, the user must delete the connection and create a new one. The ""Changed Row"" message displayed after a row is edited is misleading. 

Therefore, as a temporary fix, I have created a warning that always shows when the user is editing a connection form as shown below. 

![image](https://github.com/user-attachments/assets/0fcbbb58-6841-4783-aaf4-bb65c3002759)

What I tried to do was get the specific fields that were populated and issue a warning with those field names when the user tries to delete them. However, I'm having trouble figuring out how to do that check when the user clicks the 'Save' button. So, I have a warning of the currently populated fields that can be modified but not deleted after the user clicks 'Save' shown below. 

![image](https://github.com/user-attachments/assets/26497d9d-0449-4eb6-959a-b184cb6d61cf)

related: #40105 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",lh5844,2024-07-30 23:37:03+00:00,[],2024-08-30 11:54:14+00:00,2024-08-14 16:05:05+00:00,https://github.com/apache/airflow/pull/41144,"[('area:webserver', 'Webserver related Issues'), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2260802817, 'issue_id': 2438837449, 'author': 'RNHTTR', 'body': '@lh5844 can you also add a unit test please?', 'created_at': datetime.datetime(2024, 7, 31, 15, 31, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2261061043, 'issue_id': 2438837449, 'author': 'lh5844', 'body': ""> @lh5844 can you also add a unit test please?\r\n\r\nBecause I've kept the general warning and that change is made in the connection_form.js, there don't seem to be any unit tests for any javascript files. So, I'll leave it at that. Correct if I'm wrong though"", 'created_at': datetime.datetime(2024, 7, 31, 17, 57, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2284270891, 'issue_id': 2438837449, 'author': 'bbovenzi', 'body': 'One last comment. Otherwise lgtm!', 'created_at': datetime.datetime(2024, 8, 12, 15, 22, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287529830, 'issue_id': 2438837449, 'author': 'lh5844', 'body': 'Thank you for your suggestion! It definitely made it more concise. With that, it should be ready to be merged!', 'created_at': datetime.datetime(2024, 8, 14, 0, 35, 54, tzinfo=datetime.timezone.utc)}]","RNHTTR on (2024-07-31 15:31:58 UTC): @lh5844 can you also add a unit test please?

lh5844 (Issue Creator) on (2024-07-31 17:57:51 UTC): Because I've kept the general warning and that change is made in the connection_form.js, there don't seem to be any unit tests for any javascript files. So, I'll leave it at that. Correct if I'm wrong though

bbovenzi on (2024-08-12 15:22:08 UTC): One last comment. Otherwise lgtm!

lh5844 (Issue Creator) on (2024-08-14 00:35:54 UTC): Thank you for your suggestion! It definitely made it more concise. With that, it should be ready to be merged!

"
2438807359,pull_request,closed,,Fix Manager Tests for Dataset Isolation Mode,"Relates https://github.com/apache/airflow/pull/41067

Fixed Datasets Manager for DB Isolation.

Needed to add skip for two tests - in my view they are not called via API and are just internal.
Needed to switch to Pydantic data class instead of Mock to have a proper API serialization",jscheffl,2024-07-30 22:59:26+00:00,[],2024-07-31 07:53:29+00:00,2024-07-31 07:53:29+00:00,https://github.com/apache/airflow/pull/41143,[],[],
2438803167,pull_request,closed,,Export Azure Container Instance log messages to XCOM,"This commit adds the capability to export log messages into XCOM on an optional basis. The existing behavior (no logs) is retained as the default making this an opt-in feature. Users of the operator can retrieve either all logs or only the last log message. In either case, the log messsages are presented as a list

The bash and docker operators, among others, can export logs into XCOM to provide some feedback about the outcome of the command in the results. The AzureContainerInstancesOperator just detects if the container exits cleanly and exits with either 0 (success) or 1 (failure). This commit adds the ability to put either the last log message or all log messages into XCOM under the key 'logs' so it can be used in future operators to decide if it the operation within the container failed or succeeded.",perry2of5,2024-07-30 22:55:42+00:00,[],2024-10-09 16:12:29+00:00,2024-08-14 10:46:07+00:00,https://github.com/apache/airflow/pull/41142,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2259336139, 'issue_id': 2438803167, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better ðŸš€.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 7, 30, 22, 55, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287445773, 'issue_id': 2438803167, 'author': 'potiuk', 'body': 'static checks failing', 'created_at': datetime.datetime(2024, 8, 14, 0, 1, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287479001, 'issue_id': 2438803167, 'author': 'perry2of5', 'body': 'Thanks. Iâ€™ll look.', 'created_at': datetime.datetime(2024, 8, 14, 0, 20, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2287669521, 'issue_id': 2438803167, 'author': 'perry2of5', 'body': 'I believe I have fixed the issues from my code (currently re-running breeze static-checks), but when I run ""breeze static-checks --all-files"" it complains about a file I didn\'t change:\r\nairflow/providers/fab/auth_manager/cli_commands/user_command.py\r\n\r\nShould I ignore this?', 'created_at': datetime.datetime(2024, 8, 14, 1, 40, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288426429, 'issue_id': 2438803167, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 8, 14, 10, 46, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2288427681, 'issue_id': 2438803167, 'author': 'potiuk', 'body': '> I believe I have fixed the issues from my code (currently re-running breeze static-checks), but when I run ""breeze static-checks --all-files"" it complains about a file I didn\'t change:\r\nairflow/providers/fab/auth_manager/cli_commands/user_command.py\r\n\r\nIt was likely due to not rebased/rebuilt image with latest changes. Main succeeded, so all looks good.', 'created_at': datetime.datetime(2024, 8, 14, 10, 46, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289202164, 'issue_id': 2438803167, 'author': 'perry2of5', 'body': 'Thank you, @potiuk!', 'created_at': datetime.datetime(2024, 8, 14, 16, 4, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289818989, 'issue_id': 2438803167, 'author': 'perry2of5', 'body': ""I get the static-checks issue with a fresh checkout of main from the official repo. Is this likely to be a problem on my breeze install? An issue with the breeze config checked into the project? or an actual issue on main? I'm assuming it is one of the first two."", 'created_at': datetime.datetime(2024, 8, 14, 20, 30, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2289834280, 'issue_id': 2438803167, 'author': 'potiuk', 'body': 'no idea. Generally the system is designed to be consistent when you a) rebase, b) build the image when asked . This is what CI check does a) checks out the latest version b) builds the latest image c) uses the latest image to run the tests. If any of the steps are missing or delayed, the end results might differ. So if you are in doubt - ABR - Always Be Rebased.\r\n\r\n1) rebased\r\n2) breeze ci-image build \r\n3) run your tests\r\n\r\nThat should yield same results as CI build - but of course there are race conditions - someone could have pushed another change between the steps manually run. So again - if in doubt\r\n\r\n1) rebase\r\n2) build image\r\n3) run your tests\r\n\r\n\r\nAirflow has high traffic, things are chaning on hourly base ... so rebase, rebuild test is a recommended way.', 'created_at': datetime.datetime(2024, 8, 14, 20, 38, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402145908, 'issue_id': 2438803167, 'author': 'roman-doubrava', 'body': '@perry2of5 & @potiuk would it be possible to additionally enhace the AzureContainerInstancesOperator with the :param do_xcom_push: If True, the content of the file /airflow/xcom/return.json in the container will also be pushed to an XCom when the container completes, which would be similar behavior to the KubernetesPODOperator ?', 'created_at': datetime.datetime(2024, 10, 9, 12, 10, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2402753331, 'issue_id': 2438803167, 'author': 'perry2of5', 'body': ""That seems possible. I'm not sure if it is an optimal idea. Perhaps it would be better to push the file into some sort of store and return the location in a message and retrieve it that way? If you open an issue then you could get feedback on the idea. I doubt you'll get many people considering the idea in a closed PR. If you open an issue, feel free to tag me and I'll think about it more.\nMessage ID: ***@***.***>"", 'created_at': datetime.datetime(2024, 10, 9, 16, 12, 27, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-07-30 22:55:46 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better ðŸš€.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-08-14 00:01:51 UTC): static checks failing

perry2of5 (Issue Creator) on (2024-08-14 00:20:03 UTC): Thanks. Iâ€™ll look.

perry2of5 (Issue Creator) on (2024-08-14 01:40:39 UTC): I believe I have fixed the issues from my code (currently re-running breeze static-checks), but when I run ""breeze static-checks --all-files"" it complains about a file I didn't change:
airflow/providers/fab/auth_manager/cli_commands/user_command.py

Should I ignore this?

boring-cyborg[bot] on (2024-08-14 10:46:10 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-08-14 10:46:54 UTC): airflow/providers/fab/auth_manager/cli_commands/user_command.py

It was likely due to not rebased/rebuilt image with latest changes. Main succeeded, so all looks good.

perry2of5 (Issue Creator) on (2024-08-14 16:04:01 UTC): Thank you, @potiuk!

perry2of5 (Issue Creator) on (2024-08-14 20:30:14 UTC): I get the static-checks issue with a fresh checkout of main from the official repo. Is this likely to be a problem on my breeze install? An issue with the breeze config checked into the project? or an actual issue on main? I'm assuming it is one of the first two.

potiuk on (2024-08-14 20:38:31 UTC): no idea. Generally the system is designed to be consistent when you a) rebase, b) build the image when asked . This is what CI check does a) checks out the latest version b) builds the latest image c) uses the latest image to run the tests. If any of the steps are missing or delayed, the end results might differ. So if you are in doubt - ABR - Always Be Rebased.

1) rebased
2) breeze ci-image build 
3) run your tests

That should yield same results as CI build - but of course there are race conditions - someone could have pushed another change between the steps manually run. So again - if in doubt

1) rebase
2) build image
3) run your tests


Airflow has high traffic, things are chaning on hourly base ... so rebase, rebuild test is a recommended way.

roman-doubrava on (2024-10-09 12:10:57 UTC): @perry2of5 & @potiuk would it be possible to additionally enhace the AzureContainerInstancesOperator with the :param do_xcom_push: If True, the content of the file /airflow/xcom/return.json in the container will also be pushed to an XCom when the container completes, which would be similar behavior to the KubernetesPODOperator ?

perry2of5 (Issue Creator) on (2024-10-09 16:12:27 UTC): That seems possible. I'm not sure if it is an optimal idea. Perhaps it would be better to push the file into some sort of store and return the location in a message and retrieve it that way? If you open an issue then you could get feedback on the idea. I doubt you'll get many people considering the idea in a closed PR. If you open an issue, feel free to tag me and I'll think about it more.
Message ID: ***@***.***>

"
