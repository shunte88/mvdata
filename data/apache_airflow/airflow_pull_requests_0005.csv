id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2678915609,pull_request,closed,,docs(newsfragment): these deprecated things are functions instead of arguments,"## Why

the mentioned things are functions instead of arguments

## What
reword

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-21 10:27:55+00:00,[],2024-11-21 13:36:22+00:00,2024-11-21 13:36:20+00:00,https://github.com/apache/airflow/pull/44242,[],[],
2678826386,pull_request,closed,,"AIP 72: Handling ""deferrable"" tasks in execution_api and task SDK","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44137

This PR is trying to port the ""deferral"" logic from airflow 2 to the airflow 3 (execution api + task sdk)

## Summary of changes:

### Server side changes (execution api):
1. Handling `TIDeferredStatePayload` in `ti_update_state` -> covered by unit test: `test_ti_update_state_to_deferred`
      a. Didn't piggy back on `ti.defer_task()` as it extracts the trigger out of `TaskDeferred` exception. It is much more expensive to send across multiple models like `TaskInstance`, `TaskDeferred`, `Trigger` instead of just the required minimal properties
      b. `returning` and not proceeding with query execution as we already do it above https://github.com/apache/airflow/pull/44241/files#diff-d44a72566870079ee943e24bac2af74fb84c426c54d210561a251549a7078ed7L129
2. Defining a datamodel for TIDeferredStatePayload and adding it to the discriminator: ti_state_discriminator

### Client side changes (task sdk):

#### HTTP client:
Added a new function defer that sends a patch request to the `task-instances/{id}/state execution` api with payload: `PatchTIToDeferred`

#### Comms:
Defining a new data model to send a request to patch ti as ""deferred"" from task runner to supervisor: `PatchTIToDeferred`  (Added to ToSupervisor)

#### Supervisor:
1. Adding a new class property as `_final_state` to support `@property` `final_state` which is final state of a TI
      a. Added a setter to set values for this final state for cases like deferred so that the finish is not called for tasks those aren't in terminal stage: https://github.com/apache/airflow/pull/44241/files#diff-c2651fdee1a25e091e2a9d4f937f8032ca3d289d0de76f38ed88aee5df0f880dL392-L394
2. Deferred tasks first enter the ""wait"" in supervisor and then mark themselves as deferred by setting up a trigger. So skipping `finish()` when `final_state` is not `TerminalTIState` 
3. Extended `handle_requests` to receive requests from task runner and forwarding the message to http client to call defer

#### TaskRunner:
Task runner executes: ti.task.execute and raises `TaskDeferred` for deferral. This sends a request to supervisor using `SUPERVISOR_COMMS`


## How was this tested?
1. The end to end flow isn't available as of now, but I have tried to cover up the ground using unit tests
2. New case under `test_handle_requests` covers the supervisor + client side of things along with a mock of the message from task runner
3. `test_ti_update_state_to_deferred` covers the scenario for execution API
4. Added an integration test for task runner component:
- It creates a DAG that raises the deferral exception:
![image](https://github.com/user-attachments/assets/871fdfd1-034d-4b66-a25a-0981a47f860c)
- `test_run_deferred_basic` tests if the DAG raised a task exception and sent the right message across the SUPERVISOR_COMMS or not.


## Additional sanity tests
### Testing the ""task runner"" entries and exits (client side)

1. Wrote a async operator DAG:
![image](https://github.com/user-attachments/assets/425ec4e8-3695-4695-894b-d21c84d47ff1)

2. Breakpoint inside task_runner.py#run

3. Validated the exception entrypoint with all the variables to be set as required by running the test: `test_run_basic`
![image](https://github.com/user-attachments/assets/afdaa611-7350-45b5-9d4b-282a7a71d5dc)


### Testing the DB state in the server side (execution API)
1. Used the test: `test_ti_update_state_to_deferred`

2. Debugger inside `ti_update_state` method

3. Validated the `TaskDeferred` and related logic
![image](https://github.com/user-attachments/assets/9fb7d632-4bc1-439c-a0b8-7143a751e01a)

5. Checked state of the DB on execution
![image](https://github.com/user-attachments/assets/6fbde3e2-734b-43c2-8a02-464f401760b7)

![image](https://github.com/user-attachments/assets/5249dae5-cb81-45a2-a761-ff2437c6fed5)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-21 09:59:32+00:00,['amoghrajesh'],2024-11-27 15:07:39+00:00,2024-11-27 15:07:37+00:00,https://github.com/apache/airflow/pull/44241,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]","[{'comment_id': 2503392807, 'issue_id': 2678826386, 'author': 'amoghrajesh', 'body': '@kaxil I wrote a new integration test that tests out the deferred exception functionality in task runner as well as tests the message sent across to the SUPERVISOR_COMMS through the `send_request` function\r\n\r\nIn this commit: https://github.com/apache/airflow/commit/dc39226f6659c36db83322bfed75faba274ee32a', 'created_at': datetime.datetime(2024, 11, 27, 9, 40, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503804138, 'issue_id': 2678826386, 'author': 'kaxil', 'body': 'Squashed commits into 1 and resolved conflicts.\r\n\r\nDoing one final pass now', 'created_at': datetime.datetime(2024, 11, 27, 12, 52, 45, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-27 09:40:44 UTC): @kaxil I wrote a new integration test that tests out the deferred exception functionality in task runner as well as tests the message sent across to the SUPERVISOR_COMMS through the `send_request` function

In this commit: https://github.com/apache/airflow/commit/dc39226f6659c36db83322bfed75faba274ee32a

kaxil on (2024-11-27 12:52:45 UTC): Squashed commits into 1 and resolved conflicts.

Doing one final pass now

"
2678791134,pull_request,closed,,Fix AttributeError: '_thread._local' object has no attribute 'callers' in ExecutorSafeguard,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#42572](https://github.com/apache/airflow/pull/42572)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

When executing PythonOperators using our in-house [StreamedOperator](https://github.com/apache/airflow/pull/42572) in a multi threaded way we discovered we have sometimes random failures due to ""AttributeError: '_thread._local' object has no attribute 'callers' in ExecutorSafeguard"" errors.  This MR fixes this issue., unfortunately I couldn't write a test to reproduce it as this is a concurrency issue.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-21 09:46:21+00:00,[],2024-12-03 09:12:51+00:00,2024-12-03 09:11:50+00:00,https://github.com/apache/airflow/pull/44240,[],"[{'comment_id': 2505171422, 'issue_id': 2678791134, 'author': 'potiuk', 'body': 'What was the stactrace of such issue @dabla -> I have a hard time to figure out what race/parallelism could have caused it.', 'created_at': datetime.datetime(2024, 11, 28, 2, 59, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505710114, 'issue_id': 2678791134, 'author': 'dabla', 'body': ""> What was the stactrace of such issue @dabla -> I have a hard time to figure out what race/parallelism could have caused it.\r\n\r\nDon't know if I still have the stacktrace, I'm afraid not, but the error was the one from the title, namely AttributeError: '_thread._local' object has no attribute 'callers' in ExecutorSafeguard.  But as I explained, we only have this error because we are doing mulithreading (not multiprocessing as this isn't possible due to the fact that tasks are already executed in dedicated processes within the worker) using our inhouse StreamedOperator instead of expand for some DAG's, I'm quite certain (but cannot back this of course) when using Airflow with regular operators and expand that you won't encounter this issue. I was also a bit surprised to encounter this as you would expect that the thread local would be initialised anyway as it was written originally.  Or maybe this is a bug in the Python 3.9 implementation of threadlocal?"", 'created_at': datetime.datetime(2024, 11, 28, 9, 59, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506047950, 'issue_id': 2678791134, 'author': 'potiuk', 'body': '> > What was the stactrace of such issue @dabla -> I have a hard time to figure out what race/parallelism could have caused it.\r\n> \r\n> Or maybe this is a bug in the Python 3.9 implementation of threadlocal?\r\n\r\nYeah. that why I wanted to see stacktrace, because I cannot find a path where you would have missing attribute - when I compare ""before"" and ""after"" the change i cannot see anything that could have fixed that problem, other than slightly bigger overhead of executing the method, which could have mitigitated some race condition, having such a stack trace would definitely help us to see the root cause. I am pretty reluctant to approve and merge change that I do not understand how it works :).', 'created_at': datetime.datetime(2024, 11, 28, 12, 50, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506400146, 'issue_id': 2678791134, 'author': 'dabla', 'body': '> > > What was the stactrace of such issue @dabla -> I have a hard time to figure out what race/parallelism could have caused it.\r\n> > \r\n> > \r\n> > Or maybe this is a bug in the Python 3.9 implementation of threadlocal?\r\n> \r\n> Yeah. that why I wanted to see stacktrace, because I cannot find a path where you would have missing attribute - when I compare ""before"" and ""after"" the change i cannot see anything that could have fixed that problem, other than slightly bigger overhead of executing the method, which could have mitigitated some race condition, having such a stack trace would definitely help us to see the root cause. I am pretty reluctant to approve and merge change that I do not understand how it works :).\r\n\r\nYes, I completely understand, me personally I also don\'t understand why the ""\'fix"" fixes this issue as I wouldn\'t have expected this behaviour.  Here you, I\'ve re-executed the DAG without the patched ExecutorSafeguard:\r\n\r\n```\r\n[2024-11-28, 15:43:59 UTC] {taskinstance.py:3311} ERROR - Task failed with exception\r\nTraceback (most recent call last):\r\n  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/taskinstance.py"", line 767, in _execute_task\r\n    result = _execute_callable(context=context, **execute_callable_kwargs)\r\n  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/taskinstance.py"", line 733, in _execute_callable\r\n    return ExecutionCallableRunner(\r\n  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/utils/operator_helpers.py"", line 252, in run\r\n    return self.func(*args, **kwargs)\r\n  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/baseoperator.py"", line 417, in wrapper\r\n    return func(self, *args, **kwargs)\r\n  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 424, in execute\r\n    self.max_active_tis_per_dag,\r\n  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 346, in _run_tasks\r\n    for task, future in futures:\r\n  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 771, in get\r\n    raise self._value\r\n  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 125, in worker\r\n    result = (True, func(*args, **kwds))\r\n  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 325, in _run_task\r\n    )  # Always open new event loop as this is executed in multithreaded\r\n  File ""/usr/local/lib/python3.9/asyncio/base_events.py"", line 647, in run_until_complete\r\n    return future.result()\r\n  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 392, in _run_operator\r\n    operator: BaseOperator = cast(BaseOperator, task_instance.task)\r\n  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 219, in run\r\n    return await wait_for(\r\n  File ""/usr/local/lib/python3.9/asyncio/tasks.py"", line 479, in wait_for\r\n    return fut.result()\r\n  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 169, in _run_callable\r\n    return callable_runner.run(*args, **kwargs)\r\n  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/utils/operator_helpers.py"", line 252, in run\r\n    return self.func(*args, **kwargs)\r\n  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/baseoperator.py"", line 410, in wrapper\r\n    sentinel = cls._sentinel.callers.pop(f""{func.__qualname__.split(\'.\')[0]}__sentinel"", None)\r\nAttributeError: \'_thread._local\' object has no attribute \'callers\'\r\n```', 'created_at': datetime.datetime(2024, 11, 28, 15, 45, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506622478, 'issue_id': 2678791134, 'author': 'potiuk', 'body': 'Which version of Airflow the stacktrace was from @dabla ?', 'created_at': datetime.datetime(2024, 11, 28, 18, 23, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507195074, 'issue_id': 2678791134, 'author': 'dabla', 'body': '> Which version of Airflow the stacktrace was from @dabla ?\r\n\r\nIt was on 2.10.3', 'created_at': datetime.datetime(2024, 11, 29, 6, 55, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513949360, 'issue_id': 2678791134, 'author': 'dabla', 'body': ""I've close this PR, as this is a side effect of using the [StreamedOperator](https://github.com/apache/airflow/pull/42572), which isn't available in Airflow and is still a proof-of-concept."", 'created_at': datetime.datetime(2024, 12, 3, 9, 12, 50, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-28 02:59:11 UTC): What was the stactrace of such issue @dabla -> I have a hard time to figure out what race/parallelism could have caused it.

dabla (Issue Creator) on (2024-11-28 09:59:47 UTC): Don't know if I still have the stacktrace, I'm afraid not, but the error was the one from the title, namely AttributeError: '_thread._local' object has no attribute 'callers' in ExecutorSafeguard.  But as I explained, we only have this error because we are doing mulithreading (not multiprocessing as this isn't possible due to the fact that tasks are already executed in dedicated processes within the worker) using our inhouse StreamedOperator instead of expand for some DAG's, I'm quite certain (but cannot back this of course) when using Airflow with regular operators and expand that you won't encounter this issue. I was also a bit surprised to encounter this as you would expect that the thread local would be initialised anyway as it was written originally.  Or maybe this is a bug in the Python 3.9 implementation of threadlocal?

potiuk on (2024-11-28 12:50:31 UTC): Yeah. that why I wanted to see stacktrace, because I cannot find a path where you would have missing attribute - when I compare ""before"" and ""after"" the change i cannot see anything that could have fixed that problem, other than slightly bigger overhead of executing the method, which could have mitigitated some race condition, having such a stack trace would definitely help us to see the root cause. I am pretty reluctant to approve and merge change that I do not understand how it works :).

dabla (Issue Creator) on (2024-11-28 15:45:35 UTC): Yes, I completely understand, me personally I also don't understand why the ""'fix"" fixes this issue as I wouldn't have expected this behaviour.  Here you, I've re-executed the DAG without the patched ExecutorSafeguard:

```
[2024-11-28, 15:43:59 UTC] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/taskinstance.py"", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/taskinstance.py"", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/baseoperator.py"", line 417, in wrapper
    return func(self, *args, **kwargs)
  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 424, in execute
    self.max_active_tis_per_dag,
  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 346, in _run_tasks
    for task, future in futures:
  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 771, in get
    raise self._value
  File ""/usr/local/lib/python3.9/multiprocessing/pool.py"", line 125, in worker
    result = (True, func(*args, **kwds))
  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 325, in _run_task
    )  # Always open new event loop as this is executed in multithreaded
  File ""/usr/local/lib/python3.9/asyncio/base_events.py"", line 647, in run_until_complete
    return future.result()
  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 392, in _run_operator
    operator: BaseOperator = cast(BaseOperator, task_instance.task)
  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 219, in run
    return await wait_for(
  File ""/usr/local/lib/python3.9/asyncio/tasks.py"", line 479, in wait_for
    return fut.result()
  File ""/airflow/plugins/infrabel/operators/streamedoperator.py"", line 169, in _run_callable
    return callable_runner.run(*args, **kwargs)
  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
  File ""/airflow/.venv/lib/python3.9/site-packages/airflow/models/baseoperator.py"", line 410, in wrapper
    sentinel = cls._sentinel.callers.pop(f""{func.__qualname__.split('.')[0]}__sentinel"", None)
AttributeError: '_thread._local' object has no attribute 'callers'
```

potiuk on (2024-11-28 18:23:19 UTC): Which version of Airflow the stacktrace was from @dabla ?

dabla (Issue Creator) on (2024-11-29 06:55:28 UTC): It was on 2.10.3

dabla (Issue Creator) on (2024-12-03 09:12:50 UTC): I've close this PR, as this is a side effect of using the [StreamedOperator](https://github.com/apache/airflow/pull/42572), which isn't available in Airflow and is still a proof-of-concept.

"
2678738531,pull_request,closed,,make paginated_select kw-only,"This PR makes `paginated_select` method to have keyword only arguments. Also, renames `base_select` argument to `select`",rawwar,2024-11-21 09:35:20+00:00,[],2024-11-21 13:55:11+00:00,2024-11-21 13:54:41+00:00,https://github.com/apache/airflow/pull/44239,"[('AIP-84', 'Modern Rest API')]",[],
2678661390,pull_request,closed,,AIP-84: Migrate get_log endpoint,Related: https://github.com/apache/airflow/issues/42370,utkarsharma2,2024-11-21 09:14:53+00:00,[],2024-11-22 10:51:06+00:00,2024-11-22 10:51:04+00:00,https://github.com/apache/airflow/pull/44238,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2678423402,pull_request,closed,,AIP-84 Invalid states raises 422 status on get dag_runs and task_instances endpoints,closes #44235,rawwar,2024-11-21 07:45:13+00:00,[],2024-11-21 09:57:38+00:00,2024-11-21 09:54:47+00:00,https://github.com/apache/airflow/pull/44237,[],"[{'comment_id': 2490619797, 'issue_id': 2678423402, 'author': 'rawwar', 'body': '> We should probably directly use the state Enum at some point. (That\'s on my todo list for any enum params/ payload attr.)\r\n\r\nI tried that. But, since ""none"" isn\'t part of the States, that caused issue for me. Or maybe I did something wrong. Looking forward to see how its implemented', 'created_at': datetime.datetime(2024, 11, 21, 9, 56, 30, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-21 09:56:30 UTC): I tried that. But, since ""none"" isn't part of the States, that caused issue for me. Or maybe I did something wrong. Looking forward to see how its implemented

"
2678304620,pull_request,closed,,Rename max_execution_date ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
- Rename `execution_date` as part of config.yaml to `logical_date`
- Rename `max_execution_date` to `max_logical_date`.

related: [#42338](https://github.com/apache/airflow/issues/42338)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sunank200,2024-11-21 07:04:05+00:00,[],2024-11-25 05:35:13+00:00,2024-11-21 09:20:23+00:00,https://github.com/apache/airflow/pull/44236,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('AIP-83', 'Remove Execution Date Unique Constraint from DAG Run')]",[],
2677915752,pull_request,closed,,Fixing static check due to faulty entry in openapi spec,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fixing CI failure on https://github.com/apache/airflow/actions/runs/11945173632/job/33297606334. 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-21 04:24:08+00:00,[],2024-11-21 16:11:23+00:00,2024-11-21 16:11:23+00:00,https://github.com/apache/airflow/pull/44233,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2490090065, 'issue_id': 2677915752, 'author': 'amoghrajesh', 'body': 'Looks like the original one is the correct one', 'created_at': datetime.datetime(2024, 11, 21, 5, 6, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491517229, 'issue_id': 2677915752, 'author': 'bbovenzi', 'body': 'These are autogenerated files. Is this a manual change or is it fixing an accidental manual change?', 'created_at': datetime.datetime(2024, 11, 21, 15, 19, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491546420, 'issue_id': 2677915752, 'author': 'gopidesupavan', 'body': 'Hope this change is not required, it looks like the side effect of pydantic version issue?\r\n\r\nThis is fine now, https://github.com/apache/airflow/pull/44249', 'created_at': datetime.datetime(2024, 11, 21, 15, 30, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491559907, 'issue_id': 2677915752, 'author': 'pierrejeambrun', 'body': '> Hope this change is not required, it looks like the side effect of pydantic version issue?\r\n\r\nI think too. Can we close this one in favor of https://github.com/apache/airflow/pull/44249 ?', 'created_at': datetime.datetime(2024, 11, 21, 15, 35, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491664214, 'issue_id': 2677915752, 'author': 'amoghrajesh', 'body': 'Yep it is due to the underlying pydantic bug fixed by https://github.com/apache/airflow/pull/44249. Closing this one', 'created_at': datetime.datetime(2024, 11, 21, 16, 11, 23, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-21 05:06:56 UTC): Looks like the original one is the correct one

bbovenzi on (2024-11-21 15:19:37 UTC): These are autogenerated files. Is this a manual change or is it fixing an accidental manual change?

gopidesupavan on (2024-11-21 15:30:15 UTC): Hope this change is not required, it looks like the side effect of pydantic version issue?

This is fine now, https://github.com/apache/airflow/pull/44249

pierrejeambrun on (2024-11-21 15:35:03 UTC): I think too. Can we close this one in favor of https://github.com/apache/airflow/pull/44249 ?

amoghrajesh (Issue Creator) on (2024-11-21 16:11:23 UTC): Yep it is due to the underlying pydantic bug fixed by https://github.com/apache/airflow/pull/44249. Closing this one

"
2677689121,pull_request,closed,,AIP-72: Add support for fetching variables and connections in Supervisor,"- Updated `VariableOperations` and `ConnectionOperations` in `Client`:
  - Added `get` methods for fetching variable and connection details.
- Refactored communication protocol (`comms.py`):
  - Unified result models (`ConnectionResult`, `VariableResult`, `XComResult`) extending auto-generated models.
  - Renamed `ReadXCom` to `GetXCom` for consistency with other request models (`GetConnection`, `GetVariable`).
- Updated `WatchedSubprocess` in `supervisor.py`:
  - Integrated `handle_requests` to process `GetVariable` and `GetConnection` messages.

and some minor refactors -- check inline comments

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-21 01:39:00+00:00,[],2024-11-21 17:26:26+00:00,2024-11-21 17:26:23+00:00,https://github.com/apache/airflow/pull/44229,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2677211744,pull_request,closed,,Remove `/webapp` prefix from new UI,"Don't think we need this under the `/webapp` prefix, so lets move it to `/`.",jedcunningham,2024-11-20 21:19:59+00:00,[],2024-11-21 14:37:02+00:00,2024-11-21 14:12:16+00:00,https://github.com/apache/airflow/pull/44227,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2491342623, 'issue_id': 2677211744, 'author': 'kaxil', 'body': 'This got merged but tests are failing @bbovenzi', 'created_at': datetime.datetime(2024, 11, 21, 14, 20, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491399816, 'issue_id': 2677211744, 'author': 'jedcunningham', 'body': ""Revert here, won't be quick to fix the tests :) #44251"", 'created_at': datetime.datetime(2024, 11, 21, 14, 37, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-21 14:20:17 UTC): This got merged but tests are failing @bbovenzi

jedcunningham (Issue Creator) on (2024-11-21 14:37:00 UTC): Revert here, won't be quick to fix the tests :) #44251

"
2677144787,pull_request,closed,,Make filters param optional and fix typing,"Given that sometimes we don't want to apply any filters, it makes sense to make the param optional.  I also fix the typing on `paginated_select`.
",dstandish,2024-11-20 20:40:17+00:00,[],2024-11-21 21:10:24+00:00,2024-11-21 21:10:23+00:00,https://github.com/apache/airflow/pull/44226,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2677024737,pull_request,closed,,Fix incorrect query in `BigQueryAsyncHook.create_job_for_partition_get`,"  * The table ID column in [`INFORMATION_SCHEMA.PARTITIONS`](https://cloud.google.com/bigquery/docs/information-schema-partitions#schema) is named `table_name`, not `table_id` (currently when these queries run they fail with the error ""_Unrecognized name: table_id_"").
  * The table ID string value needs to be quoted in the SQL.

related: #37655

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sean-rose,2024-11-20 19:58:02+00:00,[],2024-11-22 23:43:02+00:00,2024-11-22 23:39:10+00:00,https://github.com/apache/airflow/pull/44225,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2494526282, 'issue_id': 2677024737, 'author': 'sean-rose', 'body': '@eladkal since you reviewed #37655 would you mind reviewing this as well? (this is a fix for issues with #37655)', 'created_at': datetime.datetime(2024, 11, 22, 18, 49, 5, tzinfo=datetime.timezone.utc)}]","sean-rose (Issue Creator) on (2024-11-22 18:49:05 UTC): @eladkal since you reviewed #37655 would you mind reviewing this as well? (this is a fix for issues with #37655)

"
2676971607,pull_request,closed,,List Variables,"relates: #43709 

<img width=""601"" alt=""image"" src=""https://github.com/user-attachments/assets/48b9cba7-896d-4f13-a1bb-2fb18238601c"">

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/9d2861b4-12ea-47b3-b05a-525f9ff4eda9"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-11-20 19:30:10+00:00,[],2024-12-09 15:43:53+00:00,2024-12-09 15:43:53+00:00,https://github.com/apache/airflow/pull/44224,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2525587838, 'issue_id': 2676971607, 'author': 'shubhamraj-git', 'body': '@bbovenzi For now, removed the search options, this PR will just have list variables, all other parts will be merged separately in smaller PRs.', 'created_at': datetime.datetime(2024, 12, 8, 10, 52, 22, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2024-12-08 10:52:22 UTC): @bbovenzi For now, removed the search options, this PR will just have list variables, all other parts will be merged separately in smaller PRs.

"
2676966141,pull_request,closed,,Migrate public endpoint Patch Task Instance to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/43753, https://github.com/apache/airflow/issues/43754 and https://github.com/apache/airflow/issues/43752
related: https://github.com/apache/airflow/issues/42370

This migrates the Patch Task Instance API from `api_connexion` to `api_fastapi`.
",omkar-foss,2024-11-20 19:27:58+00:00,['omkar-foss'],2024-11-26 10:04:10+00:00,2024-11-26 10:04:10+00:00,https://github.com/apache/airflow/pull/44223,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2489465091, 'issue_id': 2676966141, 'author': 'omkar-foss', 'body': 'All checks passed, PR is ready for review ✅', 'created_at': datetime.datetime(2024, 11, 20, 20, 16, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490124978, 'issue_id': 2676966141, 'author': 'omkar-foss', 'body': ""@pierrejeambrun I'm adding the Set Task Instance Note functionality to this (Patch Task Instance) API as you mentioned [here](https://github.com/apache/airflow/issues/43755#issuecomment-2459950793). Will update this PR in a while."", 'created_at': datetime.datetime(2024, 11, 21, 5, 40, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492438234, 'issue_id': 2676966141, 'author': 'omkar-foss', 'body': ""> I think we need to include the `update_mask` as we do for other patch endpoints. (The state part would actually be the `set_task_instance_state` of your other PR)\r\n\r\n@pierrejeambrun I've added `update_mask` here in this PR to Patch Task Instance API.\r\n\r\nYes got it, sure, I've closed the other Set Task Instance State PR https://github.com/apache/airflow/pull/44246."", 'created_at': datetime.datetime(2024, 11, 21, 22, 9, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493928125, 'issue_id': 2676966141, 'author': 'omkar-foss', 'body': 'All conversations resolved, PR rebased with `main` and all conflicts resolved, please have a look when possible @pierrejeambrun @bbovenzi. Thanks.', 'created_at': datetime.datetime(2024, 11, 22, 14, 47, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498531074, 'issue_id': 2676966141, 'author': 'omkar-foss', 'body': '@pierrejeambrun all checks passing, and have rebased with `main` just now. Please review when you get a chance, thanks.', 'created_at': datetime.datetime(2024, 11, 25, 16, 47, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500061767, 'issue_id': 2676966141, 'author': 'omkar-foss', 'body': '@pierrejeambrun PR rebased with `main` and ready to merge. Thank you.', 'created_at': datetime.datetime(2024, 11, 26, 9, 9, 34, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-20 20:16:36 UTC): All checks passed, PR is ready for review ✅

omkar-foss (Issue Creator) on (2024-11-21 05:40:41 UTC): @pierrejeambrun I'm adding the Set Task Instance Note functionality to this (Patch Task Instance) API as you mentioned [here](https://github.com/apache/airflow/issues/43755#issuecomment-2459950793). Will update this PR in a while.

omkar-foss (Issue Creator) on (2024-11-21 22:09:15 UTC): @pierrejeambrun I've added `update_mask` here in this PR to Patch Task Instance API.

Yes got it, sure, I've closed the other Set Task Instance State PR https://github.com/apache/airflow/pull/44246.

omkar-foss (Issue Creator) on (2024-11-22 14:47:04 UTC): All conversations resolved, PR rebased with `main` and all conflicts resolved, please have a look when possible @pierrejeambrun @bbovenzi. Thanks.

omkar-foss (Issue Creator) on (2024-11-25 16:47:40 UTC): @pierrejeambrun all checks passing, and have rebased with `main` just now. Please review when you get a chance, thanks.

omkar-foss (Issue Creator) on (2024-11-26 09:09:34 UTC): @pierrejeambrun PR rebased with `main` and ready to merge. Thank you.

"
2676861019,pull_request,closed,,Update fundamentals.rst,"properly show 'default_args=default_args,' like the comment implies

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",aramxc,2024-11-20 18:52:44+00:00,[],2025-01-11 00:15:23+00:00,2025-01-11 00:15:23+00:00,https://github.com/apache/airflow/pull/44222,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('kind:documentation', '')]","[{'comment_id': 2489323214, 'issue_id': 2676861019, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 20, 18, 52, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571448963, 'issue_id': 2676861019, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 5, 0, 16, 55, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-20 18:52:49 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2025-01-05 00:16:55 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2676699773,pull_request,closed,,Fix ORM vs migration files inconsistencies,"There have been some inconsistences between ORM and migration files but it doesn't fail in tests. This is an attempt to fix the inconsistency and also have it fail in tests

",ephraimbuddy,2024-11-20 17:47:19+00:00,['ephraimbuddy'],2024-12-01 22:58:32+00:00,2024-12-01 22:58:30+00:00,https://github.com/apache/airflow/pull/44221,"[('area:dev-tools', ''), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2501501080, 'issue_id': 2676699773, 'author': 'ephraimbuddy', 'body': ""Old sqlalchemy versions don't support drop table `if exists`. Should we have the _xcom_archive table in the ORM? cc @kaxil  see: https://github.com/apache/airflow/actions/runs/12034647961/job/33552179419?pr=44221#step:7:57121"", 'created_at': datetime.datetime(2024, 11, 26, 17, 14, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504182870, 'issue_id': 2676699773, 'author': 'kaxil', 'body': ""> Old sqlalchemy versions don't support drop table `if exists`. Should we have the _xcom_archive table in the ORM? cc @kaxil see: https://github.com/apache/airflow/actions/runs/12034647961/job/33552179419?pr=44221#step:7:57121\r\n\r\noh, huh,  we can remove the `if_exists` then. We can use almebic get tables to do it\r\n\r\n```python\r\ndef get_current_table_names():\r\n    connection = op.get_bind()\r\n\r\n    metadata = MetaData()\r\n    metadata.reflect(bind=connection)\r\n\r\n    return metadata.tables.keys()\r\n\r\n```\r\n\r\nor \r\n\r\nhttps://github.com/apache/airflow/blob/761cedd06103e10627ad62727eae0aac15387130/airflow/utils/db.py#L1008-L1029"", 'created_at': datetime.datetime(2024, 11, 27, 15, 36, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504745736, 'issue_id': 2676699773, 'author': 'ephraimbuddy', 'body': ""> > Old sqlalchemy versions don't support drop table `if exists`. Should we have the _xcom_archive table in the ORM? cc @kaxil see: https://github.com/apache/airflow/actions/runs/12034647961/job/33552179419?pr=44221#step:7:57121\r\n> \r\n> oh, huh, we can remove the `if_exists` then. We can use almebic get tables to do it\r\n> \r\n> ```python\r\n> def get_current_table_names():\r\n>     connection = op.get_bind()\r\n> \r\n>     metadata = MetaData()\r\n>     metadata.reflect(bind=connection)\r\n> \r\n>     return metadata.tables.keys()\r\n> ```\r\n> \r\n> or\r\n> \r\n> https://github.com/apache/airflow/blob/761cedd06103e10627ad62727eae0aac15387130/airflow/utils/db.py#L1008-L1029\r\n\r\nI think that would not work well with offline sql scripts. I’ll verify"", 'created_at': datetime.datetime(2024, 11, 27, 20, 47, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505494285, 'issue_id': 2676699773, 'author': 'ephraimbuddy', 'body': ""Didn't think of using raw SQL. I just used it now. Let's see how it goes"", 'created_at': datetime.datetime(2024, 11, 28, 8, 11, 14, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2024-11-26 17:14:58 UTC): Old sqlalchemy versions don't support drop table `if exists`. Should we have the _xcom_archive table in the ORM? cc @kaxil  see: https://github.com/apache/airflow/actions/runs/12034647961/job/33552179419?pr=44221#step:7:57121

kaxil on (2024-11-27 15:36:32 UTC): oh, huh,  we can remove the `if_exists` then. We can use almebic get tables to do it

```python
def get_current_table_names():
    connection = op.get_bind()

    metadata = MetaData()
    metadata.reflect(bind=connection)

    return metadata.tables.keys()

```

or 

https://github.com/apache/airflow/blob/761cedd06103e10627ad62727eae0aac15387130/airflow/utils/db.py#L1008-L1029

ephraimbuddy (Issue Creator) on (2024-11-27 20:47:36 UTC): I think that would not work well with offline sql scripts. I’ll verify

ephraimbuddy (Issue Creator) on (2024-11-28 08:11:14 UTC): Didn't think of using raw SQL. I just used it now. Let's see how it goes

"
2676619785,pull_request,closed,,AIP-84 Migrate public endpoint Clear Task Instances to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/43751
related: https://github.com/apache/airflow/issues/42370

This migrates the Clear Task Instances API from `api_connexion` to `api_fastapi`.",omkar-foss,2024-11-20 17:26:35+00:00,['omkar-foss'],2024-11-22 14:00:43+00:00,2024-11-22 14:00:43+00:00,https://github.com/apache/airflow/pull/44220,"[('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2489378441, 'issue_id': 2676619785, 'author': 'omkar-foss', 'body': 'Resolving conflicts from recent PR merges into `main`.', 'created_at': datetime.datetime(2024, 11, 20, 19, 25, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489400083, 'issue_id': 2676619785, 'author': 'omkar-foss', 'body': '> Resolving conflicts from recent PR merges into `main`.\r\n\r\nThis is done, PR synced with `main` and all conflicts resolved ✅', 'created_at': datetime.datetime(2024, 11, 20, 19, 37, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489505646, 'issue_id': 2676619785, 'author': 'omkar-foss', 'body': 'All checks passed, PR ready to review ✅', 'created_at': datetime.datetime(2024, 11, 20, 20, 42, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490894198, 'issue_id': 2676619785, 'author': 'omkar-foss', 'body': ""> Looking good!\r\n> \r\n> A few suggestions (only [#44220 (comment)](https://github.com/apache/airflow/pull/44220#discussion_r1851671694) requires change), we can merge after :)\r\n\r\nThanks @pierrejeambrun, I've made the changes as per your suggestions and resolved the corresponding conversations. Also rebased with `main`. Please have a look, thanks! 😁"", 'created_at': datetime.datetime(2024, 11, 21, 11, 41, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492193211, 'issue_id': 2676619785, 'author': 'omkar-foss', 'body': ""@pierrejeambrun @bbovenzi Thank you for your reviews! I've updated the PR as per your suggestions and also rebased with `main`. Please check it out when possible, thanks 😁"", 'created_at': datetime.datetime(2024, 11, 21, 20, 22, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493504979, 'issue_id': 2676619785, 'author': 'pierrejeambrun', 'body': 'I just rebased the branch, to solve additional conflicts introduced by recent merge.\r\n\r\nShould be good to merge.', 'created_at': datetime.datetime(2024, 11, 22, 11, 10, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493771631, 'issue_id': 2676619785, 'author': 'omkar-foss', 'body': '1 test failing after rebase, rebased again. It should pass now.', 'created_at': datetime.datetime(2024, 11, 22, 13, 28, 39, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-20 19:25:16 UTC): Resolving conflicts from recent PR merges into `main`.

omkar-foss (Issue Creator) on (2024-11-20 19:37:23 UTC): This is done, PR synced with `main` and all conflicts resolved ✅

omkar-foss (Issue Creator) on (2024-11-20 20:42:17 UTC): All checks passed, PR ready to review ✅

omkar-foss (Issue Creator) on (2024-11-21 11:41:18 UTC): Thanks @pierrejeambrun, I've made the changes as per your suggestions and resolved the corresponding conversations. Also rebased with `main`. Please have a look, thanks! 😁

omkar-foss (Issue Creator) on (2024-11-21 20:22:22 UTC): @pierrejeambrun @bbovenzi Thank you for your reviews! I've updated the PR as per your suggestions and also rebased with `main`. Please check it out when possible, thanks 😁

pierrejeambrun on (2024-11-22 11:10:12 UTC): I just rebased the branch, to solve additional conflicts introduced by recent merge.

Should be good to merge.

omkar-foss (Issue Creator) on (2024-11-22 13:28:39 UTC): 1 test failing after rebase, rebased again. It should pass now.

"
2676604893,pull_request,closed,,remove  `all()` for scalars,removes use of all() on scalars,rawwar,2024-11-20 17:18:17+00:00,[],2024-11-21 03:58:26+00:00,2024-11-20 18:25:33+00:00,https://github.com/apache/airflow/pull/44219,[],[],
2676433762,pull_request,closed,,"remove ""/"" at end from FastAPI endpoints routes","Removing trailing ""/"" from routes to be inline with legacy endpoints

related to #42370

",rawwar,2024-11-20 16:24:16+00:00,[],2024-11-21 03:58:12+00:00,2024-11-20 18:27:13+00:00,https://github.com/apache/airflow/pull/44218,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2676414259,pull_request,closed,,AIP-84 Pools API small improvements,"Small adjustments. (Remove trailing slash, and consolidate exception status code handling)",pierrejeambrun,2024-11-20 16:16:02+00:00,"['kaxil', 'pierrejeambrun']",2024-11-20 16:53:55+00:00,2024-11-20 16:53:52+00:00,https://github.com/apache/airflow/pull/44217,"[('AIP-84', 'Modern Rest API')]",[],
2676383841,pull_request,closed,,Refactor implementation to get OTel tracer,"Previous implementation had redundant logic in add_span for parameter inspection:

```python
with Trace.start_span(span_name=func_name, component=component):
    if len(inspect.signature(func).parameters) > 0:
        return func(*args, **kwargs)
    else:
        return func()
```

`_Trace` Metaclass was using `__init__` and few more Python-related changes -- check inline comments.

related issue: https://github.com/apache/airflow/issues/43789

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-20 16:03:08+00:00,[],2024-11-20 19:02:47+00:00,2024-11-20 19:02:30+00:00,https://github.com/apache/airflow/pull/44216,[],"[{'comment_id': 2489339795, 'issue_id': 2676383841, 'author': 'kaxil', 'body': 'Failure is unrelated:\r\n\r\n```\r\n=========================== short test summary info ============================\r\nFAILED tests/jobs/test_scheduler_job.py::TestSchedulerJob::test_setup_callback_sink_not_standalone_dag_processor - sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) server closed the connection unexpectedly\r\n\tThis probably means the server terminated abnormally\r\n\tbefore or while processing the request.\r\n\r\n```', 'created_at': datetime.datetime(2024, 11, 20, 19, 2, 46, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-20 19:02:46 UTC): Failure is unrelated:

```
=========================== short test summary info ============================
FAILED tests/jobs/test_scheduler_job.py::TestSchedulerJob::test_setup_callback_sink_not_standalone_dag_processor - sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

```

"
2676327803,pull_request,closed,,minor fixes for Get Config,"related to #42745 , #43841

CC: @jason810496",rawwar,2024-11-20 15:42:15+00:00,[],2024-11-20 16:04:08+00:00,2024-11-20 16:01:56+00:00,https://github.com/apache/airflow/pull/44215,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2676096462,pull_request,closed,,feat: add OpenLineage support for BigQueryToBigQueryOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for BigQueryToBigQueryOperator.

Within the operator itself, i removed the additional call to BQ API that got the job configuration as it's already returned by method that's submitting job - I adjusted the code to take advantage of that. The configuration returned is also saved as instance attribute for later use of OpenLineage method.

In the same time, I'm modifying two **internal** OpenLineage utils function:

- `get_facets_from_bq_table` now do not return facets instead of returning empty facets when there is no schema or description for bq table
- `get_identity_column_lineage_facet` is now checking if the source columns included in column lineage facet are actually in the schema of source datasets. It's now possible to generate this facet when source tables contain subset of columns of a destination table, which can be a case f.e. in BQ to BQ copy.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2024-11-20 14:40:30+00:00,[],2024-11-25 11:43:47+00:00,2024-11-22 23:37:29+00:00,https://github.com/apache/airflow/pull/44214,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2676044352,pull_request,closed,,[FIX] Fixed databricks repair run deferrable,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
`_handle_deferrable_databricks_operator_completion`  is assuming repair_run will always be called in case of repair_run = True however after new_settings change, that decision also include reason match and hence flow exit with execute_complete method. These changes will consider the settings and then run for repair run flow.
@Lee-W 

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",raghvendra-singh1,2024-11-20 14:30:43+00:00,[],2024-12-11 08:32:12+00:00,2024-12-11 08:32:09+00:00,https://github.com/apache/airflow/pull/44213,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2488739209, 'issue_id': 2676044352, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 20, 14, 30, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490194490, 'issue_id': 2676044352, 'author': 'Lee-W', 'body': 'Will need to get the tests fixed', 'created_at': datetime.datetime(2024, 11, 21, 6, 40, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493191338, 'issue_id': 2676044352, 'author': 'raghvendra-singh1', 'body': 'Sure, will look into that', 'created_at': datetime.datetime(2024, 11, 22, 8, 39, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527095542, 'issue_id': 2676044352, 'author': 'gaurav7261', 'body': '@Lee-W can you please review and merge this bug fix PR', 'created_at': datetime.datetime(2024, 12, 9, 7, 1, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527112601, 'issue_id': 2676044352, 'author': 'Lee-W', 'body': '> @Lee-W can you please review and merge this bug fix PR\r\n\r\nSure, will take a look once the test and CI pass', 'created_at': datetime.datetime(2024, 12, 9, 7, 10, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2532671110, 'issue_id': 2676044352, 'author': 'raghvendra-singh1', 'body': '@Lee-W Made some changes. Those failing CI tests should be fixed now. Could you please review?', 'created_at': datetime.datetime(2024, 12, 10, 19, 22, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533646651, 'issue_id': 2676044352, 'author': 'Lee-W', 'body': 'rebased from the latest main to see whether the last test passes', 'created_at': datetime.datetime(2024, 12, 11, 5, 5, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533755161, 'issue_id': 2676044352, 'author': 'raghvendra-singh1', 'body': '@Lee-W Passed the CI tests. Could you please review now?', 'created_at': datetime.datetime(2024, 12, 11, 6, 34, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2534986043, 'issue_id': 2676044352, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 11, 8, 32, 11, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-20 14:30:48 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

Lee-W on (2024-11-21 06:40:54 UTC): Will need to get the tests fixed

raghvendra-singh1 (Issue Creator) on (2024-11-22 08:39:21 UTC): Sure, will look into that

gaurav7261 on (2024-12-09 07:01:06 UTC): @Lee-W can you please review and merge this bug fix PR

Lee-W on (2024-12-09 07:10:02 UTC): Sure, will take a look once the test and CI pass

raghvendra-singh1 (Issue Creator) on (2024-12-10 19:22:20 UTC): @Lee-W Made some changes. Those failing CI tests should be fixed now. Could you please review?

Lee-W on (2024-12-11 05:05:57 UTC): rebased from the latest main to see whether the last test passes

raghvendra-singh1 (Issue Creator) on (2024-12-11 06:34:44 UTC): @Lee-W Passed the CI tests. Could you please review now?

boring-cyborg[bot] on (2024-12-11 08:32:11 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2675181643,pull_request,closed,,Fix: Remove AS Keyword for Subquery Aliases in Oracle SQL,"Oracle SQL does not permit the use of the AS keyword when aliasing subqueries. While AS is valid for column and table aliases in some contexts, subquery aliases must not include the keyword AS. This PR addresses this limitation in the SQLTableCheckOperator.

Changes:
Updated the SQLTableCheckOperator to handle Oracle-specific SQL syntax by omitting the AS keyword for subquery aliases.
Introduced a check to determine the database type, ensuring this adjustment is applied only for Oracle SQL.
Added relevant unit tests to ensure compatibility across supported databases.
Closes:
Closes [#44135](https://github.com/apache/airflow/issues/44135).

Notes:
This change ensures that Airflow's SQLTableCheckOperator works seamlessly with Oracle SQL while maintaining compatibility with other databases.",tolebiermekov,2024-11-20 09:35:06+00:00,[],2025-01-12 00:17:20+00:00,2025-01-12 00:17:20+00:00,https://github.com/apache/airflow/pull/44210,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:common-sql', '')]","[{'comment_id': 2488055030, 'issue_id': 2675181643, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 20, 9, 35, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489921730, 'issue_id': 2675181643, 'author': 'potiuk', 'body': 'Nope. This is still very wrong. ""common"" sql provider should not know anything about ""oracle"" - this is the main reason why we introduced ""common.sql"" and all the ""database"" specific calls should come to the provider - so you have to modify it in the way that all ""oracle"" specific code lives in the ""oracle"" provider. You should implement a new feature in the common.sql where you can replace the template and then make oracle provider to replace it.', 'created_at': datetime.datetime(2024, 11, 21, 2, 11, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571807421, 'issue_id': 2675181643, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 6, 0, 16, 25, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-20 09:35:25 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-11-21 02:11:55 UTC): Nope. This is still very wrong. ""common"" sql provider should not know anything about ""oracle"" - this is the main reason why we introduced ""common.sql"" and all the ""database"" specific calls should come to the provider - so you have to modify it in the way that all ""oracle"" specific code lives in the ""oracle"" provider. You should implement a new feature in the common.sql where you can replace the template and then make oracle provider to replace it.

github-actions[bot] on (2025-01-06 00:16:25 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2674693717,pull_request,closed,,Make list backfills endpoint use asyncio,"This is a sort of hello world / proof of concept for having an route implemented using asyncio.

Depends on https://github.com/apache/airflow/pull/44226

",dstandish,2024-11-20 07:01:38+00:00,[],2024-11-22 20:37:11+00:00,2024-11-22 20:37:10+00:00,https://github.com/apache/airflow/pull/44208,[],"[{'comment_id': 2493215799, 'issue_id': 2674693717, 'author': 'pierrejeambrun', 'body': 'Note to myself to not merge too early:\r\n\r\nDepends on https://github.com/apache/airflow/pull/44267', 'created_at': datetime.datetime(2024, 11, 22, 8, 49, 50, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-22 08:49:50 UTC): Note to myself to not merge too early:

Depends on https://github.com/apache/airflow/pull/44267

"
2674590040,pull_request,closed,,Don't exit doc preparation even if changelog is empty for any provider,"

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

@eladkal found an edge case where if any provider doesn't have a changelog to process, the process of `breeze release-management generate-issue-content-providers` exits and doesn't continue ahead.

How was this tested?
1. Cleared the changelog entirely for `standard` provider to ensure it has no PRs to process
2. Ran the `breeze release-management generate-issue-content-providers` command before changes:
```
Skipping extracting PRs for provider qdrant as it is missing in dist
Skipping extracting PRs for provider redis as it is missing in dist
Skipping extracting PRs for provider salesforce as it is missing in dist
Skipping extracting PRs for provider samba as it is missing in dist
Skipping extracting PRs for provider segment as it is missing in dist
Skipping extracting PRs for provider sendgrid as it is missing in dist
Skipping extracting PRs for provider sftp as it is missing in dist
Skipping extracting PRs for provider singularity as it is missing in dist
Extracting PRs for provider slack
Extracting PRs for provider smtp
Extracting PRs for provider snowflake
Extracting PRs for provider sqlite
Skipping extracting PRs for provider ssh as it is missing in dist
Extracting PRs for provider standard
Skipping provider standard. The changelog file doesn't contain any PRs for the release.
```

3. Ran the same command after the changes:
```
Extracting PRs for provider smtp
Extracting PRs for provider snowflake
Extracting PRs for provider sqlite
Extracting PRs for provider ssh
Extracting PRs for provider standard
I AM HERE for standard
Skipping provider standard. The changelog file doesn't contain any PRs for the release.

Extracting PRs for provider tableau
Extracting PRs for provider telegram
Extracting PRs for provider teradata
Extracting PRs for provider trino
Extracting PRs for provider vertica
Extracting PRs for provider weaviate
Extracting PRs for provider yandex

```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-20 06:29:25+00:00,[],2024-11-22 18:21:29+00:00,2024-11-22 18:21:28+00:00,https://github.com/apache/airflow/pull/44207,"[('area:dev-tools', '')]","[{'comment_id': 2489863095, 'issue_id': 2674590040, 'author': 'potiuk', 'body': 'Hmm... there seem to be error generated by that however (see failing tests) - looks like it expects to have provider in the dictionary and it does not find it.', 'created_at': datetime.datetime(2024, 11, 21, 1, 13, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493760960, 'issue_id': 2674590040, 'author': 'amoghrajesh', 'body': 'Ah yes, let me try and fix it', 'created_at': datetime.datetime(2024, 11, 22, 13, 22, 58, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-21 01:13:42 UTC): Hmm... there seem to be error generated by that however (see failing tests) - looks like it expects to have provider in the dictionary and it does not find it.

amoghrajesh (Issue Creator) on (2024-11-22 13:22:58 UTC): Ah yes, let me try and fix it

"
2674565076,pull_request,closed,,AIP-84 Get Mapped Task Instance Try Details,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related to: https://github.com/apache/airflow/issues/42370

<!-- Please keep an empty line above the dashes. -->
---
",kandharvishnu,2024-11-20 06:13:08+00:00,[],2024-11-20 16:52:07+00:00,2024-11-20 16:52:07+00:00,https://github.com/apache/airflow/pull/44206,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2489000543, 'issue_id': 2674565076, 'author': 'kandharvishnu', 'body': '> Looking good overall beside @rawwar comments.\r\n\r\nyes, removed the print statements', 'created_at': datetime.datetime(2024, 11, 20, 16, 10, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489062982, 'issue_id': 2674565076, 'author': 'rawwar', 'body': 'Just noticed logical_date is missing in response model(TaskInstanceHistoryResponse). Is this intentional ?', 'created_at': datetime.datetime(2024, 11, 20, 16, 35, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489072623, 'issue_id': 2674565076, 'author': 'kandharvishnu', 'body': '> Just noticed logical_date is missing in response model(TaskInstanceHistoryResponse). Is this intentional ?\r\n\r\nTaskInstanceHistoryResponse return `logical_date` \r\n<img width=""1658"" alt=""image"" src=""https://github.com/user-attachments/assets/7358e036-6fe0-4536-b1fe-c368a326fd40"">', 'created_at': datetime.datetime(2024, 11, 20, 16, 38, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489079512, 'issue_id': 2674565076, 'author': 'rawwar', 'body': 'I saw the response [Here](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_mapped_task_instance_try_details) and saw it had execution_date', 'created_at': datetime.datetime(2024, 11, 20, 16, 41, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489092055, 'issue_id': 2674565076, 'author': 'kandharvishnu', 'body': '> I saw the response [Here](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_mapped_task_instance_try_details) and saw it had execution_date\r\n\r\nI have raised a PR to fix that - https://github.com/apache/airflow/pull/43830', 'created_at': datetime.datetime(2024, 11, 20, 16, 47, 37, tzinfo=datetime.timezone.utc)}]","kandharvishnu (Issue Creator) on (2024-11-20 16:10:41 UTC): yes, removed the print statements

rawwar on (2024-11-20 16:35:11 UTC): Just noticed logical_date is missing in response model(TaskInstanceHistoryResponse). Is this intentional ?

kandharvishnu (Issue Creator) on (2024-11-20 16:38:59 UTC): TaskInstanceHistoryResponse return `logical_date` 
<img width=""1658"" alt=""image"" src=""https://github.com/user-attachments/assets/7358e036-6fe0-4536-b1fe-c368a326fd40"">

rawwar on (2024-11-20 16:41:58 UTC): I saw the response [Here](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_mapped_task_instance_try_details) and saw it had execution_date

kandharvishnu (Issue Creator) on (2024-11-20 16:47:37 UTC): I have raised a PR to fix that - https://github.com/apache/airflow/pull/43830

"
2673707246,pull_request,closed,,AIP-72: Add a basic test for a task run,"This PR adds a very basic test to parse & run. We will start adding more things here and porting things from core.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-19 22:20:20+00:00,[],2024-11-20 18:45:59+00:00,2024-11-20 18:45:56+00:00,https://github.com/apache/airflow/pull/44203,"[('area:task-sdk', None)]",[],
2673579442,pull_request,closed,,Bump `uv` to `0.5.3`,"Highlight for me is support for conflicting deps: https://github.com/astral-sh/uv/pull/9160

https://docs.astral.sh/uv/reference/settings/#conflicts

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-19 21:28:03+00:00,[],2024-11-19 22:22:21+00:00,2024-11-19 22:22:19+00:00,https://github.com/apache/airflow/pull/44202,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2673568698,pull_request,closed,,AIP-72: Extract `WatchedSubprocess` code into more methods,"Refactord the `WatchedSubprocess` class to multiple methods for just making it a little more easier (for me) to understand flow of code.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-19 21:20:58+00:00,[],2024-11-19 22:14:50+00:00,2024-11-19 22:14:47+00:00,https://github.com/apache/airflow/pull/44201,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2673550356,pull_request,closed,,Create dag graph with nested groups and join_ids,"Add Graph view in a full modal to the Dag page. This is just mock data because the API endpoint is not done yet [issue](https://github.com/apache/airflow/issues/42367)

![Nov-19-2024 15-47-44](https://github.com/user-attachments/assets/be628e2f-dfb3-48bf-becc-97b94b0d8739)

Done:
- stores modal state in url params
- renders a graph
- handles join nodes
- can expand/collapse groups which are stored in localStorage
- Setup/teardown tasks
- Mapped tasks
- Edge labels

To Do:
- Task information
- Task Instance information
- Selecting a node
- Tests
- Filtering upstream/downstream
- External deps (assets, sensors, triggers)
- Zoomed out 
- Highlighting tasks by state

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-19 21:09:05+00:00,[],2024-11-21 19:07:11+00:00,2024-11-21 19:07:09+00:00,https://github.com/apache/airflow/pull/44199,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2486919221, 'issue_id': 2673550356, 'author': 'bbovenzi', 'body': 'Nested task groups, setup/teardown, mapped tasks, edge labels:\r\n\r\n<img width=""1295"" alt=""Screenshot 2024-11-19 at 5 56 47\u202fPM"" src=""https://github.com/user-attachments/assets/08820d3a-8cec-4550-a83f-59a1c4a6788d"">', 'created_at': datetime.datetime(2024, 11, 19, 22, 57, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489583505, 'issue_id': 2673550356, 'author': 'jscheffl', 'body': 'Mhm, I don\'t know what is wrong in my env...wanted to test but ANY DAG that I call is showing the same ""wrong"" view and I can also not click/scroll the elements.\r\nUbuntu with Firefox _and_ Chrome. Both the same. Dark and light mode.\r\n\r\n![image](https://github.com/user-attachments/assets/1ab167b4-881d-44f4-a7d0-365b7db42e3d)', 'created_at': datetime.datetime(2024, 11, 20, 21, 32, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489588960, 'issue_id': 2673550356, 'author': 'jscheffl', 'body': '> Mhm, I don\'t know what is wrong in my env...wanted to test but ANY DAG that I call is showing the same ""wrong"" view and I can also not click/scroll the elements. Ubuntu with Firefox _and_ Chrome. Both the same. Dark and light mode.\r\n\r\nMhm, okay. It is better in dev-mode. But the DAG graph displayed is static and not matching to selected DAG. Is is a technical mock atm?', 'created_at': datetime.datetime(2024, 11, 20, 21, 36, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489610502, 'issue_id': 2673550356, 'author': 'bbovenzi', 'body': ""> Mhm, okay. It is better in dev-mode. But the DAG graph displayed is static and not matching to selected DAG. Is is a technical mock atm?\r\n\r\nYes, I just updated the description to say that this is all mocked data since the API endpoint isn't done yet"", 'created_at': datetime.datetime(2024, 11, 20, 21, 50, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490604185, 'issue_id': 2673550356, 'author': 'pierrejeambrun', 'body': '@jscheffl\r\n\r\nIn non `dev-mode` do you still have the issue mentioned above ?', 'created_at': datetime.datetime(2024, 11, 21, 9, 49, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491519170, 'issue_id': 2673550356, 'author': 'bbovenzi', 'body': ""No, I'm able to replicate the non-dev mode issue. I'm looking into it"", 'created_at': datetime.datetime(2024, 11, 21, 15, 20, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2491542325, 'issue_id': 2673550356, 'author': 'bbovenzi', 'body': 'Fixed!', 'created_at': datetime.datetime(2024, 11, 21, 15, 28, 45, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2024-11-19 22:57:30 UTC): Nested task groups, setup/teardown, mapped tasks, edge labels:

<img width=""1295"" alt=""Screenshot 2024-11-19 at 5 56 47 PM"" src=""https://github.com/user-attachments/assets/08820d3a-8cec-4550-a83f-59a1c4a6788d"">

jscheffl on (2024-11-20 21:32:47 UTC): Mhm, I don't know what is wrong in my env...wanted to test but ANY DAG that I call is showing the same ""wrong"" view and I can also not click/scroll the elements.
Ubuntu with Firefox _and_ Chrome. Both the same. Dark and light mode.

![image](https://github.com/user-attachments/assets/1ab167b4-881d-44f4-a7d0-365b7db42e3d)

jscheffl on (2024-11-20 21:36:25 UTC): Mhm, okay. It is better in dev-mode. But the DAG graph displayed is static and not matching to selected DAG. Is is a technical mock atm?

bbovenzi (Issue Creator) on (2024-11-20 21:50:37 UTC): Yes, I just updated the description to say that this is all mocked data since the API endpoint isn't done yet

pierrejeambrun on (2024-11-21 09:49:34 UTC): @jscheffl

In non `dev-mode` do you still have the issue mentioned above ?

bbovenzi (Issue Creator) on (2024-11-21 15:20:21 UTC): No, I'm able to replicate the non-dev mode issue. I'm looking into it

bbovenzi (Issue Creator) on (2024-11-21 15:28:45 UTC): Fixed!

"
2673525238,pull_request,closed,,Remove deprecations from fab provider,"FAB provider next version is set to be 2.0.0 (major upgrade). As such, let's do some clean up to remove deprecations from the provider.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-19 20:54:22+00:00,[],2024-11-28 19:47:38+00:00,2024-11-21 09:44:17+00:00,https://github.com/apache/airflow/pull/44198,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2487632726, 'issue_id': 2673525238, 'author': 'eladkal', 'body': 'Can you update change log similar to how you did it for AWS?', 'created_at': datetime.datetime(2024, 11, 20, 6, 47, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488617167, 'issue_id': 2673525238, 'author': 'vincbeck', 'body': '> Can you update change log similar to how you did it for AWS?\r\n\r\nSorry I forgot! Sure, doing it right now', 'created_at': datetime.datetime(2024, 11, 20, 13, 40, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488894173, 'issue_id': 2673525238, 'author': 'vincbeck', 'body': '> Can you update change log similar to how you did it for AWS?\r\n\r\nDone :)', 'created_at': datetime.datetime(2024, 11, 20, 15, 29, 24, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-20 06:47:04 UTC): Can you update change log similar to how you did it for AWS?

vincbeck (Issue Creator) on (2024-11-20 13:40:40 UTC): Sorry I forgot! Sure, doing it right now

vincbeck (Issue Creator) on (2024-11-20 15:29:24 UTC): Done :)

"
2673399595,pull_request,open,,"Changed fernetkey-secret, redis-broker-url, redis-password to lookup function","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: [#44164](https://github.com/apache/airflow/issues/44164)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

The fernet-key, redis-password, and redis-broker-url are not controlled by helm and are installed during pre-install hook.  I believe this was done as a workaround when it was implemented.  Switching it to a lookup function would let this object be managed by helm so that the chart controls the objects it creates and and can create the object during upgrade, which would be expected for a subchart if added.  

The downside of switching this is that for this upgrade we would have to manually delete the three secrets prior to the upgrade. 

1. fernet-key
2. redis-password
3. broker-url 

closes: [44164](https://github.com/apache/airflow/issues/44164)

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",JKrehling,2024-11-19 20:11:00+00:00,[],2025-01-30 00:14:45+00:00,,https://github.com/apache/airflow/pull/44197,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2504407264, 'issue_id': 2673399595, 'author': 'JKrehling', 'body': ""This would require either manually annotating or deleting the existing secrets before upgrade.  \r\nI don't know if there is a mechanism or documentation needed to handle that."", 'created_at': datetime.datetime(2024, 11, 27, 17, 18, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585490742, 'issue_id': 2673399595, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 12, 0, 17, 21, tzinfo=datetime.timezone.utc)}]","JKrehling (Issue Creator) on (2024-11-27 17:18:43 UTC): This would require either manually annotating or deleting the existing secrets before upgrade.  
I don't know if there is a mechanism or documentation needed to handle that.

github-actions[bot] on (2025-01-12 00:17:21 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2673058936,pull_request,closed,,AIP84: Transform assets/queuedEvent to assets/queuedEvents,"Transform all assets/queuedEvent into assets/queudEvents so that they are consistent with other routes as we have for assets/events.
Closes: https://github.com/apache/airflow/issues/44193
<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-19 18:01:30+00:00,[],2024-11-20 08:33:16+00:00,2024-11-20 08:33:15+00:00,https://github.com/apache/airflow/pull/44194,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2672876741,pull_request,closed,,Don't create new session in stuck queue reschedule handler,"This is a fix up / followup to https://github.com/apache/airflow/pull/43520

It does not really make a material difference, just, I'm avoiding use of the session decorator, and the create / dispose session logic, when it is not needed.  i also commit as i go along since there's no reason to handle multiple distinct tis in the same transaction.

cc @jscheffl",dstandish,2024-11-19 16:57:10+00:00,[],2024-11-19 21:49:54+00:00,2024-11-19 21:49:51+00:00,https://github.com/apache/airflow/pull/44192,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2672729211,pull_request,closed,,Fix failing mypy check on `main`,"Failure on main:

```
providers/src/airflow/providers/apache/spark/hooks/spark_submit.py:525: error:
Module ""airflow.security.kerberos"" has no attribute ""get_kerberos_principle"";
maybe ""get_kerberos_principal""?  [attr-defined]
                from airflow.security.kerberos import (
                ^
providers/src/airflow/providers/apache/spark/hooks/spark_submit.py:525: error:
Name ""get_kerberos_principal"" already defined (possibly by an import)
[no-redef]
                from airflow.security.kerberos import (
                ^
Found 2 errors in 1 file (checked 3337 source files)
Error 1 returned
```

Example: https://github.com/apache/airflow/actions/runs/11916279945/job/33209076757

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-19 16:13:50+00:00,[],2024-11-19 17:58:35+00:00,2024-11-19 16:52:47+00:00,https://github.com/apache/airflow/pull/44191,"[('area:providers', ''), ('provider:apache-spark', '')]","[{'comment_id': 2486391988, 'issue_id': 2672729211, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 19, 17, 58, 35, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-19 17:58:35 UTC): Nice!

"
2672562947,pull_request,closed,,Support connection extra parameters in MsSqlHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #43798 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-11-19 15:28:00+00:00,[],2024-11-23 14:49:37+00:00,2024-11-23 14:44:50+00:00,https://github.com/apache/airflow/pull/44190,"[('area:providers', ''), ('provider:microsoft-mssql', '')]","[{'comment_id': 2487002014, 'issue_id': 2672562947, 'author': 'jx2lee', 'body': '@shahar1 Static check was performed in different part of the code. Non-DB tests that failed are running fine locally—do I need to address something?', 'created_at': datetime.datetime(2024, 11, 19, 23, 52, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488752593, 'issue_id': 2672562947, 'author': 'jx2lee', 'body': ""Need to fix test code.. change PR to draft, I'll be back to when test code finished!"", 'created_at': datetime.datetime(2024, 11, 20, 14, 36, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493039763, 'issue_id': 2672562947, 'author': 'jx2lee', 'body': '@shahar1 I need help, is there any way to pass this test?\r\nhttps://github.com/apache/airflow/actions/runs/11965697415/job/33360361183?pr=44190', 'created_at': datetime.datetime(2024, 11, 22, 7, 20, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493066443, 'issue_id': 2672562947, 'author': 'shahar1', 'body': '> @shahar1 I need help, is there any way to pass this test? https://github.com/apache/airflow/actions/runs/11965697415/job/33360361183?pr=44190\r\n\r\nIt seems that it has to do with the the following definition in the tests:\r\n```python\r\nPYMSSQL_CONN = Connection(\r\n    conn_type=""mssql"", host=""ip"", schema=""share"", login=""username"", password=""password"", port=8081\r\n)\r\n```\r\n\r\nI assume that behind the scenes it initiates `PymssqlConnection(...)` with the `**extra_conn_args` that you just added, and now it fails all the tests that use it, as the `sqlalchemy` doesn\'t know how to handle the extra keys.\r\nDo you manage to reproduce the issue when you run the `breeze` command locally? Try to take a closer look on one of the failing tests and see what needs to be done with the extra params. I hope that it helps :)', 'created_at': datetime.datetime(2024, 11, 22, 7, 36, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2494448082, 'issue_id': 2672562947, 'author': 'jx2lee', 'body': '> > @shahar1 I need help, is there any way to pass this test? https://github.com/apache/airflow/actions/runs/11965697415/job/33360361183?pr=44190\r\n> \r\n> It seems that it has to do with the the following definition in the tests:\r\n> \r\n> ```python\r\n> PYMSSQL_CONN = Connection(\r\n>     conn_type=""mssql"", host=""ip"", schema=""share"", login=""username"", password=""password"", port=8081\r\n> )\r\n> ```\r\n> \r\n> I assume that behind the scenes it initiates `PymssqlConnection(...)` with the `**extra_conn_args` that you just added, and now it fails all the tests that use it, as the `sqlalchemy` doesn\'t know how to handle the extra keys. Do you manage to reproduce the issue when you run the `breeze` command locally? Try to take a closer look on one of the failing tests and see what needs to be done with the extra params. I hope that it helps :)\r\n\r\nis command right?\r\n`breeze testing providers-tests --use-xdist --skip-db-tests --no-db-cleanup --backend none --test-type \'Providers[microsoft]\'`\r\n\r\nTest was not broken in my local. below full logs\r\n\r\n<details>\r\n<summary>more..</summary>\r\n\r\n\r\n❯ breeze testing providers-tests --use-xdist --skip-db-tests --no-db-cleanup --backend none --test-type \'Providers[microsoft]\'\r\n\r\nBreeze dependencies changed since the installation!\r\n\r\nThis might cause various problems!!\r\n\r\nIf you experience problems - reinstall Breeze with:\r\n\r\n    breeze setup self-upgrade\r\n\r\nThis should usually take couple of seconds.\r\n\r\n\r\nReinstalling Breeze from /Users/jj/workspace/opensource/airflow/dev/breeze\r\n\r\nDocker image build is not needed for CI build as no important files are changed! You can add --force-build to force it\r\nGood version of Docker: 27.3.1.\r\nGood version of docker-compose: 2.29.7\r\nExecutable permissions on entrypoints are OK\r\n[+] Running 1/0\r\n ✔ Network airflow-test-providers_microsoft_default  Removed                                                                                                                                             0.1s \r\n[+] Creating 1/0\r\n ✔ Network airflow-test-providers_microsoft_default  Created                                                                                                                                             0.0s \r\n\r\nUsing \'uv\' to install Airflow\r\n\r\n\r\nUsing airflow version from current sources\r\n\r\n\r\nRunning Initialization. Your basic configuration is:\r\n\r\n  * Airflow home: /root/airflow\r\n  * Airflow sources: /opt/airflow\r\n  * Airflow core SQL connection: none-backend://\r\n\r\n\r\nChecking backend and integrations.\r\n\r\nWARNING: Using no database backend!\r\n\r\n\r\nUsing \'uv\' to install Airflow\r\n\r\n\r\nStarting the tests with those pytest arguments: providers/tests --verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes --junitxml=/files/test_result-providers_microsoft-none.xml --timeouts-order=moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 --disable-warnings -rfEX --skip-db-tests --ignore-glob=*/tests/system/* --ignore-glob=tests/integration/* --ignore-glob=providers/tests/integration/* --warning-output-path=/files/warnings-providers_microsoft-none.txt --ignore=helm_tests --with-db-init --ignore=providers/tests/cloudant --ignore=providers/tests/system/cloudant --ignore=providers/tests/integration/cloudant -n 8 --no-cov --no-db-cleanup\r\n\r\n============================= test session starts ==============================\r\nplatform linux -- Python 3.9.20, pytest-8.3.3, pluggy-1.5.0\r\nrootdir: /opt/airflow\r\nconfigfile: pyproject.toml\r\nplugins: rerunfailures-15.0, anyio-4.6.2.post1, xdist-3.6.1, mock-3.14.0, time-machine-2.16.0, icdiff-0.9, instafail-0.5.0, custom-exit-code-0.3.0, kgb-7.2, requests-mock-1.12.1, asyncio-0.24.0, cov-6.0.0, timeouts-1.2.1\r\nasyncio: mode=strict, default_loop_scope=function\r\nsetup timeout: 60.0s, execution timeout: 60.0s, teardown timeout: 60.0s\r\ncreated: 8/8 workers\r\n8 workers [14629 items]\r\n\r\nssssss.ss..s.s..s..s.ss.s.s...s.ss.s...s...ss...s...s................... [  0%]\r\n............s.....s.ss..s.s..s........................................s. [  0%]\r\ns..ss.......ss.......................................s..s......ssss.s.ss [  1%]\r\n..s..................................................................... [  1%]\r\n........................................................................ [  2%]\r\n........................................................................ [  2%]\r\n...................................................................s.... [  3%]\r\n........................................................................ [  3%]\r\n.............ssssssss.ssssss.sssssssssss.sssssssss.s....ssssss.sssssssss [  4%]\r\nss.ssssssssss.sss.ssss.sssssssssss.ssssssssssssssssss.ssssssssssssssssss [  4%]\r\nsssssssssssssssssssssss.........................................s....... [  5%]\r\n..............................................sss.s..................... [  5%]\r\n................................ssssss....s..ss......................... [  6%]\r\n..................s.s.s....................s.sss.ss..................... [  6%]\r\n................ssssssss....................ss....ssssssssssssssssss.... [  7%]\r\n..........................ssss.ssss.......................sssssssssssss. [  7%]\r\nssssssssssssss.ssss...s..........ssssssssssss......s.s.......ss.ssssssss [  8%]\r\nssss.....s.........ssssssssssss.sssssssss............................... [  8%]\r\n.s...................sssssssssssssssssssssssssssssssssssssssssssssssssss [  9%]\r\nsssssssssssssssssss.....................s..............sssssssssssssssss [  9%]\r\nsssssssssss.ssssssssss.sssssssssssssssssssssssssssssssssssssssssssssssss [ 10%]\r\nsss...sssssssssssssssssssss...sssssssssssssss.s......................... [ 10%]\r\n...............................ss.sssssssssssssss.ssss.sssssssssssssssss [ 11%]\r\nsssssssssssssss......................................................... [ 11%]\r\n........................................................................ [ 12%]\r\n..........................s.ss.......................................... [ 12%]\r\n.....................s.........s........................................ [ 13%]\r\n..................................................ssssssssssssss.sssssss [ 13%]\r\nsssssss....s.ss.........s......sss.......ss......sssssss.sss.s.....sssss [ 14%]\r\nsssssssssssssssssssssssssssssssssssssssssssssssssssssss.s..s.sss.....sss [ 14%]\r\nssssss.s...................ssss......sss.....sssssssssssssssssssssssssss [ 15%]\r\ns.ssssssssssssssssssssssssssssssssss..................................ss [ 15%]\r\nsssssssssssssssssssssssss............................s.................. [ 16%]\r\n...............s.ss.s.ss.ss.sss.ss.s....sss.ssssssssssssssss..sss.ssssss [ 16%]\r\nssssssssssssssssssssssssssssssssssssssssssssssssssssss.................. [ 17%]\r\n.........ss.ss.sssssss.sss.sss.ssssssssssss.sssss.s.ss.s.ss.ss.ss.s.sss. [ 17%]\r\nss.s.ss..sss..ss.s..s.s................................................. [ 18%]\r\n........................................................................ [ 18%]\r\n.............................................ssss....................... [ 19%]\r\n.........................ss.sssssssssssss.....s......................... [ 19%]\r\n.....ssssssssssss.sssssssssssssssssssssssss.ssssssssssss................ [ 20%]\r\nsss.ssssssssss............sss..s.ss..s.ss.ss.ss.s.ss.sssss.ss.sss.ss.s.s [ 20%]\r\ns.s.s.ss.ss.s.s.ssssssssssssssssssssssssssssssssssssssssssssssssssssssss [ 21%]\r\nsssssssssssssssssssss.sssssssssssssssssssss.sssssss.ss.ss.sssss.ssss.sss [ 21%]\r\n.sss.ssss.ss.sss.ss.sss.sss.ssss.ss.sss.s.sss.ss.ss.ss.sssss....s.ssssss [ 22%]\r\nsssssssssssssssssssssssssssssssss..s.ssssssssssssssssss...ss.ssss.ss.sss [ 22%]\r\nssssssssss.ssssssssssssssssssssssssssssssssssssssssssssss..ssssssss.ssss [ 23%]\r\n.ssssssssssssssssssssssssssssssssssssssssssssssssssss................... [ 23%]\r\nssssss.....................ssssss....................................... [ 24%]\r\n.............sssssssss.ssssssssssssssssssssssssssssssssssssss........... [ 24%]\r\n......sssssssssssssssssssssssssssssssssssssss......ss................... [ 25%]\r\n......s........ssss.ss...........................ssssssssssssssss....... [ 25%]\r\n.........ss......................................sssssssssss.sss........ [ 26%]\r\n......s.......s..................................................s.s.... [ 26%]\r\n......................................s.ss.s............................ [ 27%]\r\n........................................................................ [ 27%]\r\n........................................................................ [ 28%]\r\n..................................................sssssssssssssssssss.s. [ 28%]\r\n.........ss.sss.ss.sss.ss.ss.ssss.ss.sss.sss.sss.sss.ss.sss.sss.s.sss.ss [ 29%]\r\ns.s.s.ss.s.sss.ss.ss.sss.sss.sss.sss.ss................................. [ 29%]\r\n....ss.s.................ss...s.ss.s.s.s...ss.sss.ss.sss.sss.ss.sss.ss.s [ 30%]\r\ns.sss.sss.sss.ss.ss.ss.ss.s.s.sss.ss.sssssss.sssssssssss.ss.ss.ss.s.s... [ 30%]\r\n.......ss.ssss.sss.ssss.ssss.sss.ss.ss...ss.ss.sss.sss.sssss.ss.ssss.ss. [ 31%]\r\n.s..................s.s.s............................................... [ 31%]\r\n.........ssssssssssssss.sssss.sss.ss.sss.sssssssssssssssssss............ [ 31%]\r\n...............................................................ssssss... [ 32%]\r\n....s.......ssssssssssssssss............................................ [ 32%]\r\n........................................................................ [ 33%]\r\n..........................................................s............. [ 33%]\r\n.............................................................sss........ [ 34%]\r\n........................................................................ [ 34%]\r\n.......................................................s................ [ 35%]\r\n.................................s...................................... [ 35%]\r\n...s......F............................................................. [ 36%]\r\n..............................ss.s.ss.ss.s.s.ssss.sssssss.s............. [ 36%]\r\n........................................................................ [ 37%]\r\n........................................................................ [ 37%]\r\n.........................................s.............................. [ 38%]\r\n........................................................................ [ 38%]\r\n...............................................sssssssssss.............. [ 39%]\r\n............................................................sss......... [ 39%]\r\n.............s...s.s..s....s...s...s....s....s..s.....s...s....s.....ss. [ 40%]\r\ns.s.ss.ssss.ssss.ss.s.ss.sss.sss..ss.sssss.ss.ss.ss.ssss.ss.sss.ss.sss.s [ 40%]\r\ns.sss.ssss..sss.s.sssss.sss.ssss.ss.ss.ss.s.ssss.sssssssssssssssssss.sss [ 41%]\r\nsss.sssss............................................................... [ 41%]\r\n......................................s......s.......s.......s.......... [ 42%]\r\n........................................................................ [ 42%]\r\nss.ss.ssssss.sss.s.ss.s..........s..s.sssssssssssssssssssss............. [ 43%]\r\n........................................................s............... [ 43%]\r\n.................s...s.............................s......s...ss........ [ 44%]\r\n...........................................s......s........s.s.s.ss.s... [ 44%]\r\n...........s..............s.................s.............s...........s. [ 45%]\r\ns....................................................................... [ 45%]\r\n............ss.................................................s...s...s [ 46%]\r\n.....s....s.....s...s....s......s.....s............s.................sss [ 46%]\r\ns.sss..s.ss.ss.s...ss................................................... [ 47%]\r\n..............................s.ss................s...................ss [ 47%]\r\n.sss.s.ss.ss.ss......................................................... [ 48%]\r\n.............................................s...ss.sss.ss.ss.sss.ss.sss [ 48%]\r\n.ss.ss.ss.sss.sss.ss.sss.ssss.sssss.sssss.sss.s.ss.ss.s.sss.ss.s.s.s.ss. [ 49%]\r\n.sss..ss.s.ss.s.ss.s..ss.s.ss.s.ss.s.s.s.s.s.s.ss..ss.s.s.ss..ss..ss..ss [ 49%]\r\n.s.s.s.ss................................................ss.ss.s....ssss [ 50%]\r\nsssss.......s.ss.sss.ss..s.............................................. [ 50%]\r\ns.ssss....ssssssssssssssssssssssssssss.ssss.ss.ss.sss.sss.sss.sss.ss.sss [ 51%]\r\n.sss.sss.s.sssss.ss.sssss.ssss.ss.s.sss.sss.s.ss.sss.ssss.ssss.ss....... [ 51%]\r\n..........................................ss.sssss........s............. [ 52%]\r\n.sss.ss.sss.ssss.sss.ssss.sss.s.............s.sssss.sssss.ss.ss......... [ 52%]\r\n........................................sss.........s................sss [ 53%]\r\nss.s.ss.ssssssssssss....................s........................s...... [ 53%]\r\n..................................................ss..........s......... [ 54%]\r\n......sssss.s.ss........ss.........................................ss.ss [ 54%]\r\n.ss.ss.sss.sss.s.sss.sss.sss.ss.s.s.s.ss.ss...................s......... [ 55%]\r\n..............ss.s...................................................... [ 55%]\r\n.............s..........................................s............... [ 56%]\r\n.........................................................s...........s.. [ 56%]\r\n.............................s................s...........s...........s. [ 57%]\r\n..................s.....s......s...s..s...s..s.........s....ss.s.ss.ssss [ 57%]\r\n.ss.ss.ss.ss.ss...............ss.ss.ss.s.s...s.......................... [ 58%]\r\n.........................................................s.sss.s.ss.sss. [ 58%]\r\nsss.ssss.s.sssss.ss.sssss............................................... [ 59%]\r\n.......................................................................F [ 59%]\r\n............................sss........................ssss............. [ 60%]\r\n.............................................................ssss.s..... [ 60%]\r\n.....ssssss............sss...................ssssss.sss.sss.ssss........ [ 61%]\r\n........................................................................ [ 61%]\r\n.............F.....ssssss.ssss.......................................... [ 62%]\r\n................................................................ss.sss.. [ 62%]\r\n...sss.ss............................................................... [ 62%]\r\n.................................................................ss..... [ 63%]\r\n...............s.sss.ss..s.............................................. [ 63%]\r\n........................................................................ [ 64%]\r\n......................................................................ss [ 64%]\r\nsssssssssss........................................................sssss [ 65%]\r\n.ss.s......................F..............................ss..ssssssssss [ 65%]\r\n.........s...................................................ssssssss..s [ 66%]\r\nsssssssssssssssssssssssssssss.............................F............. [ 66%]\r\n................ss.sssssss.sss.ssss.ss.sss.sss.sss.ss.sss.ss.sss.ss.ssss [ 67%]\r\n.ss.s.sss.s.ss.sss..ssss.sssssss.sssssssss.ss.sss.sssss.ssssssss........ [ 67%]\r\ns.............................s......................................... [ 68%]\r\n.........ssss........................................................... [ 68%]\r\n...............s.ss..........ss.s.ss.s.ss.ss.ss.s.s.s.ss.s.s............ [ 69%]\r\n.............................................ss.ss.ss.ss.ss.s.ss.ss.ss.s [ 69%]\r\n.s.ss.s.ss.s.ss.s.sss.s............s.ss.ss.ss.ss.s.s.ss.ss..s.ss.ss.s.ss [ 70%]\r\n.ss.s.ss.ss...............ss.ss.ss.s.ss.ss..ss.......s............s..... [ 70%]\r\n..............s..................................................s...s.s [ 71%]\r\ns.s.ss..s.s.s..ss..s.s..ss.............................s................ [ 71%]\r\n................................ss.s..sss..ss.ss.s.ss...sss..s.s..ss.s.. [ 72%]\r\ns..ss...ssss..s.s.s.ss.s.s..s.s..s...s.s..s.ss..s.s.s.s..ss..sFs.s.s.s.. [ 72%]\r\n..........s.s.s..ss...s..sss.s.ssssss..ss.s.ss.s.s.ssss.s............... [ 73%]\r\n.....................................................................ss. [ 73%]\r\ns.ss..s.sss.s.ss..ssss........sssss...............ss............s..s.... [ 74%]\r\n....sssssssss.........s....sss...s....s......ss.sss.ssss..sssssssss.sss. [ 74%]\r\nss.ss..sssss.s.s.ss..ss.s.s....s..ss.s.s...ssssss.ss.ssss.ssssssssssssss [ 75%]\r\ns.sss.ss................................................s.s.s..sss..s.s. [ 75%]\r\n.ss.ssss.sss.sssss.ssss..s.s.ssssss..ssss.s.sssss.ss..ss.s..ss.s..s...s. [ 76%]\r\n.s..........s...........................ss...s.s.s..s.....s..s.s..s..ss. [ 76%]\r\n.s...s..s.s.s..............................s..sss.s.s.s.s.s.s.s.ss...... [ 77%]\r\n........................................................................ [ 77%]\r\n........................................................................ [ 78%]\r\n........................................................................ [ 78%]\r\n.....................................s.s.ss.s.ss.sss.ss.s............... [ 79%]\r\n........................................................................ [ 79%]\r\n........................................................................ [ 80%]\r\n........................................................................ [ 80%]\r\n........................................................................ [ 81%]\r\n.................s..s.s.s.s.s.s.s....................................... [ 81%]\r\n........................................................................ [ 82%]\r\n........................................................................ [ 82%]\r\n........................................................................ [ 83%]\r\n........................................................................ [ 83%]\r\n........................................................................ [ 84%]\r\n........................................................................ [ 84%]\r\n......................s..ss..ss.s....................................... [ 85%]\r\n..s....s.s...s...s.s..s.s.s..s.s.s..s........s.s.ss.ss.sss..s.sss.sss..s [ 85%]\r\nsss.ssssssssssss.s.s.s.s.s.s.s.......................................... [ 86%]\r\n.s..................................ss.ss.s.s.s.ss..s.s.ss.s.ss.sss.ss.s [ 86%]\r\ns.sssss..ssss..s.sss..s.ss.s..ss..s.ss..ssss..s.sss...ss.s.s.ss..sss.sss [ 87%]\r\n.sss.ss.s.sss..sss..ss.ss..ss.s..ss..s.s.s..ss...ss..s..s.s..ss..s.s.s.s [ 87%]\r\n..s.ss.ss.ss.sss..ssss.................................................. [ 88%]\r\n.......s.ss..s.ss.sss..sss.s.ss..ss..sss.sss.ss.s.ss..s.ss.ssss.sss.ss.s [ 88%]\r\nsssssssssssssssssssss.ssss.ssssssssssssssssss.s.ssssssssssssssssssssssss [ 89%]\r\n.ssss.sssssssssssssssss.sssss.sssssssssssssss.sssssssssssssss.ssssssssss [ 89%]\r\nsssssssssssssssss.sssssssssssssssssssssssssssss.ssssssssssssssssssssssss [ 90%]\r\nssssssss.ssssssssssssssssssssssssssssssss.ssssssssssssssssssssssssssssss [ 90%]\r\nsssssss.sssssssssssssssssssssssssssssssss.sssss.ssss.ssss.ssss.sss.ss..s [ 91%]\r\nssssss.ssss.ssss.s..................ss.sss.sss.ssss.ss.s.ssss.ssssss.sss [ 91%]\r\nsss.ssssss.ss.ss........................................................ [ 92%]\r\n........................................................................ [ 92%]\r\n...............................................ss...s.........ss..s.s.s. [ 93%]\r\ns.ss..ss.s.s....................................................s....... [ 93%]\r\n.sssss.s..........ssssssssssssssssssssssssssssssssssssssssssssssssssssss [ 94%]\r\nsssssssssssssssssssssssssss............s................................ [ 94%]\r\n...........sssssssssss.......ssss.......s........s....ssss.........sssss [ 94%]\r\nssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss.ss.ss [ 95%]\r\nsss.sss.ssss.ssss.ssss.sssss.sss.ssss.ssss.ss........................... [ 95%]\r\n............................ss.......................................... [ 96%]\r\n.....................................................ssss......sssssssss [ 96%]\r\nsssssss..sssssssssssssss....ssssssssssssssssssssssssssssssssssssssssssss [ 97%]\r\nssssssssssssssssss..........s..........sssssss...............s........ss [ 97%]\r\n........................................................................ [ 98%]\r\n..........................s.s........................................... [ 98%]\r\n.......................................s...s...........................s [ 99%]\r\n........................................................................ [ 99%]\r\n.............                                                            [100%]\r\n=================================== FAILURES ===================================\r\n______________ TestEC2RebootInstanceOperator.test_reboot_instance ______________\r\n[gw3] linux -- Python 3.9.20 /usr/local/bin/python\r\nproviders/tests/amazon/aws/operators/test_ec2.py:385: in test_reboot_instance\r\n    image_id=self._get_image_id(ec2_hook),\r\nproviders/tests/amazon/aws/operators/test_ec2.py:48: in _get_image_id\r\n    images = ec2_client.describe_images()[""Images""]\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:569: in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:1005: in _make_api_call\r\n    http, parsed_response = self._make_request(\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:1029: in _make_request\r\n    return self._endpoint.make_request(operation_model, request_dict)\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:119: in make_request\r\n    return self._send_request(request_dict, operation_model)\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:197: in _send_request\r\n    success_response, exception = self._get_response(\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:239: in _get_response\r\n    success_response, exception = self._do_get_response(\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:276: in _do_get_response\r\n    responses = self._event_emitter.emit(event_name, request=request)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:412: in emit\r\n    return self._emitter.emit(aliased_event_name, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:256: in emit\r\n    return self._emit(event_name, kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:239: in _emit\r\n    response = handler(**kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:38: in __call__\r\n    response = self.process_request(request)\r\n/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:88: in process_request\r\n    status, headers, body = method_to_execute(\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:291: in dispatch\r\n    return cls()._dispatch(*args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:503: in _dispatch\r\n    return self.call_action()\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:591: in call_action\r\n    response = method()\r\n/usr/local/lib/python3.9/site-packages/moto/ec2/responses/amis.py:56: in describe_images\r\n    return template.render(images=images)\r\n/usr/local/lib/python3.9/site-packages/jinja2/environment.py:1302: in render\r\n    return self.environment.concat(self.root_render_func(ctx))  # type: ignore\r\n<template>:55: in root\r\n    ???\r\n/usr/local/lib/python3.9/site-packages/jinja2/runtime.py:303: in call\r\n    return __obj(*args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/ec2/models/core.py:12: in get_tags\r\n    tags = self.ec2_backend.describe_tags(filters={""resource-id"": [self.id]})  # type: ignore[attr-defined]\r\n/usr/local/lib/python3.9/site-packages/moto/ec2/models/tags.py:76: in describe_tags\r\n    re.compile(simple_aws_filter_to_re(value))\r\n/usr/local/lib/python3.9/re.py:252: in compile\r\n    return _compile(pattern, flags)\r\n/usr/local/lib/python3.9/re.py:304: in _compile\r\n    p = sre_compile.compile(pattern, flags)\r\n/usr/local/lib/python3.9/sre_compile.py:806: in compile\r\n    p.state.groups-1,\r\nE   Failed: Timeout >60.0s\r\n----------------------------- Captured stdout call -----------------------------\r\n[2024-11-22T14:29:34.070+0000] {base.py:66} INFO - Retrieving connection \'aws_default\'\r\n[2024-11-22T14:29:36.936+0000] {credentials.py:1147} INFO - Found credentials in environment variables.\r\n------------------------------ Captured log call -------------------------------\r\nINFO     airflow.hooks.base:base.py:66 Retrieving connection \'aws_default\'\r\nINFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.\r\n_____________ TestEksHooks.test_list_clusters_returns_all_results ______________\r\n[gw1] linux -- Python 3.9.20 /usr/local/bin/python\r\nproviders/tests/amazon/aws/hooks/test_eks.py:255: in test_list_clusters_returns_all_results\r\n    eks_hook, generated_test_data = cluster_builder(count=initial_batch_size)\r\nproviders/tests/amazon/aws/hooks/test_eks.py:129: in _execute\r\n    return eks_hook, ClusterTestDataFactory(count=count, minimal=minimal)\r\nproviders/tests/amazon/aws/hooks/test_eks.py:111: in __init__\r\n    self.cluster_names: list[str] = generate_clusters(\r\nproviders/tests/amazon/aws/utils/eks_test_utils.py:96: in generate_clusters\r\n    return [\r\nproviders/tests/amazon/aws/utils/eks_test_utils.py:97: in <listcomp>\r\n    eks_hook.create_cluster(name=f""cluster{count}"", **_input_builder(ClusterInputs, minimal))[\r\nproviders/src/airflow/providers/amazon/aws/hooks/eks.py:138: in create_cluster\r\n    response = eks_client.create_cluster(\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:569: in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:1005: in _make_api_call\r\n    http, parsed_response = self._make_request(\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:1029: in _make_request\r\n    return self._endpoint.make_request(operation_model, request_dict)\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:119: in make_request\r\n    return self._send_request(request_dict, operation_model)\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:197: in _send_request\r\n    success_response, exception = self._get_response(\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:239: in _get_response\r\n    success_response, exception = self._do_get_response(\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:276: in _do_get_response\r\n    responses = self._event_emitter.emit(event_name, request=request)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:412: in emit\r\n    return self._emitter.emit(aliased_event_name, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:256: in emit\r\n    return self._emit(event_name, kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:239: in _emit\r\n    response = handler(**kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:38: in __call__\r\n    response = self.process_request(request)\r\n/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:88: in process_request\r\n    status, headers, body = method_to_execute(\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:291: in dispatch\r\n    return cls()._dispatch(*args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:503: in _dispatch\r\n    return self.call_action()\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:591: in call_action\r\n    response = method()\r\n/usr/local/lib/python3.9/site-packages/moto/eks/responses.py:33: in create_cluster\r\n    cluster = self.eks_backend.create_cluster(\r\n/usr/local/lib/python3.9/site-packages/moto/eks/models.py:360: in create_cluster\r\n    validate_role_arn(role_arn)\r\n/usr/local/lib/python3.9/site-packages/moto/eks/utils.py:45: in validate_role_arn\r\n    valid_partition = match.group(""partition"") in Session().get_available_partitions()  # type: ignore\r\n/usr/local/lib/python3.9/site-packages/boto3/session.py:160: in get_available_partitions\r\n    return self._session.get_available_partitions()\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:1078: in get_available_partitions\r\n    resolver = self._get_internal_component(\'endpoint_resolver\')\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:818: in _get_internal_component\r\n    return self._internal_components.get_component(name)\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:1140: in get_component\r\n    self._components[name] = factory()\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:205: in create_default_resolver\r\n    endpoints, path = loader.load_data_with_path(\'endpoints\')\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper\r\n    data = func(self, *args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path\r\n    found = self.file_loader.load_file(possible_path)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file\r\n    data = self._load_file(file_path + ext, open_method)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file\r\n    return json.loads(payload, object_pairs_hook=OrderedDict)\r\n/usr/local/lib/python3.9/json/__init__.py:359: in loads\r\n    return cls(**kw).decode(s)\r\n/usr/local/lib/python3.9/json/decoder.py:337: in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\nE   Failed: Timeout >60.0s\r\n----------------------------- Captured stdout call -----------------------------\r\n[2024-11-22T14:31:21.322+0000] {base.py:66} INFO - Retrieving connection \'aws_default\'\r\n[2024-11-22T14:31:24.432+0000] {credentials.py:1147} INFO - Found credentials in environment variables.\r\n[2024-11-22T14:31:25.001+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster0.\r\n[2024-11-22T14:31:25.130+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster1.\r\n[2024-11-22T14:31:25.274+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster2.\r\n[2024-11-22T14:31:25.395+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster3.\r\n[2024-11-22T14:31:25.518+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster4.\r\n[2024-11-22T14:31:25.649+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster5.\r\n[2024-11-22T14:31:25.814+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster6.\r\n[2024-11-22T14:31:25.968+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster7.\r\n[2024-11-22T14:31:26.113+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster8.\r\n[2024-11-22T14:31:26.269+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster9.\r\n[2024-11-22T14:31:26.425+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster10.\r\n[2024-11-22T14:31:26.602+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster11.\r\n[2024-11-22T14:31:26.794+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster12.\r\n[2024-11-22T14:31:26.942+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster13.\r\n[2024-11-22T14:31:27.093+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster14.\r\n[2024-11-22T14:31:27.309+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster15.\r\n[2024-11-22T14:31:27.478+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster16.\r\n[2024-11-22T14:31:27.659+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster17.\r\n[2024-11-22T14:31:27.836+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster18.\r\n[2024-11-22T14:31:28.082+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster19.\r\n[2024-11-22T14:31:28.454+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster20.\r\n[2024-11-22T14:31:28.726+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster21.\r\n[2024-11-22T14:31:28.931+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster22.\r\n[2024-11-22T14:31:29.170+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster23.\r\n------------------------------ Captured log call -------------------------------\r\nINFO     airflow.hooks.base:base.py:66 Retrieving connection \'aws_default\'\r\nINFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster0.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster1.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster2.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster3.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster4.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster5.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster6.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster7.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster8.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster9.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster10.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster11.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster12.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster13.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster14.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster15.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster16.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster17.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster18.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster19.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster20.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster21.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster22.\r\nINFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster23.\r\n____________ TestSqsPublishOperator.test_execute_failure_fifo_queue ____________\r\n[gw4] linux -- Python 3.9.20 /usr/local/bin/python\r\nproviders/tests/amazon/aws/operators/test_sqs.py:104: in test_execute_failure_fifo_queue\r\n    op.execute(mocked_context)\r\nairflow/models/baseoperator.py:376: in wrapper\r\n    return func(self, *args, **kwargs)\r\nproviders/src/airflow/providers/amazon/aws/operators/sqs.py:94: in execute\r\n    result = self.hook.send_message(\r\nproviders/src/airflow/providers/amazon/aws/hooks/sqs.py:85: in send_message\r\n    return self.get_conn().send_message(**params)\r\nproviders/src/airflow/providers/amazon/aws/hooks/base_aws.py:783: in get_conn\r\n    return self.conn\r\n/usr/local/lib/python3.9/functools.py:993: in __get__\r\n    val = self.func(instance)\r\nproviders/src/airflow/providers/amazon/aws/hooks/base_aws.py:740: in conn\r\n    return self.get_client_type(region_name=self.region_name)\r\nproviders/src/airflow/providers/amazon/aws/hooks/base_aws.py:710: in get_client_type\r\n    return session.client(\r\n/usr/local/lib/python3.9/site-packages/boto3/session.py:297: in client\r\n    return self._session.create_client(\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:959: in create_client\r\n    endpoint_resolver = self._get_internal_component(\'endpoint_resolver\')\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:818: in _get_internal_component\r\n    return self._internal_components.get_component(name)\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:1140: in get_component\r\n    self._components[name] = factory()\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:205: in create_default_resolver\r\n    endpoints, path = loader.load_data_with_path(\'endpoints\')\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper\r\n    data = func(self, *args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path\r\n    found = self.file_loader.load_file(possible_path)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file\r\n    data = self._load_file(file_path + ext, open_method)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file\r\n    return json.loads(payload, object_pairs_hook=OrderedDict)\r\n/usr/local/lib/python3.9/json/__init__.py:359: in loads\r\n    return cls(**kw).decode(s)\r\n/usr/local/lib/python3.9/json/decoder.py:337: in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\nE   Failed: Timeout >60.0s\r\n---------------------------- Captured stdout setup -----------------------------\r\n[2024-11-22T14:31:59.676+0000] {base_aws.py:177} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name=\'eu-west-1\'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\r\n[2024-11-22T14:32:00.853+0000] {credentials.py:1147} INFO - Found credentials in environment variables.\r\n------------------------------ Captured log setup ------------------------------\r\nINFO     airflow.providers.amazon.aws.hooks.base_aws.BaseSessionFactory:base_aws.py:177 No connection ID provided. Fallback on boto3 credential strategy (region_name=\'eu-west-1\'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\r\nINFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.\r\n----------------------------- Captured stdout call -----------------------------\r\n[2024-11-22T14:32:01.590+0000] {base_aws.py:177} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name=\'eu-west-1\'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\r\n[2024-11-22T14:32:04.005+0000] {credentials.py:1147} INFO - Found credentials in environment variables.\r\n------------------------------ Captured log call -------------------------------\r\nINFO     airflow.providers.amazon.aws.hooks.base_aws.BaseSessionFactory:base_aws.py:177 No connection ID provided. Fallback on boto3 credential strategy (region_name=\'eu-west-1\'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\r\nINFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.\r\n_______________________ TestGCSToS3Operator.test_execute _______________________\r\n[gw5] linux -- Python 3.9.20 /usr/local/bin/python\r\nproviders/tests/amazon/aws/transfers/test_gcs_to_s3.py:182: in test_execute\r\n    hook, _ = _create_test_bucket()\r\nproviders/tests/amazon/aws/transfers/test_gcs_to_s3.py:44: in _create_test_bucket\r\n    bucket = hook.get_bucket(""bucket"")\r\nproviders/src/airflow/providers/amazon/aws/hooks/s3.py:125: in wrapper\r\n    return func(*bound_args.args, **bound_args.kwargs)\r\nproviders/src/airflow/providers/amazon/aws/hooks/s3.py:335: in get_bucket\r\n    return self.resource.Bucket(bucket_name)\r\n/usr/local/lib/python3.9/functools.py:993: in __get__\r\n    val = self.func(instance)\r\nproviders/src/airflow/providers/amazon/aws/hooks/s3.py:208: in resource\r\n    return self.get_session().resource(\r\n/usr/local/lib/python3.9/site-packages/boto3/session.py:394: in resource\r\n    resource_model = self._loader.load_service_model(\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper\r\n    data = func(self, *args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:418: in load_service_model\r\n    model = self.load_data(full_path)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:472: in load_data\r\n    data, _ = self.load_data_with_path(name)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper\r\n    data = func(self, *args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path\r\n    found = self.file_loader.load_file(possible_path)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file\r\n    data = self._load_file(file_path + ext, open_method)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file\r\n    return json.loads(payload, object_pairs_hook=OrderedDict)\r\n/usr/local/lib/python3.9/json/__init__.py:359: in loads\r\n    return cls(**kw).decode(s)\r\n/usr/local/lib/python3.9/json/decoder.py:337: in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\nE   Failed: Timeout >60.0s\r\n----------------------------- Captured stdout call -----------------------------\r\n[2024-11-22T14:32:38.330+0000] {base_aws.py:177} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name=None). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\r\n------------------------------ Captured log call -------------------------------\r\nINFO     airflow.providers.amazon.aws.hooks.base_aws.BaseSessionFactory:base_aws.py:177 No connection ID provided. Fallback on boto3 credential strategy (region_name=None). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html\r\n__________ TestVaultClient.test_kubernetes_different_auth_mount_point __________\r\n[gw3] linux -- Python 3.9.20 /usr/local/bin/python\r\nproviders/tests/hashicorp/_internal_client/test_vault_client.py:404: in test_kubernetes_different_auth_mount_point\r\n    client = vault_client.client\r\nproviders/src/airflow/providers/hashicorp/_internal_client/vault_client.py:187: in client\r\n    if not self._client.is_authenticated():\r\n/usr/local/lib/python3.9/functools.py:993: in __get__\r\n    val = self.func(instance)\r\nproviders/src/airflow/providers/hashicorp/_internal_client/vault_client.py:243: in _client\r\n    if _client.is_authenticated():\r\n/usr/local/lib/python3.9/unittest/mock.py:1092: in __call__\r\n    return self._mock_call(*args, **kwargs)\r\n/usr/local/lib/python3.9/unittest/mock.py:1096: in _mock_call\r\n    return self._execute_mock_call(*args, **kwargs)\r\n/usr/local/lib/python3.9/unittest/mock.py:1168: in _execute_mock_call\r\n    return self.return_value\r\n/usr/local/lib/python3.9/unittest/mock.py:519: in __get_return_value\r\n    ret = self._get_child_mock(\r\n/usr/local/lib/python3.9/unittest/mock.py:1018: in _get_child_mock\r\n    return klass(**kw)\r\n/usr/local/lib/python3.9/unittest/mock.py:2033: in __init__\r\n    self._mock_set_magics()  # make magic work for kwargs in init\r\n/usr/local/lib/python3.9/unittest/mock.py:2058: in _mock_set_magics\r\n    setattr(_type, entry, MagicProxy(entry, self))\r\n/usr/local/lib/python3.9/unittest/mock.py:2104: in __init__\r\n    self.name = name\r\nE   Failed: Timeout >60.0s\r\n___________ TestEksHooks.test_delete_cluster_returns_deleted_cluster ___________\r\n[gw1] linux -- Python 3.9.20 /usr/local/bin/python\r\nproviders/tests/amazon/aws/hooks/test_eks.py:352: in test_delete_cluster_returns_deleted_cluster\r\n    eks_hook, generated_test_data = cluster_builder(count=initial_batch_size, minimal=False)\r\nproviders/tests/amazon/aws/hooks/test_eks.py:129: in _execute\r\n    return eks_hook, ClusterTestDataFactory(count=count, minimal=minimal)\r\nproviders/tests/amazon/aws/hooks/test_eks.py:111: in __init__\r\n    self.cluster_names: list[str] = generate_clusters(\r\nproviders/tests/amazon/aws/utils/eks_test_utils.py:96: in generate_clusters\r\n    return [\r\nproviders/tests/amazon/aws/utils/eks_test_utils.py:97: in <listcomp>\r\n    eks_hook.create_cluster(name=f""cluster{count}"", **_input_builder(ClusterInputs, minimal))[\r\nproviders/src/airflow/providers/amazon/aws/hooks/eks.py:138: in create_cluster\r\n    response = eks_client.create_cluster(\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:569: in _api_call\r\n    return self._make_api_call(operation_name, kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:1005: in _make_api_call\r\n    http, parsed_response = self._make_request(\r\n/usr/local/lib/python3.9/site-packages/botocore/client.py:1029: in _make_request\r\n    return self._endpoint.make_request(operation_model, request_dict)\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:119: in make_request\r\n    return self._send_request(request_dict, operation_model)\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:197: in _send_request\r\n    success_response, exception = self._get_response(\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:239: in _get_response\r\n    success_response, exception = self._do_get_response(\r\n/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:276: in _do_get_response\r\n    responses = self._event_emitter.emit(event_name, request=request)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:412: in emit\r\n    return self._emitter.emit(aliased_event_name, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:256: in emit\r\n    return self._emit(event_name, kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/hooks.py:239: in _emit\r\n    response = handler(**kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:38: in __call__\r\n    response = self.process_request(request)\r\n/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:88: in process_request\r\n    status, headers, body = method_to_execute(\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:291: in dispatch\r\n    return cls()._dispatch(*args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:503: in _dispatch\r\n    return self.call_action()\r\n/usr/local/lib/python3.9/site-packages/moto/core/responses.py:591: in call_action\r\n    response = method()\r\n/usr/local/lib/python3.9/site-packages/moto/eks/responses.py:33: in create_cluster\r\n    cluster = self.eks_backend.create_cluster(\r\n/usr/local/lib/python3.9/site-packages/moto/eks/models.py:360: in create_cluster\r\n    validate_role_arn(role_arn)\r\n/usr/local/lib/python3.9/site-packages/moto/eks/utils.py:45: in validate_role_arn\r\n    valid_partition = match.group(""partition"") in Session().get_available_partitions()  # type: ignore\r\n/usr/local/lib/python3.9/site-packages/boto3/session.py:160: in get_available_partitions\r\n    return self._session.get_available_partitions()\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:1078: in get_available_partitions\r\n    resolver = self._get_internal_component(\'endpoint_resolver\')\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:818: in _get_internal_component\r\n    return self._internal_components.get_component(name)\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:1140: in get_component\r\n    self._components[name] = factory()\r\n/usr/local/lib/python3.9/site-packages/botocore/session.py:205: in create_default_resolver\r\n    endpoints, path = loader.load_data_with_path(\'endpoints\')\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper\r\n    data = func(self, *args, **kwargs)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path\r\n    found = self.file_loader.load_file(possible_path)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file\r\n    data = self._load_file(file_path + ext, open_method)\r\n/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file\r\n    return json.loads(payload, object_pairs_hook=OrderedDict)\r\n/usr/local/lib/python3.9/json/__init__.py:359: in loads\r\n    return cls(**kw).decode(s)\r\n/usr/local/lib/python3.9/json/decoder.py:337: in decode\r\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\r\n/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode\r\n    obj, end = self.scan_once(s, idx)\r\nE   Failed: Timeout >60.0s\r\n----------------------------- Captured stdout call -----------------------------\r\n[2024-11-22T14:33:28.248+0000] {base.py:66} INFO - Retrieving connection \'aws_default\'\r\n[2024-11-22T14:33:30.631+0000] {credentials.py:1147} INFO - Found credentials in environment variables.\r\n------------------------------ Captured log call -------------------------------\r\nINFO     airflow.hooks.base:base.py:66 Retrieving connection \'aws_default\'\r\nINFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.\r\n----- generated xml file: /files/test_result-providers_microsoft-none.xml ------\r\n============================ slowest 100 durations =============================\r\n127.15s call     providers/tests/hashicorp/hooks/test_vault.py::TestConfigurationFromSecrets::test_config_from_secret_backend\r\n92.37s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_clusters_returns_all_results\r\n87.82s call     providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute\r\n85.34s call     providers/tests/google/cloud/transfers/test_gcs_to_bigquery.py::TestGCSToBigQueryOperator::test_get_openlineage_facets_on_complete_empty_table\r\n78.49s call     providers/tests/google/cloud/hooks/test_life_sciences.py::TestLifeSciencesHookWithPassedProjectId::test_run_pipeline_immediately_complete\r\n77.77s call     providers/tests/amazon/aws/operators/test_sqs.py::TestSqsPublishOperator::test_execute_failure_fifo_queue\r\n75.57s call     providers/tests/neo4j/hooks/test_neo4j.py::TestNeo4jHookConn::test_run_without_schema\r\n75.37s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_delete_cluster_returns_deleted_cluster\r\n65.54s setup    providers/tests/google/cloud/hooks/test_dataproc.py::TestDataProcJobBuilder::test_set_python_main\r\n64.01s call     providers/tests/hashicorp/_internal_client/test_vault_client.py::TestVaultClient::test_kubernetes_different_auth_mount_point\r\n60.31s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2RebootInstanceOperator::test_reboot_instance\r\n59.29s setup    providers/tests/amazon/aws/sensors/test_cloud_formation.py::TestCloudFormationDeleteStackSensor::test_poke\r\n57.40s call     providers/tests/amazon/aws/hooks/test_ses.py::test_send_email[bcc@domain.com-cc1-to@domain.com]\r\n55.82s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_hook\r\n54.36s setup    providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_nodegroups_returns_all_results\r\n53.63s call     providers/tests/amazon/aws/hooks/test_base_aws.py::TestAwsBaseHook::test_connection_region_name[aws://?-None-us-gov-east-1-us-gov-east-1-resource]\r\n52.18s call     providers/tests/amazon/aws/waiters/test_kinesis_analytics.py::TestKinesisAnalyticsV2CustomWaiters::test_service_waiters\r\n50.72s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_put_bucket_tagging_with_pair\r\n50.45s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3DeleteObjectsOperator::test_s3_delete_from_to_datetime\r\n50.25s setup    providers/tests/amazon/aws/hooks/test_datasync.py::TestDataSyncHookMocked::test_init\r\n50.25s call     providers/tests/amazon/aws/transfers/test_s3_to_dynamodb.py::TestS3ToDynamoDBOperator::test_s3_to_dynamodb_new_table_job_startup_error\r\n49.60s call     providers/tests/amazon/aws/hooks/test_ec2.py::TestEC2Hook::test_get_instance_state\r\n49.35s call     providers/tests/amazon/aws/executors/batch/test_batch_executor.py::TestAwsBatchExecutor::test_start_health_check_config\r\n49.15s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_delete_bucket_if_bucket_not_exist\r\n48.34s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2TerminateInstanceOperator::test_terminate_instance\r\n48.23s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_hibernate_instance\r\n47.61s call     providers/tests/amazon/aws/operators/test_eks.py::TestEksDeleteClusterOperator::test_existing_cluster_not_in_use_with_wait\r\n47.51s call     providers/tests/amazon/aws/sensors/test_ec2.py::TestEC2InstanceStateSensor::test_terminated\r\n47.18s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_transform_script\r\n46.08s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCopyDbSnapshotOperator::test_copy_db_cluster_snapshot_no_wait\r\n45.55s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_incremental_file_upload_without_replace\r\n44.08s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCreateDbInstanceOperator::test_create_db_instance\r\n43.95s setup    providers/tests/amazon/aws/hooks/test_datasync.py::TestDataSyncHookMocked::test_cancel_task_execution\r\n42.60s setup    providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_get_key\r\n42.59s setup    providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_list_prefixes\r\n42.38s call     providers/tests/amazon/aws/hooks/test_ses.py::test_send_email[bcc1@domain.com,bcc2@domain.com-cc1@domain.com,cc2@domain.com-to1@domain.com,to2@domain.com]\r\n40.44s call     providers/tests/amazon/aws/sensors/test_sqs.py::TestSqsSensor::test_poke_message_invalid_filtering\r\n37.79s call     providers/tests/amazon/aws/sensors/test_redshift_cluster.py::TestRedshiftClusterSensor::test_poke\r\n36.58s setup    providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_load_bytes\r\n36.52s teardown providers/tests/amazon/aws/operators/test_datasync.py::TestDataSyncOperatorDelete::test_init\r\n34.92s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_nodegroups_returns_all_results\r\n34.08s call     providers/tests/amazon/aws/hooks/test_base_aws.py::TestAwsBaseHook::test_user_agent_caller_target_function_found[found_classes0]\r\n30.76s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_read_pod_logs_retries_fails\r\n30.71s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_monitor_pod_logs_failures_non_fatal\r\n30.40s teardown providers/tests/amazon/aws/operators/test_datasync.py::TestDataSyncOperatorGetTasks::test_init_fails\r\n24.32s call     providers/tests/apache/beam/hooks/test_beam.py::TestBeamAsyncHook::test_beam_version\r\n23.22s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_delete_objects_many_keys\r\n20.73s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_extract_xcom_none\r\n20.30s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_extract_xcom_failure\r\n17.70s call     providers/tests/amazon/aws/waiters/test_bedrock.py::TestBedrockCustomWaiters::test_service_waiters\r\n17.01s call     providers/tests/amazon/aws/sensors/test_ec2.py::TestEC2InstanceStateSensor::test_running\r\n15.48s call     providers/tests/amazon/aws/hooks/test_ec2.py::TestEC2Hook::test_client_type_get_instance_ids\r\n15.44s call     providers/tests/google/cloud/hooks/test_dataprep.py::TestGoogleDataprepHook::test_get_job_group_status_four_errors\r\n14.43s call     providers/tests/amazon/aws/sensors/test_s3.py::TestS3KeySensor::test_custom_metadata_default_return_vals\r\n14.37s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_cannot_hibernate_some_instances\r\n13.60s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCreateDbSnapshotOperator::test_create_db_instance_snapshot\r\n13.32s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2CreateInstanceOperator::test_create_instance\r\n12.81s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_create_cluster_throws_exception_when_cluster_exists\r\n12.61s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_select_expression_and_serialization_config\r\n12.58s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2RebootInstanceOperator::test_reboot_multiple_instances\r\n11.66s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_hibernate_multiple_instances\r\n10.81s call     providers/tests/amazon/aws/sensors/test_s3.py::TestS3KeySensor::test_custom_metadata_all_attributes\r\n10.79s call     providers/tests/amazon/aws/hooks/test_bedrock.py::TestBedrockHooks::test_bedrock_hooks[bedrock]\r\n10.60s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_cannot_hibernate_instance\r\n10.57s call     providers/tests/amazon/aws/hooks/test_cloud_formation.py::TestCloudFormationHook::test_get_conn_returns_a_boto3_connection\r\n10.32s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_await_xcom_sidecar_container_timeout\r\n9.99s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_autoscaled_cluster\r\n9.81s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_non_autoscaled_cluster_check_error\r\n9.74s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_autoscaled_cluster_check_error\r\n9.43s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2StopInstanceOperator::test_stop_instance\r\n9.38s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2TerminateInstanceOperator::test_terminate_multiple_instances\r\n9.30s call     providers/tests/amazon/aws/sensors/test_sqs.py::TestSqsSensor::test_poke_batch_messages\r\n9.26s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsStartExportTaskOperator::test_start_export_task\r\n9.24s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_with_impersonation_service_account\r\n9.11s call     providers/tests/amazon/aws/sensors/test_rds.py::TestRdsSnapshotExistenceSensor::test_db_instance_snapshot_poke_true\r\n8.74s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_no_file_upload_with_replace\r\n8.74s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_select_expression\r\n8.68s call     providers/tests/amazon/aws/auth_manager/avp/test_facade.py::TestAwsAuthManagerAmazonVerifiedPermissionsFacade::test_avp_client\r\n8.63s call     providers/tests/amazon/aws/hooks/test_ec2.py::TestEC2Hook::test_client_type_get_instances\r\n8.57s call     providers/tests/amazon/aws/sensors/test_rds.py::TestRdsDbSensor::test_poke_true_instance\r\n8.50s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2CreateInstanceOperator::test_create_multiple_instances\r\n8.41s call     providers/tests/amazon/aws/sensors/test_ec2.py::TestEC2InstanceStateSensor::test_stopped\r\n8.37s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_with_impersonation_service_chain_one_element\r\n8.22s call     providers/tests/amazon/aws/sensors/test_rds.py::TestRdsExportTaskExistenceSensor::test_export_task_poke_true\r\n8.17s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_get_conn\r\n7.88s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCancelExportTaskOperator::test_cancel_export_task\r\n7.79s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2StartInstanceOperator::test_start_instance\r\n7.75s call     providers/tests/amazon/aws/waiters/test_eks.py::TestCustomEKSServiceWaiters::test_existing_waiter_inherited\r\n7.67s call     providers/tests/amazon/aws/sensors/test_s3.py::TestS3KeySensor::test_custom_metadata_default_custom_vals\r\n7.64s call     providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute_with_replace\r\n7.58s call     providers/tests/amazon/aws/transfers/test_hive_to_dynamodb.py::TestHiveToDynamoDBOperator::test_get_records_with_schema\r\n7.55s setup    providers/tests/amazon/aws/hooks/test_ssm.py::TestSsmHook::test_get_parameter_value_param_does_not_exist_no_default_provided[unencrypted-string]\r\n7.49s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_no_file_upload_without_replace\r\n7.34s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_incremental_file_upload_with_replace\r\n7.28s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_delete_cluster_throws_exception_when_cluster_not_found\r\n7.15s call     providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute_incremental_with_replace\r\n7.04s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_transform_script_args\r\n6.97s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCopyDbSnapshotOperator::test_copy_db_instance_snapshot\r\n6.83s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsStopDbOperator::test_stop_db_instance\r\n6.67s call     providers/tests/amazon/aws/waiters/test_opensearch_serverless.py::TestOpenSearchServerlessCustomWaiters::test_service_waiters\r\n=================== Warning summary. Total: 347, Unique: 67 ====================\r\nother: total 18, unique 8\r\n  runtest: total 18, unique 8\r\nproviders: total 271, unique 25\r\n  runtest: total 271, unique 25\r\ntests: total 58, unique 34\r\n  runtest: total 58, unique 34\r\nWarnings saved into /files/warnings-providers_microsoft-none.txt file.\r\n=========================== short test summary info ============================\r\nFAILED providers/tests/amazon/aws/operators/test_ec2.py::TestEC2RebootInstanceOperator::test_reboot_instance - Failed: Timeout >60.0s\r\nFAILED providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_clusters_returns_all_results - Failed: Timeout >60.0s\r\nFAILED providers/tests/amazon/aws/operators/test_sqs.py::TestSqsPublishOperator::test_execute_failure_fifo_queue - Failed: Timeout >60.0s\r\nFAILED providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute - Failed: Timeout >60.0s\r\nFAILED providers/tests/hashicorp/_internal_client/test_vault_client.py::TestVaultClient::test_kubernetes_different_auth_mount_point - Failed: Timeout >60.0s\r\nFAILED providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_delete_cluster_returns_deleted_cluster - Failed: Timeout >60.0s\r\n==== 6 failed, 10402 passed, 4222 skipped, 9 warnings in 1330.15s (0:22:10) ====\r\nNo stopped containers\r\nairflow-test-providers_microsoft_default\r\n\r\n\r\n</details>', 'created_at': datetime.datetime(2024, 11, 22, 18, 4, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495100267, 'issue_id': 2672562947, 'author': 'potiuk', 'body': 'And make sure to rebase the PR @jx2lee', 'created_at': datetime.datetime(2024, 11, 22, 23, 36, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495503300, 'issue_id': 2672562947, 'author': 'jx2lee', 'body': 'Oops, I had a problem and closed & recreated the PR.', 'created_at': datetime.datetime(2024, 11, 23, 14, 49, 16, tzinfo=datetime.timezone.utc)}]","jx2lee (Issue Creator) on (2024-11-19 23:52:51 UTC): @shahar1 Static check was performed in different part of the code. Non-DB tests that failed are running fine locally—do I need to address something?

jx2lee (Issue Creator) on (2024-11-20 14:36:12 UTC): Need to fix test code.. change PR to draft, I'll be back to when test code finished!

jx2lee (Issue Creator) on (2024-11-22 07:20:02 UTC): @shahar1 I need help, is there any way to pass this test?
https://github.com/apache/airflow/actions/runs/11965697415/job/33360361183?pr=44190

shahar1 on (2024-11-22 07:36:57 UTC): It seems that it has to do with the the following definition in the tests:
```python
PYMSSQL_CONN = Connection(
    conn_type=""mssql"", host=""ip"", schema=""share"", login=""username"", password=""password"", port=8081
)
```

I assume that behind the scenes it initiates `PymssqlConnection(...)` with the `**extra_conn_args` that you just added, and now it fails all the tests that use it, as the `sqlalchemy` doesn't know how to handle the extra keys.
Do you manage to reproduce the issue when you run the `breeze` command locally? Try to take a closer look on one of the failing tests and see what needs to be done with the extra params. I hope that it helps :)

jx2lee (Issue Creator) on (2024-11-22 18:04:01 UTC): is command right?
`breeze testing providers-tests --use-xdist --skip-db-tests --no-db-cleanup --backend none --test-type 'Providers[microsoft]'`

Test was not broken in my local. below full logs

<details>
<summary>more..</summary>


❯ breeze testing providers-tests --use-xdist --skip-db-tests --no-db-cleanup --backend none --test-type 'Providers[microsoft]'

Breeze dependencies changed since the installation!

This might cause various problems!!

If you experience problems - reinstall Breeze with:

    breeze setup self-upgrade

This should usually take couple of seconds.


Reinstalling Breeze from /Users/jj/workspace/opensource/airflow/dev/breeze

Docker image build is not needed for CI build as no important files are changed! You can add --force-build to force it
Good version of Docker: 27.3.1.
Good version of docker-compose: 2.29.7
Executable permissions on entrypoints are OK
[+] Running 1/0
 ✔ Network airflow-test-providers_microsoft_default  Removed                                                                                                                                             0.1s 
[+] Creating 1/0
 ✔ Network airflow-test-providers_microsoft_default  Created                                                                                                                                             0.0s 

Using 'uv' to install Airflow


Using airflow version from current sources


Running Initialization. Your basic configuration is:

  * Airflow home: /root/airflow
  * Airflow sources: /opt/airflow
  * Airflow core SQL connection: none-backend://


Checking backend and integrations.

WARNING: Using no database backend!


Using 'uv' to install Airflow


Starting the tests with those pytest arguments: providers/tests --verbosity=0 --strict-markers --durations=100 --maxfail=50 --color=yes --junitxml=/files/test_result-providers_microsoft-none.xml --timeouts-order=moi --setup-timeout=60 --execution-timeout=60 --teardown-timeout=60 --disable-warnings -rfEX --skip-db-tests --ignore-glob=*/tests/system/* --ignore-glob=tests/integration/* --ignore-glob=providers/tests/integration/* --warning-output-path=/files/warnings-providers_microsoft-none.txt --ignore=helm_tests --with-db-init --ignore=providers/tests/cloudant --ignore=providers/tests/system/cloudant --ignore=providers/tests/integration/cloudant -n 8 --no-cov --no-db-cleanup

============================= test session starts ==============================
platform linux -- Python 3.9.20, pytest-8.3.3, pluggy-1.5.0
rootdir: /opt/airflow
configfile: pyproject.toml
plugins: rerunfailures-15.0, anyio-4.6.2.post1, xdist-3.6.1, mock-3.14.0, time-machine-2.16.0, icdiff-0.9, instafail-0.5.0, custom-exit-code-0.3.0, kgb-7.2, requests-mock-1.12.1, asyncio-0.24.0, cov-6.0.0, timeouts-1.2.1
asyncio: mode=strict, default_loop_scope=function
setup timeout: 60.0s, execution timeout: 60.0s, teardown timeout: 60.0s
created: 8/8 workers
8 workers [14629 items]

ssssss.ss..s.s..s..s.ss.s.s...s.ss.s...s...ss...s...s................... [  0%]
............s.....s.ss..s.s..s........................................s. [  0%]
s..ss.......ss.......................................s..s......ssss.s.ss [  1%]
..s..................................................................... [  1%]
........................................................................ [  2%]
........................................................................ [  2%]
...................................................................s.... [  3%]
........................................................................ [  3%]
.............ssssssss.ssssss.sssssssssss.sssssssss.s....ssssss.sssssssss [  4%]
ss.ssssssssss.sss.ssss.sssssssssss.ssssssssssssssssss.ssssssssssssssssss [  4%]
sssssssssssssssssssssss.........................................s....... [  5%]
..............................................sss.s..................... [  5%]
................................ssssss....s..ss......................... [  6%]
..................s.s.s....................s.sss.ss..................... [  6%]
................ssssssss....................ss....ssssssssssssssssss.... [  7%]
..........................ssss.ssss.......................sssssssssssss. [  7%]
ssssssssssssss.ssss...s..........ssssssssssss......s.s.......ss.ssssssss [  8%]
ssss.....s.........ssssssssssss.sssssssss............................... [  8%]
.s...................sssssssssssssssssssssssssssssssssssssssssssssssssss [  9%]
sssssssssssssssssss.....................s..............sssssssssssssssss [  9%]
sssssssssss.ssssssssss.sssssssssssssssssssssssssssssssssssssssssssssssss [ 10%]
sss...sssssssssssssssssssss...sssssssssssssss.s......................... [ 10%]
...............................ss.sssssssssssssss.ssss.sssssssssssssssss [ 11%]
sssssssssssssss......................................................... [ 11%]
........................................................................ [ 12%]
..........................s.ss.......................................... [ 12%]
.....................s.........s........................................ [ 13%]
..................................................ssssssssssssss.sssssss [ 13%]
sssssss....s.ss.........s......sss.......ss......sssssss.sss.s.....sssss [ 14%]
sssssssssssssssssssssssssssssssssssssssssssssssssssssss.s..s.sss.....sss [ 14%]
ssssss.s...................ssss......sss.....sssssssssssssssssssssssssss [ 15%]
s.ssssssssssssssssssssssssssssssssss..................................ss [ 15%]
sssssssssssssssssssssssss............................s.................. [ 16%]
...............s.ss.s.ss.ss.sss.ss.s....sss.ssssssssssssssss..sss.ssssss [ 16%]
ssssssssssssssssssssssssssssssssssssssssssssssssssssss.................. [ 17%]
.........ss.ss.sssssss.sss.sss.ssssssssssss.sssss.s.ss.s.ss.ss.ss.s.sss. [ 17%]
ss.s.ss..sss..ss.s..s.s................................................. [ 18%]
........................................................................ [ 18%]
.............................................ssss....................... [ 19%]
.........................ss.sssssssssssss.....s......................... [ 19%]
.....ssssssssssss.sssssssssssssssssssssssss.ssssssssssss................ [ 20%]
sss.ssssssssss............sss..s.ss..s.ss.ss.ss.s.ss.sssss.ss.sss.ss.s.s [ 20%]
s.s.s.ss.ss.s.s.ssssssssssssssssssssssssssssssssssssssssssssssssssssssss [ 21%]
sssssssssssssssssssss.sssssssssssssssssssss.sssssss.ss.ss.sssss.ssss.sss [ 21%]
.sss.ssss.ss.sss.ss.sss.sss.ssss.ss.sss.s.sss.ss.ss.ss.sssss....s.ssssss [ 22%]
sssssssssssssssssssssssssssssssss..s.ssssssssssssssssss...ss.ssss.ss.sss [ 22%]
ssssssssss.ssssssssssssssssssssssssssssssssssssssssssssss..ssssssss.ssss [ 23%]
.ssssssssssssssssssssssssssssssssssssssssssssssssssss................... [ 23%]
ssssss.....................ssssss....................................... [ 24%]
.............sssssssss.ssssssssssssssssssssssssssssssssssssss........... [ 24%]
......sssssssssssssssssssssssssssssssssssssss......ss................... [ 25%]
......s........ssss.ss...........................ssssssssssssssss....... [ 25%]
.........ss......................................sssssssssss.sss........ [ 26%]
......s.......s..................................................s.s.... [ 26%]
......................................s.ss.s............................ [ 27%]
........................................................................ [ 27%]
........................................................................ [ 28%]
..................................................sssssssssssssssssss.s. [ 28%]
.........ss.sss.ss.sss.ss.ss.ssss.ss.sss.sss.sss.sss.ss.sss.sss.s.sss.ss [ 29%]
s.s.s.ss.s.sss.ss.ss.sss.sss.sss.sss.ss................................. [ 29%]
....ss.s.................ss...s.ss.s.s.s...ss.sss.ss.sss.sss.ss.sss.ss.s [ 30%]
s.sss.sss.sss.ss.ss.ss.ss.s.s.sss.ss.sssssss.sssssssssss.ss.ss.ss.s.s... [ 30%]
.......ss.ssss.sss.ssss.ssss.sss.ss.ss...ss.ss.sss.sss.sssss.ss.ssss.ss. [ 31%]
.s..................s.s.s............................................... [ 31%]
.........ssssssssssssss.sssss.sss.ss.sss.sssssssssssssssssss............ [ 31%]
...............................................................ssssss... [ 32%]
....s.......ssssssssssssssss............................................ [ 32%]
........................................................................ [ 33%]
..........................................................s............. [ 33%]
.............................................................sss........ [ 34%]
........................................................................ [ 34%]
.......................................................s................ [ 35%]
.................................s...................................... [ 35%]
...s......F............................................................. [ 36%]
..............................ss.s.ss.ss.s.s.ssss.sssssss.s............. [ 36%]
........................................................................ [ 37%]
........................................................................ [ 37%]
.........................................s.............................. [ 38%]
........................................................................ [ 38%]
...............................................sssssssssss.............. [ 39%]
............................................................sss......... [ 39%]
.............s...s.s..s....s...s...s....s....s..s.....s...s....s.....ss. [ 40%]
s.s.ss.ssss.ssss.ss.s.ss.sss.sss..ss.sssss.ss.ss.ss.ssss.ss.sss.ss.sss.s [ 40%]
s.sss.ssss..sss.s.sssss.sss.ssss.ss.ss.ss.s.ssss.sssssssssssssssssss.sss [ 41%]
sss.sssss............................................................... [ 41%]
......................................s......s.......s.......s.......... [ 42%]
........................................................................ [ 42%]
ss.ss.ssssss.sss.s.ss.s..........s..s.sssssssssssssssssssss............. [ 43%]
........................................................s............... [ 43%]
.................s...s.............................s......s...ss........ [ 44%]
...........................................s......s........s.s.s.ss.s... [ 44%]
...........s..............s.................s.............s...........s. [ 45%]
s....................................................................... [ 45%]
............ss.................................................s...s...s [ 46%]
.....s....s.....s...s....s......s.....s............s.................sss [ 46%]
s.sss..s.ss.ss.s...ss................................................... [ 47%]
..............................s.ss................s...................ss [ 47%]
.sss.s.ss.ss.ss......................................................... [ 48%]
.............................................s...ss.sss.ss.ss.sss.ss.sss [ 48%]
.ss.ss.ss.sss.sss.ss.sss.ssss.sssss.sssss.sss.s.ss.ss.s.sss.ss.s.s.s.ss. [ 49%]
.sss..ss.s.ss.s.ss.s..ss.s.ss.s.ss.s.s.s.s.s.s.ss..ss.s.s.ss..ss..ss..ss [ 49%]
.s.s.s.ss................................................ss.ss.s....ssss [ 50%]
sssss.......s.ss.sss.ss..s.............................................. [ 50%]
s.ssss....ssssssssssssssssssssssssssss.ssss.ss.ss.sss.sss.sss.sss.ss.sss [ 51%]
.sss.sss.s.sssss.ss.sssss.ssss.ss.s.sss.sss.s.ss.sss.ssss.ssss.ss....... [ 51%]
..........................................ss.sssss........s............. [ 52%]
.sss.ss.sss.ssss.sss.ssss.sss.s.............s.sssss.sssss.ss.ss......... [ 52%]
........................................sss.........s................sss [ 53%]
ss.s.ss.ssssssssssss....................s........................s...... [ 53%]
..................................................ss..........s......... [ 54%]
......sssss.s.ss........ss.........................................ss.ss [ 54%]
.ss.ss.sss.sss.s.sss.sss.sss.ss.s.s.s.ss.ss...................s......... [ 55%]
..............ss.s...................................................... [ 55%]
.............s..........................................s............... [ 56%]
.........................................................s...........s.. [ 56%]
.............................s................s...........s...........s. [ 57%]
..................s.....s......s...s..s...s..s.........s....ss.s.ss.ssss [ 57%]
.ss.ss.ss.ss.ss...............ss.ss.ss.s.s...s.......................... [ 58%]
.........................................................s.sss.s.ss.sss. [ 58%]
sss.ssss.s.sssss.ss.sssss............................................... [ 59%]
.......................................................................F [ 59%]
............................sss........................ssss............. [ 60%]
.............................................................ssss.s..... [ 60%]
.....ssssss............sss...................ssssss.sss.sss.ssss........ [ 61%]
........................................................................ [ 61%]
.............F.....ssssss.ssss.......................................... [ 62%]
................................................................ss.sss.. [ 62%]
...sss.ss............................................................... [ 62%]
.................................................................ss..... [ 63%]
...............s.sss.ss..s.............................................. [ 63%]
........................................................................ [ 64%]
......................................................................ss [ 64%]
sssssssssss........................................................sssss [ 65%]
.ss.s......................F..............................ss..ssssssssss [ 65%]
.........s...................................................ssssssss..s [ 66%]
sssssssssssssssssssssssssssss.............................F............. [ 66%]
................ss.sssssss.sss.ssss.ss.sss.sss.sss.ss.sss.ss.sss.ss.ssss [ 67%]
.ss.s.sss.s.ss.sss..ssss.sssssss.sssssssss.ss.sss.sssss.ssssssss........ [ 67%]
s.............................s......................................... [ 68%]
.........ssss........................................................... [ 68%]
...............s.ss..........ss.s.ss.s.ss.ss.ss.s.s.s.ss.s.s............ [ 69%]
.............................................ss.ss.ss.ss.ss.s.ss.ss.ss.s [ 69%]
.s.ss.s.ss.s.ss.s.sss.s............s.ss.ss.ss.ss.s.s.ss.ss..s.ss.ss.s.ss [ 70%]
.ss.s.ss.ss...............ss.ss.ss.s.ss.ss..ss.......s............s..... [ 70%]
..............s..................................................s...s.s [ 71%]
s.s.ss..s.s.s..ss..s.s..ss.............................s................ [ 71%]
................................ss.s..sss..ss.ss.s.ss...sss..s.s..ss.s.. [ 72%]
s..ss...ssss..s.s.s.ss.s.s..s.s..s...s.s..s.ss..s.s.s.s..ss..sFs.s.s.s.. [ 72%]
..........s.s.s..ss...s..sss.s.ssssss..ss.s.ss.s.s.ssss.s............... [ 73%]
.....................................................................ss. [ 73%]
s.ss..s.sss.s.ss..ssss........sssss...............ss............s..s.... [ 74%]
....sssssssss.........s....sss...s....s......ss.sss.ssss..sssssssss.sss. [ 74%]
ss.ss..sssss.s.s.ss..ss.s.s....s..ss.s.s...ssssss.ss.ssss.ssssssssssssss [ 75%]
s.sss.ss................................................s.s.s..sss..s.s. [ 75%]
.ss.ssss.sss.sssss.ssss..s.s.ssssss..ssss.s.sssss.ss..ss.s..ss.s..s...s. [ 76%]
.s..........s...........................ss...s.s.s..s.....s..s.s..s..ss. [ 76%]
.s...s..s.s.s..............................s..sss.s.s.s.s.s.s.s.ss...... [ 77%]
........................................................................ [ 77%]
........................................................................ [ 78%]
........................................................................ [ 78%]
.....................................s.s.ss.s.ss.sss.ss.s............... [ 79%]
........................................................................ [ 79%]
........................................................................ [ 80%]
........................................................................ [ 80%]
........................................................................ [ 81%]
.................s..s.s.s.s.s.s.s....................................... [ 81%]
........................................................................ [ 82%]
........................................................................ [ 82%]
........................................................................ [ 83%]
........................................................................ [ 83%]
........................................................................ [ 84%]
........................................................................ [ 84%]
......................s..ss..ss.s....................................... [ 85%]
..s....s.s...s...s.s..s.s.s..s.s.s..s........s.s.ss.ss.sss..s.sss.sss..s [ 85%]
sss.ssssssssssss.s.s.s.s.s.s.s.......................................... [ 86%]
.s..................................ss.ss.s.s.s.ss..s.s.ss.s.ss.sss.ss.s [ 86%]
s.sssss..ssss..s.sss..s.ss.s..ss..s.ss..ssss..s.sss...ss.s.s.ss..sss.sss [ 87%]
.sss.ss.s.sss..sss..ss.ss..ss.s..ss..s.s.s..ss...ss..s..s.s..ss..s.s.s.s [ 87%]
..s.ss.ss.ss.sss..ssss.................................................. [ 88%]
.......s.ss..s.ss.sss..sss.s.ss..ss..sss.sss.ss.s.ss..s.ss.ssss.sss.ss.s [ 88%]
sssssssssssssssssssss.ssss.ssssssssssssssssss.s.ssssssssssssssssssssssss [ 89%]
.ssss.sssssssssssssssss.sssss.sssssssssssssss.sssssssssssssss.ssssssssss [ 89%]
sssssssssssssssss.sssssssssssssssssssssssssssss.ssssssssssssssssssssssss [ 90%]
ssssssss.ssssssssssssssssssssssssssssssss.ssssssssssssssssssssssssssssss [ 90%]
sssssss.sssssssssssssssssssssssssssssssss.sssss.ssss.ssss.ssss.sss.ss..s [ 91%]
ssssss.ssss.ssss.s..................ss.sss.sss.ssss.ss.s.ssss.ssssss.sss [ 91%]
sss.ssssss.ss.ss........................................................ [ 92%]
........................................................................ [ 92%]
...............................................ss...s.........ss..s.s.s. [ 93%]
s.ss..ss.s.s....................................................s....... [ 93%]
.sssss.s..........ssssssssssssssssssssssssssssssssssssssssssssssssssssss [ 94%]
sssssssssssssssssssssssssss............s................................ [ 94%]
...........sssssssssss.......ssss.......s........s....ssss.........sssss [ 94%]
ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss.ss.ss [ 95%]
sss.sss.ssss.ssss.ssss.sssss.sss.ssss.ssss.ss........................... [ 95%]
............................ss.......................................... [ 96%]
.....................................................ssss......sssssssss [ 96%]
sssssss..sssssssssssssss....ssssssssssssssssssssssssssssssssssssssssssss [ 97%]
ssssssssssssssssss..........s..........sssssss...............s........ss [ 97%]
........................................................................ [ 98%]
..........................s.s........................................... [ 98%]
.......................................s...s...........................s [ 99%]
........................................................................ [ 99%]
.............                                                            [100%]
=================================== FAILURES ===================================
______________ TestEC2RebootInstanceOperator.test_reboot_instance ______________
[gw3] linux -- Python 3.9.20 /usr/local/bin/python
providers/tests/amazon/aws/operators/test_ec2.py:385: in test_reboot_instance
    image_id=self._get_image_id(ec2_hook),
providers/tests/amazon/aws/operators/test_ec2.py:48: in _get_image_id
    images = ec2_client.describe_images()[""Images""]
/usr/local/lib/python3.9/site-packages/botocore/client.py:569: in _api_call
    return self._make_api_call(operation_name, kwargs)
/usr/local/lib/python3.9/site-packages/botocore/client.py:1005: in _make_api_call
    http, parsed_response = self._make_request(
/usr/local/lib/python3.9/site-packages/botocore/client.py:1029: in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:119: in make_request
    return self._send_request(request_dict, operation_model)
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:197: in _send_request
    success_response, exception = self._get_response(
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:239: in _get_response
    success_response, exception = self._do_get_response(
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:276: in _do_get_response
    responses = self._event_emitter.emit(event_name, request=request)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:412: in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:256: in emit
    return self._emit(event_name, kwargs)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:239: in _emit
    response = handler(**kwargs)
/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:38: in __call__
    response = self.process_request(request)
/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:88: in process_request
    status, headers, body = method_to_execute(
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:291: in dispatch
    return cls()._dispatch(*args, **kwargs)
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:503: in _dispatch
    return self.call_action()
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:591: in call_action
    response = method()
/usr/local/lib/python3.9/site-packages/moto/ec2/responses/amis.py:56: in describe_images
    return template.render(images=images)
/usr/local/lib/python3.9/site-packages/jinja2/environment.py:1302: in render
    return self.environment.concat(self.root_render_func(ctx))  # type: ignore
<template>:55: in root
    ???
/usr/local/lib/python3.9/site-packages/jinja2/runtime.py:303: in call
    return __obj(*args, **kwargs)
/usr/local/lib/python3.9/site-packages/moto/ec2/models/core.py:12: in get_tags
    tags = self.ec2_backend.describe_tags(filters={""resource-id"": [self.id]})  # type: ignore[attr-defined]
/usr/local/lib/python3.9/site-packages/moto/ec2/models/tags.py:76: in describe_tags
    re.compile(simple_aws_filter_to_re(value))
/usr/local/lib/python3.9/re.py:252: in compile
    return _compile(pattern, flags)
/usr/local/lib/python3.9/re.py:304: in _compile
    p = sre_compile.compile(pattern, flags)
/usr/local/lib/python3.9/sre_compile.py:806: in compile
    p.state.groups-1,
E   Failed: Timeout >60.0s
----------------------------- Captured stdout call -----------------------------
[2024-11-22T14:29:34.070+0000] {base.py:66} INFO - Retrieving connection 'aws_default'
[2024-11-22T14:29:36.936+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
------------------------------ Captured log call -------------------------------
INFO     airflow.hooks.base:base.py:66 Retrieving connection 'aws_default'
INFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.
_____________ TestEksHooks.test_list_clusters_returns_all_results ______________
[gw1] linux -- Python 3.9.20 /usr/local/bin/python
providers/tests/amazon/aws/hooks/test_eks.py:255: in test_list_clusters_returns_all_results
    eks_hook, generated_test_data = cluster_builder(count=initial_batch_size)
providers/tests/amazon/aws/hooks/test_eks.py:129: in _execute
    return eks_hook, ClusterTestDataFactory(count=count, minimal=minimal)
providers/tests/amazon/aws/hooks/test_eks.py:111: in __init__
    self.cluster_names: list[str] = generate_clusters(
providers/tests/amazon/aws/utils/eks_test_utils.py:96: in generate_clusters
    return [
providers/tests/amazon/aws/utils/eks_test_utils.py:97: in <listcomp>
    eks_hook.create_cluster(name=f""cluster{count}"", **_input_builder(ClusterInputs, minimal))[
providers/src/airflow/providers/amazon/aws/hooks/eks.py:138: in create_cluster
    response = eks_client.create_cluster(
/usr/local/lib/python3.9/site-packages/botocore/client.py:569: in _api_call
    return self._make_api_call(operation_name, kwargs)
/usr/local/lib/python3.9/site-packages/botocore/client.py:1005: in _make_api_call
    http, parsed_response = self._make_request(
/usr/local/lib/python3.9/site-packages/botocore/client.py:1029: in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:119: in make_request
    return self._send_request(request_dict, operation_model)
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:197: in _send_request
    success_response, exception = self._get_response(
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:239: in _get_response
    success_response, exception = self._do_get_response(
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:276: in _do_get_response
    responses = self._event_emitter.emit(event_name, request=request)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:412: in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:256: in emit
    return self._emit(event_name, kwargs)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:239: in _emit
    response = handler(**kwargs)
/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:38: in __call__
    response = self.process_request(request)
/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:88: in process_request
    status, headers, body = method_to_execute(
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:291: in dispatch
    return cls()._dispatch(*args, **kwargs)
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:503: in _dispatch
    return self.call_action()
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:591: in call_action
    response = method()
/usr/local/lib/python3.9/site-packages/moto/eks/responses.py:33: in create_cluster
    cluster = self.eks_backend.create_cluster(
/usr/local/lib/python3.9/site-packages/moto/eks/models.py:360: in create_cluster
    validate_role_arn(role_arn)
/usr/local/lib/python3.9/site-packages/moto/eks/utils.py:45: in validate_role_arn
    valid_partition = match.group(""partition"") in Session().get_available_partitions()  # type: ignore
/usr/local/lib/python3.9/site-packages/boto3/session.py:160: in get_available_partitions
    return self._session.get_available_partitions()
/usr/local/lib/python3.9/site-packages/botocore/session.py:1078: in get_available_partitions
    resolver = self._get_internal_component('endpoint_resolver')
/usr/local/lib/python3.9/site-packages/botocore/session.py:818: in _get_internal_component
    return self._internal_components.get_component(name)
/usr/local/lib/python3.9/site-packages/botocore/session.py:1140: in get_component
    self._components[name] = factory()
/usr/local/lib/python3.9/site-packages/botocore/session.py:205: in create_default_resolver
    endpoints, path = loader.load_data_with_path('endpoints')
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper
    data = func(self, *args, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path
    found = self.file_loader.load_file(possible_path)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file
    data = self._load_file(file_path + ext, open_method)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file
    return json.loads(payload, object_pairs_hook=OrderedDict)
/usr/local/lib/python3.9/json/__init__.py:359: in loads
    return cls(**kw).decode(s)
/usr/local/lib/python3.9/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode
    obj, end = self.scan_once(s, idx)
E   Failed: Timeout >60.0s
----------------------------- Captured stdout call -----------------------------
[2024-11-22T14:31:21.322+0000] {base.py:66} INFO - Retrieving connection 'aws_default'
[2024-11-22T14:31:24.432+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
[2024-11-22T14:31:25.001+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster0.
[2024-11-22T14:31:25.130+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster1.
[2024-11-22T14:31:25.274+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster2.
[2024-11-22T14:31:25.395+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster3.
[2024-11-22T14:31:25.518+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster4.
[2024-11-22T14:31:25.649+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster5.
[2024-11-22T14:31:25.814+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster6.
[2024-11-22T14:31:25.968+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster7.
[2024-11-22T14:31:26.113+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster8.
[2024-11-22T14:31:26.269+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster9.
[2024-11-22T14:31:26.425+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster10.
[2024-11-22T14:31:26.602+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster11.
[2024-11-22T14:31:26.794+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster12.
[2024-11-22T14:31:26.942+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster13.
[2024-11-22T14:31:27.093+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster14.
[2024-11-22T14:31:27.309+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster15.
[2024-11-22T14:31:27.478+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster16.
[2024-11-22T14:31:27.659+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster17.
[2024-11-22T14:31:27.836+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster18.
[2024-11-22T14:31:28.082+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster19.
[2024-11-22T14:31:28.454+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster20.
[2024-11-22T14:31:28.726+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster21.
[2024-11-22T14:31:28.931+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster22.
[2024-11-22T14:31:29.170+0000] {eks.py:142} INFO - Created Amazon EKS cluster with the name cluster23.
------------------------------ Captured log call -------------------------------
INFO     airflow.hooks.base:base.py:66 Retrieving connection 'aws_default'
INFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster0.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster1.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster2.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster3.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster4.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster5.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster6.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster7.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster8.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster9.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster10.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster11.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster12.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster13.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster14.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster15.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster16.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster17.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster18.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster19.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster20.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster21.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster22.
INFO     airflow.task.hooks.airflow.providers.amazon.aws.hooks.eks.EksHook:eks.py:142 Created Amazon EKS cluster with the name cluster23.
____________ TestSqsPublishOperator.test_execute_failure_fifo_queue ____________
[gw4] linux -- Python 3.9.20 /usr/local/bin/python
providers/tests/amazon/aws/operators/test_sqs.py:104: in test_execute_failure_fifo_queue
    op.execute(mocked_context)
airflow/models/baseoperator.py:376: in wrapper
    return func(self, *args, **kwargs)
providers/src/airflow/providers/amazon/aws/operators/sqs.py:94: in execute
    result = self.hook.send_message(
providers/src/airflow/providers/amazon/aws/hooks/sqs.py:85: in send_message
    return self.get_conn().send_message(**params)
providers/src/airflow/providers/amazon/aws/hooks/base_aws.py:783: in get_conn
    return self.conn
/usr/local/lib/python3.9/functools.py:993: in __get__
    val = self.func(instance)
providers/src/airflow/providers/amazon/aws/hooks/base_aws.py:740: in conn
    return self.get_client_type(region_name=self.region_name)
providers/src/airflow/providers/amazon/aws/hooks/base_aws.py:710: in get_client_type
    return session.client(
/usr/local/lib/python3.9/site-packages/boto3/session.py:297: in client
    return self._session.create_client(
/usr/local/lib/python3.9/site-packages/botocore/session.py:959: in create_client
    endpoint_resolver = self._get_internal_component('endpoint_resolver')
/usr/local/lib/python3.9/site-packages/botocore/session.py:818: in _get_internal_component
    return self._internal_components.get_component(name)
/usr/local/lib/python3.9/site-packages/botocore/session.py:1140: in get_component
    self._components[name] = factory()
/usr/local/lib/python3.9/site-packages/botocore/session.py:205: in create_default_resolver
    endpoints, path = loader.load_data_with_path('endpoints')
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper
    data = func(self, *args, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path
    found = self.file_loader.load_file(possible_path)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file
    data = self._load_file(file_path + ext, open_method)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file
    return json.loads(payload, object_pairs_hook=OrderedDict)
/usr/local/lib/python3.9/json/__init__.py:359: in loads
    return cls(**kw).decode(s)
/usr/local/lib/python3.9/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode
    obj, end = self.scan_once(s, idx)
E   Failed: Timeout >60.0s
---------------------------- Captured stdout setup -----------------------------
[2024-11-22T14:31:59.676+0000] {base_aws.py:177} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name='eu-west-1'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
[2024-11-22T14:32:00.853+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
------------------------------ Captured log setup ------------------------------
INFO     airflow.providers.amazon.aws.hooks.base_aws.BaseSessionFactory:base_aws.py:177 No connection ID provided. Fallback on boto3 credential strategy (region_name='eu-west-1'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
INFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.
----------------------------- Captured stdout call -----------------------------
[2024-11-22T14:32:01.590+0000] {base_aws.py:177} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name='eu-west-1'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
[2024-11-22T14:32:04.005+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
------------------------------ Captured log call -------------------------------
INFO     airflow.providers.amazon.aws.hooks.base_aws.BaseSessionFactory:base_aws.py:177 No connection ID provided. Fallback on boto3 credential strategy (region_name='eu-west-1'). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
INFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.
_______________________ TestGCSToS3Operator.test_execute _______________________
[gw5] linux -- Python 3.9.20 /usr/local/bin/python
providers/tests/amazon/aws/transfers/test_gcs_to_s3.py:182: in test_execute
    hook, _ = _create_test_bucket()
providers/tests/amazon/aws/transfers/test_gcs_to_s3.py:44: in _create_test_bucket
    bucket = hook.get_bucket(""bucket"")
providers/src/airflow/providers/amazon/aws/hooks/s3.py:125: in wrapper
    return func(*bound_args.args, **bound_args.kwargs)
providers/src/airflow/providers/amazon/aws/hooks/s3.py:335: in get_bucket
    return self.resource.Bucket(bucket_name)
/usr/local/lib/python3.9/functools.py:993: in __get__
    val = self.func(instance)
providers/src/airflow/providers/amazon/aws/hooks/s3.py:208: in resource
    return self.get_session().resource(
/usr/local/lib/python3.9/site-packages/boto3/session.py:394: in resource
    resource_model = self._loader.load_service_model(
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper
    data = func(self, *args, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:418: in load_service_model
    model = self.load_data(full_path)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:472: in load_data
    data, _ = self.load_data_with_path(name)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper
    data = func(self, *args, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path
    found = self.file_loader.load_file(possible_path)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file
    data = self._load_file(file_path + ext, open_method)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file
    return json.loads(payload, object_pairs_hook=OrderedDict)
/usr/local/lib/python3.9/json/__init__.py:359: in loads
    return cls(**kw).decode(s)
/usr/local/lib/python3.9/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode
    obj, end = self.scan_once(s, idx)
E   Failed: Timeout >60.0s
----------------------------- Captured stdout call -----------------------------
[2024-11-22T14:32:38.330+0000] {base_aws.py:177} INFO - No connection ID provided. Fallback on boto3 credential strategy (region_name=None). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
------------------------------ Captured log call -------------------------------
INFO     airflow.providers.amazon.aws.hooks.base_aws.BaseSessionFactory:base_aws.py:177 No connection ID provided. Fallback on boto3 credential strategy (region_name=None). See: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html
__________ TestVaultClient.test_kubernetes_different_auth_mount_point __________
[gw3] linux -- Python 3.9.20 /usr/local/bin/python
providers/tests/hashicorp/_internal_client/test_vault_client.py:404: in test_kubernetes_different_auth_mount_point
    client = vault_client.client
providers/src/airflow/providers/hashicorp/_internal_client/vault_client.py:187: in client
    if not self._client.is_authenticated():
/usr/local/lib/python3.9/functools.py:993: in __get__
    val = self.func(instance)
providers/src/airflow/providers/hashicorp/_internal_client/vault_client.py:243: in _client
    if _client.is_authenticated():
/usr/local/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/usr/local/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
/usr/local/lib/python3.9/unittest/mock.py:1168: in _execute_mock_call
    return self.return_value
/usr/local/lib/python3.9/unittest/mock.py:519: in __get_return_value
    ret = self._get_child_mock(
/usr/local/lib/python3.9/unittest/mock.py:1018: in _get_child_mock
    return klass(**kw)
/usr/local/lib/python3.9/unittest/mock.py:2033: in __init__
    self._mock_set_magics()  # make magic work for kwargs in init
/usr/local/lib/python3.9/unittest/mock.py:2058: in _mock_set_magics
    setattr(_type, entry, MagicProxy(entry, self))
/usr/local/lib/python3.9/unittest/mock.py:2104: in __init__
    self.name = name
E   Failed: Timeout >60.0s
___________ TestEksHooks.test_delete_cluster_returns_deleted_cluster ___________
[gw1] linux -- Python 3.9.20 /usr/local/bin/python
providers/tests/amazon/aws/hooks/test_eks.py:352: in test_delete_cluster_returns_deleted_cluster
    eks_hook, generated_test_data = cluster_builder(count=initial_batch_size, minimal=False)
providers/tests/amazon/aws/hooks/test_eks.py:129: in _execute
    return eks_hook, ClusterTestDataFactory(count=count, minimal=minimal)
providers/tests/amazon/aws/hooks/test_eks.py:111: in __init__
    self.cluster_names: list[str] = generate_clusters(
providers/tests/amazon/aws/utils/eks_test_utils.py:96: in generate_clusters
    return [
providers/tests/amazon/aws/utils/eks_test_utils.py:97: in <listcomp>
    eks_hook.create_cluster(name=f""cluster{count}"", **_input_builder(ClusterInputs, minimal))[
providers/src/airflow/providers/amazon/aws/hooks/eks.py:138: in create_cluster
    response = eks_client.create_cluster(
/usr/local/lib/python3.9/site-packages/botocore/client.py:569: in _api_call
    return self._make_api_call(operation_name, kwargs)
/usr/local/lib/python3.9/site-packages/botocore/client.py:1005: in _make_api_call
    http, parsed_response = self._make_request(
/usr/local/lib/python3.9/site-packages/botocore/client.py:1029: in _make_request
    return self._endpoint.make_request(operation_model, request_dict)
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:119: in make_request
    return self._send_request(request_dict, operation_model)
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:197: in _send_request
    success_response, exception = self._get_response(
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:239: in _get_response
    success_response, exception = self._do_get_response(
/usr/local/lib/python3.9/site-packages/botocore/endpoint.py:276: in _do_get_response
    responses = self._event_emitter.emit(event_name, request=request)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:412: in emit
    return self._emitter.emit(aliased_event_name, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:256: in emit
    return self._emit(event_name, kwargs)
/usr/local/lib/python3.9/site-packages/botocore/hooks.py:239: in _emit
    response = handler(**kwargs)
/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:38: in __call__
    response = self.process_request(request)
/usr/local/lib/python3.9/site-packages/moto/core/botocore_stubber.py:88: in process_request
    status, headers, body = method_to_execute(
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:291: in dispatch
    return cls()._dispatch(*args, **kwargs)
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:503: in _dispatch
    return self.call_action()
/usr/local/lib/python3.9/site-packages/moto/core/responses.py:591: in call_action
    response = method()
/usr/local/lib/python3.9/site-packages/moto/eks/responses.py:33: in create_cluster
    cluster = self.eks_backend.create_cluster(
/usr/local/lib/python3.9/site-packages/moto/eks/models.py:360: in create_cluster
    validate_role_arn(role_arn)
/usr/local/lib/python3.9/site-packages/moto/eks/utils.py:45: in validate_role_arn
    valid_partition = match.group(""partition"") in Session().get_available_partitions()  # type: ignore
/usr/local/lib/python3.9/site-packages/boto3/session.py:160: in get_available_partitions
    return self._session.get_available_partitions()
/usr/local/lib/python3.9/site-packages/botocore/session.py:1078: in get_available_partitions
    resolver = self._get_internal_component('endpoint_resolver')
/usr/local/lib/python3.9/site-packages/botocore/session.py:818: in _get_internal_component
    return self._internal_components.get_component(name)
/usr/local/lib/python3.9/site-packages/botocore/session.py:1140: in get_component
    self._components[name] = factory()
/usr/local/lib/python3.9/site-packages/botocore/session.py:205: in create_default_resolver
    endpoints, path = loader.load_data_with_path('endpoints')
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:143: in _wrapper
    data = func(self, *args, **kwargs)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:449: in load_data_with_path
    found = self.file_loader.load_file(possible_path)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:195: in load_file
    data = self._load_file(file_path + ext, open_method)
/usr/local/lib/python3.9/site-packages/botocore/loaders.py:182: in _load_file
    return json.loads(payload, object_pairs_hook=OrderedDict)
/usr/local/lib/python3.9/json/__init__.py:359: in loads
    return cls(**kw).decode(s)
/usr/local/lib/python3.9/json/decoder.py:337: in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
/usr/local/lib/python3.9/json/decoder.py:353: in raw_decode
    obj, end = self.scan_once(s, idx)
E   Failed: Timeout >60.0s
----------------------------- Captured stdout call -----------------------------
[2024-11-22T14:33:28.248+0000] {base.py:66} INFO - Retrieving connection 'aws_default'
[2024-11-22T14:33:30.631+0000] {credentials.py:1147} INFO - Found credentials in environment variables.
------------------------------ Captured log call -------------------------------
INFO     airflow.hooks.base:base.py:66 Retrieving connection 'aws_default'
INFO     botocore.credentials:credentials.py:1147 Found credentials in environment variables.
----- generated xml file: /files/test_result-providers_microsoft-none.xml ------
============================ slowest 100 durations =============================
127.15s call     providers/tests/hashicorp/hooks/test_vault.py::TestConfigurationFromSecrets::test_config_from_secret_backend
92.37s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_clusters_returns_all_results
87.82s call     providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute
85.34s call     providers/tests/google/cloud/transfers/test_gcs_to_bigquery.py::TestGCSToBigQueryOperator::test_get_openlineage_facets_on_complete_empty_table
78.49s call     providers/tests/google/cloud/hooks/test_life_sciences.py::TestLifeSciencesHookWithPassedProjectId::test_run_pipeline_immediately_complete
77.77s call     providers/tests/amazon/aws/operators/test_sqs.py::TestSqsPublishOperator::test_execute_failure_fifo_queue
75.57s call     providers/tests/neo4j/hooks/test_neo4j.py::TestNeo4jHookConn::test_run_without_schema
75.37s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_delete_cluster_returns_deleted_cluster
65.54s setup    providers/tests/google/cloud/hooks/test_dataproc.py::TestDataProcJobBuilder::test_set_python_main
64.01s call     providers/tests/hashicorp/_internal_client/test_vault_client.py::TestVaultClient::test_kubernetes_different_auth_mount_point
60.31s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2RebootInstanceOperator::test_reboot_instance
59.29s setup    providers/tests/amazon/aws/sensors/test_cloud_formation.py::TestCloudFormationDeleteStackSensor::test_poke
57.40s call     providers/tests/amazon/aws/hooks/test_ses.py::test_send_email[bcc@domain.com-cc1-to@domain.com]
55.82s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_hook
54.36s setup    providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_nodegroups_returns_all_results
53.63s call     providers/tests/amazon/aws/hooks/test_base_aws.py::TestAwsBaseHook::test_connection_region_name[aws://?-None-us-gov-east-1-us-gov-east-1-resource]
52.18s call     providers/tests/amazon/aws/waiters/test_kinesis_analytics.py::TestKinesisAnalyticsV2CustomWaiters::test_service_waiters
50.72s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_put_bucket_tagging_with_pair
50.45s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3DeleteObjectsOperator::test_s3_delete_from_to_datetime
50.25s setup    providers/tests/amazon/aws/hooks/test_datasync.py::TestDataSyncHookMocked::test_init
50.25s call     providers/tests/amazon/aws/transfers/test_s3_to_dynamodb.py::TestS3ToDynamoDBOperator::test_s3_to_dynamodb_new_table_job_startup_error
49.60s call     providers/tests/amazon/aws/hooks/test_ec2.py::TestEC2Hook::test_get_instance_state
49.35s call     providers/tests/amazon/aws/executors/batch/test_batch_executor.py::TestAwsBatchExecutor::test_start_health_check_config
49.15s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_delete_bucket_if_bucket_not_exist
48.34s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2TerminateInstanceOperator::test_terminate_instance
48.23s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_hibernate_instance
47.61s call     providers/tests/amazon/aws/operators/test_eks.py::TestEksDeleteClusterOperator::test_existing_cluster_not_in_use_with_wait
47.51s call     providers/tests/amazon/aws/sensors/test_ec2.py::TestEC2InstanceStateSensor::test_terminated
47.18s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_transform_script
46.08s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCopyDbSnapshotOperator::test_copy_db_cluster_snapshot_no_wait
45.55s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_incremental_file_upload_without_replace
44.08s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCreateDbInstanceOperator::test_create_db_instance
43.95s setup    providers/tests/amazon/aws/hooks/test_datasync.py::TestDataSyncHookMocked::test_cancel_task_execution
42.60s setup    providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_get_key
42.59s setup    providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_list_prefixes
42.38s call     providers/tests/amazon/aws/hooks/test_ses.py::test_send_email[bcc1@domain.com,bcc2@domain.com-cc1@domain.com,cc2@domain.com-to1@domain.com,to2@domain.com]
40.44s call     providers/tests/amazon/aws/sensors/test_sqs.py::TestSqsSensor::test_poke_message_invalid_filtering
37.79s call     providers/tests/amazon/aws/sensors/test_redshift_cluster.py::TestRedshiftClusterSensor::test_poke
36.58s setup    providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_load_bytes
36.52s teardown providers/tests/amazon/aws/operators/test_datasync.py::TestDataSyncOperatorDelete::test_init
34.92s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_nodegroups_returns_all_results
34.08s call     providers/tests/amazon/aws/hooks/test_base_aws.py::TestAwsBaseHook::test_user_agent_caller_target_function_found[found_classes0]
30.76s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_read_pod_logs_retries_fails
30.71s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_monitor_pod_logs_failures_non_fatal
30.40s teardown providers/tests/amazon/aws/operators/test_datasync.py::TestDataSyncOperatorGetTasks::test_init_fails
24.32s call     providers/tests/apache/beam/hooks/test_beam.py::TestBeamAsyncHook::test_beam_version
23.22s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_delete_objects_many_keys
20.73s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_extract_xcom_none
20.30s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_extract_xcom_failure
17.70s call     providers/tests/amazon/aws/waiters/test_bedrock.py::TestBedrockCustomWaiters::test_service_waiters
17.01s call     providers/tests/amazon/aws/sensors/test_ec2.py::TestEC2InstanceStateSensor::test_running
15.48s call     providers/tests/amazon/aws/hooks/test_ec2.py::TestEC2Hook::test_client_type_get_instance_ids
15.44s call     providers/tests/google/cloud/hooks/test_dataprep.py::TestGoogleDataprepHook::test_get_job_group_status_four_errors
14.43s call     providers/tests/amazon/aws/sensors/test_s3.py::TestS3KeySensor::test_custom_metadata_default_return_vals
14.37s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_cannot_hibernate_some_instances
13.60s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCreateDbSnapshotOperator::test_create_db_instance_snapshot
13.32s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2CreateInstanceOperator::test_create_instance
12.81s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_create_cluster_throws_exception_when_cluster_exists
12.61s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_select_expression_and_serialization_config
12.58s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2RebootInstanceOperator::test_reboot_multiple_instances
11.66s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_hibernate_multiple_instances
10.81s call     providers/tests/amazon/aws/sensors/test_s3.py::TestS3KeySensor::test_custom_metadata_all_attributes
10.79s call     providers/tests/amazon/aws/hooks/test_bedrock.py::TestBedrockHooks::test_bedrock_hooks[bedrock]
10.60s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2HibernateInstanceOperator::test_cannot_hibernate_instance
10.57s call     providers/tests/amazon/aws/hooks/test_cloud_formation.py::TestCloudFormationHook::test_get_conn_returns_a_boto3_connection
10.32s call     providers/tests/cncf/kubernetes/utils/test_pod_manager.py::TestPodManager::test_await_xcom_sidecar_container_timeout
9.99s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_autoscaled_cluster
9.81s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_non_autoscaled_cluster_check_error
9.74s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_autoscaled_cluster_check_error
9.43s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2StopInstanceOperator::test_stop_instance
9.38s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2TerminateInstanceOperator::test_terminate_multiple_instances
9.30s call     providers/tests/amazon/aws/sensors/test_sqs.py::TestSqsSensor::test_poke_batch_messages
9.26s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsStartExportTaskOperator::test_start_export_task
9.24s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_with_impersonation_service_account
9.11s call     providers/tests/amazon/aws/sensors/test_rds.py::TestRdsSnapshotExistenceSensor::test_db_instance_snapshot_poke_true
8.74s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_no_file_upload_with_replace
8.74s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_select_expression
8.68s call     providers/tests/amazon/aws/auth_manager/avp/test_facade.py::TestAwsAuthManagerAmazonVerifiedPermissionsFacade::test_avp_client
8.63s call     providers/tests/amazon/aws/hooks/test_ec2.py::TestEC2Hook::test_client_type_get_instances
8.57s call     providers/tests/amazon/aws/sensors/test_rds.py::TestRdsDbSensor::test_poke_true_instance
8.50s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2CreateInstanceOperator::test_create_multiple_instances
8.41s call     providers/tests/amazon/aws/sensors/test_ec2.py::TestEC2InstanceStateSensor::test_stopped
8.37s call     providers/tests/google/cloud/operators/test_kubernetes_engine.py::TestGKEStartKueueInsideClusterOperator::test_execute_with_impersonation_service_chain_one_element
8.22s call     providers/tests/amazon/aws/sensors/test_rds.py::TestRdsExportTaskExistenceSensor::test_export_task_poke_true
8.17s call     providers/tests/amazon/aws/hooks/test_s3.py::TestAwsS3Hook::test_get_conn
7.88s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCancelExportTaskOperator::test_cancel_export_task
7.79s call     providers/tests/amazon/aws/operators/test_ec2.py::TestEC2StartInstanceOperator::test_start_instance
7.75s call     providers/tests/amazon/aws/waiters/test_eks.py::TestCustomEKSServiceWaiters::test_existing_waiter_inherited
7.67s call     providers/tests/amazon/aws/sensors/test_s3.py::TestS3KeySensor::test_custom_metadata_default_custom_vals
7.64s call     providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute_with_replace
7.58s call     providers/tests/amazon/aws/transfers/test_hive_to_dynamodb.py::TestHiveToDynamoDBOperator::test_get_records_with_schema
7.55s setup    providers/tests/amazon/aws/hooks/test_ssm.py::TestSsmHook::test_get_parameter_value_param_does_not_exist_no_default_provided[unencrypted-string]
7.49s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_no_file_upload_without_replace
7.34s call     providers/tests/amazon/aws/transfers/test_azure_blob_to_s3.py::TestAzureBlobToS3Operator::test_operator_incremental_file_upload_with_replace
7.28s call     providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_delete_cluster_throws_exception_when_cluster_not_found
7.15s call     providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute_incremental_with_replace
7.04s call     providers/tests/amazon/aws/operators/test_s3.py::TestS3FileTransformOperator::test_execute_with_transform_script_args
6.97s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsCopyDbSnapshotOperator::test_copy_db_instance_snapshot
6.83s call     providers/tests/amazon/aws/operators/test_rds.py::TestRdsStopDbOperator::test_stop_db_instance
6.67s call     providers/tests/amazon/aws/waiters/test_opensearch_serverless.py::TestOpenSearchServerlessCustomWaiters::test_service_waiters
=================== Warning summary. Total: 347, Unique: 67 ====================
other: total 18, unique 8
  runtest: total 18, unique 8
providers: total 271, unique 25
  runtest: total 271, unique 25
tests: total 58, unique 34
  runtest: total 58, unique 34
Warnings saved into /files/warnings-providers_microsoft-none.txt file.
=========================== short test summary info ============================
FAILED providers/tests/amazon/aws/operators/test_ec2.py::TestEC2RebootInstanceOperator::test_reboot_instance - Failed: Timeout >60.0s
FAILED providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_list_clusters_returns_all_results - Failed: Timeout >60.0s
FAILED providers/tests/amazon/aws/operators/test_sqs.py::TestSqsPublishOperator::test_execute_failure_fifo_queue - Failed: Timeout >60.0s
FAILED providers/tests/amazon/aws/transfers/test_gcs_to_s3.py::TestGCSToS3Operator::test_execute - Failed: Timeout >60.0s
FAILED providers/tests/hashicorp/_internal_client/test_vault_client.py::TestVaultClient::test_kubernetes_different_auth_mount_point - Failed: Timeout >60.0s
FAILED providers/tests/amazon/aws/hooks/test_eks.py::TestEksHooks::test_delete_cluster_returns_deleted_cluster - Failed: Timeout >60.0s
==== 6 failed, 10402 passed, 4222 skipped, 9 warnings in 1330.15s (0:22:10) ====
No stopped containers
airflow-test-providers_microsoft_default


</details>

potiuk on (2024-11-22 23:36:41 UTC): And make sure to rebase the PR @jx2lee

jx2lee (Issue Creator) on (2024-11-23 14:49:16 UTC): Oops, I had a problem and closed & recreated the PR.

"
2672555587,pull_request,closed,,Independently update source code changes in DagCode,"When the source code changes but not structural changes that would trigger a new version, we should update the DagCode's source code.

To do that, I removed the fileloc_hash, which is no longer necessary as we read the code from the DB. I also added the source_code_hash column, which is used to detect code changes and update the source code.

",ephraimbuddy,2024-11-19 15:25:00+00:00,[],2024-11-25 18:12:16+00:00,2024-11-25 18:12:14+00:00,https://github.com/apache/airflow/pull/44189,"[('area:CLI', ''), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2672503637,pull_request,closed,,Added operator Azure Analysis Services,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Added the Azure Analysis Services provider. Still need to add tests.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",10bas10,2024-11-19 15:04:43+00:00,[],2025-02-07 00:15:19+00:00,2025-02-07 00:15:19+00:00,https://github.com/apache/airflow/pull/44188,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2485969478, 'issue_id': 2672503637, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 19, 15, 4, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2623222639, 'issue_id': 2672503637, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 30, 0, 14, 45, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-19 15:04:49 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2025-01-30 00:14:45 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2672502773,pull_request,closed,,AIP-84 Fix session handling,"I scratched my head on this one.

## Problem
Tests are green, CI is green, manual API testing looks good, but when we use the UI, we see random 500 errors from time to time, cf screenshot.

All that hint to a bug in the session management. Between the DB dependency from fastapi, the way fastapi uses multiple thread to serve `sync` route requests, how we create session in airflow utility code and when / how are sessions rolled back / commited.

## TLDR:
The default `Session` factory uses sessionmaker that will make a session thread local, on the other hand FastAPI can re-use the same thread to serve multiple requests but because of the dependency we use, the session is closed after each request making successive requests on the same thread to fail.

Session lifecycle that we want is not `per thread` but `per  HTTTP request`. To achieve that we delegate the `session` handling to FastAPI dependency system and use a normal session factory not a threadlocal one.

![Screenshot 2024-11-19 at 16 06 47](https://github.com/user-attachments/assets/d5f1d5b5-9d10-4d34-9c96-4c01583c3a19)
",pierrejeambrun,2024-11-19 15:04:23+00:00,['pierrejeambrun'],2024-11-19 18:01:27+00:00,2024-11-19 18:01:25+00:00,https://github.com/apache/airflow/pull/44187,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2486017731, 'issue_id': 2672502773, 'author': 'ashb', 'body': ""Doesn't this mean that each request is going to open a new connection, and there is no re-use or pooling between requests?"", 'created_at': datetime.datetime(2024, 11, 19, 15, 22, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486065860, 'issue_id': 2672502773, 'author': 'pierrejeambrun', 'body': ""> Doesn't this mean that each request is going to open a new connection, and there is no re-use or pooling between requests?\r\n\r\nEach request will open a new `Session`, I am not super familiar with our code regarding pooling but I would say that pooling setting is done at the engine level, so that would still be handled by the underlying engine ?\r\n\r\nThe only difference with what we had before is the Session factory which is now not thread local in some cases but 'request' local."", 'created_at': datetime.datetime(2024, 11, 19, 15, 41, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486073332, 'issue_id': 2672502773, 'author': 'ashb', 'body': ""It's not our code doing the pooling, we're using the feature built in to SQLA to handle this"", 'created_at': datetime.datetime(2024, 11, 19, 15, 43, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486086281, 'issue_id': 2672502773, 'author': 'pierrejeambrun', 'body': ""If we have more concurrent request in FastAPI than connections allowed in the Pool, we might run into a problem indeed.\r\n\r\nBut we can argue that this would already be the case with thread local session. FastAPI handles sync requests in different threads so multiple concurrent requests end up using multiple threads and therefore as many different sessions checkout a connection from the pool.\r\n\r\nI don't think that removing a thread local registry for session directly impact how connection pooling is done in this case.\r\n\r\nBut I might be missing something."", 'created_at': datetime.datetime(2024, 11, 19, 15, 48, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486097294, 'issue_id': 2672502773, 'author': 'ashb', 'body': 'https://docs.sqlalchemy.org/en/14/orm/contextual.html#using-thread-local-scope-with-web-applications says how we should be doing this. Creating a session object per request is not it.', 'created_at': datetime.datetime(2024, 11, 19, 15, 53, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486129588, 'issue_id': 2672502773, 'author': 'pierrejeambrun', 'body': '> https://docs.sqlalchemy.org/en/14/orm/contextual.html#using-thread-local-scope-with-web-applications says how we should be doing this. Creating a session object per request is not it.\r\n\r\nI don\'t think that works, as mentioned in the documentation there are exceptions for asynchronous webservers:\r\n> with notable exceptions such as the asynchronous frameworks Twisted and Tornado,\r\n\r\nFastAPI I believe falls in that category. There is no direct correspondence between the request and 1 single thread processing it. (Dependencies can be resolved in different thread, it\'s even less true when we migrate to full async support). This is why we cannot use `scoped_session` for FastAPI.\r\n\r\nAll that is not super intuitive, this is why ""I scratched my head on this one.""', 'created_at': datetime.datetime(2024, 11, 19, 16, 5, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486165816, 'issue_id': 2672502773, 'author': 'pierrejeambrun', 'body': 'https://github.com/fastapi/fastapi/issues/726#issuecomment-584371305 I think this comment is relevant.', 'created_at': datetime.datetime(2024, 11, 19, 16, 19, 17, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-19 15:22:42 UTC): Doesn't this mean that each request is going to open a new connection, and there is no re-use or pooling between requests?

pierrejeambrun (Issue Creator) on (2024-11-19 15:41:09 UTC): Each request will open a new `Session`, I am not super familiar with our code regarding pooling but I would say that pooling setting is done at the engine level, so that would still be handled by the underlying engine ?

The only difference with what we had before is the Session factory which is now not thread local in some cases but 'request' local.

ashb on (2024-11-19 15:43:59 UTC): It's not our code doing the pooling, we're using the feature built in to SQLA to handle this

pierrejeambrun (Issue Creator) on (2024-11-19 15:48:57 UTC): If we have more concurrent request in FastAPI than connections allowed in the Pool, we might run into a problem indeed.

But we can argue that this would already be the case with thread local session. FastAPI handles sync requests in different threads so multiple concurrent requests end up using multiple threads and therefore as many different sessions checkout a connection from the pool.

I don't think that removing a thread local registry for session directly impact how connection pooling is done in this case.

But I might be missing something.

ashb on (2024-11-19 15:53:20 UTC): https://docs.sqlalchemy.org/en/14/orm/contextual.html#using-thread-local-scope-with-web-applications says how we should be doing this. Creating a session object per request is not it.

pierrejeambrun (Issue Creator) on (2024-11-19 16:05:09 UTC): I don't think that works, as mentioned in the documentation there are exceptions for asynchronous webservers:

FastAPI I believe falls in that category. There is no direct correspondence between the request and 1 single thread processing it. (Dependencies can be resolved in different thread, it's even less true when we migrate to full async support). This is why we cannot use `scoped_session` for FastAPI.

All that is not super intuitive, this is why ""I scratched my head on this one.""

pierrejeambrun (Issue Creator) on (2024-11-19 16:19:17 UTC): https://github.com/fastapi/fastapi/issues/726#issuecomment-584371305 I think this comment is relevant.

"
2672192301,pull_request,closed,,"Make task output ""unbuffered"" so output is captured straight away","Without this change a dag like this:

```
@task()
def hello():
    print(""hello"")
    time.sleep(300)
    print(""goodbye"")
```

would not show the output for ""hello"" until after the sleep!

This is analogouys to setting PYTHONUNBUFFERED environment variable when
running something like `python script.py | cat` etc.
",ashb,2024-11-19 13:27:01+00:00,[],2024-11-19 17:07:13+00:00,2024-11-19 13:42:33+00:00,https://github.com/apache/airflow/pull/44186,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2672120708,pull_request,closed,,Add gcloud command to DataprocCreateClusterOperator to be able to create dataproc on GKE cluster,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR was added gcloud command to DataprocCreateClusterOperator to be able to create dataproc on GKE cluster.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-11-19 13:15:10+00:00,[],2024-11-20 08:59:51+00:00,2024-11-20 08:59:51+00:00,https://github.com/apache/airflow/pull/44185,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2672068208,pull_request,closed,,[v2-10-test] Exclude Scarf Usage Data Collection in CI Environments (#44155),"Most of the the CI systems add ""CI=true"" env var.

Refereces:

- https://docs.pytest.org/en/stable/explanation/ci.html
- https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#default-environment-variables
- https://docs.travis-ci.com/user/environment-variables/
- https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
- https://circleci.com/docs/variables/#built-in-environment-variables
- https://www.jenkins.io/doc/book/pipeline/jenkinsfile/#using-environment-variables
- https://adamj.eu/tech/2020/03/09/detect-if-your-tests-are-running-on-ci/
- https://github.com/The-Compiler/pytest-vw/blob/master/pytest_vw.py
(cherry picked from commit 347a83a)

Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>",github-actions[bot],2024-11-19 12:51:56+00:00,[],2025-01-11 19:44:12+00:00,2024-11-19 15:45:26+00:00,https://github.com/apache/airflow/pull/44184,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2486077370, 'issue_id': 2672068208, 'author': 'kaxil', 'body': 'Failure was unrelated', 'created_at': datetime.datetime(2024, 11, 19, 15, 45, 32, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-19 15:45:32 UTC): Failure was unrelated

"
2671887207,pull_request,closed,,"Oracle not supports table alias ""AS"" keyword ","closes: https://github.com/apache/airflow/issues/44135

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",igvog,2024-11-19 11:35:11+00:00,[],2025-01-09 00:15:34+00:00,2025-01-09 00:15:34+00:00,https://github.com/apache/airflow/pull/44182,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:common-sql', '')]","[{'comment_id': 2485469498, 'issue_id': 2671887207, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 19, 11, 35, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569955025, 'issue_id': 2671887207, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 4, 0, 14, 54, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-19 11:35:20 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2025-01-04 00:14:54 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2671795853,pull_request,closed,,"docs(newsfragement): fix typos in 41762, 42060 and remove unnecessary 41814","41814 is no longer needed and might be misleading after #43915

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-19 11:13:47+00:00,[],2024-11-19 18:44:53+00:00,2024-11-19 18:44:53+00:00,https://github.com/apache/airflow/pull/44181,[],[],
2671754519,pull_request,closed,,Version Dags when the python_callable name changes,"We currently version DAGs when the serialized DAGs changes. Some code changes don't lead to versioning of the DAG, and we prefer not to version through code changes.

This change will allow the python callable name change to trigger versioning. A code change, but this is the max we want to go in versioning from code changes

",ephraimbuddy,2024-11-19 10:58:48+00:00,[],2024-11-20 05:11:50+00:00,2024-11-20 05:11:49+00:00,https://github.com/apache/airflow/pull/44180,"[('area:serialization', ''), ('AIP-65: DAG history in UI', '')]",[],
2671365682,pull_request,closed,,Lower bound spy calls check,"Updating `test_regular_heartbeat` spy.calls assert to minimum one spy call.

https://github.com/apache/airflow/actions/runs/11904772863/job/33174379856#step:9:840
https://github.com/apache/airflow/actions/runs/11909113739/job/33186211665?pr=44174#step:9:668

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-19 09:01:10+00:00,[],2024-11-19 10:54:13+00:00,2024-11-19 10:54:13+00:00,https://github.com/apache/airflow/pull/44177,"[('area:task-sdk', None)]","[{'comment_id': 2485096137, 'issue_id': 2671365682, 'author': 'gopidesupavan', 'body': 'WDYT? I noticed that some of the tests are passing but also failing in a few runs. is that fine check minimum 1 , i see it is completely depending on the timing. :)', 'created_at': datetime.datetime(2024, 11, 19, 9, 4, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-19 09:04:00 UTC): WDYT? I noticed that some of the tests are passing but also failing in a few runs. is that fine check minimum 1 , i see it is completely depending on the timing. :)

"
2671356768,pull_request,closed,,Migrate magic numbers for status codes to named constants,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Building up on https://github.com/apache/airflow/pull/43663, replacing few of newer occurences of these magic number status codes to named constants as recommended by https://fastapi.tiangolo.com/reference/status/


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-19 08:58:05+00:00,[],2024-11-19 13:12:00+00:00,2024-11-19 13:11:58+00:00,https://github.com/apache/airflow/pull/44176,"[('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2671257292,pull_request,closed,,AIP-84 constraint wildcard path params for get batch TI,Route should not accept anything else than wildcard for path parameters,pierrejeambrun,2024-11-19 08:32:48+00:00,['pierrejeambrun'],2024-11-19 13:15:20+00:00,2024-11-19 13:15:17+00:00,https://github.com/apache/airflow/pull/44175,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2671247654,pull_request,closed,,Add task sdk tests checks to slack notifier,"Currently in schedule run if any `tests-task-sdk` tests failed its not notifying. 

eg. https://github.com/apache/airflow/actions/runs/11904772863/job/33174379856#step:9:869 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-19 08:28:04+00:00,[],2024-11-19 10:55:15+00:00,2024-11-19 10:55:15+00:00,https://github.com/apache/airflow/pull/44174,"[('area:dev-tools', '')]","[{'comment_id': 2485098396, 'issue_id': 2671247654, 'author': 'gopidesupavan', 'body': 'updated lower bound value to spy call here: https://github.com/apache/airflow/pull/44177', 'created_at': datetime.datetime(2024, 11, 19, 9, 4, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485310696, 'issue_id': 2671247654, 'author': 'gopidesupavan', 'body': '> updated lower bound value to spy call here: #44177\r\n\r\none test failed, after merging above and rebase this PR. it will work..', 'created_at': datetime.datetime(2024, 11, 19, 10, 32, 46, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-19 09:04:56 UTC): updated lower bound value to spy call here: https://github.com/apache/airflow/pull/44177

gopidesupavan (Issue Creator) on (2024-11-19 10:32:46 UTC): one test failed, after merging above and rebase this PR. it will work..

"
2671012639,pull_request,closed,,Remove scheduler automate serviceaccount token,"closes: https://github.com/apache/airflow/issues/43464
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-11-19 06:58:09+00:00,[],2025-01-06 13:12:48+00:00,2025-01-06 13:12:47+00:00,https://github.com/apache/airflow/pull/44173,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2486380952, 'issue_id': 2671012639, 'author': 'potiuk', 'body': 'Hmm. I wonder.. Looking at #43464 - yes, when you have K8S executor, you will not be able to work without serviceAutomount set to true. But is it generally true for LocalExecutor and CeleryExecutor for example? \r\n\r\nI believe should work without automount for those executors?', 'created_at': datetime.datetime(2024, 11, 19, 17, 53, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486478294, 'issue_id': 2671012639, 'author': 'jedcunningham', 'body': ""@potiuk you'd still need it for LocalExecutor and KubernetesPodOperator too.\r\n\r\nBut yes, with CeleryExecutor it should be fine. Or if you don't care about LE+KPO. Not sure removing completely is the right call."", 'created_at': datetime.datetime(2024, 11, 19, 18, 43, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486500890, 'issue_id': 2671012639, 'author': 'potiuk', 'body': ""> @potiuk you'd still need it for LocalExecutor and KubernetesPodOperator too.\r\n> \r\n> But yes, with CeleryExecutor it should be fine. Or if you don't care about LE+KPO. Not sure removing completely is the right call.\r\n\r\nYeah. For me it looks like maybe we should detect it when we need it and it is not set and provide a better diagnostics."", 'created_at': datetime.datetime(2024, 11, 19, 18, 54, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487695577, 'issue_id': 2671012639, 'author': 'romsharon98', 'body': ""didn't fully understand what are the cases that we will need it."", 'created_at': datetime.datetime(2024, 11, 20, 7, 18, 53, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-19 17:53:21 UTC): Hmm. I wonder.. Looking at #43464 - yes, when you have K8S executor, you will not be able to work without serviceAutomount set to true. But is it generally true for LocalExecutor and CeleryExecutor for example? 

I believe should work without automount for those executors?

jedcunningham on (2024-11-19 18:43:39 UTC): @potiuk you'd still need it for LocalExecutor and KubernetesPodOperator too.

But yes, with CeleryExecutor it should be fine. Or if you don't care about LE+KPO. Not sure removing completely is the right call.

potiuk on (2024-11-19 18:54:54 UTC): Yeah. For me it looks like maybe we should detect it when we need it and it is not set and provide a better diagnostics.

romsharon98 (Issue Creator) on (2024-11-20 07:18:53 UTC): didn't fully understand what are the cases that we will need it.

"
2670793386,pull_request,closed,,Trigger openlineage test when asset files changes,"### Description
Adding `FileGroupForCi.ASSET_FILES` and running Openlineage test when Assets files are changed.

### Motivation:
We recently noticed [PR](https://github.com/apache/airflow/pull/41325) broke OL tests as `openlineage` tests heavily rely on assets and are often broken after asset changes. We want to trigger OL test whenever there is a change in Asset related files.

closes: [#44026](https://github.com/apache/airflow/issues/44026)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-19 05:25:45+00:00,[],2024-11-22 23:42:05+00:00,2024-11-22 23:41:54+00:00,https://github.com/apache/airflow/pull/44172,"[('area:dev-tools', '')]","[{'comment_id': 2486568184, 'issue_id': 2670793386, 'author': 'potiuk', 'body': 'Two small comments.', 'created_at': datetime.datetime(2024, 11, 19, 19, 24, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487250954, 'issue_id': 2670793386, 'author': 'vatsrahul1001', 'body': '> Two small comments.\r\n\r\nThank you for the suggestions. I have implemented the suggested changes.', 'created_at': datetime.datetime(2024, 11, 20, 3, 7, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488215037, 'issue_id': 2670793386, 'author': 'uranusjr', 'body': 'Can you elaborate what broke in OL? I’m not sure `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` need to trigger OL tests. Those aren’t really about assets, but more _using_ assets.', 'created_at': datetime.datetime(2024, 11, 20, 10, 38, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488238345, 'issue_id': 2670793386, 'author': 'vatsrahul1001', 'body': '> #44026\r\n\r\n\r\n\r\n> Can you elaborate what broke in OL? I’m not sure `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` need to trigger OL tests. Those aren’t really about assets, but more _using_ assets.\r\n\r\n@uranusjr This [issue](https://github.com/apache/airflow/issues/44026) explain more about what broke in OL. Also, this [PR](https://github.com/apache/airflow/pull/44025) was raised to fix OL tests. I asked @Lee-W for the assets file we can remove these files `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` if needed.', 'created_at': datetime.datetime(2024, 11, 20, 10, 47, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488661042, 'issue_id': 2670793386, 'author': 'Lee-W', 'body': ""> > #44026\r\n> \r\n> > Can you elaborate what broke in OL? I’m not sure `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` need to trigger OL tests. Those aren’t really about assets, but more _using_ assets.\r\n> \r\n> @uranusjr This [issue](https://github.com/apache/airflow/issues/44026) explain more about what broke in OL. Also, this [PR](https://github.com/apache/airflow/pull/44025) was raised to fix OL tests. I asked @Lee-W for the assets file we can remove these files `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` if needed.\r\n\r\nI believe @uranusjr's point is more convincing. Although those are related to assets, they are using assets and are unlikely to affect OL. I should have thought it through more thoroughly."", 'created_at': datetime.datetime(2024, 11, 20, 14, 0, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488666314, 'issue_id': 2670793386, 'author': 'vatsrahul1001', 'body': ""> > > #44026\r\n> > \r\n> > \r\n> > > Can you elaborate what broke in OL? I’m not sure `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` need to trigger OL tests. Those aren’t really about assets, but more _using_ assets.\r\n> > \r\n> > \r\n> > @uranusjr This [issue](https://github.com/apache/airflow/issues/44026) explain more about what broke in OL. Also, this [PR](https://github.com/apache/airflow/pull/44025) was raised to fix OL tests. I asked @Lee-W for the assets file we can remove these files `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` if needed.\r\n> \r\n> I believe @uranusjr's point is more convincing. Although those are related to assets, they are using assets and are unlikely to affect OL. I should have thought it through more thoroughly.\r\n\r\nThanks, @Lee-W and @uranusjr for the suggestion. I will remove `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py`"", 'created_at': datetime.datetime(2024, 11, 20, 14, 2, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492777200, 'issue_id': 2670793386, 'author': 'Lee-W', 'body': ""@vatsrahul1001 should we resolve the discussions or are we waiting for @potiuk 's confirmation? or"", 'created_at': datetime.datetime(2024, 11, 22, 2, 54, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2492799489, 'issue_id': 2670793386, 'author': 'vatsrahul1001', 'body': ""> @vatsrahul1001 should we resolve the discussions or are we waiting for @potiuk 's confirmation? or\r\n\r\nWe can resolve the discussion. @potiuk, is it good to merge?"", 'created_at': datetime.datetime(2024, 11, 22, 3, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495104369, 'issue_id': 2670793386, 'author': 'potiuk', 'body': 'Good to go, merged :)', 'created_at': datetime.datetime(2024, 11, 22, 23, 42, 3, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-19 19:24:34 UTC): Two small comments.

vatsrahul1001 (Issue Creator) on (2024-11-20 03:07:31 UTC): Thank you for the suggestions. I have implemented the suggested changes.

uranusjr on (2024-11-20 10:38:01 UTC): Can you elaborate what broke in OL? I’m not sure `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` need to trigger OL tests. Those aren’t really about assets, but more _using_ assets.

vatsrahul1001 (Issue Creator) on (2024-11-20 10:47:01 UTC): @uranusjr This [issue](https://github.com/apache/airflow/issues/44026) explain more about what broke in OL. Also, this [PR](https://github.com/apache/airflow/pull/44025) was raised to fix OL tests. I asked @Lee-W for the assets file we can remove these files `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py` if needed.

Lee-W on (2024-11-20 14:00:13 UTC): I believe @uranusjr's point is more convincing. Although those are related to assets, they are using assets and are unlikely to affect OL. I should have thought it through more thoroughly.

vatsrahul1001 (Issue Creator) on (2024-11-20 14:02:09 UTC): Thanks, @Lee-W and @uranusjr for the suggestion. I will remove `airflow/dag_processing/collection.py` and `airflow/timetables/assets.py`

Lee-W on (2024-11-22 02:54:05 UTC): @vatsrahul1001 should we resolve the discussions or are we waiting for @potiuk 's confirmation? or

vatsrahul1001 (Issue Creator) on (2024-11-22 03:21:00 UTC): We can resolve the discussion. @potiuk, is it good to merge?

potiuk on (2024-11-22 23:42:03 UTC): Good to go, merged :)

"
2670780111,pull_request,closed,,AIP-84 update List  Task Instances  route,"Currently, the route is `/public/dags/{dag_id}/dagRuns/{dag_run_id}/taskInstances/` 

When running tests, I noticed a redirect:

```
(Pdb) test_client.get(""/public/dags/~/dagRuns/~/taskInstances"")
[2024-11-19T10:43:57.544+0530] {_client.py:1026} INFO - HTTP Request: GET http://testserver/public/dags/~/dagRuns/~/taskInstances ""HTTP/1.1 307 Temporary Redirect""
[2024-11-19T10:43:57.561+0530] {_client.py:1026} INFO - HTTP Request: GET http://testserver/public/dags/~/dagRuns/~/taskInstances/ ""HTTP/1.1 200 OK""
```",rawwar,2024-11-19 05:14:17+00:00,[],2024-11-19 13:34:46+00:00,2024-11-19 13:34:41+00:00,https://github.com/apache/airflow/pull/44171,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2484801151, 'issue_id': 2670780111, 'author': 'amoghrajesh', 'body': 'Closing and opening to run full tests', 'created_at': datetime.datetime(2024, 11, 19, 6, 23, 22, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2024-11-19 06:23:22 UTC): Closing and opening to run full tests

"
2670750629,pull_request,closed,,AIP-84 Migrate POST list Dag Runs(batch) endpoint to FastAPI ,related to #42701,rawwar,2024-11-19 04:51:35+00:00,[],2024-11-26 09:42:53+00:00,2024-11-26 09:42:53+00:00,https://github.com/apache/airflow/pull/44170,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2670627891,pull_request,closed,,no hard-coded sensitive data.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",XiaomingX,2024-11-19 03:38:42+00:00,[],2024-11-24 06:34:32+00:00,2024-11-24 06:34:32+00:00,https://github.com/apache/airflow/pull/44168,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2484667380, 'issue_id': 2670627891, 'author': 'potiuk', 'body': 'Why?  IMHO the way it is now is better.\r\n\r\nIThis is fake data that looks like real - it\'s better to see it especially if you are not sure which value is which, seeing ""real-like"" values is better,', 'created_at': datetime.datetime(2024, 11, 19, 4, 9, 37, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-19 04:09:37 UTC): Why?  IMHO the way it is now is better.

IThis is fake data that looks like real - it's better to see it especially if you are not sure which value is which, seeing ""real-like"" values is better,

"
2670622933,pull_request,closed,,[v2-10-test] suppress the warnings where we check for sensitive values (#44148),"(cherry picked from commit 9eaeb1c3098e364f940dbbf36e8f7fc72a262eee)

Co-authored-by: Zach Liu <zachliu@users.noreply.github.com>
https: //github.com/apache/airflow/pull/44061#issuecomment-2480320259",github-actions[bot],2024-11-19 03:33:49+00:00,[],2024-12-04 08:53:57+00:00,2024-11-19 03:35:06+00:00,https://github.com/apache/airflow/pull/44167,"[('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2484637471, 'issue_id': 2670622933, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 19, 3, 35, 9, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-19 03:35:09 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2670347516,pull_request,closed,,Migrate pickled data & change XCom value type to JSON,"follow-up of https://github.com/apache/airflow/pull/43905

Changes:
- Changed `XCom.value` column to JSON for all dbs.
- Archived pickled XCom data to `_xcom_archive` and removed it from the `xcom` table.
- Removed encoded string in XCom serialization and deserialization logic.
- Updated logic for `XComObjectStorageBackend` to make it compatible for AF 2 & 3


<img width=""1625"" alt=""image"" src=""https://github.com/user-attachments/assets/e2cad4c7-ed8d-425a-8179-224e3a1ca2d6"">



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-18 23:57:12+00:00,[],2024-11-19 19:33:59+00:00,2024-11-19 15:56:20+00:00,https://github.com/apache/airflow/pull/44166,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2486105764, 'issue_id': 2670347516, 'author': 'kaxil', 'body': 'Static failure is unrelated', 'created_at': datetime.datetime(2024, 11, 19, 15, 56, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486584637, 'issue_id': 2670347516, 'author': 'jscheffl', 'body': 'Thanks for the PR - I LIKE it! Sorry entering too late for review :-(', 'created_at': datetime.datetime(2024, 11, 19, 19, 33, 58, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-19 15:56:31 UTC): Static failure is unrelated

jscheffl on (2024-11-19 19:33:58 UTC): Thanks for the PR - I LIKE it! Sorry entering too late for review :-(

"
2670089199,pull_request,closed,,Fix typo in scheduler_job_runner,"fix typos
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-18 22:21:46+00:00,[],2024-11-23 19:55:31+00:00,2024-11-19 04:10:20+00:00,https://github.com/apache/airflow/pull/44165,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2670046969,pull_request,closed,,Remove commented breakpoint in dbt provider,That is all.,dstandish,2024-11-18 21:57:14+00:00,[],2024-11-19 04:04:20+00:00,2024-11-19 04:04:20+00:00,https://github.com/apache/airflow/pull/44163,"[('area:providers', ''), ('provider:dbt-cloud', '')]","[{'comment_id': 2484249926, 'issue_id': 2670046969, 'author': 'hussein-awala', 'body': '<img width=""829"" alt=""Screenshot 2024-11-18 at 23 14 04"" src=""https://github.com/user-attachments/assets/5e9c4307-af35-4a2c-bf13-7ae4046a1363"">\r\n\r\nWhy were there two workflows awaiting maintainer approval in a PR from one of the PMC members, am I missing something?', 'created_at': datetime.datetime(2024, 11, 18, 22, 17, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484661190, 'issue_id': 2670046969, 'author': 'potiuk', 'body': '> Why were there two workflows awaiting maintainer approval in a PR from one of the PMC members, am I missing something?\r\n\r\nI raised question about it through GitHub support and still wait for answer (we discussed about it in Slack).', 'created_at': datetime.datetime(2024, 11, 19, 4, 2, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484662421, 'issue_id': 2670046969, 'author': 'potiuk', 'body': '> > Why were there two workflows awaiting maintainer approval in a PR from one of the PMC members, am I missing something?\r\n> \r\n> I raised question about it through GitHub support and still wait for answer (we discussed about it in Slack).\r\n\r\nI followed up.', 'created_at': datetime.datetime(2024, 11, 19, 4, 4, 9, tzinfo=datetime.timezone.utc)}]","hussein-awala on (2024-11-18 22:17:38 UTC): <img width=""829"" alt=""Screenshot 2024-11-18 at 23 14 04"" src=""https://github.com/user-attachments/assets/5e9c4307-af35-4a2c-bf13-7ae4046a1363"">

Why were there two workflows awaiting maintainer approval in a PR from one of the PMC members, am I missing something?

potiuk on (2024-11-19 04:02:45 UTC): I raised question about it through GitHub support and still wait for answer (we discussed about it in Slack).

potiuk on (2024-11-19 04:04:09 UTC): I followed up.

"
2669896028,pull_request,closed,,Ensure that the Task SDK regularly sends heartbeats for running tasks,"There is more nuance and edge cases to support, but this is the crux of the
behaviour we want.

This fixes the payload to be what the server expects, and fixes the URL suffix
to match latest changes too

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-18 20:57:33+00:00,[],2024-11-19 10:55:34+00:00,2024-11-18 22:13:36+00:00,https://github.com/apache/airflow/pull/44162,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2669858582,pull_request,closed,,Update FastAPI endpoints to use status.HTTP_404_NOT_FOUND,Update FastAPI endpoints to use status.HTTP_404_NOT_FOUND,rawwar,2024-11-18 20:39:15+00:00,[],2024-11-19 10:09:15+00:00,2024-11-19 09:55:40+00:00,https://github.com/apache/airflow/pull/44161,[],[],
2669791185,pull_request,closed,,Use `S3CopyObjectOperator` in `example_comprehend_document_classifier`,"Today, the system test `example_comprehend_document_classifier` downloads 10 times the same file from Github and save it in s3. As a consequence, Github might block you access and return a 403. Let's be nice with Github and download it once and then copy it from s3 to s3

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-18 20:26:10+00:00,[],2024-11-19 19:18:04+00:00,2024-11-19 08:14:07+00:00,https://github.com/apache/airflow/pull/44160,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2669721844,pull_request,closed,,[v2-10-test] Re-queue tassk when they are stuck in queued (#43520),"Backport of #43520.
Note: Cherry-pick is w/o K8s provider files as these are always taken from main during test and release.

The old ""stuck in queued"" logic just failed the tasks.  Now we requeue them.  We accomplish this by revoking the task from executor and setting state to scheduled.  We'll re-queue it up to 2 times.  Number of times is configurable by hidden config.

We added a method to base executor revoke_task because, it's a discrete operation that is required for this feature, and it might be useful in other cases e.g. when detecting as zombies etc.  We set state to failed or scheduled directly from scheduler (rather than sending through the event buffer) because event buffer makes more sense for handling external events -- why round trip through the executor and back to scheduler when scheduler is initiating the action?  Anyway this avoids having to deal with ""state mismatch"" issues when processing events.

---------

(cherry picked from commit a41feeb5aedad842be2b0f954e0be30c767dbc5e)",jscheffl,2024-11-18 19:55:07+00:00,[],2024-11-19 20:06:59+00:00,2024-11-19 20:06:59+00:00,https://github.com/apache/airflow/pull/44158,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2484192416, 'issue_id': 2669721844, 'author': 'dstandish', 'body': 'might need this as well @jscheffl https://github.com/apache/airflow/pull/44093', 'created_at': datetime.datetime(2024, 11, 18, 21, 43, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484198081, 'issue_id': 2669721844, 'author': 'jscheffl', 'body': '> might need this as well @jscheffl #44093\r\n\r\nYeeah, figured out the same commit right at the same time :-D Added to the PR!', 'created_at': datetime.datetime(2024, 11, 18, 21, 46, 34, tzinfo=datetime.timezone.utc)}]","dstandish on (2024-11-18 21:43:03 UTC): might need this as well @jscheffl https://github.com/apache/airflow/pull/44093

jscheffl (Issue Creator) on (2024-11-18 21:46:34 UTC): Yeeah, figured out the same commit right at the same time :-D Added to the PR!

"
2669698059,pull_request,closed,,[v2-10-test] doc: providers github link (#44136),"(cherry picked from commit f834a637216cc13e86cb121ea0685d27b5227a1a)

Co-authored-by: raphaelauv <raphaelauv@gmail.com>
Co-authored-by: raphaelauv <raphaelauv@users.noreply.github.com>",github-actions[bot],2024-11-18 19:47:16+00:00,[],2024-11-19 05:15:51+00:00,2024-11-19 03:47:07+00:00,https://github.com/apache/airflow/pull/44157,"[('kind:documentation', '')]","[{'comment_id': 2483959821, 'issue_id': 2669698059, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 18, 19, 47, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483967679, 'issue_id': 2669698059, 'author': 'eladkal', 'body': 'We release providers from main branch. There is no need to have it on v2.10', 'created_at': datetime.datetime(2024, 11, 18, 19, 50, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484647648, 'issue_id': 2669698059, 'author': 'potiuk', 'body': 'Agreed.', 'created_at': datetime.datetime(2024, 11, 19, 3, 47, 12, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-18 19:47:21 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2024-11-18 19:50:07 UTC): We release providers from main branch. There is no need to have it on v2.10

potiuk on (2024-11-19 03:47:12 UTC): Agreed.

"
2669672379,pull_request,closed,,raise 404 when dag or dag_run_id is not found in List TI endpoint,related to https://github.com/apache/airflow/pull/43506#issuecomment-2482730997,rawwar,2024-11-18 19:34:58+00:00,[],2024-11-19 14:26:44+00:00,2024-11-19 14:26:44+00:00,https://github.com/apache/airflow/pull/44156,"[('area:API', ""Airflow's REST/HTTP API"")]","[{'comment_id': 2485712735, 'issue_id': 2669672379, 'author': 'pierrejeambrun', 'body': 'Needs rebasing, can merge after', 'created_at': datetime.datetime(2024, 11, 19, 13, 26, 56, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-19 13:26:56 UTC): Needs rebasing, can merge after

"
2669430618,pull_request,closed,,Exclude Scarf Usage Data Collection in CI Environments,"Most of the the CI systems add ""CI=true"" env var.

Refereces:

- https://docs.pytest.org/en/stable/explanation/ci.html
- https://docs.github.com/en/actions/writing-workflows/choosing-what-your-workflow-does/store-information-in-variables#default-environment-variables
- https://docs.travis-ci.com/user/environment-variables/
- https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
- https://circleci.com/docs/variables/#built-in-environment-variables
- https://www.jenkins.io/doc/book/pipeline/jenkinsfile/#using-environment-variables
- https://adamj.eu/tech/2020/03/09/detect-if-your-tests-are-running-on-ci/
- https://github.com/The-Compiler/pytest-vw/blob/master/pytest_vw.py

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-18 18:12:30+00:00,[],2024-11-19 12:55:56+00:00,2024-11-18 18:55:59+00:00,https://github.com/apache/airflow/pull/44155,"[('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2485643587, 'issue_id': 2669430618, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/11913495978\'> Run details </a>\n\n<table>\n            <tr>\n                <th>Status</th>\n                <th>Branch</th>\n                <th>Result</th>\n            </tr>\n            <tr>\n                <td>❌</td>\n                <td>v2-10-test</td>\n                <td><a href=""https://github.com/apache/airflow/commit/347a83afbd5f860b37f91d4726f615ef9b71f1c7""><img src=\'https://img.shields.io/badge/Commit-347a83a-red\' alt=\'Commit Link\'></a></td>\n            </tr>\n        </table>', 'created_at': datetime.datetime(2024, 11, 19, 12, 55, 55, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-19 12:55:55 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/11913495978'> Run details </a>

<table>
            <tr>
                <th>Status</th>
                <th>Branch</th>
                <th>Result</th>
            </tr>
            <tr>
                <td>❌</td>
                <td>v2-10-test</td>
                <td><a href=""https://github.com/apache/airflow/commit/347a83afbd5f860b37f91d4726f615ef9b71f1c7""><img src='https://img.shields.io/badge/Commit-347a83a-red' alt='Commit Link'></a></td>
            </tr>
        </table>

"
2669303519,pull_request,closed,,Fix link to events page,"Clicking on Browse->Events caused a weird page flicker. That is because we were using the wrong `Link` component. We should use the one from react-router-dom which plays better with the UIs navigation.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-18 17:30:45+00:00,[],2024-11-18 17:33:22+00:00,2024-11-18 17:33:20+00:00,https://github.com/apache/airflow/pull/44154,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2669235031,pull_request,closed,,Improve IDE type hinting of methdtools.lru_cache in Task SDK client,"mypy doesn't check the type of double decorators (hence why we still need the
ignore misc) but pyright does, and methodtools doesn't have type hints, which
lead to it not being able to tell what type of `client.task_instances` was
",ashb,2024-11-18 16:59:15+00:00,[],2024-11-18 18:29:14+00:00,2024-11-18 18:15:38+00:00,https://github.com/apache/airflow/pull/44152,"[('area:task-sdk', None)]","[{'comment_id': 2483812715, 'issue_id': 2669235031, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 18, 18, 29, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-18 18:29:13 UTC): Nice!

"
2669035048,pull_request,closed,,spark-submit: replace `principle` by `principal`,"This is related to #43679, in which the `airflow.security.kerberos.get_kerberos_principle` function was renamed `get_kerberos_principle`.

In this patch, we introduce a `try/except` block around this import, getting ready to deprecate the typo-ed function in Airflow 3.0.

We also fix a innocuous typo in a unit test.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",brouberol,2024-11-18 15:52:13+00:00,[],2024-11-19 12:41:17+00:00,2024-11-19 12:41:17+00:00,https://github.com/apache/airflow/pull/44150,"[('area:providers', ''), ('provider:apache-spark', '')]","[{'comment_id': 2485125800, 'issue_id': 2669035048, 'author': 'brouberol', 'body': 'Sorry, I was afk for a bit. Thanks for taking care of the fixes!', 'created_at': datetime.datetime(2024, 11, 19, 9, 16, 25, tzinfo=datetime.timezone.utc)}]","brouberol (Issue Creator) on (2024-11-19 09:16:25 UTC): Sorry, I was afk for a bit. Thanks for taking care of the fixes!

"
2669028763,pull_request,closed,,AIP-84 Fix sqlite in non tests environment,"We actually need that in **tests** but also **outside of tests.** (breeze, standalone).

I didn't know that but FastAPI can use multiple threads to handle the same requests. (Some part are processed by one thread, some other by another thread, for instance for dependency resolutions).

Running breeze with sqlite currently yields errors without this change.

More information in FastAPI documentation:
https://fastapi.tiangolo.com/tutorial/sql-databases/#create-an-engine",pierrejeambrun,2024-11-18 15:49:44+00:00,['pierrejeambrun'],2024-11-19 21:21:03+00:00,2024-11-19 21:21:03+00:00,https://github.com/apache/airflow/pull/44149,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2483481387, 'issue_id': 2669028763, 'author': 'pierrejeambrun', 'body': '🤔 having some troubles when testing more extensively.', 'created_at': datetime.datetime(2024, 11, 18, 16, 7, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485983917, 'issue_id': 2669028763, 'author': 'pierrejeambrun', 'body': 'ready for review, https://github.com/apache/airflow/pull/44187 should be merged first but with this additional change solve the issues for SQLite.', 'created_at': datetime.datetime(2024, 11, 19, 15, 10, 4, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2024-11-18 16:07:40 UTC): 🤔 having some troubles when testing more extensively.

pierrejeambrun (Issue Creator) on (2024-11-19 15:10:04 UTC): ready for review, https://github.com/apache/airflow/pull/44187 should be merged first but with this additional change solve the issues for SQLite.

"
2668903554,pull_request,closed,,suppress the warnings where we check for sensitive values,"https://github.com/apache/airflow/pull/44061#issuecomment-2480320259

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fixes https://github.com/apache/airflow/issues/43794

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",zachliu,2024-11-18 15:18:01+00:00,[],2024-11-19 03:45:45+00:00,2024-11-19 03:33:04+00:00,https://github.com/apache/airflow/pull/44148,"[('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2484636423, 'issue_id': 2668903554, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44167""><img src=""https://img.shields.io/badge/PR-44167-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 11, 19, 3, 33, 51, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-19 03:33:51 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44167""><img src=""https://img.shields.io/badge/PR-44167-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2668616899,pull_request,closed,,fix(providers/databricks): remove additional argument passed to repair_run,"Closes: https://github.com/apache/airflow/issues/44114
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-18 13:45:31+00:00,[],2024-11-19 01:55:27+00:00,2024-11-19 01:55:26+00:00,https://github.com/apache/airflow/pull/44140,"[('area:providers', ''), ('provider:databricks', '')]",[],
2668552403,pull_request,closed,,AIP-84: Migrating GET queued asset events for assets to FASTAPI,"Related: https://github.com/apache/airflow/issues/42370

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-18 13:24:39+00:00,[],2024-11-19 15:20:25+00:00,2024-11-19 15:20:23+00:00,https://github.com/apache/airflow/pull/44139,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2668455282,pull_request,closed,,AIP-84: Migrating DELETE queued asset events for assets to FASTAPI,"Related: https://github.com/apache/airflow/issues/42370

Swagger Specs
<img width=""1542"" alt=""image"" src=""https://github.com/user-attachments/assets/c4a9ffe6-8d0b-40b2-99ca-3b3005d82554"">
<img width=""1423"" alt=""image"" src=""https://github.com/user-attachments/assets/5805d8d0-6141-48c4-a780-213b02645c0e"">

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).


<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-18 12:56:56+00:00,[],2024-11-18 18:30:51+00:00,2024-11-18 18:30:49+00:00,https://github.com/apache/airflow/pull/44138,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2483100335, 'issue_id': 2668455282, 'author': 'pierrejeambrun', 'body': ""Won't pass, tests need fixing"", 'created_at': datetime.datetime(2024, 11, 18, 13, 47, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483119680, 'issue_id': 2668455282, 'author': 'vatsrahul1001', 'body': ""> Won't pass, tests need fixing\r\n\r\ntaking a look"", 'created_at': datetime.datetime(2024, 11, 18, 13, 55, 37, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-18 13:47:31 UTC): Won't pass, tests need fixing

vatsrahul1001 (Issue Creator) on (2024-11-18 13:55:37 UTC): taking a look

"
2668426020,pull_request,closed,,doc: providers github link,,raphaelauv,2024-11-18 12:44:13+00:00,[],2024-11-18 19:47:22+00:00,2024-11-18 14:59:16+00:00,https://github.com/apache/airflow/pull/44136,"[('kind:documentation', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2483317269, 'issue_id': 2668426020, 'author': 'raphaelauv', 'body': ""@romsharon98 let's add this to the `apache:v2-10-test` ?"", 'created_at': datetime.datetime(2024, 11, 18, 15, 5, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483324880, 'issue_id': 2668426020, 'author': 'romsharon98', 'body': ""I don't think it should be add to `apache:v2-10-test` because it does not have this hierarchy"", 'created_at': datetime.datetime(2024, 11, 18, 15, 8, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483339686, 'issue_id': 2668426020, 'author': 'raphaelauv', 'body': 'the current like is dead in the documentation , so we need to fix it ( otherwise it will be dead until release of airflow 3 )', 'created_at': datetime.datetime(2024, 11, 18, 15, 14, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483373699, 'issue_id': 2668426020, 'author': 'romsharon98', 'body': 'Oh my mistake! I will create a PR for backporting it', 'created_at': datetime.datetime(2024, 11, 18, 15, 27, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483959795, 'issue_id': 2668426020, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/44157""><img src=""https://img.shields.io/badge/PR-44157-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2024, 11, 18, 19, 47, 20, tzinfo=datetime.timezone.utc)}]","raphaelauv (Issue Creator) on (2024-11-18 15:05:56 UTC): @romsharon98 let's add this to the `apache:v2-10-test` ?

romsharon98 on (2024-11-18 15:08:57 UTC): I don't think it should be add to `apache:v2-10-test` because it does not have this hierarchy

raphaelauv (Issue Creator) on (2024-11-18 15:14:05 UTC): the current like is dead in the documentation , so we need to fix it ( otherwise it will be dead until release of airflow 3 )

romsharon98 on (2024-11-18 15:27:07 UTC): Oh my mistake! I will create a PR for backporting it

github-actions[bot] on (2024-11-18 19:47:20 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/44157""><img src=""https://img.shields.io/badge/PR-44157-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2668146731,pull_request,closed,,AIP-84 Clean status code,"Clean remnant of 401, 403 errors.",pierrejeambrun,2024-11-18 11:02:25+00:00,[],2024-11-18 11:59:06+00:00,2024-11-18 11:59:04+00:00,https://github.com/apache/airflow/pull/44134,"[('AIP-84', 'Modern Rest API')]",[],
2667893442,pull_request,closed,,get_task_instance_try_details API returns TaskInstanceHistory schema …,"…(#43830)

* Update v1.yaml

these
- get_task_instance_try_details
- get_mapped_task_instance_try_details
- get_task_instance_tries
- get_mapped_task_instance_tries

are actually returning TaskInstanceHistory

* Update v1.yaml

* dummy change

* revert ""dummy change""

* Update api-generated.ts

* Update api-generated.ts

* Update api-generated.ts

* Update api-generated.ts

* changes to v1.yaml

* Update api-generated.ts

* removing execution_date

---------

Co-authored-by: kandharvishnuu <148410552+kandharvishnuu@users.noreply.github.com>
(cherry picked from commit 6f02fdbe2e917d20482fd31c1b090b5d6d880320)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2024-11-18 09:49:35+00:00,['pierrejeambrun'],2024-11-18 13:21:10+00:00,2024-11-18 13:21:08+00:00,https://github.com/apache/airflow/pull/44133,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2667746723,pull_request,closed,,Update providers metadata 2024-11-18,,eladkal,2024-11-18 09:04:01+00:00,[],2024-11-18 11:35:12+00:00,2024-11-18 11:35:09+00:00,https://github.com/apache/airflow/pull/44132,[],[],
2667723267,pull_request,closed,,Bugfix KubernetesJobOperator.on_kill(),"Bugfix the `KubernetesJobOperator` by removing the ""job"" parameter from the K8s client method call (`delete_namespaced_job`) as it is not expected by [the API](https://github.com/kubernetes-client/python/blob/v31.0.0/kubernetes/docs/BatchV1Api.md#delete_namespaced_job). Apparently this parameter was added here by mistake.",moiseenkov,2024-11-18 08:55:32+00:00,[],2024-11-18 23:55:03+00:00,2024-11-18 23:55:03+00:00,https://github.com/apache/airflow/pull/44131,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2482364374, 'issue_id': 2667723267, 'author': 'eladkal', 'body': 'Can you amend the commit to a meaningful one? We use commit titles for change log', 'created_at': datetime.datetime(2024, 11, 18, 9, 12, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482375375, 'issue_id': 2667723267, 'author': 'moiseenkov', 'body': '> Can you amend the commit to a meaningful one? We use commit titles for change log\r\n\r\nDone. Thanks for noticing!', 'created_at': datetime.datetime(2024, 11, 18, 9, 17, 13, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-18 09:12:53 UTC): Can you amend the commit to a meaningful one? We use commit titles for change log

moiseenkov (Issue Creator) on (2024-11-18 09:17:13 UTC): Done. Thanks for noticing!

"
2667712975,pull_request,closed,,AIP-84: Migrating DELETE a queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370
Migrating delete a queued asset events for DAG to fastAPI

Dependent on https://github.com/apache/airflow/pull/44124

Same setup as https://github.com/apache/airflow/pull/44124

Responses:
1. Legacy
![image](https://github.com/user-attachments/assets/68af6869-4ba4-4343-a9c3-cf7ac98bc17e)

2. FastAPI
![image](https://github.com/user-attachments/assets/4d4df85a-d21d-46f3-8d57-d6c8e495d886)


With time filtering:
1. Legacy
![image](https://github.com/user-attachments/assets/b58aec22-0245-43f9-97bd-44c8c70efe9a)

2. FastAPI
![image](https://github.com/user-attachments/assets/386de798-88ab-4798-adf4-22c8440618e2)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-18 08:51:00+00:00,['amoghrajesh'],2024-11-19 07:12:07+00:00,2024-11-19 07:12:05+00:00,https://github.com/apache/airflow/pull/44130,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2667651173,pull_request,closed,,AIP-84: Migrating DELETE queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370
Migrating delete queued asset events for DAG to fastAPI 

Dependent on https://github.com/apache/airflow/pull/44124


Same setup as https://github.com/apache/airflow/pull/44124

Responses:
1. Legacy
![image](https://github.com/user-attachments/assets/7188d931-afc1-4fd1-be1a-009faacf40fb)

2. FastAPI
![image](https://github.com/user-attachments/assets/55f23c87-dde7-4229-a3e8-2ea380259d88)


With time filtering
1. Legacy
![image](https://github.com/user-attachments/assets/5180412c-fd32-4289-8399-9eb8e8a3c518)

2. FastAPI
![image](https://github.com/user-attachments/assets/7b39e98b-821b-48e8-bf78-c58e9080850e)

Time filtering but no queued event found
1. Legacy
![image](https://github.com/user-attachments/assets/bb46d7ae-1eb5-4272-b07b-d22dfef4f64d)

2. FastAPI
![image](https://github.com/user-attachments/assets/d7a44f48-05fb-4e91-be63-0feec6e6f716)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-18 08:41:55+00:00,['amoghrajesh'],2024-11-18 13:57:08+00:00,2024-11-18 13:57:06+00:00,https://github.com/apache/airflow/pull/44129,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2482896989, 'issue_id': 2667651173, 'author': 'amoghrajesh', 'body': '@Lee-W @rawwar I pushed a fix for the reviews, can you check again?', 'created_at': datetime.datetime(2024, 11, 18, 12, 25, 17, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-18 12:25:17 UTC): @Lee-W @rawwar I pushed a fix for the reviews, can you check again?

"
2667620687,pull_request,closed,,AIP-84: Migrating GET one queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370

Same setup as https://github.com/apache/airflow/pull/44124 and dependent on https://github.com/apache/airflow/pull/44124

Responses:
1. Legacy
![image](https://github.com/user-attachments/assets/9434be96-5558-4d55-a2a2-565df823411b)


2. FastAPI
![image](https://github.com/user-attachments/assets/50257c74-b1e3-440e-9d9f-f303c9d597e9)

With time filtering
1. Legacy
![image](https://github.com/user-attachments/assets/d079968c-a8e2-4cd7-8000-48862b0a9c87)

2. FastAPI
![image](https://github.com/user-attachments/assets/f960ecf4-411e-431a-80b5-c5093ec76d2a)

Swagger spec:
<img width=""1279"" alt=""image"" src=""https://github.com/user-attachments/assets/e0057771-8964-4f88-badc-b23f32a89eb9"">

<img width=""1279"" alt=""image"" src=""https://github.com/user-attachments/assets/7bbfb0b2-64f5-416d-9307-a1f43e2e4c84"">



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-18 08:27:23+00:00,['amoghrajesh'],2024-11-19 05:47:59+00:00,2024-11-19 05:47:58+00:00,https://github.com/apache/airflow/pull/44128,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2482258084, 'issue_id': 2667620687, 'author': 'amoghrajesh', 'body': 'Only last commit is relevant', 'created_at': datetime.datetime(2024, 11, 18, 8, 27, 36, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-18 08:27:36 UTC): Only last commit is relevant

"
2667538409,pull_request,closed,,Add directory transfer support for SFTPOperator,"This PR implements directory transfer for SFTPOperator, related to the [issue](https://github.com/apache/airflow/issues/40365) I have raised before.
Currently, the SFTPOperator only accepts file paths, and you have to specify every filename in a folder by list when transferring an entire folder.
By adding some directory handling logic, the operator now can accept directory paths as well, allowing users easily transfer entire folders.
",Dawnpool,2024-11-18 07:47:45+00:00,[],2024-12-31 05:01:15+00:00,2024-12-28 01:44:25+00:00,https://github.com/apache/airflow/pull/44126,"[('area:providers', ''), ('provider:sftp', '')]","[{'comment_id': 2482181134, 'issue_id': 2667538409, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 18, 7, 47, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483706176, 'issue_id': 2667538409, 'author': 'kunaljubce', 'body': '@Dawnpool You seem to have a whole test non-db test suite failing. Can you check it on your local breeze and see if you can fix it?', 'created_at': datetime.datetime(2024, 11, 18, 17, 39, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2496085469, 'issue_id': 2667538409, 'author': 'Dawnpool', 'body': '> @Dawnpool You seem to have a whole test non-db test suite failing. Can you check it on your local breeze and see if you can fix it?\r\n\r\nHi, I guess there was an issue with the test code at the time I forked the repository. It might have been resolved by merging the main branch. There is no problem on my local breeze environment for now.', 'created_at': datetime.datetime(2024, 11, 24, 16, 1, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2499802218, 'issue_id': 2667538409, 'author': 'kunaljubce', 'body': ""> > @Dawnpool You seem to have a whole test non-db test suite failing. Can you check it on your local breeze and see if you can fix it?\r\n> \r\n> Hi, I guess there was an issue with the test code at the time I forked the repository. It might have been resolved by merging the main branch. There is no problem on my local breeze environment for now.\r\n\r\nLet's wait for one of the maintainers to approve the remaining workflows. That will give you some clarity if rebasing against `main` fixed it. Feel free to drop a gentle reminder on the Slack channel - `#contributors`."", 'created_at': datetime.datetime(2024, 11, 26, 6, 52, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505056501, 'issue_id': 2667538409, 'author': 'potiuk', 'body': ""> Let's wait for one of the maintainers to approve the remaining workflows. That will give you some clarity if rebasing against `main` fixed it. Feel free to drop a gentle reminder on the Slack channel - `#contributors`.\r\n\r\nApproved workflows."", 'created_at': datetime.datetime(2024, 11, 28, 0, 44, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505182474, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'errrors, errors everywhere :D', 'created_at': datetime.datetime(2024, 11, 28, 3, 13, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506510376, 'issue_id': 2667538409, 'author': 'kunaljubce', 'body': ""@Dawnpool Try reproducing your CI tests locally and figuring out what's going wrong. Seems this is a good place to start - https://github.com/apache/airflow/blob/main/dev/breeze/doc/ci/08_running_ci_locally.md"", 'created_at': datetime.datetime(2024, 11, 28, 16, 53, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2553134209, 'issue_id': 2667538409, 'author': 'eladkal', 'body': 'PR has conflicts that needs to be resolved', 'created_at': datetime.datetime(2024, 12, 19, 9, 5, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559115598, 'issue_id': 2667538409, 'author': 'Dawnpool', 'body': ""@potiuk \r\nThe non-db tests keep failing and it doesn't seem related to the changes I made based on the error logs.\r\nI noticed your comment(https://github.com/apache/airflow/pull/44625#issuecomment-2522299932) on a recent approved PR with the same error, where you mentioned that it was an unrelated intermittent error. Is there an ongoing issue with the non-db tests?\r\n\r\n@eladkal \r\nI have resolved the conflicts. Please feel free to check!"", 'created_at': datetime.datetime(2024, 12, 23, 8, 6, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2559629012, 'issue_id': 2667538409, 'author': 'potiuk', 'body': ""I think it's a side effect of bad  configuration - likely some initialization issue in some of the skipped provider tests that are missing somewhere. Likely it is mitigated when full tests are run as some other tests are intitializing SQL Alchemy (where we completely should not need it for DB Tests). I will take a look at it later today and try to find out what it is (And it would be great to not merge it till then as we might be eble to see if the problem is fixed when I find it."", 'created_at': datetime.datetime(2024, 12, 23, 12, 35, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563560360, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'Can you please rebase/resolve conflicts and ping me if it fails again.', 'created_at': datetime.datetime(2024, 12, 27, 10, 31, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563642617, 'issue_id': 2667538409, 'author': 'Dawnpool', 'body': '@potiuk \r\nit failed again😥 same error with the non-db tests', 'created_at': datetime.datetime(2024, 12, 27, 12, 12, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563698061, 'issue_id': 2667538409, 'author': 'potiuk', 'body': ':scream:', 'created_at': datetime.datetime(2024, 12, 27, 13, 22, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563702881, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'I think this should fix it: https://github.com/apache/airflow/pull/45244', 'created_at': datetime.datetime(2024, 12, 27, 13, 28, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563728591, 'issue_id': 2667538409, 'author': 'potiuk', 'body': ""Let's see - I added the fix on top and we should see if the problem is fixed."", 'created_at': datetime.datetime(2024, 12, 27, 13, 59, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563806955, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'Nope - there is another issue', 'created_at': datetime.datetime(2024, 12, 27, 15, 33, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2563905558, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'All right. I think I found it https://github.com/apache/airflow/pull/45249 - very interesting issue (and your change accidentally revealed it because it selectively run non-db `microsoft.azure` test collection as the first group of tests to run - and it turned out that those tests relied on a side-effect of other tests being run before.', 'created_at': datetime.datetime(2024, 12, 27, 17, 45, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564008659, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'OK. The fix is merged. You can rebase again and I :crossed_fingers: that it should work now.', 'created_at': datetime.datetime(2024, 12, 27, 20, 23, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564133291, 'issue_id': 2667538409, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 28, 1, 44, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564133320, 'issue_id': 2667538409, 'author': 'potiuk', 'body': 'Finally!', 'created_at': datetime.datetime(2024, 12, 28, 1, 44, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564134453, 'issue_id': 2667538409, 'author': 'Dawnpool', 'body': 'Finally! Thank you all😁', 'created_at': datetime.datetime(2024, 12, 28, 1, 49, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2564362993, 'issue_id': 2667538409, 'author': 'Dev-iL', 'body': 'Thank you for your contribution @Dawnpool!\r\n\r\nIn this implementation, files are downloaded sequentially, right? If so - when downloading folders containing a large number of small files, this approach will be quite inefficient. I think we should consider expanding the method, or adding another one that downloads files concurrently.  \r\n\r\nPossibly related to [SFTPHookAsync](https://airflow.apache.org/docs/apache-airflow-providers-sftp/stable/_api/airflow/providers/sftp/hooks/sftp/index.html#airflow.providers.sftp.hooks.sftp.SFTPHookAsync).', 'created_at': datetime.datetime(2024, 12, 28, 15, 31, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566131567, 'issue_id': 2667538409, 'author': 'Dawnpool', 'body': ""Hi @Dev-iL!\r\nYes, just as you said, files are downloaded sequentially since it simply uses multiple calls to the `retrieve_file` function in the order file names are collected.\r\nI totally agree with your point this approach would be inefficient in the case you said.\r\nIt would be awesome if we could download multiple files concurrently, but I'm not sure what kind of approach to take (probably multi-threading?) and we should definitely do performance checks to compare after implementing the method."", 'created_at': datetime.datetime(2024, 12, 31, 4, 54, 37, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-18 07:47:49 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

kunaljubce on (2024-11-18 17:39:27 UTC): @Dawnpool You seem to have a whole test non-db test suite failing. Can you check it on your local breeze and see if you can fix it?

Dawnpool (Issue Creator) on (2024-11-24 16:01:55 UTC): Hi, I guess there was an issue with the test code at the time I forked the repository. It might have been resolved by merging the main branch. There is no problem on my local breeze environment for now.

kunaljubce on (2024-11-26 06:52:53 UTC): Let's wait for one of the maintainers to approve the remaining workflows. That will give you some clarity if rebasing against `main` fixed it. Feel free to drop a gentle reminder on the Slack channel - `#contributors`.

potiuk on (2024-11-28 00:44:53 UTC): Approved workflows.

potiuk on (2024-11-28 03:13:08 UTC): errrors, errors everywhere :D

kunaljubce on (2024-11-28 16:53:27 UTC): @Dawnpool Try reproducing your CI tests locally and figuring out what's going wrong. Seems this is a good place to start - https://github.com/apache/airflow/blob/main/dev/breeze/doc/ci/08_running_ci_locally.md

eladkal on (2024-12-19 09:05:05 UTC): PR has conflicts that needs to be resolved

Dawnpool (Issue Creator) on (2024-12-23 08:06:12 UTC): @potiuk 
The non-db tests keep failing and it doesn't seem related to the changes I made based on the error logs.
I noticed your comment(https://github.com/apache/airflow/pull/44625#issuecomment-2522299932) on a recent approved PR with the same error, where you mentioned that it was an unrelated intermittent error. Is there an ongoing issue with the non-db tests?

@eladkal 
I have resolved the conflicts. Please feel free to check!

potiuk on (2024-12-23 12:35:44 UTC): I think it's a side effect of bad  configuration - likely some initialization issue in some of the skipped provider tests that are missing somewhere. Likely it is mitigated when full tests are run as some other tests are intitializing SQL Alchemy (where we completely should not need it for DB Tests). I will take a look at it later today and try to find out what it is (And it would be great to not merge it till then as we might be eble to see if the problem is fixed when I find it.

potiuk on (2024-12-27 10:31:37 UTC): Can you please rebase/resolve conflicts and ping me if it fails again.

Dawnpool (Issue Creator) on (2024-12-27 12:12:06 UTC): @potiuk 
it failed again😥 same error with the non-db tests

potiuk on (2024-12-27 13:22:28 UTC): :scream:

potiuk on (2024-12-27 13:28:29 UTC): I think this should fix it: https://github.com/apache/airflow/pull/45244

potiuk on (2024-12-27 13:59:27 UTC): Let's see - I added the fix on top and we should see if the problem is fixed.

potiuk on (2024-12-27 15:33:40 UTC): Nope - there is another issue

potiuk on (2024-12-27 17:45:05 UTC): All right. I think I found it https://github.com/apache/airflow/pull/45249 - very interesting issue (and your change accidentally revealed it because it selectively run non-db `microsoft.azure` test collection as the first group of tests to run - and it turned out that those tests relied on a side-effect of other tests being run before.

potiuk on (2024-12-27 20:23:43 UTC): OK. The fix is merged. You can rebase again and I :crossed_fingers: that it should work now.

boring-cyborg[bot] on (2024-12-28 01:44:27 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-12-28 01:44:32 UTC): Finally!

Dawnpool (Issue Creator) on (2024-12-28 01:49:37 UTC): Finally! Thank you all😁

Dev-iL on (2024-12-28 15:31:55 UTC): Thank you for your contribution @Dawnpool!

In this implementation, files are downloaded sequentially, right? If so - when downloading folders containing a large number of small files, this approach will be quite inefficient. I think we should consider expanding the method, or adding another one that downloads files concurrently.  

Possibly related to [SFTPHookAsync](https://airflow.apache.org/docs/apache-airflow-providers-sftp/stable/_api/airflow/providers/sftp/hooks/sftp/index.html#airflow.providers.sftp.hooks.sftp.SFTPHookAsync).

Dawnpool (Issue Creator) on (2024-12-31 04:54:37 UTC): Hi @Dev-iL!
Yes, just as you said, files are downloaded sequentially since it simply uses multiple calls to the `retrieve_file` function in the order file names are collected.
I totally agree with your point this approach would be inefficient in the case you said.
It would be awesome if we could download multiple files concurrently, but I'm not sure what kind of approach to take (probably multi-threading?) and we should definitely do performance checks to compare after implementing the method.

"
2667419587,pull_request,closed,,Improve dag_maker compatibility handling,"This makes dag_maker automatically handle the Airflow 2-3 difference on logical_date/execution_date, and the new required triggered_by argument. This way, we can eliminate most of the compatibility code in provider tests.

Edit: Forgot to mention, I also took the chance to add some more type hints to related fixtures.",uranusjr,2024-11-18 07:05:27+00:00,[],2024-11-18 23:56:06+00:00,2024-11-18 10:27:40+00:00,https://github.com/apache/airflow/pull/44125,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:sftp', ''), ('provider:standard', '')]",[],
2667287349,pull_request,closed,,AIP-84: Migrating GET queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #42370 

Migrating the GET queued asset events for a DAG endpoint to fast API.

Setup:
1. Created producer and consumer dags:
![image](https://github.com/user-attachments/assets/951335ba-7e56-488d-8d56-3642ddb3b699)

2. Paused one producer while running the other to generate queued events
![image](https://github.com/user-attachments/assets/09945aa8-4a0f-43bf-858c-bc42480f2b01)

Responses:

1. Legacy
![image](https://github.com/user-attachments/assets/5377c493-2bfb-4f38-b6c2-0b01c9cfa291)

2. FastAPI
![image](https://github.com/user-attachments/assets/d7d6ea27-2035-4b8b-bb52-18b587207344)

With time filtering:
1. Legacy
![image](https://github.com/user-attachments/assets/a87e99f3-04a5-4598-ac95-6bb68edefcf7)

(Beyond creation time)
![image](https://github.com/user-attachments/assets/e03505ea-82c7-4741-ad6a-d6a273eea377)

2. FastAPI
![image](https://github.com/user-attachments/assets/8a2ce955-bdbb-4dea-96b1-09973d0185e2)

(Beyond creation time)
![image](https://github.com/user-attachments/assets/5b7b47cd-a586-4505-939d-2a8743007782)


Swagger spec: (maintained under dag section)
![image](https://github.com/user-attachments/assets/8fd645c8-b9a3-4eca-a4f6-488bd03395b4)

![image](https://github.com/user-attachments/assets/8fd645c8-b9a3-4eca-a4f6-488bd03395b4)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-18 06:13:19+00:00,['amoghrajesh'],2024-11-18 09:25:53+00:00,2024-11-18 09:25:51+00:00,https://github.com/apache/airflow/pull/44124,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2482283789, 'issue_id': 2667287349, 'author': 'pierrejeambrun', 'body': 'Just rebased the branch to get the latest, I think we can merge then if the CI is green.', 'created_at': datetime.datetime(2024, 11, 18, 8, 39, 47, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-18 08:39:47 UTC): Just rebased the branch to get the latest, I think we can merge then if the CI is green.

"
2667012598,pull_request,closed,,Update databricks.rst,"remove the duplicate line

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",KaraBilly,2024-11-18 03:47:28+00:00,[],2025-01-09 00:15:36+00:00,2025-01-09 00:15:36+00:00,https://github.com/apache/airflow/pull/44122,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('kind:documentation', ''), ('pending-response', ''), ('provider:databricks', '')]","[{'comment_id': 2481887358, 'issue_id': 2667012598, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 18, 3, 47, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569955045, 'issue_id': 2667012598, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 4, 0, 14, 55, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-18 03:47:32 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

github-actions[bot] on (2025-01-04 00:14:55 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2666911738,pull_request,closed,,AIP-81 Add Insert Multiple Pools API,"closes: #43896
related: #43657

### Fix: Add `max_length=256` for `PoolPostBody.pool`  

The model defined in https://github.com/apache/airflow/blob/main/airflow/models/pool.py#L54 enforces a string length constraint on `Pool.pool`. To maintain consistency, this constraint should also be validated at the router level.  

### Refactor: Handle Duplicate Cases in `Insert Pool`  

The `Insert Pool` (single insert) functionality should account for cases where a duplicate pool name is provided, as `Pool.pool` is defined with a `unique` constraint.  

### Feat: Add Insert Multiple Pools API  

A new API endpoint for inserting multiple pools has been introduced as `/pools/bulk`. Alternative names such as `/pools/batch` or `/pools/multiple` were considered. Feedback on which name best describes the endpoint is welcome.  
",jason810496,2024-11-18 02:53:50+00:00,[],2025-01-23 09:15:20+00:00,2024-11-22 08:40:35+00:00,https://github.com/apache/airflow/pull/44121,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('AIP-81', 'Enhanced Security in CLI via Integration of API')]","[{'comment_id': 2486456350, 'issue_id': 2666911738, 'author': 'bugraoz93', 'body': 'Looks good! Thanks for the changes @jason810496! I believe the CI failure is likely a transient error caused by a DNS issue that couldn’t resolve AWS S3 at that moment.', 'created_at': datetime.datetime(2024, 11, 19, 18, 31, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487235191, 'issue_id': 2666911738, 'author': 'Lee-W', 'body': '> Looks good! Thanks for the changes @jason810496! I believe the CI failure is likely a transient error caused by a DNS issue that couldn’t resolve AWS S3 at that moment.\r\n\r\njust reran. seems to work fine 👀', 'created_at': datetime.datetime(2024, 11, 20, 2, 51, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488459353, 'issue_id': 2666911738, 'author': 'jason810496', 'body': 'Just resolved the issue with inserting duplicate pools by handling the database exception rather than adding extra logic to the `datamodels` or performing additional database queries.  \r\nBy the way, I’m happy to work further on refactoring to handle duplicate insertion cases across all endpoints  🙌', 'created_at': datetime.datetime(2024, 11, 20, 12, 28, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488613082, 'issue_id': 2666911738, 'author': 'pierrejeambrun', 'body': ""> By the way, I’m happy to work further on refactoring to handle duplicate insertion cases across all endpoints 🙌\r\n\r\nThat would be great. You can create an issue to track that if you're not going to work on it directly just so we do not forget about it. If you plan on tackling that right away, no need to create an issue opening a PR is perfectly fine."", 'created_at': datetime.datetime(2024, 11, 20, 13, 38, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493114866, 'issue_id': 2666911738, 'author': 'jason810496', 'body': 'Just fixed the nit. I will refactor all endpoints to adopt the global error handler for managing unique constraint violation errors in further PR.', 'created_at': datetime.datetime(2024, 11, 22, 8, 3, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493193823, 'issue_id': 2666911738, 'author': 'pierrejeambrun', 'body': ""> Just fixed the nit. I will refactor all endpoints to adopt the global error handler for managing unique constraint violation errors in further PR.\r\n\r\nNice. 🎉 \r\n\r\nWhat is great about that is the `exception_handler` is global to the application. All endpoints should benefit from it without any additional specifications. The only thing I can thing of is to correctly document the `409` that can be possibly returned. (That's the benefit of this approach)"", 'created_at': datetime.datetime(2024, 11, 22, 8, 40, 16, tzinfo=datetime.timezone.utc)}]","bugraoz93 on (2024-11-19 18:31:44 UTC): Looks good! Thanks for the changes @jason810496! I believe the CI failure is likely a transient error caused by a DNS issue that couldn’t resolve AWS S3 at that moment.

Lee-W on (2024-11-20 02:51:43 UTC): just reran. seems to work fine 👀

jason810496 (Issue Creator) on (2024-11-20 12:28:53 UTC): Just resolved the issue with inserting duplicate pools by handling the database exception rather than adding extra logic to the `datamodels` or performing additional database queries.  
By the way, I’m happy to work further on refactoring to handle duplicate insertion cases across all endpoints  🙌

pierrejeambrun on (2024-11-20 13:38:42 UTC): That would be great. You can create an issue to track that if you're not going to work on it directly just so we do not forget about it. If you plan on tackling that right away, no need to create an issue opening a PR is perfectly fine.

jason810496 (Issue Creator) on (2024-11-22 08:03:19 UTC): Just fixed the nit. I will refactor all endpoints to adopt the global error handler for managing unique constraint violation errors in further PR.

pierrejeambrun on (2024-11-22 08:40:16 UTC): Nice. 🎉 

What is great about that is the `exception_handler` is global to the application. All endpoints should benefit from it without any additional specifications. The only thing I can thing of is to correctly document the `409` that can be possibly returned. (That's the benefit of this approach)

"
2666260900,pull_request,closed,,Fix missing end of block in Airflow 3 DEV readme,"Follow up after #44118

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-17 18:38:50+00:00,[],2024-11-17 21:05:49+00:00,2024-11-17 21:05:08+00:00,https://github.com/apache/airflow/pull/44120,"[('area:dev-tools', '')]","[{'comment_id': 2481421949, 'issue_id': 2666260900, 'author': 'potiuk', 'body': 'Merged previous one too fast :)', 'created_at': datetime.datetime(2024, 11, 17, 18, 39, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481560764, 'issue_id': 2666260900, 'author': 'potiuk', 'body': '> sorry my bad, that suggestion added properly.\r\n\r\nAnd I did not check how it renders :)', 'created_at': datetime.datetime(2024, 11, 17, 21, 5, 47, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-17 18:39:14 UTC): Merged previous one too fast :)

potiuk (Issue Creator) on (2024-11-17 21:05:47 UTC): And I did not check how it renders :)

"
2666245791,pull_request,closed,,Update Edge Executor documentation to current state,Adding some clarification to current state and that it must be built manually atm.,jscheffl,2024-11-17 18:05:50+00:00,[],2024-11-18 02:26:08+00:00,2024-11-18 02:26:08+00:00,https://github.com/apache/airflow/pull/44119,"[('area:providers', ''), ('kind:documentation', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2666222067,pull_request,closed,,Add cherry-picker documentation,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-17 17:36:34+00:00,[],2024-11-17 18:35:09+00:00,2024-11-17 18:35:06+00:00,https://github.com/apache/airflow/pull/44118,"[('area:dev-tools', '')]","[{'comment_id': 2481420542, 'issue_id': 2666222067, 'author': 'potiuk', 'body': '> Cool! Maybe should we also just model `cherry-picker`being a dependency in breeze that this is automatically installed when setting up breeze? :-D\r\n\r\nI think that is mostly an ""external"" dependency that should be use outside of breeze and independently which environment you are in.  If you install it with `breeze` it will shadow the one that you have installed with `uv tool` or `pipx`. Not sure if that is what we want :)', 'created_at': datetime.datetime(2024, 11, 17, 18, 34, 45, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-17 18:34:45 UTC): I think that is mostly an ""external"" dependency that should be use outside of breeze and independently which environment you are in.  If you install it with `breeze` it will shadow the one that you have installed with `uv tool` or `pipx`. Not sure if that is what we want :)

"
2666176103,pull_request,closed,,Bump cross-spawn from 7.0.3 to 7.0.5 in /airflow/ui,"Bumps [cross-spawn](https://github.com/moxystudio/node-cross-spawn) from 7.0.3 to 7.0.5.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/moxystudio/node-cross-spawn/blob/master/CHANGELOG.md"">cross-spawn's changelog</a>.</em></p>
<blockquote>
<h3><a href=""https://github.com/moxystudio/node-cross-spawn/compare/v7.0.4...v7.0.5"">7.0.5</a> (2024-11-07)</h3>
<h3>Bug Fixes</h3>
<ul>
<li>fix escaping bug introduced by backtracking (<a href=""https://github.com/moxystudio/node-cross-spawn/commit/640d391fde65388548601d95abedccc12943374f"">640d391</a>)</li>
</ul>
<h3><a href=""https://github.com/moxystudio/node-cross-spawn/compare/v7.0.3...v7.0.4"">7.0.4</a> (2024-11-07)</h3>
<h3>Bug Fixes</h3>
<ul>
<li>disable regexp backtracking (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/160"">#160</a>) (<a href=""https://github.com/moxystudio/node-cross-spawn/commit/5ff3a07d9add449021d806e45c4168203aa833ff"">5ff3a07</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/085268352dcbcad8064c64c5efb25268b4023184""><code>0852683</code></a> chore(release): 7.0.5</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/640d391fde65388548601d95abedccc12943374f""><code>640d391</code></a> fix: fix escaping bug introduced by backtracking</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/bff0c87c8b627c4e6d04ec2449e733048bebb464""><code>bff0c87</code></a> chore: remove codecov</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/a7c6abc6fee79641d45b452fe6217deaa1bd0973""><code>a7c6abc</code></a> chore: replace travis with github workflows</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/9b9246e0969e86656d7ccd527716bc3c18842a19""><code>9b9246e</code></a> chore(release): 7.0.4</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/5ff3a07d9add449021d806e45c4168203aa833ff""><code>5ff3a07</code></a> fix: disable regexp backtracking (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/160"">#160</a>)</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/9521e2da94d94998f948e0455903e62d87884600""><code>9521e2d</code></a> chore: fix tests in recent node js versions</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/97ded399e9c9ae325040fc52274c1cd4def357f8""><code>97ded39</code></a> chore: convert package lock</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/d52b6b9da499ca464e609162a6afeb326f1dbbb1""><code>d52b6b9</code></a> chore: remove unused argument (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/156"">#156</a>)</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/5d843849e1ed434b7030e0aa49281c2bf4ad2e71""><code>5d84384</code></a> chore: add travis jobs on ppc64le (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/142"">#142</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/moxystudio/node-cross-spawn/compare/v7.0.3...v7.0.5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cross-spawn&package-manager=npm_and_yarn&previous-version=7.0.3&new-version=7.0.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-11-17 17:14:30+00:00,[],2024-11-17 17:26:44+00:00,2024-11-17 17:26:36+00:00,https://github.com/apache/airflow/pull/44117,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2666169012,pull_request,closed,,Move cherry pick config to root and better rename for backport workflow,"Moving cherry picker config to root.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-17 17:06:56+00:00,[],2024-11-17 17:13:11+00:00,2024-11-17 17:13:11+00:00,https://github.com/apache/airflow/pull/44116,"[('area:dev-tools', '')]",[],
2666003577,pull_request,closed,,Bump to mypy-boto3-appflow and pass without `# type: ignore[arg-type]`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44111 



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jx2lee,2024-11-17 15:28:26+00:00,[],2024-11-18 07:34:00+00:00,2024-11-18 00:23:42+00:00,https://github.com/apache/airflow/pull/44115,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2481701595, 'issue_id': 2666003577, 'author': 'potiuk', 'body': 'NICE! Good job @jx2lee !', 'created_at': datetime.datetime(2024, 11, 18, 0, 23, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481702631, 'issue_id': 2666003577, 'author': 'jx2lee', 'body': '@potiuk Thank you for reviewing! 💟', 'created_at': datetime.datetime(2024, 11, 18, 0, 25, 8, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-18 00:23:36 UTC): NICE! Good job @jx2lee !

jx2lee (Issue Creator) on (2024-11-18 00:25:08 UTC): @potiuk Thank you for reviewing! 💟

"
2665917561,pull_request,closed,,Update v2-10-test constraints,"Constraints raise an error on v2-10-test, see https://github.com/apache/airflow/actions/runs/11879458232/job/33101430691

This PR updates constraints in hoping to get it green again",jscheffl,2024-11-17 14:20:21+00:00,[],2024-12-04 09:00:50+00:00,2024-11-17 16:55:27+00:00,https://github.com/apache/airflow/pull/44113,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:helm-chart', 'Airflow Helm Chart'), ('area:production-image', 'Production image improvements and fixes'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2481370979, 'issue_id': 2665917561, 'author': 'potiuk', 'body': 'The lowest-dep failure was accidental', 'created_at': datetime.datetime(2024, 11, 17, 16, 55, 39, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-17 16:55:39 UTC): The lowest-dep failure was accidental

"
2665834040,pull_request,closed,,Fix docker documentation auth url,"While testing the release docker provider, observed the documentation for docker api broken.

https://airflow.apache.org/docs/apache-airflow-providers-docker/stable/connections/docker.html

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-17 12:59:12+00:00,[],2024-11-17 16:47:03+00:00,2024-11-17 16:47:03+00:00,https://github.com/apache/airflow/pull/44112,"[('area:providers', ''), ('kind:documentation', ''), ('provider:docker', '')]",[],
2665404101,pull_request,closed,,update standard provider CHANGELOG.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",eladkal,2024-11-17 06:56:14+00:00,[],2024-11-17 09:37:59+00:00,2024-11-17 09:37:56+00:00,https://github.com/apache/airflow/pull/44110,"[('area:providers', ''), ('provider:standard', '')]",[],
2665210706,pull_request,closed,,AIP-84 Allow only positive limit and offset  ,"As of now, OffsetFilter and LimitFilter allow the setting of negative values. With this PR, negative values will raise a 400 error.",rawwar,2024-11-17 03:28:22+00:00,[],2024-11-18 17:36:12+00:00,2024-11-18 17:36:12+00:00,https://github.com/apache/airflow/pull/44109,"[('AIP-84', 'Modern Rest API')]","[{'comment_id': 2481320168, 'issue_id': 2665210706, 'author': 'rawwar', 'body': ""> Could you please add a test for this?\r\n\r\n~~We aren't adding tests specifically for filters. But, I'm adding endpoints which will utilize this and have tests. - #43506~~\r\n\r\nI'll add a few to existing endpoints to verify the tests. Thanks"", 'created_at': datetime.datetime(2024, 11, 17, 15, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483557532, 'issue_id': 2665210706, 'author': 'pierrejeambrun', 'body': 'Wating for https://github.com/apache/airflow/pull/44138 before merging. (This CI is shorter to run, and PR is easier to update if there are merge conflicts)', 'created_at': datetime.datetime(2024, 11, 18, 16, 39, 26, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-17 15:39:00 UTC): ~~We aren't adding tests specifically for filters. But, I'm adding endpoints which will utilize this and have tests. - #43506~~

I'll add a few to existing endpoints to verify the tests. Thanks

pierrejeambrun on (2024-11-18 16:39:26 UTC): Wating for https://github.com/apache/airflow/pull/44138 before merging. (This CI is shorter to run, and PR is easier to update if there are merge conflicts)

"
2665166472,pull_request,closed,,adding new dateformatter,Fixes #44033,iprithv,2024-11-17 03:04:51+00:00,[],2025-01-12 00:17:23+00:00,2025-01-12 00:17:23+00:00,https://github.com/apache/airflow/pull/44108,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file')]","[{'comment_id': 2480904320, 'issue_id': 2665166472, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 17, 3, 4, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482068235, 'issue_id': 2665166472, 'author': 'kunaljubce', 'body': '@amoghrajesh I see this `.isoformat().replace(""+00:00"", ""Z"")` usage in a couple of other places too. Do you suggest moving to the same formatter for consistency?\r\n\r\nhttps://github.com/kunaljubce/airflow/blob/c269be90c9a840d159fd38c03459bc6aeaf5708d/tests/api_fastapi/core_api/routes/public/test_import_error.py#L118\r\nhttps://github.com/kunaljubce/airflow/blob/c269be90c9a840d159fd38c03459bc6aeaf5708d/tests/api_fastapi/core_api/routes/public/test_event_logs.py#L163\r\nhttps://github.com/kunaljubce/airflow/blob/c269be90c9a840d159fd38c03459bc6aeaf5708d/tests/api_fastapi/core_api/routes/public/test_event_logs.py#L170', 'created_at': datetime.datetime(2024, 11, 18, 6, 33, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490035519, 'issue_id': 2665166472, 'author': 'amoghrajesh', 'body': '@iprithv I also see static checks failing. We have a pre-commit to maintain quality standards. You can install pre-commit using this: https://github.com/apache/airflow/blob/d43052e53bcf9bd8772484b8be4590f869932330/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit', 'created_at': datetime.datetime(2024, 11, 21, 4, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571807436, 'issue_id': 2665166472, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 6, 0, 16, 27, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-17 03:04:55 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

kunaljubce on (2024-11-18 06:33:15 UTC): @amoghrajesh I see this `.isoformat().replace(""+00:00"", ""Z"")` usage in a couple of other places too. Do you suggest moving to the same formatter for consistency?

https://github.com/kunaljubce/airflow/blob/c269be90c9a840d159fd38c03459bc6aeaf5708d/tests/api_fastapi/core_api/routes/public/test_import_error.py#L118
https://github.com/kunaljubce/airflow/blob/c269be90c9a840d159fd38c03459bc6aeaf5708d/tests/api_fastapi/core_api/routes/public/test_event_logs.py#L163
https://github.com/kunaljubce/airflow/blob/c269be90c9a840d159fd38c03459bc6aeaf5708d/tests/api_fastapi/core_api/routes/public/test_event_logs.py#L170

amoghrajesh on (2024-11-21 04:18:09 UTC): @iprithv I also see static checks failing. We have a pre-commit to maintain quality standards. You can install pre-commit using this: https://github.com/apache/airflow/blob/d43052e53bcf9bd8772484b8be4590f869932330/contributing-docs/03_contributors_quick_start.rst#configuring-pre-commit

github-actions[bot] on (2025-01-06 00:16:27 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2665135922,pull_request,closed,,[v2-10-test] Add usedforsecurity for sha1 algorithm ,"SHA1 is cryptographically weak and some restricted environments
(FIPS compliant) are blocking weak algorithms. You can use them
(as of Python 3.9) in those environments by specifically stating
that the algorithm is not used for security.
(cherry picked from commit https://github.com/apache/airflow/commit/a85d94e6cdcd09efe93c3acee0b4ce5c9508bc23)

Co-authored-by: Jarek Potiuk <jarek@potiuk.com>


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-17 01:14:13+00:00,[],2024-11-17 01:31:30+00:00,2024-11-17 01:31:30+00:00,https://github.com/apache/airflow/pull/44106,"[('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]","[{'comment_id': 2480880948, 'issue_id': 2665135922, 'author': 'gopidesupavan', 'body': 'Hope CLI tool is very useful 😃', 'created_at': datetime.datetime(2024, 11, 17, 1, 25, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480882377, 'issue_id': 2665135922, 'author': 'potiuk', 'body': ""Ah ... we can't. Python 3.8"", 'created_at': datetime.datetime(2024, 11, 17, 1, 31, 27, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-17 01:25:28 UTC): Hope CLI tool is very useful 😃

potiuk (Issue Creator) on (2024-11-17 01:31:27 UTC): Ah ... we can't. Python 3.8

"
2665132957,pull_request,closed,,[v2-9-stable] Add .dockerignore to target workflow override (#43885),"There is an extra layer of protection that code provided by PR should not be executed in the context of pull_request_target by running the code only inside docker container. However the container is build from local sources, so it could contain other code. We do not allow that by .dockerignore, but the .dockerignore should not be overrideable from the incoming PR.
(cherry picked from commit 5d6b836c61235765bfdf7ce65f58231e948b0881)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-17 01:03:24+00:00,[],2024-11-17 01:16:50+00:00,2024-11-17 01:16:48+00:00,https://github.com/apache/airflow/pull/44105,"[('area:dev-tools', '')]",[],
2665132334,pull_request,closed,,[v2-9-test] Add .dockerignore to target workflow override (#43885),"There is an extra layer of protection that code provided by PR should not be executed in the context of pull_request_target by running the code only inside docker container. However the container is build from local sources, so it could contain other code. We do not allow that by .dockerignore, but the .dockerignore should not be overrideable from the incoming PR.
(cherry picked from commit 5d6b836c61235765bfdf7ce65f58231e948b0881)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-17 01:01:13+00:00,[],2024-11-17 01:01:53+00:00,2024-11-17 01:01:52+00:00,https://github.com/apache/airflow/pull/44104,"[('area:dev-tools', '')]",[],
2665128693,pull_request,closed,,[v2-10-test] Add .dockerignore to target workflow override (#43885),"There is an extra layer of protection that code provided by PR should not be executed in the context of pull_request_target by running the code only inside docker container. However the container is build from local sources, so it could contain other code. We do not allow that by .dockerignore, but the .dockerignore should not be overrideable from the incoming PR.
(cherry picked from commit 5d6b836c61235765bfdf7ce65f58231e948b0881)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-17 00:48:11+00:00,[],2024-11-17 01:25:39+00:00,2024-11-17 00:57:33+00:00,https://github.com/apache/airflow/pull/44103,"[('area:dev-tools', '')]","[{'comment_id': 2480881004, 'issue_id': 2665128693, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: da9c4017d19bf17a8f3c3015602e54c919be2e2a. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/11874802664\'> Run details </a>\n\n<table>\n            <tr>\n                <th>Status</th>\n                <th>Branch</th>\n                <th>Result</th>\n            </tr>\n            <tr>\n                <td>❌</td>\n                <td>da9c4017d19bf17a8f3c3015602e54c919be2e2a</td>\n                <td><a href=""https://github.com/apache/airflow/commit/v2-10-test""><img src=\'https://img.shields.io/badge/Commit-v2-10-t-red\' alt=\'Commit Link\'></a></td>\n            </tr>\n        </table>', 'created_at': datetime.datetime(2024, 11, 17, 1, 25, 37, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-11-17 01:25:37 UTC): ### Backport failed to create: da9c4017d19bf17a8f3c3015602e54c919be2e2a. View the failure log <a href='https://github.com/apache/airflow/actions/runs/11874802664'> Run details </a>

<table>
            <tr>
                <th>Status</th>
                <th>Branch</th>
                <th>Result</th>
            </tr>
            <tr>
                <td>❌</td>
                <td>da9c4017d19bf17a8f3c3015602e54c919be2e2a</td>
                <td><a href=""https://github.com/apache/airflow/commit/v2-10-test""><img src='https://img.shields.io/badge/Commit-v2-10-t-red' alt='Commit Link'></a></td>
            </tr>
        </table>

"
2665046664,pull_request,closed,,Add cherry picker,"Integrating the Cherry Picker tool for backporting commits.

The Cherry Picker tool simplifies backporting by allowing you to apply a squashed commit to any specified branch via CLI arguments.

cherry_picker {commit_sha} v2-1-test

https://pypi.org/project/cherry-picker/

Here are some tests from my repository:
1. All backports succeeded: https://github.com/gopidesupavan/backporting-test/pull/3
2. One backport failed with conflicts, while two succeeded:https://github.com/gopidesupavan/backporting-test/pull/10

Am not good at html/css 😄 so basic thing i have tried and added to backport completion message to pr comment.

The workflows operates two ways.

1. When a PR is merged, if it contains any backport-to-* labels, the commit automatically backported to all the branches specified by those labels.
2. Alternatively, the backport can be triggered manually by specifying the commit and the target branch.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-16 22:47:09+00:00,[],2024-11-17 00:38:27+00:00,2024-11-16 23:53:37+00:00,https://github.com/apache/airflow/pull/44102,"[('area:dev-tools', '')]","[{'comment_id': 2480855062, 'issue_id': 2665046664, 'author': 'potiuk', 'body': 'Let me merge and try to cherry-pick manually my .dockerignore PR', 'created_at': datetime.datetime(2024, 11, 16, 23, 53, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480859724, 'issue_id': 2665046664, 'author': 'gopidesupavan', 'body': '> Let me merge and try to cherry-pick manually my .dockerignore PR\r\n\r\nYeah which is cool :)', 'created_at': datetime.datetime(2024, 11, 17, 0, 9, 55, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-16 23:53:32 UTC): Let me merge and try to cherry-pick manually my .dockerignore PR

gopidesupavan (Issue Creator) on (2024-11-17 00:09:55 UTC): Yeah which is cool :)

"
2665000957,pull_request,closed,,"AIP-72: Add ""XCom"" POST endpoint for Execution API","closes https://github.com/apache/airflow/issues/44100

Follow-up of https://github.com/apache/airflow/pull/43894

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-16 22:27:57+00:00,[],2025-01-31 10:44:24+00:00,2024-11-18 15:32:59+00:00,https://github.com/apache/airflow/pull/44101,"[('area:task-sdk', None)]",[],
2664930201,pull_request,closed,,Fix Pydantic model in Airflow 2.10 back-compat tests for Edge,"Fixes broken canary test. See:
https://github.com/apache/airflow/actions/runs/11872681950/job/33086780319

After fixing the one problem there was also a error appearing in collection of non-db tests for this PR. Therefore needed to adjust pytests which are known not to be working in Airflow 3. DIFF looks large but it is actually just 200 lines indented. Difference is just an IF and re-formatting. Hiding white-space changes help as
![image](https://github.com/user-attachments/assets/005393b0-0726-43d8-a375-2e4052fe3783)


```
==================================== ERRORS ====================================
___ ERROR collecting providers/tests/edge/worker_api/routes/test_rpc_api.py ____
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_typing_extra.py:303: in _eval_type_backport
    return _eval_type(value, globalns, localns, type_params)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_typing_extra.py:332: in _eval_type
    return typing._eval_type(  # type: ignore
/usr/local/lib/python3.9/typing.py:292: in _eval_type
    return t._evaluate(globalns, localns, recursive_guard)
/usr/local/lib/python3.9/typing.py:554: in _evaluate
    eval(self.__forward_code__, globalns, localns),
<string>:1: in <module>
    ???
E   TypeError: unsupported operand type(s) for |: 'types.GenericAlias' and 'NoneType'

The above exception was the direct cause of the following exception:
providers/tests/edge/worker_api/routes/test_rpc_api.py:37: in <module>
    from airflow.providers.edge.worker_api.routes.rpc_api import _initialize_method_map
/usr/local/lib/python3.9/site-packages/airflow/providers/edge/worker_api/routes/rpc_api.py:40: in <module>
    from airflow.providers.edge.worker_api.datamodels import JsonRpcRequest
/usr/local/lib/python3.9/site-packages/airflow/providers/edge/worker_api/datamodels.py:24: in <module>
    class JsonRpcRequest(BaseModel):
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_model_construction.py:219: in __new__
    set_model_fields(cls, bases, config_wrapper, types_namespace)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_model_construction.py:512: in set_model_fields
    fields, class_vars = collect_model_fields(cls, bases, config_wrapper, types_namespace, typevars_map=typevars_map)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_fields.py:105: in collect_model_fields
    type_hints = get_cls_type_hints_lenient(cls, types_namespace)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_typing_extra.py:245: in get_cls_type_hints_lenient
    hints[name] = eval_type_lenient(value, globalns, localns)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_typing_extra.py:257: in eval_type_lenient
    return eval_type_backport(value, globalns, localns)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_typing_extra.py:279: in eval_type_backport
    return _eval_type_backport(value, globalns, localns, type_params)
/usr/local/lib/python3.9/site-packages/pydantic/_internal/_typing_extra.py:311: in _eval_type_backport
    raise TypeError(
E   TypeError: Unable to evaluate type annotation 'dict[str, Any] | None'. If you are making use of the new typing syntax (unions using `|` since Python 3.10 or builtins subscripting since Python 3.9), you should either replace the use of new syntax with the existing `typing` constructs or install the `eval_type_backport` package.
- generated xml file: /files/test_result-providers_-amazon_google_stand-sqlite.xml -
```",jscheffl,2024-11-16 21:05:25+00:00,[],2024-11-16 21:49:43+00:00,2024-11-16 21:49:43+00:00,https://github.com/apache/airflow/pull/44099,"[('area:providers', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2480817012, 'issue_id': 2664930201, 'author': 'potiuk', 'body': 'Good hint with whitespace', 'created_at': datetime.datetime(2024, 11, 16, 21, 37, 46, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-16 21:37:46 UTC): Good hint with whitespace

"
2664921158,pull_request,closed,,Repair internal API on main for Edge Worker / RPC API,"While I was testing the new FastAPI for EdgeWorker in #43865 I realized that the model changes on main broke the EdgeWorker for current Airflow 3.

While the internal API will never get to Airflow 3... still the ""broken window"" is something that needs repair... until AIP-72 is not available... to further test EdgeWorker on main.

This PR corrects a few glitches introduced by changes:
- Field `dag_version_id` as UUID was missed in Pydantic models
- Funcion `_update_ti_heartbeat` was missed in internal API spec
- Function `_register_asset_changes_int` was missed in internal API in general after it was added, fails remotely

P.S.: Time to have AIP-72 working to remove the internal API...",jscheffl,2024-11-16 20:48:35+00:00,[],2024-11-17 21:19:25+00:00,2024-11-17 21:19:25+00:00,https://github.com/apache/airflow/pull/44098,"[('area:serialization', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor')]","[{'comment_id': 2480817990, 'issue_id': 2664921158, 'author': 'potiuk', 'body': '> P.S.: Time to have AIP-72 working to remove the internal API...\r\n\r\nOh yes.', 'created_at': datetime.datetime(2024, 11, 16, 21, 42, 8, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-16 21:42:08 UTC): Oh yes.

"
2664917757,pull_request,closed,,Correct type hinting for RPC API endpoint in EdgeWorker for FastAPI,While testing the new FastAPI with Airflow 3 / main I saw that type hints broke RPC API for cases where Non-Dict values are returned by functions. Some functions called on internal API return scalar values or lists.,jscheffl,2024-11-16 20:43:24+00:00,[],2024-11-16 23:03:33+00:00,2024-11-16 23:03:33+00:00,https://github.com/apache/airflow/pull/44097,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2664332770,pull_request,closed,,BUG Update `initialise_virtualenv.py` to use `uv sync`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #44078

`uv` is the recommended tool for installing `airflow` and other dependecies. I updated the `./scripts/tool/initialise_virtualenv.py` file to use `uv sync` instead of `pip unstall`



<!-- Please keep an empty line above the dashes. -->",SuccessMoses,2024-11-16 13:23:18+00:00,[],2024-11-17 09:39:30+00:00,2024-11-17 09:39:30+00:00,https://github.com/apache/airflow/pull/44096,"[('area:dev-tools', '')]","[{'comment_id': 2480578046, 'issue_id': 2664332770, 'author': 'SuccessMoses', 'body': 'even with this changes there is still a bug:\r\n```\r\nairflow version\r\n```\r\nObservation:\r\n```\r\nairflow) success@success-HP-Laptop-14-cf3xxx:~/Desktop/airflow$ airflow version\r\nTraceback (most recent call last):\r\n  File ""/home/success/Desktop/airflow/.venv/bin/airflow"", line 5, in <module>\r\n    from airflow.__main__ import main\r\n  File ""/home/success/Desktop/airflow/airflow/__init__.py"", line 78, in <module>\r\n    settings.initialize()\r\n  File ""/home/success/Desktop/airflow/airflow/settings.py"", line 787, in initialize\r\n    configure_orm()\r\n  File ""/home/success/Desktop/airflow/airflow/settings.py"", line 494, in configure_orm\r\n    async_engine = create_async_engine(SQL_ALCHEMY_CONN_ASYNC, future=True)\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py"", line 43, in create_async_engine\r\n    sync_engine = _create_engine(*arg, **kw)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""<string>"", line 2, in create_engine\r\n  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/util/deprecations.py"", line 375, in warned\r\n    return fn(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/engine/create.py"", line 544, in create_engine\r\n    dbapi = dialect_cls.dbapi(**dbapi_args)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 321, in dbapi\r\n    __import__(""aiosqlite""), __import__(""sqlite3"")\r\n```', 'created_at': datetime.datetime(2024, 11, 16, 13, 53, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480662916, 'issue_id': 2664332770, 'author': 'potiuk', 'body': ""If we use `uv` to create venv. You should either activate it with sourcing `. ./.venv/bin/activate`first  or using `uv run` to run the command in the venv you just created (the venv is created in projects's root `.venv` sub-folder.\r\n\r\nMight be worth to describe this behaviour and where the venv is created in the docs which refer to this script."", 'created_at': datetime.datetime(2024, 11, 16, 16, 51, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480968142, 'issue_id': 2664332770, 'author': 'SuccessMoses', 'body': 'Should I add `aiosqlite` to dependencies in `./pyproject.toml`', 'created_at': datetime.datetime(2024, 11, 17, 7, 1, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2481062074, 'issue_id': 2664332770, 'author': 'potiuk', 'body': 'No - it\'s already added by ""hatch_build.py""  via sqlite dependency. What you needed to do (see the fixup I added) - is to run the airflow commands via ""uv run"" command.', 'created_at': datetime.datetime(2024, 11, 17, 9, 10, 11, tzinfo=datetime.timezone.utc)}]","SuccessMoses (Issue Creator) on (2024-11-16 13:53:28 UTC): even with this changes there is still a bug:
```
airflow version
```
Observation:
```
airflow) success@success-HP-Laptop-14-cf3xxx:~/Desktop/airflow$ airflow version
Traceback (most recent call last):
  File ""/home/success/Desktop/airflow/.venv/bin/airflow"", line 5, in <module>
    from airflow.__main__ import main
  File ""/home/success/Desktop/airflow/airflow/__init__.py"", line 78, in <module>
    settings.initialize()
  File ""/home/success/Desktop/airflow/airflow/settings.py"", line 787, in initialize
    configure_orm()
  File ""/home/success/Desktop/airflow/airflow/settings.py"", line 494, in configure_orm
    async_engine = create_async_engine(SQL_ALCHEMY_CONN_ASYNC, future=True)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py"", line 43, in create_async_engine
    sync_engine = _create_engine(*arg, **kw)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""<string>"", line 2, in create_engine
  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/util/deprecations.py"", line 375, in warned
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/engine/create.py"", line 544, in create_engine
    dbapi = dialect_cls.dbapi(**dbapi_args)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/success/Desktop/airflow/.venv/lib/python3.12/site-packages/sqlalchemy/dialects/sqlite/aiosqlite.py"", line 321, in dbapi
    __import__(""aiosqlite""), __import__(""sqlite3"")
```

potiuk on (2024-11-16 16:51:45 UTC): If we use `uv` to create venv. You should either activate it with sourcing `. ./.venv/bin/activate`first  or using `uv run` to run the command in the venv you just created (the venv is created in projects's root `.venv` sub-folder.

Might be worth to describe this behaviour and where the venv is created in the docs which refer to this script.

SuccessMoses (Issue Creator) on (2024-11-17 07:01:24 UTC): Should I add `aiosqlite` to dependencies in `./pyproject.toml`

potiuk on (2024-11-17 09:10:11 UTC): No - it's already added by ""hatch_build.py""  via sqlite dependency. What you needed to do (see the fixup I added) - is to run the airflow commands via ""uv run"" command.

"
2664106397,pull_request,closed,,Ignore requests RetryError in k8s tests,"We have max_attempts to loop until the DAG successfully parses. Additionally, there is a retry configuration in place, so it might fail before reaching the max_attempts. RetryError exceptions can be safely ignored in this case.


https://github.com/apache/airflow/actions/runs/11868315063/job/33077761184#step:10:1494
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-16 09:35:17+00:00,[],2024-11-16 10:37:29+00:00,2024-11-16 10:13:36+00:00,https://github.com/apache/airflow/pull/44094,"[('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2480518026, 'issue_id': 2664106397, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 16, 10, 37, 28, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-16 10:37:28 UTC): Nice!

"
2664058390,pull_request,closed,,Fix test_handle_stuck_queued_tasks_multiple_attempts,"Tests are failing due to side effects.
https://github.com/apache/airflow/actions/runs/11868349296/job/33077514082?pr=44087#step:7:2550

The query is pulling all the log events, Log table might have previous test results stored. so updated now to pull with runid

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-16 09:01:01+00:00,[],2024-11-19 16:57:48+00:00,2024-11-16 09:36:06+00:00,https://github.com/apache/airflow/pull/44093,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2483516152, 'issue_id': 2664058390, 'author': 'dstandish', 'body': 'ah, oops, thanks', 'created_at': datetime.datetime(2024, 11, 18, 16, 21, 50, tzinfo=datetime.timezone.utc)}]","dstandish on (2024-11-18 16:21:50 UTC): ah, oops, thanks

"
2663984551,pull_request,closed,,Add newsfragment PR 43393,"## Why
https://github.com/apache/airflow/pull/44009#issuecomment-2480453454

## What

add newsfragment for https://github.com/apache/airflow/pull/43393

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-16 07:44:29+00:00,[],2024-11-18 07:06:15+00:00,2024-11-16 16:25:01+00:00,https://github.com/apache/airflow/pull/44091,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2663936843,pull_request,closed,,Fix command quoting in breeze README,"Before:
![Screenshot 2024-11-16 at 12 19 19 AM](https://github.com/user-attachments/assets/8d3762b2-5adc-4c88-8f22-9af1cfb8390e)


After:

![Screenshot 2024-11-16 at 12 18 56 AM](https://github.com/user-attachments/assets/d0007e52-3363-4543-b776-c311184121a3)
",jedcunningham,2024-11-16 07:19:35+00:00,[],2024-11-16 18:01:34+00:00,2024-11-16 16:33:15+00:00,https://github.com/apache/airflow/pull/44090,"[('area:dev-tools', '')]",[],
2663877889,pull_request,closed,,Optimize test execution time after refactors,"After refactor of running providers tests and after some recent changes we need to re-sort the order of test type execution and separate out standards provider.

Ths ""standard"" provider has slow Venv tests and it is now the slowest provider when it comes to test suite. Similarly API test type has many more tests now and it is pretty slow. Both should be started earlier in order to make use of the parallelism we have (long running tests should go first to avoid them to stay as last ones and utilise only one processor while doing so.

This PR separates standard provider and moves both standard provider and API to the top of the list used for sorting, similarly google and amazon are put higher on the list

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-16 06:31:32+00:00,[],2024-11-16 06:59:23+00:00,2024-11-16 06:59:22+00:00,https://github.com/apache/airflow/pull/44089,"[('area:dev-tools', '')]",[],
2663868846,pull_request,closed,,"Revert ""AIP-84: Migrating GET queued asset events for DAG to fastAPI …","…(#43934)""

This reverts commit 391773018747b37cfa5dab0dcfc8b22d763e38e6.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-16 06:09:30+00:00,[],2024-11-16 07:30:50+00:00,2024-11-16 07:30:50+00:00,https://github.com/apache/airflow/pull/44088,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2480432866, 'issue_id': 2663868846, 'author': 'potiuk', 'body': 'We need to revert that one - because bug of no error fixed in #44087  did not catch the API errors introduced in #43934 . @amoghrajesh  - you will have to recreate the PR unfortunately.', 'created_at': datetime.datetime(2024, 11, 16, 6, 12, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480462234, 'issue_id': 2663868846, 'author': 'Lee-W', 'body': 'now we have Copilot as reviewer 🤔', 'created_at': datetime.datetime(2024, 11, 16, 7, 23, 51, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-16 06:12:58 UTC): We need to revert that one - because bug of no error fixed in #44087  did not catch the API errors introduced in #43934 . @amoghrajesh  - you will have to recreate the PR unfortunately.

Lee-W on (2024-11-16 07:23:51 UTC): now we have Copilot as reviewer 🤔

"
2663861822,pull_request,closed,,Fix error propagation in new tests,"The #43979 introduced unit_tests.sh script that did not properly propagate error codes (no -e/+e setting).

This PR fixes it - also fixes an edge case where the -e setting is not restored in run breeze commmand script.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-16 05:55:20+00:00,[],2024-11-16 10:17:46+00:00,2024-11-16 10:17:43+00:00,https://github.com/apache/airflow/pull/44087,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2480441548, 'issue_id': 2663861822, 'author': 'potiuk', 'body': 'We will also have to merge #44088 to revert the failing API tests.', 'created_at': datetime.datetime(2024, 11, 16, 6, 16, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480454591, 'issue_id': 2663861822, 'author': 'potiuk', 'body': 'Now - we detect those errors properlu.', 'created_at': datetime.datetime(2024, 11, 16, 6, 52, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480487742, 'issue_id': 2663861822, 'author': 'gopidesupavan', 'body': 'added fix here for the failed tests: https://github.com/apache/airflow/pull/44093', 'created_at': datetime.datetime(2024, 11, 16, 9, 8, 24, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-16 06:16:28 UTC): We will also have to merge #44088 to revert the failing API tests.

potiuk (Issue Creator) on (2024-11-16 06:52:32 UTC): Now - we detect those errors properlu.

gopidesupavan on (2024-11-16 09:08:24 UTC): added fix here for the failed tests: https://github.com/apache/airflow/pull/44093

"
2663744376,pull_request,closed,,Resolve circular import issue related to task sdk,"When building official prod image locally and trying to run a task with it, I got circular import error.

This PR shows how to resolve it.  But it may not be ""the right way"".  For that I defer to @ashb and @kaxil.

Please don't merge this unless they approve.

Note that, with these changes, you can still import the ""normal"" way from dag files.  E.g. the below now works fine.  Just the internal code had to import from the actual full paths.

<img width=""802"" alt=""image"" src=""https://github.com/user-attachments/assets/a7abb906-1e2a-41ac-96d2-a19953148d42"">


",dstandish,2024-11-16 04:25:22+00:00,[],2024-11-19 19:25:53+00:00,2024-11-18 16:15:01+00:00,https://github.com/apache/airflow/pull/44086,"[('area:serialization', ''), ('area:task-sdk', None)]","[{'comment_id': 2480398502, 'issue_id': 2663744376, 'author': 'potiuk', 'body': 'IMHO I think those lazy imports (below) are evil.\r\n\r\nI think we should not try to repeat the same mistake we did with ""airflow."". In theory it\'s **nice** to have objects like that at the top package, but it only creates confusion to have the same classes importable from multiple places and it precisely causes circular imports, because instead of distributing imports and only importing what\'s needed, we are effectively importing the whole sub-tree - even if those imports are ""lazified"".\r\n\r\nIn Airflow 2 it caused us to have a special pre-commit that forbid to import from top-level when we used it in ""core"" airflow codebase because it caused exactly the same circular imports problem.\r\n\r\nI would very much prefer if we ALWAYS explicitly import from `definitions`. Other than being a little longer, it does not have any other bad effects, and it\'s actually even better for IDEs because it will automatically import it from the right place. And it\'s more explicit (i.e. follows Python Zen).\r\n\r\nI think we are trying to be too smart with those lazy imports - for no good reason. IMHO in most cases __init__ should contain absolutely nothing, unless it\'s really necessary, that improves startup time - and avoids the circular imports problems like that.\r\n\r\n```\r\n__all__ = [\r\n    ""BaseOperator"",\r\n    ""DAG"",\r\n    ""EdgeModifier"",\r\n    ""Label"",\r\n    ""TaskGroup"",\r\n    ""dag"",\r\n    ""__version__"",\r\n]\r\n\r\n__version__ = ""1.0.0.dev1""\r\n\r\nif TYPE_CHECKING:\r\n    from airflow.sdk.definitions.baseoperator import BaseOperator\r\n    from airflow.sdk.definitions.dag import DAG, dag\r\n    from airflow.sdk.definitions.edges import EdgeModifier, Label\r\n    from airflow.sdk.definitions.taskgroup import TaskGroup\r\n\r\n__lazy_imports: dict[str, str] = {\r\n    ""DAG"": "".definitions.dag"",\r\n    ""dag"": "".definitions.dag"",\r\n    ""BaseOperator"": "".definitions.baseoperator"",\r\n    ""TaskGroup"": "".definitions.taskgroup"",\r\n    ""EdgeModifier"": "".definitions.edges"",\r\n    ""Label"": "".definitions.edges"",\r\n}\r\n\r\n\r\ndef __getattr__(name: str):\r\n    if module_path := __lazy_imports.get(name):\r\n        import importlib\r\n\r\n        mod = importlib.import_module(module_path, __name__)\r\n        val = getattr(mod, name)\r\n\r\n        # Store for next time\r\n        globals()[name] = val\r\n        return val\r\n    raise AttributeError(f""module {__name__!r} has no attribute {name!r}"")\r\n```', 'created_at': datetime.datetime(2024, 11, 16, 4, 46, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480403120, 'issue_id': 2663744376, 'author': 'potiuk', 'body': 'This is what we have in Airflow pre-commit now because of that. I would not want to maintain another pre-commit like that.\r\n\r\n```\r\n      - id: check-base-operator-usage\r\n        language: pygrep\r\n        name: Check BaseOperator core imports\r\n        description: Make sure BaseOperator is imported from airflow.models.baseoperator in core\r\n        entry: ""from airflow\\\\.models import.* BaseOperator\\\\b""\r\n        files: \\.py$\r\n        pass_filenames: true\r\n        exclude: >\r\n          (?x)\r\n          ^airflow/decorators/.*$|\r\n          ^airflow/hooks/.*$|\r\n          ^airflow/operators/.*$|\r\n          ^providers/src/airflow/providers/.*$|\r\n          ^airflow/sensors/.*$|\r\n          ^dev/provider_packages/.*$\r\n      - id: check-base-operator-usage\r\n        language: pygrep\r\n        name: Check BaseOperatorLink core imports\r\n        description: Make sure BaseOperatorLink is imported from airflow.models.baseoperatorlink in core\r\n        entry: ""from airflow\\\\.models import.* BaseOperatorLink""\r\n        files: \\.py$\r\n        pass_filenames: true\r\n        exclude: >\r\n          (?x)\r\n          ^airflow/decorators/.*$|\r\n          ^airflow/hooks/.*$|\r\n          ^airflow/operators/.*$|\r\n          ^providers/src/airflow/providers/.*$|\r\n          ^airflow/sensors/.*$|\r\n          ^dev/provider_packages/.*$\r\n      - id: check-base-operator-usage\r\n        language: pygrep\r\n        name: Check BaseOperator[Link] other imports\r\n        description: Make sure BaseOperator[Link] is imported from airflow.models outside of core\r\n        entry: ""from airflow\\\\.models\\\\.baseoperator(link)? import.* BaseOperator""\r\n        pass_filenames: true\r\n        files: >\r\n          (?x)\r\n          ^providers/src/airflow/providers/.*\\.py$\r\n        exclude: ^.*/.*_vendor/|providers/src/airflow/providers/standard/operators/bash.py|providers/src/airflow/providers/standard/operators/python.py\r\n```', 'created_at': datetime.datetime(2024, 11, 16, 4, 56, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483463731, 'issue_id': 2663744376, 'author': 'dstandish', 'body': ""To be clear, this PR doesn't change anything re lazy  imports, or imports from root.  This is just using the FQN for internal code."", 'created_at': datetime.datetime(2024, 11, 18, 16, 0, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483485678, 'issue_id': 2663744376, 'author': 'ashb', 'body': 'What was the error?', 'created_at': datetime.datetime(2024, 11, 18, 16, 9, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483494507, 'issue_id': 2663744376, 'author': 'dstandish', 'body': '> What was the error?\r\n\r\n```log\r\nTraceback (most recent call last):\r\n  File ""/home/airflow/.local/bin/airflow"", line 8, in <module>\r\n    sys.exit(main())\r\n  File ""/opt/airflow/airflow/__main__.py"", line 62, in main\r\n    args.func(args)\r\n  File ""/opt/airflow/airflow/cli/cli_config.py"", line 48, in command\r\n    func = import_string(import_path)\r\n  File ""/opt/airflow/airflow/utils/module_loading.py"", line 39, in import_string\r\n    module = import_module(module_path)\r\n  File ""/usr/local/lib/python3.9/importlib/__init__.py"", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import\r\n  File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load\r\n  File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked\r\n  File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked\r\n  File ""<frozen importlib._bootstrap_external>"", line 850, in exec_module\r\n  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed\r\n  File ""/opt/airflow/airflow/cli/commands/task_command.py"", line 46, in <module>\r\n    from airflow.models.dag import DAG, _run_inline_trigger\r\n  File ""/opt/airflow/airflow/models/dag.py"", line 87, in <module>\r\n    from airflow.models.baseoperator import BaseOperator\r\n  File ""/opt/airflow/airflow/models/baseoperator.py"", line 80, in <module>\r\n    from airflow.sdk import DAG, BaseOperator as TaskSDKBaseOperator, EdgeModifier as TaskSDKEdgeModifier\r\nImportError: cannot import name \'DAG\' from \'airflow.sdk\' (/opt/airflow/task_sdk/src/airflow/sdk/__init__.py)\r\n```', 'created_at': datetime.datetime(2024, 11, 18, 16, 12, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483507217, 'issue_id': 2663744376, 'author': 'ashb', 'body': 'Yes, we need to sort out our init files ""long"" term before we cut Airflow 3 release.', 'created_at': datetime.datetime(2024, 11, 18, 16, 18, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483898367, 'issue_id': 2663744376, 'author': 'potiuk', 'body': '> To be clear, this PR doesn\'t change anything re lazy imports, or imports from root. This is just using the FQN for internal code.\r\n\r\nOf course it does not change it - but it **avoids** the problem by switching to FQN imports from ""from airflow.sdk import"" ones (this is exactly we implemented pre-commits  - to  forbid  the internal code to use the ""from airflow import"" to avoid circular dependencies. History repeats itself.\r\n\r\nThe true problem is that `airflow.sdk` has the same pattern - when we attempt to import some of the sub-packages at top level lazily and because our sub-packages refer to each other, this will only work if the original import is importing the sub-packages in the correct sequence, because it in some cases it will attempt to re-import the `__init__.py` that is still being imported.\r\n\r\nThis will happen always when:  you are importing an internal moduke of airflow (in your case `airflow.cli.cli_config`), that then imports any common object (ALIAS) from ""airflow.sdk"" by some sequence of imports it does (say in your case by a sequence of imports  `from airflow.sdk imports DAG` gets imported - which in turn imports `airflow.sdk.definitions.dag`), and then that `airflow.sdk.definitions.dag` - again might not be directly but by a sequence of imports, imports another common object (ALIAS) from `airflow.sdk` - say `from airflow.sdk import BaseOperator`.\r\n\r\nIn this case what happens:\r\n\r\n1) ""airflow.cli_config` is ""being imported""\r\n\r\n2) it imports from `airflow.sdk import DAG`. At this moment the ""airflow.sdk"" module is not fully imported yet, because the whole ""from airlfow.sdk import DAG"" will only mark the ""airflow.sdk"" as imported AFTER that line is fully completed by Python parser - only then it will be added as `airflow.sdk` to `modules`.\r\n\r\n3) so - while ""airflow.sdk"" is being imported, the `airflow.sdk.definitions.dag` is imported (via `__getattr__` - because DAG is in the process of being imported) \r\n\r\n4) that - in turn - make ""dag"" module import (directly or indirectly through other imports)  `from airflow.sdk import BaseOperator`\r\n\r\n5) and this fails with circular import because `airflow.sdk` module is not yet fully imported and we are trying to effectively import it second time before the ""on-going"" import is completed and `airflow.sdk` is added to `modules` dictionary..\r\n\r\nSo yes - you are not changing aliases here, you are avoiding the problem, really. And the lazy imports are not really the root-cause of the problem, they are merely half-working workaround to actual issue we have here.\r\n\r\nIn this case the root cause is not the ""lazy import"" itself. But the fact that we are ""aliasing"" multiple packages and modules in the same ""airflow.sdk"" package (and those classes have cross-imports).  \r\n\r\nIn this case we alias both ""airlfow.definitions.sdk.dag.DAG"", and ""airflow.definitions.sdk.baseoperator.BaseOperator"" to be ""airflow.sdk.DAG"" and ""airflow.sdk.BaseOperator"" respectively. This aliasing and the fact that those aliased operators are using other ""aliases"" in the ""airflow.sdk"" is the root of the problem. \r\n\r\nIf we did not have those lazy imports, the whole aliasing thing would simply not work at all - you wil always get circular imports if you try to do normal ""non-lazy"" imports. So ""lazy imports"" is an attempt to workaround that circular references we have.\r\n\r\nBut the lazy imports  are only masking the problem and solving only one variant of it - where  imports of aliased classes only happens ONCE in the whole import sequence when running the first import. But if the nested import attempts to import aliases twice in the same `import` instructions - even with lazy imports you get ""circular reference"".\r\n\r\nI am not sure if there is any other solution than **not** having aliases at all. Maiin reason is that `from airflow.sdk import ALIAS` will not make ""airflow.sdk"" fully imported until DAG is fully imported. And it\'s just consequence of how Python imports work.\r\n\r\nThe solution of ours where we never use ""aliases"" in the internal code only works because it effectively avoids having two aliases imported in the ""first time import sequence"". If none of our internal code is using ""from airlfow.sdk import"", then it means that we will never attempt to load an alias from an aliased operator. That can be (similarly as in case of Airlfow) prevented and enforced by `pre-commit`. \r\n\r\nBut the problem is when one of our users uses a custom code that uses ""aliases"" in their custom code that is imported by ""airflow internal"" code.\r\n\r\nFor example when someone uses custom `SecretsManager` that is loaded by our config and that ""SecretsManager"" uses ""from airlfow.sdk import ALIAS"". In this case - depending which class is imported first, we might have another alias being imported first, then custom SecretsManager, and then again another alias from ""airlfow.sdk"" - which would trigger the circular import. And we cannot prevent or enforce custom code to **NOT** use those aliases. There are plenty of similar issues with custom code of our users causing circular reference because of that very issue.\r\n\r\nAnd i am not sure if that can be solved in other way than not having the aliases at all.\r\n\r\nUnless somoene has a better idea.', 'created_at': datetime.datetime(2024, 11, 18, 19, 14, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484197265, 'issue_id': 2663744376, 'author': 'dstandish', 'body': ""i don't dispute anything related to the import design discussion.  i was just trying to make the point that, all i am doing in this pr, is fixing broken main, essentially.  i think the import design issues is really a separate discussion and you might want to transfer the discussion to a discussion, or an issue, or dev list.  i'm not involved with AIP-72 at this time -- but i am trying to use breeze for other reasons, and this issue was standing in my way."", 'created_at': datetime.datetime(2024, 11, 18, 21, 46, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484212265, 'issue_id': 2663744376, 'author': 'kaxil', 'body': 'Once we change the core to airflow-core and have task sdk / core completely isolated (from import POV) — things should be better.\r\n\r\nIn the coming weeks, Ash & I are also planning to take de-couple Core & SDK completely', 'created_at': datetime.datetime(2024, 11, 18, 21, 55, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484658641, 'issue_id': 2663744376, 'author': 'potiuk', 'body': '> i don\'t dispute anything related to the import design discussion. i was just trying to make the point that, all i am doing in this pr, is fixing broken main, essentially. i think the import design issues is really a separate discussion and you might want to transfer the discussion to a discussion, or an issue, or dev list. i\'m not involved with AIP-72 at this time -- but i am trying to use breeze for other reasons, and this issue was standing in my way.\r\n\r\nYes, but this oss is extra explanation - I am not disputing the PR - just explaining in detail what was the root cause of it and why this PR was needed so that it is captured somewhere. I am not sure why I would multiply number of issues or discussions here. I could do that as well, but It\'s very relevant - to understand what happened here (as it is not at all obvious).\r\n\r\n> Once we change the core to airflow-core and have task sdk / core completely isolated (from import POV) — things should be better.\r\n\r\nFYI @kaxil . Actually just separating airflow core and sdk is not going to help if we keep aliases in `sdk` I am afraid. This is not because we mix ""airlfow"" and ""sdk"" - this is because we are lazy importing modules nested below sdk as part of `sdk.__init__.py`.', 'created_at': datetime.datetime(2024, 11, 19, 3, 59, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485681043, 'issue_id': 2663744376, 'author': 'kaxil', 'body': '>FYI @kaxil . Actually just separating airflow core and sdk is not going to help if we keep aliases in sdk I am afraid. This is not because we mix ""airlfow"" and ""sdk"" - this is because we are lazy importing modules nested below sdk as part of sdk.__init__.py.\r\n\r\nYeah but there are actual cross deps too right now with SDK relying on Core and Core relying on SDK -- that is what I am referring to', 'created_at': datetime.datetime(2024, 11, 19, 13, 13, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486570317, 'issue_id': 2663744376, 'author': 'potiuk', 'body': ""> Yeah but there are actual cross deps too right now with SDK relying on Core and Core relying on SDK -- that is what I am referring to\r\n\r\nYep. Let's just fix it :)"", 'created_at': datetime.datetime(2024, 11, 19, 19, 25, 52, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-16 04:46:23 UTC): IMHO I think those lazy imports (below) are evil.

I think we should not try to repeat the same mistake we did with ""airflow."". In theory it's **nice** to have objects like that at the top package, but it only creates confusion to have the same classes importable from multiple places and it precisely causes circular imports, because instead of distributing imports and only importing what's needed, we are effectively importing the whole sub-tree - even if those imports are ""lazified"".

In Airflow 2 it caused us to have a special pre-commit that forbid to import from top-level when we used it in ""core"" airflow codebase because it caused exactly the same circular imports problem.

I would very much prefer if we ALWAYS explicitly import from `definitions`. Other than being a little longer, it does not have any other bad effects, and it's actually even better for IDEs because it will automatically import it from the right place. And it's more explicit (i.e. follows Python Zen).

I think we are trying to be too smart with those lazy imports - for no good reason. IMHO in most cases __init__ should contain absolutely nothing, unless it's really necessary, that improves startup time - and avoids the circular imports problems like that.

```
__all__ = [
    ""BaseOperator"",
    ""DAG"",
    ""EdgeModifier"",
    ""Label"",
    ""TaskGroup"",
    ""dag"",
    ""__version__"",
]

__version__ = ""1.0.0.dev1""

if TYPE_CHECKING:
    from airflow.sdk.definitions.baseoperator import BaseOperator
    from airflow.sdk.definitions.dag import DAG, dag
    from airflow.sdk.definitions.edges import EdgeModifier, Label
    from airflow.sdk.definitions.taskgroup import TaskGroup

__lazy_imports: dict[str, str] = {
    ""DAG"": "".definitions.dag"",
    ""dag"": "".definitions.dag"",
    ""BaseOperator"": "".definitions.baseoperator"",
    ""TaskGroup"": "".definitions.taskgroup"",
    ""EdgeModifier"": "".definitions.edges"",
    ""Label"": "".definitions.edges"",
}


def __getattr__(name: str):
    if module_path := __lazy_imports.get(name):
        import importlib

        mod = importlib.import_module(module_path, __name__)
        val = getattr(mod, name)

        # Store for next time
        globals()[name] = val
        return val
    raise AttributeError(f""module {__name__!r} has no attribute {name!r}"")
```

potiuk on (2024-11-16 04:56:35 UTC): This is what we have in Airflow pre-commit now because of that. I would not want to maintain another pre-commit like that.

```
      - id: check-base-operator-usage
        language: pygrep
        name: Check BaseOperator core imports
        description: Make sure BaseOperator is imported from airflow.models.baseoperator in core
        entry: ""from airflow\\.models import.* BaseOperator\\b""
        files: \.py$
        pass_filenames: true
        exclude: >
          (?x)
          ^airflow/decorators/.*$|
          ^airflow/hooks/.*$|
          ^airflow/operators/.*$|
          ^providers/src/airflow/providers/.*$|
          ^airflow/sensors/.*$|
          ^dev/provider_packages/.*$
      - id: check-base-operator-usage
        language: pygrep
        name: Check BaseOperatorLink core imports
        description: Make sure BaseOperatorLink is imported from airflow.models.baseoperatorlink in core
        entry: ""from airflow\\.models import.* BaseOperatorLink""
        files: \.py$
        pass_filenames: true
        exclude: >
          (?x)
          ^airflow/decorators/.*$|
          ^airflow/hooks/.*$|
          ^airflow/operators/.*$|
          ^providers/src/airflow/providers/.*$|
          ^airflow/sensors/.*$|
          ^dev/provider_packages/.*$
      - id: check-base-operator-usage
        language: pygrep
        name: Check BaseOperator[Link] other imports
        description: Make sure BaseOperator[Link] is imported from airflow.models outside of core
        entry: ""from airflow\\.models\\.baseoperator(link)? import.* BaseOperator""
        pass_filenames: true
        files: >
          (?x)
          ^providers/src/airflow/providers/.*\.py$
        exclude: ^.*/.*_vendor/|providers/src/airflow/providers/standard/operators/bash.py|providers/src/airflow/providers/standard/operators/python.py
```

dstandish (Issue Creator) on (2024-11-18 16:00:40 UTC): To be clear, this PR doesn't change anything re lazy  imports, or imports from root.  This is just using the FQN for internal code.

ashb on (2024-11-18 16:09:22 UTC): What was the error?

dstandish (Issue Creator) on (2024-11-18 16:12:57 UTC): ```log
Traceback (most recent call last):
  File ""/home/airflow/.local/bin/airflow"", line 8, in <module>
    sys.exit(main())
  File ""/opt/airflow/airflow/__main__.py"", line 62, in main
    args.func(args)
  File ""/opt/airflow/airflow/cli/cli_config.py"", line 48, in command
    func = import_string(import_path)
  File ""/opt/airflow/airflow/utils/module_loading.py"", line 39, in import_string
    module = import_module(module_path)
  File ""/usr/local/lib/python3.9/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 850, in exec_module
  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
  File ""/opt/airflow/airflow/cli/commands/task_command.py"", line 46, in <module>
    from airflow.models.dag import DAG, _run_inline_trigger
  File ""/opt/airflow/airflow/models/dag.py"", line 87, in <module>
    from airflow.models.baseoperator import BaseOperator
  File ""/opt/airflow/airflow/models/baseoperator.py"", line 80, in <module>
    from airflow.sdk import DAG, BaseOperator as TaskSDKBaseOperator, EdgeModifier as TaskSDKEdgeModifier
ImportError: cannot import name 'DAG' from 'airflow.sdk' (/opt/airflow/task_sdk/src/airflow/sdk/__init__.py)
```

ashb on (2024-11-18 16:18:11 UTC): Yes, we need to sort out our init files ""long"" term before we cut Airflow 3 release.

potiuk on (2024-11-18 19:14:21 UTC): Of course it does not change it - but it **avoids** the problem by switching to FQN imports from ""from airflow.sdk import"" ones (this is exactly we implemented pre-commits  - to  forbid  the internal code to use the ""from airflow import"" to avoid circular dependencies. History repeats itself.

The true problem is that `airflow.sdk` has the same pattern - when we attempt to import some of the sub-packages at top level lazily and because our sub-packages refer to each other, this will only work if the original import is importing the sub-packages in the correct sequence, because it in some cases it will attempt to re-import the `__init__.py` that is still being imported.

This will happen always when:  you are importing an internal moduke of airflow (in your case `airflow.cli.cli_config`), that then imports any common object (ALIAS) from ""airflow.sdk"" by some sequence of imports it does (say in your case by a sequence of imports  `from airflow.sdk imports DAG` gets imported - which in turn imports `airflow.sdk.definitions.dag`), and then that `airflow.sdk.definitions.dag` - again might not be directly but by a sequence of imports, imports another common object (ALIAS) from `airflow.sdk` - say `from airflow.sdk import BaseOperator`.

In this case what happens:

1) ""airflow.cli_config` is ""being imported""

2) it imports from `airflow.sdk import DAG`. At this moment the ""airflow.sdk"" module is not fully imported yet, because the whole ""from airlfow.sdk import DAG"" will only mark the ""airflow.sdk"" as imported AFTER that line is fully completed by Python parser - only then it will be added as `airflow.sdk` to `modules`.

3) so - while ""airflow.sdk"" is being imported, the `airflow.sdk.definitions.dag` is imported (via `__getattr__` - because DAG is in the process of being imported) 

4) that - in turn - make ""dag"" module import (directly or indirectly through other imports)  `from airflow.sdk import BaseOperator`

5) and this fails with circular import because `airflow.sdk` module is not yet fully imported and we are trying to effectively import it second time before the ""on-going"" import is completed and `airflow.sdk` is added to `modules` dictionary..

So yes - you are not changing aliases here, you are avoiding the problem, really. And the lazy imports are not really the root-cause of the problem, they are merely half-working workaround to actual issue we have here.

In this case the root cause is not the ""lazy import"" itself. But the fact that we are ""aliasing"" multiple packages and modules in the same ""airflow.sdk"" package (and those classes have cross-imports).  

In this case we alias both ""airlfow.definitions.sdk.dag.DAG"", and ""airflow.definitions.sdk.baseoperator.BaseOperator"" to be ""airflow.sdk.DAG"" and ""airflow.sdk.BaseOperator"" respectively. This aliasing and the fact that those aliased operators are using other ""aliases"" in the ""airflow.sdk"" is the root of the problem. 

If we did not have those lazy imports, the whole aliasing thing would simply not work at all - you wil always get circular imports if you try to do normal ""non-lazy"" imports. So ""lazy imports"" is an attempt to workaround that circular references we have.

But the lazy imports  are only masking the problem and solving only one variant of it - where  imports of aliased classes only happens ONCE in the whole import sequence when running the first import. But if the nested import attempts to import aliases twice in the same `import` instructions - even with lazy imports you get ""circular reference"".

I am not sure if there is any other solution than **not** having aliases at all. Maiin reason is that `from airflow.sdk import ALIAS` will not make ""airflow.sdk"" fully imported until DAG is fully imported. And it's just consequence of how Python imports work.

The solution of ours where we never use ""aliases"" in the internal code only works because it effectively avoids having two aliases imported in the ""first time import sequence"". If none of our internal code is using ""from airlfow.sdk import"", then it means that we will never attempt to load an alias from an aliased operator. That can be (similarly as in case of Airlfow) prevented and enforced by `pre-commit`. 

But the problem is when one of our users uses a custom code that uses ""aliases"" in their custom code that is imported by ""airflow internal"" code.

For example when someone uses custom `SecretsManager` that is loaded by our config and that ""SecretsManager"" uses ""from airlfow.sdk import ALIAS"". In this case - depending which class is imported first, we might have another alias being imported first, then custom SecretsManager, and then again another alias from ""airlfow.sdk"" - which would trigger the circular import. And we cannot prevent or enforce custom code to **NOT** use those aliases. There are plenty of similar issues with custom code of our users causing circular reference because of that very issue.

And i am not sure if that can be solved in other way than not having the aliases at all.

Unless somoene has a better idea.

dstandish (Issue Creator) on (2024-11-18 21:46:04 UTC): i don't dispute anything related to the import design discussion.  i was just trying to make the point that, all i am doing in this pr, is fixing broken main, essentially.  i think the import design issues is really a separate discussion and you might want to transfer the discussion to a discussion, or an issue, or dev list.  i'm not involved with AIP-72 at this time -- but i am trying to use breeze for other reasons, and this issue was standing in my way.

kaxil on (2024-11-18 21:55:16 UTC): Once we change the core to airflow-core and have task sdk / core completely isolated (from import POV) — things should be better.

In the coming weeks, Ash & I are also planning to take de-couple Core & SDK completely

potiuk on (2024-11-19 03:59:57 UTC): Yes, but this oss is extra explanation - I am not disputing the PR - just explaining in detail what was the root cause of it and why this PR was needed so that it is captured somewhere. I am not sure why I would multiply number of issues or discussions here. I could do that as well, but It's very relevant - to understand what happened here (as it is not at all obvious).


FYI @kaxil . Actually just separating airflow core and sdk is not going to help if we keep aliases in `sdk` I am afraid. This is not because we mix ""airlfow"" and ""sdk"" - this is because we are lazy importing modules nested below sdk as part of `sdk.__init__.py`.

kaxil on (2024-11-19 13:13:05 UTC): Yeah but there are actual cross deps too right now with SDK relying on Core and Core relying on SDK -- that is what I am referring to

potiuk on (2024-11-19 19:25:52 UTC): Yep. Let's just fix it :)

"
2663739037,pull_request,closed,,Bump cross-spawn from 7.0.3 to 7.0.5 in /airflow/www,"Bumps [cross-spawn](https://github.com/moxystudio/node-cross-spawn) from 7.0.3 to 7.0.5.
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/moxystudio/node-cross-spawn/blob/master/CHANGELOG.md"">cross-spawn's changelog</a>.</em></p>
<blockquote>
<h3><a href=""https://github.com/moxystudio/node-cross-spawn/compare/v7.0.4...v7.0.5"">7.0.5</a> (2024-11-07)</h3>
<h3>Bug Fixes</h3>
<ul>
<li>fix escaping bug introduced by backtracking (<a href=""https://github.com/moxystudio/node-cross-spawn/commit/640d391fde65388548601d95abedccc12943374f"">640d391</a>)</li>
</ul>
<h3><a href=""https://github.com/moxystudio/node-cross-spawn/compare/v7.0.3...v7.0.4"">7.0.4</a> (2024-11-07)</h3>
<h3>Bug Fixes</h3>
<ul>
<li>disable regexp backtracking (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/160"">#160</a>) (<a href=""https://github.com/moxystudio/node-cross-spawn/commit/5ff3a07d9add449021d806e45c4168203aa833ff"">5ff3a07</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/085268352dcbcad8064c64c5efb25268b4023184""><code>0852683</code></a> chore(release): 7.0.5</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/640d391fde65388548601d95abedccc12943374f""><code>640d391</code></a> fix: fix escaping bug introduced by backtracking</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/bff0c87c8b627c4e6d04ec2449e733048bebb464""><code>bff0c87</code></a> chore: remove codecov</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/a7c6abc6fee79641d45b452fe6217deaa1bd0973""><code>a7c6abc</code></a> chore: replace travis with github workflows</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/9b9246e0969e86656d7ccd527716bc3c18842a19""><code>9b9246e</code></a> chore(release): 7.0.4</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/5ff3a07d9add449021d806e45c4168203aa833ff""><code>5ff3a07</code></a> fix: disable regexp backtracking (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/160"">#160</a>)</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/9521e2da94d94998f948e0455903e62d87884600""><code>9521e2d</code></a> chore: fix tests in recent node js versions</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/97ded399e9c9ae325040fc52274c1cd4def357f8""><code>97ded39</code></a> chore: convert package lock</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/d52b6b9da499ca464e609162a6afeb326f1dbbb1""><code>d52b6b9</code></a> chore: remove unused argument (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/156"">#156</a>)</li>
<li><a href=""https://github.com/moxystudio/node-cross-spawn/commit/5d843849e1ed434b7030e0aa49281c2bf4ad2e71""><code>5d84384</code></a> chore: add travis jobs on ppc64le (<a href=""https://redirect.github.com/moxystudio/node-cross-spawn/issues/142"">#142</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/moxystudio/node-cross-spawn/compare/v7.0.3...v7.0.5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cross-spawn&package-manager=npm_and_yarn&previous-version=7.0.3&new-version=7.0.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-11-16 04:11:31+00:00,[],2024-11-16 04:55:22+00:00,2024-11-16 04:55:14+00:00,https://github.com/apache/airflow/pull/44085,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]","[{'comment_id': 2480394838, 'issue_id': 2663739037, 'author': 'dependabot[bot]', 'body': ""OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.\n\nIf you change your mind, just re-open this PR and I'll resolve any conflicts on it."", 'created_at': datetime.datetime(2024, 11, 16, 4, 33, 50, tzinfo=datetime.timezone.utc)}]","dependabot[bot] (Issue Creator) on (2024-11-16 04:33:50 UTC): OK, I won't notify you again about this release, but will get in touch when a new version is available. If you'd rather skip all updates until the next major or minor version, let me know by commenting `@dependabot ignore this major version` or `@dependabot ignore this minor version`.

If you change your mind, just re-open this PR and I'll resolve any conflicts on it.

"
2663737366,pull_request,closed,,Do not reset DB in CI tests if not needed,"The #43979 refactoring of tests caused unnecessary database reset attempts in tests that did not require it or had no database set.

This caused unnecessary `airflow db reset` in collection-only tests with removed non-ARM packages, but also it caused the error printed in non-DB tests:

```
Resetting the DB

[2024-11-16T03:50:37.812+0000] {cli_parser.py:67} ERROR - Failed to load CLI commands from executor: LocalExecutor
Traceback (most recent call last):
  File ""/opt/airflow/airflow/cli/cli_parser.py"", line 64, in <module>
    executor, _ = ExecutorLoader.import_executor_cls(executor_name)
  File ""/opt/airflow/airflow/executors/executor_loader.py"", line 285, in import_executor_cls
    return _import_and_validate(executor_name.module_path), executor_name.connector_source
  File ""/opt/airflow/airflow/executors/executor_loader.py"", line 282, in _import_and_validate
    cls.validate_database_executor_compatibility(executor)
  File ""/opt/airflow/airflow/executors/executor_loader.py"", line 327, in validate_database_executor_compatibility
    if engine.dialect.name == ""sqlite"":
AttributeError: 'NoneType' object has no attribute 'dialect'
[2024-11-16T03:50:37.813+0000] {cli_parser.py:68} ERROR - Ensure all dependencies are met and try again. If using a Celery based executor install a 3.3.0+ version of the Celery provider. If using a Kubernetes executor, install a 7.4.0+ version of the CNCF provider
Traceback (most recent call last):
  File ""/usr/local/bin/airflow"", line 8, in <module>
    sys.exit(main())
  File ""/opt/airflow/airflow/__main__.py"", line 62, in main
    args.func(args)
  File ""/opt/airflow/airflow/cli/cli_config.py"", line 49, in command
    return func(*args, **kwargs)
  File ""/opt/airflow/airflow/utils/providers_configuration_loader.py"", line 55, in wrapped_function
    return func(*args, **kwargs)
  File ""/opt/airflow/airflow/cli/commands/db_command.py"", line 63, in resetdb
    print(f""DB: {settings.engine.url!r}"")
AttributeError: 'NoneType' object has no attribute 'url'

Database has been reset
```

The fix is to add `--no-db-reset` in collection tests and force db_reset = False in case `skip_db_tests` is set to True.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-16 04:07:08+00:00,[],2024-11-16 11:24:49+00:00,2024-11-16 11:24:47+00:00,https://github.com/apache/airflow/pull/44084,"[('area:dev-tools', '')]",[],
2663717421,pull_request,closed,,Fix special tests in the new workflow structure,"When #43979 there was a typo where inputs passed as test-groups were not passed to unit tests in ""special-tests"" case - because the ""needs.build-info.outputs"" were used instead.

Unfortunately this is not caught by GitHub parsing the workflows, it will only signal it by having annotations of errors on the affected actions - missing needs.build-info entries are simply replaced by empty string.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-16 03:41:24+00:00,[],2024-11-16 04:09:14+00:00,2024-11-16 04:09:13+00:00,https://github.com/apache/airflow/pull/44083,"[('area:dev-tools', '')]",[],
2663612976,pull_request,closed,,Add usedforsecurity for sha1 algorithm,"SHA1 is cryptographically weak and some restricted environments (FIPS compliant) are blocking weak algorithms. You can use them (as of Python 3.9) in those environments by specifically stating that the algorithm is not used for security.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-16 01:55:19+00:00,[],2024-11-17 01:27:03+00:00,2024-11-16 16:37:23+00:00,https://github.com/apache/airflow/pull/44081,[],"[{'comment_id': 2480304492, 'issue_id': 2663612976, 'author': 'potiuk', 'body': 'This has been detected by CodeQL scanning (cc: @vikramkoka  -> FIPS compliance, that what we talked about on Thursday).', 'created_at': datetime.datetime(2024, 11, 16, 1, 57, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480319467, 'issue_id': 2663612976, 'author': 'rawwar', 'body': '@potiuk , I notice `hashlib.sha1` being used in two other places that can use this argument:\r\n\r\n1. https://github.com/apache/airflow/blob/19303ca655ad8f977642be49dc225433ffa3cef5/airflow/models/dagcode.py#L197\r\n2. https://github.com/apache/airflow/blob/19303ca655ad8f977642be49dc225433ffa3cef5/airflow/models/taskinstance.py#L2543', 'created_at': datetime.datetime(2024, 11, 16, 2, 9, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480336258, 'issue_id': 2663612976, 'author': 'potiuk', 'body': '> @potiuk , I notice `hashlib.sha1` being used in two other places that can use this argument: \r\n\r\nOh nice. I wonder why CodeQL has not detected those :)', 'created_at': datetime.datetime(2024, 11, 16, 2, 28, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480340778, 'issue_id': 2663612976, 'author': 'potiuk', 'body': 'Updated it/', 'created_at': datetime.datetime(2024, 11, 16, 2, 33, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480353333, 'issue_id': 2663612976, 'author': 'potiuk', 'body': ""> The usedforsecurity parameter for hashlib.sha1 is available from Python 3.9 onwards. Verify that the project does not need to support older versions of Python.\r\n\r\nThanks Copiiot. That was a useful advice and yes we use Python 3.9+ - that's why we could apply those fixes :).\r\n\r\nBTW. Today I got the Copilot Review access that I applied - I will be experimenting with it and adding it on some PRs to see how good it is."", 'created_at': datetime.datetime(2024, 11, 16, 2, 53, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480855391, 'issue_id': 2663612976, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/11874200699\'> Run details </a>\n\n<table>\n            <tr>\n                <th>Status</th>\n                <th>Branch</th>\n                <th>Result</th>\n            </tr>\n            <tr>\n                <td>❌</td>\n                <td>v2-10-test</td>\n                <td><a href=""https://github.com/apache/airflow/commit/a85d94e6cdcd09efe93c3acee0b4ce5c9508bc23""><img src=\'https://img.shields.io/badge/Commit-a85d94e-red\' alt=\'Commit Link\'></a></td>\n            </tr>\n        </table>', 'created_at': datetime.datetime(2024, 11, 16, 23, 55, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480881324, 'issue_id': 2663612976, 'author': 'gopidesupavan', 'body': '> ### Backport failed to create: v2-10-test. View the failure log [ Run details ](https://github.com/apache/airflow/actions/runs/11874200699)\r\n> Status\tBranch\tResult\r\n> ❌\tv2-10-test\t[![Commit Link](https://camo.githubusercontent.com/955fee2413ee8217f153d861d4b0e068a59a457b74923079660fab04540db8df/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f436f6d6d69742d613835643934652d726564)](https://github.com/apache/airflow/commit/a85d94e6cdcd09efe93c3acee0b4ce5c9508bc23)\r\n\r\nLooks like it failed, due to conflicts', 'created_at': datetime.datetime(2024, 11, 17, 1, 27, 2, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-16 01:57:30 UTC): This has been detected by CodeQL scanning (cc: @vikramkoka  -> FIPS compliance, that what we talked about on Thursday).

rawwar on (2024-11-16 02:09:42 UTC): @potiuk , I notice `hashlib.sha1` being used in two other places that can use this argument:

1. https://github.com/apache/airflow/blob/19303ca655ad8f977642be49dc225433ffa3cef5/airflow/models/dagcode.py#L197
2. https://github.com/apache/airflow/blob/19303ca655ad8f977642be49dc225433ffa3cef5/airflow/models/taskinstance.py#L2543

potiuk (Issue Creator) on (2024-11-16 02:28:34 UTC): Oh nice. I wonder why CodeQL has not detected those :)

potiuk (Issue Creator) on (2024-11-16 02:33:25 UTC): Updated it/

potiuk (Issue Creator) on (2024-11-16 02:53:48 UTC): Thanks Copiiot. That was a useful advice and yes we use Python 3.9+ - that's why we could apply those fixes :).

BTW. Today I got the Copilot Review access that I applied - I will be experimenting with it and adding it on some PRs to see how good it is.

github-actions[bot] on (2024-11-16 23:55:40 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/11874200699'> Run details </a>

<table>
            <tr>
                <th>Status</th>
                <th>Branch</th>
                <th>Result</th>
            </tr>
            <tr>
                <td>❌</td>
                <td>v2-10-test</td>
                <td><a href=""https://github.com/apache/airflow/commit/a85d94e6cdcd09efe93c3acee0b4ce5c9508bc23""><img src='https://img.shields.io/badge/Commit-a85d94e-red' alt='Commit Link'></a></td>
            </tr>
        </table>

gopidesupavan on (2024-11-17 01:27:02 UTC): Looks like it failed, due to conflicts

"
2663582817,pull_request,closed,,Drop support for PostgreSQL 12,It reached EOL on 2024-11-14.,jedcunningham,2024-11-16 01:27:51+00:00,[],2024-11-16 16:02:27+00:00,2024-11-16 16:02:25+00:00,https://github.com/apache/airflow/pull/44080,"[('area:dev-tools', '')]","[{'comment_id': 2480453039, 'issue_id': 2663582817, 'author': 'eladkal', 'body': 'Do we need newsfragment for this one?', 'created_at': datetime.datetime(2024, 11, 16, 6, 46, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480459839, 'issue_id': 2663582817, 'author': 'jedcunningham', 'body': ""> Do we need newsfragment for this one?\r\n\r\nGood idea. We've been pretty inconsistent about this when dropping support for versions of things that hit EOL, but I think we should call it out explicitly."", 'created_at': datetime.datetime(2024, 11, 16, 7, 14, 31, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-16 06:46:04 UTC): Do we need newsfragment for this one?

jedcunningham (Issue Creator) on (2024-11-16 07:14:31 UTC): Good idea. We've been pretty inconsistent about this when dropping support for versions of things that hit EOL, but I think we should call it out explicitly.

"
2663388733,pull_request,closed,,Make host/port configurable for Snowflake connections,"First of all - thanks so much for building Airflow, it is an absolutely awesome platform! 🙌 🚀 

This PR extends the functionality of `SnowflakeHook` to make the host/port configurable for Snowflake connections. This facilitates testing against non-standard Snowflake endpoints, for example when testing against [LocalStack](https://www.localstack.cloud/localstack-for-snowflake) (a local cloud emulator).

A similar PR has been created against the Astronomer Cosmos repo some time ago (see https://github.com/astronomer/astronomer-cosmos/pull/1063), and our users have now requested to use the standard Airflow Snowflake connector with LocalStack Snowflake as well.

The PR also updates the documentation for the Snowflake connector, but it does not contain any tests at this point. If adding a test is required, then any pointers or guidance would be appreciated. 👍 

## Testing

Tested this locally against the LocalStack Snowflake emulator - with a connection config like this:

<img width=""1009"" alt=""image"" src=""https://github.com/user-attachments/assets/0977470c-234f-4cd2-8aff-736b3fc82124"">

... and a simple DAG like this:
```
from airflow import DAG
from airflow.providers.snowflake.operators.snowflake import SnowflakeOperator

conn_id = ""snowflake_local""

dag = DAG(
    'snowflake_test',
    default_args={'snowflake_conn_id': conn_id},
    tags=['example'],
    catchup=False,
)

snowflake_op_sql_str = SnowflakeOperator(
    task_id='query1',
    dag=dag,
    sql=""SELECT CURRENT_ACCOUNT()"",
)
```

... the DAG executes successfully, and outputs:
<img width=""862"" alt=""image"" src=""https://github.com/user-attachments/assets/66ca0cf1-a1ee-45ad-affb-4bddf18e2faf"">


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",whummer,2024-11-15 22:42:54+00:00,[],2024-11-16 01:28:11+00:00,2024-11-16 01:26:53+00:00,https://github.com/apache/airflow/pull/44079,"[('area:providers', ''), ('kind:documentation', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]",[],
2663131292,pull_request,closed,,Extend OpenAPI schema with extra models for Task SDK,"- Introduced `custom_openapi` to extend OpenAPI schema with additional models.
- Added `TaskInstance` model for inclusion in OpenAPI schema, specifically for Task SDK

Reference: https://fastapi.tiangolo.com/how-to/extending-openapi/#modify-the-openapi-schema

closes https://github.com/apache/airflow/issues/44077

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-15 21:02:40+00:00,[],2024-11-15 22:06:31+00:00,2024-11-15 22:06:29+00:00,https://github.com/apache/airflow/pull/44076,"[('area:task-sdk', None)]",[],
2663095129,pull_request,closed,,Fix duration charts,"When migrating `datasets` to `assets` we broke the run and task duration charts in the legacy UI and they weren't rendering anything.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-15 20:40:48+00:00,[],2024-11-16 21:34:44+00:00,2024-11-16 21:34:43+00:00,https://github.com/apache/airflow/pull/44075,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]",[],
2663040106,pull_request,closed,,Init Dag Overview page with time range selector and failed tasks,"Initialize the Dag Overview page with a timerange selector that will search for failed task instances in that range and show it as a button with the total count and the distribution of failed tis over the time range.

In another PR: build the tasks page so clicking the button brings you somewhere useful.

<img width=""1188"" alt=""Screenshot 2024-11-15 at 3 28 51 PM"" src=""https://github.com/user-attachments/assets/2fab0ad2-dfb1-49ab-86d6-f8eb4059d627"">
<img width=""1194"" alt=""Screenshot 2024-11-15 at 3 28 58 PM"" src=""https://github.com/user-attachments/assets/fda32999-d7d3-49cd-a49e-a39bf758aa5c"">


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-15 20:31:11+00:00,[],2024-11-18 15:36:21+00:00,2024-11-18 15:36:19+00:00,https://github.com/apache/airflow/pull/44074,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2482613859, 'issue_id': 2663040106, 'author': 'pierrejeambrun', 'body': 'Also this just makes me realize that `http://localhost:29091/ui/dags/recent_dag_runs?dag_id_pattern=xxxxx` endpoint should most certainly also support a `dag_id` query params or `dag_ids`.\r\n\r\nI am affraid that using a `pattern` like this could end up matching multiple dags while we are really trying to get the dag_runs from a specific dag like here.', 'created_at': datetime.datetime(2024, 11, 18, 10, 26, 9, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-18 10:26:09 UTC): Also this just makes me realize that `http://localhost:29091/ui/dags/recent_dag_runs?dag_id_pattern=xxxxx` endpoint should most certainly also support a `dag_id` query params or `dag_ids`.

I am affraid that using a `pattern` like this could end up matching multiple dags while we are really trying to get the dag_runs from a specific dag like here.

"
2663037993,pull_request,closed,,Fix system test `test_aws_auth_manager`,"`test_aws_auth_manager` is failing because the schema from Amazon Verified Permissions has been moved when doing the refactoring of providers in Airflow codebase.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-15 20:29:26+00:00,[],2024-11-18 21:07:43+00:00,2024-11-15 21:39:36+00:00,https://github.com/apache/airflow/pull/44073,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2662976301,pull_request,closed,, Log message source details are grouped (#43681),Backport of #43681,jscheffl,2024-11-15 19:47:48+00:00,[],2024-11-17 14:00:05+00:00,2024-11-17 14:00:05+00:00,https://github.com/apache/airflow/pull/44070,"[('area:logging', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]",[],
2662866193,pull_request,closed,,Redact extra fields for Asset Endpoints in fastAPI,"This PR address the review [comment](https://github.com/apache/airflow/pull/43984#discussion_r1843856417) in Asset migration [PR](https://github.com/apache/airflow/pull/43984). We noticed `extra` are redacted in the Log table, but not in the plain response from Asset Legacy API. Querying the events shouldn't return sensitive values in plain text. This PR handles that in fastAPI.

### Testing

**Asset events reponse**
<img width=""1371"" alt=""image"" src=""https://github.com/user-attachments/assets/9c35fac5-bd40-4cfb-b724-ff7d89e31d8a"">

**Asset response**

<img width=""1084"" alt=""image"" src=""https://github.com/user-attachments/assets/2c39541d-83fa-4544-b6ab-a5978e455e50"">

**create Asset response**
<img width=""1116"" alt=""image"" src=""https://github.com/user-attachments/assets/5c7da3d4-0f95-4ef8-b64d-4ae6750036b7"">

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-15 18:58:14+00:00,[],2024-11-18 14:02:33+00:00,2024-11-18 14:02:30+00:00,https://github.com/apache/airflow/pull/44069,[],"[{'comment_id': 2479728591, 'issue_id': 2662866193, 'author': 'vatsrahul1001', 'body': '@pierrejeambrun I have `redacted` for `create Asset response` as well let me know if its not needed I can remove that', 'created_at': datetime.datetime(2024, 11, 15, 19, 0, 2, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-11-15 19:00:02 UTC): @pierrejeambrun I have `redacted` for `create Asset response` as well let me know if its not needed I can remove that

"
2662781650,pull_request,closed,,Modularize datamodels in Execution API,"Split the `datamodels` module to granular mods

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-15 18:26:17+00:00,[],2024-11-15 19:08:41+00:00,2024-11-15 19:08:39+00:00,https://github.com/apache/airflow/pull/44068,[],[],
2662772830,pull_request,closed,,Update set-up-database.rst,"Update procedure to setup PostgreSQL database

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hanifmusa96,2024-11-15 18:20:34+00:00,[],2024-11-18 15:11:14+00:00,2024-11-18 15:11:09+00:00,https://github.com/apache/airflow/pull/44067,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]","[{'comment_id': 2479664024, 'issue_id': 2662772830, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 15, 18, 20, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483330571, 'issue_id': 2662772830, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 18, 15, 11, 12, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-15 18:20:39 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-18 15:11:12 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2662646255,pull_request,closed,,Exclude `src/airflow/__init__.py` when building providers,"same as Task SDK change in https://github.com/apache/airflow/pull/43899 -- but for providers

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-15 17:30:03+00:00,[],2024-11-16 21:41:05+00:00,2024-11-15 17:52:32+00:00,https://github.com/apache/airflow/pull/44066,[],"[{'comment_id': 2479601005, 'issue_id': 2662646255, 'author': 'ashb', 'body': ""Makes sense, even though this isn't a real package it can confuse things if it's there."", 'created_at': datetime.datetime(2024, 11, 15, 17, 51, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2479908595, 'issue_id': 2662646255, 'author': 'potiuk', 'body': 'Does it mean that our packages from release are broken ? cc: @eladkal ? I guess we need to re-release them? Or do they work as usual? (I did not have time to check them)', 'created_at': datetime.datetime(2024, 11, 15, 20, 54, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480083924, 'issue_id': 2662646255, 'author': 'kaxil', 'body': '> Does it mean that our packages from release are broken ? cc: @eladkal ? I guess we need to re-release them? Or do they work as usual? (I did not have time to check them)\r\n\r\nThey are good as while preparing provider packages we copy the a specific provider directory e.g. `providers/src/airflow/providers/apache/hdfs`.\r\n\r\nhttps://github.com/apache/airflow/blob/f7270c8a2026b8da07590623560ba58e9da38d7f/dev/breeze/tests/test_packages.py#L153-L156\r\n\r\nhttps://github.com/apache/airflow/blob/f7270c8a2026b8da07590623560ba58e9da38d7f/docs/exts/provider_yaml_utils.py#L30\r\n\r\n```\r\n❯ tree apache_airflow_providers_amazon-9.1.0rc4-py3-none-any\r\napache_airflow_providers_amazon-9.1.0rc4-py3-none-any\r\n├── airflow\r\n│\xa0\xa0 └── providers\r\n│\xa0\xa0     └── amazon\r\n```', 'created_at': datetime.datetime(2024, 11, 15, 22, 53, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480391145, 'issue_id': 2662646255, 'author': 'potiuk', 'body': 'UFF 😓', 'created_at': datetime.datetime(2024, 11, 16, 4, 19, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480742369, 'issue_id': 2662646255, 'author': 'eladkal', 'body': ""I don't see any problem with current rc of providers. If you find something is wrong let me know"", 'created_at': datetime.datetime(2024, 11, 16, 19, 11, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480817725, 'issue_id': 2662646255, 'author': 'potiuk', 'body': ""> I don't see any problem with current rc of providers. If you find something is wrong let me know\r\n\r\nConfirmed - no probl;ems."", 'created_at': datetime.datetime(2024, 11, 16, 21, 41, 4, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-15 17:51:45 UTC): Makes sense, even though this isn't a real package it can confuse things if it's there.

potiuk on (2024-11-15 20:54:41 UTC): Does it mean that our packages from release are broken ? cc: @eladkal ? I guess we need to re-release them? Or do they work as usual? (I did not have time to check them)

kaxil (Issue Creator) on (2024-11-15 22:53:08 UTC): They are good as while preparing provider packages we copy the a specific provider directory e.g. `providers/src/airflow/providers/apache/hdfs`.

https://github.com/apache/airflow/blob/f7270c8a2026b8da07590623560ba58e9da38d7f/dev/breeze/tests/test_packages.py#L153-L156

https://github.com/apache/airflow/blob/f7270c8a2026b8da07590623560ba58e9da38d7f/docs/exts/provider_yaml_utils.py#L30

```
❯ tree apache_airflow_providers_amazon-9.1.0rc4-py3-none-any
apache_airflow_providers_amazon-9.1.0rc4-py3-none-any
├── airflow
│   └── providers
│       └── amazon
```

potiuk on (2024-11-16 04:19:20 UTC): UFF 😓

eladkal on (2024-11-16 19:11:52 UTC): I don't see any problem with current rc of providers. If you find something is wrong let me know

potiuk on (2024-11-16 21:41:04 UTC): Confirmed - no probl;ems.

"
2662502693,pull_request,closed,,AIP-72: Use explicit TI State enums for TI update state endpoint,"Created explicit enums so the generated client doesn't have names like `State1` and reduces duplication of states!

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-15 16:35:43+00:00,[],2024-11-15 17:41:39+00:00,2024-11-15 17:41:38+00:00,https://github.com/apache/airflow/pull/44065,"[('area:task-sdk', None)]",[],
2662337589,pull_request,closed,,Fix flakey test in TaskSDK supervisor,"Under ""normal"" operation the subprocess will not do anything (other than a few
imports) until it gets the StartupDetails message on stdin, but in our unit tests
when we replace the target function with a custom implementation it's possible
that the subprocess could exit (closing the stdin socket) before the parent
has written anything to it.

The fix is to make our test target follow the same behaviour of the real code
and read a line from stdin before doing anything else.

The error we saw in tests was this:

```
 ________________ TestWatchedSubprocess.test_reading_from_pipes _________________
[gw2] linux -- Python 3.9.20 /usr/local/bin/python
task_sdk/tests/execution_time/test_supervisor.py:72: in test_reading_from_pipes
    proc = WatchedSubprocess.start(
task_sdk/src/airflow/sdk/execution_time/supervisor.py:354: in start
    feed_stdin.write(msg.model_dump_json().encode())
/usr/local/lib/python3.9/socket.py:734: in write
    return self._sock.send(b)
E   BrokenPipeError: [Errno 32] Broken pipe
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-15 15:34:19+00:00,[],2024-11-15 16:03:20+00:00,2024-11-15 15:54:47+00:00,https://github.com/apache/airflow/pull/44064,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2662150441,pull_request,closed,,"MAINT Fix Incorrect FutureWarning in 2,10","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Fixes #43794

In airflow version 2.10, removed deprecation warning for `sql_alchemy_conn` and others in `[core]` instead of `[database]` in `airflow.cfg`
",SuccessMoses,2024-11-15 14:35:13+00:00,[],2024-11-19 03:37:15+00:00,2024-11-19 03:35:47+00:00,https://github.com/apache/airflow/pull/44061,[],"[{'comment_id': 2480320259, 'issue_id': 2662150441, 'author': 'potiuk', 'body': ""It's not the right fix. Rather than removing the old values from deprecated list, we should suppress the warnings in this particular case where we check for sensitive values."", 'created_at': datetime.datetime(2024, 11, 16, 2, 10, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480373429, 'issue_id': 2662150441, 'author': 'zachliu', 'body': ""> It's not the right fix. Rather than removing the old values from deprecated list, we should suppress the warnings in this particular case where we check for sensitive values.\r\n\r\nisn't this my bandit fix? :grin: i just added `with self.suppress_future_warnings():` before\r\n\r\nhttps://github.com/apache/airflow/blob/c99887ec11ce3e1a43f2794fcf36d27555140f00/airflow/configuration.py#L859"", 'created_at': datetime.datetime(2024, 11, 16, 3, 39, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480393886, 'issue_id': 2662150441, 'author': 'potiuk', 'body': ""> isn't this my bandit fix? 😁 i just added with self.suppress_future_warnings(): before\r\n\r\nYep. That's what it should be"", 'created_at': datetime.datetime(2024, 11, 16, 4, 30, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483352604, 'issue_id': 2662150441, 'author': 'zachliu', 'body': '> suppress the warnings in this particular case where we check for sensitive values.\r\n\r\nokie doke\r\n\r\nhttps://github.com/apache/airflow/pull/44148', 'created_at': datetime.datetime(2024, 11, 18, 15, 18, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484639224, 'issue_id': 2662150441, 'author': 'potiuk', 'body': 'Closing. Fixed by #44148', 'created_at': datetime.datetime(2024, 11, 19, 3, 37, 13, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-16 02:10:46 UTC): It's not the right fix. Rather than removing the old values from deprecated list, we should suppress the warnings in this particular case where we check for sensitive values.

zachliu on (2024-11-16 03:39:46 UTC): isn't this my bandit fix? :grin: i just added `with self.suppress_future_warnings():` before

https://github.com/apache/airflow/blob/c99887ec11ce3e1a43f2794fcf36d27555140f00/airflow/configuration.py#L859

potiuk on (2024-11-16 04:30:39 UTC): Yep. That's what it should be

zachliu on (2024-11-18 15:18:48 UTC): okie doke

https://github.com/apache/airflow/pull/44148

potiuk on (2024-11-19 03:37:13 UTC): Closing. Fixed by #44148

"
2662141885,pull_request,closed,,MAINT Fix Incorrect FutureWarning in 2.10,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Fixes #43794

In airflow version 2.10, removed deprecation warning for `sql_alchemy_conn` and others in `[core]` instead of `[database]` in `airflow.cfg`
",SuccessMoses,2024-11-15 14:30:46+00:00,[],2024-11-15 14:32:07+00:00,2024-11-15 14:31:45+00:00,https://github.com/apache/airflow/pull/44060,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2479024083, 'issue_id': 2662141885, 'author': 'SuccessMoses', 'body': 'sorry :)', 'created_at': datetime.datetime(2024, 11, 15, 14, 32, 5, tzinfo=datetime.timezone.utc)}]","SuccessMoses (Issue Creator) on (2024-11-15 14:32:05 UTC): sorry :)

"
2662140708,pull_request,closed,,Remove pre-commit from devel extra of Airflow,"Having pre-commit as devel dependency is not a good idea because it might conflict with the one installed globall when you install a local venv. Instead of installing it as a dependency, we install it separately in CI and CI image - together with UV and pre-comit-uv to make it fast and keep consistency and keep it in the same version in the development environment.

We still have TODO to keep it synchronized and updated automatically in all places and in github action - that will be done in a separate PR.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-15 14:30:06+00:00,[],2024-11-17 01:27:05+00:00,2024-11-15 17:46:58+00:00,https://github.com/apache/airflow/pull/44059,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2479120885, 'issue_id': 2662140708, 'author': 'potiuk', 'body': 'created an issue for the TODO: https://github.com/apache/airflow/issues/44062', 'created_at': datetime.datetime(2024, 11, 15, 15, 17, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2479588654, 'issue_id': 2662140708, 'author': 'potiuk', 'body': 'Merging. Those are intermittent issues only', 'created_at': datetime.datetime(2024, 11, 15, 17, 46, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480881328, 'issue_id': 2662140708, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/11874812291\'> Run details </a>\n\n<table>\n            <tr>\n                <th>Status</th>\n                <th>Branch</th>\n                <th>Result</th>\n            </tr>\n            <tr>\n                <td>❌</td>\n                <td>v2-10-test</td>\n                <td><a href=""https://github.com/apache/airflow/commit/da9c4017d19bf17a8f3c3015602e54c919be2e2a""><img src=\'https://img.shields.io/badge/Commit-da9c401-red\' alt=\'Commit Link\'></a></td>\n            </tr>\n        </table>', 'created_at': datetime.datetime(2024, 11, 17, 1, 27, 4, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-15 15:17:32 UTC): created an issue for the TODO: https://github.com/apache/airflow/issues/44062

potiuk (Issue Creator) on (2024-11-15 17:46:53 UTC): Merging. Those are intermittent issues only

github-actions[bot] on (2024-11-17 01:27:04 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/11874812291'> Run details </a>

<table>
            <tr>
                <th>Status</th>
                <th>Branch</th>
                <th>Result</th>
            </tr>
            <tr>
                <td>❌</td>
                <td>v2-10-test</td>
                <td><a href=""https://github.com/apache/airflow/commit/da9c4017d19bf17a8f3c3015602e54c919be2e2a""><img src='https://img.shields.io/badge/Commit-da9c401-red' alt='Commit Link'></a></td>
            </tr>
        </table>

"
2662120457,pull_request,closed,,Remove commented code in xcom_arg.py,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-15 14:19:14+00:00,[],2024-11-15 15:07:07+00:00,2024-11-15 15:07:07+00:00,https://github.com/apache/airflow/pull/44058,[],[],
2661849601,pull_request,closed,,Fix bug in task_sdk's `parse` function,"This function was added by not used or tested in the first PR that added the
task_runner code, and in the final throes of that PR we swapped from msgspec
to pydantic, and in doing so introduced a runtime error from Pydantic as it
tried to look at the type hints of the `task: BaseOperator` property

The fix here is to call model_construct to skip pydantic validations, which is
safe here as the TI (which RuntimeTI inherits from) was validated when the
StartupDetails object was parsed+created.

And this time add tests for the function too.

In order to test this I have created the first very simple test dag in the
SDK and configured pytest to skip that entire directory when looking for
tests.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-15 12:36:04+00:00,[],2024-11-15 13:00:20+00:00,2024-11-15 12:58:04+00:00,https://github.com/apache/airflow/pull/44056,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2661836227,pull_request,closed,,Add wait_policy option to EmrCreateJobFlowOperator.,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

Currently, when using `wait_for_complition=True` it will trigger the node to only wait until the cluster is successfully launched. 
I added the option `wait_policy` so that one can chose what waiter will be used. 

Possible values:
- `None`: No wait (default)
- `WaitPolicy.WAIT_FOR_COMPLETION`: Previous behaviour when `wait_for_completion` was `True`
- `WaitPolicy.WAIT_FOR_STEPS_COMPLETION`: New behaviour - wait for the cluster to terminate.

This is useful because it will eliminate the need to have an extra node in your DAG. 
",adrian-adikteev,2024-11-15 12:28:25+00:00,[],2024-11-25 15:56:01+00:00,2024-11-25 15:55:58+00:00,https://github.com/apache/airflow/pull/44055,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2478707940, 'issue_id': 2661836227, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 15, 12, 28, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483432280, 'issue_id': 2661836227, 'author': 'vincbeck', 'body': 'Good job! I like that version', 'created_at': datetime.datetime(2024, 11, 18, 15, 48, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490974792, 'issue_id': 2661836227, 'author': 'adrian-adikteev', 'body': ""I'm not sure what's the next step here but from my side everything is ready."", 'created_at': datetime.datetime(2024, 11, 21, 12, 13, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2497323546, 'issue_id': 2661836227, 'author': 'adrian-adikteev', 'body': 'Should be ready for merge', 'created_at': datetime.datetime(2024, 11, 25, 8, 59, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498405146, 'issue_id': 2661836227, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 25, 15, 56, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-15 12:28:29 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

vincbeck on (2024-11-18 15:48:26 UTC): Good job! I like that version

adrian-adikteev (Issue Creator) on (2024-11-21 12:13:15 UTC): I'm not sure what's the next step here but from my side everything is ready.

adrian-adikteev (Issue Creator) on (2024-11-25 08:59:54 UTC): Should be ready for merge

boring-cyborg[bot] on (2024-11-25 15:56:00 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2661752912,pull_request,closed,,AIP-84: Migrating DELETE a queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370
Migrating delete a queued asset events for DAG to fastAPI

Dependent on https://github.com/apache/airflow/pull/43934

Same setup as https://github.com/apache/airflow/pull/43934

Responses:
1. Legacy
![image](https://github.com/user-attachments/assets/68af6869-4ba4-4343-a9c3-cf7ac98bc17e)

2. FastAPI
![image](https://github.com/user-attachments/assets/4d4df85a-d21d-46f3-8d57-d6c8e495d886)


With time filtering:
1. Legacy
![image](https://github.com/user-attachments/assets/b58aec22-0245-43f9-97bd-44c8c70efe9a)

2. FastAPI
![image](https://github.com/user-attachments/assets/386de798-88ab-4798-adf4-22c8440618e2)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-15 11:42:04+00:00,[],2024-11-18 08:51:30+00:00,2024-11-18 08:51:29+00:00,https://github.com/apache/airflow/pull/44054,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2478633994, 'issue_id': 2661752912, 'author': 'amoghrajesh', 'body': 'Only last 2 commits are relevant', 'created_at': datetime.datetime(2024, 11, 15, 11, 42, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482310181, 'issue_id': 2661752912, 'author': 'amoghrajesh', 'body': 'Closing in favour of https://github.com/apache/airflow/pull/44130', 'created_at': datetime.datetime(2024, 11, 18, 8, 51, 30, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-15 11:42:18 UTC): Only last 2 commits are relevant

amoghrajesh (Issue Creator) on (2024-11-18 08:51:30 UTC): Closing in favour of https://github.com/apache/airflow/pull/44130

"
2661672808,pull_request,closed,,Move `TriggerDagRunOperator` to standard provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE


How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Moving trigger_dagrun operator to standard provider.

`airflow/operators/trigger_dagrun.py  >> providers/src/airflow/providers/standard/operators/trigger_dagrun.py`

related: #43641 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).",hardeybisey,2024-11-15 11:19:05+00:00,[],2025-01-17 09:59:57+00:00,2024-11-20 09:01:32+00:00,https://github.com/apache/airflow/pull/44053,"[('area:providers', ''), ('area:serialization', ''), ('area:system-tests', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('provider:standard', '')]","[{'comment_id': 2487949234, 'issue_id': 2661672808, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 20, 9, 1, 36, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-20 09:01:36 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2661622739,pull_request,closed,,AIP-84: Migrating DELETE queued asset events for assets to fastAPI,"Related: https://github.com/apache/airflow/issues/42370
Dependent: https://github.com/apache/airflow/pull/43934

Swagger Specs
<img width=""1542"" alt=""image"" src=""https://github.com/user-attachments/assets/c4a9ffe6-8d0b-40b2-99ca-3b3005d82554"">
<img width=""1423"" alt=""image"" src=""https://github.com/user-attachments/assets/5805d8d0-6141-48c4-a780-213b02645c0e"">

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-15 10:53:11+00:00,[],2024-11-18 14:27:54+00:00,2024-11-18 14:27:53+00:00,https://github.com/apache/airflow/pull/44052,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2483215665, 'issue_id': 2661622739, 'author': 'vatsrahul1001', 'body': 'closing in favor of https://github.com/apache/airflow/pull/44138', 'created_at': datetime.datetime(2024, 11, 18, 14, 27, 53, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-11-18 14:27:53 UTC): closing in favor of https://github.com/apache/airflow/pull/44138

"
2661553229,pull_request,closed,,AIP-84 Get Batch Task Instances,"related to https://github.com/apache/airflow/issues/42370
closes: https://github.com/apache/airflow/issues/43756",pierrejeambrun,2024-11-15 10:36:50+00:00,['pierrejeambrun'],2024-11-19 08:33:56+00:00,2024-11-15 18:33:06+00:00,https://github.com/apache/airflow/pull/44051,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2661515702,pull_request,closed,,Remove console log from TriggerDag,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Removing the warning for addition of console.log
```
/Users/amoghdesai/Documents/OSS/airflow/airflow/ui/src/components/TriggerDag/TriggerDag.tsx
  43:3  warning  Unexpected console statement  no-console

```


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-15 10:16:43+00:00,['amoghrajesh'],2024-11-15 14:59:15+00:00,2024-11-15 14:12:13+00:00,https://github.com/apache/airflow/pull/44050,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2479082415, 'issue_id': 2661515702, 'author': 'bbovenzi', 'body': 'That was intentional just to confirm the dagParams generated. But its fine.', 'created_at': datetime.datetime(2024, 11, 15, 14, 59, 13, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-11-15 14:59:13 UTC): That was intentional just to confirm the dagParams generated. But its fine.

"
2661311781,pull_request,closed,,AIP-84: Migrating GET queued asset events for assets to fastAPI,"Related: https://github.com/apache/airflow/issues/42370
Dependent: https://github.com/apache/airflow/pull/43934

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-15 09:03:27+00:00,[],2024-11-18 14:28:20+00:00,2024-11-18 14:28:20+00:00,https://github.com/apache/airflow/pull/44048,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2482399769, 'issue_id': 2661311781, 'author': 'pierrejeambrun', 'body': 'needs rabasing + conflict resolution', 'created_at': datetime.datetime(2024, 11, 18, 9, 27, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483217203, 'issue_id': 2661311781, 'author': 'vatsrahul1001', 'body': 'closing in favour of https://github.com/apache/airflow/pull/44139', 'created_at': datetime.datetime(2024, 11, 18, 14, 28, 20, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-18 09:27:11 UTC): needs rabasing + conflict resolution

vatsrahul1001 (Issue Creator) on (2024-11-18 14:28:20 UTC): closing in favour of https://github.com/apache/airflow/pull/44139

"
2660504006,pull_request,closed,,Replace Example DAGs Link,"- Replaces example DAGs link with permalink
If the permalink is incorrect, please let me know!",ashishjayamohan,2024-11-15 01:59:24+00:00,[],2024-11-15 18:28:38+00:00,2024-11-15 18:28:32+00:00,https://github.com/apache/airflow/pull/44047,"[('area:providers', ''), ('kind:documentation', ''), ('provider:docker', '')]","[{'comment_id': 2477797871, 'issue_id': 2660504006, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 15, 1, 59, 28, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-15 01:59:28 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2660269397,pull_request,closed,,Give log event a name in a test,"This is mostly pointless but hey.

I didn't want to write log because there's often a log var.  I was annoyed that pre-commit was complaining about this so I just noqa'd it.  But what Kaxil wants, Kaxil gets ;)
",dstandish,2024-11-14 22:44:33+00:00,[],2024-11-15 02:47:08+00:00,2024-11-15 00:59:37+00:00,https://github.com/apache/airflow/pull/44046,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2477606277, 'issue_id': 2660269397, 'author': 'kaxil', 'body': '>But what Kaxil wants, Kaxil gets ;)\r\n\r\n<img src=""https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExMnFsM2prd2s0cWd0YW4zeXQzeTU0bXV3ZXBzbG82NzNlZzRjcGwzZSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/kHOts8xerNiFI6KdCO/giphy.gif"" />', 'created_at': datetime.datetime(2024, 11, 14, 23, 23, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477606477, 'issue_id': 2660269397, 'author': 'kaxil', 'body': 'PR of the month ;)', 'created_at': datetime.datetime(2024, 11, 14, 23, 23, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477845993, 'issue_id': 2660269397, 'author': 'dstandish', 'body': '> Indeed. Good candidate for PR of the month.\r\n\r\nYeah if this does not win it’s a totally rigged competition', 'created_at': datetime.datetime(2024, 11, 15, 2, 47, 7, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-14 23:23:02 UTC): <img src=""https://i.giphy.com/media/v1.Y2lkPTc5MGI3NjExMnFsM2prd2s0cWd0YW4zeXQzeTU0bXV3ZXBzbG82NzNlZzRjcGwzZSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/kHOts8xerNiFI6KdCO/giphy.gif"" />

kaxil on (2024-11-14 23:23:14 UTC): PR of the month ;)

dstandish (Issue Creator) on (2024-11-15 02:47:07 UTC): Yeah if this does not win it’s a totally rigged competition

"
2660227523,pull_request,closed,, Ensure priority weight is capped at 32-bit integer to prevent roll-over (#43611),Backport of #43611,jscheffl,2024-11-14 22:37:39+00:00,[],2024-11-17 21:19:32+00:00,2024-11-17 21:19:31+00:00,https://github.com/apache/airflow/pull/44045,"[('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core', '')]",[],
2660038333,pull_request,closed,,Improve parsing of HTTP errors in Task SDK API client,"There was a logic bug where a non-list detail error was not parsing correctly
causing a _different_ error (pydantic ValidationError, rather than a 404 error)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-14 20:52:25+00:00,[],2024-11-15 09:52:28+00:00,2024-11-14 21:48:04+00:00,https://github.com/apache/airflow/pull/44044,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2660023079,pull_request,closed,,AIP-84 Fix: Allow Null Values for end_date Field in Dashboard Endpint in FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
related: #43846

- Allow `safe_date_time` to return `None` if the input is `None`
- Handle `None` in queries/endpoints 
- Simplify unit tests

I have created a separate PR because write permissions don't allow me to push to the existing PR.
cc: @bbovenzi @pierrejeambrun @tirkarthi 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-11-14 20:44:18+00:00,[],2024-11-19 17:07:42+00:00,2024-11-19 17:07:41+00:00,https://github.com/apache/airflow/pull/44043,[],"[{'comment_id': 2480406445, 'issue_id': 2660023079, 'author': 'tirkarthi', 'body': ""The following were added in #43934 . The changes broke dashboard endpoint probably due `str` changed to `datetime` . During resolving merge conflicts maybe OptionalDateTimeQuery could be used for `end_date` which hopefully resolves this PR's use case.\r\n\r\n```\r\nDateTimeQuery = Annotated[datetime, AfterValidator(_safe_parse_datetime)]\r\nOptionalDateTimeQuery = Annotated[Union[datetime, None], AfterValidator(_safe_parse_datetime_optional)]\r\n```\r\n\r\nhttps://github.com/apache/airflow/pull/43934/files#diff-183a76763667e545ddd8c2aadf6858fdd7a80fecdd04b71e61eaa4ff344239cdR638-R639"", 'created_at': datetime.datetime(2024, 11, 16, 5, 5, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480661125, 'issue_id': 2660023079, 'author': 'bugraoz93', 'body': ""> Thanks a few suggestions\r\n\r\nI’ve made the adjustments in the methods and let FastAPI handle it as a `422`. I followed a similar approach to the changes you made in the other PR.\r\n\r\n> The following were added in #43934 . The changes broke dashboard endpoint probably due `str` changed to `datetime` . During resolving merge conflicts maybe OptionalDateTimeQuery could be used for `end_date` which hopefully resolves this PR's use case.\r\n> \r\n> ```\r\n> DateTimeQuery = Annotated[datetime, AfterValidator(_safe_parse_datetime)]\r\n> OptionalDateTimeQuery = Annotated[Union[datetime, None], AfterValidator(_safe_parse_datetime_optional)]\r\n> ```\r\n> \r\n> https://github.com/apache/airflow/pull/43934/files#diff-183a76763667e545ddd8c2aadf6858fdd7a80fecdd04b71e61eaa4ff344239cdR638-R639\r\n\r\n\r\nI haven’t updated the annotation to `datetime` yet because, in `airflow/utils/timezone.py`, we’re parsing the date as a `pendulum` object to ensure consistent `timezone` handling, and it currently accepts a string. If we want to validate the `datetime` type directly in FastAPI and ensure it works with `pendulum` for proper timezone handling, we could introduce a new implementation using something like `pendulum.instance()`. However, I’m uncertain if adding that new capability is necessary. If it is, I am up for the change."", 'created_at': datetime.datetime(2024, 11, 16, 16, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480738364, 'issue_id': 2660023079, 'author': 'bugraoz93', 'body': 'FastAPI itself returns `str` for `datetime` objects in both requests and responses. As mentioned earlier, I’m not certain if there would be a meaningful difference since `pendulum.parse()` already supports the `ISO 8601` format.\r\n\r\n> * datetime.datetime:\r\nA Python datetime.datetime.\r\nIn requests and responses will be represented as a str in ISO 8601 format, like: 2008-09-15T15:53:00+05:00.\r\n\r\nhttps://fastapi.tiangolo.com/tutorial/extra-data-types/?h=datet#other-data-types', 'created_at': datetime.datetime(2024, 11, 16, 19, 3, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484313703, 'issue_id': 2660023079, 'author': 'bugraoz93', 'body': '> Looks good, let us just merge again the PR introducing `OptionalDateTimeQuery` (it got reverted because of CI issues not catching tests etc...) and we should be good to go\r\n\r\nThanks for the quick reviews and for merging the changes again so promptly! I aimed to replicate the changes and test the endpoint accordingly. I also followed up on the CI failure, which helped me realize I needed to apply a similar fix to the CI script updates in another PR later on :)', 'created_at': datetime.datetime(2024, 11, 18, 22, 59, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486171686, 'issue_id': 2660023079, 'author': 'pierrejeambrun', 'body': 'Restarting failed job, ready to merge when CI is green.', 'created_at': datetime.datetime(2024, 11, 19, 16, 21, 40, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-11-16 05:05:48 UTC): The following were added in #43934 . The changes broke dashboard endpoint probably due `str` changed to `datetime` . During resolving merge conflicts maybe OptionalDateTimeQuery could be used for `end_date` which hopefully resolves this PR's use case.

```
DateTimeQuery = Annotated[datetime, AfterValidator(_safe_parse_datetime)]
OptionalDateTimeQuery = Annotated[Union[datetime, None], AfterValidator(_safe_parse_datetime_optional)]
```

https://github.com/apache/airflow/pull/43934/files#diff-183a76763667e545ddd8c2aadf6858fdd7a80fecdd04b71e61eaa4ff344239cdR638-R639

bugraoz93 (Issue Creator) on (2024-11-16 16:48:50 UTC): I’ve made the adjustments in the methods and let FastAPI handle it as a `422`. I followed a similar approach to the changes you made in the other PR.



I haven’t updated the annotation to `datetime` yet because, in `airflow/utils/timezone.py`, we’re parsing the date as a `pendulum` object to ensure consistent `timezone` handling, and it currently accepts a string. If we want to validate the `datetime` type directly in FastAPI and ensure it works with `pendulum` for proper timezone handling, we could introduce a new implementation using something like `pendulum.instance()`. However, I’m uncertain if adding that new capability is necessary. If it is, I am up for the change.

bugraoz93 (Issue Creator) on (2024-11-16 19:03:36 UTC): FastAPI itself returns `str` for `datetime` objects in both requests and responses. As mentioned earlier, I’m not certain if there would be a meaningful difference since `pendulum.parse()` already supports the `ISO 8601` format.

A Python datetime.datetime.
In requests and responses will be represented as a str in ISO 8601 format, like: 2008-09-15T15:53:00+05:00.

https://fastapi.tiangolo.com/tutorial/extra-data-types/?h=datet#other-data-types

bugraoz93 (Issue Creator) on (2024-11-18 22:59:30 UTC): Thanks for the quick reviews and for merging the changes again so promptly! I aimed to replicate the changes and test the endpoint accordingly. I also followed up on the CI failure, which helped me realize I needed to apply a similar fix to the CI script updates in another PR later on :)

pierrejeambrun on (2024-11-19 16:21:40 UTC): Restarting failed job, ready to merge when CI is green.

"
2659869950,pull_request,closed,,Add async engine and session (Draft PR to test a fix),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Draft PR to test a fix.
",omkar-foss,2024-11-14 19:37:14+00:00,[],2024-11-14 20:56:40+00:00,2024-11-14 20:56:33+00:00,https://github.com/apache/airflow/pull/44042,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:postgres', ''), ('provider:mysql', ''), ('provider:sqlite', '')]","[{'comment_id': 2477394128, 'issue_id': 2659869950, 'author': 'omkar-foss', 'body': 'Testing complete, failing tests are passing. Closing this PR.', 'created_at': datetime.datetime(2024, 11, 14, 20, 56, 33, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-14 20:56:33 UTC): Testing complete, failing tests are passing. Closing this PR.

"
2659760715,pull_request,closed,,Feat: telegram send file Operator and Hook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
I found that the Slack provider has a `send_file` hook and related operator, so I want to implement a similar one for the Telegram provider!

If this is a good idea, I will add unit tests and any other necessary components later!

My first PR, which was related to unit tests, was submitted last month, so I am still a newcomer. Any suggestions or feedback on this work would be greatly appreciated!

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",HaKkaz,2024-11-14 18:54:00+00:00,[],2024-11-18 00:36:10+00:00,2024-11-18 00:36:10+00:00,https://github.com/apache/airflow/pull/44040,"[('area:providers', ''), ('provider:telegram', '')]","[{'comment_id': 2477197722, 'issue_id': 2659760715, 'author': 'potiuk', 'body': 'sure. Go ahead.', 'created_at': datetime.datetime(2024, 11, 14, 19, 2, 52, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-14 19:02:52 UTC): sure. Go ahead.

"
2659610655,pull_request,closed,,Fix Google Cloud Datacatalog test,"This field (`dataplex_transfer_status`) got added in https://github.com/googleapis/google-cloud-python/pull/13277 as part of `google-cloud-datacatalog==3.22.0`

Example failure: https://github.com/apache/airflow/actions/runs/11842030744/job/33000167393?pr=44036

```
=========================== short test summary info ============================
FAILED providers/tests/google/cloud/operators/test_datacatalog.py::TestCloudDataCatalogCreateTagTemplateOperator::test_assert_valid_hook_call - AssertionError: assert equals failed
  {                                {                               
                                     'dataplex_transfer_status': 0 
                                   ,                               
    'display_name': '',              'display_name': '',           
    'fields': {},                    'fields': {},                 
    'is_publicly_readable': False    'is_publicly_readable': False 
  ,                                ,                               
    'name': 'projects/example_id/    'name': 'projects/example_id/ 
  locations/en-west-3/tagTemplate  locations/en-west-3/tagTemplate 
  s/test-tag-template-id',         s/test-tag-template-id',        
  }                                }
====== 1 failed, 4200 passed, 79 skipped, 1 warning in 261.02s (0:04:21) =======

```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-14 17:54:08+00:00,[],2024-11-14 19:34:34+00:00,2024-11-14 19:34:32+00:00,https://github.com/apache/airflow/pull/44037,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2477163418, 'issue_id': 2659610655, 'author': 'potiuk', 'body': 'Yeah I was afraid of this - you cannot us `dict in dict` assert :( .', 'created_at': datetime.datetime(2024, 11, 14, 18, 44, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477166484, 'issue_id': 2659610655, 'author': 'potiuk', 'body': 'https://github.com/pytest-dev/pytest/issues/2376#issuecomment-852366588', 'created_at': datetime.datetime(2024, 11, 14, 18, 45, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477167345, 'issue_id': 2659610655, 'author': 'potiuk', 'body': 'Python 3.9+\r\n\r\n```\r\nassert {**dict2, **dict1} == dict2\r\n```', 'created_at': datetime.datetime(2024, 11, 14, 18, 46, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477204059, 'issue_id': 2659610655, 'author': 'kaxil', 'body': 'oh whoops, fixing', 'created_at': datetime.datetime(2024, 11, 14, 19, 6, 29, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-14 18:44:01 UTC): Yeah I was afraid of this - you cannot us `dict in dict` assert :( .

potiuk on (2024-11-14 18:45:40 UTC): https://github.com/pytest-dev/pytest/issues/2376#issuecomment-852366588

potiuk on (2024-11-14 18:46:08 UTC): Python 3.9+

```
assert {**dict2, **dict1} == dict2
```

kaxil (Issue Creator) on (2024-11-14 19:06:29 UTC): oh whoops, fixing

"
2659485324,pull_request,closed,,Bump `aiohttp` to `3.11.1`,"https://github.com/aio-libs/aiohttp/issues/9866 was fixed by https://github.com/pnuckowski/aioresponses/pull/262#issuecomment-2476728212

https://pypi.org/project/aiohttp/3.11.1/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-14 17:06:26+00:00,[],2024-11-14 23:59:38+00:00,2024-11-14 21:27:51+00:00,https://github.com/apache/airflow/pull/44036,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2476973443, 'issue_id': 2659485324, 'author': 'kaxil', 'body': ""https://github.com/pnuckowski/aioresponses/pull/262 hasn't been merged yet though"", 'created_at': datetime.datetime(2024, 11, 14, 17, 8, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477051831, 'issue_id': 2659485324, 'author': 'potiuk', 'body': ""> [pnuckowski/aioresponses#262](https://github.com/pnuckowski/aioresponses/pull/262) hasn't been merged yet though\r\n\r\nIt's unllikely to be merged - the maintainer seems to be MIA for 2 years. That's why likely aiohttp brought back compatiblity with released version of the aioresponses as it is popular"", 'created_at': datetime.datetime(2024, 11, 14, 17, 47, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477152573, 'issue_id': 2659485324, 'author': 'potiuk', 'body': 'looks good. Maybe one nit - would be great to add comment with link to the issue in provider.yaml', 'created_at': datetime.datetime(2024, 11, 14, 18, 38, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477153607, 'issue_id': 2659485324, 'author': 'potiuk', 'body': '(we have it in commit so no strictly necessary - but it safes git blame etc.)', 'created_at': datetime.datetime(2024, 11, 14, 18, 39, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477210034, 'issue_id': 2659485324, 'author': 'kaxil', 'body': '> (we have it in commit so no strictly necessary - but it safes git blame etc.)\r\n\r\nDone', 'created_at': datetime.datetime(2024, 11, 14, 19, 9, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477465026, 'issue_id': 2659485324, 'author': 'kaxil', 'body': 'Damn! last commit msg was used as commit title :(', 'created_at': datetime.datetime(2024, 11, 14, 21, 41, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477656188, 'issue_id': 2659485324, 'author': 'potiuk', 'body': 'Good we have the comment :)', 'created_at': datetime.datetime(2024, 11, 14, 23, 59, 37, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-14 17:08:09 UTC): https://github.com/pnuckowski/aioresponses/pull/262 hasn't been merged yet though

potiuk on (2024-11-14 17:47:23 UTC): It's unllikely to be merged - the maintainer seems to be MIA for 2 years. That's why likely aiohttp brought back compatiblity with released version of the aioresponses as it is popular

potiuk on (2024-11-14 18:38:43 UTC): looks good. Maybe one nit - would be great to add comment with link to the issue in provider.yaml

potiuk on (2024-11-14 18:39:19 UTC): (we have it in commit so no strictly necessary - but it safes git blame etc.)

kaxil (Issue Creator) on (2024-11-14 19:09:35 UTC): Done

kaxil (Issue Creator) on (2024-11-14 21:41:17 UTC): Damn! last commit msg was used as commit title :(

potiuk on (2024-11-14 23:59:37 UTC): Good we have the comment :)

"
2659410637,pull_request,closed,,Pass last_dag_run_state to recent dagruns API to fetch only dags with given state for the latest dagrun.,I noticed while debugging https://github.com/apache/airflow/issues/43882 the recent dagruns endpoint supports passing `last_dag_run_state` which makes it efficient to fetch only the dag with given `last_dag_run_state` as latest dagrun and corresponding dagruns for the dag. Else all dags of all states are returned and filtered in the frontend.,tirkarthi,2024-11-14 16:44:48+00:00,[],2024-11-14 18:20:08+00:00,2024-11-14 18:20:08+00:00,https://github.com/apache/airflow/pull/44035,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2659167510,pull_request,closed,,Update DAG example links in multiple providers documents,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:


related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44012 


<!-- Please keep an empty line above the dashes. -->
---

Updated multiple provider documents with new DAG example links.
",amirmor1,2024-11-14 15:28:46+00:00,[],2024-11-16 03:23:56+00:00,2024-11-15 18:37:26+00:00,https://github.com/apache/airflow/pull/44034,"[('area:providers', ''), ('kind:documentation', ''), ('provider:docker', '')]","[{'comment_id': 2477220727, 'issue_id': 2659167510, 'author': 'kaxil', 'body': 'Could you please update the PR title? The current one is a bit vague and doesn’t clearly communicate the purpose of the change. I recommend reading [this blog post](https://cbea.ms/git-commit/) for guidance.\r\n\r\nIn particular, it would be helpful to follow this principle:\r\n\r\n> **_A properly formed Git commit subject line should always be able to complete the following sentence: “If applied, this commit will [your subject line here].”_**\r\n\r\nSince this entry will appear in the release notes, it’s important that the PR title and description clearly explain the changes and their impact.', 'created_at': datetime.datetime(2024, 11, 14, 19, 15, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480367784, 'issue_id': 2659167510, 'author': 'potiuk', 'body': ""We will likely have to adapt some links in released providers already (and @eladkal -> for sure you'd have to apply it and regenerate the docs for current provider's wave."", 'created_at': datetime.datetime(2024, 11, 16, 3, 23, 54, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-14 19:15:47 UTC): Could you please update the PR title? The current one is a bit vague and doesn’t clearly communicate the purpose of the change. I recommend reading [this blog post](https://cbea.ms/git-commit/) for guidance.

In particular, it would be helpful to follow this principle:


Since this entry will appear in the release notes, it’s important that the PR title and description clearly explain the changes and their impact.

potiuk on (2024-11-16 03:23:54 UTC): We will likely have to adapt some links in released providers already (and @eladkal -> for sure you'd have to apply it and regenerate the docs for current provider's wave.

"
2659113591,pull_request,closed,,Move trigger dagrun to standard provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE


How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Moving trigger_dagrun operator to standard provider.

`airflow/operators/trigger_dagrun.py  >> providers/src/airflow/providers/standard/operators/trigger_dagrun.py`


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hardeybisey,2024-11-14 15:05:40+00:00,[],2024-11-23 14:33:48+00:00,2024-11-15 11:07:59+00:00,https://github.com/apache/airflow/pull/44030,"[('area:providers', ''), ('area:serialization', ''), ('area:system-tests', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]",[],
2658949033,pull_request,closed,,Fix side effect of bad grpc.Chanel mocking,"The grpc.Channel has been patched but not relased in the test_grpc.py and it could have caused other tests failing - when they were run later in the same interpreter. For example it failed in in #44011 in the https://github.com/apache/airflow/pull/44011#issuecomment-2476439247

Patching is now fixed via using fixtures.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-14 14:15:33+00:00,[],2024-11-14 14:38:39+00:00,2024-11-14 14:38:37+00:00,https://github.com/apache/airflow/pull/44029,"[('area:providers', ''), ('provider:grpc', '')]","[{'comment_id': 2476471777, 'issue_id': 2658949033, 'author': 'potiuk', 'body': ""Interestingly it's been there since the very beginning - i.e 2019"", 'created_at': datetime.datetime(2024, 11, 14, 14, 18, 20, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-14 14:18:20 UTC): Interestingly it's been there since the very beginning - i.e 2019

"
2658930056,pull_request,closed,,Fix error file not found. tmp file is deleted before inserting rows to DB in VerticaToMySQLOperator bulk ,"
Fix error file not found. tmp file is deleted before inserting rows to DB in VerticaToMySQLOperator bulk .

---

",bareketamir,2024-11-14 14:08:21+00:00,[],2024-11-19 21:27:12+00:00,2024-11-19 21:26:59+00:00,https://github.com/apache/airflow/pull/44028,"[('area:providers', ''), ('provider:mysql', '')]","[{'comment_id': 2486787115, 'issue_id': 2658930056, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 19, 21, 27, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486787397, 'issue_id': 2658930056, 'author': 'potiuk', 'body': 'error already fixed in main.', 'created_at': datetime.datetime(2024, 11, 19, 21, 27, 11, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-19 21:27:01 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2024-11-19 21:27:11 UTC): error already fixed in main.

"
2658817029,pull_request,closed,,Move decorators to standard provider,"related: #43641 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-11-14 13:22:28+00:00,[],2025-01-15 16:13:07+00:00,2025-01-15 16:13:07+00:00,https://github.com/apache/airflow/pull/44027,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2481987480, 'issue_id': 2658817029, 'author': 'uranusjr', 'body': 'I don’t think we are moving core Airflow concepts like BaseOperator into the provider? Unless we are, at least `@task` should stay in core. Likely `@setup` and `@teardown` as well (since `as_setup()` and `as_teardown()` are on BaseOperator).', 'created_at': datetime.datetime(2024, 11, 18, 5, 27, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483283127, 'issue_id': 2658817029, 'author': 'romsharon98', 'body': ""> I don’t think we are moving core Airflow concepts like BaseOperator into the provider? Unless we are, at least `@task` should stay in core. Likely `@setup` and `@teardown` as well (since `as_setup()` and `as_teardown()` are on BaseOperator).\r\n\r\nBut isn't @ task mean PythonOperator and therefore we want it out of Core?"", 'created_at': datetime.datetime(2024, 11, 18, 14, 52, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505164494, 'issue_id': 2658817029, 'author': 'potiuk', 'body': '> But isn\'t @ task mean PythonOperator and therefore we want it out of Core?\r\n\r\nYeah. I also think while the base `DecoratedOperator` (and all in airflow/decorators/base.py) should stay in ""core"" - ""task"" and other decorators can be easily (or so I think) move to `standard` (unless there is a good reason not to).\r\n\r\nBaseOperator. MappedOperator, DecoratedOperator are all ""core"" concepts - but @task, @task.bash etc. could be just considered as concrete implementations of those that could live in the standard provider.\r\n\r\n@uranusjr - is there a reason why we should not move it ?', 'created_at': datetime.datetime(2024, 11, 28, 2, 50, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585982177, 'issue_id': 2658817029, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 13, 0, 16, 36, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-11-18 05:27:24 UTC): I don’t think we are moving core Airflow concepts like BaseOperator into the provider? Unless we are, at least `@task` should stay in core. Likely `@setup` and `@teardown` as well (since `as_setup()` and `as_teardown()` are on BaseOperator).

romsharon98 (Issue Creator) on (2024-11-18 14:52:47 UTC): But isn't @ task mean PythonOperator and therefore we want it out of Core?

potiuk on (2024-11-28 02:50:39 UTC): Yeah. I also think while the base `DecoratedOperator` (and all in airflow/decorators/base.py) should stay in ""core"" - ""task"" and other decorators can be easily (or so I think) move to `standard` (unless there is a good reason not to).

BaseOperator. MappedOperator, DecoratedOperator are all ""core"" concepts - but @task, @task.bash etc. could be just considered as concrete implementations of those that could live in the standard provider.

@uranusjr - is there a reason why we should not move it ?

github-actions[bot] on (2025-01-13 00:16:36 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2658761467,pull_request,closed,,Fix openlineage tests,"Tests are failing https://github.com/apache/airflow/actions/runs/11837035818/job/32983342904?pr=44018#step:7:4873

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-14 13:08:43+00:00,[],2024-11-14 14:56:44+00:00,2024-11-14 13:11:06+00:00,https://github.com/apache/airflow/pull/44025,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2476320535, 'issue_id': 2658761467, 'author': 'gopidesupavan', 'body': 'Not sure which PR causes this failure trying to find :)', 'created_at': datetime.datetime(2024, 11, 14, 13, 10, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476326911, 'issue_id': 2658761467, 'author': 'potiuk', 'body': 'One of the few latest asset changes. I think we should automatically add providers open-lineage tests after any changes in assets, as their test heavily depend on them.\r\n\r\nThis will be quite a bit easier I think after https://github.com/apache/airflow/pull/43979 lands.', 'created_at': datetime.datetime(2024, 11, 14, 13, 13, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476335490, 'issue_id': 2658761467, 'author': 'potiuk', 'body': 'Issue created : https://github.com/apache/airflow/issues/44026', 'created_at': datetime.datetime(2024, 11, 14, 13, 17, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476344769, 'issue_id': 2658761467, 'author': 'potiuk', 'body': 'Yeah it was caused by #41325 - and there the test were green because openlineage tests were skipped by selective checks., so #44026 when implemented might help to avoid such breakages.', 'created_at': datetime.datetime(2024, 11, 14, 13, 21, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476347003, 'issue_id': 2658761467, 'author': 'potiuk', 'body': '(or maybe @mobuchowski @kacpermuda - we could make those open-lineage tests less depending on actual dataset implementation ? Not sure).', 'created_at': datetime.datetime(2024, 11, 14, 13, 22, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476354132, 'issue_id': 2658761467, 'author': 'mobuchowski', 'body': ""The uri vs name thing is not purely implementation detail in this case. We actually try to serialize that information - the event output we want to have _is_ depending on actual dataset specification - I'd rather do the opposite and run OL tests with any change to assets/datasets."", 'created_at': datetime.datetime(2024, 11, 14, 13, 25, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476355254, 'issue_id': 2658761467, 'author': 'mobuchowski', 'body': ""Oh yeah that's what you actually suggested within the issue :)"", 'created_at': datetime.datetime(2024, 11, 14, 13, 26, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476585590, 'issue_id': 2658761467, 'author': 'potiuk', 'body': ""> Oh yeah that's what you actually suggested within the issue :)\r\n\r\nYeah. I just wanted to check whether this is an accidental or REAL dependency on asset features."", 'created_at': datetime.datetime(2024, 11, 14, 14, 56, 42, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-14 13:10:27 UTC): Not sure which PR causes this failure trying to find :)

potiuk on (2024-11-14 13:13:30 UTC): One of the few latest asset changes. I think we should automatically add providers open-lineage tests after any changes in assets, as their test heavily depend on them.

This will be quite a bit easier I think after https://github.com/apache/airflow/pull/43979 lands.

potiuk on (2024-11-14 13:17:29 UTC): Issue created : https://github.com/apache/airflow/issues/44026

potiuk on (2024-11-14 13:21:36 UTC): Yeah it was caused by #41325 - and there the test were green because openlineage tests were skipped by selective checks., so #44026 when implemented might help to avoid such breakages.

potiuk on (2024-11-14 13:22:34 UTC): (or maybe @mobuchowski @kacpermuda - we could make those open-lineage tests less depending on actual dataset implementation ? Not sure).

mobuchowski on (2024-11-14 13:25:34 UTC): The uri vs name thing is not purely implementation detail in this case. We actually try to serialize that information - the event output we want to have _is_ depending on actual dataset specification - I'd rather do the opposite and run OL tests with any change to assets/datasets.

mobuchowski on (2024-11-14 13:26:06 UTC): Oh yeah that's what you actually suggested within the issue :)

potiuk on (2024-11-14 14:56:42 UTC): Yeah. I just wanted to check whether this is an accidental or REAL dependency on asset features.

"
2658435887,pull_request,closed,,AIP-38 | List Import Errors,"closes: #43711 

<img width=""1536"" alt=""Screenshot 2024-11-16 at 2 13 09 AM"" src=""https://github.com/user-attachments/assets/889240b0-a3ee-4220-8a65-ace5492c8e0c"">
<img width=""1536"" alt=""Screenshot 2024-11-16 at 2 13 18 AM"" src=""https://github.com/user-attachments/assets/d8078673-df0b-4944-a525-c8be62583e97"">
<img width=""1536"" alt=""Screenshot 2024-11-16 at 2 13 57 AM"" src=""https://github.com/user-attachments/assets/0f6612fc-2175-4ab2-a72e-fb72b6eaa31b"">
<img width=""1536"" alt=""Screenshot 2024-11-16 at 2 14 24 AM"" src=""https://github.com/user-attachments/assets/3ad82806-7dd7-4b1e-9279-04b4e929faa3"">



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2024-11-14 10:54:20+00:00,[],2024-11-18 13:57:41+00:00,2024-11-18 13:57:40+00:00,https://github.com/apache/airflow/pull/44021,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2476858937, 'issue_id': 2658435887, 'author': 'tirkarthi', 'body': 'One point to add is that current import errors are shown all at once in the legacy home page which makes using `Ctrl+F` easier to search especially on large Airflow instances with lot of users and hundreds of import errors which might not be possible anymore with pagination.', 'created_at': datetime.datetime(2024, 11, 14, 16, 23, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2479889069, 'issue_id': 2658435887, 'author': 'shubhamraj-git', 'body': '> One point to add is that current import errors are shown all at once in the legacy home page which makes using `Ctrl+F` easier to search especially on large Airflow instances with lot of users and hundreds of import errors which might not be possible anymore with pagination.\r\n\r\n@tirkarthi I have added a search option to do that.', 'created_at': datetime.datetime(2024, 11, 15, 20, 41, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480456235, 'issue_id': 2658435887, 'author': 'shubhamraj-git', 'body': '@bbovenzi \r\nAlso, since this is an error showing page, I saw the old UI have names too in red, So what do you think, which of the two options look good? Red or normal black?\r\n<img width=""996"" alt=""image"" src=""https://github.com/user-attachments/assets/84383519-7933-4e8e-aa3a-b2e459bb53a7"">', 'created_at': datetime.datetime(2024, 11, 16, 7, 0, 25, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-11-14 16:23:35 UTC): One point to add is that current import errors are shown all at once in the legacy home page which makes using `Ctrl+F` easier to search especially on large Airflow instances with lot of users and hundreds of import errors which might not be possible anymore with pagination.

shubhamraj-git (Issue Creator) on (2024-11-15 20:41:39 UTC): @tirkarthi I have added a search option to do that.

shubhamraj-git (Issue Creator) on (2024-11-16 07:00:25 UTC): @bbovenzi 
Also, since this is an error showing page, I saw the old UI have names too in red, So what do you think, which of the two options look good? Red or normal black?
<img width=""996"" alt=""image"" src=""https://github.com/user-attachments/assets/84383519-7933-4e8e-aa3a-b2e459bb53a7"">

"
2658401036,pull_request,closed,,Move version imports to inside utils standard provider,"Version imports causing issues when using from __init__ : https://github.com/apache/airflow/pull/44011
https://github.com/apache/airflow/pull/44011#discussion_r1841786333
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-14 10:42:50+00:00,[],2024-11-14 13:12:18+00:00,2024-11-14 13:10:44+00:00,https://github.com/apache/airflow/pull/44018,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:standard', '')]","[{'comment_id': 2476206188, 'issue_id': 2658401036, 'author': 'eladkal', 'body': 'cc @potiuk', 'created_at': datetime.datetime(2024, 11, 14, 12, 15, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476207314, 'issue_id': 2658401036, 'author': 'potiuk', 'body': 'This is strange error', 'created_at': datetime.datetime(2024, 11, 14, 12, 15, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476209062, 'issue_id': 2658401036, 'author': 'gopidesupavan', 'body': 'Not sure one test is failing.. \r\nhttps://github.com/apache/airflow/actions/runs/11835585982/job/32982431658?pr=44018#step:12:1349', 'created_at': datetime.datetime(2024, 11, 14, 12, 16, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476213295, 'issue_id': 2658401036, 'author': 'potiuk', 'body': 'Applying full tests needed should help', 'created_at': datetime.datetime(2024, 11, 14, 12, 18, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476221290, 'issue_id': 2658401036, 'author': 'potiuk', 'body': 'The problem is that ""sdist"" test build new providers and try to install them, and they do it in ""chunks"" - and only for providers affected in this PR. This is a bit missing piece - this PR  only modifies the standard provider but no common.sql 1.20 that it depends on, so it misses 1.20 version locally built.\r\n\r\nWe could likely solve it by smarter selection which providers should be built for sdist builds, but for now ""full tests needed""  should be enough - also this will go away after we merge this one an release common.sql 1.20 , and applying ""full tests needed"" should solve the problem as all provider\'s sdist will be built.', 'created_at': datetime.datetime(2024, 11, 14, 12, 23, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476240893, 'issue_id': 2658401036, 'author': 'eladkal', 'body': '> We could likely solve it by smarter selection which providers should be built for sdist builds, but for now ""full tests needed"" should be enough - also this will go away after we merge this one an release common.sql 1.20 , and applying ""full tests needed"" should solve the problem as all provider\'s sdist will be built.\r\n\r\nYeah the problem should not happen after merging to main.\r\nWe can open a followup task in Github issue to get it done when we have the time', 'created_at': datetime.datetime(2024, 11, 14, 12, 33, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476244814, 'issue_id': 2658401036, 'author': 'potiuk', 'body': '> We can open a followup task in Github issue to get it done when we have the time\r\n\r\nYeah. I was adding it as you wrote it :) https://github.com/apache/airflow/issues/44023', 'created_at': datetime.datetime(2024, 11, 14, 12, 35, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476250530, 'issue_id': 2658401036, 'author': 'gopidesupavan', 'body': '> The problem is that ""sdist"" test build new providers and try to install them, and they do it in ""chunks"" - and only for providers affected in this PR. This is a bit missing piece - this PR only modifies the standard provider but no common.sql 1.20 that it depends on, so it misses 1.20 version locally built.\r\n> \r\n> We could likely solve it by smarter selection which providers should be built for sdist builds, but for now ""full tests needed"" should be enough - also this will go away after we merge this one an release common.sql 1.20 , and applying ""full tests needed"" should solve the problem as all provider\'s sdist will be built.\r\n\r\noh i see, good learning bit to know this :)', 'created_at': datetime.datetime(2024, 11, 14, 12, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476319564, 'issue_id': 2658401036, 'author': 'gopidesupavan', 'body': 'tests are failing for openlineage, created this https://github.com/apache/airflow/pull/44025', 'created_at': datetime.datetime(2024, 11, 14, 13, 10, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-14 12:15:36 UTC): cc @potiuk

potiuk on (2024-11-14 12:15:54 UTC): This is strange error

gopidesupavan (Issue Creator) on (2024-11-14 12:16:46 UTC): Not sure one test is failing.. 
https://github.com/apache/airflow/actions/runs/11835585982/job/32982431658?pr=44018#step:12:1349

potiuk on (2024-11-14 12:18:59 UTC): Applying full tests needed should help

potiuk on (2024-11-14 12:23:12 UTC): The problem is that ""sdist"" test build new providers and try to install them, and they do it in ""chunks"" - and only for providers affected in this PR. This is a bit missing piece - this PR  only modifies the standard provider but no common.sql 1.20 that it depends on, so it misses 1.20 version locally built.

We could likely solve it by smarter selection which providers should be built for sdist builds, but for now ""full tests needed""  should be enough - also this will go away after we merge this one an release common.sql 1.20 , and applying ""full tests needed"" should solve the problem as all provider's sdist will be built.

eladkal on (2024-11-14 12:33:07 UTC): Yeah the problem should not happen after merging to main.
We can open a followup task in Github issue to get it done when we have the time

potiuk on (2024-11-14 12:35:08 UTC): Yeah. I was adding it as you wrote it :) https://github.com/apache/airflow/issues/44023

gopidesupavan (Issue Creator) on (2024-11-14 12:37:54 UTC): oh i see, good learning bit to know this :)

gopidesupavan (Issue Creator) on (2024-11-14 13:10:00 UTC): tests are failing for openlineage, created this https://github.com/apache/airflow/pull/44025

"
2658382739,pull_request,closed,,Fix template for standard provider init,"To address https://github.com/apache/airflow/pull/44011#discussion_r1841786333
We probably need to add static check to verify no changes are made to init unless changing the template",eladkal,2024-11-14 10:40:43+00:00,[],2024-11-14 16:26:00+00:00,2024-11-14 12:02:51+00:00,https://github.com/apache/airflow/pull/44017,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:standard', '')]","[{'comment_id': 2476015021, 'issue_id': 2658382739, 'author': 'gopidesupavan', 'body': 'ah i see you already created this :) , have made change here https://github.com/apache/airflow/pull/44018 do you want me to close that?', 'created_at': datetime.datetime(2024, 11, 14, 10, 47, 4, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-14 10:47:04 UTC): ah i see you already created this :) , have made change here https://github.com/apache/airflow/pull/44018 do you want me to close that?

"
2658325450,pull_request,closed,,BaseExecutor allows executors to consumer task_instance parameters,"# Description

During implementation of the slot handling in the Edge provider package (see https://github.com/apache/airflow/pull/43737) a discussion about how to enable executors to use additional information was started. This PR tackles the idea on extend the execute_async function with task_instance to allow executor consuming all the task_instance parameters. With this it is pretty simple to change a the interface and the executer can decide with task_instance parameters he wants to use to implement task specific behaviors.

This PR shows a possible solution how to tackle option 2 of discussion in this PR https://github.com/apache/airflow/pull/43737. Will also create a devlist discussion about this.

# Details about changes

* Add execute function into BaseExecutor which has task_instance as parameter.
* New execute function calls old execute_async function to keep not updated Executors running.
* Add deprecation warning for Executor which use the old execute_async function.",AutomationDev85,2024-11-14 10:17:27+00:00,[],2025-01-31 00:14:57+00:00,2025-01-31 00:14:57+00:00,https://github.com/apache/airflow/pull/44016,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2477264542, 'issue_id': 2658325450, 'author': 'jscheffl', 'body': 'Even though it is green, converting to DRAFT as long as devlist discussion is ongoing.', 'created_at': datetime.datetime(2024, 11, 14, 19, 40, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505139905, 'issue_id': 2658325450, 'author': 'potiuk', 'body': ""Yes. It's cool."", 'created_at': datetime.datetime(2024, 11, 28, 2, 25, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506806086, 'issue_id': 2658325450, 'author': 'jscheffl', 'body': ""> Yes. It's cool.\r\n\r\nI assume we can drop this as in AIP-72 the interface is changing anyway as far as I understood @ashb - and will not go into 2.10-line.\r\n\r\n@AutomationDev85 is thi sstill something that is needed?"", 'created_at': datetime.datetime(2024, 11, 28, 22, 13, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585982208, 'issue_id': 2658325450, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 13, 0, 16, 39, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-11-14 19:40:27 UTC): Even though it is green, converting to DRAFT as long as devlist discussion is ongoing.

potiuk on (2024-11-28 02:25:26 UTC): Yes. It's cool.

jscheffl on (2024-11-28 22:13:24 UTC): I assume we can drop this as in AIP-72 the interface is changing anyway as far as I understood @ashb - and will not go into 2.10-line.

@AutomationDev85 is thi sstill something that is needed?

github-actions[bot] on (2025-01-13 00:16:39 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2658143981,pull_request,closed,,AIP-84: Migrating GET one queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370

Same setup as https://github.com/apache/airflow/pull/43934 and dependent on https://github.com/apache/airflow/pull/43934

Responses:
1. Legacy
![image](https://github.com/user-attachments/assets/9434be96-5558-4d55-a2a2-565df823411b)


2. FastAPI
![image](https://github.com/user-attachments/assets/50257c74-b1e3-440e-9d9f-f303c9d597e9)

With time filtering
1. Legacy
![image](https://github.com/user-attachments/assets/d079968c-a8e2-4cd7-8000-48862b0a9c87)

2. FastAPI
![image](https://github.com/user-attachments/assets/f960ecf4-411e-431a-80b5-c5093ec76d2a)

Swagger spec:
<img width=""1279"" alt=""image"" src=""https://github.com/user-attachments/assets/e0057771-8964-4f88-badc-b23f32a89eb9"">

<img width=""1279"" alt=""image"" src=""https://github.com/user-attachments/assets/7bbfb0b2-64f5-416d-9307-a1f43e2e4c84"">



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-14 09:18:51+00:00,['amoghrajesh'],2024-11-18 08:28:14+00:00,2024-11-18 08:28:14+00:00,https://github.com/apache/airflow/pull/44013,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2475812917, 'issue_id': 2658143981, 'author': 'amoghrajesh', 'body': 'Only last 2 commits are relevant', 'created_at': datetime.datetime(2024, 11, 14, 9, 19, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482259205, 'issue_id': 2658143981, 'author': 'amoghrajesh', 'body': 'Closing in favour of https://github.com/apache/airflow/pull/44128', 'created_at': datetime.datetime(2024, 11, 18, 8, 28, 12, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-14 09:19:17 UTC): Only last 2 commits are relevant

amoghrajesh (Issue Creator) on (2024-11-18 08:28:12 UTC): Closing in favour of https://github.com/apache/airflow/pull/44128

"
2657963883,pull_request,closed,,Prepare docs for Nov 1st wave of providers,"```
Summary of prepared documentation:

Success: 45

amazon apache.beam apache.drill apache.druid apache.hive apache.impala apache.pinot apache.spark apprise atlassian.jira celery cloudant cncf.kubernetes common.compat common.sql databricks dbt.cloud
docker elasticsearch exasol fab google http jdbc microsoft.azure microsoft.mssql microsoft.winrm mysql odbc openlineage oracle pagerduty papermill pinecone postgres presto slack smtp snowflake sqlite
standard teradata trino vertica ydb

Docs only: 43

airbyte alibaba apache.cassandra apache.flink apache.hdfs apache.iceberg apache.kafka apache.kylin apache.pig arangodb asana cohere common.io datadog dingding discord facebook ftp github grpc hashicorp
imap influxdb microsoft.psrp neo4j openai openfaas opensearch opsgenie pgvector qdrant redis salesforce samba segment sendgrid sftp singularity tableau telegram weaviate yandex zendesk

Skipped on no changes: 4

apache.livy jenkins mongo ssh


Successfully prepared documentation for packages!
```",eladkal,2024-11-14 08:03:53+00:00,[],2024-11-14 16:24:09+00:00,2024-11-14 16:24:05+00:00,https://github.com/apache/airflow/pull/44011,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:celery', ''), ('provider:apprise', ''), ('provider:atlassian-jira', ''), ('provider:apache-hive', ''), ('provider:apache-druid', ''), ('provider:apache-spark', ''), ('provider:apache-beam', ''), ('provider:apache-drill', ''), ('provider:cloudant', ''), ('provider:apache-pinot', ''), ('provider:apache-impala', ''), ('provider:common-compat', '')]","[{'comment_id': 2476370987, 'issue_id': 2657963883, 'author': 'potiuk', 'body': 'Hmm. Interesting thing - now we have circular dependency: compat -> standard , standard->compat ... which is generally fine but we might have some interesting CI issues because of that :)', 'created_at': datetime.datetime(2024, 11, 14, 13, 33, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476379597, 'issue_id': 2657963883, 'author': 'potiuk', 'body': ""That will also mean @eladkal that we MUST release standard provider with this wave - otherwise common won't be installable.\r\n\r\n\r\nIt's currently 0.0.1 - which I think migt be a good idea to keep it at 0.* until we migrate all things out from core?"", 'created_at': datetime.datetime(2024, 11, 14, 13, 37, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476382502, 'issue_id': 2657963883, 'author': 'eladkal', 'body': '> That will also mean @eladkal that we MUST release standard provider with this wave - otherwise common won\'t be installable.\r\n\r\n>It\'s currently 0.0.1 - which I think migt be a good idea to keep it at 0.* until we migrate all things out from core?\r\n\r\n\r\nthat is the plan. This wave is pretty much all or nothing.\r\n\r\nIt\'s 0.0.1 till we make it ""stable"" by extracting everything.', 'created_at': datetime.datetime(2024, 11, 14, 13, 39, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476439247, 'issue_id': 2657963883, 'author': 'potiuk', 'body': 'Very interesting error. Side effect of another test. Fix is coming. \r\n\r\n```\r\n_______________________ TestAutoMLHook.test_get_dataset ________________________\r\n[gw2] linux -- Python 3.9.20 /usr/local/bin/python\r\n/opt/airflow/providers/tests/google/cloud/hooks/test_automl.py:258: in test_get_dataset\r\n    self.hook.get_dataset(dataset_id=DATASET_ID, location=GCP_LOCATION, project_id=GCP_PROJECT_ID)\r\n/opt/airflow/providers/src/airflow/providers/google/common/hooks/base_google.py:560: in inner_wrapper\r\n    return func(self, *args, **kwargs)\r\n/opt/airflow/providers/src/airflow/providers/google/cloud/hooks/automl.py:669: in get_dataset\r\n    client = self.get_conn()\r\n/opt/airflow/providers/src/airflow/providers/google/cloud/hooks/automl.py:97: in get_conn\r\n    self._client = AutoMlClient(credentials=self.get_credentials(), client_info=CLIENT_INFO)\r\n/usr/local/lib/python3.9/site-packages/google/cloud/automl_v1beta1/services/auto_ml/client.py:793: in __init__\r\n    self._transport = transport_init(\r\n/usr/local/lib/python3.9/site-packages/google/cloud/automl_v1beta1/services/auto_ml/transports/grpc.py:145: in __init__\r\n    if isinstance(channel, grpc.Channel):\r\nE   TypeError: isinstance() arg 2 must be a type or tuple of types\r\n```', 'created_at': datetime.datetime(2024, 11, 14, 14, 4, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476472608, 'issue_id': 2657963883, 'author': 'potiuk', 'body': 'The failure is fixed in https://github.com/apache/airflow/pull/44029', 'created_at': datetime.datetime(2024, 11, 14, 14, 18, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476512638, 'issue_id': 2657963883, 'author': 'eladkal', 'body': '> The failure is fixed in #44029\r\n\r\nCool so no need to regenerate docs as the fix is only in a test', 'created_at': datetime.datetime(2024, 11, 14, 14, 35, 2, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-14 13:33:51 UTC): Hmm. Interesting thing - now we have circular dependency: compat -> standard , standard->compat ... which is generally fine but we might have some interesting CI issues because of that :)

potiuk on (2024-11-14 13:37:53 UTC): That will also mean @eladkal that we MUST release standard provider with this wave - otherwise common won't be installable.


It's currently 0.0.1 - which I think migt be a good idea to keep it at 0.* until we migrate all things out from core?

eladkal (Issue Creator) on (2024-11-14 13:39:12 UTC): that is the plan. This wave is pretty much all or nothing.

It's 0.0.1 till we make it ""stable"" by extracting everything.

potiuk on (2024-11-14 14:04:57 UTC): Very interesting error. Side effect of another test. Fix is coming. 

```
_______________________ TestAutoMLHook.test_get_dataset ________________________
[gw2] linux -- Python 3.9.20 /usr/local/bin/python
/opt/airflow/providers/tests/google/cloud/hooks/test_automl.py:258: in test_get_dataset
    self.hook.get_dataset(dataset_id=DATASET_ID, location=GCP_LOCATION, project_id=GCP_PROJECT_ID)
/opt/airflow/providers/src/airflow/providers/google/common/hooks/base_google.py:560: in inner_wrapper
    return func(self, *args, **kwargs)
/opt/airflow/providers/src/airflow/providers/google/cloud/hooks/automl.py:669: in get_dataset
    client = self.get_conn()
/opt/airflow/providers/src/airflow/providers/google/cloud/hooks/automl.py:97: in get_conn
    self._client = AutoMlClient(credentials=self.get_credentials(), client_info=CLIENT_INFO)
/usr/local/lib/python3.9/site-packages/google/cloud/automl_v1beta1/services/auto_ml/client.py:793: in __init__
    self._transport = transport_init(
/usr/local/lib/python3.9/site-packages/google/cloud/automl_v1beta1/services/auto_ml/transports/grpc.py:145: in __init__
    if isinstance(channel, grpc.Channel):
E   TypeError: isinstance() arg 2 must be a type or tuple of types
```

potiuk on (2024-11-14 14:18:40 UTC): The failure is fixed in https://github.com/apache/airflow/pull/44029

eladkal (Issue Creator) on (2024-11-14 14:35:02 UTC): Cool so no need to regenerate docs as the fix is only in a test

"
2657533421,pull_request,closed,,Remove ORM references from datamodels for assets,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


As per this comment: https://github.com/apache/airflow/pull/43874#discussion_r1841541409, the ORM term shouldnt be used for general datamodels. Removing the ORM references from previous additions.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-14 04:37:43+00:00,['amoghrajesh'],2024-11-14 10:29:37+00:00,2024-11-14 10:29:35+00:00,https://github.com/apache/airflow/pull/44010,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2657375577,pull_request,closed,,build(chart): update statsd-exporter to 0.28.0,"## Why
https://github.com/apache/airflow/actions/runs/11828396054/job/32960017155

## What
 build(chart): update statsd-exporter to 0.28.0 #44009 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-14 02:51:33+00:00,['Lee-W'],2024-11-18 07:45:23+00:00,2024-11-18 07:44:57+00:00,https://github.com/apache/airflow/pull/44009,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:helm-chart', 'Airflow Helm Chart'), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2477856149, 'issue_id': 2657375577, 'author': 'Lee-W', 'body': '> Need a newsfragment for it, otherwise LGTM.\r\n\r\nJust added! Thanks!', 'created_at': datetime.datetime(2024, 11, 15, 2, 59, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478096911, 'issue_id': 2657375577, 'author': 'Lee-W', 'body': ""> Oops, actually, it needs to go in `chart/newsfragments` instead.\r\n\r\nah got it, didn't notice there's this folder. let me fix it now"", 'created_at': datetime.datetime(2024, 11, 15, 7, 3, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478140508, 'issue_id': 2657375577, 'author': 'Lee-W', 'body': '> Why this PR targets v2-10-test branch? Helm chart is released from main branch\r\n\r\nHmmm... this is just for fixing the CI failure on `v2-10-test`', 'created_at': datetime.datetime(2024, 11, 15, 7, 35, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478154829, 'issue_id': 2657375577, 'author': 'eladkal', 'body': '> > Why this PR targets v2-10-test branch? Helm chart is released from main branch\r\n> \r\n> Hmmm... this is just for fixing the CI failure on `v2-10-test`\r\n\r\nThen why the newsfragment? I think me and Jed see this as feature not an internal fix to the CI.\r\nIs this already avaliable in main branch and this is just the ""chery pick"" to fix the CI?', 'created_at': datetime.datetime(2024, 11, 15, 7, 46, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478158762, 'issue_id': 2657375577, 'author': 'Lee-W', 'body': '> > > Why this PR targets v2-10-test branch? Helm chart is released from main branch\r\n> > \r\n> > \r\n> > Hmmm... this is just for fixing the CI failure on `v2-10-test`\r\n> \r\n> Then why the newsfragment? I think me and Jed see this as feature not an internal fix to the CI. Is this already avaliable in main branch and this is just the ""chery pick"" to fix the CI?\r\n\r\nJust notice there\'s indeed a PR for this on the main branch https://github.com/apache/airflow/pull/43393, but it was not backported', 'created_at': datetime.datetime(2024, 11, 15, 7, 49, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480453454, 'issue_id': 2657375577, 'author': 'eladkal', 'body': '> > > > Why this PR targets v2-10-test branch? Helm chart is released from main branch\r\n> > > \r\n> > > \r\n> > > Hmmm... this is just for fixing the CI failure on `v2-10-test`\r\n> > \r\n> > \r\n> > Then why the newsfragment? I think me and Jed see this as feature not an internal fix to the CI. Is this already avaliable in main branch and this is just the ""chery pick"" to fix the CI?\r\n> \r\n> Just notice there\'s indeed a PR for this on the main branch #43393, but it was not backported\r\n\r\nOk then we need this PR against v2-10-test to be only backport and new pr against main with the newsfragment', 'created_at': datetime.datetime(2024, 11, 16, 6, 47, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480461651, 'issue_id': 2657375577, 'author': 'Lee-W', 'body': '> > > > > Why this PR targets v2-10-test branch? Helm chart is released from main branch\r\n> > > > \r\n> > > > \r\n> > > > Hmmm... this is just for fixing the CI failure on `v2-10-test`\r\n> > > \r\n> > > \r\n> > > Then why the newsfragment? I think me and Jed see this as feature not an internal fix to the CI. Is this already avaliable in main branch and this is just the ""chery pick"" to fix the CI?\r\n> > \r\n> > \r\n> > Just notice there\'s indeed a PR for this on the main branch #43393, but it was not backported\r\n> \r\n> Ok then we need this PR against v2-10-test to be only backport and new pr against main with the newsfragment\r\n\r\nSounds good. Then I think I don\'t need to do anything for this one, but will need to create an new one to main (for newsfragment)', 'created_at': datetime.datetime(2024, 11, 16, 7, 21, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482116436, 'issue_id': 2657375577, 'author': 'eladkal', 'body': 'No need for newsfragment on this PR after the fix in main', 'created_at': datetime.datetime(2024, 11, 18, 7, 5, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482177022, 'issue_id': 2657375577, 'author': 'Lee-W', 'body': 'it seems to be fixed already. close this one', 'created_at': datetime.datetime(2024, 11, 18, 7, 45, 21, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-11-15 02:59:05 UTC): Just added! Thanks!

Lee-W (Issue Creator) on (2024-11-15 07:03:10 UTC): ah got it, didn't notice there's this folder. let me fix it now

Lee-W (Issue Creator) on (2024-11-15 07:35:37 UTC): Hmmm... this is just for fixing the CI failure on `v2-10-test`

eladkal on (2024-11-15 07:46:43 UTC): Then why the newsfragment? I think me and Jed see this as feature not an internal fix to the CI.
Is this already avaliable in main branch and this is just the ""chery pick"" to fix the CI?

Lee-W (Issue Creator) on (2024-11-15 07:49:37 UTC): Just notice there's indeed a PR for this on the main branch https://github.com/apache/airflow/pull/43393, but it was not backported

eladkal on (2024-11-16 06:47:40 UTC): Ok then we need this PR against v2-10-test to be only backport and new pr against main with the newsfragment

Lee-W (Issue Creator) on (2024-11-16 07:21:07 UTC): Sounds good. Then I think I don't need to do anything for this one, but will need to create an new one to main (for newsfragment)

eladkal on (2024-11-18 07:05:46 UTC): No need for newsfragment on this PR after the fix in main

Lee-W (Issue Creator) on (2024-11-18 07:45:21 UTC): it seems to be fixed already. close this one

"
2657295523,pull_request,closed,,Refactor DagRun tracing into `_trace_dagrun` helper method,"related: https://github.com/apache/airflow/issues/43789

Changes:
This commit
- extracts the tracing logic from the `update_state` method in `DagRun` to a new helper method `_trace_dagrun`.
- preserves types in some cases like: int and bool. Otel Attributes can be str, bool, int, float, Sequence[str], Sequence[bool], Sequence[int], Sequence[float]

<img width=""482"" alt=""image"" src=""https://github.com/user-attachments/assets/df2b5622-fcdf-4448-85ab-9def2e5c677e"">


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-14 01:56:11+00:00,[],2024-11-14 03:14:50+00:00,2024-11-14 03:14:48+00:00,https://github.com/apache/airflow/pull/44008,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2657268338,pull_request,closed,,Improve CI test that prepares and test python client,"The test for python client require locally installed airflow with some providers prepared from sources. We have been preparing the selected packages and installing them, but sometimes this required to add new package there.

To make it simpler, we can instead prepare and install all the packages - this will be pretty fast with `uv` and we will avoid to manually modify the CI tests every time we add some package that requires installation.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-14 01:41:24+00:00,[],2024-11-17 16:21:29+00:00,2024-11-17 16:21:29+00:00,https://github.com/apache/airflow/pull/44007,"[('area:dev-tools', '')]","[{'comment_id': 2475996871, 'issue_id': 2657268338, 'author': 'potiuk', 'body': ""Actually - I've hit the same problem that made the breeze ci image necessary - hard to install Airflow with all dependencies in consistent way in CI (uv wants to build kerberos :). I think I will actually change it to run the client  inside breeze - but I will defer it after coming back from Ireland (I am going to be far less available next week)."", 'created_at': datetime.datetime(2024, 11, 14, 10, 38, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475997375, 'issue_id': 2657268338, 'author': 'potiuk', 'body': 'converted to draft for now', 'created_at': datetime.datetime(2024, 11, 14, 10, 38, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475998805, 'issue_id': 2657268338, 'author': 'potiuk', 'body': 'I will create an issue for that maybe @gopidesupavan or others would like to take that :)', 'created_at': datetime.datetime(2024, 11, 14, 10, 39, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476025512, 'issue_id': 2657268338, 'author': 'potiuk', 'body': 'I added https://github.com/apache/airflow/issues/44020 describing what needs to be done', 'created_at': datetime.datetime(2024, 11, 14, 10, 52, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476259039, 'issue_id': 2657268338, 'author': 'gopidesupavan', 'body': '> I will create an issue for that maybe @gopidesupavan or others would like to take that :)\r\n\r\nCool , Interesting one to solve :)', 'created_at': datetime.datetime(2024, 11, 14, 12, 41, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476263969, 'issue_id': 2657268338, 'author': 'potiuk', 'body': '> > I will create an issue for that maybe @gopidesupavan or others would like to take that :)\r\n> \r\n> Cool , Interesting one to solve :)\r\n\r\nIndeed :). It touches a bit of everything :D', 'created_at': datetime.datetime(2024, 11, 14, 12, 44, 3, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-14 10:38:20 UTC): Actually - I've hit the same problem that made the breeze ci image necessary - hard to install Airflow with all dependencies in consistent way in CI (uv wants to build kerberos :). I think I will actually change it to run the client  inside breeze - but I will defer it after coming back from Ireland (I am going to be far less available next week).

potiuk (Issue Creator) on (2024-11-14 10:38:35 UTC): converted to draft for now

potiuk (Issue Creator) on (2024-11-14 10:39:16 UTC): I will create an issue for that maybe @gopidesupavan or others would like to take that :)

potiuk (Issue Creator) on (2024-11-14 10:52:20 UTC): I added https://github.com/apache/airflow/issues/44020 describing what needs to be done

gopidesupavan on (2024-11-14 12:41:45 UTC): Cool , Interesting one to solve :)

potiuk (Issue Creator) on (2024-11-14 12:44:03 UTC): Indeed :). It touches a bit of everything :D

"
2657188812,pull_request,closed,,Limit temporarily aiohttp to < 3.11.0,"Because of aio-libs/aiohttp#9866 some tests are failing. This PR can be reverted when pnuckowski/aioresponses#262 is merged and released

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-14 00:30:07+00:00,[],2024-11-14 00:57:23+00:00,2024-11-14 00:57:10+00:00,https://github.com/apache/airflow/pull/44006,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2475130327, 'issue_id': 2657188812, 'author': 'potiuk', 'body': 'Non-DB tests are passing. Merging.', 'created_at': datetime.datetime(2024, 11, 14, 0, 57, 22, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-14 00:57:22 UTC): Non-DB tests are passing. Merging.

"
2657154114,pull_request,closed,,Limit temporarily aiohttp to < 3.11.0,"Because of aio-libs/aiohttp#9866 some tests are failing. This PR can be reverted when pnuckowski/aioresponses#262 is merged and released

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 23:58:53+00:00,[],2024-11-14 00:32:31+00:00,2024-11-14 00:27:54+00:00,https://github.com/apache/airflow/pull/43998,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2475099426, 'issue_id': 2657154114, 'author': 'potiuk', 'body': 'Actually .... even better fix coming', 'created_at': datetime.datetime(2024, 11, 14, 0, 27, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475104402, 'issue_id': 2657154114, 'author': 'potiuk', 'body': 'Even better fix in https://github.com/apache/airflow/pull/44006', 'created_at': datetime.datetime(2024, 11, 14, 0, 32, 30, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-14 00:27:54 UTC): Actually .... even better fix coming

potiuk (Issue Creator) on (2024-11-14 00:32:30 UTC): Even better fix in https://github.com/apache/airflow/pull/44006

"
2657141119,pull_request,closed,,Fix parsing of development dependencies for airflow version,"The script to install development dependencies asumed development dependencies are always `>=` this might not be true in case we limit the depdencies to be < or provide other requirements for them.

This PR fixes it by using ""packaging.requirements.Requirement"" to parse the specifier, which should handle all cases nicely.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 23:48:39+00:00,[],2024-11-14 00:33:52+00:00,2024-11-14 00:33:50+00:00,https://github.com/apache/airflow/pull/43995,"[('area:dev-tools', '')]",[],
2657079564,pull_request,closed,,"Stop passing ""context"" dict in OTel traces","The context dict could be huge and contain DAG and TI object!

https://github.com/apache/airflow/blob/517132d60bac707fc7e8b513c3f80f31d4c5e9b3/airflow/models/taskinstance.py#L1118-L1169

related: https://github.com/apache/airflow/issues/43789

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-13 23:18:38+00:00,[],2024-11-14 00:18:15+00:00,2024-11-13 23:58:01+00:00,https://github.com/apache/airflow/pull/43991,[],[],
2657037882,pull_request,closed,,Separate Public Router for Auth-Free Endpoints,"Follow-up from https://github.com/apache/airflow/pull/43932
The PR splits the public_router by creating a common_router for routes that need 401/403 responses, separating them from routes without auth restrictions.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-13 22:46:22+00:00,[],2024-11-14 19:32:30+00:00,2024-11-14 15:24:50+00:00,https://github.com/apache/airflow/pull/43990,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2477250742, 'issue_id': 2657037882, 'author': 'jscheffl', 'body': 'Cool! Thanks!', 'created_at': datetime.datetime(2024, 11, 14, 19, 32, 29, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-11-14 19:32:29 UTC): Cool! Thanks!

"
2656945079,pull_request,closed,,Add DMS Serverless Operators,"
---
Adding operators, waiters, and triggers to support AWS DMS Serverless replications.
closes #39954",ellisms,2024-11-13 22:00:08+00:00,[],2025-01-08 12:21:30+00:00,2024-12-17 15:04:50+00:00,https://github.com/apache/airflow/pull/43988,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2505968905, 'issue_id': 2656945079, 'author': 'eladkal', 'body': ""The current error in the CI is a valid one:\r\n`FAILED tests/always/test_project_structure.py::TestAmazonProviderProjectStructure::test_missing_examples - Failed: Not all classes are covered with example dags. Update self.MISSING_EXAMPLES_FOR_CLASSES if you want to skip this error`\r\n\r\nYou'll need to add example dags or exclude if there is a reason"", 'created_at': datetime.datetime(2024, 11, 28, 12, 8, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533362614, 'issue_id': 2656945079, 'author': 'ellisms', 'body': 'Added the missing example.', 'created_at': datetime.datetime(2024, 12, 11, 0, 46, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2533666685, 'issue_id': 2656945079, 'author': 'eladkal', 'body': 'Test fail :(\r\n\r\n```\r\ntests/always/test_example_dags.py::test_should_be_importable[providers/tests/system/amazon/aws/example_dms_serverless.py] - AssertionError: import_errors={\'/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py\': \'Traceback (most recent call last):\\n  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed\\n  File ""/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py"", line 472, in <module>\\n    from tests.system.utils.watcher import watcher\\nModuleNotFoundError: No module named \\\'tests.system.utils\\\'\\n\'}\r\nassert 1 == 0\r\n +  where 1 = len({\'/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py\': \'Traceback (most recent call last):\\n  Fi...e>\\n    from tests.system.utils.watcher import watcher\\nModuleNotFoundError: No module named \\\'tests.system.utils\\\'\\n\'})\r\n +    where {\'/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py\': \'Traceback (most recent call last):\\n  Fi...e>\\n    from tests.system.utils.watcher import watcher\\nModuleNotFoundError: No module named \\\'tests.system.utils\\\'\\n\'} = <airflow.models.dagbag.DagBag object at 0x7f0814d88190>.import_errors\r\n\r\n```', 'created_at': datetime.datetime(2024, 12, 11, 5, 23, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535673295, 'issue_id': 2656945079, 'author': 'ellisms', 'body': 'The import error should be fixed now.', 'created_at': datetime.datetime(2024, 12, 11, 11, 38, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535838777, 'issue_id': 2656945079, 'author': 'eladkal', 'body': 'still seeing error\r\n```\r\nproviders/tests/system/amazon/aws/example_dms_serverless.py:472: error: Module\r\n""tests_common.test_utils.system_tests"" has no attribute ""watcher"" \r\n[attr-defined]\r\n        from tests_common.test_utils.system_tests import watcher\r\n        ^\r\nFound 1 error in 1 file (checked 3356 source files)\r\n```', 'created_at': datetime.datetime(2024, 12, 11, 12, 19, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549612452, 'issue_id': 2656945079, 'author': 'jscheffl', 'body': 'It seems the merge of this PR broke tests on main/canary builds:\r\nhttps://github.com/apache/airflow/actions/runs/12380031516/job/34555973915\r\n\r\nSomebody having an idea how to fix? Shall we revert?', 'created_at': datetime.datetime(2024, 12, 17, 20, 56, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549629413, 'issue_id': 2656945079, 'author': 'jscheffl', 'body': 'Okay, I thought I make a ""quick fix"" and add aiobotocore as dependency... but there is a bit of history and even as pre-commit check NOT to add this.\r\nSo loading/testing it seems need to be selective.', 'created_at': datetime.datetime(2024, 12, 17, 21, 6, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2549756515, 'issue_id': 2656945079, 'author': 'potiuk', 'body': 'Fix merged in #45013', 'created_at': datetime.datetime(2024, 12, 17, 22, 15, 49, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-28 12:08:20 UTC): The current error in the CI is a valid one:
`FAILED tests/always/test_project_structure.py::TestAmazonProviderProjectStructure::test_missing_examples - Failed: Not all classes are covered with example dags. Update self.MISSING_EXAMPLES_FOR_CLASSES if you want to skip this error`

You'll need to add example dags or exclude if there is a reason

ellisms (Issue Creator) on (2024-12-11 00:46:07 UTC): Added the missing example.

eladkal on (2024-12-11 05:23:21 UTC): Test fail :(

```
tests/always/test_example_dags.py::test_should_be_importable[providers/tests/system/amazon/aws/example_dms_serverless.py] - AssertionError: import_errors={'/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py': 'Traceback (most recent call last):\n  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed\n  File ""/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py"", line 472, in <module>\n    from tests.system.utils.watcher import watcher\nModuleNotFoundError: No module named \'tests.system.utils\'\n'}
assert 1 == 0
 +  where 1 = len({'/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py': 'Traceback (most recent call last):\n  Fi...e>\n    from tests.system.utils.watcher import watcher\nModuleNotFoundError: No module named \'tests.system.utils\'\n'})
 +    where {'/opt/airflow/providers/tests/system/amazon/aws/example_dms_serverless.py': 'Traceback (most recent call last):\n  Fi...e>\n    from tests.system.utils.watcher import watcher\nModuleNotFoundError: No module named \'tests.system.utils\'\n'} = <airflow.models.dagbag.DagBag object at 0x7f0814d88190>.import_errors

```

ellisms (Issue Creator) on (2024-12-11 11:38:28 UTC): The import error should be fixed now.

eladkal on (2024-12-11 12:19:20 UTC): still seeing error
```
providers/tests/system/amazon/aws/example_dms_serverless.py:472: error: Module
""tests_common.test_utils.system_tests"" has no attribute ""watcher"" 
[attr-defined]
        from tests_common.test_utils.system_tests import watcher
        ^
Found 1 error in 1 file (checked 3356 source files)
```

jscheffl on (2024-12-17 20:56:44 UTC): It seems the merge of this PR broke tests on main/canary builds:
https://github.com/apache/airflow/actions/runs/12380031516/job/34555973915

Somebody having an idea how to fix? Shall we revert?

jscheffl on (2024-12-17 21:06:06 UTC): Okay, I thought I make a ""quick fix"" and add aiobotocore as dependency... but there is a bit of history and even as pre-commit check NOT to add this.
So loading/testing it seems need to be selective.

potiuk on (2024-12-17 22:15:49 UTC): Fix merged in #45013

"
2656807750,pull_request,closed,,Fix DagRunInfo component,"We lost the dag run state info in https://github.com/apache/airflow/pull/43501. This PR restores it. We also missed to wrap a few dates inside of a `<Time />` component. Finally, we should delete the unused LatestRun component.


<img width=""345"" alt=""Screenshot 2024-11-13 at 4 09 01 PM"" src=""https://github.com/user-attachments/assets/d5af4a1d-0b92-4dc5-9a9b-bbac41239510"">

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-13 21:13:43+00:00,[],2024-11-13 21:55:51+00:00,2024-11-13 21:55:49+00:00,https://github.com/apache/airflow/pull/43987,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2656795908,pull_request,closed,,AWS DMS Serverless Operators,"

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Adding Operators for DMS Serverless replications. Added required triggers and waiters.
closes #39954",ellisms,2024-11-13 21:06:19+00:00,[],2025-01-31 13:57:29+00:00,2024-11-13 21:18:09+00:00,https://github.com/apache/airflow/pull/43986,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2474788918, 'issue_id': 2656795908, 'author': 'ellisms', 'body': 'Looks like something went bad in my rebase. I did not change 5000+ files. I need to look into it.', 'created_at': datetime.datetime(2024, 11, 13, 21, 8, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474789533, 'issue_id': 2656795908, 'author': 'jscheffl', 'body': 'Something is ""wrong"" with this PR :-D', 'created_at': datetime.datetime(2024, 11, 13, 21, 8, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477080671, 'issue_id': 2656795908, 'author': 'o-nikolas', 'body': 'New PR: #43988', 'created_at': datetime.datetime(2024, 11, 14, 18, 2, tzinfo=datetime.timezone.utc)}]","ellisms (Issue Creator) on (2024-11-13 21:08:15 UTC): Looks like something went bad in my rebase. I did not change 5000+ files. I need to look into it.

jscheffl on (2024-11-13 21:08:39 UTC): Something is ""wrong"" with this PR :-D

o-nikolas on (2024-11-14 18:02:00 UTC): New PR: #43988

"
2656767819,pull_request,closed,,Move trigger dag run to standard provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #43641

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

Moving trigger_dagrun operator to standard provider.

`airflow/operators/trigger_dagrun.py  >> providers/src/airflow/providers/standard/operators/trigger_dagrun.py`

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",hardeybisey,2024-11-13 20:54:11+00:00,[],2024-11-14 09:29:31+00:00,2024-11-14 09:29:16+00:00,https://github.com/apache/airflow/pull/43985,"[('area:providers', ''), ('area:serialization', ''), ('area:system-tests', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2474762936, 'issue_id': 2656767819, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 13, 20, 54, 16, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-13 20:54:16 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2656724737,pull_request,closed,,AIP 84: Migrate POST ASSET EVENT legacy API to fast API. ,"Migrating the connexion API for POST ASSETS EVENTS to fastAPI.

Depends on https://github.com/apache/airflow/pull/43881
related: https://github.com/apache/airflow/issues/43845

Swagger Specs
<img width=""1446"" alt=""image"" src=""https://github.com/user-attachments/assets/5a3d58c1-8210-4e3d-a8d5-08a117ba561f"">
<img width=""1398"" alt=""image"" src=""https://github.com/user-attachments/assets/2db9f4d8-2032-4ba7-90a9-f20817c13887"">



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-13 20:37:08+00:00,[],2024-11-15 16:46:16+00:00,2024-11-15 16:46:14+00:00,https://github.com/apache/airflow/pull/43984,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2656658551,pull_request,closed,,Limit temporarily `aiohttp` to < 3.11.0,"Because of https://github.com/aio-libs/aiohttp/issues/9866 some tests are failing. This PR can be reverted when https://github.com/pnuckowski/aioresponses/pull/262 is merged and released

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-13 20:15:38+00:00,[],2024-11-18 21:07:36+00:00,2024-11-14 00:33:20+00:00,https://github.com/apache/airflow/pull/43983,[],"[{'comment_id': 2475056534, 'issue_id': 2656658551, 'author': 'potiuk', 'body': 'This PR (when you open failing output you can see it) revealed  limitation on parsing development dependencies that should be installed for compatiblity testing.\r\n\r\nThe fix is here: https://github.com/apache/airflow/pull/43995 - but I think this limit should not be placed in devel-deps. I will take a look in a moment.', 'created_at': datetime.datetime(2024, 11, 13, 23, 50, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475066667, 'issue_id': 2656658551, 'author': 'potiuk', 'body': 'This is a better fix https://github.com/apache/airflow/pull/43998 - aiohttp is already a dependency of `adlfs` so we can add it there.', 'created_at': datetime.datetime(2024, 11, 14, 0, 0, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475104808, 'issue_id': 2656658551, 'author': 'potiuk', 'body': 'Even better fix https://github.com/apache/airflow/pull/44006', 'created_at': datetime.datetime(2024, 11, 14, 0, 32, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475105372, 'issue_id': 2656658551, 'author': 'potiuk', 'body': 'Closing -> the fix from https://github.com/apache/airflow/pull/44006 is much more ""appropriate"".', 'created_at': datetime.datetime(2024, 11, 14, 0, 33, 20, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-13 23:50:34 UTC): This PR (when you open failing output you can see it) revealed  limitation on parsing development dependencies that should be installed for compatiblity testing.

The fix is here: https://github.com/apache/airflow/pull/43995 - but I think this limit should not be placed in devel-deps. I will take a look in a moment.

potiuk on (2024-11-14 00:00:06 UTC): This is a better fix https://github.com/apache/airflow/pull/43998 - aiohttp is already a dependency of `adlfs` so we can add it there.

potiuk on (2024-11-14 00:32:47 UTC): Even better fix https://github.com/apache/airflow/pull/44006

potiuk on (2024-11-14 00:33:20 UTC): Closing -> the fix from https://github.com/apache/airflow/pull/44006 is much more ""appropriate"".

"
2656655518,pull_request,closed,,OTel: Refactor span attribute setting with `span.set_attributes`,"Replaced multiple `span.set_attribute` calls with a single `span.set_attributes`!

This is not a huge change but still improves readability somewhat.

`span.set_attribute` calls `span.set_attributes` in OTel python SDK internally:

https://github.com/open-telemetry/opentelemetry-python/blob/a1191854ca69a8111e0d7b303b2c2c49245b83f8/opentelemetry-sdk/src/opentelemetry/sdk/trace/__init__.py#L844-L856

Docs: https://opentelemetry-python.readthedocs.io/en/stable/sdk/trace.html#opentelemetry.sdk.trace.Span.set_attributes

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-13 20:13:40+00:00,[],2024-11-14 00:17:57+00:00,2024-11-13 21:19:31+00:00,https://github.com/apache/airflow/pull/43982,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:Triggerer', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2474742807, 'issue_id': 2656655518, 'author': 'kaxil', 'body': '> i approve so you can move fast but gave some comments\r\n\r\nI appreciate it, going to keep this PR limited to just the set_attributes change, will follow-up it with other things', 'created_at': datetime.datetime(2024, 11, 13, 20, 41, 57, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-13 20:41:57 UTC): I appreciate it, going to keep this PR limited to just the set_attributes change, will follow-up it with other things

"
2656644033,pull_request,closed,,Improve ability to see and clear dags list filters,"Make it easier to use filters on the dags list.

- Create a StateCircle component to render the state across the UI
- Reduce visual impact of toggle table/card and filtering by dag run state
- Add a ""Reset X Filters"" to reset everything at once
- Also added blue color scheme to the trigger button to better indicate that its an action

<img width=""1259"" alt=""Screenshot 2024-11-13 at 5 30 05 PM"" src=""https://github.com/user-attachments/assets/406b84c9-86e0-4f09-aeac-61d1fb89eb99"">
<img width=""632"" alt=""Screenshot 2024-11-13 at 5 29 56 PM"" src=""https://github.com/user-attachments/assets/5c77d5f7-3ce8-49a3-97e3-81e65632d2dc"">


---

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-13 20:06:52+00:00,[],2024-11-14 15:03:59+00:00,2024-11-14 15:03:56+00:00,https://github.com/apache/airflow/pull/43981,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2474955165, 'issue_id': 2656644033, 'author': 'bbovenzi', 'body': 'Changed my mind around some UX and colors. Screenshots are updated.', 'created_at': datetime.datetime(2024, 11, 13, 22, 30, 49, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2024-11-13 22:30:49 UTC): Changed my mind around some UX and colors. Screenshots are updated.

"
2656453452,pull_request,closed,,Migrate public endpoint Get Tasks to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/42875
related: https://github.com/apache/airflow/issues/42370

This migrates the Get Tasks API from `api_connexion` to `api_fastapi`.
",omkar-foss,2024-11-13 18:45:20+00:00,['omkar-foss'],2024-11-15 18:12:55+00:00,2024-11-15 13:13:08+00:00,https://github.com/apache/airflow/pull/43980,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2474623206, 'issue_id': 2656453452, 'author': 'omkar-foss', 'body': ""@pierrejeambrun This PR also addresses [the pending part](https://github.com/apache/airflow/pull/43718#discussion_r1835330707) from #43718 - have used `model_validator` which worked well to access the task properly, and have also moved the `_get_class_ref()` function to the `tasks` data model as it's not very reusable. Cheers."", 'created_at': datetime.datetime(2024, 11, 13, 19, 51, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476768379, 'issue_id': 2656453452, 'author': 'omkar-foss', 'body': '@pierrejeambrun PR synced with `main` and all conversations resolved. Thank you! ✅', 'created_at': datetime.datetime(2024, 11, 14, 15, 51, 52, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-13 19:51:07 UTC): @pierrejeambrun This PR also addresses [the pending part](https://github.com/apache/airflow/pull/43718#discussion_r1835330707) from #43718 - have used `model_validator` which worked well to access the task properly, and have also moved the `_get_class_ref()` function to the `tasks` data model as it's not very reusable. Cheers.

omkar-foss (Issue Creator) on (2024-11-14 15:51:52 UTC): @pierrejeambrun PR synced with `main` and all conversations resolved. Thank you! ✅

"
2656446202,pull_request,closed,,Split tests to core/providers/task-sdk/integration/system,"The tests execution was traditionally using single ""breeze testing tests"" command and you could select which test to run via TEST_TYPE.

However the recent move of providers and adding task_sdk necessitates splitting the tests commands into separate commands for core, providers, task_sdk, helm, integration and system.

This is done via introducing ""TEST_GROUP"" - which determines which group of tests is being executed, and dedicated testing command for each of the groups - with ""db"" and ""non-db"" variants where applicable.

Cleanup and small refactoring has been done to make it easier to reason about parameters passed down from the command line to docker and in-container pytest command.

Related: #42632

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 18:43:57+00:00,[],2025-01-11 19:41:43+00:00,2024-11-15 08:57:32+00:00,https://github.com/apache/airflow/pull/43979,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2476109433, 'issue_id': 2656446202, 'author': 'potiuk', 'body': 'OK. I moved it here from https://github.com/apache/airflow/pull/43965 .\r\n\r\nThat one should be ready for review. I got it green, all the tests are nicely split between core and providers. I will be adding a little more diagnostics (Right now it is not obvious if the successful tests are doing what they are supposed to do) and running it for all versions of Python etc. to check that everythong is as expected + I will add runnig system tests - but other than that, I think it is in the shape that is pretty much ready to merge (and for sure ready to review).\r\n\r\nLeter we can run a number optimizations, but the way it is and after I check it for all typos and run in multiple versions, we should be ready to go. I am quite away next week (in Ireland) - and will be less available again in the next week, but I am confident it\'s pretty stable (but will be able to fix things when on/off and with @gopidesupavan @romsharon98 @shahar1 @amoghrajesh @tirkarthi  @ashb @kaxil @pierrejeambrun @vincbeck @o-nikolas and others who contributed recently, I think this way of running tests  should be easier to reason about and fix.\r\n\r\nFree screenshots to show the current state:\r\n\r\nThe ""core"" and ""providers"" tests now run in completely separate now - following the \'Stage 1` of https://github.com/apache/airflow/issues/42632#issuecomment-2449671014: \r\n\r\n![image](https://github.com/user-attachments/assets/2c08b221-4a81-46a8-ae0b-06d390392d10)\r\n\r\nList of tests commands:\r\n\r\n![image](https://github.com/user-attachments/assets/523e5e74-3106-42b1-bd88-427e765d9280)\r\n\r\nOne thing I am not sure here is naming. Should it be:\r\n\r\n* `integration-providers-tests`\r\n\r\nor\r\n\r\n* `providers-integration-tests`\r\n\r\nBoth have it\'s rationale, it\'s mostly about whether we want to group them by ""type"" or ""what sub-system they are working on"". Would love to have other\'s opinion on that.\r\n\r\nAny and all comments are welcome! Yes. It\'s huge, but a lot of it is auto-generated and you can just mark it as ""read"" and it will go away.', 'created_at': datetime.datetime(2024, 11, 14, 11, 27, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476377330, 'issue_id': 2656446202, 'author': 'ashb', 'body': ""Just so I understand the plan, this splits out the running of tests, but doesn't change to code location which will be a future PR?"", 'created_at': datetime.datetime(2024, 11, 14, 13, 36, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476382031, 'issue_id': 2656446202, 'author': 'ashb', 'body': ""Interface question should the db/non-db be a flag that operates like a filter, so something like `breeze testing core-tests --non-db` etc?\r\n\r\nOf particular note, I _imagine_ that soon (as part of TaskSDK work) all the db unit tests for the providers will go away/become non-db tests. I don't know if that changes your thinking at all"", 'created_at': datetime.datetime(2024, 11, 14, 13, 38, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476386657, 'issue_id': 2656446202, 'author': 'ashb', 'body': ""` +6,413 / −3,614 ` 😱 \r\n\r\nOh, this is mostly in the SVG images isn't it"", 'created_at': datetime.datetime(2024, 11, 14, 13, 41, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476900960, 'issue_id': 2656446202, 'author': 'vincbeck', 'body': ""> Interface question should the db/non-db be a flag that operates like a filter, so something like `breeze testing core-tests --non-db` etc?\r\n> \r\n> Of particular note, I _imagine_ that soon (as part of TaskSDK work) all the db unit tests for the providers will go away/become non-db tests. I don't know if that changes your thinking at all\r\n\r\nI agree, a flag to filter db/non-db tests would make more sense to me instead of having separate commands"", 'created_at': datetime.datetime(2024, 11, 14, 16, 38, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477112511, 'issue_id': 2656446202, 'author': 'potiuk', 'body': ""> Oh, this is mostly in the SVG images isn't it\r\n\r\nYeah. It's definitely less code than it was :)"", 'created_at': datetime.datetime(2024, 11, 14, 18, 17, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477121441, 'issue_id': 2656446202, 'author': 'potiuk', 'body': '@ashb \r\n> Interface question should the db/non-db be a flag that operates like a filter, so something like breeze testing core-tests --non-db etc?\r\n\r\n@vincbeck \r\n> \r\n> I agree, a flag to filter db/non-db tests would make more sense to me instead of having separate commands\r\n\r\nOK. That\'s the 3rd similar comment after @o-nikolas - and I explained the reasons in: https://github.com/apache/airflow/pull/43965#issuecomment-2474956968 \r\n\r\nSo if everyone around you seems to be mad, maybe it\'s you :) \r\n\r\nIt\'s really additional level of abstraction for the base command that makes it easier to run and has some defaults set differently, but it is all possible to be done with the base command - it\'s just a matter to pass a few more parameters.  And it was meant as ""easier to reproduce locally"" - in CI I can easily make those commands more complex.\r\n\r\nLet me try to remove it and see how it will be then, that\'s not a big change and will decrease amount of code.', 'created_at': datetime.datetime(2024, 11, 14, 18, 22, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477125267, 'issue_id': 2656446202, 'author': 'potiuk', 'body': ""> Of particular note, I imagine that soon (as part of TaskSDK work) all the db unit tests for the providers will go away/become non-db tests. I don't know if that changes your thinking at all\r\n\r\nThat's planned  in  stage 3 in https://github.com/apache/airflow/issues/42632#issuecomment-2449671014 - but it's pretty independent - there we would simply remove the db method and rename it, but yeah, I will try to remove `db/non-db` commands now."", 'created_at': datetime.datetime(2024, 11, 14, 18, 24, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477135993, 'issue_id': 2656446202, 'author': 'potiuk', 'body': '> \r\nJust so I understand the plan, this splits out the running of tests, but doesn\'t change to code location which will be a future PR?\r\n\r\nAbsolutely. One thing at  a time. We want to merge it, let it run for 2-3 weeks and fix all teething problems before we go to next stages. Same as with the past ""providers"" move. We will find things a week or two from now after we merge this one, I am quite sure of that. And we have to do it carefully while not breaking too much the workflows of people who work noow with a speed of litght -  in parallel.', 'created_at': datetime.datetime(2024, 11, 14, 18, 29, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477775329, 'issue_id': 2656446202, 'author': 'potiuk', 'body': 'The whole  set of test commands is simplified now:\r\n\r\n<img width=""971"" alt=""Screenshot 2024-11-15 at 02 21 55"" src=""https://github.com/user-attachments/assets/1c865a38-08bf-4258-aed6-66d7a91eefed"">\r\n\r\nI also updated docs and examples and contributing docs.\r\n\r\nI also reviewed and updated docs and fixed and simplified how sytem tests are run.\r\n\r\nThere is no more `--system SYSTEM` or `pytest.mark.system(""SYSTEM"")` but simply `--system`  and `pytest.mark.system`. Also the example dags in ""tests/system"" and ""providers/tests/system"" are automatically marked with the ""system"" marker.\r\n\r\nSo tests shoudl be run:\r\n\r\nIn venv/inside breeze:\r\n\r\n```bash\r\npytest --system providers/tests/system/google/cloud/bigquery/example_bigquery_queries.py\r\n```\r\n\r\nvia Breeze - there is one command only:\r\n\r\n```bash\r\nbreeze testing system-tests  providers/tests/system/google/cloud/bigquery/example_bigquery_queries.py\r\n```\r\n\r\ncc: @ahidalgob @kosteev @pankajkoti @fdemiane @sc250072 \r\n\r\nnce we merge it you will have to update the dashboards', 'created_at': datetime.datetime(2024, 11, 15, 1, 36, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478270973, 'issue_id': 2656446202, 'author': 'potiuk', 'body': 'And merged!', 'created_at': datetime.datetime(2024, 11, 15, 8, 57, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478684388, 'issue_id': 2656446202, 'author': 'kosteev', 'body': 'Thanks for heads up, Jarek.\r\nWe will update System Tests Dashboard for google provider package with regard to these changes.', 'created_at': datetime.datetime(2024, 11, 15, 12, 13, 45, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-14 11:27:44 UTC): OK. I moved it here from https://github.com/apache/airflow/pull/43965 .

That one should be ready for review. I got it green, all the tests are nicely split between core and providers. I will be adding a little more diagnostics (Right now it is not obvious if the successful tests are doing what they are supposed to do) and running it for all versions of Python etc. to check that everythong is as expected + I will add runnig system tests - but other than that, I think it is in the shape that is pretty much ready to merge (and for sure ready to review).

Leter we can run a number optimizations, but the way it is and after I check it for all typos and run in multiple versions, we should be ready to go. I am quite away next week (in Ireland) - and will be less available again in the next week, but I am confident it's pretty stable (but will be able to fix things when on/off and with @gopidesupavan @romsharon98 @shahar1 @amoghrajesh @tirkarthi  @ashb @kaxil @pierrejeambrun @vincbeck @o-nikolas and others who contributed recently, I think this way of running tests  should be easier to reason about and fix.

Free screenshots to show the current state:

The ""core"" and ""providers"" tests now run in completely separate now - following the 'Stage 1` of https://github.com/apache/airflow/issues/42632#issuecomment-2449671014: 

![image](https://github.com/user-attachments/assets/2c08b221-4a81-46a8-ae0b-06d390392d10)

List of tests commands:

![image](https://github.com/user-attachments/assets/523e5e74-3106-42b1-bd88-427e765d9280)

One thing I am not sure here is naming. Should it be:

* `integration-providers-tests`

or

* `providers-integration-tests`

Both have it's rationale, it's mostly about whether we want to group them by ""type"" or ""what sub-system they are working on"". Would love to have other's opinion on that.

Any and all comments are welcome! Yes. It's huge, but a lot of it is auto-generated and you can just mark it as ""read"" and it will go away.

ashb on (2024-11-14 13:36:52 UTC): Just so I understand the plan, this splits out the running of tests, but doesn't change to code location which will be a future PR?

ashb on (2024-11-14 13:38:59 UTC): Interface question should the db/non-db be a flag that operates like a filter, so something like `breeze testing core-tests --non-db` etc?

Of particular note, I _imagine_ that soon (as part of TaskSDK work) all the db unit tests for the providers will go away/become non-db tests. I don't know if that changes your thinking at all

ashb on (2024-11-14 13:41:05 UTC): ` +6,413 / −3,614 ` 😱 

Oh, this is mostly in the SVG images isn't it

vincbeck on (2024-11-14 16:38:16 UTC): I agree, a flag to filter db/non-db tests would make more sense to me instead of having separate commands

potiuk (Issue Creator) on (2024-11-14 18:17:06 UTC): Yeah. It's definitely less code than it was :)

potiuk (Issue Creator) on (2024-11-14 18:22:05 UTC): @ashb 

@vincbeck 

OK. That's the 3rd similar comment after @o-nikolas - and I explained the reasons in: https://github.com/apache/airflow/pull/43965#issuecomment-2474956968 

So if everyone around you seems to be mad, maybe it's you :) 

It's really additional level of abstraction for the base command that makes it easier to run and has some defaults set differently, but it is all possible to be done with the base command - it's just a matter to pass a few more parameters.  And it was meant as ""easier to reproduce locally"" - in CI I can easily make those commands more complex.

Let me try to remove it and see how it will be then, that's not a big change and will decrease amount of code.

potiuk (Issue Creator) on (2024-11-14 18:24:17 UTC): That's planned  in  stage 3 in https://github.com/apache/airflow/issues/42632#issuecomment-2449671014 - but it's pretty independent - there we would simply remove the db method and rename it, but yeah, I will try to remove `db/non-db` commands now.

potiuk (Issue Creator) on (2024-11-14 18:29:39 UTC): Just so I understand the plan, this splits out the running of tests, but doesn't change to code location which will be a future PR?

Absolutely. One thing at  a time. We want to merge it, let it run for 2-3 weeks and fix all teething problems before we go to next stages. Same as with the past ""providers"" move. We will find things a week or two from now after we merge this one, I am quite sure of that. And we have to do it carefully while not breaking too much the workflows of people who work noow with a speed of litght -  in parallel.

potiuk (Issue Creator) on (2024-11-15 01:36:40 UTC): The whole  set of test commands is simplified now:

<img width=""971"" alt=""Screenshot 2024-11-15 at 02 21 55"" src=""https://github.com/user-attachments/assets/1c865a38-08bf-4258-aed6-66d7a91eefed"">

I also updated docs and examples and contributing docs.

I also reviewed and updated docs and fixed and simplified how sytem tests are run.

There is no more `--system SYSTEM` or `pytest.mark.system(""SYSTEM"")` but simply `--system`  and `pytest.mark.system`. Also the example dags in ""tests/system"" and ""providers/tests/system"" are automatically marked with the ""system"" marker.

So tests shoudl be run:

In venv/inside breeze:

```bash
pytest --system providers/tests/system/google/cloud/bigquery/example_bigquery_queries.py
```

via Breeze - there is one command only:

```bash
breeze testing system-tests  providers/tests/system/google/cloud/bigquery/example_bigquery_queries.py
```

cc: @ahidalgob @kosteev @pankajkoti @fdemiane @sc250072 

nce we merge it you will have to update the dashboards

potiuk (Issue Creator) on (2024-11-15 08:57:41 UTC): And merged!

kosteev on (2024-11-15 12:13:45 UTC): Thanks for heads up, Jarek.
We will update System Tests Dashboard for google provider package with regard to these changes.

"
2656437453,pull_request,closed,,Fix: ensure `bool(check_query_exists)` returns `True` or `False`,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #43977

<!-- Please keep an empty line above the dashes. -->
---

It is possible for `bool(check_query_exists)` to return `None`. This can break Xcom Jinja templates that retrieve null values from the airflow database using a `LazySelectSequence`",johncmerfeld,2024-11-13 18:42:52+00:00,[],2024-12-03 06:47:39+00:00,2024-12-03 06:46:50+00:00,https://github.com/apache/airflow/pull/43978,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2474452136, 'issue_id': 2656437453, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 13, 18, 42, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475018122, 'issue_id': 2656437453, 'author': 'potiuk', 'body': 'Could you please add a unit test covering this case?', 'created_at': datetime.datetime(2024, 11, 13, 23, 16, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477594175, 'issue_id': 2656437453, 'author': 'johncmerfeld', 'body': ""> Could you please add a unit test covering this case?\r\n\r\nI'd love to; I'm just a little unsure where it would go. I couldn't find any module that tests the behavior of `LazySelectSequence` directly. I'd appreciate any advice you have on this!"", 'created_at': datetime.datetime(2024, 11, 14, 23, 12, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480325171, 'issue_id': 2656437453, 'author': 'potiuk', 'body': ""> > Could you please add a unit test covering this case?\r\n> \r\n> I'd love to; I'm just a little unsure where it would go. I couldn't find any module that tests the behavior of `LazySelectSequence` directly. I'd appreciate any advice you have on this!\r\n\r\nMaybe add one then - following the same structure in `tests` as you have for the source"", 'created_at': datetime.datetime(2024, 11, 16, 2, 17, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484340542, 'issue_id': 2656437453, 'author': 'johncmerfeld', 'body': '> Maybe add one then - following the same structure in `tests` as you have for the source\r\n\r\nSure. Since it\'s an abstract class, I\'m thinking I\'ll have to create a mock implementation for the test. I\'ll also need to mock `check_query_exists` so that it returns `None` .Something like:\r\n```python\r\nclass LazySelectSequenceInstance(LazySelectSequence[Any]):\r\n    ... # implement required methods\r\n\r\n@mock.patch(""check_query_exists"", lambda x, y: None):\r\ndef test_lazy_select_sequence():\r\n    lss = LazySelectSequenceInstance(...)\r\n    assert bool(lss) == False\r\n```\r\n\r\n\r\nDoes this make sense?', 'created_at': datetime.datetime(2024, 11, 18, 23, 14, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484629746, 'issue_id': 2656437453, 'author': 'Lee-W', 'body': '> > Maybe add one then - following the same structure in `tests` as you have for the source\r\n> \r\n> Sure. Since it\'s an abstract class, I\'m thinking I\'ll have to create a mock implementation for the test. I\'ll also need to mock `check_query_exists` so that it returns `None` .Something like:\r\n> \r\n> ```python\r\n> class LazySelectSequenceInstance(LazySelectSequence[Any]):\r\n>     ... # implement required methods\r\n> \r\n> @mock.patch(""check_query_exists"", lambda x, y: None):\r\n> def test_lazy_select_sequence():\r\n>     lss = LazySelectSequenceInstance(...)\r\n>     assert bool(lss) == False\r\n> ```\r\n> \r\n> Does this make sense?\r\n\r\nSounds reasonable. We already have a mock class here https://github.com/apache/airflow/blob/f5abe506fc6ba22a8b8efb0d4784dd85eaa90af4/tests/serialization/test_serialized_objects.py#L170\r\nprobably we could do something similar here as well?', 'created_at': datetime.datetime(2024, 11, 19, 3, 26, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486019501, 'issue_id': 2656437453, 'author': 'johncmerfeld', 'body': ""@Lee-W I'm struggling to get unit tests running locally with virtualenv but all the CI checks appear to be passing. \r\n\r\nEDIT: Ahh okay I see the tests don't actually run until there is an approval. Alas I'm unable to run the tests when building locally on MacOS or ubuntu. Not sure I have the hardware needed to run the docker version of the tests"", 'created_at': datetime.datetime(2024, 11, 19, 15, 23, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2487222599, 'issue_id': 2656437453, 'author': 'Lee-W', 'body': ""> @Lee-W I'm struggling to get unit tests running locally with virtualenv but all the CI checks appear to be passing.\r\n> \r\n> EDIT: Ahh okay I see the tests don't actually run until there is an approval. Alas I'm unable to run the tests when building locally on MacOS or ubuntu. Not sure I have the hardware needed to run the docker version of the tests\r\n\r\nfor local test https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst is the thing you might want to try 🙂"", 'created_at': datetime.datetime(2024, 11, 20, 2, 39, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513691328, 'issue_id': 2656437453, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 12, 3, 6, 46, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513692304, 'issue_id': 2656437453, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12134388167\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/8d6bde8246cd5933829b2e0aa3de7d41a7ea1957""><img src=\'https://img.shields.io/badge/Commit-8d6bde8-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 8d6bde8 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2024, 12, 3, 6, 47, 38, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-13 18:42:56 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-11-13 23:16:38 UTC): Could you please add a unit test covering this case?

johncmerfeld (Issue Creator) on (2024-11-14 23:12:13 UTC): I'd love to; I'm just a little unsure where it would go. I couldn't find any module that tests the behavior of `LazySelectSequence` directly. I'd appreciate any advice you have on this!

potiuk on (2024-11-16 02:17:50 UTC): Maybe add one then - following the same structure in `tests` as you have for the source

johncmerfeld (Issue Creator) on (2024-11-18 23:14:06 UTC): Sure. Since it's an abstract class, I'm thinking I'll have to create a mock implementation for the test. I'll also need to mock `check_query_exists` so that it returns `None` .Something like:
```python
class LazySelectSequenceInstance(LazySelectSequence[Any]):
    ... # implement required methods

@mock.patch(""check_query_exists"", lambda x, y: None):
def test_lazy_select_sequence():
    lss = LazySelectSequenceInstance(...)
    assert bool(lss) == False
```


Does this make sense?

Lee-W on (2024-11-19 03:26:13 UTC): Sounds reasonable. We already have a mock class here https://github.com/apache/airflow/blob/f5abe506fc6ba22a8b8efb0d4784dd85eaa90af4/tests/serialization/test_serialized_objects.py#L170
probably we could do something similar here as well?

johncmerfeld (Issue Creator) on (2024-11-19 15:23:26 UTC): @Lee-W I'm struggling to get unit tests running locally with virtualenv but all the CI checks appear to be passing. 

EDIT: Ahh okay I see the tests don't actually run until there is an approval. Alas I'm unable to run the tests when building locally on MacOS or ubuntu. Not sure I have the hardware needed to run the docker version of the tests

Lee-W on (2024-11-20 02:39:54 UTC): for local test https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst is the thing you might want to try 🙂

boring-cyborg[bot] on (2024-12-03 06:46:53 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

github-actions[bot] on (2024-12-03 06:47:38 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12134388167'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/8d6bde8246cd5933829b2e0aa3de7d41a7ea1957""><img src='https://img.shields.io/badge/Commit-8d6bde8-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 8d6bde8 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2656350219,pull_request,closed,,Add queued_at to fastapi dag run response,"Our dag run datamodel was missing `queued_at`

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-13 18:05:00+00:00,[],2024-11-13 21:16:06+00:00,2024-11-13 21:16:04+00:00,https://github.com/apache/airflow/pull/43976,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2656344949,pull_request,closed,,Standardize timer metrics to milliseconds and remove config,"- Removes the `timer_unit_consistency` configuration option, standardizing all timer and timing metrics to milliseconds by default.
- Updates metric loggers (e.g., Datadog, OpenTelemetry) to ensure uniform milliseconds-based reporting.
- Cleans up related warnings!

This is a follow-up of https://github.com/apache/airflow/pull/43966 for main & Airflow 3

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-13 18:02:06+00:00,[],2024-11-14 14:33:03+00:00,2024-11-14 14:33:01+00:00,https://github.com/apache/airflow/pull/43975,"[('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]",[],
2656321717,pull_request,closed,,Remove references to logical date in new UI,"We should avoid using logical date for display in the UI.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-13 17:52:06+00:00,[],2024-11-13 18:18:19+00:00,2024-11-13 18:18:17+00:00,https://github.com/apache/airflow/pull/43974,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2656212733,pull_request,closed,,Core operator modules deprecations,"Using pep 562 way to redirect modules.

There are issues when using metapath finder to redirect modules.

https://github.com/apache/airflow/pull/43610

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-13 17:16:59+00:00,[],2024-11-13 18:47:01+00:00,2024-11-13 18:45:31+00:00,https://github.com/apache/airflow/pull/43972,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2474260948, 'issue_id': 2656212733, 'author': 'gopidesupavan', 'body': 'Find this approach already using in airflow, so followed similar one here. is that fine?', 'created_at': datetime.datetime(2024, 11, 13, 17, 18, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474460495, 'issue_id': 2656212733, 'author': 'potiuk', 'body': 'It looks it works nicely :)', 'created_at': datetime.datetime(2024, 11, 13, 18, 47, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-13 17:18:35 UTC): Find this approach already using in airflow, so followed similar one here. is that fine?

potiuk on (2024-11-13 18:47:00 UTC): It looks it works nicely :)

"
2655782244,pull_request,closed,,Refactor & rename `metrics_consistency_on` conf to `timer_unit_consistency`,"Follow-up of https://github.com/apache/airflow/pull/39908
Changes:
- Replaces the `metrics_consistency_on` config with `timer_unit_consistency` for better clarity!
- Improves the newsfragment entry & deprecation warning
- Changes the default to be `False` so folks aren't caught by surprise.

We should backport this to 2.11 and remove this setting from Airflow main

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-13 14:53:19+00:00,[],2024-11-13 17:53:05+00:00,2024-11-13 16:28:37+00:00,https://github.com/apache/airflow/pull/43966,[],"[{'comment_id': 2474114611, 'issue_id': 2655782244, 'author': 'kaxil', 'body': 'The failed checks are unrelated and due to ""docker timeouts""', 'created_at': datetime.datetime(2024, 11, 13, 16, 28, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474271634, 'issue_id': 2655782244, 'author': 'ferruzzi', 'body': 'I like the name change, but the default being ""on"" was discussed in the PR where it was added](https://github.com/apache/airflow/pull/39908), why are we changing it now?  This is a ""breaking change"" in that it requires adjusting StatsD dashboards, but it is being applied in 3.0 which is the time to do such changes, right?  The last I heard in discussions was that StatsD was being moved to second-class and OTel Metrics were supposed to be treated as the standard starting in 3.0 \r\n\r\nPlease read through the conversation on the other PR and reconsider this change.', 'created_at': datetime.datetime(2024, 11, 13, 17, 23, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474314602, 'issue_id': 2655782244, 'author': 'kaxil', 'body': '> I like the name change, but the default being ""on"" was discussed in the PR where it was added](#39908), why are we changing it now? This is a ""breaking change"" in that it requires adjusting StatsD dashboards, but it is being applied in 3.0 which is the time to do such changes, right? The last I heard in discussions was that StatsD was being moved to second-class and OTel Metrics were supposed to be treated as the standard starting in 3.0\r\n> \r\n> Please read through the conversation on the other PR and reconsider this change.\r\n\r\nA few things:\r\n- The version-added in this one was still `version_added: 2.10.0`\r\n- Airflow 3 will already remove this, check PR description where it says: ""We should backport this to 2.11 and remove this setting from Airflow main"" including the newsfragment. The idea is to keep it ""off"" for 2.11 so users get advanced warning and they can migrate early if they want without breaking and of their current tools. The main behaviour still says the same once we remove it, there is also a TODO I had added in this PR, please let me know if that isn\'t what you wanted', 'created_at': datetime.datetime(2024, 11, 13, 17, 41, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474330576, 'issue_id': 2655782244, 'author': 'kaxil', 'body': 'The only thing different is instead of getting it in 3.0 with default ""on"" and breaking compact and removing it in 3.1 -- here we make it consistent that 3.0 will break it -- and we warn users in advance about this in 2.11 -- our bridge release.\r\n\r\nIt will make it consistent with how we are breaking other things.', 'created_at': datetime.datetime(2024, 11, 13, 17, 48, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474339250, 'issue_id': 2655782244, 'author': 'ferruzzi', 'body': 'Thank you.', 'created_at': datetime.datetime(2024, 11, 13, 17, 53, 4, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-13 16:28:26 UTC): The failed checks are unrelated and due to ""docker timeouts""

ferruzzi on (2024-11-13 17:23:19 UTC): I like the name change, but the default being ""on"" was discussed in the PR where it was added](https://github.com/apache/airflow/pull/39908), why are we changing it now?  This is a ""breaking change"" in that it requires adjusting StatsD dashboards, but it is being applied in 3.0 which is the time to do such changes, right?  The last I heard in discussions was that StatsD was being moved to second-class and OTel Metrics were supposed to be treated as the standard starting in 3.0 

Please read through the conversation on the other PR and reconsider this change.

kaxil (Issue Creator) on (2024-11-13 17:41:41 UTC): A few things:
- The version-added in this one was still `version_added: 2.10.0`
- Airflow 3 will already remove this, check PR description where it says: ""We should backport this to 2.11 and remove this setting from Airflow main"" including the newsfragment. The idea is to keep it ""off"" for 2.11 so users get advanced warning and they can migrate early if they want without breaking and of their current tools. The main behaviour still says the same once we remove it, there is also a TODO I had added in this PR, please let me know if that isn't what you wanted

kaxil (Issue Creator) on (2024-11-13 17:48:58 UTC): The only thing different is instead of getting it in 3.0 with default ""on"" and breaking compact and removing it in 3.1 -- here we make it consistent that 3.0 will break it -- and we warn users in advance about this in 2.11 -- our bridge release.

It will make it consistent with how we are breaking other things.

ferruzzi on (2024-11-13 17:53:04 UTC): Thank you.

"
2655628361,pull_request,closed,,[OLD VERSION DO NOT MERGE] Split tests to core/providers/task-sdk/integration/system,"The tests execution was traditionally using single ""breeze testing tests"" command and you could select which test to run via TEST_TYPE.

However the recent move of providers and adding task_sdk necessitates splitting the tests commands into separate commands for core, providers, task_sdk, helm, integration and system.

This is done via introducing ""TEST_GROUP"" - which determines which group of tests is being executed, and dedicated testing command for each of the groups - with ""db"" and ""non-db"" variants where applicable.

Cleanup and small refactoring has been done to make it easier to reason about parameters passed down from the command line to docker and in-container pytest command.

Related: #42632

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 14:04:21+00:00,[],2024-11-14 11:12:32+00:00,2024-11-14 11:12:31+00:00,https://github.com/apache/airflow/pull/43965,"[('area:dev-tools', '')]","[{'comment_id': 2473784549, 'issue_id': 2655628361, 'author': 'potiuk', 'body': 'Also cc: @ahidalgob @kosteev @pankajkoti @fdemiane @sc250072  except the reviewers that I pinged.\r\n\r\nThis is something I worked on for last few days as first stage of #42632 - it will be quite big eventually and it is still work in progress (I am still working on fixing all the tests in breeze selective checks and need to apply changes to github workflows to run the tests but wanted to give you a heads up of what I am proposing as a change.\r\n\r\nSo do not (yet) comment on subtle details - that will come, but I\'d love more to get a heads-up on the whole concept that I am planning to implement for our tests, some simplifications it will bring and impact on the system tests execution (because that is something not yet in our CI and something that should be applied as a change when you will run system tests of Amazon, Google, Astronomer and Teradata people.\r\n\r\nFew general things:\r\n\r\n1) The set of testing commands we will be able to use is this:\r\n\r\n![image](https://github.com/user-attachments/assets/5bf802c2-cf26-4dd2-ba60-5797cc4e3168)\r\n\r\nThis means that we can separate out providers/task_sdk, core tests as completely different jobs in CI (also it will make it easier to run locally.\r\n\r\n2) I introduced the concept of ""Group Of Tests"" - previously the test types (`All/Core/Other/...`)  in the core were mixed with `Helm` or `System` test type and it was very confusing. Now we have test group (\'Core, Providers, Integration-Core, Integration-Providers, System-Core, System-Providers, Helm) - and each group has it\'s own ""test types"" defined (so ""Other/Always etc. "" are valid for ""Core Test Group"", but not valid for ""Providers Test Group"" - also you cannot specify ""Providers*"" test type for anything else than one of Providers test group.\r\n\r\n3) The ""options"" for each of the test commands are now much more consistent and definition of groups of those options  is now much more composable and logical. Example ""providers-tests"" set of options that are grouped accorting to test type (db/non-db, providers/core etc). For example DB operations are available for the ""general"" and ""db"" test scopes and not available for the ""non-db"" scope. \r\n\r\n![image](https://github.com/user-attachments/assets/d25fad22-a1a1-4ac2-a01f-04167a8ab3a2)\r\n\r\n4) I am still working on cleaning up and restructuring the code a bit - but generally code for different test groups to produce the right pytest command will be separate ""per group"" when I finish.\r\n\r\n5) the overall idea for the change is to be able to keep the same ""selective check"" optimizations that allow to run only subset of changes for each change and to allo to run tests in parallel on bigger machines (once we have ARC running cc: @hussein-awala ).\r\n\r\n6) Running system tests after this is merged should look this way:\r\n\r\n```\r\nbreeze testing system-providers-tests ./providers/tests/system/amazon/aws/tests/test_aws_auth_manager.py\r\n```\r\n\r\n(plus the usual parameters - env vars etc. configured).\r\n\r\n\r\nLet me know what you think - high level - I will work on fixing the tests and adding missing changes and updating docs accordingly in the meantime.', 'created_at': datetime.datetime(2024, 11, 13, 14, 30, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473787860, 'issue_id': 2655628361, 'author': 'potiuk', 'body': ""And yes - it's huge - I know, but I have not figured out how to split it."", 'created_at': datetime.datetime(2024, 11, 13, 14, 31, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473928470, 'issue_id': 2655628361, 'author': 'potiuk', 'body': '!!!!!!!!!!  Please, Please, Pretty please - committers do not approve the workflow. This is an example for Github Ticket I opened to show that I need to approve my own workflows now. !!!!!!!\r\n:scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream:', 'created_at': datetime.datetime(2024, 11, 13, 15, 21, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473996705, 'issue_id': 2655628361, 'author': 'vincbeck', 'body': ""I have not looked at the code but only at the description. I like the direction it is taking, the notion of test group makes sense. Having more granular test commands makes sense and will reduce the number of options we have today for the `breeze testing tests` command. As mentioned in the description, some of these options do not apply for certain tests and managing all the different combinations of these options is cumbersome. So I guess we'll gain a lot of simplification there"", 'created_at': datetime.datetime(2024, 11, 13, 15, 45, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474326305, 'issue_id': 2655628361, 'author': 'o-nikolas', 'body': 'Looks good so far!\r\nDo we need to make the db/non-db part of the command (e.g. `core-tests`, `core-db-tests`, `core-non-db-tests`)? It feels like we should have just one group command and then an option to toggle db/non-db/both.\r\n\r\nOther than that I like the changes!', 'created_at': datetime.datetime(2024, 11, 13, 17, 47, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474956968, 'issue_id': 2655628361, 'author': 'potiuk', 'body': '> Do we need to make the db/non-db part of the command (e.g. core-tests, core-db-tests, core-non-db-tests)? It feels like we should have just one group command and then an option to toggle db/non-db/both.\r\n\r\nIt makes it quite a bit easier to handle. DB paralel tests are run using multi-processing and running parallel docker-composes. Where Non-DB parallel tests are run using xdist. This makes the two commands pretty distinct - they not only behave diferently but also they have various other parameters applicable on in one of those cases (mostly the DB).\r\n\r\nThose are the options that only make senses for DB tests:\r\n\r\n* `--db-reset`\r\n* `--backend`\r\n* `--no-db-cleanup`\r\n* `--postgres-version`\r\n* `--mysql-version`\r\n\r\nThanks to that teh `non-db-tests` have way smaller set of parameter than `db-tests`.\r\n\r\nTechnically we could pass all the necessary parametters for non-db option in the ""regular"" (that handles both db and non-db) - parallelism, backend=none and few others, But then that makes `non-db` commands way simpler when we select which command to use based on parameters passed - for example:\r\n\r\n```\r\n    if [[ ""${TEST_SCOPE}"" == ""DB"" ]]; then\r\n        set -x\r\n        breeze testing core-db-tests\r\n        set +x\r\n    elif [[ ""${TEST_SCOPE}"" == ""Non-DB"" ]]; then\r\n        set -x\r\n        breeze testing core-non-db-tests\r\n        set +x\r\n```\r\n\r\nI experimented with it before, and that one produced the nicest and simplest set of commands to execute without specifying too many parameters.', 'created_at': datetime.datetime(2024, 11, 13, 22, 32, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476068231, 'issue_id': 2655628361, 'author': 'potiuk', 'body': 'I moved the change to https://github.com/apache/airflow/pull/43979.  Closing this one - seems workflows have been run eventualy BTW', 'created_at': datetime.datetime(2024, 11, 14, 11, 12, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-13 14:30:04 UTC): Also cc: @ahidalgob @kosteev @pankajkoti @fdemiane @sc250072  except the reviewers that I pinged.

This is something I worked on for last few days as first stage of #42632 - it will be quite big eventually and it is still work in progress (I am still working on fixing all the tests in breeze selective checks and need to apply changes to github workflows to run the tests but wanted to give you a heads up of what I am proposing as a change.

So do not (yet) comment on subtle details - that will come, but I'd love more to get a heads-up on the whole concept that I am planning to implement for our tests, some simplifications it will bring and impact on the system tests execution (because that is something not yet in our CI and something that should be applied as a change when you will run system tests of Amazon, Google, Astronomer and Teradata people.

Few general things:

1) The set of testing commands we will be able to use is this:

![image](https://github.com/user-attachments/assets/5bf802c2-cf26-4dd2-ba60-5797cc4e3168)

This means that we can separate out providers/task_sdk, core tests as completely different jobs in CI (also it will make it easier to run locally.

2) I introduced the concept of ""Group Of Tests"" - previously the test types (`All/Core/Other/...`)  in the core were mixed with `Helm` or `System` test type and it was very confusing. Now we have test group ('Core, Providers, Integration-Core, Integration-Providers, System-Core, System-Providers, Helm) - and each group has it's own ""test types"" defined (so ""Other/Always etc. "" are valid for ""Core Test Group"", but not valid for ""Providers Test Group"" - also you cannot specify ""Providers*"" test type for anything else than one of Providers test group.

3) The ""options"" for each of the test commands are now much more consistent and definition of groups of those options  is now much more composable and logical. Example ""providers-tests"" set of options that are grouped accorting to test type (db/non-db, providers/core etc). For example DB operations are available for the ""general"" and ""db"" test scopes and not available for the ""non-db"" scope. 

![image](https://github.com/user-attachments/assets/d25fad22-a1a1-4ac2-a01f-04167a8ab3a2)

4) I am still working on cleaning up and restructuring the code a bit - but generally code for different test groups to produce the right pytest command will be separate ""per group"" when I finish.

5) the overall idea for the change is to be able to keep the same ""selective check"" optimizations that allow to run only subset of changes for each change and to allo to run tests in parallel on bigger machines (once we have ARC running cc: @hussein-awala ).

6) Running system tests after this is merged should look this way:

```
breeze testing system-providers-tests ./providers/tests/system/amazon/aws/tests/test_aws_auth_manager.py
```

(plus the usual parameters - env vars etc. configured).


Let me know what you think - high level - I will work on fixing the tests and adding missing changes and updating docs accordingly in the meantime.

potiuk (Issue Creator) on (2024-11-13 14:31:15 UTC): And yes - it's huge - I know, but I have not figured out how to split it.

potiuk (Issue Creator) on (2024-11-13 15:21:25 UTC): !!!!!!!!!!  Please, Please, Pretty please - committers do not approve the workflow. This is an example for Github Ticket I opened to show that I need to approve my own workflows now. !!!!!!!
:scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream: :scream:

vincbeck on (2024-11-13 15:45:52 UTC): I have not looked at the code but only at the description. I like the direction it is taking, the notion of test group makes sense. Having more granular test commands makes sense and will reduce the number of options we have today for the `breeze testing tests` command. As mentioned in the description, some of these options do not apply for certain tests and managing all the different combinations of these options is cumbersome. So I guess we'll gain a lot of simplification there

o-nikolas on (2024-11-13 17:47:06 UTC): Looks good so far!
Do we need to make the db/non-db part of the command (e.g. `core-tests`, `core-db-tests`, `core-non-db-tests`)? It feels like we should have just one group command and then an option to toggle db/non-db/both.

Other than that I like the changes!

potiuk (Issue Creator) on (2024-11-13 22:32:06 UTC): It makes it quite a bit easier to handle. DB paralel tests are run using multi-processing and running parallel docker-composes. Where Non-DB parallel tests are run using xdist. This makes the two commands pretty distinct - they not only behave diferently but also they have various other parameters applicable on in one of those cases (mostly the DB).

Those are the options that only make senses for DB tests:

* `--db-reset`
* `--backend`
* `--no-db-cleanup`
* `--postgres-version`
* `--mysql-version`

Thanks to that teh `non-db-tests` have way smaller set of parameter than `db-tests`.

Technically we could pass all the necessary parametters for non-db option in the ""regular"" (that handles both db and non-db) - parallelism, backend=none and few others, But then that makes `non-db` commands way simpler when we select which command to use based on parameters passed - for example:

```
    if [[ ""${TEST_SCOPE}"" == ""DB"" ]]; then
        set -x
        breeze testing core-db-tests
        set +x
    elif [[ ""${TEST_SCOPE}"" == ""Non-DB"" ]]; then
        set -x
        breeze testing core-non-db-tests
        set +x
```

I experimented with it before, and that one produced the nicest and simplest set of commands to execute without specifying too many parameters.

potiuk (Issue Creator) on (2024-11-14 11:12:31 UTC): I moved the change to https://github.com/apache/airflow/pull/43979.  Closing this one - seems workflows have been run eventualy BTW

"
2655491037,pull_request,closed,,Added for tests,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 13:17:03+00:00,[],2024-11-13 13:18:10+00:00,2024-11-13 13:18:10+00:00,https://github.com/apache/airflow/pull/43964,[],[],
2655231816,pull_request,closed,,Remove duplicate routers from the FastAPI app,"`variables_router` and `dags_router` were duplicates

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-13 11:49:32+00:00,[],2024-11-13 12:21:57+00:00,2024-11-13 12:21:55+00:00,https://github.com/apache/airflow/pull/43962,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2655180516,pull_request,closed,,Bump min version of sqlparse to 0.5.1,We are going to bump it anyway to unblock https://github.com/apache/airflow/pull/41916 so raised PR to expedite things,eladkal,2024-11-13 11:29:01+00:00,[],2024-11-13 12:21:22+00:00,2024-11-13 12:10:25+00:00,https://github.com/apache/airflow/pull/43961,"[('area:providers', ''), ('provider:common-sql', '')]","[{'comment_id': 2473423647, 'issue_id': 2655180516, 'author': 'potiuk', 'body': 'Yeah. I really like how the ""lowest dependency"" tests are keeping thing in order - this is a result of #41916 telling us ""Not good version"" :)', 'created_at': datetime.datetime(2024, 11, 13, 12, 6, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-13 12:06:01 UTC): Yeah. I really like how the ""lowest dependency"" tests are keeping thing in order - this is a result of #41916 telling us ""Not good version"" :)

"
2655138672,pull_request,closed,,Add source_tag to PineconeHook,The Pinecone partners team asked if it would be possible to add an [attribution tag](https://docs.pinecone.io/integrations/build-integration/attribute-usage-to-your-integration) to the provider to track how much SDK usage they get through it.,TJaniF,2024-11-13 11:17:05+00:00,[],2024-11-13 14:59:31+00:00,2024-11-13 14:59:31+00:00,https://github.com/apache/airflow/pull/43960,"[('area:providers', ''), ('provider:pinecone', '')]",[],
2655126967,pull_request,closed,,Deprecate accessing inlet and outlet events through string,"relates: https://github.com/apache/airflow/issues/43956

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-13 11:13:06+00:00,[],2024-12-10 10:33:32+00:00,2024-12-10 10:33:32+00:00,https://github.com/apache/airflow/pull/43959,"[('kind:documentation', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2514163847, 'issue_id': 2655126967, 'author': 'Lee-W', 'body': ""as discussed in https://github.com/apache/airflow/issues/43956#issuecomment-2511443068, we'll hold the deprecation part of this PR but will extract the new asset attribute support part to another PR"", 'created_at': datetime.datetime(2024, 12, 3, 10, 33, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2531157267, 'issue_id': 2655126967, 'author': 'Lee-W', 'body': 'close in favor of #44639', 'created_at': datetime.datetime(2024, 12, 10, 10, 33, 32, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-12-03 10:33:48 UTC): as discussed in https://github.com/apache/airflow/issues/43956#issuecomment-2511443068, we'll hold the deprecation part of this PR but will extract the new asset attribute support part to another PR

Lee-W (Issue Creator) on (2024-12-10 10:33:32 UTC): close in favor of #44639

"
2654885074,pull_request,closed,,AIP-84: Migrating delete queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370
Migrating delete queued asset events for DAG to fastAPI 

Dependent on https://github.com/apache/airflow/pull/43934


Same setup as https://github.com/apache/airflow/pull/43934

Responses:
1. Legacy
![image](https://github.com/user-attachments/assets/7188d931-afc1-4fd1-be1a-009faacf40fb)

2. FastAPI
![image](https://github.com/user-attachments/assets/55f23c87-dde7-4229-a3e8-2ea380259d88)


With time filtering
1. Legacy
![image](https://github.com/user-attachments/assets/5180412c-fd32-4289-8399-9eb8e8a3c518)

2. FastAPI
![image](https://github.com/user-attachments/assets/7b39e98b-821b-48e8-bf78-c58e9080850e)

Time filtering but no queued event found
1. Legacy
![image](https://github.com/user-attachments/assets/bb46d7ae-1eb5-4272-b07b-d22dfef4f64d)

2. FastAPI
![image](https://github.com/user-attachments/assets/d7a44f48-05fb-4e91-be63-0feec6e6f716)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-13 09:51:03+00:00,['amoghrajesh'],2024-11-18 08:42:22+00:00,2024-11-18 08:42:22+00:00,https://github.com/apache/airflow/pull/43955,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2473026260, 'issue_id': 2654885074, 'author': 'amoghrajesh', 'body': 'Only the last 2 commits are relevant', 'created_at': datetime.datetime(2024, 11, 13, 9, 51, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482290069, 'issue_id': 2654885074, 'author': 'amoghrajesh', 'body': 'Closing in favour of https://github.com/apache/airflow/pull/44129', 'created_at': datetime.datetime(2024, 11, 18, 8, 42, 22, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-13 09:51:55 UTC): Only the last 2 commits are relevant

amoghrajesh (Issue Creator) on (2024-11-18 08:42:22 UTC): Closing in favour of https://github.com/apache/airflow/pull/44129

"
2654811440,pull_request,closed,,[edge] Fixed UnicodeDecodeError during log file upload of Edge worker,"# Description

Edge worker runs into UnicodeDecodeError exception during log file upload. The Worker reads log file as string and counts number of string characters to seek into the file during uploading next log file part. This can result in mismatch between number of bytes and number of string characters if log file contains none UTF-8 characters. So during upload of next log file part worker can jump between 2 bytes of none utf-8 characters and crashes. Edge worker now uses read bytes to calc place to seek into and decode string as UTF-8 to handle none UTF-8 charaters.

# Details about changes

* Worker reads log file as byte string to calc number of read bytes to seek in.
* Worker decode byte string to UTF-8
* Changed unit tests to test none UTF-8 log file.
",AutomationDev85,2024-11-13 09:28:31+00:00,[],2024-11-13 14:44:04+00:00,2024-11-13 14:44:04+00:00,https://github.com/apache/airflow/pull/43954,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2654788600,pull_request,closed,,Remove deprecated functionality from Google provider,"Remove deprecated functionality that reached the end of life November 01, 2024.",moiseenkov,2024-11-13 09:18:57+00:00,[],2024-11-16 16:14:46+00:00,2024-11-16 16:14:46+00:00,https://github.com/apache/airflow/pull/43953,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('area:serialization', ''), ('kind:documentation', '')]","[{'comment_id': 2473143130, 'issue_id': 2654788600, 'author': 'VladaZakharova', 'body': 'Hi @potiuk @eladkal @kosteev !\r\nThis PR removes operators, hooks and other stuff that was planned for removal after November 1st, so based on our deprecation policy (6 months notice period)', 'created_at': datetime.datetime(2024, 11, 13, 10, 40, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476180387, 'issue_id': 2654788600, 'author': 'potiuk', 'body': '#protm', 'created_at': datetime.datetime(2024, 11, 14, 12, 6, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476181457, 'issue_id': 2654788600, 'author': 'potiuk', 'body': 'I think you got big chances for PR of the month @moiseenkov :+1: \r\n\r\n![image](https://github.com/user-attachments/assets/60e73f6e-60d5-4e17-94ed-539eceede48f)', 'created_at': datetime.datetime(2024, 11, 14, 12, 6, 40, tzinfo=datetime.timezone.utc)}]","VladaZakharova on (2024-11-13 10:40:37 UTC): Hi @potiuk @eladkal @kosteev !
This PR removes operators, hooks and other stuff that was planned for removal after November 1st, so based on our deprecation policy (6 months notice period)

potiuk on (2024-11-14 12:06:07 UTC): #protm

potiuk on (2024-11-14 12:06:40 UTC): I think you got big chances for PR of the month @moiseenkov :+1: 

![image](https://github.com/user-attachments/assets/60e73f6e-60d5-4e17-94ed-539eceede48f)

"
2654758491,pull_request,closed,,Remove Airflow 2.1 compat code in Google provider,We've dropped the old version a long time ago. This is unreachable code at this point.,uranusjr,2024-11-13 09:05:32+00:00,[],2024-11-13 10:52:50+00:00,2024-11-13 10:42:22+00:00,https://github.com/apache/airflow/pull/43952,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2654717870,pull_request,closed,,Add missing test for apache cassandra hooks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
Related: #35442
This PR will add unit tests for apache cassandra hooks [hooks/cassandra.py](url).

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---",yangyulely,2024-11-13 08:48:08+00:00,[],2024-11-14 02:25:42+00:00,2024-11-13 12:22:04+00:00,https://github.com/apache/airflow/pull/43951,"[('area:providers', ''), ('provider:apache-cassandra', '')]","[{'comment_id': 2473459774, 'issue_id': 2654717870, 'author': 'potiuk', 'body': 'Nice ! thanks!', 'created_at': datetime.datetime(2024, 11, 13, 12, 21, 59, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-13 12:21:59 UTC): Nice ! thanks!

"
2654458156,pull_request,closed,,Fix duplication of Task tries in the UI (#43891),"It was observed that there are moments where the TI tries endpoint returns duplicate TaskInstance. I have observed this to happen when the TI is in up_for_retry state.

When the TI is in up_for_retry state, we have already recorded the previous try in TI history and the TI try_number has not incremented at this time, so we must exclude this recorded TI from the taskinstance tries endpoint. We know the TI because its state is in up_for_retry, so we filter TIs with up_for_retry state when querying for the task instance tries.

Closes: #41765
(cherry picked from commit 4bc1257df4bf1f7391ad8bca3b10d294b2d92e7a)

",ephraimbuddy,2024-11-13 07:01:36+00:00,[],2024-12-04 08:55:30+00:00,2024-11-13 08:48:24+00:00,https://github.com/apache/airflow/pull/43950,"[('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2654378878,pull_request,closed,,Update dag reserialize command,"Now that we have versioning, users must specify that they want to delete history before we do it in `airflow dags reserialize` command.

serialize dags are no longer deleted as part of this command. Users should use airflow db-clean command

Also updated the _reserialize function at DB upgrade so that it doesn't delete the serializedDag since that won't be necessary.

",ephraimbuddy,2024-11-13 06:35:36+00:00,['ephraimbuddy'],2024-11-26 11:30:00+00:00,2024-11-26 11:29:57+00:00,https://github.com/apache/airflow/pull/43949,"[('area:CLI', ''), ('AIP-65: DAG history in UI', '')]","[{'comment_id': 2473449922, 'issue_id': 2654378878, 'author': 'potiuk', 'body': ""Approved. We need it now. Though I think it's quite a big limitation. Possibly (@jedcunningham ) - with DAG bundles we could actually in the future to reserialize also history ? It sounds feasible, we would just have to go through version history and checkout the bundle in each version and reserialize it then. It also might (or might not) work - depends for example on the third-party package versions installed `now` vs `then` but we could at least try.\r\n\r\nBut yeah, that's likely Airflow 3.5+ or smth :)"", 'created_at': datetime.datetime(2024, 11, 13, 12, 17, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473454171, 'issue_id': 2654378878, 'author': 'potiuk', 'body': 'Maybe also we should attempt to keep old serialized DAGS and attempt to load them (Assuming that our serialization is forward-compatible) . That could also be done on a ""best effort"" case.', 'created_at': datetime.datetime(2024, 11, 13, 12, 19, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473868120, 'issue_id': 2654378878, 'author': 'ephraimbuddy', 'body': '> Maybe also we should attempt to keep old serialized DAGS and attempt to load them (Assuming that our serialization is forward-compatible) . That could also be done on a ""best effort"" case.\r\n\r\nYeah, old serialized dags won\'t be deleted except users want to do so. We would keep a serialization version that when deserializing, we could check the version it was serialized with and use that to deserialize it. It should be forward-compatible', 'created_at': datetime.datetime(2024, 11, 13, 15, 1, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474324242, 'issue_id': 2654378878, 'author': 'jedcunningham', 'body': '> with DAG bundles we could actually in the future to reserialize also history ? It sounds feasible, we would just have to go through version history and checkout the bundle in each version and reserialize it then.\r\n\r\nThis can already be pretty slow. Doing it for every historical version isn\'t an option imo.\r\n\r\n> Maybe also we should attempt to keep old serialized DAGS and attempt to load them (Assuming that our serialization is forward-compatible) . That could also be done on a ""best effort"" case.\r\n\r\nI think something like this is the right way to handle this. I think Kaxil is going to look into it as part of AIP-72 stuff: #43648', 'created_at': datetime.datetime(2024, 11, 13, 17, 46, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477342541, 'issue_id': 2654378878, 'author': 'ashb', 'body': ""Given users often run this as part of upgrades (or db  upgrade does it itself) we'll need to stop deleting things very soon"", 'created_at': datetime.datetime(2024, 11, 14, 20, 24, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485171709, 'issue_id': 2654378878, 'author': 'ephraimbuddy', 'body': ""I'm thinking of renaming this command as `airflow dags re-version` or any better name other than reserialize. Thoughts?"", 'created_at': datetime.datetime(2024, 11, 19, 9, 36, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486027833, 'issue_id': 2654378878, 'author': 'ephraimbuddy', 'body': 'Will appreciate another review @jedcunningham @pierrejeambrun', 'created_at': datetime.datetime(2024, 11, 19, 15, 26, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486212142, 'issue_id': 2654378878, 'author': 'dstandish', 'body': ""> I'm thinking of renaming this command as `airflow dags re-version` or any better name other than reserialize. Thoughts?\r\n\r\nI think re-version is probably not a good name. Shall we chat about it?"", 'created_at': datetime.datetime(2024, 11, 19, 16, 38, 27, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-13 12:17:48 UTC): Approved. We need it now. Though I think it's quite a big limitation. Possibly (@jedcunningham ) - with DAG bundles we could actually in the future to reserialize also history ? It sounds feasible, we would just have to go through version history and checkout the bundle in each version and reserialize it then. It also might (or might not) work - depends for example on the third-party package versions installed `now` vs `then` but we could at least try.

But yeah, that's likely Airflow 3.5+ or smth :)

potiuk on (2024-11-13 12:19:36 UTC): Maybe also we should attempt to keep old serialized DAGS and attempt to load them (Assuming that our serialization is forward-compatible) . That could also be done on a ""best effort"" case.

ephraimbuddy (Issue Creator) on (2024-11-13 15:01:01 UTC): Yeah, old serialized dags won't be deleted except users want to do so. We would keep a serialization version that when deserializing, we could check the version it was serialized with and use that to deserialize it. It should be forward-compatible

jedcunningham on (2024-11-13 17:46:15 UTC): This can already be pretty slow. Doing it for every historical version isn't an option imo.


I think something like this is the right way to handle this. I think Kaxil is going to look into it as part of AIP-72 stuff: #43648

ashb on (2024-11-14 20:24:44 UTC): Given users often run this as part of upgrades (or db  upgrade does it itself) we'll need to stop deleting things very soon

ephraimbuddy (Issue Creator) on (2024-11-19 09:36:07 UTC): I'm thinking of renaming this command as `airflow dags re-version` or any better name other than reserialize. Thoughts?

ephraimbuddy (Issue Creator) on (2024-11-19 15:26:33 UTC): Will appreciate another review @jedcunningham @pierrejeambrun

dstandish on (2024-11-19 16:38:27 UTC): I think re-version is probably not a good name. Shall we chat about it?

"
2653992402,pull_request,closed,,AIP-84 Refactor Filter Query Parameters,"related: #43407

Hi @pierrejeambrun,

As we discussed in https://github.com/apache/airflow/pull/43407#pullrequestreview-2405200579, here is the current implementation and usage for the refactored filter query parameters. I'd appreciate your feedback before proceeding with refactoring other endpoints to align with this approach.

Since parameter types need to be specified statically to generate the OpenAPI schema, it is necessary to have a corresponding `filter_param_factory` for each common type ( Like `float_range_filter_factory` and `datetime_range_filter_factory` for `RangeFilter` ).

Thanks!
",jason810496,2024-11-13 03:07:00+00:00,[],2024-12-03 16:55:19+00:00,2024-12-03 16:55:19+00:00,https://github.com/apache/airflow/pull/43947,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2474201466, 'issue_id': 2653992402, 'author': 'pierrejeambrun', 'body': ""I didn't run it myself but we need to make sure that the documentation is well detected and constructed. On `http://localhost:29091/docs` (default values, types, parameter names, schemas etc..)"", 'created_at': datetime.datetime(2024, 11, 13, 16, 57, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480496188, 'issue_id': 2653992402, 'author': 'jason810496', 'body': 'Hi @pierrejeambrun, \r\n\r\nWhat are your thoughts on the current `filter_param_factory` implementation? The current approach adds a new parameter, `_type`, to specify the type of query parameter at runtime. This implementation consolidates multiple factories like `str_filter_param_factory`, `str_list_filter_param_factory`, etc., into a single `filter_param_factory`.\r\n\r\nI have checked the OpenAPI schema at `http://localhost:29091/docs`, and the correct type is displayed in the documentation. \r\n\r\nLooking forward to your feedback!', 'created_at': datetime.datetime(2024, 11, 16, 9, 44, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482713207, 'issue_id': 2653992402, 'author': 'pierrejeambrun', 'body': 'I think it\'s great, last time I tried exactly the same, code was working but documentation was missing the appropriate type. I think I was missing the following to make it work:\r\n```\r\ndepends_filter.__annotations__[""value""] = _type\r\n```\r\n\r\nBut indeed having a Generic factory is the best approach, removing the need for type specific factories.\r\n\r\nLove it.', 'created_at': datetime.datetime(2024, 11, 18, 11, 5, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2495517395, 'issue_id': 2653992402, 'author': 'jason810496', 'body': 'Hi @pierrejeambrun,\r\nI chose the schema with only basic functionalities defined in `common/parameters.py` but used solely in a single endpoint.\r\nThe refactor will not affect the OpenAPI schema or test cases. The current differences in `v1-generated.yaml` are caused by the `Offset`, `Limit`, and `OrderBy` parameters.\r\n\r\n### Follow-Up\r\nI noticed that `_SearchParam` could leverage the factory pattern as well. I plan to refactor this part after this PR is merged to avoid making the scope of this PR too large.\r\n\r\n### Question\r\nFor some parameter schemas like `QueryTIStateFilter`, which are only used twice in `task_instance.py`, should such parameter schemas be placed directly in `task_instance.py` rather than in `common/parameters`?  \r\n\r\nThanks !', 'created_at': datetime.datetime(2024, 11, 23, 15, 40, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2503874473, 'issue_id': 2653992402, 'author': 'pierrejeambrun', 'body': ""> For some parameter schemas like QueryTIStateFilter, which are only used twice in task_instance.py, should such parameter schemas be placed directly in task_instance.py rather than in common/parameters?\r\n\r\nAs long as they are 'reused' and not specific to a fonction I think it's fine to factorize them into `parameters.py`"", 'created_at': datetime.datetime(2024, 11, 27, 13, 25, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504159549, 'issue_id': 2653992402, 'author': 'jason810496', 'body': ""> Nice, should we generalize that to all routes ?\r\n\r\nYes, I believe most routers can adopt `filter_param_factory` if there isn't complex logic within `to_orm`."", 'created_at': datetime.datetime(2024, 11, 27, 15, 26, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507354888, 'issue_id': 2653992402, 'author': 'jason810496', 'body': ""Hi @pierrejeambrun, the refactor for `_SearchParam` is complete. Overall, only these 4 parameters remain unchanged as they don't contain common filter logic:\r\n\r\n- `_TagsFilter`\r\n- `_OwnersFilter`\r\n- `_DagIdAssetReferenceFilter`\r\n\r\nLet me know if further adjustments are needed."", 'created_at': datetime.datetime(2024, 11, 29, 8, 56, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511885956, 'issue_id': 2653992402, 'author': 'jason810496', 'body': 'Rebased to the latest `main`. Looking forward to further feedback before merging 🙌', 'created_at': datetime.datetime(2024, 12, 2, 15, 42, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514970540, 'issue_id': 2653992402, 'author': 'pierrejeambrun', 'body': 'Rebasing, merging on green CI.', 'created_at': datetime.datetime(2024, 12, 3, 16, 3, 22, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-13 16:57:06 UTC): I didn't run it myself but we need to make sure that the documentation is well detected and constructed. On `http://localhost:29091/docs` (default values, types, parameter names, schemas etc..)

jason810496 (Issue Creator) on (2024-11-16 09:44:27 UTC): Hi @pierrejeambrun, 

What are your thoughts on the current `filter_param_factory` implementation? The current approach adds a new parameter, `_type`, to specify the type of query parameter at runtime. This implementation consolidates multiple factories like `str_filter_param_factory`, `str_list_filter_param_factory`, etc., into a single `filter_param_factory`.

I have checked the OpenAPI schema at `http://localhost:29091/docs`, and the correct type is displayed in the documentation. 

Looking forward to your feedback!

pierrejeambrun on (2024-11-18 11:05:24 UTC): I think it's great, last time I tried exactly the same, code was working but documentation was missing the appropriate type. I think I was missing the following to make it work:
```
depends_filter.__annotations__[""value""] = _type
```

But indeed having a Generic factory is the best approach, removing the need for type specific factories.

Love it.

jason810496 (Issue Creator) on (2024-11-23 15:40:10 UTC): Hi @pierrejeambrun,
I chose the schema with only basic functionalities defined in `common/parameters.py` but used solely in a single endpoint.
The refactor will not affect the OpenAPI schema or test cases. The current differences in `v1-generated.yaml` are caused by the `Offset`, `Limit`, and `OrderBy` parameters.

### Follow-Up
I noticed that `_SearchParam` could leverage the factory pattern as well. I plan to refactor this part after this PR is merged to avoid making the scope of this PR too large.

### Question
For some parameter schemas like `QueryTIStateFilter`, which are only used twice in `task_instance.py`, should such parameter schemas be placed directly in `task_instance.py` rather than in `common/parameters`?  

Thanks !

pierrejeambrun on (2024-11-27 13:25:19 UTC): As long as they are 'reused' and not specific to a fonction I think it's fine to factorize them into `parameters.py`

jason810496 (Issue Creator) on (2024-11-27 15:26:45 UTC): Yes, I believe most routers can adopt `filter_param_factory` if there isn't complex logic within `to_orm`.

jason810496 (Issue Creator) on (2024-11-29 08:56:28 UTC): Hi @pierrejeambrun, the refactor for `_SearchParam` is complete. Overall, only these 4 parameters remain unchanged as they don't contain common filter logic:

- `_TagsFilter`
- `_OwnersFilter`
- `_DagIdAssetReferenceFilter`

Let me know if further adjustments are needed.

jason810496 (Issue Creator) on (2024-12-02 15:42:48 UTC): Rebased to the latest `main`. Looking forward to further feedback before merging 🙌

pierrejeambrun on (2024-12-03 16:03:22 UTC): Rebasing, merging on green CI.

"
2653934587,pull_request,closed,,"Revert ""Redirect old location module imports to standard provider (#4…","…3610)""

There is a very interesting breaking change introduced in Python 3.11 that will likely mean that we should not use MetaPathFinder for old standard provider classes redirection.

There was a change introduced in Python 3.11 that caused that module might not be found in some cases (for example when unit test patches the path) when the module is loaded as a different module (i.e. a.b differs from sys.modules['a.b'])

This is tracked in CPython via:
https://github.com/python/cpython/issues/117860

This causes standard operator's tests fail in Python 3.11 and 3.12 when the providers/tests/standard/test_module_redirect_finder.py is executed before - i.e. the standard modules are loaded as old modules.

This reverts commit 5de2e73cc3b1fd12a4be228d03bdfb2093ca44f0.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 02:33:01+00:00,[],2024-11-13 09:13:35+00:00,2024-11-13 05:25:11+00:00,https://github.com/apache/airflow/pull/43946,"[('area:providers', ''), ('provider:standard', '')]","[{'comment_id': 2472424761, 'issue_id': 2653934587, 'author': 'gopidesupavan', 'body': 'really interesting one :)', 'created_at': datetime.datetime(2024, 11, 13, 5, 26, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472922494, 'issue_id': 2653934587, 'author': 'potiuk', 'body': '> really interesting one :)\r\n\r\nIndeed - that is about third time when our test harness (which I am reeally happy about) uncover a bug in CPython.\r\nFor me this one case is a single most important reason why we should have all the matrices and canary builds running everything. Once evey half a year or so, they discover an issue in one or two of the combos that would take us weeks of investigation if it would have happened in ""production"" - and it happens way, way, way before it is even close to being released.', 'created_at': datetime.datetime(2024, 11, 13, 9, 13, 34, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-13 05:26:22 UTC): really interesting one :)

potiuk (Issue Creator) on (2024-11-13 09:13:34 UTC): Indeed - that is about third time when our test harness (which I am reeally happy about) uncover a bug in CPython.
For me this one case is a single most important reason why we should have all the matrices and canary builds running everything. Once evey half a year or so, they discover an issue in one or two of the combos that would take us weeks of investigation if it would have happened in ""production"" - and it happens way, way, way before it is even close to being released.

"
2653850486,pull_request,closed,,Upgrade hatchling to 1.26.3,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-13 01:41:05+00:00,[],2024-11-13 07:21:14+00:00,2024-11-13 07:21:14+00:00,https://github.com/apache/airflow/pull/43945,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2472238171, 'issue_id': 2653850486, 'author': 'potiuk', 'body': 'The failure in 3.11 and 3.12 will be handled by reverting MetaPath redirection in https://github.com/apache/airflow/pull/43946', 'created_at': datetime.datetime(2024, 11, 13, 2, 34, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472436860, 'issue_id': 2653850486, 'author': 'gopidesupavan', 'body': 'merged the reverted changes for redirect module.', 'created_at': datetime.datetime(2024, 11, 13, 5, 36, 44, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-13 02:34:20 UTC): The failure in 3.11 and 3.12 will be handled by reverting MetaPath redirection in https://github.com/apache/airflow/pull/43946

gopidesupavan on (2024-11-13 05:36:44 UTC): merged the reverted changes for redirect module.

"
2653540992,pull_request,closed,,Add basic asyncio support,"This is meant to be sort of a hello world for asyncio support in airflow.  It will be refined and extended in the future. E.g. probably we would add more config flexibility re the libraries, connect args etc.  But it's good to start simple.

Anyway, ultimately, I think Airflow really needs to go in this direction: in the new REST API, in the new AIP-72 internal API server, in triggers, and ultimately, in the scheduler.
",dstandish,2024-11-12 22:49:30+00:00,[],2024-11-14 23:21:03+00:00,2024-11-14 22:38:46+00:00,https://github.com/apache/airflow/pull/43944,[],"[{'comment_id': 2472370909, 'issue_id': 2653540992, 'author': 'tirkarthi', 'body': 'Is this related to AIP-70?\r\n\r\nhttps://cwiki.apache.org/confluence/display/AIRFLOW/%5BWIP%5D+AIP-70+Migrating+to+asynchronous+programming', 'created_at': datetime.datetime(2024, 11, 13, 4, 51, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472431971, 'issue_id': 2653540992, 'author': 'dstandish', 'body': '> Is this related to AIP-70?\r\n> \r\n> https://cwiki.apache.org/confluence/display/AIRFLOW/%5BWIP%5D+AIP-70+Migrating+to+asynchronous+programming\r\n\r\nI think you prob know the answer.  The AIP deals with asyncio, so yes strictly speaking related in that sense.  But not ""part of"".  That AIP has been in draft a long time not sure actively worked on.  Anyway, I don\'t think what I\'m doing here really requires an AIP.', 'created_at': datetime.datetime(2024, 11, 13, 5, 32, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472442896, 'issue_id': 2653540992, 'author': 'tirkarthi', 'body': 'There is a similar draft PR open as POC for it though not active. So just wanted to confirm. Thanks for the details.\r\n\r\nhttps://github.com/apache/airflow/pull/36504', 'created_at': datetime.datetime(2024, 11, 13, 5, 41, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473621473, 'issue_id': 2653540992, 'author': 'ashb', 'body': '@pierrejeambrun A FastAPI dep to give an async session would be good, but I think anything in the models etc should be passed an explicit session.', 'created_at': datetime.datetime(2024, 11, 13, 13, 26, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473630921, 'issue_id': 2653540992, 'author': 'potiuk', 'body': 'NICE! Yeah. I really like to see it working with mysql compatibility and benchmarks :package: \r\n\r\n(because of course MySQL is our beloved database)', 'created_at': datetime.datetime(2024, 11, 13, 13, 30, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474566846, 'issue_id': 2653540992, 'author': 'dstandish', 'body': ""> Really exciting.\r\n> \r\n> Do we want an `@provide_async_session` as a follow up ? (I think Ash wanted to kill that decorator at some point, even if I find it kind of useful actually)\r\n\r\ni would say let's wait and see how / where / when we need it"", 'created_at': datetime.datetime(2024, 11, 13, 19, 35, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474675966, 'issue_id': 2653540992, 'author': 'omkar-foss', 'body': 'Lovely! Thank you for adding this, will try to start using this soon :)', 'created_at': datetime.datetime(2024, 11, 13, 20, 5, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477243333, 'issue_id': 2653540992, 'author': 'omkar-foss', 'body': ""@dstandish in lowest direct dep tests, we may need to limit minimum version for `aiosqlite` to `0.5.0` instead of `0.2.0` being used currently, as it doesn't have `DatabaseError`, hence leading to [this error](https://github.com/apache/airflow/actions/runs/11830062047/job/32963195433?pr=43944#step:7:15631).\r\n\r\nMore info on [this slack thread](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1731612243375739?thread_ts=1731529259.740149&cid=C06K9Q5G2UA)."", 'created_at': datetime.datetime(2024, 11, 14, 19, 28, 57, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-11-13 04:51:20 UTC): Is this related to AIP-70?

https://cwiki.apache.org/confluence/display/AIRFLOW/%5BWIP%5D+AIP-70+Migrating+to+asynchronous+programming

dstandish (Issue Creator) on (2024-11-13 05:32:02 UTC): I think you prob know the answer.  The AIP deals with asyncio, so yes strictly speaking related in that sense.  But not ""part of"".  That AIP has been in draft a long time not sure actively worked on.  Anyway, I don't think what I'm doing here really requires an AIP.

tirkarthi on (2024-11-13 05:41:25 UTC): There is a similar draft PR open as POC for it though not active. So just wanted to confirm. Thanks for the details.

https://github.com/apache/airflow/pull/36504

ashb on (2024-11-13 13:26:54 UTC): @pierrejeambrun A FastAPI dep to give an async session would be good, but I think anything in the models etc should be passed an explicit session.

potiuk on (2024-11-13 13:30:52 UTC): NICE! Yeah. I really like to see it working with mysql compatibility and benchmarks :package: 

(because of course MySQL is our beloved database)

dstandish (Issue Creator) on (2024-11-13 19:35:43 UTC): i would say let's wait and see how / where / when we need it

omkar-foss on (2024-11-13 20:05:58 UTC): Lovely! Thank you for adding this, will try to start using this soon :)

omkar-foss on (2024-11-14 19:28:57 UTC): @dstandish in lowest direct dep tests, we may need to limit minimum version for `aiosqlite` to `0.5.0` instead of `0.2.0` being used currently, as it doesn't have `DatabaseError`, hence leading to [this error](https://github.com/apache/airflow/actions/runs/11830062047/job/32963195433?pr=43944#step:7:15631).

More info on [this slack thread](https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1731612243375739?thread_ts=1731529259.740149&cid=C06K9Q5G2UA).

"
2653462510,pull_request,closed,,Remove sending of task logs in otel traces inside the Scheduler,"This was sending task logs from the scheduler has two problems:

1. It blocks the scheduling loop reading remote logs -- a huge performance
   foot-gun for anyone that turns this feature on
2. Sending task logs in a span seems too large, and way too verbose to provide
   any use in a span.

Addresses https://github.com/apache/airflow/issues/43868#issuecomment-2471667613",ashb,2024-11-12 22:17:54+00:00,[],2024-11-13 09:52:27+00:00,2024-11-13 01:22:13+00:00,https://github.com/apache/airflow/pull/43943,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2653441629,pull_request,closed,,Remove concurrency problem in no-db tests and mock by late import,"Fix for errors in https://github.com/apache/airflow/actions/runs/11798339919

Assumed root casue - only 90% certain: Concurrency in pytest with xdist.
I was able to fix it with not seeing the error locally by making imports late - seems if a top level import is made befor the mock, the `execute_in_subprocess` call was not correctly mocked... whyever.",jscheffl,2024-11-12 22:02:25+00:00,[],2024-11-13 19:34:13+00:00,2024-11-13 19:34:10+00:00,https://github.com/apache/airflow/pull/43942,"[('area:providers', ''), ('provider:standard', '')]","[{'comment_id': 2474561167, 'issue_id': 2653441629, 'author': 'jscheffl', 'body': 'giving-up but the problem anyway was in another side', 'created_at': datetime.datetime(2024, 11, 13, 19, 34, 10, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-11-13 19:34:10 UTC): giving-up but the problem anyway was in another side

"
2652956961,pull_request,open,,Provide an alternative OpenTelemetry implementation for traces that follows standard otel practices,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This is my first time contributing to Airflow and I'm not sure if there should be an AIP or a mailing discussion for such changes. I'd appreciate any feedback.

## Issue description

related: https://github.com/apache/airflow/pull/40802

There are some OpenTelemetry standard practices that help keep the usage consistent across multiple projects. According to those
* when a root span starts, the trace id and the span id are generated randomly
* while the span is active, the context is captured
  * injected into a carrier object which is a map or a python dictionary
* the carrier with the captured context is propagated across services and used to create sub spans
* the new sub-span extracts the parent context from the carrier and uses it to set the parent
  * the trace id is accessed from the carrier and the span id is generated randomly

To explain more, this is what the flow of operations should be
1. Dag run starts - start `dagrun` span
    i. Get the `dagrun` span context
2. Start task - with the `dagrun` context, start `ti` span
    i. Get the `ti` span context
4. With the `ti` span context create task-sub span
5. Task finishes - `ti` span ends
6. Dag run finishes - `dagrun` span ends 

Airflow follows a different approach
* trace and span ids are generated in a deterministic way from various properties  of the `dag_run` and the `task_instance`
* the spans for a dag and its tasks, are generated after the run has finished

This is the flow of the current implementation
1. Dag run starts
2. Tasks start
3. Tasks finish
4. Create spans for the tasks
5. Dag run finishes
6. Create span for the dag run

The current approach makes it impossible to create spans from under tasks while using the existing airflow code. To achieve that, you need to use https://github.com/howardyoo/airflow_otel_provider which has to generate the same trace id and span id as airflow otherwise the spans won't be properly associated. This isn't easily maintainable and it also makes it hard for people that are familiar with otel but new to airflow, to start using the feature.

These are some references to OpenTelemetry docs

https://opentelemetry.io/docs/concepts/context-propagation/
https://opentelemetry.io/docs/languages/python/propagation/
https://www.w3.org/TR/trace-context/

## Implementation description

For the dagrun and ti spans, I've reused the attributes from the original implementation. I found in my testing that the span timings were occasionally off. That was due to the fact that the time conversion to nanoseconds wasn't considering that the timezone isn't always present.

To be able to propagate the context of a span, and use it to create subspan, the span must be active.

For example, for a dag run, the span can't be created at the end but 
* it needs to start with the run
* stay active so that the context can be captured and propagated
* end once the run also ends

Same goes for a task and any sub-spans.

With this approach, we can use the new otel methods for creating spans directly from under a task without the need of the `airflow_otel_provider`. These spans will be children of the task span.

Check `test_otel_dag.py` for an example of usage.

In scheduler HA, multiple schedulers might process a dag, that is running for a long time. The OpenTelemetry philosophy is that spans can't be shared between processes. The process that starts a span should also be the only one that can end it.

To workaround that while staying consistent with the otel spec, each scheduler will keep track of the spans that it starts and will also be solely responsible for ending them.  

Let's assume that we are expecting these spans to be created and exported

```
dag_span
    |_ task1_span
          |_ task1_sub1_span
                |_ task1_sub1_sub_span
          |_ task1_sub2_span
    |_ task2_span
```

With the existing airflow implementation, the spans will be
```
dag_span
    |_ task1_span
    |_ task2_span
```

Here are some possible scenarios and how the dag spans will look like, assuming that the dag creates the same spans as above

1. Scheduler1 processes a dag from start to finish.
    ```
    dag_span
        |_ task1_span
              |_ task1_sub1_span
                    |_ task1_sub1_sub_span
              |_ task1_sub2_span
        |_ task2_span
    ```
2. Scheduler1 starts a dag and sometime during the run, Scheduler2 picks up the processing and finishes the dag.

    Through a db update, Scheduler2 will notify whoever scheduler started the spans, to end them.
    ```
    dag_span
        |_ task1_span
              |_ task1_sub1_span
                    |_ task1_sub1_sub_span
              |_ task1_sub2_span
        |_ task2_span
    ```

3. Scheduler1 starts a dag and while the dag is running, exits gracefully. Scheduler2 picks up the processing and finishes the dag while the initial scheduler is no longer running.

    Scheduler1 will end all active spans that it has a record of and update the db, while exiting. Scheduler2 will create continued spans. This will result in 2 or more spans in place of a long span, but the total duration will be the same. The continued span will be the new parent.
    ```
    dag_span
        |_ task1_span
        |_ scheduler_exits_span
        |_ new_scheduler_span
        |_ dag_span_continued
              |_ task1_span_continued
                    |_ task1_sub1_span
                          |_ task1_sub1_sub_span
                    |_ task1_sub2_span
              |_ task2_span
    ```

4. Scheduler1 starts a dag and while the dag is running, exits forcefully. Scheduler2 picks up the processing and finishes the dag while the initial scheduler is no longer running.

    Scheduler1 didn't have time to end any spans. Once the new scheduler picks up that the scheduler that started the spans, is unhealthy, it will recreate the lost spans.
    ```
    dag_span_recreated
        |_ task1_span_recreated
              |_ task1_sub1_span
                    |_ task1_sub1_sub_span
              |_ task1_sub2_span
        |_ task2_span
    ```


## Testing

* Added a new unit test for the `otel_tracer` methods and updated the existing ones
* Added an integration test for each possible scenario
* Updated the existing tests to handle the changes
* Tested the changes manually with a `PythonVirtualenvOperator` without issues

The integration test can be used with otel and jaeger as well. To do that, follow the steps on [this comment](https://github.com/apache/airflow/blob/ea3fbc158e3f5fc12515dad38dfbe58b0ca0d635/tests/integration/otel/test_otel.py#L405-L412).

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",xBis7,2024-11-12 18:12:58+00:00,[],2025-01-17 12:00:14+00:00,,https://github.com/apache/airflow/pull/43941,"[('pinned', 'Protect from Stalebot auto closing'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:serialization', ''), ('kind:documentation', ''), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]","[{'comment_id': 2471243631, 'issue_id': 2652956961, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 12, 18, 13, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471372742, 'issue_id': 2652956961, 'author': 'ashb', 'body': ""I'm confirming, but otel traces might have been experimental still, and if that's the case we are free to change them for a good reason, and your description certainly sounds like one!"", 'created_at': datetime.datetime(2024, 11, 12, 19, 22, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471507662, 'issue_id': 2652956961, 'author': 'ferruzzi', 'body': 'If I may, can you add some indication to the title that this is related to OTel Traces specifically?   We also have OTel Metrics implemented and it would be nice to minimize confusion.', 'created_at': datetime.datetime(2024, 11, 12, 20, 21, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472870498, 'issue_id': 2652956961, 'author': 'xBis7', 'body': ""@ferruzzi I adjusted the title. The only change in this patch that is related to metrics, it's https://github.com/apache/airflow/pull/43941/files#diff-1cca954ec0be1aaf2c212e718c004cb0902a96ac60043bf0c97a782dee52cc32R85-R86\r\n\r\nIf you think that it's out of scope, then I can remove it."", 'created_at': datetime.datetime(2024, 11, 13, 8, 50, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2512595217, 'issue_id': 2652956961, 'author': 'xBis7', 'body': ""My initial approach wasn't considering scheduler HA. I've updated the patch accordingly.\r\n\r\nThere have been two main challenges\r\n* Opentelemetry spans are designed so that only the process that starts them, can end them\r\n  * The span objects can't be shared or stored to a db\r\n* The airflow philosophy for scheduler HA is that the only shared state between multiple schedulers is the db\r\n  * It is very common that one scheduler starts a dag (also starts the span) and another scheduler finishes the dag (should end the span)\r\n\r\nTo avoid breaking things, each scheduler will have a list of the spans that it started and will be solely responsible for ending them. We will save two new attributes on the `dagrun` table and the `ti` table.\r\n\r\nThe new columns will be\r\n* `context_carrier`\r\n    * this is used for propagating the context and creating sub spans\r\n* `span_status`\r\n    * this is keeping track of the span status and notifying each scheduler of how to handle the span\r\n\r\nPossible scenarios with 2 scheduler (this can easily work with more)\r\n1. Scheduler1 starts a dag and finishes processing it\r\n    * This is straight forward\r\n      ```\r\n      dag span\r\n        |_ task1 span\r\n              |_ task1 sub span\r\n        |_ task2 span\r\n      ```\r\n2. Scheduler1 starts a dag while another scheduler finishes it\r\n    * The visualized result will be the same as scenario 1\r\n      ```\r\n      dag span\r\n        |_ task1 span\r\n              |_ task1 sub span\r\n        |_ task2 span\r\n      ```\r\n    * scheduler2 will set the span status to `SHOULD_END` and scheduler1 will end the spans during the next loop iteration.\r\n3. Scheduler1 starts a dag, exits gracefully and another scheduler picks up the dag and finishes it\r\n    * Since scheduler1 exits gracefully, e.g. with a `SIGTERM` or `SIGINT` signal, we can end the spans and update the status\r\n    * scheduler2 will create a continued span, for each prematurely ended span\r\n       ```\r\n       original       |----|\r\n       continued           |-------|\r\n\r\n      dag span\r\n        |_ task1 span\r\n        |_ scheduler exited span\r\n        |_ new scheduler span\r\n        |_ dag span (continued suffix)\r\n              |_ task1 span (continued suffix)\r\n                    |_ task1 sub span\r\n              |_ task2 span\r\n      ```\r\n4. Scheduler1 starts a dag, exits forcefully and another scheduler picks up the dag and finishes it \r\n    * In this case scheduler1 exited with active spans. Airflow has a standard way of declaring a scheduler unhealthy and also stores the id of the scheduler job that started a dagrun or a ti\r\n    * If the scheduler that started the dagrun or the ti, is unhealthy, we can recreate the lost spans\r\n    * If a task is active and running and its part that hasn't been executed yet, is supposed to create some sub-spans, then it will use the new recreated span as a parent\r\n      ```\r\n      dag span (recreated suffix)\r\n        |_ task1 span (recreated suffix)\r\n              |_ task1 sub span\r\n        |_ task2 span\r\n      ```\r\n    * If a task has finished and it created some sub-spans, then those spans are referencing a parent span that is lost along with the unhealthy scheduler. The only way to get the sub-spans is to re-run the task. In that case, we are recreating the span of the task itself but we can't recreate the sub-spans without rerunning the task\r\n      ```\r\n      dag span (recreated suffix)\r\n        |_ task1 span (recreated suffix)\r\n        |_ task2 span\r\n      ```\r\n\r\nNote that with the current airflow otel implementation, you can't create sub-spans from tasks. All dagrun spans are visualized like this\r\n```\r\ndag span\r\n  |_ task1 span\r\n  |_ task2 span\r\n```\r\n\r\n\r\nI'll do some testing to make sure nothing has been broken from merging with main and I'll move the PR out of draft."", 'created_at': datetime.datetime(2024, 12, 2, 19, 39, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2551301114, 'issue_id': 2652956961, 'author': 'xBis7', 'body': ""Hi @ashb,\r\n* I've addressed all your comments,\r\n* I created a new migration file,\r\n* I added some unit tests for the scheduler changes\r\n* I fixed 2 bugs that I came across while making the changes.\r\n\r\nPlease take a look when you get a chance and let me know how it looks. \r\n\r\nI'll push some commits for moving the dagrun/scheduler span changes to new methods, to make the code more readable.\r\n\r\n> I think this will work, though the main question I have is: if we can re-create the span for an unhealthy scheduler, couldn't we do that for healthy schedulers too? That way we wouldn't need to store active_spans in memory at all, and nor would we need to store span status in the DB?\r\n\r\nThis will get us to the old implementation where we can't create spans from under tasks.\r\n\r\nIf a task has already been run and it created spans, then these spans will be lost when we recreate the task span. This is happening for a few reasons\r\n* the already exported spans are referencing the old span as a parent\r\n* we are not setting the traceid and spanid deterministically but we are letting the otel sdk to handle that\r\n* the task sub spans are getting the parent with context propagation\r\n\r\nThe only way to get the spans back, will be to rerun the task."", 'created_at': datetime.datetime(2024, 12, 18, 13, 17, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593336281, 'issue_id': 2652956961, 'author': 'ashb', 'body': ""I'm aware this is waiting on my for a review, I will look at this when I can, but I've got some critical bits of AIP-72 (Task Execution Interface) to land first."", 'created_at': datetime.datetime(2025, 1, 15, 16, 7, 9, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-12 18:13:03 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

ashb on (2024-11-12 19:22:20 UTC): I'm confirming, but otel traces might have been experimental still, and if that's the case we are free to change them for a good reason, and your description certainly sounds like one!

ferruzzi on (2024-11-12 20:21:47 UTC): If I may, can you add some indication to the title that this is related to OTel Traces specifically?   We also have OTel Metrics implemented and it would be nice to minimize confusion.

xBis7 (Issue Creator) on (2024-11-13 08:50:08 UTC): @ferruzzi I adjusted the title. The only change in this patch that is related to metrics, it's https://github.com/apache/airflow/pull/43941/files#diff-1cca954ec0be1aaf2c212e718c004cb0902a96ac60043bf0c97a782dee52cc32R85-R86

If you think that it's out of scope, then I can remove it.

xBis7 (Issue Creator) on (2024-12-02 19:39:19 UTC): My initial approach wasn't considering scheduler HA. I've updated the patch accordingly.

There have been two main challenges
* Opentelemetry spans are designed so that only the process that starts them, can end them
  * The span objects can't be shared or stored to a db
* The airflow philosophy for scheduler HA is that the only shared state between multiple schedulers is the db
  * It is very common that one scheduler starts a dag (also starts the span) and another scheduler finishes the dag (should end the span)

To avoid breaking things, each scheduler will have a list of the spans that it started and will be solely responsible for ending them. We will save two new attributes on the `dagrun` table and the `ti` table.

The new columns will be
* `context_carrier`
    * this is used for propagating the context and creating sub spans
* `span_status`
    * this is keeping track of the span status and notifying each scheduler of how to handle the span

Possible scenarios with 2 scheduler (this can easily work with more)
1. Scheduler1 starts a dag and finishes processing it
    * This is straight forward
      ```
      dag span
        |_ task1 span
              |_ task1 sub span
        |_ task2 span
      ```
2. Scheduler1 starts a dag while another scheduler finishes it
    * The visualized result will be the same as scenario 1
      ```
      dag span
        |_ task1 span
              |_ task1 sub span
        |_ task2 span
      ```
    * scheduler2 will set the span status to `SHOULD_END` and scheduler1 will end the spans during the next loop iteration.
3. Scheduler1 starts a dag, exits gracefully and another scheduler picks up the dag and finishes it
    * Since scheduler1 exits gracefully, e.g. with a `SIGTERM` or `SIGINT` signal, we can end the spans and update the status
    * scheduler2 will create a continued span, for each prematurely ended span
       ```
       original       |----|
       continued           |-------|

      dag span
        |_ task1 span
        |_ scheduler exited span
        |_ new scheduler span
        |_ dag span (continued suffix)
              |_ task1 span (continued suffix)
                    |_ task1 sub span
              |_ task2 span
      ```
4. Scheduler1 starts a dag, exits forcefully and another scheduler picks up the dag and finishes it 
    * In this case scheduler1 exited with active spans. Airflow has a standard way of declaring a scheduler unhealthy and also stores the id of the scheduler job that started a dagrun or a ti
    * If the scheduler that started the dagrun or the ti, is unhealthy, we can recreate the lost spans
    * If a task is active and running and its part that hasn't been executed yet, is supposed to create some sub-spans, then it will use the new recreated span as a parent
      ```
      dag span (recreated suffix)
        |_ task1 span (recreated suffix)
              |_ task1 sub span
        |_ task2 span
      ```
    * If a task has finished and it created some sub-spans, then those spans are referencing a parent span that is lost along with the unhealthy scheduler. The only way to get the sub-spans is to re-run the task. In that case, we are recreating the span of the task itself but we can't recreate the sub-spans without rerunning the task
      ```
      dag span (recreated suffix)
        |_ task1 span (recreated suffix)
        |_ task2 span
      ```

Note that with the current airflow otel implementation, you can't create sub-spans from tasks. All dagrun spans are visualized like this
```
dag span
  |_ task1 span
  |_ task2 span
```


I'll do some testing to make sure nothing has been broken from merging with main and I'll move the PR out of draft.

xBis7 (Issue Creator) on (2024-12-18 13:17:52 UTC): Hi @ashb,
* I've addressed all your comments,
* I created a new migration file,
* I added some unit tests for the scheduler changes
* I fixed 2 bugs that I came across while making the changes.

Please take a look when you get a chance and let me know how it looks. 

I'll push some commits for moving the dagrun/scheduler span changes to new methods, to make the code more readable.


This will get us to the old implementation where we can't create spans from under tasks.

If a task has already been run and it created spans, then these spans will be lost when we recreate the task span. This is happening for a few reasons
* the already exported spans are referencing the old span as a parent
* we are not setting the traceid and spanid deterministically but we are letting the otel sdk to handle that
* the task sub spans are getting the parent with context propagation

The only way to get the spans back, will be to rerun the task.

ashb on (2025-01-15 16:07:09 UTC): I'm aware this is waiting on my for a review, I will look at this when I can, but I've got some critical bits of AIP-72 (Task Execution Interface) to land first.

"
2652835106,pull_request,closed,,Very much *experiment* with asyncio dag scheduling,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dstandish,2024-11-12 17:19:35+00:00,[],2025-01-05 00:16:58+00:00,2025-01-05 00:16:58+00:00,https://github.com/apache/airflow/pull/43940,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2564879966, 'issue_id': 2652835106, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 30, 0, 16, 15, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-30 00:16:15 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2652657306,pull_request,closed,,Prepare FAB provider to set next version as major version,"Prepare the provider to set its next version as major version. I also set the state of the provider as non-ready because we should not release the provider next major version before Airflow 3 release timeframe.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-12 16:15:13+00:00,[],2024-11-19 17:21:28+00:00,2024-11-19 17:21:27+00:00,https://github.com/apache/airflow/pull/43939,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:fab', '')]","[{'comment_id': 2471468130, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': 'I need to work on the tests since it seems that setting the state of an already installed provider from ready to non-ready is not that trivial', 'created_at': datetime.datetime(2024, 11, 12, 20, 4, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472343270, 'issue_id': 2652657306, 'author': 'eladkal', 'body': '> I need to work on the tests since it seems that setting the state of an already installed provider from ready to non-ready is not that trivial\r\n\r\nI dont think this is right approch. We may still release 1.x versions. For example if we find security risk.\r\nProvider should stay in ready state.\r\nAlso, we are going to have airflow 3 alpha/beta which might need also alpha/beta of the provider\r\n\r\nI can simply skip its release manually if needed.', 'created_at': datetime.datetime(2024, 11, 13, 4, 21, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473076306, 'issue_id': 2652657306, 'author': 'potiuk', 'body': ""Yeah. Let's keep it ready - agree. It should have `apache-airflow>=3.0.0dev0` as min version - so no-one will install it and as Elad wrote - we can skip it when preparing, or if it becomes a problem we can add a new state for it"", 'created_at': datetime.datetime(2024, 11, 13, 10, 12, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473866265, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': 'Sounds good!', 'created_at': datetime.datetime(2024, 11, 13, 15, 0, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474161565, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': 'The compat tests are failing because Airflow 2.9 and 2.10 tries to install the latest fab provider that is only compatible with Airflow 3. In `hatch_build`, the fab provider constraint is `fab>=1.0.2`. How can we solve that?  Should we, somehow, update this constraint to `fab>=1.0.2<=2.0.0` for Airflow 2.9 and 2.10?', 'created_at': datetime.datetime(2024, 11, 13, 16, 43, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474189123, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': 'Or should `uv` figure it out on its own?', 'created_at': datetime.datetime(2024, 11, 13, 16, 52, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474257719, 'issue_id': 2652657306, 'author': 'potiuk', 'body': '> Or should `uv` figure it out on its own?\r\n\r\nI think we will have to simply skip fab provider for Airflow 2.9 and 2.10. That should do the job. It will be installing applicable FAB from PyPI then', 'created_at': datetime.datetime(2024, 11, 13, 17, 17, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474264126, 'issue_id': 2652657306, 'author': 'potiuk', 'body': 'In global_constants.py in Breeze:\r\n\r\n```python\r\nBASE_PROVIDERS_COMPATIBILITY_CHECKS: list[dict[str, str | list[str]]] = [\r\n    {\r\n        ""python-version"": ""3.9"",\r\n        ""airflow-version"": ""2.8.4"",\r\n        ""remove-providers"": ""cloudant fab edge"",\r\n        ""run-tests"": ""true"",\r\n    },\r\n    {\r\n        ""python-version"": ""3.9"",\r\n        ""airflow-version"": ""2.9.3"",\r\n        ""remove-providers"": ""cloudant edge"",\r\n        ""run-tests"": ""true"",\r\n    },\r\n    {\r\n        ""python-version"": ""3.9"",\r\n        ""airflow-version"": ""2.10.3"",\r\n        ""remove-providers"": ""cloudant"",\r\n        ""run-tests"": ""true"",\r\n    },\r\n]\r\n```', 'created_at': datetime.datetime(2024, 11, 13, 17, 20, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474460964, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': '> > Or should `uv` figure it out on its own?\r\n> \r\n> I think we will have to simply skip fab provider for Airflow 2.9 and 2.10. That should do the job. It will be installing applicable FAB from PyPI then\r\n\r\nMakes sense. Thank you!', 'created_at': datetime.datetime(2024, 11, 13, 18, 47, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477443476, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': 'All tests are passing!', 'created_at': datetime.datetime(2024, 11, 14, 21, 27, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483464185, 'issue_id': 2652657306, 'author': 'vincbeck', 'body': 'Providers are now released. Can we proceed with this one?', 'created_at': datetime.datetime(2024, 11, 18, 16, 0, 50, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-11-12 20:04:56 UTC): I need to work on the tests since it seems that setting the state of an already installed provider from ready to non-ready is not that trivial

eladkal on (2024-11-13 04:21:09 UTC): I dont think this is right approch. We may still release 1.x versions. For example if we find security risk.
Provider should stay in ready state.
Also, we are going to have airflow 3 alpha/beta which might need also alpha/beta of the provider

I can simply skip its release manually if needed.

potiuk on (2024-11-13 10:12:47 UTC): Yeah. Let's keep it ready - agree. It should have `apache-airflow>=3.0.0dev0` as min version - so no-one will install it and as Elad wrote - we can skip it when preparing, or if it becomes a problem we can add a new state for it

vincbeck (Issue Creator) on (2024-11-13 15:00:25 UTC): Sounds good!

vincbeck (Issue Creator) on (2024-11-13 16:43:16 UTC): The compat tests are failing because Airflow 2.9 and 2.10 tries to install the latest fab provider that is only compatible with Airflow 3. In `hatch_build`, the fab provider constraint is `fab>=1.0.2`. How can we solve that?  Should we, somehow, update this constraint to `fab>=1.0.2<=2.0.0` for Airflow 2.9 and 2.10?

vincbeck (Issue Creator) on (2024-11-13 16:52:49 UTC): Or should `uv` figure it out on its own?

potiuk on (2024-11-13 17:17:12 UTC): I think we will have to simply skip fab provider for Airflow 2.9 and 2.10. That should do the job. It will be installing applicable FAB from PyPI then

potiuk on (2024-11-13 17:20:03 UTC): In global_constants.py in Breeze:

```python
BASE_PROVIDERS_COMPATIBILITY_CHECKS: list[dict[str, str | list[str]]] = [
    {
        ""python-version"": ""3.9"",
        ""airflow-version"": ""2.8.4"",
        ""remove-providers"": ""cloudant fab edge"",
        ""run-tests"": ""true"",
    },
    {
        ""python-version"": ""3.9"",
        ""airflow-version"": ""2.9.3"",
        ""remove-providers"": ""cloudant edge"",
        ""run-tests"": ""true"",
    },
    {
        ""python-version"": ""3.9"",
        ""airflow-version"": ""2.10.3"",
        ""remove-providers"": ""cloudant"",
        ""run-tests"": ""true"",
    },
]
```

vincbeck (Issue Creator) on (2024-11-13 18:47:15 UTC): Makes sense. Thank you!

vincbeck (Issue Creator) on (2024-11-14 21:27:11 UTC): All tests are passing!

vincbeck (Issue Creator) on (2024-11-18 16:00:50 UTC): Providers are now released. Can we proceed with this one?

"
2652633030,pull_request,closed,,Fix: Delete Kubernetes jobs if they are killed in the UI,"Related to: https://github.com/apache/airflow/issues/36090


`KuberentesJobOperator` didn't cancel jobs when they were cancelled via the UI.

1. non-deferrable run failed on API call
2. deferrable operators don't call `on_kill`; fixed with workaround described here: https://github.com/apache/airflow/issues/36090#issuecomment-2094972855 



",hhhonzik,2024-11-12 16:04:44+00:00,[],2024-12-11 13:13:10+00:00,2024-12-11 13:13:09+00:00,https://github.com/apache/airflow/pull/43938,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2488475367, 'issue_id': 2652633030, 'author': 'eladkal', 'body': 'can we have unit test to cover this change?', 'created_at': datetime.datetime(2024, 11, 20, 12, 36, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2535956288, 'issue_id': 2652633030, 'author': 'hhhonzik', 'body': ""I've seen a lot of issues with JobOperator, possibly thanks to this change - duplicated pod / job generators etc. \r\n\r\nWith the update by @eladkal PodOperator seems to be working for us. Closing."", 'created_at': datetime.datetime(2024, 12, 11, 13, 13, 9, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-20 12:36:57 UTC): can we have unit test to cover this change?

hhhonzik (Issue Creator) on (2024-12-11 13:13:09 UTC): I've seen a lot of issues with JobOperator, possibly thanks to this change - duplicated pod / job generators etc. 

With the update by @eladkal PodOperator seems to be working for us. Closing.

"
2652613608,pull_request,closed,,AIP-84 Improve doc for backfill API,Specifying return type will allow better typing in the OpenAPI spec and front-end generated code.,pierrejeambrun,2024-11-12 15:56:50+00:00,['pierrejeambrun'],2024-11-13 14:51:56+00:00,2024-11-13 14:46:43+00:00,https://github.com/apache/airflow/pull/43937,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2473842221, 'issue_id': 2652613608, 'author': 'kaxil', 'body': 'Nice', 'created_at': datetime.datetime(2024, 11, 13, 14, 51, 49, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-13 14:51:49 UTC): Nice

"
2652520612,pull_request,closed,,utilize map_index for deterministic generation of OpenLineage's run_id,"Use `queued_dttm` to differentiate between sensors with mode=reschedule runs.
Use `map_index` to differentiate between mapped tasks runs. ",mobuchowski,2024-11-12 15:27:36+00:00,[],2024-11-26 13:55:19+00:00,2024-11-25 13:21:35+00:00,https://github.com/apache/airflow/pull/43936,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:openlineage', 'AIP-53'), ('provider:dbt-cloud', '')]","[{'comment_id': 2497812524, 'issue_id': 2652520612, 'author': 'mobuchowski', 'body': ""@dstandish at the end just \r\n```\r\n        session.query(\r\n            exists().where(\r\n                TaskReschedule.dag_id == ti.dag_id,\r\n                TaskReschedule.task_id == ti.task_id,\r\n                TaskReschedule.run_id == ti.run_id,\r\n                TaskReschedule.map_index == ti.map_index,\r\n                TaskReschedule.try_number == ti.try_number,\r\n            )\r\n        ).scalar()\r\n        is True\r\n``` \r\nworks - the additional query isn't a big problem because I can perform those just for reschedulable sensors."", 'created_at': datetime.datetime(2024, 11, 25, 11, 55, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498552440, 'issue_id': 2652520612, 'author': 'dstandish', 'body': ""> @dstandish at the end just\r\n> \r\n> ```\r\n>         session.query(\r\n>             exists().where(\r\n>                 TaskReschedule.dag_id == ti.dag_id,\r\n>                 TaskReschedule.task_id == ti.task_id,\r\n>                 TaskReschedule.run_id == ti.run_id,\r\n>                 TaskReschedule.map_index == ti.map_index,\r\n>                 TaskReschedule.try_number == ti.try_number,\r\n>             )\r\n>         ).scalar()\r\n>         is True\r\n> ```\r\n> \r\n> works - the additional query isn't a big problem because I can perform those just for reschedulable sensors.\r\n\r\ncool @mobuchowski"", 'created_at': datetime.datetime(2024, 11, 25, 16, 57, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500861435, 'issue_id': 2652520612, 'author': 'potiuk', 'body': 'Is not that something that should be back-ported to 2.10.4 ? It certainly looks like', 'created_at': datetime.datetime(2024, 11, 26, 13, 52, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500866378, 'issue_id': 2652520612, 'author': 'potiuk', 'body': ""I provisionally added 2.10.4 milestone now but @mobuchowski -> maybe you can use the new cherry-picker manual flow to back-port it (it's already merged, so we missed the opportunity to auto cherry-pick it) https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#how-to-backport-pr-with-cherry-picker-cli"", 'created_at': datetime.datetime(2024, 11, 26, 13, 54, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2500868122, 'issue_id': 2652520612, 'author': 'potiuk', 'body': ""Ah. STupid me. It's provider-only :). Forget it."", 'created_at': datetime.datetime(2024, 11, 26, 13, 55, 17, tzinfo=datetime.timezone.utc)}]","mobuchowski (Issue Creator) on (2024-11-25 11:55:32 UTC): @dstandish at the end just 
```
        session.query(
            exists().where(
                TaskReschedule.dag_id == ti.dag_id,
                TaskReschedule.task_id == ti.task_id,
                TaskReschedule.run_id == ti.run_id,
                TaskReschedule.map_index == ti.map_index,
                TaskReschedule.try_number == ti.try_number,
            )
        ).scalar()
        is True
``` 
works - the additional query isn't a big problem because I can perform those just for reschedulable sensors.

dstandish on (2024-11-25 16:57:07 UTC): cool @mobuchowski

potiuk on (2024-11-26 13:52:25 UTC): Is not that something that should be back-ported to 2.10.4 ? It certainly looks like

potiuk on (2024-11-26 13:54:35 UTC): I provisionally added 2.10.4 milestone now but @mobuchowski -> maybe you can use the new cherry-picker manual flow to back-port it (it's already merged, so we missed the opportunity to auto cherry-pick it) https://github.com/apache/airflow/blob/main/dev/README_AIRFLOW3_DEV.md#how-to-backport-pr-with-cherry-picker-cli

potiuk on (2024-11-26 13:55:17 UTC): Ah. STupid me. It's provider-only :). Forget it.

"
2652422228,pull_request,closed,,AIP-84: Migrating GET queued asset events for DAG to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #42370 

Migrating the GET queued asset events for a DAG endpoint to fast API.

Setup:
1. Created producer and consumer dags:
![image](https://github.com/user-attachments/assets/951335ba-7e56-488d-8d56-3642ddb3b699)

2. Paused one producer while running the other to generate queued events
![image](https://github.com/user-attachments/assets/09945aa8-4a0f-43bf-858c-bc42480f2b01)

Responses:

1. Legacy
![image](https://github.com/user-attachments/assets/5377c493-2bfb-4f38-b6c2-0b01c9cfa291)

2. FastAPI
![image](https://github.com/user-attachments/assets/d7d6ea27-2035-4b8b-bb52-18b587207344)

With time filtering:
1. Legacy
![image](https://github.com/user-attachments/assets/a87e99f3-04a5-4598-ac95-6bb68edefcf7)

(Beyond creation time)
![image](https://github.com/user-attachments/assets/e03505ea-82c7-4741-ad6a-d6a273eea377)

2. FastAPI
![image](https://github.com/user-attachments/assets/8a2ce955-bdbb-4dea-96b1-09973d0185e2)

(Beyond creation time)
![image](https://github.com/user-attachments/assets/5b7b47cd-a586-4505-939d-2a8743007782)


Swagger spec: (maintained under dag section)
![image](https://github.com/user-attachments/assets/8fd645c8-b9a3-4eca-a4f6-488bd03395b4)

![image](https://github.com/user-attachments/assets/8fd645c8-b9a3-4eca-a4f6-488bd03395b4)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-12 14:48:29+00:00,['amoghrajesh'],2024-11-16 00:02:19+00:00,2024-11-16 00:02:17+00:00,https://github.com/apache/airflow/pull/43934,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2478065933, 'issue_id': 2652422228, 'author': 'amoghrajesh', 'body': '@pierrejeambrun FYI, I have pushed the changes for all the ""resolved"" comments. The rest are open for input from you.\r\n\r\nEDIT: I kept the endpoint at public/dags.py cos if I move to assets, the path will become: `/public/assets/{dag_id}/assets/queuedEvent` due to the underlying router registration. I moved the datamodels and tests to assets.py however', 'created_at': datetime.datetime(2024, 11, 15, 6, 37, 50, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-15 06:37:50 UTC): @pierrejeambrun FYI, I have pushed the changes for all the ""resolved"" comments. The rest are open for input from you.

EDIT: I kept the endpoint at public/dags.py cos if I move to assets, the path will become: `/public/assets/{dag_id}/assets/queuedEvent` due to the underlying router registration. I moved the datamodels and tests to assets.py however

"
2652296020,pull_request,closed,,Consolidate HTTP 401/403 Responses for Public API Routes,"Moved 401 & 403 responses to top-level router so we can avoid having to add it too all the public api routers

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-12 14:06:08+00:00,[],2024-11-13 22:46:35+00:00,2024-11-13 21:38:08+00:00,https://github.com/apache/airflow/pull/43932,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2470669603, 'issue_id': 2652296020, 'author': 'ashb', 'body': ""There's no problem with saying those endpoints return a 401/403 even if they don't tbh -- the error responses doesn't really mean much to clients if the endpoint never returns it.\r\n\r\nAnd as for auth vs anon, there's another way you are meant to specify security/auth requirements in Open API spec, so this doesn't affect that"", 'created_at': datetime.datetime(2024, 11, 12, 14, 22, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470739476, 'issue_id': 2652296020, 'author': 'pierrejeambrun', 'body': ""> There's no problem with saying those endpoints return a 401/403 even if they don't tbh -- the error responses doesn't really mean much to clients if the endpoint never returns it.\r\n\r\n> And as for auth vs anon, there's another way you are meant to specify security/auth requirements in Open API spec, so this doesn't affect that\r\n\r\nAre you referring to the `security` parameter in the openapi spec ? Because we are using that field in the legacy as a `global` one, not setting it on a per route basis. (We could do that in the new spec but that needs to be developed) \r\n\r\nAlso I do not fully agree, as a client if the document states that the endpoint can return 401 and 403, I expect it to be an authenticated endpoint, and I will try to provide credentials to it. Also I will also write code to handle those 401, 403 on the client side...for nothing. I just think it's not ideal, but I agree that's not really a big deal so if that sounds reasonable to you, I'm perfectly fine merging that. (That's also much easier for us :))"", 'created_at': datetime.datetime(2024, 11, 12, 14, 49, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471432053, 'issue_id': 2652296020, 'author': 'jscheffl', 'body': '> > There\'s no problem with saying those endpoints return a 401/403 even if they don\'t tbh -- the error responses doesn\'t really mean much to clients if the endpoint never returns it.\r\n> \r\n> > And as for auth vs anon, there\'s another way you are meant to specify security/auth requirements in Open API spec, so this doesn\'t affect that\r\n> \r\n> Are you referring to the `security` parameter in the openapi spec ? Because we are using that field in the legacy as a `global` one, not setting it on a per route basis. (We could do that in the new spec but that needs to be developed)\r\n> \r\n> Also I do not fully agree, as a client if the document states that the endpoint can return 401 and 403, I expect it to be an authenticated endpoint, and I will try to provide credentials to it. Also I will also write code to handle those 401, 403 on the client side...for nothing. I just think it\'s not ideal, but I agree that\'s not really a big deal so if that sounds reasonable to you, I\'m perfectly fine merging that. (That\'s also much easier for us :))\r\n\r\nTo make the ""open API endpoints"" explicit could we add a ""anonymous"" router for these both endpoints and separate them on the top level from the authenticated ones?', 'created_at': datetime.datetime(2024, 11, 12, 19, 49, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474845766, 'issue_id': 2652296020, 'author': 'kaxil', 'body': '> > > There\'s no problem with saying those endpoints return a 401/403 even if they don\'t tbh -- the error responses doesn\'t really mean much to clients if the endpoint never returns it.\r\n> > \r\n> > \r\n> > > And as for auth vs anon, there\'s another way you are meant to specify security/auth requirements in Open API spec, so this doesn\'t affect that\r\n> > \r\n> > \r\n> > Are you referring to the `security` parameter in the openapi spec ? Because we are using that field in the legacy as a `global` one, not setting it on a per route basis. (We could do that in the new spec but that needs to be developed)\r\n> > Also I do not fully agree, as a client if the document states that the endpoint can return 401 and 403, I expect it to be an authenticated endpoint, and I will try to provide credentials to it. Also I will also write code to handle those 401, 403 on the client side...for nothing. I just think it\'s not ideal, but I agree that\'s not really a big deal so if that sounds reasonable to you, I\'m perfectly fine merging that. (That\'s also much easier for us :))\r\n> \r\n> To make the ""open API endpoints"" explicit could we add a ""anonymous"" router for these both endpoints and separate them on the top level from the authenticated ones?\r\n\r\nI will take a stab at it as a separate PR', 'created_at': datetime.datetime(2024, 11, 13, 21, 38, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474978412, 'issue_id': 2652296020, 'author': 'kaxil', 'body': 'Here is one attempt: https://github.com/apache/airflow/pull/43990', 'created_at': datetime.datetime(2024, 11, 13, 22, 46, 34, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-12 14:22:22 UTC): There's no problem with saying those endpoints return a 401/403 even if they don't tbh -- the error responses doesn't really mean much to clients if the endpoint never returns it.

And as for auth vs anon, there's another way you are meant to specify security/auth requirements in Open API spec, so this doesn't affect that

pierrejeambrun on (2024-11-12 14:49:27 UTC): Are you referring to the `security` parameter in the openapi spec ? Because we are using that field in the legacy as a `global` one, not setting it on a per route basis. (We could do that in the new spec but that needs to be developed) 

Also I do not fully agree, as a client if the document states that the endpoint can return 401 and 403, I expect it to be an authenticated endpoint, and I will try to provide credentials to it. Also I will also write code to handle those 401, 403 on the client side...for nothing. I just think it's not ideal, but I agree that's not really a big deal so if that sounds reasonable to you, I'm perfectly fine merging that. (That's also much easier for us :))

jscheffl on (2024-11-12 19:49:13 UTC): To make the ""open API endpoints"" explicit could we add a ""anonymous"" router for these both endpoints and separate them on the top level from the authenticated ones?

kaxil (Issue Creator) on (2024-11-13 21:38:01 UTC): I will take a stab at it as a separate PR

kaxil (Issue Creator) on (2024-11-13 22:46:34 UTC): Here is one attempt: https://github.com/apache/airflow/pull/43990

"
2652276680,pull_request,closed,,Fix pre-commit selective checks,"This PR highlighted an issue with the pre-commit selective checks, https://github.com/apache/airflow/pull/43521. diffs on the `v1-genereated.yaml` spec did not trigger the `ts-compile-lint-ui` hook that is supposed to run the front-end codegen.",pierrejeambrun,2024-11-12 13:59:27+00:00,[],2024-11-12 16:37:42+00:00,2024-11-12 16:37:40+00:00,https://github.com/apache/airflow/pull/43931,"[('area:dev-tools', '')]",[],
2652270424,pull_request,closed,,Added host_proxy_cmd field in the ssh hooks extra options,"
closes: #43636

One can now add the key: `host_proxy_cmd` to the `extra_options` of the SSHHook.

This is the now preferred option of setting an external command. Only if the `host_proxy_cmd` attribute of the class is not set via the `extra_options`, it will be read from the hosts `~/.ssh/config`.
I have also added a unit test for the new functionality.

If there is anything I should change / add, let me know.

---",dominikhei,2024-11-12 13:57:14+00:00,[],2024-12-12 10:46:26+00:00,2024-12-12 10:46:26+00:00,https://github.com/apache/airflow/pull/43930,"[('area:providers', ''), ('kind:documentation', ''), ('provider:ssh', '')]","[{'comment_id': 2505054027, 'issue_id': 2652270424, 'author': 'potiuk', 'body': 'You will need to fix tests', 'created_at': datetime.datetime(2024, 11, 28, 0, 41, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2513869646, 'issue_id': 2652270424, 'author': 'eladkal', 'body': '@dominikhei can you rebase and fix the tests?', 'created_at': datetime.datetime(2024, 12, 3, 8, 37, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2515498257, 'issue_id': 2652270424, 'author': 'dominikhei', 'body': '> @dominikhei can you rebase and fix the tests?\r\n\r\n@eladkal Thank you for the reminder. I will fix it in the next few days!', 'created_at': datetime.datetime(2024, 12, 3, 20, 34, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527465486, 'issue_id': 2652270424, 'author': 'eladkal', 'body': 'Looks like this was already added in https://github.com/apache/airflow/pull/44565', 'created_at': datetime.datetime(2024, 12, 9, 10, 2, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2527483316, 'issue_id': 2652270424, 'author': 'dominikhei', 'body': ""> Looks like this was already added in #44565\r\n\r\n@eladkal Yes, didn't see the update in the original Issue."", 'created_at': datetime.datetime(2024, 12, 9, 10, 10, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-28 00:41:41 UTC): You will need to fix tests

eladkal on (2024-12-03 08:37:17 UTC): @dominikhei can you rebase and fix the tests?

dominikhei (Issue Creator) on (2024-12-03 20:34:39 UTC): @eladkal Thank you for the reminder. I will fix it in the next few days!

eladkal on (2024-12-09 10:02:26 UTC): Looks like this was already added in https://github.com/apache/airflow/pull/44565

dominikhei (Issue Creator) on (2024-12-09 10:10:05 UTC): @eladkal Yes, didn't see the update in the original Issue.

"
2652251976,pull_request,closed,,Minor Improvements to public FastAPI XCom endpoint,"- Remove ""print"" statement, thought it was added as a mistake
- Change the status code from raw int to named constants
- Change Query params to use Query and added validation of `>=-1` for map index
- Added validation for response type to `str | None` instead of previous generic of `Any`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-12 13:50:21+00:00,[],2024-11-12 14:50:22+00:00,2024-11-12 14:29:06+00:00,https://github.com/apache/airflow/pull/43928,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2470741680, 'issue_id': 2652251976, 'author': 'pierrejeambrun', 'body': 'Thanks Kaxil', 'created_at': datetime.datetime(2024, 11, 12, 14, 50, 20, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-12 14:50:20 UTC): Thanks Kaxil

"
2652119337,pull_request,closed,,[Edge]Add child processes to separate process group than main,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Currently we use subprocess.Popen to spawn a job by the edge worker. When SIGINT is raised, it will be passed down to the child process, where it is not handled, meaning that even if we handle it in the worker, the exception will be raised anyway.

This PR adds the start_new_session flag for Popen, which will call the setsid() prior to the execution of the child process, and start it in a separate process group

Since exceptions are not passed down to child tasks there is a separate method to handle SIGTERM for hard termination
 
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-11-12 13:02:49+00:00,[],2024-11-12 14:46:49+00:00,2024-11-12 14:46:49+00:00,https://github.com/apache/airflow/pull/43927,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2652054533,pull_request,closed,,"Skip DB, Task SDK and constraints generation for PRs with only new UI changes.","For PRs with only new UI changes there is no need to run DB tests, Task SDK tests and constraints generation since the PRs with only `airflow/ui` folder changes don't affect these tests.",tirkarthi,2024-11-12 12:32:22+00:00,[],2024-11-12 13:51:49+00:00,2024-11-12 13:51:30+00:00,https://github.com/apache/airflow/pull/43926,"[('area:dev-tools', '')]","[{'comment_id': 2470428186, 'issue_id': 2652054533, 'author': 'potiuk', 'body': 'Nice optimisation !', 'created_at': datetime.datetime(2024, 11, 12, 12, 39, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470585968, 'issue_id': 2652054533, 'author': 'tirkarthi', 'body': 'Thanks @potiuk', 'created_at': datetime.datetime(2024, 11, 12, 13, 51, 47, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-12 12:39:39 UTC): Nice optimisation !

tirkarthi (Issue Creator) on (2024-11-12 13:51:47 UTC): Thanks @potiuk

"
2651997073,pull_request,closed,,"Combine fab, standard and sql providers into one step in Breeze",Now that standard provider also depended on common.sql lets merge the step into one,eladkal,2024-11-12 12:05:05+00:00,[],2024-11-12 13:32:19+00:00,2024-11-12 13:32:15+00:00,https://github.com/apache/airflow/pull/43925,"[('area:dev-tools', '')]",[],
2651947904,pull_request,closed,,Remove non-existing field  from the ListCustomTrainingJobOperator's template_fields,Fix the `ListCustomTrainingJobOperator` by removing the non-existing field `display_name` from the `template_fields`,moiseenkov,2024-11-12 11:43:19+00:00,[],2024-11-14 07:10:21+00:00,2024-11-14 07:10:21+00:00,https://github.com/apache/airflow/pull/43924,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2651863190,pull_request,closed,,Fix main pre-commit,,pierrejeambrun,2024-11-12 11:13:57+00:00,[],2024-11-12 12:00:52+00:00,2024-11-12 11:47:24+00:00,https://github.com/apache/airflow/pull/43923,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2470259049, 'issue_id': 2651863190, 'author': 'ashb', 'body': 'Do we need to fix up the selective check logic?\r\n\r\nhttps://github.com/apache/airflow/actions/runs/11750492342/job/32738823728?pr=43521#step:8:878\r\n\r\n> skip-pre-commits = ...,ts-compile-format-lint-ui,ts-compile-format-lint-www\r\n\r\nhttps://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/utils/selective_checks.py#L1077-L1133 will need updating.', 'created_at': datetime.datetime(2024, 11, 12, 11, 16, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470270668, 'issue_id': 2651863190, 'author': 'pierrejeambrun', 'body': ""> Do we need to fix up the selective check logic?\r\n\r\nYes, something must be wrong in those, the `ts-compile-format-lint-ui` shouldn't be skipped in https://github.com/apache/airflow/pull/43521"", 'created_at': datetime.datetime(2024, 11, 12, 11, 21, 48, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-12 11:16:02 UTC): Do we need to fix up the selective check logic?

https://github.com/apache/airflow/actions/runs/11750492342/job/32738823728?pr=43521#step:8:878


https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/utils/selective_checks.py#L1077-L1133 will need updating.

pierrejeambrun (Issue Creator) on (2024-11-12 11:21:48 UTC): Yes, something must be wrong in those, the `ts-compile-format-lint-ui` shouldn't be skipped in https://github.com/apache/airflow/pull/43521

"
2651792918,pull_request,closed,,Raise deprecation warning when accessing inlet or outlet events through str,"
This behavior will be removed in airflow 3 as assets have attributes name and uri, it would be confusing to identify which attribute should be used to filter the right asset

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-12 10:43:40+00:00,['Lee-W'],2024-12-04 08:55:12+00:00,2024-11-14 00:36:50+00:00,https://github.com/apache/airflow/pull/43922,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2651633226,pull_request,closed,,Fix Mypy errors in main after recent changes,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-12 09:45:13+00:00,[],2024-11-12 10:34:36+00:00,2024-11-12 10:34:35+00:00,https://github.com/apache/airflow/pull/43920,"[('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider')]",[],
2651530248,pull_request,closed,,Tweak strict_dataset_uri_validation documentation wording,"See #43915. The warning message also already says this will be a hard error in Airflow 3.

https://github.com/apache/airflow/blob/0380160eda9dee4cc13a13c23719a06499c2c398/airflow/datasets/__init__.py#L114-L119",uranusjr,2024-11-12 09:09:51+00:00,[],2024-12-04 08:56:29+00:00,2024-11-12 09:57:26+00:00,https://github.com/apache/airflow/pull/43918,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2651527451,pull_request,closed,,Please ignore this,"See #43915. The warning message also already says this will be a hard error in Airflow 3.

https://github.com/apache/airflow/blob/0380160eda9dee4cc13a13c23719a06499c2c398/airflow/datasets/__init__.py#L91-L96",uranusjr,2024-11-12 09:08:32+00:00,[],2024-11-12 09:57:28+00:00,2024-11-12 09:08:53+00:00,https://github.com/apache/airflow/pull/43917,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2469972722, 'issue_id': 2651527451, 'author': 'uranusjr', 'body': 'Oops, wrong branch 🤦', 'created_at': datetime.datetime(2024, 11, 12, 9, 8, 53, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2024-11-12 09:08:53 UTC): Oops, wrong branch 🤦

"
2651507199,pull_request,closed,,Remove strict_asset_uri_validation,"An invalid asset URI now should always raise a hard error instead, as specified in AIP-60.

A separate PR will be submitted later to add this to the warning message in Airflow 2 to explicitly tell users to fix the URI.",uranusjr,2024-11-12 08:59:30+00:00,[],2024-11-12 10:52:55+00:00,2024-11-12 10:52:52+00:00,https://github.com/apache/airflow/pull/43915,[],[],
2651433928,pull_request,closed,,"Revert ""Add backport action to workflow (#43886)""","This reverts commit 9ee9e52dc6e6355cd655636caadbab739cae2546.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-12 08:34:49+00:00,[],2024-11-12 09:21:03+00:00,2024-11-12 09:21:01+00:00,https://github.com/apache/airflow/pull/43914,"[('area:dev-tools', '')]","[{'comment_id': 2469903729, 'issue_id': 2651433928, 'author': 'gopidesupavan', 'body': 'Yes I completely agree :)', 'created_at': datetime.datetime(2024, 11, 12, 8, 37, 13, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-12 08:37:13 UTC): Yes I completely agree :)

"
2651375359,pull_request,closed,,Fix prepare-provider-packages for fab and standard providers,"This should unblock the issue in https://github.com/apache/airflow/pull/41916

```
The conflict is caused by:
    apache-airflow 3.0.0.dev0 depends on apache-airflow-providers-common-sql
    apache-airflow-providers-standard 0.0.1 depends on apache-airflow-providers-common-sql>=1.20.0
```",eladkal,2024-11-12 08:03:26+00:00,[],2024-11-12 09:36:33+00:00,2024-11-12 09:30:22+00:00,https://github.com/apache/airflow/pull/43913,"[('area:dev-tools', '')]","[{'comment_id': 2469939833, 'issue_id': 2651375359, 'author': 'eladkal', 'body': 'mypy failures are not related to this PR', 'created_at': datetime.datetime(2024, 11, 12, 8, 54, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470028026, 'issue_id': 2651375359, 'author': 'potiuk', 'body': 'Yeah. We should solve it separately (if not solved already).', 'created_at': datetime.datetime(2024, 11, 12, 9, 30, 18, tzinfo=datetime.timezone.utc)}]","eladkal (Issue Creator) on (2024-11-12 08:54:08 UTC): mypy failures are not related to this PR

potiuk on (2024-11-12 09:30:18 UTC): Yeah. We should solve it separately (if not solved already).

"
2651163190,pull_request,closed,,Docs: Add prominent deprecations notice via css ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #41532 
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Updated deprecated Bigquery docstrings with the `.. warning::` admonition and added custom CSS styling, which will apply to all `.. warning::` admonitions found in docstrtings.

closes https://github.com/apache/airflow/issues/41532
",geraj1010,2024-11-12 06:20:14+00:00,[],2024-12-01 18:35:48+00:00,2024-11-29 00:52:46+00:00,https://github.com/apache/airflow/pull/43909,"[('kind:documentation', '')]","[{'comment_id': 2470030114, 'issue_id': 2651163190, 'author': 'ashb', 'body': 'Could you include before and after pics please?\r\n\r\nAnd if we use `.. warning::` anywhere else before and after of one those too please', 'created_at': datetime.datetime(2024, 11, 12, 9, 31, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471625804, 'issue_id': 2651163190, 'author': 'kaxil', 'body': 'Screenshots are here: https://github.com/apache/airflow/issues/41532#issuecomment-2467139167', 'created_at': datetime.datetime(2024, 11, 12, 21, 31, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472371004, 'issue_id': 2651163190, 'author': 'geraj1010', 'body': '**For `BigQueryExecuteQueryOperator`:**\r\n\r\n**Before:**\r\n<img width=""628"" alt=""image"" src=""https://github.com/user-attachments/assets/4ac926d8-9a7e-4565-8ced-deddac061a91"">\r\n\r\n**After:**\r\n<img width=""608"" alt=""image"" src=""https://github.com/user-attachments/assets/8b1f6609-8f53-440e-b7de-bb68e3d398ba"">\r\n\r\n\r\n\r\n\r\n\r\n\r\nThere are other operators that use `.. warning::` in their docstring, here is `CloudDataTransferServiceCreateJobOperator`\r\n\r\n**Before:**\r\n<img width=""609"" alt=""image"" src=""https://github.com/user-attachments/assets/29d62ef0-22ac-4ba3-8ef0-5ced4f3d0edc"">\r\n\r\n**After:**\r\n<img width=""608"" alt=""image"" src=""https://github.com/user-attachments/assets/1cc619ce-eb8c-4698-a8d1-a12c18be7b5e"">\r\n\r\n\r\n\r\n\r\n\r\nSo the styling appears to apply to all docstrings, which use the `.. warning::` admonition (since the CSS is in `docs/sphinx_design/static/custom.css`) . If that is an issue, I could create a `.css` specifically for Google Providers if that helps. Then that would restrict the styling to Google Providers.', 'created_at': datetime.datetime(2024, 11, 13, 4, 51, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477995090, 'issue_id': 2651163190, 'author': 'geraj1010', 'body': '@ashb Did I provide enough screenshots? Are there any other concerns?', 'created_at': datetime.datetime(2024, 11, 15, 5, 32, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478809424, 'issue_id': 2651163190, 'author': 'kaxil', 'body': 'We should do the same for all deprecated operators too', 'created_at': datetime.datetime(2024, 11, 15, 13, 24, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480104040, 'issue_id': 2651163190, 'author': 'geraj1010', 'body': ""> We should do the same for all deprecated operators too\r\n\r\nThat would be great. I could go through and apply this update to all deprecated operators. Unfortunately, it's a manual effort. I did mention something about extending the Sphinx `AutoAPI` extension (https://github.com/apache/airflow/issues/41532#issuecomment-2472688497), but that would take more work for sure."", 'created_at': datetime.datetime(2024, 11, 15, 23, 3, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505180457, 'issue_id': 2651163190, 'author': 'potiuk', 'body': 'You need to rebase/resolve conflicts @geraj1010', 'created_at': datetime.datetime(2024, 11, 28, 3, 10, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505407694, 'issue_id': 2651163190, 'author': 'omkar-foss', 'body': ""> I could go through and apply this update to all deprecated operators. Unfortunately, it's a manual effort. I did mention something about extending the Sphinx `AutoAPI` extension ([#41532 (comment)](https://github.com/apache/airflow/issues/41532#issuecomment-2472688497)), but that would take more work for sure.\r\n\r\nNo problem, I can help with applying this update to all deprecated operators.\r\n\r\n@kaxil @potiuk Shall I raise a separate PR with commits from this PR or something else, please let me know. Thank you :)"", 'created_at': datetime.datetime(2024, 11, 28, 7, 13, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506025551, 'issue_id': 2651163190, 'author': 'potiuk', 'body': '> @kaxil @potiuk Shall I raise a separate PR with commits from this PR or something else, please let me know. Thank you :)\r\n\r\nIf @geraj1010 is ok with it, absolutely - feel free.', 'created_at': datetime.datetime(2024, 11, 28, 12, 38, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506025958, 'issue_id': 2651163190, 'author': 'kaxil', 'body': ""> > I could go through and apply this update to all deprecated operators. Unfortunately, it's a manual effort. I did mention something about extending the Sphinx `AutoAPI` extension ([#41532 (comment)](https://github.com/apache/airflow/issues/41532#issuecomment-2472688497)), but that would take more work for sure.\r\n> \r\n> No problem, I can help with applying this update to all deprecated operators.\r\n> \r\n> @kaxil @potiuk Shall I raise a separate PR with commits from this PR or something else, please let me know. Thank you :)\r\n\r\nI think we can merge this one to credit @geraj1010"", 'created_at': datetime.datetime(2024, 11, 28, 12, 38, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506898334, 'issue_id': 2651163190, 'author': 'kaxil', 'body': 'I resolved the conflict, and merged', 'created_at': datetime.datetime(2024, 11, 29, 0, 53, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506898544, 'issue_id': 2651163190, 'author': 'kaxil', 'body': 'Verified it locally:\r\n\r\n<img width=""1108"" alt=""image"" src=""https://github.com/user-attachments/assets/bb02a45f-2f6b-438f-af36-355fb20aef90"">', 'created_at': datetime.datetime(2024, 11, 29, 0, 53, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506899335, 'issue_id': 2651163190, 'author': 'kaxil', 'body': '@eladkal Worth including this change in the next batch of providers', 'created_at': datetime.datetime(2024, 11, 29, 0, 54, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2507932277, 'issue_id': 2651163190, 'author': 'omkar-foss', 'body': ""Thanks a lot for looking into this @kaxil, and kudos @geraj1010 for this PR!\r\n\r\nI've raised https://github.com/apache/airflow/pull/44479 to use the warning block wherever applicable, so that we can show these prominent deprecation warnings consistently across Airflow docs. Cheers."", 'created_at': datetime.datetime(2024, 11, 29, 14, 31, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509544808, 'issue_id': 2651163190, 'author': 'geraj1010', 'body': ""> Thanks a lot for looking into this @kaxil, and kudos @geraj1010 for this PR!\r\n> \r\n> I've raised #44479 to use the warning block wherever applicable, so that we can show these prominent deprecation warnings consistently across Airflow docs. Cheers.\r\n\r\nMy pleasure!"", 'created_at': datetime.datetime(2024, 12, 1, 3, 12, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509545502, 'issue_id': 2651163190, 'author': 'geraj1010', 'body': 'Greetings, I was away for the holidays. Thank you all for review!\r\n\r\n@kaxil Thank you for resolving the conflict. Can you please tell me what it was?', 'created_at': datetime.datetime(2024, 12, 1, 3, 15, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2509731479, 'issue_id': 2651163190, 'author': 'kaxil', 'body': '> Greetings, I was away for the holidays. Thank you all for review!\r\n> \r\n> @kaxil Thank you for resolving the conflict. Can you please tell me what it was?\r\n\r\nHi @geraj1010 , I hope you had a good holiday. Your base branch was 1000 commits behind the Airflow main -- Example: https://github.com/apache/airflow/commits/39ebd75c5cb066218a2b6b3940eddc217dd816d9/docs/sphinx_design/static/custom.css -- your branch\'s base commit was from December 2023 -- so rebased on the main branch.\r\n\r\n<img width=""718"" alt=""image"" src=""https://github.com/user-attachments/assets/dccf8aef-d95b-4c93-aa43-6aed31160571"">', 'created_at': datetime.datetime(2024, 12, 1, 11, 52, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2510200587, 'issue_id': 2651163190, 'author': 'geraj1010', 'body': ""> > Greetings, I was away for the holidays. Thank you all for review!\r\n> > @kaxil Thank you for resolving the conflict. Can you please tell me what it was?\r\n> \r\n> Hi @geraj1010 , I hope you had a good holiday. Your base branch was 1000 commits behind the Airflow main -- Example: https://github.com/apache/airflow/commits/39ebd75c5cb066218a2b6b3940eddc217dd816d9/docs/sphinx_design/static/custom.css -- your branch's base commit was from December 2023 -- so rebased on the main branch.\r\n\r\nAhh I see! I wonder how that happened? I've only started contributing in August 2024. Maybe I forked the repo incorrectly?"", 'created_at': datetime.datetime(2024, 12, 1, 18, 35, 27, tzinfo=datetime.timezone.utc)}]","ashb on (2024-11-12 09:31:13 UTC): Could you include before and after pics please?

And if we use `.. warning::` anywhere else before and after of one those too please

kaxil on (2024-11-12 21:31:34 UTC): Screenshots are here: https://github.com/apache/airflow/issues/41532#issuecomment-2467139167

geraj1010 (Issue Creator) on (2024-11-13 04:51:26 UTC): **For `BigQueryExecuteQueryOperator`:**

**Before:**
<img width=""628"" alt=""image"" src=""https://github.com/user-attachments/assets/4ac926d8-9a7e-4565-8ced-deddac061a91"">

**After:**
<img width=""608"" alt=""image"" src=""https://github.com/user-attachments/assets/8b1f6609-8f53-440e-b7de-bb68e3d398ba"">






There are other operators that use `.. warning::` in their docstring, here is `CloudDataTransferServiceCreateJobOperator`

**Before:**
<img width=""609"" alt=""image"" src=""https://github.com/user-attachments/assets/29d62ef0-22ac-4ba3-8ef0-5ced4f3d0edc"">

**After:**
<img width=""608"" alt=""image"" src=""https://github.com/user-attachments/assets/1cc619ce-eb8c-4698-a8d1-a12c18be7b5e"">





So the styling appears to apply to all docstrings, which use the `.. warning::` admonition (since the CSS is in `docs/sphinx_design/static/custom.css`) . If that is an issue, I could create a `.css` specifically for Google Providers if that helps. Then that would restrict the styling to Google Providers.

geraj1010 (Issue Creator) on (2024-11-15 05:32:12 UTC): @ashb Did I provide enough screenshots? Are there any other concerns?

kaxil on (2024-11-15 13:24:59 UTC): We should do the same for all deprecated operators too

geraj1010 (Issue Creator) on (2024-11-15 23:03:25 UTC): That would be great. I could go through and apply this update to all deprecated operators. Unfortunately, it's a manual effort. I did mention something about extending the Sphinx `AutoAPI` extension (https://github.com/apache/airflow/issues/41532#issuecomment-2472688497), but that would take more work for sure.

potiuk on (2024-11-28 03:10:16 UTC): You need to rebase/resolve conflicts @geraj1010

omkar-foss on (2024-11-28 07:13:53 UTC): No problem, I can help with applying this update to all deprecated operators.

@kaxil @potiuk Shall I raise a separate PR with commits from this PR or something else, please let me know. Thank you :)

potiuk on (2024-11-28 12:38:29 UTC): If @geraj1010 is ok with it, absolutely - feel free.

kaxil on (2024-11-28 12:38:42 UTC): I think we can merge this one to credit @geraj1010

kaxil on (2024-11-29 00:53:13 UTC): I resolved the conflict, and merged

kaxil on (2024-11-29 00:53:34 UTC): Verified it locally:

<img width=""1108"" alt=""image"" src=""https://github.com/user-attachments/assets/bb02a45f-2f6b-438f-af36-355fb20aef90"">

kaxil on (2024-11-29 00:54:48 UTC): @eladkal Worth including this change in the next batch of providers

omkar-foss on (2024-11-29 14:31:40 UTC): Thanks a lot for looking into this @kaxil, and kudos @geraj1010 for this PR!

I've raised https://github.com/apache/airflow/pull/44479 to use the warning block wherever applicable, so that we can show these prominent deprecation warnings consistently across Airflow docs. Cheers.

geraj1010 (Issue Creator) on (2024-12-01 03:12:30 UTC): My pleasure!

geraj1010 (Issue Creator) on (2024-12-01 03:15:01 UTC): Greetings, I was away for the holidays. Thank you all for review!

@kaxil Thank you for resolving the conflict. Can you please tell me what it was?

kaxil on (2024-12-01 11:52:39 UTC): Hi @geraj1010 , I hope you had a good holiday. Your base branch was 1000 commits behind the Airflow main -- Example: https://github.com/apache/airflow/commits/39ebd75c5cb066218a2b6b3940eddc217dd816d9/docs/sphinx_design/static/custom.css -- your branch's base commit was from December 2023 -- so rebased on the main branch.

<img width=""718"" alt=""image"" src=""https://github.com/user-attachments/assets/dccf8aef-d95b-4c93-aa43-6aed31160571"">

geraj1010 (Issue Creator) on (2024-12-01 18:35:27 UTC): Ahh I see! I wonder how that happened? I've only started contributing in August 2024. Maybe I forked the repo incorrectly?

"
2651074010,pull_request,closed,,Fix CI ruff format static checks,"Fixing static checks failures.

https://github.com/apache/airflow/actions/runs/11789272591/job/32838092271#step:8:221
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-12 05:31:52+00:00,[],2024-11-12 06:10:25+00:00,2024-11-12 06:10:17+00:00,https://github.com/apache/airflow/pull/43908,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:apache-hdfs', '')]",[],
2650765082,pull_request,closed,,Remove missed DAG pickling code,"Follow-up of https://github.com/apache/airflow/pull/43667

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-12 01:29:21+00:00,[],2024-11-12 14:28:51+00:00,2024-11-12 14:28:49+00:00,https://github.com/apache/airflow/pull/43907,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-sdk', None)]",[],
2650745828,pull_request,closed,,Remove XCom pickling,"XCom pickling was disabled by default in Airflow 2.0.0: https://airflow.apache.org/docs/apache-airflow/1.10.15/configurations-ref.html#enable-xcom-pickling

## Discussion
To avoid a time-consuming DB migration, I have not changed the column type of `value`; it is still `LargeBinary`/`LONGBLOB` (MySQL).

As part of Airflow 3, we should strongly recommend users to use the `airflow db clean` command to prune the DBs to the minimum required. If we assume, most users would do that, we can run the following migration:

### Option 1: Try to migrate pickle to JSON
```python
def upgrade():
    bind = op.get_bind()
    session = Session(bind=bind)

    for row in session.query(XCom).all():
        try:
            unpickled_data = pickle.loads(row.value)
            row.value = json.dumps(unpickled_data).encode('utf-8')
        except (pickle.UnpicklingError, json.JSONDecodeError):
            # If unpickling fails, assume it's already JSON and skip
            continue

    op.alter_column(""xcom"", ""value"", type_=sa.Text)
``` 

### Option 2: Delete XCom rows with pickle

```python
from airflow.models.xcom import BaseXCom

def upgrade():
    bind = op.get_bind()
    session = Session(bind=bind)

    pickled_xcoms = session.query(BaseXCom).filter(BaseXCom.value.isnot(None))
    
    deleted_count = 0
    for xcom in pickled_xcoms:
        if xcom.value.startswith(b'\x80'):  # Identify as pickled by protocol marker: https://github.com/python/cpython/blob/494360afd00dc8f6b549f160525c3e86ec14905d/Lib/pickletools.py#L2122-L2133
            session.delete(xcom)

```

### Option 3: Keep the current column type

Not optimal, but we can keep the current column type to binary/long-blob

Any thoughts?

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-12 01:08:55+00:00,[],2024-11-18 23:57:53+00:00,2024-11-18 17:44:29+00:00,https://github.com/apache/airflow/pull/43905,"[('area:API', ""Airflow's REST/HTTP API""), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2470384240, 'issue_id': 2650745828, 'author': 'pgagnon', 'body': ""@kaxil \r\n\r\n> Option 1: Try to migrate pickle to JSON\r\n\r\n```# If unpickling fails, assume it's already JSON and skip```\r\n\r\nIf JSON decoding fails, maybe we could save the value in a backup blob field (to be deprecated and removed in a specified future version).\r\n\r\nWhile XComs are _generally_ not that important I feel it might be better to soft-delete wherever there's a risk of data loss as a general practice."", 'created_at': datetime.datetime(2024, 11, 12, 12, 18, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471401861, 'issue_id': 2650745828, 'author': 'jscheffl', 'body': 'I like the drop of the pickle type - but I\'d favor not keeping this as blob/binary in the DB. Then we can not use any DB feature to efficiently ""use"" the data other than a blob.\r\n\r\nIf not in this PR, can we have a follow-up that converts the data into `json` data type as described in https://www.postgresql.org/docs/17/datatype-json.html ?\r\n\r\n(MySQL is: https://dev.mysql.com/doc/refman/8.4/en/json.html)\r\n\r\nAnd totally forgot about the vote: I think we can also consider to provide an offline migration tool which we request to be executed by everybody manually prior upgrade such that we don\'t need to carry complex inline migration. Everybody who uses XCom pickling should know this from the config. So Option 1 or Option 1a (a=offline tool)', 'created_at': datetime.datetime(2024, 11, 12, 19, 33, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483474045, 'issue_id': 2650745828, 'author': 'kaxil', 'body': 'I will create a separate PR to handle the migration so that can be reviewed independently -- will have a PR by EOD today', 'created_at': datetime.datetime(2024, 11, 18, 16, 4, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2484417123, 'issue_id': 2650745828, 'author': 'kaxil', 'body': 'PR created: https://github.com/apache/airflow/pull/44166', 'created_at': datetime.datetime(2024, 11, 18, 23, 57, 52, tzinfo=datetime.timezone.utc)}]","pgagnon on (2024-11-12 12:18:35 UTC): @kaxil 


```# If unpickling fails, assume it's already JSON and skip```

If JSON decoding fails, maybe we could save the value in a backup blob field (to be deprecated and removed in a specified future version).

While XComs are _generally_ not that important I feel it might be better to soft-delete wherever there's a risk of data loss as a general practice.

jscheffl on (2024-11-12 19:33:56 UTC): I like the drop of the pickle type - but I'd favor not keeping this as blob/binary in the DB. Then we can not use any DB feature to efficiently ""use"" the data other than a blob.

If not in this PR, can we have a follow-up that converts the data into `json` data type as described in https://www.postgresql.org/docs/17/datatype-json.html ?

(MySQL is: https://dev.mysql.com/doc/refman/8.4/en/json.html)

And totally forgot about the vote: I think we can also consider to provide an offline migration tool which we request to be executed by everybody manually prior upgrade such that we don't need to carry complex inline migration. Everybody who uses XCom pickling should know this from the config. So Option 1 or Option 1a (a=offline tool)

kaxil (Issue Creator) on (2024-11-18 16:04:45 UTC): I will create a separate PR to handle the migration so that can be reviewed independently -- will have a PR by EOD today

kaxil (Issue Creator) on (2024-11-18 23:57:52 UTC): PR created: https://github.com/apache/airflow/pull/44166

"
2650681826,pull_request,closed,,Add `pdbr` as devel debuggers,"https://github.com/cansarigol/pdbr - I regularly use it and love it and I am sure others would love it too in breeze.

It has niceties of pdb with `rich`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-12 00:01:04+00:00,[],2024-11-12 01:19:05+00:00,2024-11-12 01:19:04+00:00,https://github.com/apache/airflow/pull/43904,[],"[{'comment_id': 2469341365, 'issue_id': 2650681826, 'author': 'potiuk', 'body': 'Nice. never used it but might be a good idea :)', 'created_at': datetime.datetime(2024, 11, 12, 0, 21, 51, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-12 00:21:51 UTC): Nice. never used it but might be a good idea :)

"
2650670566,pull_request,closed,,Bump ruff to `0.7.3`,"https://pypi.org/project/ruff/0.7.3/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-11 23:51:54+00:00,[],2024-11-12 01:21:16+00:00,2024-11-12 01:21:14+00:00,https://github.com/apache/airflow/pull/43903,"[('area:dev-tools', '')]",[],
2650665014,pull_request,closed,,Rename execution_date to logical_date across codebase,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

### **Motivation**
This PR renames `execution_date` to `logical_date` across the codebase.  The shift towards `logical_date` helps move away from the limitations of `execution_date`, particularly with dynamic DAG runs and cases where multiple runs occur at the same time.

### **Key Changes**
- Replaced all instances of `execution_date` with `logical_date` including models.
- Updated references in database models, templates, and functions.
- Removed unique constraints on `execution_date` in the database to allow multiple DAG runs with the same logical time.

### **How `execution_date` and `logical_date` Work**
1. **Logical date is equivalent to execution date**: The two are just different names for the same value.
2. **Timetable controls logical date**: The logical date can be set to any value, not necessarily tied to the data interval's start or end.
3. **Schedules dictate behavior**: For value-based schedules (like cron), the logical date is set by the timetable class used.

### **Transitioning from `execution_date`**
- Airflow 3.0 will fully remove `execution_date`.
- For uniquely identifying runs:
  - Use `run_id` for human-readable identifiers.
  - Use `data_interval_start`/`data_interval_end` for data partitioning in future.
  - `id` (auto-incremented) is recommended for ordering DAG runs.
- If your existing logic relies on `execution_date`, switch to using `data_interval_start` or `data_interval_end` for identifying time ranges.

### **Testing**
- Updated unit tests to reflect the changes.

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sunank200,2024-11-11 23:47:17+00:00,[],2024-11-25 05:34:58+00:00,2024-11-15 09:15:46+00:00,https://github.com/apache/airflow/pull/43902,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('AIP-83', 'Remove Execution Date Unique Constraint from DAG Run'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2469587869, 'issue_id': 2650665014, 'author': 'uranusjr', 'body': 'This needs a news fragment. Rewording the above summary would work fine. See existing files in `newsfragments` (the `significant` ones) for some examples.', 'created_at': datetime.datetime(2024, 11, 12, 4, 39, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469589009, 'issue_id': 2650665014, 'author': 'uranusjr', 'body': '> For templates, replace `{{ ds }}` with `{{ data_interval_start | ds }}`.\r\n\r\n~~This should probably use `logical_date` for max compatibility. Also should mention `ts` (same rewrite).~~\r\n\r\nOh wait, we’re not removing those in this PR yet, so this should not be mentioned at all.', 'created_at': datetime.datetime(2024, 11, 12, 4, 40, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469907149, 'issue_id': 2650665014, 'author': 'eladkal', 'body': 'Is this change backward compatible for all providers?', 'created_at': datetime.datetime(2024, 11, 12, 8, 38, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469928527, 'issue_id': 2650665014, 'author': 'uranusjr', 'body': 'Providers don’t generally use `execution_date`; in the rare cases they do, a compatibility layer is provided so they work on both Airflow 2 and 3. No official providers have interface that expose `execution_date` to the user.', 'created_at': datetime.datetime(2024, 11, 12, 8, 49, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470118445, 'issue_id': 2650665014, 'author': 'potiuk', 'body': '> Providers don’t generally use `execution_date`; in the rare cases they do, a compatibility layer is provided so they work on both Airflow 2 and 3. No official providers have interface that expose `execution_date` to the user.\r\n\r\nYeah. I think we need to bite the bullet and change it - even if we know that **some** things outside of our providers will be broken. Our compat tests are passing, which means that the change is ""good to go"" from our provider\'s point of view, but we should add this change to be listed in https://github.com/apache/airflow/issues/41641 so that we remember there is a 2 to 3 migration rule that will check if execution_date is still not used somewhwere in the user code when they are attempting to migrate.', 'created_at': datetime.datetime(2024, 11, 12, 10, 10, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471650423, 'issue_id': 2650665014, 'author': 'sunank200', 'body': '> The shift towards `logical_date` helps move away from the limitations of `execution_date`, particularly with dynamic DAG runs and cases where multiple runs occur at the same time.\r\n\r\nAdded the newsfragment', 'created_at': datetime.datetime(2024, 11, 12, 21, 46, 49, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-11-12 04:39:29 UTC): This needs a news fragment. Rewording the above summary would work fine. See existing files in `newsfragments` (the `significant` ones) for some examples.

uranusjr on (2024-11-12 04:40:43 UTC): ~~This should probably use `logical_date` for max compatibility. Also should mention `ts` (same rewrite).~~

Oh wait, we’re not removing those in this PR yet, so this should not be mentioned at all.

eladkal on (2024-11-12 08:38:55 UTC): Is this change backward compatible for all providers?

uranusjr on (2024-11-12 08:49:07 UTC): Providers don’t generally use `execution_date`; in the rare cases they do, a compatibility layer is provided so they work on both Airflow 2 and 3. No official providers have interface that expose `execution_date` to the user.

potiuk on (2024-11-12 10:10:40 UTC): Yeah. I think we need to bite the bullet and change it - even if we know that **some** things outside of our providers will be broken. Our compat tests are passing, which means that the change is ""good to go"" from our provider's point of view, but we should add this change to be listed in https://github.com/apache/airflow/issues/41641 so that we remember there is a 2 to 3 migration rule that will check if execution_date is still not used somewhwere in the user code when they are attempting to migrate.

sunank200 (Issue Creator) on (2024-11-12 21:46:49 UTC): Added the newsfragment

"
2650602004,pull_request,closed,, Correct mime-type in OpenAPI spec (#43879),Backport of #43879 to v2-10-test,jscheffl,2024-11-11 23:05:34+00:00,[],2024-11-12 00:46:05+00:00,2024-11-12 00:46:05+00:00,https://github.com/apache/airflow/pull/43901,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2650591416,pull_request,closed,,Upgrade tomli as build dependency,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-11 22:56:35+00:00,[],2024-11-12 00:19:41+00:00,2024-11-12 00:19:39+00:00,https://github.com/apache/airflow/pull/43900,[],[],
2650406042,pull_request,closed,,Fix completion/linting/type checking with VSCode/pyright,"Pyright (the type engine powering VSCode's python extension) doesn't treat
`airflow` as a namespace package because of the `airflow/__init__.py` and it
doesn't want to/can't support detecting the `__path__ = ...` method of making
it an explicit namespace package, so we are left with no option but to create
Yet Another Stub File.

Tested by pytting `reveal_type(FAB_VERSION); reveal_type(TaskSDKDag)` inside
`_upgrade_outdated_dag_access_control` in `airflow/model/dag.py` -- before
this change it was reporting both as Unknown.
",ashb,2024-11-11 21:11:22+00:00,[],2024-11-12 12:09:22+00:00,2024-11-12 12:09:19+00:00,https://github.com/apache/airflow/pull/43899,"[('area:providers', ''), ('area:task-sdk', None)]","[{'comment_id': 2469028592, 'issue_id': 2650406042, 'author': 'ashb', 'body': 'cc @JDarDagran', 'created_at': datetime.datetime(2024, 11, 11, 21, 12, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470050050, 'issue_id': 2650406042, 'author': 'ashb', 'body': ""Okay sadly we can't do this. By creating this empty file pycharm thinks `airflow` is an empty module.\r\n\r\nOkay, think I might have it fixed now."", 'created_at': datetime.datetime(2024, 11, 12, 9, 40, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470290746, 'issue_id': 2650406042, 'author': 'ashb', 'body': 'Static check failure unrelated and will be fixed by #43923', 'created_at': datetime.datetime(2024, 11, 12, 11, 31, 52, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2024-11-11 21:12:27 UTC): cc @JDarDagran

ashb (Issue Creator) on (2024-11-12 09:40:32 UTC): Okay sadly we can't do this. By creating this empty file pycharm thinks `airflow` is an empty module.

Okay, think I might have it fixed now.

ashb (Issue Creator) on (2024-11-12 11:31:52 UTC): Static check failure unrelated and will be fixed by #43923

"
2650337385,pull_request,closed,,Change Airflow Backcompat provider tests to 2.10.3,I just noticed by accident that our back-compar provider tests still test against 2.10.1... so this PR updates to 2.10.3,jscheffl,2024-11-11 20:31:42+00:00,[],2024-11-12 00:16:38+00:00,2024-11-11 23:01:52+00:00,https://github.com/apache/airflow/pull/43898,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2469336260, 'issue_id': 2650337385, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 12, 0, 16, 36, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-12 00:16:36 UTC): Nice!

"
2650298301,pull_request,closed,,Added support for job_parameters and dbt_commands in DatabricksRunNow Operator,"- Added support for job_parameters and dbt_commands in DatabricksRunNow Operator
- Added tests

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pranshupand-db,2024-11-11 20:13:10+00:00,[],2024-11-12 12:30:50+00:00,2024-11-12 12:30:46+00:00,https://github.com/apache/airflow/pull/43895,"[('area:providers', ''), ('provider:databricks', '')]","[{'comment_id': 2468949756, 'issue_id': 2650298301, 'author': 'pranshupand-db', 'body': '@potiuk Please merge this, I have created a fresh pr for the change.', 'created_at': datetime.datetime(2024, 11, 11, 20, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470409205, 'issue_id': 2650298301, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 12, 12, 30, 48, tzinfo=datetime.timezone.utc)}]","pranshupand-db (Issue Creator) on (2024-11-11 20:14:00 UTC): @potiuk Please merge this, I have created a fresh pr for the change.

boring-cyborg[bot] on (2024-11-12 12:30:48 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2650207099,pull_request,closed,,"AIP-72: Add ""XCom"" GET endpoint for Execution API","closes https://github.com/apache/airflow/issues/43839
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-11 19:32:19+00:00,[],2024-11-12 12:35:52+00:00,2024-11-12 12:35:50+00:00,https://github.com/apache/airflow/pull/43894,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2650122028,pull_request,closed,,Start building the replacement task runner for Task Execution SDK,"The eventual goal of this ""airflow.sdk.exeuction_time"" package is to replace
LocalTaskJob and StandardTaskRunner, but at this stage it co-exists with it's
replacement.

As this PR is not a complete re-implementation of all the features that exist
currently (no handling of task level callbacks yet, no AirflowSkipException
etc.) the current tests are skeleton at best. Once we get closer to feature
parity (in future PRs) the tests will grow to match.

This supervisor and task runner operates slightly differently to the current
classes in these ways

**Logs from the subprocess are send over a different channel to stdout/stderr**

This makes the task supervisor a little bit more complex as it now has to
read stdout, stderr and a logs channel. The advantage of this approach is
that it makes the logs setup in the task process itself markedly simpler --
all it has to do is write logs output to the custom file handle as JSON and
it will show up ""natively"" as logs.

structlog has been chosen as the logging engine over stdlib's own logging as
the ability to have structured fields in the logs is nice, and stdlib is
configured to send logs to a stuctlog processor.

**Direct database access is replaced with an HTTP API client**

This is the crux of this feature and of AIP-72 in general -- tasks run via
this runner can no longer access DB models or DB session directly. This PR
doesn't yet implement the code/shims to make `Connection.get_connection_from_secrets`
use this client yet - that will be future work.

The reason tasks don't speak directly to the API server is primarily for two
reasons:

1. The supervisor process already needs to maintain an http session in order
   to report the task as started, to heart beat it, and to mark it as
   finished; and so because of that
2. Reduce the number of active HTTP connections for tasks to 1 per task
   (instead of 2 per task).

THe other reason we have this interface is that DAG parsing code will very
soon need to be updated to not have direct DB access either, and having this
""in process"" interface ability already means that we can support commands like
`airflow dags reserialize` without having a running API server.

The API client itself is not auto-generated: I tried a number of different
client generates based on the OpenAPI spec and found them all lacking or buggy
in different ways, and the http client side itself is very simple, the only
interesting/difficult bit is the generation of the datamodels from the OpenAPI
spec which I found one that

msgspec was chosen over Pydantic as it is much lighter weight (and thus
quicker), especially on a client side when we have next to no validation
requirements of response data. I admit that I have not benchmarked it
specifically though.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2024-11-11 18:51:08+00:00,[],2024-11-14 14:32:49+00:00,2024-11-14 14:31:51+00:00,https://github.com/apache/airflow/pull/43893,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2469341673, 'issue_id': 2650122028, 'author': 'raphaelauv', 'body': ""do you plan to make `runner` mode customizable at task level ( like executor ) ?\r\n\r\ncause I have multiple `operational` pythonoperator that manage heavy database operations like this \r\n\r\n```python\r\n    def clear_dag_runs(dag_id, status_to_clear):\r\n        context = get_current_context()\r\n        session = settings.Session()\r\n\r\n        query = session.query(DagRun).filter(\r\n            DagRun.state == status_to_clear, DagRun.dag_id == dag_id)\r\n        rst = query.all()\r\n\r\n        dag_bag = DagBag(dag_folder=path.join(SRC_FOLDER, 'dags'), include_examples=False)\r\n        dag: DAG = dag_bag.get_dag(dag_id, session)\r\n\r\n        for dag_run in rst:\r\n            dag.clear(\r\n                start_date=dag_run.logical_date,\r\n                end_date=dag_run.logical_date,\r\n                task_ids=None,\r\n                include_subdags=True,\r\n                include_parentdag=True,\r\n                only_failed=False,\r\n            )\r\n        session.close()\r\n```"", 'created_at': datetime.datetime(2024, 11, 12, 0, 22, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470335901, 'issue_id': 2650122028, 'author': 'ashb', 'body': '> do you plan to make `runner` mode customizable at task level ( like executor ) ?\r\n> \r\n> cause I have multiple `operational` pythonoperator that manage heavy database operations like this\r\n\r\n@raphaelauv No plans today. This is not something in scope for AIP-72 (nor is it possible today)', 'created_at': datetime.datetime(2024, 11, 12, 11, 54, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471500404, 'issue_id': 2650122028, 'author': 'ashb', 'body': '> lgtm. Worth splitting certain methods/func into more granular funcs and adding more docstrings wherever you can.\r\n\r\nFor sure, I will do that before merging and ping you tomrorow for another look', 'created_at': datetime.datetime(2024, 11, 12, 20, 18, 42, tzinfo=datetime.timezone.utc)}]","raphaelauv on (2024-11-12 00:22:11 UTC): do you plan to make `runner` mode customizable at task level ( like executor ) ?

cause I have multiple `operational` pythonoperator that manage heavy database operations like this 

```python
    def clear_dag_runs(dag_id, status_to_clear):
        context = get_current_context()
        session = settings.Session()

        query = session.query(DagRun).filter(
            DagRun.state == status_to_clear, DagRun.dag_id == dag_id)
        rst = query.all()

        dag_bag = DagBag(dag_folder=path.join(SRC_FOLDER, 'dags'), include_examples=False)
        dag: DAG = dag_bag.get_dag(dag_id, session)

        for dag_run in rst:
            dag.clear(
                start_date=dag_run.logical_date,
                end_date=dag_run.logical_date,
                task_ids=None,
                include_subdags=True,
                include_parentdag=True,
                only_failed=False,
            )
        session.close()
```

ashb (Issue Creator) on (2024-11-12 11:54:32 UTC): @raphaelauv No plans today. This is not something in scope for AIP-72 (nor is it possible today)

ashb (Issue Creator) on (2024-11-12 20:18:42 UTC): For sure, I will do that before merging and ping you tomrorow for another look

"
2650075517,pull_request,closed,,Fix duplication of Task tries in the UI,"It was observed that there are moments where the TI tries endpoint returns duplicate TaskInstance. I have observed this to happen when the TI is in up_for_retry state.

When the TI is in up_for_retry state, we have already recorded the previous try in TI history and the TI try_number has not incremented at this time, so we must exclude this recorded TI from the taskinstance tries endpoint. We know the TI because its state is in up_for_retry, so we filter TIs with up_for_retry state when querying for the task instance tries.

Closes: #41765

",ephraimbuddy,2024-11-11 18:34:55+00:00,[],2024-11-12 07:29:21+00:00,2024-11-12 00:08:55+00:00,https://github.com/apache/airflow/pull/43891,"[('area:API', ""Airflow's REST/HTTP API""), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2649899759,pull_request,closed,,Move filesystem sensor to standard provider,"Move filesystem sensor to standard provider, relates to #43641.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-11-11 17:05:38+00:00,[],2024-11-17 23:16:17+00:00,2024-11-17 15:53:30+00:00,https://github.com/apache/airflow/pull/43890,"[('area:CLI', ''), ('area:providers', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2481666963, 'issue_id': 2649899759, 'author': 'potiuk', 'body': 'nice!', 'created_at': datetime.datetime(2024, 11, 17, 23, 16, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-17 23:16:16 UTC): nice!

"
2649896943,pull_request,closed,,Fix standard provider how to guide section,"Updating how to guide section with doc references for standard provider.

Static checks are failing with this https://github.com/apache/airflow/actions/runs/11782299839/job/32817391596?pr=43886#step:8:1341 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-11 17:04:02+00:00,[],2024-11-11 17:30:53+00:00,2024-11-11 17:30:46+00:00,https://github.com/apache/airflow/pull/43889,"[('area:providers', ''), ('provider:standard', '')]",[],
2649690862,pull_request,closed,,Add dag run and task instance metrics to dashboard.,"Related #42700

Adds dag run and task instance metrics from historical metrics endpoint to dashboard.

* The bar charts will be added later once API is available.
* Checkboxes are missing. It seems in chakra 3 adding a components takes a few more steps.
* State colors are of more contrast and might need to be toned down.
* Some padding to center text in the status box. Probably there should be some bubble text type of component.
* Currently the select box has preset hours shown to users at last 1, 8, 12 and 24 hours. This can be a component where users can select date time freely on their own. Probably need to see if this needs to be limited since using 30 days might take a lot of time to query and render the plot.

![image](https://github.com/user-attachments/assets/b39633c5-9f89-40d9-b114-6145c1ae658c)
![image](https://github.com/user-attachments/assets/1ef60017-40a3-4aa5-9a26-ac2ef6551764)
",tirkarthi,2024-11-11 15:35:24+00:00,[],2024-11-14 18:05:10+00:00,2024-11-14 16:33:13+00:00,https://github.com/apache/airflow/pull/43888,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2468544813, 'issue_id': 2649690862, 'author': 'bbovenzi', 'body': ""Nice start!\r\n\r\nA few other thoughts:\r\n- In a separate PR, I definitely need to adjust the task colors because they do not work in both light and dark mode.\r\n- Let's use a more subtle color for the percentage bars\r\n- We need a bit more vertical space under the titles of each section\r\n- Eventually, we need a full date range selector instead of just a few preset dropdown options"", 'created_at': datetime.datetime(2024, 11, 11, 16, 15, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468713944, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': ""Thanks @bbovenzi for the comments. Did the following changes.\r\n\r\n1. Refactored `Metrics.tsx` to `HistoricalMetrics` folder with one component per file.\r\n2. Updated colors to use semantic codes.\r\n3. Added a custom badge component that can be updated so that the badge looks same across the components.\r\n\r\n> Eventually, we need a full date range selector instead of just a few preset dropdown options\r\n\r\nAgreed, it looks like Chakra doesn't have a datepicker component. So something like https://www.npmjs.com/package/react-datepicker can be used or one of the options from the discussion https://github.com/chakra-ui/chakra-ui/issues/580 . The datepicker can be a general component since it will be used across the app.\r\n\r\nFeel free to push to the branch if you have any changes directly too. Thanks."", 'created_at': datetime.datetime(2024, 11, 11, 17, 41, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470881736, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': 'Applied all the PR comments locally and rebased with latest main branch. Thanks.', 'created_at': datetime.datetime(2024, 11, 12, 15, 44, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470918516, 'issue_id': 2649690862, 'author': 'pierrejeambrun', 'body': 'Are screenshots up to date following latest changes ? Just to get a rough idea of the rendered UI.', 'created_at': datetime.datetime(2024, 11, 12, 15, 59, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470927953, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': 'Latest screenshots after the review changes. Most of it has been moving `Metrics.tsx` to `HistoricalMetrics` with one component per file. Moving from text customization to using `Badge` and a few text size, padding, margin changes.\r\n\r\n![image](https://github.com/user-attachments/assets/3e95ff72-cac5-4d3a-ac71-80a7b424a3ae)\r\n\r\n![image](https://github.com/user-attachments/assets/c458055c-0961-4f6f-a538-97a2770de244)', 'created_at': datetime.datetime(2024, 11, 12, 16, 3, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470936601, 'issue_id': 2649690862, 'author': 'pierrejeambrun', 'body': ""Looking nice.\r\n\r\nJust a minor nit, it looks like the number in the badge is not centered vertically. Maybe that's just because of the screenshot but it looks slightly off."", 'created_at': datetime.datetime(2024, 11, 12, 16, 6, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470960825, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': ""Yes, in the layout tab for the badge WxH is 15.5667×20 in Firefox on Ubuntu for me. I can see the centering not correct in inspect toolbar. The padding is equally applied at the y-axis with `py={1}` . @bbovenzi mentioned the same in the comment but couldn't figure out the right change in CSS.\r\n\r\nhttps://github.com/apache/airflow/pull/43888#discussion_r1836903396"", 'created_at': datetime.datetime(2024, 11, 12, 16, 15, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471007219, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': 'It appears okay in Brave on Ubuntu. Probably a Firefox/Linux issue as many have reported it in https://github.com/chakra-ui/chakra-ui/issues/983 , https://github.com/chakra-ui/chakra-ui/issues/2314\r\n\r\n![localhost_8000_webapp_ (1)](https://github.com/user-attachments/assets/255f1923-34fb-4823-9831-b4dcc5708c37)', 'created_at': datetime.datetime(2024, 11, 12, 16, 33, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471089691, 'issue_id': 2649690862, 'author': 'pierrejeambrun', 'body': '> It appears okay in Brave on Ubuntu. Probably a Firefox/Linux issue as many have reported it.\r\n\r\nNice to hear, thanks for investigating.', 'created_at': datetime.datetime(2024, 11, 12, 16, 59, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476003286, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': ""Thanks @bbovenzi for the feedback. Made the below changes as per latest review.\r\n\r\n1. Simple skeleton for dagrun and task instance sections. A better one would be using `SkeletonCircle` for badge and `SkeletonText` for the bar for each state in https://www.chakra-ui.com/docs/components/skeleton . I can take it up in another PR since it's not urgent.\r\n\r\n![image](https://github.com/user-attachments/assets/6059f06e-a966-400b-84bb-8f636caae0c3)\r\n\r\n2. I have refactored the datetime selector into a separate component. I would like to access the state changes to `startDate` and `endDate` to pass to API. I had tried to use the pattern as per state lifting docs. Please let me know if there is any other correct approach. https://react.dev/learn/sharing-state-between-components .\r\n\r\n3. I will make the changes related to `end_date` being null once the PR changes are merged and not to block this PR."", 'created_at': datetime.datetime(2024, 11, 14, 10, 41, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476885401, 'issue_id': 2649690862, 'author': 'bbovenzi', 'body': 'Lgtm! We can iterate on a more detailed loading state and update `end_date` later.', 'created_at': datetime.datetime(2024, 11, 14, 16, 33, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476902341, 'issue_id': 2649690862, 'author': 'tirkarthi', 'body': 'Thanks @bbovenzi and @pierrejeambrun .', 'created_at': datetime.datetime(2024, 11, 14, 16, 38, 47, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-11-11 16:15:17 UTC): Nice start!

A few other thoughts:
- In a separate PR, I definitely need to adjust the task colors because they do not work in both light and dark mode.
- Let's use a more subtle color for the percentage bars
- We need a bit more vertical space under the titles of each section
- Eventually, we need a full date range selector instead of just a few preset dropdown options

tirkarthi (Issue Creator) on (2024-11-11 17:41:17 UTC): Thanks @bbovenzi for the comments. Did the following changes.

1. Refactored `Metrics.tsx` to `HistoricalMetrics` folder with one component per file.
2. Updated colors to use semantic codes.
3. Added a custom badge component that can be updated so that the badge looks same across the components.


Agreed, it looks like Chakra doesn't have a datepicker component. So something like https://www.npmjs.com/package/react-datepicker can be used or one of the options from the discussion https://github.com/chakra-ui/chakra-ui/issues/580 . The datepicker can be a general component since it will be used across the app.

Feel free to push to the branch if you have any changes directly too. Thanks.

tirkarthi (Issue Creator) on (2024-11-12 15:44:34 UTC): Applied all the PR comments locally and rebased with latest main branch. Thanks.

pierrejeambrun on (2024-11-12 15:59:17 UTC): Are screenshots up to date following latest changes ? Just to get a rough idea of the rendered UI.

tirkarthi (Issue Creator) on (2024-11-12 16:03:04 UTC): Latest screenshots after the review changes. Most of it has been moving `Metrics.tsx` to `HistoricalMetrics` with one component per file. Moving from text customization to using `Badge` and a few text size, padding, margin changes.

![image](https://github.com/user-attachments/assets/3e95ff72-cac5-4d3a-ac71-80a7b424a3ae)

![image](https://github.com/user-attachments/assets/c458055c-0961-4f6f-a538-97a2770de244)

pierrejeambrun on (2024-11-12 16:06:29 UTC): Looking nice.

Just a minor nit, it looks like the number in the badge is not centered vertically. Maybe that's just because of the screenshot but it looks slightly off.

tirkarthi (Issue Creator) on (2024-11-12 16:15:56 UTC): Yes, in the layout tab for the badge WxH is 15.5667×20 in Firefox on Ubuntu for me. I can see the centering not correct in inspect toolbar. The padding is equally applied at the y-axis with `py={1}` . @bbovenzi mentioned the same in the comment but couldn't figure out the right change in CSS.

https://github.com/apache/airflow/pull/43888#discussion_r1836903396

tirkarthi (Issue Creator) on (2024-11-12 16:33:31 UTC): It appears okay in Brave on Ubuntu. Probably a Firefox/Linux issue as many have reported it in https://github.com/chakra-ui/chakra-ui/issues/983 , https://github.com/chakra-ui/chakra-ui/issues/2314

![localhost_8000_webapp_ (1)](https://github.com/user-attachments/assets/255f1923-34fb-4823-9831-b4dcc5708c37)

pierrejeambrun on (2024-11-12 16:59:58 UTC): Nice to hear, thanks for investigating.

tirkarthi (Issue Creator) on (2024-11-14 10:41:22 UTC): Thanks @bbovenzi for the feedback. Made the below changes as per latest review.

1. Simple skeleton for dagrun and task instance sections. A better one would be using `SkeletonCircle` for badge and `SkeletonText` for the bar for each state in https://www.chakra-ui.com/docs/components/skeleton . I can take it up in another PR since it's not urgent.

![image](https://github.com/user-attachments/assets/6059f06e-a966-400b-84bb-8f636caae0c3)

2. I have refactored the datetime selector into a separate component. I would like to access the state changes to `startDate` and `endDate` to pass to API. I had tried to use the pattern as per state lifting docs. Please let me know if there is any other correct approach. https://react.dev/learn/sharing-state-between-components .

3. I will make the changes related to `end_date` being null once the PR changes are merged and not to block this PR.

bbovenzi on (2024-11-14 16:33:05 UTC): Lgtm! We can iterate on a more detailed loading state and update `end_date` later.

tirkarthi (Issue Creator) on (2024-11-14 16:38:47 UTC): Thanks @bbovenzi and @pierrejeambrun .

"
2649617929,pull_request,closed,,Move Annotated import to `typing` module,"Since on `main`, we are already 3.9+, we can import Annotated from `typing` module.

- https://docs.python.org/3/library/typing.html#typing.Annotated
- https://peps.python.org/pep-0593/

It also move import of `Self` to `airflow.typing`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-11 15:09:21+00:00,[],2024-11-12 00:15:17+00:00,2024-11-11 22:43:57+00:00,https://github.com/apache/airflow/pull/43887,"[('area:serialization', '')]","[{'comment_id': 2469334904, 'issue_id': 2649617929, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 12, 0, 15, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-12 00:15:16 UTC): Nice!

"
2649606200,pull_request,closed,,Add backport action to workflow,"Adding backport action workflow , to automate PR's that require backport to other branches.

This backports the merged commit to the specified backport branch lable ex: `backport-to-v2-10-test`, then it uses `v2-10-test` as the target branch to to backport

Backport action repo: https://github.com/sorenlouv/backport-github-action/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-11 15:03:48+00:00,[],2024-11-12 08:40:54+00:00,2024-11-11 20:51:26+00:00,https://github.com/apache/airflow/pull/43886,"[('area:dev-tools', '')]","[{'comment_id': 2468404162, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '@amoghrajesh thanks for the suggestion :)', 'created_at': datetime.datetime(2024, 11, 11, 15, 10, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468445695, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '> I fail to see where we configure the target branch.\r\n\r\nah it would take from the label, backport-to-v2-10-test, so here `v2-10-test` is the target branch', 'created_at': datetime.datetime(2024, 11, 11, 15, 29, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468852411, 'issue_id': 2649606200, 'author': 'potiuk', 'body': '> > I fail to see where we configure the target branch.\r\n> \r\n> ah it would take from the label, backport-to-v2-10-test, so here `v2-10-test` is the target branch\r\n\r\nYeah, We will just have to create appropriate labels for all past versions.', 'created_at': datetime.datetime(2024, 11, 11, 19, 7, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468853382, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'I rebased it to account for latest static check fixes.', 'created_at': datetime.datetime(2024, 11, 11, 19, 8, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468868854, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '> > > I fail to see where we configure the target branch.\r\n> > \r\n> > \r\n> > ah it would take from the label, backport-to-v2-10-test, so here `v2-10-test` is the target branch\r\n> \r\n> Yeah, We will just have to create appropriate labels for all past versions.\r\n\r\nYes agreed, not sure how to test? do we have any prs to backport? 😄', 'created_at': datetime.datetime(2024, 11, 11, 19, 18, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468873111, 'issue_id': 2649606200, 'author': 'potiuk', 'body': '> Yes agreed, not sure how to test? do we have any prs to backport? 😄\r\n\r\nAbsolutely: https://github.com/apache/airflow/pull/43885 should be backported to all branches. Perfect candidate :D. I will rebase and create/apply backport branches when this one is merged :)', 'created_at': datetime.datetime(2024, 11, 11, 19, 21, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468998656, 'issue_id': 2649606200, 'author': 'potiuk', 'body': '> Looks cool! Do you prepare labels with a description such that we know what to pick.\r\n> \r\n> Looking forward to automate the manual burden!\r\n\r\nI will do it when backporting #43885 to ALL past branches :)', 'created_at': datetime.datetime(2024, 11, 11, 20, 50, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469004521, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'And I will delete the old branches after testing :). We want to have quick label selection.', 'created_at': datetime.datetime(2024, 11, 11, 20, 54, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469012970, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'Ah.... We will need to get approval from INFRA\r\n\r\n```\r\nsorenlouv/backport-github-action@ad888e978060bc1b2798690dd9d03c4036560947 is not allowed to be used in \r\napache/airflow. Actions in this workflow must be: within a repository that belongs to your Enterprise account, created by \r\nGitHub, verified in the GitHub Marketplace, or matching the following:\r\n */*@[a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9]+, AdoptOpenJDK/install-jdk@*, \r\nTobKed/label-when-approved-action@*, actions-cool/issues-helper@*, actions-rs/*, al-cheb/configure-pagefile-action@*, amannn/action-semantic-pull-request@*, apache/*, burrunan/gradle-cache-action@*, \r\nbytedeco/javacpp-presets/.github/actions/*, chromaui/action@*, codecov/codecov-action@*, \r\ncontainer-tools/kind-action@*, container-tools/microshift-action@*, \r\ndawidd6/action-download-artifact@*, delaguardo/setup-graalvm@*, \r\ndocker://jekyll/jekyll:*, docker://pandoc/core:2.9, eps1lon/actions-label-merge-conflict@*, \r\ngaurav-nelson/github-action-markdown-link-check@*, golangci/*, gr2m/twitter-together@*, \r\ngradle/wra...\r\n```', 'created_at': datetime.datetime(2024, 11, 11, 21, 0, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469022045, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'Created a JIRA issue https://issues.apache.org/jira/browse/INFRA-26262', 'created_at': datetime.datetime(2024, 11, 11, 21, 7, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469051597, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '> Ah.... We will need to get approval from INFRA\r\n> \r\n> ```\r\n> sorenlouv/backport-github-action@ad888e978060bc1b2798690dd9d03c4036560947 is not allowed to be used in \r\n> apache/airflow. Actions in this workflow must be: within a repository that belongs to your Enterprise account, created by \r\n> GitHub, verified in the GitHub Marketplace, or matching the following:\r\n>  */*@[a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9]+, AdoptOpenJDK/install-jdk@*, \r\n> TobKed/label-when-approved-action@*, actions-cool/issues-helper@*, actions-rs/*, al-cheb/configure-pagefile-action@*, amannn/action-semantic-pull-request@*, apache/*, burrunan/gradle-cache-action@*, \r\n> bytedeco/javacpp-presets/.github/actions/*, chromaui/action@*, codecov/codecov-action@*, \r\n> container-tools/kind-action@*, container-tools/microshift-action@*, \r\n> dawidd6/action-download-artifact@*, delaguardo/setup-graalvm@*, \r\n> docker://jekyll/jekyll:*, docker://pandoc/core:2.9, eps1lon/actions-label-merge-conflict@*, \r\n> gaurav-nelson/github-action-markdown-link-check@*, golangci/*, gr2m/twitter-together@*, \r\n> gradle/wra...\r\n> ```\r\n\r\noh i see :)', 'created_at': datetime.datetime(2024, 11, 11, 21, 29, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469052030, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '> Created a JIRA issue https://issues.apache.org/jira/browse/INFRA-26262\r\n\r\nnice thank you :)', 'created_at': datetime.datetime(2024, 11, 11, 21, 30, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469895635, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'Hmm. it seems that we might have some hard time (and I kind of agree with it eventually) about using pull_request_target for that one - INFRA (Rightfully) is worried about security of those, so we should likely look for alternative - where we could either user `workflow_dispatch` kind of workflow or maybe even use some **slightly** less automated workflow that we write manually.', 'created_at': datetime.datetime(2024, 11, 12, 8, 33, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469896116, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'I will revert it for now', 'created_at': datetime.datetime(2024, 11, 12, 8, 33, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469898455, 'issue_id': 2649606200, 'author': 'potiuk', 'body': 'Reference https://issues.apache.org/jira/browse/INFRA-26262', 'created_at': datetime.datetime(2024, 11, 12, 8, 34, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469908524, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '> Hmm. it seems that we might have some hard time (and I kind of agree with it eventually) about using pull_request_target for that one - INFRA (Rightfully) is worried about security of those, so we should likely look for alternative - where we could either user `workflow_dispatch` kind of workflow or maybe even use some **slightly** less automated workflow that we write manually.\r\n\r\nYes agree , we can look some alternatives, I have posted another alternative on slack thread which gives ability to use workflow_dispatch, and I feel we can automate this some way. But not entirely sure thats the right path :) please suggest', 'created_at': datetime.datetime(2024, 11, 12, 8, 39, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469911233, 'issue_id': 2649606200, 'author': 'gopidesupavan', 'body': '> > Hmm. it seems that we might have some hard time (and I kind of agree with it eventually) about using pull_request_target for that one - INFRA (Rightfully) is worried about security of those, so we should likely look for alternative - where we could either user `workflow_dispatch` kind of workflow or maybe even use some **slightly** less automated workflow that we write manually.\r\n> \r\n> Yes agree , we can look some alternatives, I have posted another alternative on slack thread which gives ability to use workflow_dispatch, and I feel we can automate this some way. But not entirely sure thats the right path :) please suggest\r\n\r\nhttps://apache-airflow.slack.com/archives/C0808SJPNGM/p1731388388011519', 'created_at': datetime.datetime(2024, 11, 12, 8, 40, 53, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-11 15:10:16 UTC): @amoghrajesh thanks for the suggestion :)

gopidesupavan (Issue Creator) on (2024-11-11 15:29:05 UTC): ah it would take from the label, backport-to-v2-10-test, so here `v2-10-test` is the target branch

potiuk on (2024-11-11 19:07:25 UTC): Yeah, We will just have to create appropriate labels for all past versions.

potiuk on (2024-11-11 19:08:06 UTC): I rebased it to account for latest static check fixes.

gopidesupavan (Issue Creator) on (2024-11-11 19:18:44 UTC): Yes agreed, not sure how to test? do we have any prs to backport? 😄

potiuk on (2024-11-11 19:21:26 UTC): Absolutely: https://github.com/apache/airflow/pull/43885 should be backported to all branches. Perfect candidate :D. I will rebase and create/apply backport branches when this one is merged :)

potiuk on (2024-11-11 20:50:04 UTC): I will do it when backporting #43885 to ALL past branches :)

potiuk on (2024-11-11 20:54:22 UTC): And I will delete the old branches after testing :). We want to have quick label selection.

potiuk on (2024-11-11 21:00:57 UTC): Ah.... We will need to get approval from INFRA

```
sorenlouv/backport-github-action@ad888e978060bc1b2798690dd9d03c4036560947 is not allowed to be used in 
apache/airflow. Actions in this workflow must be: within a repository that belongs to your Enterprise account, created by 
GitHub, verified in the GitHub Marketplace, or matching the following:
 */*@[a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9][a-f0-9]+, AdoptOpenJDK/install-jdk@*, 
TobKed/label-when-approved-action@*, actions-cool/issues-helper@*, actions-rs/*, al-cheb/configure-pagefile-action@*, amannn/action-semantic-pull-request@*, apache/*, burrunan/gradle-cache-action@*, 
bytedeco/javacpp-presets/.github/actions/*, chromaui/action@*, codecov/codecov-action@*, 
container-tools/kind-action@*, container-tools/microshift-action@*, 
dawidd6/action-download-artifact@*, delaguardo/setup-graalvm@*, 
docker://jekyll/jekyll:*, docker://pandoc/core:2.9, eps1lon/actions-label-merge-conflict@*, 
gaurav-nelson/github-action-markdown-link-check@*, golangci/*, gr2m/twitter-together@*, 
gradle/wra...
```

potiuk on (2024-11-11 21:07:18 UTC): Created a JIRA issue https://issues.apache.org/jira/browse/INFRA-26262

gopidesupavan (Issue Creator) on (2024-11-11 21:29:48 UTC): oh i see :)

gopidesupavan (Issue Creator) on (2024-11-11 21:30:05 UTC): nice thank you :)

potiuk on (2024-11-12 08:33:16 UTC): Hmm. it seems that we might have some hard time (and I kind of agree with it eventually) about using pull_request_target for that one - INFRA (Rightfully) is worried about security of those, so we should likely look for alternative - where we could either user `workflow_dispatch` kind of workflow or maybe even use some **slightly** less automated workflow that we write manually.

potiuk on (2024-11-12 08:33:30 UTC): I will revert it for now

potiuk on (2024-11-12 08:34:38 UTC): Reference https://issues.apache.org/jira/browse/INFRA-26262

gopidesupavan (Issue Creator) on (2024-11-12 08:39:35 UTC): Yes agree , we can look some alternatives, I have posted another alternative on slack thread which gives ability to use workflow_dispatch, and I feel we can automate this some way. But not entirely sure thats the right path :) please suggest

gopidesupavan (Issue Creator) on (2024-11-12 08:40:53 UTC): https://apache-airflow.slack.com/archives/C0808SJPNGM/p1731388388011519

"
2649580210,pull_request,closed,,Add .dockerignore to target workflow override,"There is an extra layer of protection that code provided by PR should not be executed in the context of pull_request_target by running the code only inside docker container. However the container is build from local sources, so it could contain other code. We do not allow that by .dockerignore, but the .dockerignore should not be overrideable from the incoming PR.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-11 14:53:59+00:00,[],2024-11-16 21:22:23+00:00,2024-11-16 14:16:16+00:00,https://github.com/apache/airflow/pull/43885,"[('area:dev-tools', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2468824568, 'issue_id': 2649580210, 'author': 'gopidesupavan', 'body': 'cool :)', 'created_at': datetime.datetime(2024, 11, 11, 18, 48, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2480813561, 'issue_id': 2649580210, 'author': 'potiuk', 'body': 'Ah .. I wanted to use it to test cherry-picker automation - but I can do it manually actually with cherry-picker cli- now that they released a version that has the new feature that @gopidesupavan also advocated for it in the cherry-picker PR', 'created_at': datetime.datetime(2024, 11, 16, 21, 22, 22, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-11 18:48:50 UTC): cool :)

potiuk (Issue Creator) on (2024-11-16 21:22:22 UTC): Ah .. I wanted to use it to test cherry-picker automation - but I can do it manually actually with cherry-picker cli- now that they released a version that has the new feature that @gopidesupavan also advocated for it in the cherry-picker PR

"
2649503547,pull_request,closed,,Change check for SQLite for FastAPI tests,"This changes the current check for Sqlite that relies on `BACKEND` env var set by Breeze. This allow running same tests outside of Breeze.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-11 14:33:09+00:00,[],2024-11-12 08:58:10+00:00,2024-11-11 16:23:05+00:00,https://github.com/apache/airflow/pull/43884,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2468564905, 'issue_id': 2649503547, 'author': 'kaxil', 'body': 'fyi @pierrejeambrun', 'created_at': datetime.datetime(2024, 11, 11, 16, 23, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469464013, 'issue_id': 2649503547, 'author': 'rawwar', 'body': 'Thanks @kaxil!', 'created_at': datetime.datetime(2024, 11, 12, 2, 28, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469948924, 'issue_id': 2649503547, 'author': 'pierrejeambrun', 'body': 'Thanks @kaxil', 'created_at': datetime.datetime(2024, 11, 12, 8, 58, 8, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-11 16:23:12 UTC): fyi @pierrejeambrun

rawwar on (2024-11-12 02:28:12 UTC): Thanks @kaxil!

pierrejeambrun on (2024-11-12 08:58:08 UTC): Thanks @kaxil

"
2649215345,pull_request,closed,,AIP 84: Migrate GET ASSET EVENTS legacy API to fast API ,"Migrating the connexion API for GET ASSETS EVENTS to fastAPI.

Depends on https://github.com/apache/airflow/pull/43783
related: https://github.com/apache/airflow/issues/43845


Swagger Specs

<img width=""1472"" alt=""image"" src=""https://github.com/user-attachments/assets/e320e30e-fcfa-4e28-9300-f2b3c1756259"">

<img width=""1396"" alt=""image"" src=""https://github.com/user-attachments/assets/0d733a66-c4c6-4758-b080-cc791bebbc92"">




Response JSON

```
{
  ""asset_events"": [
    {
      ""id"": 1,
      ""asset_id"": 1,
      ""asset_uri"": ""s3://bucket/key/1"",
      ""extra"": {
        ""foo"": ""bar""
      },
      ""source_task_id"": ""source_task_id"",
      ""source_dag_id"": ""source_dag_id"",
      ""source_run_id"": ""source_run_id_1"",
      ""source_map_index"": -1,
      ""created_dagruns"": [
        {
          ""run_id"": ""source_run_id_1"",
          ""dag_id"": ""source_dag_id"",
          ""logical_date"": ""2020-06-11T18:00:00Z"",
          ""start_date"": ""2020-06-11T18:00:00Z"",
          ""end_date"": ""2020-06-11T18:00:00Z"",
          ""state"": ""success"",
          ""data_interval_start"": ""2020-06-11T18:00:00Z"",
          ""data_interval_end"": ""2020-06-11T18:00:00Z""
        }
      ],
      ""timestamp"": ""2020-06-11T18:00:00Z""
    },
    {
      ""id"": 2,
      ""asset_id"": 2,
      ""uri"": ""s3://bucket/key/2"",
      ""extra"": {
        ""foo"": ""bar""
      },
      ""source_task_id"": ""source_task_id"",
      ""source_dag_id"": ""source_dag_id"",
      ""source_run_id"": ""source_run_id_2"",
      ""source_map_index"": -1,
      ""created_dagruns"": [
        {
          ""run_id"": ""source_run_id_2"",
          ""dag_id"": ""source_dag_id"",
          ""logical_date"": ""2020-06-11T18:00:00Z"",
          ""start_date"": ""2020-06-11T18:00:00Z"",
          ""end_date"": ""2020-06-11T18:00:00Z"",
          ""state"": ""success"",
          ""data_interval_start"": ""2020-06-11T18:00:00Z"",
          ""data_interval_end"": ""2020-06-11T18:00:00Z""
        }
      ],
      ""timestamp"": ""2020-06-11T18:00:00Z""
    }
  ],
  ""total_entries"": 2
}
```

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-11 12:34:22+00:00,[],2024-11-14 09:59:55+00:00,2024-11-14 09:59:54+00:00,https://github.com/apache/airflow/pull/43881,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2469667672, 'issue_id': 2649215345, 'author': 'vatsrahul1001', 'body': 'Note: Kindly review after [commit](https://github.com/apache/airflow/pull/43881/commits/8b6b09ea58b384f96a6cdd07dd6a1ad43fd41856) had to build from  [PR](https://github.com/apache/airflow/pull/43783) as its still not merged.', 'created_at': datetime.datetime(2024, 11, 12, 5, 52, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471079934, 'issue_id': 2649215345, 'author': 'pierrejeambrun', 'body': 'Can you rebase the branch and resolve conflicts. The base branch has been merged as well, it should simplify the review, thanks.', 'created_at': datetime.datetime(2024, 11, 12, 16, 56, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471364192, 'issue_id': 2649215345, 'author': 'vatsrahul1001', 'body': '> Can you rebase the branch and resolve conflicts. The base branch has been merged as well, it should simplify the review, thanks.\r\n\r\n@pierrejeambrun resolved conflicts', 'created_at': datetime.datetime(2024, 11, 12, 19, 17, 23, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2024-11-12 05:52:56 UTC): Note: Kindly review after [commit](https://github.com/apache/airflow/pull/43881/commits/8b6b09ea58b384f96a6cdd07dd6a1ad43fd41856) had to build from  [PR](https://github.com/apache/airflow/pull/43783) as its still not merged.

pierrejeambrun on (2024-11-12 16:56:10 UTC): Can you rebase the branch and resolve conflicts. The base branch has been merged as well, it should simplify the review, thanks.

vatsrahul1001 (Issue Creator) on (2024-11-12 19:17:23 UTC): @pierrejeambrun resolved conflicts

"
2649113406,pull_request,closed,,Correct mime-type in OpenAPI spec,"Correct mime-type in OpenAPI spec for /api/v1/dagSources/{file_token}

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",xitep,2024-11-11 11:47:59+00:00,[],2024-11-11 23:05:59+00:00,2024-11-11 23:02:35+00:00,https://github.com/apache/airflow/pull/43879,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2468018428, 'issue_id': 2649113406, 'author': 'xitep', 'body': ""> Please ask maintainer to assign the 'legacy api' label to the PR in order to continue\r\n\r\n:pray:"", 'created_at': datetime.datetime(2024, 11, 11, 12, 6, 38, tzinfo=datetime.timezone.utc)}]","xitep (Issue Creator) on (2024-11-11 12:06:38 UTC): :pray:

"
2649083010,pull_request,closed,,ci(github-actions): add uv to news-fragment action,"## Why
uv is missing in `news-fragment` workflow

## What
`pip install uv` in `news-fragment` workflow

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-11 11:35:10+00:00,[],2024-11-11 14:06:40+00:00,2024-11-11 14:06:38+00:00,https://github.com/apache/airflow/pull/43878,"[('area:dev-tools', '')]",[],
2649017765,pull_request,closed,,fix(dag_warning): rename argument error_type as warning_type,"## Why
The argument error_type in `DagWarning.__init__` is later set as the value of `DagWarning.warning_type`. Not sure whether it's expected

## What
Rename argument error_type as warning_type in `DagWarning.__init__`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-11 11:12:02+00:00,[],2024-11-13 14:23:09+00:00,2024-11-13 14:23:07+00:00,https://github.com/apache/airflow/pull/43877,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]",[],
2648978285,pull_request,closed,,AIP-84 Migrate GET asset event for a Dag Run endpoint to FastAPI ,related to #42701,rawwar,2024-11-11 10:53:59+00:00,[],2024-11-14 17:51:01+00:00,2024-11-14 17:51:01+00:00,https://github.com/apache/airflow/pull/43876,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2477058556, 'issue_id': 2648978285, 'author': 'rawwar', 'body': 'Closing in reference to https://github.com/apache/airflow/pull/43874', 'created_at': datetime.datetime(2024, 11, 14, 17, 51, 1, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2024-11-14 17:51:01 UTC): Closing in reference to https://github.com/apache/airflow/pull/43874

"
2648934000,pull_request,closed,,AIP-84 Migrate Trigger Dag Run endpoint to FastAPI ,related to #42701,rawwar,2024-11-11 10:41:41+00:00,[],2024-11-27 00:02:48+00:00,2024-11-27 00:02:48+00:00,https://github.com/apache/airflow/pull/43875,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2648849550,pull_request,closed,,AIP-84: Migrating GET Dataset events for DAG runs api to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related https://github.com/apache/airflow/issues/42370

Depends on https://github.com/apache/airflow/pull/43783

Migrating the GET Dataset events for DAG runs to fastAPI

Responses:
Legacy
![image](https://github.com/user-attachments/assets/9399748c-f942-4d1a-a9cf-45f516faaba2)

FastAPI
![image](https://github.com/user-attachments/assets/d9c1aa64-4df5-411b-af11-ff316524b363)

Swagger spec
![image](https://github.com/user-attachments/assets/70b6634e-017d-4914-acf0-20beffda97e4)

![image](https://github.com/user-attachments/assets/2c4893fd-dbcd-4b6e-95ba-b6803fe9d176)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-11 10:16:16+00:00,['amoghrajesh'],2024-11-15 16:18:01+00:00,2024-11-15 16:17:58+00:00,https://github.com/apache/airflow/pull/43874,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2467770016, 'issue_id': 2648849550, 'author': 'amoghrajesh', 'body': 'Only the last 3 commits are relevant here', 'created_at': datetime.datetime(2024, 11, 11, 10, 16, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471097785, 'issue_id': 2648849550, 'author': 'pierrejeambrun', 'body': 'The base branch has been merged, branch needs rebasing.\r\n\r\nAlso you can add the `legacy api` tag to allow the CI to build.', 'created_at': datetime.datetime(2024, 11, 12, 17, 2, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476797019, 'issue_id': 2648849550, 'author': 'amoghrajesh', 'body': 'OK i got a green CI. Is this one good to merge @pierrejeambrun?', 'created_at': datetime.datetime(2024, 11, 14, 16, 2, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2479339461, 'issue_id': 2648849550, 'author': 'pierrejeambrun', 'body': 'Thanks 🎉', 'created_at': datetime.datetime(2024, 11, 15, 16, 17, 56, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-11 10:16:31 UTC): Only the last 3 commits are relevant here

pierrejeambrun on (2024-11-12 17:02:54 UTC): The base branch has been merged, branch needs rebasing.

Also you can add the `legacy api` tag to allow the CI to build.

amoghrajesh (Issue Creator) on (2024-11-14 16:02:33 UTC): OK i got a green CI. Is this one good to merge @pierrejeambrun?

pierrejeambrun on (2024-11-15 16:17:56 UTC): Thanks 🎉

"
2648770242,pull_request,closed,,fix(scheduler_job_runner/asset): fix how asset dag warning is added,"## Why
The logic for activating assets is not correct now.

## What
The correct logic is
1. Find the warning that should exist after this round
2. Delete the warnings that no longer needed
3. Update the warnings if they already exist and add new warnings if they do not yet exists

Related PR: https://github.com/apache/airflow/pull/43693 (that one fix the logic in the wrong way and is fixed in this PR)
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-11 09:48:33+00:00,[],2024-11-14 04:27:26+00:00,2024-11-14 04:27:25+00:00,https://github.com/apache/airflow/pull/43873,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('airflow3.0:candidate', 'Potential candidates for Airflow 3.0')]",[],
2648355085,pull_request,closed,,[Edge]Worker UI link beautification,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

This PR adds a a small beautification to find links easier to tasks which are e.g. queued or running on the edge worker on the Airflow UI.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-11-11 06:48:59+00:00,[],2024-11-11 08:30:18+00:00,2024-11-11 08:30:18+00:00,https://github.com/apache/airflow/pull/43869,"[('area:providers', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2647864411,pull_request,closed,,Further make sure graphviz is truly optional feature on MacOS,"For our development, Pygraphviz is quite a difficul dependency to
install on MacOS. That's why we disable it by default on MacOS -
it was attempted in https://github.com/apache/airflow/pull/43604, but it turned out some other dependencies
pulled it in as well.

This PR removes all the graphviz dependencies as being required,
and providers more readable error message and iink to documuentation
explaining how to install graphviz if needed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-11 01:12:11+00:00,[],2024-11-12 20:00:11+00:00,2024-11-11 10:28:26+00:00,https://github.com/apache/airflow/pull/43867,"[('area:dev-tools', ''), ('mans-hackathon', '')]","[{'comment_id': 2467050184, 'issue_id': 2647864411, 'author': 'potiuk', 'body': 'cc: @enisnazif', 'created_at': datetime.datetime(2024, 11, 11, 1, 17, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467730505, 'issue_id': 2647864411, 'author': 'potiuk', 'body': ""Another result of the Man's Hackathon :). We were lucky to have @enisnazif who had brand-new M4 Mac just set-up from scratch so I hope firrst time MacOS experience for new contributors will get better thanks to that!"", 'created_at': datetime.datetime(2024, 11, 11, 10, 3, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467734123, 'issue_id': 2647864411, 'author': 'amoghrajesh', 'body': 'A new laptop always helps find bugs in the docs :)', 'created_at': datetime.datetime(2024, 11, 11, 10, 5, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2471459416, 'issue_id': 2647864411, 'author': 'ferruzzi', 'body': '> A new laptop always helps find bugs in the docs :)\r\n\r\nNew laptops and new hires/interns.  Their best first contribution is always verifying and updating docs :+1:', 'created_at': datetime.datetime(2024, 11, 12, 20, 0, 9, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-11 01:17:31 UTC): cc: @enisnazif

potiuk (Issue Creator) on (2024-11-11 10:03:56 UTC): Another result of the Man's Hackathon :). We were lucky to have @enisnazif who had brand-new M4 Mac just set-up from scratch so I hope firrst time MacOS experience for new contributors will get better thanks to that!

amoghrajesh on (2024-11-11 10:05:14 UTC): A new laptop always helps find bugs in the docs :)

ferruzzi on (2024-11-12 20:00:09 UTC): New laptops and new hires/interns.  Their best first contribution is always verifying and updating docs :+1:

"
2647839018,pull_request,closed,,Recommend and use ``uv`` instead of ``pipx`` in a few remaining places,"The ``pipx`` has still been used and recommended in a few places in our documentation and in a few scripts/github actions.

We also installed pipx in the container image to be able to run mmsql-cli, but this is not needed any more as mssql is not supported as metadata backend.

This PR updates the remaining parts.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-11 00:39:39+00:00,[],2024-11-11 10:02:18+00:00,2024-11-11 04:40:20+00:00,https://github.com/apache/airflow/pull/43866,"[('area:dev-tools', ''), ('kind:documentation', ''), ('area:production-image', 'Production image improvements and fixes'), ('mans-hackathon', '')]","[{'comment_id': 2467024744, 'issue_id': 2647839018, 'author': 'potiuk', 'body': ""During Man's Hackathon, it turned out that there are quite a few places where either `pipx` was used or recommended - or the only option explained."", 'created_at': datetime.datetime(2024, 11, 11, 0, 41, 5, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-11 00:41:05 UTC): During Man's Hackathon, it turned out that there are quite a few places where either `pipx` was used or recommended - or the only option explained.

"
2647702146,pull_request,closed,,Migrate Edge Worker backend to FastAPI,"As Airflow 3.0 on main is migrating to FastAPI so must also Edge provider move...

Initial MVP was built on Connexion endpoint, made it working in 2.10. This PR adds support for FastAPI on the API back-ends as a hybrid. Provider package is using Connexion on Airflow 2.10 and FastAPI when running on Airflow 3.

Starting this PR as draft, let's see if CI is turning green. Manual tests worked.

NOT contained in this PR, to be implemented as follow-up:
- Make the Edge Worker specific calls a dedicated API to un-bundle from AIP-44 API (Means task execution would further use AIP-44 but the Edge Package not anymore) - Needed to wipe-off AIP-44
- Integration of AIP-74 Task SDK - can be done once this would be able to run tasks",jscheffl,2024-11-10 22:04:42+00:00,[],2024-11-16 15:49:19+00:00,2024-11-16 15:49:19+00:00,https://github.com/apache/airflow/pull/43865,"[('area:providers', ''), ('area:dev-tools', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2647541425,pull_request,closed,,Fix breeze panel to start EdgeWorker when EdgeExecutor is selected in breeze,"As continuing to develop EdgeExecutor / AIP-69 I noticed that the breeze integration was ""broken"" on another point:
- If breeze is started with EdgeExecutor the executor path needed to be tweaked in #43842
- But a moment later TMUX is starting all panels and as the name was not matching, the edge worker panel was not starting - so the setup was missing a worker...

Root cause was like PR #43842 that the executor short name was removed during review and no direct mapping from ""EdgeExecutor"" in airflow core exists to map to provider package module name",jscheffl,2024-11-10 19:17:12+00:00,[],2024-11-11 19:29:14+00:00,2024-11-11 19:29:13+00:00,https://github.com/apache/airflow/pull/43864,"[('area:dev-tools', '')]",[],
2647364560,pull_request,closed,,Bump hatchling to 1.26.1,"hatchling new version has been released, i have executed locally this seems fine. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-10 15:39:31+00:00,[],2024-11-10 17:05:43+00:00,2024-11-10 17:05:32+00:00,https://github.com/apache/airflow/pull/43863,"[('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:production-image', 'Production image improvements and fixes')]",[],
2647181761,pull_request,closed,,Introduce new gcp TranslateText and TranslateTextBatch operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2024-11-10 12:23:20+00:00,[],2024-11-20 11:43:42+00:00,2024-11-20 11:43:42+00:00,https://github.com/apache/airflow/pull/43860,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2647051981,pull_request,closed,,AIP-84 Add Lists Jobs with Filters API,"

Closes: #43660  
Related: #43657  

### Feature

I’ve placed the endpoint in `airflow/api_fastapi/core_api/routes/public/job.py`, but I’m not certain if this is the most appropriate location—perhaps `airflow/api_fastapi/core_api/routes/cli/job.py` would also fine ?
The query parameters, response data models, and implementation are consistent with the rest of the public API, utilizing `common.parameters` and `paginated_select`.

### Tests

The test cases are refactored from the original [airflow/tests/cli/commands/test_jobs_command.py](https://github.com/apache/airflow/blob/main/tests/cli/commands/test_jobs_command.py), as the CLI should yield the same results when leveraging the API instead of direct DB access.

### Question

Hi @bugraoz93, I’m curious about the distinction between this PR’s endpoint (List Jobs with filters) and #43661 (List Jobs), as both endpoints seem to provide job listings. From my perspective, calling this ""List Jobs with filters"" endpoint without query parameters would yield the same response as the ""List Jobs"" endpoint.  
cc @josix  
",jason810496,2024-11-10 09:37:54+00:00,[],2024-11-25 13:44:43+00:00,2024-11-25 13:44:43+00:00,https://github.com/apache/airflow/pull/43859,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2466738962, 'issue_id': 2647051981, 'author': 'bugraoz93', 'body': 'Hey @jason810496,\r\n\r\nThat’s a good question, and I’m glad you raised it! @rawwar and I had a similar discussion, and it seems we all have similar concerns.\r\n\r\nAt first, I thought keeping `""List Jobs""` and `""List Jobs with Filters""` as separate endpoints made sense for clarity. But after thinking it through more and taking a closer look, I believe combining them into a single ""List Jobs"" endpoint with optional query parameters for filters might be a better approach. This way, the endpoint would return all jobs by default, with filtering options (as a `QueryParameter`) as needed. It would make it both straightforward and easy to maintain.\r\n\r\nThanks for raising this! I am happy to keep the discussion going if others have thoughts on this approach. Otherwise, let’s go ahead and merge it into one endpoint.\r\n\r\ncc: @josix @rawwar', 'created_at': datetime.datetime(2024, 11, 10, 13, 35, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466811425, 'issue_id': 2647051981, 'author': 'bugraoz93', 'body': '>I’ve placed the endpoint in airflow/api_fastapi/core_api/routes/public/job.py, but I’m not certain if this is the most appropriate location—perhaps airflow/api_fastapi/core_api/routes/cli/job.py would also fine ?\r\nThe query parameters, response data models, and implementation are consistent with the rest of the public API, utilizing common.parameters and paginated_select.\r\n\r\n@jason810496 I missed including this part in my previous answer. I responded from my mind but forgot to put it into text. :) \r\n\r\nI think it makes more sense to keep the endpoint under `Core API`. Since most `CLI` calls will still rely on `Core API`, creating a separate category for just a few endpoints could add unnecessary complexity. By sticking to `Core API`, we stay consistent with the rest of the API and follow the same rules across the board. This way, we avoid extra maintenance overhead and keep things simple as we scale.', 'created_at': datetime.datetime(2024, 11, 10, 17, 6, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488570257, 'issue_id': 2647051981, 'author': 'pierrejeambrun', 'body': 'I think rebasing went wrong on the genrated file part.\r\n\r\nWhen you have any conflicts on those (openapi spec, or front end generated code). You can just re-run manually the hooks to refresh the files:\r\n```\r\npre-commit run generate-openapi-spec --all-files\r\npre-commit run ts-compile-format-lint-ui --all-files\r\n```', 'created_at': datetime.datetime(2024, 11, 20, 13, 22, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493093935, 'issue_id': 2647051981, 'author': 'jason810496', 'body': 'Just fix the trailing endpoint naming.\r\nI will work on follow up PR to refactor the test case with manual replace to `datetime_zulu_format` utility function 👍', 'created_at': datetime.datetime(2024, 11, 22, 7, 52, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493518221, 'issue_id': 2647051981, 'author': 'pierrejeambrun', 'body': 'Well I just tried the `conflict` resolution via the github interface. (because it was a really small conflict), quite handy for quick  and simple conflicts.', 'created_at': datetime.datetime(2024, 11, 22, 11, 17, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493712020, 'issue_id': 2647051981, 'author': 'jason810496', 'body': ""Hi @pierrejeambrun , I have ran the pre-commit locally and didn't not encounter current CI issue, not sure about what cause the `Generate the FastAPI API spec` error."", 'created_at': datetime.datetime(2024, 11, 22, 13, 0, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493819905, 'issue_id': 2647051981, 'author': 'pierrejeambrun', 'body': 'This is due to the recent pydantic release that breaks some stuff. Main lower bound has been added and should be better, you most likely not have the appropriate pydantic version locally. Now it should be `>= 2.10.1`(#44284)', 'created_at': datetime.datetime(2024, 11, 22, 13, 52, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493836512, 'issue_id': 2647051981, 'author': 'pierrejeambrun', 'body': 'Most likely the CI image used to run the pre-commit hook (`in_container` script) still has an old pydantic version.\r\n\r\nYou can run:\r\n```shell\r\nbreeze ci-image build --python 3.9\r\n```\r\n\r\nTo refresh the image. And you should get the appropriate generated spec locally then.', 'created_at': datetime.datetime(2024, 11, 22, 14, 1, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498061569, 'issue_id': 2647051981, 'author': 'pierrejeambrun', 'body': ""One unrelated provider failure, merging:\r\n\r\n```\r\n      from google.cloud.translate_v3.types import automl_translation\r\n  E   ImportError: cannot import name 'automl_translation' from 'google.cloud.translate_v3.types' (/usr/local/lib/python3.9/site-packages/google/cloud/translate_v3/types/__init__.py)\r\n  ----- generated xml file: /files/test_result-providers_google-postgres.xml -----\r\n ```"", 'created_at': datetime.datetime(2024, 11, 25, 13, 44, 27, tzinfo=datetime.timezone.utc)}]","bugraoz93 on (2024-11-10 13:35:07 UTC): Hey @jason810496,

That’s a good question, and I’m glad you raised it! @rawwar and I had a similar discussion, and it seems we all have similar concerns.

At first, I thought keeping `""List Jobs""` and `""List Jobs with Filters""` as separate endpoints made sense for clarity. But after thinking it through more and taking a closer look, I believe combining them into a single ""List Jobs"" endpoint with optional query parameters for filters might be a better approach. This way, the endpoint would return all jobs by default, with filtering options (as a `QueryParameter`) as needed. It would make it both straightforward and easy to maintain.

Thanks for raising this! I am happy to keep the discussion going if others have thoughts on this approach. Otherwise, let’s go ahead and merge it into one endpoint.

cc: @josix @rawwar

bugraoz93 on (2024-11-10 17:06:52 UTC): The query parameters, response data models, and implementation are consistent with the rest of the public API, utilizing common.parameters and paginated_select.

@jason810496 I missed including this part in my previous answer. I responded from my mind but forgot to put it into text. :) 

I think it makes more sense to keep the endpoint under `Core API`. Since most `CLI` calls will still rely on `Core API`, creating a separate category for just a few endpoints could add unnecessary complexity. By sticking to `Core API`, we stay consistent with the rest of the API and follow the same rules across the board. This way, we avoid extra maintenance overhead and keep things simple as we scale.

pierrejeambrun on (2024-11-20 13:22:12 UTC): I think rebasing went wrong on the genrated file part.

When you have any conflicts on those (openapi spec, or front end generated code). You can just re-run manually the hooks to refresh the files:
```
pre-commit run generate-openapi-spec --all-files
pre-commit run ts-compile-format-lint-ui --all-files
```

jason810496 (Issue Creator) on (2024-11-22 07:52:17 UTC): Just fix the trailing endpoint naming.
I will work on follow up PR to refactor the test case with manual replace to `datetime_zulu_format` utility function 👍

pierrejeambrun on (2024-11-22 11:17:58 UTC): Well I just tried the `conflict` resolution via the github interface. (because it was a really small conflict), quite handy for quick  and simple conflicts.

jason810496 (Issue Creator) on (2024-11-22 13:00:13 UTC): Hi @pierrejeambrun , I have ran the pre-commit locally and didn't not encounter current CI issue, not sure about what cause the `Generate the FastAPI API spec` error.

pierrejeambrun on (2024-11-22 13:52:29 UTC): This is due to the recent pydantic release that breaks some stuff. Main lower bound has been added and should be better, you most likely not have the appropriate pydantic version locally. Now it should be `>= 2.10.1`(#44284)

pierrejeambrun on (2024-11-22 14:01:12 UTC): Most likely the CI image used to run the pre-commit hook (`in_container` script) still has an old pydantic version.

You can run:
```shell
breeze ci-image build --python 3.9
```

To refresh the image. And you should get the appropriate generated spec locally then.

pierrejeambrun on (2024-11-25 13:44:27 UTC): One unrelated provider failure, merging:

```
      from google.cloud.translate_v3.types import automl_translation
  E   ImportError: cannot import name 'automl_translation' from 'google.cloud.translate_v3.types' (/usr/local/lib/python3.9/site-packages/google/cloud/translate_v3/types/__init__.py)
  ----- generated xml file: /files/test_result-providers_google-postgres.xml -----
 ```

"
2647026387,pull_request,closed,,Fix hatchling to 1.25.0,"A recent release of hatchling broke, which is 1.26.0.

All the prs are failing: https://github.com/apache/airflow/actions/runs/11763006635/job/32766578221?pr=43857#step:7:429
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-10 09:23:42+00:00,[],2024-11-10 17:02:35+00:00,2024-11-10 12:14:51+00:00,https://github.com/apache/airflow/pull/43858,"[('area:dev-tools', '')]","[{'comment_id': 2466714951, 'issue_id': 2647026387, 'author': 'gopidesupavan', 'body': 'Upgrade checks failing in canary for hatchling version, I will get that into separate pr', 'created_at': datetime.datetime(2024, 11, 10, 12, 25, 14, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-10 12:25:14 UTC): Upgrade checks failing in canary for hatchling version, I will get that into separate pr

"
2646913334,pull_request,closed,,Use updated data from Dags API for Dag with recent DagRun.,"On toggling pause for a dag with recent dagrun in the dags list page only the list dags and dag detail API are invalidated. On re-render of the page the dagruns API has stale data with older value for is_paused which is used thus not reflecting the change in UI though the patch API to update the dag was successful. For dags with recent dag runs use data from dags list API which has the updated value since the cache is invalidated. Another fix would be to invalidate the recent dagruns API too through useDagsServiceRecentDagRunsKey in TogglePause success but that results in an unnecessary API call.

To reproduce : 

1. Go to dags list page with one of the filters selected like success.
2. Toggle pause slider for the dag.
3. API call for update is made but the UI doesn't reflect the changes until page is refreshed.

https://github.com/apache/airflow/blob/6d85a0466d91d501af87c8904b902ea92cee466d/airflow/ui/src/components/TogglePause.tsx#L38-L46",tirkarthi,2024-11-10 06:47:14+00:00,[],2024-11-11 17:07:25+00:00,2024-11-11 17:07:25+00:00,https://github.com/apache/airflow/pull/43857,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2646486550,pull_request,closed,,Additional Contribution Documentation Updates,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

---
Additional changes to contribution documentation. Added descriptive text in testing, documentation 'working with git' as well as 'contribution quickstart' have been uniformly formatted, and further smaller changes.


**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Baerenstein,2024-11-09 19:56:15+00:00,[],2024-11-09 20:01:06+00:00,2024-11-09 20:01:05+00:00,https://github.com/apache/airflow/pull/43856,"[('area:dev-tools', ''), ('mans-hackathon', '')]",[],
2646455437,pull_request,closed,,Add uv sync to breeze precommit (#43684),"If breeze's pyproject.toml is manually modified, the uv.lock might not reflect the changed packages. 
For this reason if pyproject.toml is modified we should also make sure `uv sync` is run prior to commit - this will update uv.lock if there has been a change, or be a no-op if there has not 

Fixes: #43684",enisnazif,2024-11-09 19:22:15+00:00,[],2025-01-09 00:15:38+00:00,2025-01-09 00:15:38+00:00,https://github.com/apache/airflow/pull/43855,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:dev-tools', ''), ('mans-hackathon', '')]","[{'comment_id': 2467924218, 'issue_id': 2646455437, 'author': 'potiuk', 'body': 'As discussed at the hackathon on Saturday @enisnazif - just run pre-commit, and it will fix all the static checks - then committing it, and should be greeen', 'created_at': datetime.datetime(2024, 11, 11, 11, 18, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467968925, 'issue_id': 2646455437, 'author': 'enisnazif', 'body': ""Thanks - I'll do this at some point this week"", 'created_at': datetime.datetime(2024, 11, 11, 11, 40, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468870487, 'issue_id': 2646455437, 'author': 'potiuk', 'body': 'Cool!. And one more thing. This is about `breeze\'s pyproject.toml` syncing (currently we .gitignore uv.lock of Airflow as we have to figure out how to upgrade it ""in bulk"" and convert it into constraints. So this one is about using `uv sync` in the `dev/breeze` folder (that\'s where breeze\'s pyproject.toml is) \r\n\r\nOne more small comment here. Adding `Fixes: #PR_NUMBER`  will lead to closing the related issue when this one is merged I will link the issue manually, but it\'s good to refer to it in commits - then also it will appear as a ""linked PR"" in the issue and others will see that this is work in progress :)', 'created_at': datetime.datetime(2024, 11, 11, 19, 19, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567194896, 'issue_id': 2646455437, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 2, 0, 15, 15, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-11 11:18:17 UTC): As discussed at the hackathon on Saturday @enisnazif - just run pre-commit, and it will fix all the static checks - then committing it, and should be greeen

enisnazif (Issue Creator) on (2024-11-11 11:40:49 UTC): Thanks - I'll do this at some point this week

potiuk on (2024-11-11 19:19:40 UTC): Cool!. And one more thing. This is about `breeze's pyproject.toml` syncing (currently we .gitignore uv.lock of Airflow as we have to figure out how to upgrade it ""in bulk"" and convert it into constraints. So this one is about using `uv sync` in the `dev/breeze` folder (that's where breeze's pyproject.toml is) 

One more small comment here. Adding `Fixes: #PR_NUMBER`  will lead to closing the related issue when this one is merged I will link the issue manually, but it's good to refer to it in commits - then also it will appear as a ""linked PR"" in the issue and others will see that this is work in progress :)

github-actions[bot] on (2025-01-02 00:15:15 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2646435648,pull_request,closed,,Create Mock object with resource id as an attribute instead of passing a string,"closes: #42248
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",KS0107,2024-11-09 19:14:55+00:00,[],2025-01-09 00:15:39+00:00,2025-01-09 00:15:39+00:00,https://github.com/apache/airflow/pull/43854,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:providers', ''), ('provider:tableau', ''), ('mans-hackathon', '')]","[{'comment_id': 2466416207, 'issue_id': 2646435648, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 9, 19, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466418339, 'issue_id': 2646435648, 'author': 'potiuk', 'body': 'This one needs a unit test', 'created_at': datetime.datetime(2024, 11, 9, 19, 22, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566766337, 'issue_id': 2646435648, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2025, 1, 1, 0, 17, 6, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-09 19:15:00 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2024-11-09 19:22:47 UTC): This one needs a unit test

github-actions[bot] on (2025-01-01 00:17:06 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2646430324,pull_request,closed,,Add logging support for init containers in KubernetesPodOperator (#42498),"This change adds an option to print logs for init containers. The init_container_logs argument enables the display of logs specifically for spec.initContainers (not spec.containers).

Fixes: #42498",mrk-andreev,2024-11-09 19:03:33+00:00,[],2024-12-17 22:58:28+00:00,2024-12-17 22:58:28+00:00,https://github.com/apache/airflow/pull/43853,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('mans-hackathon', '')]","[{'comment_id': 2466414292, 'issue_id': 2646430324, 'author': 'potiuk', 'body': ""@dstandish @jedcunningham  @jscheffl @hussein-awala  -> that one was submitted during the Man's Hackathon - I am not sure if I am competent enough to review the details, but it looks good at a first glance, I'd need someone more k8s-api-involved to review it :)"", 'created_at': datetime.datetime(2024, 11, 9, 19, 8, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466437489, 'issue_id': 2646430324, 'author': 'mrk-andreev', 'body': '> I am not an K8s expert, can init containers run in parallel? Or are they executed serial?\r\nHow about if init containers run for a longer time? Would it be interesting to stream logs while they are running to see progress? And if they run in parallel would it mix logs?\r\n\r\nEach init container runs sequentially, with each one waiting for the previous container to complete. The main containers wait until all init containers are ready before starting.\r\n\r\nRef: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#understanding-init-containers\r\n\r\n> Init containers are exactly like regular containers, except:\r\n> * Init containers always run to completion.\r\n> * Each init container must complete successfully before the next one starts.', 'created_at': datetime.datetime(2024, 11, 9, 19, 59, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486764952, 'issue_id': 2646430324, 'author': 'mrk-andreev', 'body': 'Hi @jscheffl, @hussein-awala, @dstandish, @potiuk, @jedcunningham\r\n\r\nDoes this PR need any additional changes? Are there any blockers we should address? Let me know how I can help to move it forward!', 'created_at': datetime.datetime(2024, 11, 19, 21, 13, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2514887694, 'issue_id': 2646430324, 'author': 'potiuk', 'body': 'Can you rebase in the meantime @mrk-andreev ?', 'created_at': datetime.datetime(2024, 12, 3, 15, 30, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546278437, 'issue_id': 2646430324, 'author': 'potiuk', 'body': ""> LGTM\r\n> \r\n> If no further comments I will merge this PR for next provider wave\r\n\r\nLet's. I think it looks good."", 'created_at': datetime.datetime(2024, 12, 16, 17, 53, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2546280015, 'issue_id': 2646430324, 'author': 'potiuk', 'body': ""I rebased it - and let's give @dstandish and @hussein-awala last chance to comment."", 'created_at': datetime.datetime(2024, 12, 16, 17, 54, 10, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-09 19:08:30 UTC): @dstandish @jedcunningham  @jscheffl @hussein-awala  -> that one was submitted during the Man's Hackathon - I am not sure if I am competent enough to review the details, but it looks good at a first glance, I'd need someone more k8s-api-involved to review it :)

mrk-andreev (Issue Creator) on (2024-11-09 19:59:33 UTC): How about if init containers run for a longer time? Would it be interesting to stream logs while they are running to see progress? And if they run in parallel would it mix logs?

Each init container runs sequentially, with each one waiting for the previous container to complete. The main containers wait until all init containers are ready before starting.

Ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#understanding-init-containers

mrk-andreev (Issue Creator) on (2024-11-19 21:13:33 UTC): Hi @jscheffl, @hussein-awala, @dstandish, @potiuk, @jedcunningham

Does this PR need any additional changes? Are there any blockers we should address? Let me know how I can help to move it forward!

potiuk on (2024-12-03 15:30:05 UTC): Can you rebase in the meantime @mrk-andreev ?

potiuk on (2024-12-16 17:53:23 UTC): Let's. I think it looks good.

potiuk on (2024-12-16 17:54:10 UTC): I rebased it - and let's give @dstandish and @hussein-awala last chance to comment.

"
2646414575,pull_request,closed,,pydocstyle check: add leading underscore (PT004) ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

works towards #40567, closes 23 PT004 issues (add leading underscores)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",LyndonFan,2024-11-09 18:40:41+00:00,[],2024-11-09 19:50:52+00:00,2024-11-09 19:06:53+00:00,https://github.com/apache/airflow/pull/43852,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('mans-hackathon', '')]",[],
2646388352,pull_request,closed,,#43252 Disable extra links button if link is null or empty (#43844),Backport of #43844) to 2.10 line,jscheffl,2024-11-09 18:21:47+00:00,[],2024-11-09 19:50:52+00:00,2024-11-09 18:54:03+00:00,https://github.com/apache/airflow/pull/43851,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('mans-hackathon', '')]",[],
2646378397,pull_request,closed,,Correct provider path details in docs,"Some leftovers from the repo adjustments were in the providers docs, small PR to correct the file layout",jscheffl,2024-11-09 17:57:47+00:00,[],2024-11-09 19:51:20+00:00,2024-11-09 19:51:20+00:00,https://github.com/apache/airflow/pull/43850,"[('area:providers', '')]","[{'comment_id': 2466377931, 'issue_id': 2646378397, 'author': 'jscheffl', 'body': '@potiuk a few seconds tooo fast... I was reminded that the location of providers system tests were also wrong... updated as well...', 'created_at': datetime.datetime(2024, 11, 9, 18, 14, 57, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2024-11-09 18:14:57 UTC): @potiuk a few seconds tooo fast... I was reminded that the location of providers system tests were also wrong... updated as well...

"
2646330174,pull_request,closed,,fix: replace \s with space,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #39252
related: #39428, #38734, #38864

Remove deprecated ""\s"" with "" "" (single space). This is okay because output is from running [eks_get_token.py](./providers/src/airflow/providers/amazon/aws/utils/eks_get_token.py), which we know is just a sinlge space. Extra backslash is from running ruff.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",LyndonFan,2024-11-09 17:16:52+00:00,[],2024-11-09 19:50:51+00:00,2024-11-09 17:39:54+00:00,https://github.com/apache/airflow/pull/43849,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('mans-hackathon', '')]",[],
2646316037,pull_request,closed,,Contribution Documentation Updates,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Updated contribution documentation for better readability. 
Contribution quickstart is now accessible from the project README, typos in the contribution guide README have been fixed, and minor structural and linguistic changes were done. 

--- 
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Baerenstein,2024-11-09 16:57:07+00:00,[],2024-11-09 19:50:51+00:00,2024-11-09 17:36:56+00:00,https://github.com/apache/airflow/pull/43848,"[('area:dev-tools', ''), ('mans-hackathon', '')]","[{'comment_id': 2466292224, 'issue_id': 2646316037, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 9, 16, 57, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466308467, 'issue_id': 2646316037, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 9, 17, 36, 58, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-09 16:57:11 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-09 17:36:58 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2646271327,pull_request,closed,,Add random_name_suffix to SparkKubernetesOperator (#43800),"Prior to this change, `random_name_suffix` was only documented but not implemented as a configurable option. Passing this value as an argument had no effect. This commit introduces a `false` option for `random_name_suffix`, which prevents the generation of a random suffix for the pod name. For compatibility, the default value is set to `true`, ensuring the pod name will still conform to `MAX_LABEL_LEN = 63`.

Fixes: #43800 ",mrk-andreev,2024-11-09 16:25:22+00:00,[],2024-11-09 19:50:50+00:00,2024-11-09 17:22:38+00:00,https://github.com/apache/airflow/pull/43847,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('mans-hackathon', '')]",[],
2646117390,pull_request,closed,,Allow null for end_date to fetch dags in running state without end_date.,"While working on https://github.com/apache/airflow/issues/42700 I found that dagruns in running state without `end_date` are not returned even with current time sent as `end_date`. It seems that in the query `end_date` on being null uses `timezone.utcnow()` which will have a value greater than the frontend `end_date` value due to HTTP latency in the order of milliseconds to seconds thus never returning running dagruns and task instances associated with the corresponding dagrun. It's okay to allow dagruns with a start_date and no end_date which usually means they are in running state. Please correct me if I am missing any scenario regarding this.

https://github.com/apache/airflow/blob/340a70bfe7289e01898ddd75f8edfaf7772e9d09/airflow/api_fastapi/core_api/routes/ui/dashboard.py#L56-L58

cc: @bugraoz93 for https://github.com/apache/airflow/pull/42629",tirkarthi,2024-11-09 14:11:11+00:00,[],2024-11-15 01:34:24+00:00,2024-11-15 01:34:23+00:00,https://github.com/apache/airflow/pull/43846,[],"[{'comment_id': 2466443725, 'issue_id': 2646117390, 'author': 'bugraoz93', 'body': "">https://github.com/apache/airflow/blob/340a70bfe7289e01898ddd75f8edfaf7772e9d09/airflow/api_fastapi/core_api/routes/ui/dashboard.py#L56-L58\r\n\r\nThis part was lifted and shifted from `legacy ui`/`views.py`. \r\nhttps://github.com/apache/airflow/blob/main/airflow/www/views.py#L3318-L3320\r\n\r\nI will have time to check this in detail in 3-4 hours. If you think it is not working as expected, this should be a bug and we should fix it for old versions too. \r\n\r\nIf you think this part doesn't provide enough latency to the new UI then, it makes sense to make the changes."", 'created_at': datetime.datetime(2024, 11, 9, 20, 22, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466582723, 'issue_id': 2646117390, 'author': 'tirkarthi', 'body': 'It seems the default filters in cluster activity add 1 hour to current time as `end_date`. I am not sure if the same needs to be done in new UI since it presents preset hours like last 1 hour, 8 hours etc. for now where `end_date` has to be current time in the UI. \r\n\r\nhttps://github.com/apache/airflow/blob/6d85a0466d91d501af87c8904b902ea92cee466d/airflow/www/static/js/cluster-activity/useFilters.tsx#L52-L59', 'created_at': datetime.datetime(2024, 11, 10, 4, 42, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466747420, 'issue_id': 2646117390, 'author': 'bugraoz93', 'body': 'We should take a step back and clarify the intended use case for the `dashboard` (old `historical_metrics_data`). The current lifted and shifted version was designed to show historical data, so it makes sense not to include running jobs in this context. As we transition to the `new UI` and the `dashboard` term for this endpoint, we should ensure the endpoint aligns with the updated requirements.\r\n\r\nIt would be beneficial to get @bbovenzi and @pierrejeambrun’s input to gain the overall vision of the dashboard’s requirements.', 'created_at': datetime.datetime(2024, 11, 10, 13, 59, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468403189, 'issue_id': 2646117390, 'author': 'tirkarthi', 'body': 'IMO not showing running dagruns reduces the value of the new dashboard. The running dagruns are present in current cluster activity page too. When I raised the PR I thought it was a bug. It comes to a decision over adding 1hr in UI like cluster activity or changing the API as per the PR to imply dagruns without end_date as running.', 'created_at': datetime.datetime(2024, 11, 11, 15, 9, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468493485, 'issue_id': 2646117390, 'author': 'bbovenzi', 'body': ""Doesn't this always add running dags even when I set my `end_date` param to be in the past? (ex: I only wanted to look at dag runs from last week)\r\n\r\nI think there's a few ways to redo this:\r\n- make `end_date` an optional param\r\n- only filter on `start_date`, then you capture any dags that ran during that time period, even if they didn't finish within that time period (if the dagrun's end_date is after the date range we also miss it)"", 'created_at': datetime.datetime(2024, 11, 11, 15, 51, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468510542, 'issue_id': 2646117390, 'author': 'tirkarthi', 'body': ""> Doesn't this always add running dags even when I set my end_date param to be in the past? (ex: I only wanted to look at dag runs from last week)\r\n\r\nWhen the dagrun started in the last week after given start_date in the UI and yet to finish with end_date as None for the dagrun it will be present in the API with this change. Before this change it won't be shown."", 'created_at': datetime.datetime(2024, 11, 11, 15, 59, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468908783, 'issue_id': 2646117390, 'author': 'bugraoz93', 'body': ""> > Doesn't this always add running dags even when I set my end_date param to be in the past? (ex: I only wanted to look at dag runs from last week)\r\n> \r\n> When the dagrun started in the last week after given start_date in the UI and yet to finish with end_date as None for the dagrun it will be present in the API with this change. Before this change it won't be shown.\r\n\r\nI dug more after the answers since this was the case in the `legacy api`. We should check the parameters.py rather than editing the endpoint itself. We should return None here similar to the old version. I think I made it `ValueError` if `end_date` is not provided but as @bbovenzi said we can make this value `None` when it's not provided (optional).\r\n\r\n**Where we should change:**\r\nhttps://github.com/apache/airflow/blob/2105c94854a2f8d5d2411d08a66e6d5f7002c8d4/airflow/api_fastapi/common/parameters.py#L373-L374\r\n**Where it was before:**\r\nhttps://github.com/apache/airflow/blob/2105c94854a2f8d5d2411d08a66e6d5f7002c8d4/airflow/www/views.py#L294-L295\r\n\r\nOf course, we should adjust this to make FastAPI accept the value as optional in the endpoint.\r\nhttps://github.com/apache/airflow/blob/2105c94854a2f8d5d2411d08a66e6d5f7002c8d4/airflow/api_fastapi/core_api/routes/ui/dashboard.py#L49\r\n-> `end_date: DateTimeQuery | None,`\r\n\r\nI haven't fully tested the changes but from the conversation, this could lead to `None` values not returning. Because it's not allowing `None` values at the moment when you pass `None`. The query should behave the same since there aren't any changes on how we are querying the database :thinking:"", 'created_at': datetime.datetime(2024, 11, 11, 19, 45, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469009730, 'issue_id': 2646117390, 'author': 'bugraoz93', 'body': 'I can help with the changes and testing if you’d like, @tirkarthi. This issue originated from my change, but if you already have a UI set up for testing, it would be much faster to verify the changes through the UI, as it would show exactly what’s needed. Let me know how you’d like to proceed!', 'created_at': datetime.datetime(2024, 11, 11, 20, 58, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474704871, 'issue_id': 2646117390, 'author': 'bbovenzi', 'body': ""@bugraoz93 You can use this in the UI: https://github.com/apache/airflow/pull/43888\r\n\r\nI agree that we should allow end_date be `None` and then we don't need to worry about constantly changing the end_date in the UI when we set it to now."", 'created_at': datetime.datetime(2024, 11, 13, 20, 19, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476152284, 'issue_id': 2646117390, 'author': 'pierrejeambrun', 'body': ""> Doesn't this always add running dags even when I set my end_date param to be in the past? (ex: I only wanted to look at dag runs from last week)\r\n\r\nYes I think we need to pay attention to that case.\r\n\r\n\r\nAllowing end_date to be none is perfectly fine. The backend can fill it with `utcnow()` but we need the same `utcnow()` for comparison ? (if we allow filtering on None, only dags with None as end_date will show, which might not be what we want, this is why I think we should fill the value on the backend side, preventing the front-end from having to manipulate the date, etc...).\r\n\r\nOr we can make a case in the Query. We take dags with `.end_date == None` if `end_date` param is not provided (i.e None). If it is provided with an actual value, we keep the current implementation. (coalesce None to utcnow and compare)"", 'created_at': datetime.datetime(2024, 11, 14, 11, 50, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477773156, 'issue_id': 2646117390, 'author': 'tirkarthi', 'body': 'Closing in favour of https://github.com/apache/airflow/pull/44043 . Thanks everyone for the details.', 'created_at': datetime.datetime(2024, 11, 15, 1, 34, 23, tzinfo=datetime.timezone.utc)}]","bugraoz93 on (2024-11-09 20:22:54 UTC): This part was lifted and shifted from `legacy ui`/`views.py`. 
https://github.com/apache/airflow/blob/main/airflow/www/views.py#L3318-L3320

I will have time to check this in detail in 3-4 hours. If you think it is not working as expected, this should be a bug and we should fix it for old versions too. 

If you think this part doesn't provide enough latency to the new UI then, it makes sense to make the changes.

tirkarthi (Issue Creator) on (2024-11-10 04:42:29 UTC): It seems the default filters in cluster activity add 1 hour to current time as `end_date`. I am not sure if the same needs to be done in new UI since it presents preset hours like last 1 hour, 8 hours etc. for now where `end_date` has to be current time in the UI. 

https://github.com/apache/airflow/blob/6d85a0466d91d501af87c8904b902ea92cee466d/airflow/www/static/js/cluster-activity/useFilters.tsx#L52-L59

bugraoz93 on (2024-11-10 13:59:26 UTC): We should take a step back and clarify the intended use case for the `dashboard` (old `historical_metrics_data`). The current lifted and shifted version was designed to show historical data, so it makes sense not to include running jobs in this context. As we transition to the `new UI` and the `dashboard` term for this endpoint, we should ensure the endpoint aligns with the updated requirements.

It would be beneficial to get @bbovenzi and @pierrejeambrun’s input to gain the overall vision of the dashboard’s requirements.

tirkarthi (Issue Creator) on (2024-11-11 15:09:49 UTC): IMO not showing running dagruns reduces the value of the new dashboard. The running dagruns are present in current cluster activity page too. When I raised the PR I thought it was a bug. It comes to a decision over adding 1hr in UI like cluster activity or changing the API as per the PR to imply dagruns without end_date as running.

bbovenzi on (2024-11-11 15:51:06 UTC): Doesn't this always add running dags even when I set my `end_date` param to be in the past? (ex: I only wanted to look at dag runs from last week)

I think there's a few ways to redo this:
- make `end_date` an optional param
- only filter on `start_date`, then you capture any dags that ran during that time period, even if they didn't finish within that time period (if the dagrun's end_date is after the date range we also miss it)

tirkarthi (Issue Creator) on (2024-11-11 15:59:10 UTC): When the dagrun started in the last week after given start_date in the UI and yet to finish with end_date as None for the dagrun it will be present in the API with this change. Before this change it won't be shown.

bugraoz93 on (2024-11-11 19:45:58 UTC): I dug more after the answers since this was the case in the `legacy api`. We should check the parameters.py rather than editing the endpoint itself. We should return None here similar to the old version. I think I made it `ValueError` if `end_date` is not provided but as @bbovenzi said we can make this value `None` when it's not provided (optional).

**Where we should change:**
https://github.com/apache/airflow/blob/2105c94854a2f8d5d2411d08a66e6d5f7002c8d4/airflow/api_fastapi/common/parameters.py#L373-L374
**Where it was before:**
https://github.com/apache/airflow/blob/2105c94854a2f8d5d2411d08a66e6d5f7002c8d4/airflow/www/views.py#L294-L295

Of course, we should adjust this to make FastAPI accept the value as optional in the endpoint.
https://github.com/apache/airflow/blob/2105c94854a2f8d5d2411d08a66e6d5f7002c8d4/airflow/api_fastapi/core_api/routes/ui/dashboard.py#L49
-> `end_date: DateTimeQuery | None,`

I haven't fully tested the changes but from the conversation, this could lead to `None` values not returning. Because it's not allowing `None` values at the moment when you pass `None`. The query should behave the same since there aren't any changes on how we are querying the database :thinking:

bugraoz93 on (2024-11-11 20:58:27 UTC): I can help with the changes and testing if you’d like, @tirkarthi. This issue originated from my change, but if you already have a UI set up for testing, it would be much faster to verify the changes through the UI, as it would show exactly what’s needed. Let me know how you’d like to proceed!

bbovenzi on (2024-11-13 20:19:31 UTC): @bugraoz93 You can use this in the UI: https://github.com/apache/airflow/pull/43888

I agree that we should allow end_date be `None` and then we don't need to worry about constantly changing the end_date in the UI when we set it to now.

pierrejeambrun on (2024-11-14 11:50:46 UTC): Yes I think we need to pay attention to that case.


Allowing end_date to be none is perfectly fine. The backend can fill it with `utcnow()` but we need the same `utcnow()` for comparison ? (if we allow filtering on None, only dags with None as end_date will show, which might not be what we want, this is why I think we should fill the value on the backend side, preventing the front-end from having to manipulate the date, etc...).

Or we can make a case in the Query. We take dags with `.end_date == None` if `end_date` param is not provided (i.e None). If it is provided with an actual value, we keep the current implementation. (coalesce None to utcnow and compare)

tirkarthi (Issue Creator) on (2024-11-15 01:34:23 UTC): Closing in favour of https://github.com/apache/airflow/pull/44043 . Thanks everyone for the details.

"
2646102362,pull_request,closed,,#43252 Disable extra links button if link is null or empty,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",enisnazif,2024-11-09 14:02:27+00:00,[],2024-11-09 19:50:50+00:00,2024-11-09 17:40:54+00:00,https://github.com/apache/airflow/pull/43844,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('mans-hackathon', '')]","[{'comment_id': 2466386132, 'issue_id': 2646102362, 'author': 'jscheffl', 'body': '@potiuk I propose to back-port to 2.10, will make a PR...', 'created_at': datetime.datetime(2024, 11, 9, 18, 18, 17, tzinfo=datetime.timezone.utc)}]","jscheffl on (2024-11-09 18:18:17 UTC): @potiuk I propose to back-port to 2.10, will make a PR...

"
2646036664,pull_request,closed,,pydocstyle check: add leading underscore (PT004),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

works towards #40567 for PT004 (add leading underscores)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",LyndonFan,2024-11-09 13:26:11+00:00,[],2024-11-09 19:50:49+00:00,2024-11-09 16:15:19+00:00,https://github.com/apache/airflow/pull/43843,"[('area:dev-tools', ''), ('mans-hackathon', '')]","[{'comment_id': 2466213899, 'issue_id': 2646036664, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 9, 13, 26, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466272312, 'issue_id': 2646036664, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2024, 11, 9, 16, 15, 21, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-09 13:26:15 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2024-11-09 16:15:21 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2646033099,pull_request,closed,,Fix EdgeExecutor breeze call,"During development of EdgeExecutor I noticed to to rework to merge, local run via breeze was broken.

If you start breeze via 
```
breeze start-airflow --python 3.12 --load-example-dags --backend postgres --executor EdgeExecutor
```
...the executor can not be loaded because dottet mapping is missing
...but if you add the dottet mapping, breeze does not accept the executor name.

This 3 lines add the mapping to the call for shell params in beeeze",jscheffl,2024-11-09 13:21:39+00:00,[],2024-11-09 16:58:19+00:00,2024-11-09 16:58:19+00:00,https://github.com/apache/airflow/pull/43842,"[('area:dev-tools', '')]",[],
2645997168,pull_request,closed,,AIP-84 Get Configs / Get Config Value,"closes: #42745
related: #42370",jason810496,2024-11-09 12:44:36+00:00,[],2024-11-20 18:16:34+00:00,2024-11-20 15:29:48+00:00,https://github.com/apache/airflow/pull/43841,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2479685616, 'issue_id': 2645997168, 'author': 'jason810496', 'body': 'Hi @pierrejeambrun, here is the update:\r\n\r\n### Common `Accept` Header for JSON and Text\r\nI have added `HeaderAcceptJsonOrText` in `common/headers.py`, annotated with `Mimetype` from `common/types.py`. \r\n\r\nI tested it with `application/json; charset=utf-8`, and for headers including `utf-8`, we need to use `startswith` to match the header correctly. Additionally, I included an OpenAPI schema for the `Accept` header.', 'created_at': datetime.datetime(2024, 11, 15, 18, 33, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488385673, 'issue_id': 2645997168, 'author': 'jason810496', 'body': 'Just resolve the conflict  🚀', 'created_at': datetime.datetime(2024, 11, 20, 11, 53, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2488641712, 'issue_id': 2645997168, 'author': 'pierrejeambrun', 'body': 'Hello @jason810496 do you mind fixing the formatting errors, it would be great to merge this one :)', 'created_at': datetime.datetime(2024, 11, 20, 13, 51, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489060941, 'issue_id': 2645997168, 'author': 'bbovenzi', 'body': '<img width=""510"" alt=""Screenshot 2024-11-20 at 11 32 21\u202fAM"" src=""https://github.com/user-attachments/assets/a060e9a2-553f-4fd5-8820-3a84eeff7c4f"">\r\n\r\n\r\nI was just testing this and noticed that we\'re passing all the values as strings. It would be nice if I am passing \'application/json\' that values are actually converted so `\'True\'` becomes `true`, `\'5\'` becomes `5`', 'created_at': datetime.datetime(2024, 11, 20, 16, 34, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489073360, 'issue_id': 2645997168, 'author': 'rawwar', 'body': ""> I was just testing this and noticed that we're passing all the values as strings. It would be nice if I am passing 'application/json' that values are actually converted so `'True'` becomes `true`, `'5'` becomes `5`\r\n\r\nI think, that would require us to maintain a Model with all possible configs along with their type. ~~From what I remember, we typecast them after retrieving from the config. For example, retries are fetched as a string and then typecasted in methods.~~ Wrong example. \r\n\r\nBut, AirflowConfigParser has methods defined to typecast and reuse. Like for `log_fetch_timeout` \r\n\r\nhttps://github.com/rawwar/airflow/blob/9f0c4dfe224fbc417eb107f04c19d7108341f839/airflow/utils/log/file_task_handler.py#L92\r\n\r\n\r\n@bbovenzi , Should I create a separate issue? I don't think its a trivial change"", 'created_at': datetime.datetime(2024, 11, 20, 16, 39, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489096766, 'issue_id': 2645997168, 'author': 'pierrejeambrun', 'body': ""I would be for creating an issue, and tagging that as a feature request ? \r\n\r\nUnless this was already implemented in the legacy endpoint but I don't believe so.\r\n\r\nThat would be a great addition. Full string values is quite limited and force work on the client side."", 'created_at': datetime.datetime(2024, 11, 20, 16, 49, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489262498, 'issue_id': 2645997168, 'author': 'bbovenzi', 'body': ""I think I'll make this a feature for the UI only config endpoint"", 'created_at': datetime.datetime(2024, 11, 20, 18, 16, 33, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2024-11-15 18:33:38 UTC): Hi @pierrejeambrun, here is the update:

### Common `Accept` Header for JSON and Text
I have added `HeaderAcceptJsonOrText` in `common/headers.py`, annotated with `Mimetype` from `common/types.py`. 

I tested it with `application/json; charset=utf-8`, and for headers including `utf-8`, we need to use `startswith` to match the header correctly. Additionally, I included an OpenAPI schema for the `Accept` header.

jason810496 (Issue Creator) on (2024-11-20 11:53:28 UTC): Just resolve the conflict  🚀

pierrejeambrun on (2024-11-20 13:51:53 UTC): Hello @jason810496 do you mind fixing the formatting errors, it would be great to merge this one :)

bbovenzi on (2024-11-20 16:34:18 UTC): <img width=""510"" alt=""Screenshot 2024-11-20 at 11 32 21 AM"" src=""https://github.com/user-attachments/assets/a060e9a2-553f-4fd5-8820-3a84eeff7c4f"">


I was just testing this and noticed that we're passing all the values as strings. It would be nice if I am passing 'application/json' that values are actually converted so `'True'` becomes `true`, `'5'` becomes `5`

rawwar on (2024-11-20 16:39:18 UTC): I think, that would require us to maintain a Model with all possible configs along with their type. ~~From what I remember, we typecast them after retrieving from the config. For example, retries are fetched as a string and then typecasted in methods.~~ Wrong example. 

But, AirflowConfigParser has methods defined to typecast and reuse. Like for `log_fetch_timeout` 

https://github.com/rawwar/airflow/blob/9f0c4dfe224fbc417eb107f04c19d7108341f839/airflow/utils/log/file_task_handler.py#L92


@bbovenzi , Should I create a separate issue? I don't think its a trivial change

pierrejeambrun on (2024-11-20 16:49:47 UTC): I would be for creating an issue, and tagging that as a feature request ? 

Unless this was already implemented in the legacy endpoint but I don't believe so.

That would be a great addition. Full string values is quite limited and force work on the client side.

bbovenzi on (2024-11-20 18:16:33 UTC): I think I'll make this a feature for the UI only config endpoint

"
2645981362,pull_request,closed,,Fix logs with leading spaces in the Docker operator (#33692),"Python 3.11’s multi-line error arrows don’t display correctly in Airflow’s DockerOperator logs due to leading spaces being removed, making error messages hard to read.

Before fix:
```
return self.main(*args, **kwargs)
^^^^^^^^^^^^^^^^
```

After fix:
```
return self.main(*args, **kwargs)
       ^^^^^^^^^^^^^^^^
```
Fixes: https://github.com/apache/airflow/issues/33692",mrk-andreev,2024-11-09 12:03:55+00:00,[],2024-11-11 15:55:32+00:00,2024-11-09 14:29:10+00:00,https://github.com/apache/airflow/pull/43840,"[('area:providers', ''), ('provider:docker', ''), ('mans-hackathon', '')]","[{'comment_id': 2466219172, 'issue_id': 2645981362, 'author': 'potiuk', 'body': ""It could be great to use 'Fixes: #PR` to close PR after it's merged.\r\n\r\n> related: [#33692](https://github.com/apache/airflow/pull/33692)\r\n> \r\n> cc: @potiuk\r\n\r\nPlease describe in commit message what it is about -linking to issues does not leave trace in commit history."", 'created_at': datetime.datetime(2024, 11, 9, 13, 38, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466220939, 'issue_id': 2645981362, 'author': 'potiuk', 'body': ""Can  you please just improve the commit message. It's ready to go otherwise"", 'created_at': datetime.datetime(2024, 11, 9, 13, 42, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468502932, 'issue_id': 2645981362, 'author': 'notatallshaw-gts', 'body': 'Thanks for fixing this! And sorry I was never able to prioritize raising a PR, my local patch of Airflow uses the same method to solve this.', 'created_at': datetime.datetime(2024, 11, 11, 15, 55, 30, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-09 13:38:39 UTC): It could be great to use 'Fixes: #PR` to close PR after it's merged.


Please describe in commit message what it is about -linking to issues does not leave trace in commit history.

potiuk on (2024-11-09 13:42:17 UTC): Can  you please just improve the commit message. It's ready to go otherwise

notatallshaw-gts on (2024-11-11 15:55:30 UTC): Thanks for fixing this! And sorry I was never able to prioritize raising a PR, my local patch of Airflow uses the same method to solve this.

"
2645400600,pull_request,closed,,Bump `uv` to `0.5.1`,"The uv team is fast: https://github.com/astral-sh/uv/releases/tag/0.5.1

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-08 23:57:49+00:00,[],2024-11-09 01:32:54+00:00,2024-11-09 01:32:52+00:00,https://github.com/apache/airflow/pull/43838,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2645018220,pull_request,closed,,Remove async keyword for Get Connection,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/pull/43831

cc: @pierrejeambrun",omkar-foss,2024-11-08 19:48:36+00:00,['omkar-foss'],2024-11-11 17:06:40+00:00,2024-11-08 23:00:07+00:00,https://github.com/apache/airflow/pull/43836,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2644812657,pull_request,closed,,Bump apache-airflow from 2.10.1 to 2.10.3 in /performance,"Bumps [apache-airflow](https://github.com/apache/airflow) from 2.10.1 to 2.10.3.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/apache/airflow/releases"">apache-airflow's releases</a>.</em></p>
<blockquote>
<h2>Apache Airflow 2.10.3</h2>
<h1>Significant Changes</h1>
<p>No significant changes.</p>
<h2>Bug Fixes</h2>
<ul>
<li>Improves the handling of value masking when setting Airflow variables for enhanced security.  (<a href=""https://redirect.github.com/apache/airflow/issues/43123"">#43123</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43278"">#43278</a>)</li>
<li>Adds support for task_instance_mutation_hook to handle mapped operators with index 0. (<a href=""https://redirect.github.com/apache/airflow/issues/42661"">#42661</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43089"">#43089</a>)</li>
<li>Fixes executor cleanup to properly handle zombie tasks when task instances are terminated. (<a href=""https://redirect.github.com/apache/airflow/issues/43065"">#43065</a>)</li>
<li>Adds retry logic for HTTP 502 and 504 errors in internal API calls to handle webserver startup issues. (<a href=""https://redirect.github.com/apache/airflow/issues/42994"">#42994</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43044"">#43044</a>)</li>
<li>Restores the use of separate sessions for writing and deleting RTIF data to prevent StaleDataError. (<a href=""https://redirect.github.com/apache/airflow/issues/42928"">#42928</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43012"">#43012</a>)</li>
<li>Fixes PythonOperator error by replacing hyphens with underscores in DAG names. (<a href=""https://redirect.github.com/apache/airflow/issues/42993"">#42993</a>)</li>
<li>Improving validation of task retries to handle None values (<a href=""https://redirect.github.com/apache/airflow/issues/42532"">#42532</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42915"">#42915</a>)</li>
<li>Fixes error handling in dataset managers when resolving dataset aliases into new datasets (<a href=""https://redirect.github.com/apache/airflow/issues/42733"">#42733</a>)</li>
<li>Enables clicking on task names in the DAG Graph View to correctly select the corresponding task. (<a href=""https://redirect.github.com/apache/airflow/issues/38782"">#38782</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42697"">#42697</a>)</li>
<li>Prevent redirect loop on /home with tags/last run filters (<a href=""https://redirect.github.com/apache/airflow/issues/42607"">#42607</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42609"">#42609</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42628"">#42628</a>)</li>
<li>Support of host.name in OTEL metrics and usage of OTEL_RESOURCE_ATTRIBUTES in metrics (<a href=""https://redirect.github.com/apache/airflow/issues/42428"">#42428</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42604"">#42604</a>)</li>
<li>Reduce eyestrain in dark mode with reduced contrast and saturation (<a href=""https://redirect.github.com/apache/airflow/issues/42567"">#42567</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42583"">#42583</a>)</li>
<li>Handle ENTER key correctly in trigger form and allow manual JSON (<a href=""https://redirect.github.com/apache/airflow/issues/42525"">#42525</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42535"">#42535</a>)</li>
<li>Ensure DAG trigger form submits with updated parameters upon keyboard submit (<a href=""https://redirect.github.com/apache/airflow/issues/42487"">#42487</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42499"">#42499</a>)</li>
<li>Do not attempt to provide not <code>stringified</code> objects to UI via xcom if pickling is active (<a href=""https://redirect.github.com/apache/airflow/issues/42388"">#42388</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42486"">#42486</a>)</li>
<li>Fix the span link of task instance to point to the correct span in the scheduler_job_loop (<a href=""https://redirect.github.com/apache/airflow/issues/42430"">#42430</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42480"">#42480</a>)</li>
<li>Bugfix task execution from runner in Windows (<a href=""https://redirect.github.com/apache/airflow/issues/42426"">#42426</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42478"">#42478</a>)</li>
<li>Allows overriding the hardcoded OTEL_SERVICE_NAME with an environment variable (<a href=""https://redirect.github.com/apache/airflow/issues/42242"">#42242</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42441"">#42441</a>)</li>
<li>Improves trigger performance by using <code>selectinload</code> instead of <code>joinedload</code> (<a href=""https://redirect.github.com/apache/airflow/issues/40487"">#40487</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42351"">#42351</a>)</li>
<li>Suppress warnings when masking sensitive configs (<a href=""https://redirect.github.com/apache/airflow/issues/43335"">#43335</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43337"">#43337</a>)</li>
<li>Masking configuration values irrelevant to DAG author (<a href=""https://redirect.github.com/apache/airflow/issues/43040"">#43040</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43336"">#43336</a>)</li>
<li>Execute templated bash script as file in BashOperator (<a href=""https://redirect.github.com/apache/airflow/issues/43191"">#43191</a>)</li>
<li>Fixes schedule_downstream_tasks to include upstream tasks for one_success trigger rule (<a href=""https://redirect.github.com/apache/airflow/issues/42582"">#42582</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43299"">#43299</a>)</li>
<li>Add retry logic in the scheduler for updating trigger timeouts in case of deadlocks. (<a href=""https://redirect.github.com/apache/airflow/issues/41429"">#41429</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42651"">#42651</a>)</li>
<li>Mark all tasks as skipped when failing a dag_run manually (<a href=""https://redirect.github.com/apache/airflow/issues/43572"">#43572</a>)</li>
<li>Fix <code>TrySelector</code> for Mapped Tasks in Logs and Details Grid Panel (<a href=""https://redirect.github.com/apache/airflow/issues/43566"">#43566</a>)</li>
<li>Conditionally add OTEL events when processing executor events (<a href=""https://redirect.github.com/apache/airflow/issues/43558"">#43558</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43567"">#43567</a>)</li>
<li>Fix broken stat <code>scheduler_loop_duration</code> (<a href=""https://redirect.github.com/apache/airflow/issues/42886"">#42886</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43544"">#43544</a>)</li>
<li>Ensure total_entries in /api/v1/dags (<a href=""https://redirect.github.com/apache/airflow/issues/43377"">#43377</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43429"">#43429</a>)</li>
<li>Include limit and offset in request body schema for List task instances (batch) endpoint (<a href=""https://redirect.github.com/apache/airflow/issues/43479"">#43479</a>)</li>
<li>Don't raise a warning in ExecutorSafeguard when execute is called from an extended operator (<a href=""https://redirect.github.com/apache/airflow/issues/42849"">#42849</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43577"">#43577</a>)</li>
</ul>
<h2>Miscellaneous</h2>
<ul>
<li>Deprecate session auth backend (<a href=""https://redirect.github.com/apache/airflow/issues/42911"">#42911</a>)</li>
<li>Removed unicodecsv dependency for providers with Airflow version 2.8.0 and above (<a href=""https://redirect.github.com/apache/airflow/issues/42765"">#42765</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42970"">#42970</a>)</li>
<li>Remove the referrer from Webserver to Scarf (<a href=""https://redirect.github.com/apache/airflow/issues/42901"">#42901</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42942"">#42942</a>)</li>
<li>Bump <code>dompurify</code> from 2.2.9 to 2.5.6 in /airflow/www (<a href=""https://redirect.github.com/apache/airflow/issues/42263"">#42263</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42270"">#42270</a>)</li>
<li>Correct docstring format in _get_template_context (<a href=""https://redirect.github.com/apache/airflow/issues/42244"">#42244</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42272"">#42272</a>)</li>
<li>Backport: Bump Flask-AppBuilder to <code>4.5.2</code> (<a href=""https://redirect.github.com/apache/airflow/issues/43309"">#43309</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43318"">#43318</a>)</li>
<li>Check python version that was used to install pre-commit venvs (<a href=""https://redirect.github.com/apache/airflow/issues/43282"">#43282</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43310"">#43310</a>)</li>
<li>Resolve warning in Dataset Alias migration (<a href=""https://redirect.github.com/apache/airflow/issues/43425"">#43425</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/apache/airflow/blob/main/RELEASE_NOTES.rst"">apache-airflow's changelog</a>.</em></p>
<blockquote>
<h2>Airflow 2.10.3 (2024-11-05)</h2>
<p>Significant Changes
^^^^^^^^^^^^^^^^^^^</p>
<p>No significant changes.</p>
<p>Bug Fixes
&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</p>
<ul>
<li>Improves the handling of value masking when setting Airflow variables for enhanced security.  (<a href=""https://redirect.github.com/apache/airflow/issues/43123"">#43123</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43278"">#43278</a>)</li>
<li>Adds support for task_instance_mutation_hook to handle mapped operators with index 0. (<a href=""https://redirect.github.com/apache/airflow/issues/42661"">#42661</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43089"">#43089</a>)</li>
<li>Fixes executor cleanup to properly handle zombie tasks when task instances are terminated. (<a href=""https://redirect.github.com/apache/airflow/issues/43065"">#43065</a>)</li>
<li>Adds retry logic for HTTP 502 and 504 errors in internal API calls to handle webserver startup issues. (<a href=""https://redirect.github.com/apache/airflow/issues/42994"">#42994</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43044"">#43044</a>)</li>
<li>Restores the use of separate sessions for writing and deleting RTIF data to prevent StaleDataError. (<a href=""https://redirect.github.com/apache/airflow/issues/42928"">#42928</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43012"">#43012</a>)</li>
<li>Fixes PythonOperator error by replacing hyphens with underscores in DAG names. (<a href=""https://redirect.github.com/apache/airflow/issues/42993"">#42993</a>)</li>
<li>Improving validation of task retries to handle None values (<a href=""https://redirect.github.com/apache/airflow/issues/42532"">#42532</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42915"">#42915</a>)</li>
<li>Fixes error handling in dataset managers when resolving dataset aliases into new datasets (<a href=""https://redirect.github.com/apache/airflow/issues/42733"">#42733</a>)</li>
<li>Enables clicking on task names in the DAG Graph View to correctly select the corresponding task. (<a href=""https://redirect.github.com/apache/airflow/issues/38782"">#38782</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42697"">#42697</a>)</li>
<li>Prevent redirect loop on /home with tags/last run filters (<a href=""https://redirect.github.com/apache/airflow/issues/42607"">#42607</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42609"">#42609</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42628"">#42628</a>)</li>
<li>Support of host.name in OTEL metrics and usage of OTEL_RESOURCE_ATTRIBUTES in metrics (<a href=""https://redirect.github.com/apache/airflow/issues/42428"">#42428</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42604"">#42604</a>)</li>
<li>Reduce eyestrain in dark mode with reduced contrast and saturation (<a href=""https://redirect.github.com/apache/airflow/issues/42567"">#42567</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42583"">#42583</a>)</li>
<li>Handle ENTER key correctly in trigger form and allow manual JSON (<a href=""https://redirect.github.com/apache/airflow/issues/42525"">#42525</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42535"">#42535</a>)</li>
<li>Ensure DAG trigger form submits with updated parameters upon keyboard submit (<a href=""https://redirect.github.com/apache/airflow/issues/42487"">#42487</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42499"">#42499</a>)</li>
<li>Do not attempt to provide not <code>stringified</code> objects to UI via xcom if pickling is active (<a href=""https://redirect.github.com/apache/airflow/issues/42388"">#42388</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42486"">#42486</a>)</li>
<li>Fix the span link of task instance to point to the correct span in the scheduler_job_loop (<a href=""https://redirect.github.com/apache/airflow/issues/42430"">#42430</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42480"">#42480</a>)</li>
<li>Bugfix task execution from runner in Windows (<a href=""https://redirect.github.com/apache/airflow/issues/42426"">#42426</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42478"">#42478</a>)</li>
<li>Allows overriding the hardcoded OTEL_SERVICE_NAME with an environment variable (<a href=""https://redirect.github.com/apache/airflow/issues/42242"">#42242</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42441"">#42441</a>)</li>
<li>Improves trigger performance by using <code>selectinload</code> instead of <code>joinedload</code> (<a href=""https://redirect.github.com/apache/airflow/issues/40487"">#40487</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42351"">#42351</a>)</li>
<li>Suppress warnings when masking sensitive configs (<a href=""https://redirect.github.com/apache/airflow/issues/43335"">#43335</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43337"">#43337</a>)</li>
<li>Masking configuration values irrelevant to DAG author (<a href=""https://redirect.github.com/apache/airflow/issues/43040"">#43040</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43336"">#43336</a>)</li>
<li>Execute templated bash script as file in BashOperator (<a href=""https://redirect.github.com/apache/airflow/issues/43191"">#43191</a>)</li>
<li>Fixes schedule_downstream_tasks to include upstream tasks for one_success trigger rule (<a href=""https://redirect.github.com/apache/airflow/issues/42582"">#42582</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43299"">#43299</a>)</li>
<li>Add retry logic in the scheduler for updating trigger timeouts in case of deadlocks. (<a href=""https://redirect.github.com/apache/airflow/issues/41429"">#41429</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42651"">#42651</a>)</li>
<li>Mark all tasks as skipped when failing a dag_run manually (<a href=""https://redirect.github.com/apache/airflow/issues/43572"">#43572</a>)</li>
<li>Fix <code>TrySelector</code> for Mapped Tasks in Logs and Details Grid Panel (<a href=""https://redirect.github.com/apache/airflow/issues/43566"">#43566</a>)</li>
<li>Conditionally add OTEL events when processing executor events (<a href=""https://redirect.github.com/apache/airflow/issues/43558"">#43558</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43567"">#43567</a>)</li>
<li>Fix broken stat <code>scheduler_loop_duration</code> (<a href=""https://redirect.github.com/apache/airflow/issues/42886"">#42886</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43544"">#43544</a>)</li>
<li>Ensure total_entries in /api/v1/dags (<a href=""https://redirect.github.com/apache/airflow/issues/43377"">#43377</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43429"">#43429</a>)</li>
<li>Include limit and offset in request body schema for List task instances (batch) endpoint (<a href=""https://redirect.github.com/apache/airflow/issues/43479"">#43479</a>)</li>
<li>Don't raise a warning in ExecutorSafeguard when execute is called from an extended operator (<a href=""https://redirect.github.com/apache/airflow/issues/42849"">#42849</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43577"">#43577</a>)</li>
</ul>
<p>Miscellaneous
&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</p>
<ul>
<li>Deprecate session auth backend (<a href=""https://redirect.github.com/apache/airflow/issues/42911"">#42911</a>)</li>
<li>Removed unicodecsv dependency for providers with Airflow version 2.8.0 and above (<a href=""https://redirect.github.com/apache/airflow/issues/42765"">#42765</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42970"">#42970</a>)</li>
<li>Remove the referrer from Webserver to Scarf (<a href=""https://redirect.github.com/apache/airflow/issues/42901"">#42901</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42942"">#42942</a>)</li>
<li>Bump <code>dompurify</code> from 2.2.9 to 2.5.6 in /airflow/www (<a href=""https://redirect.github.com/apache/airflow/issues/42263"">#42263</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42270"">#42270</a>)</li>
<li>Correct docstring format in _get_template_context (<a href=""https://redirect.github.com/apache/airflow/issues/42244"">#42244</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/42272"">#42272</a>)</li>
<li>Backport: Bump Flask-AppBuilder to <code>4.5.2</code> (<a href=""https://redirect.github.com/apache/airflow/issues/43309"">#43309</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43318"">#43318</a>)</li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/apache/airflow/commit/c99887ec11ce3e1a43f2794fcf36d27555140f00""><code>c99887e</code></a> Update RELEASE_NOTES.rst</li>
<li><a href=""https://github.com/apache/airflow/commit/1c7fba76ec613517632931d5a268029ad24b33cb""><code>1c7fba7</code></a> mark test_task_workflow_trigger_success as flaky (<a href=""https://redirect.github.com/apache/airflow/issues/42972"">#42972</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43580"">#43580</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/08bbf89225b9b87521044fa04a9666690792a4cb""><code>08bbf89</code></a> FIX: Don't raise a warning in ExecutorSafeguard when execute is called from a...</li>
<li><a href=""https://github.com/apache/airflow/commit/7e86bf85d3bd6fda387f0a5b189f382c0673f611""><code>7e86bf8</code></a> Mark all tasks as skipped when failing a dag_run manually including t… (<a href=""https://redirect.github.com/apache/airflow/issues/43572"">#43572</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/8e79c7a27f1fdb465afdd1d4de0de7d607a27357""><code>8e79c7a</code></a> Fix TrySelector for Mapped Tasks in Logs and Details Grid Panel (<a href=""https://redirect.github.com/apache/airflow/issues/43566"">#43566</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/c12e6284c1a769da58903f076b93a32b185b12f1""><code>c12e628</code></a> Conditionally add OTEL events when processing executor events (<a href=""https://redirect.github.com/apache/airflow/issues/43558"">#43558</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43567"">#43567</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/898f332773772fea5ae76182c5393f14d212ddf8""><code>898f332</code></a> Fix broken stat scheduler_loop_duration (<a href=""https://redirect.github.com/apache/airflow/issues/42886"">#42886</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43544"">#43544</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/7aea4b56d76e80ee65613b851b5a9898df56d79a""><code>7aea4b5</code></a> Ensure total_entries in /api/v1/dags (<a href=""https://redirect.github.com/apache/airflow/issues/43377"">#43377</a>) (<a href=""https://redirect.github.com/apache/airflow/issues/43429"">#43429</a>)</li>
<li><a href=""https://github.com/apache/airflow/commit/9c044ea2a25240f7cc28b6e20337c2c4dc6e1e78""><code>9c044ea</code></a> include limit and offset in request body schema for List task instances (batc...</li>
<li><a href=""https://github.com/apache/airflow/commit/dd296c5338150cebe24c1edb46ba5a944f82a5eb""><code>dd296c5</code></a> This PR resolves an SQLAlchemy warning in the migration by correctly setting ...</li>
<li>Additional commits viewable in <a href=""https://github.com/apache/airflow/compare/2.10.1...2.10.3"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=apache-airflow&package-manager=pip&previous-version=2.10.1&new-version=2.10.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-11-08 18:25:53+00:00,[],2024-11-08 19:08:45+00:00,2024-11-08 19:08:37+00:00,https://github.com/apache/airflow/pull/43834,"[('area:dependencies', 'Issues related to dependencies problems'), ('python', 'Pull requests that update Python code')]",[],
2644529160,pull_request,closed,,"AIP-72: Add ""Get Variable"" endpoint for Execution API","This commit introduces a new endpoint, `/execution/variable/{variable_key}`, in the Execution API to retrieve Variables details.

Same as the Connections PR, it uses a placeholder `check_connection_access` function to validate task permissions for each request.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-08 16:35:57+00:00,[],2024-11-08 23:55:48+00:00,2024-11-08 23:55:47+00:00,https://github.com/apache/airflow/pull/43832,[],[],
2644505424,pull_request,closed,,AIP-84 remove remnants of async def,"Early merge re-introduced a bunch of them.

Removing.",pierrejeambrun,2024-11-08 16:23:53+00:00,['pierrejeambrun'],2024-11-08 19:01:07+00:00,2024-11-08 19:01:06+00:00,https://github.com/apache/airflow/pull/43831,"[('AIP-84', 'Modern Rest API')]",[],
2644501133,pull_request,closed,,get_task_instance_try_details API returns TaskInstanceHistory schema,"these API requests 
- get_task_instance_try_details
- get_mapped_task_instance_try_details
- get_task_instance_tries
- get_mapped_task_instance_tries
 
are actually returning TaskInstanceHistory

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
Airflow API Docs mentions that the [get_task_instance_try_details](https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html#operation/get_task_instance_try_details) return `task_instance` schema
![image](https://github.com/user-attachments/assets/0f0348b8-f701-4461-939f-7d4ef5f148cf)

But API actually returns `TaskInstanceHistory` schema

<img width=""1300"" alt=""image"" src=""https://github.com/user-attachments/assets/8c4b2fc2-eaf8-4ab5-addf-c26066050037"">

[get_task_instance_try_details method](https://github.com/apache/airflow/blob/0b59ca372f6b90994047ada636c17affa38847f8/airflow/api_connexion/endpoints/task_instance_endpoint.py#L768) also returns the `TaskInstanceHistory`

![image](https://github.com/user-attachments/assets/3c5d054b-2b31-4e38-aceb-a0305a89b0d1)
",kandharvishnu,2024-11-08 16:22:23+00:00,[],2024-11-18 09:44:28+00:00,2024-11-18 09:44:28+00:00,https://github.com/apache/airflow/pull/43830,"[('area:API', ""Airflow's REST/HTTP API""), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2470807546, 'issue_id': 2644501133, 'author': 'ephraimbuddy', 'body': ""There's no difference between TI and TI History except for loading related objects. It makes me wonder if we need this PR"", 'created_at': datetime.datetime(2024, 11, 12, 15, 15, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470901004, 'issue_id': 2644501133, 'author': 'pierrejeambrun', 'body': ""> There's no difference between TI and TI History except for loading related objects. It makes me wonder if we need this PR\r\n\r\nIn that case exposing a TaskInstance might be sufficient and less confusing for users of the API. Otherwise they might be intrigued by `TaskInstanceHistory`. Maybe in this PR we can just add a comment in the code, in the `TaskInstanceHistory` Schema to specify that there are no differences beside loading objects, and that in terms of `response` TaskInstance is fine ? (All that will be deleted soon anyway).\r\n\r\nAlso there is the deprecated `execution_date` difference, maybe the TaskInstanceHistory is missing the `logical_date`/`execution_date` ?"", 'created_at': datetime.datetime(2024, 11, 12, 15, 52, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470919913, 'issue_id': 2644501133, 'author': 'kandharvishnu', 'body': '> Also there is the deprecated `execution_date` difference, maybe the TaskInstanceHistory is missing the `logical_date`/`execution_date` ?\r\n\r\nAdditionally, I noticed that the following columns are missing in `TaskInstanceHistory` when compared with `TaskInstance`:\r\n\r\n- `sla_miss`\r\n- `rendered_map_index`\r\n- `rendered_fields`\r\n- `trigger`\r\n- `triggerer_job`\r\n- `note`', 'created_at': datetime.datetime(2024, 11, 12, 15, 59, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478510905, 'issue_id': 2644501133, 'author': 'ephraimbuddy', 'body': "">Also there is the deprecated execution_date difference, maybe the TaskInstanceHistory is missing the logical_date/execution_date ?\r\n\r\nthe logical_date/execution_date is a proxy in TaskInstance so we couldn't have it in TI history."", 'created_at': datetime.datetime(2024, 11, 15, 10, 30, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478513763, 'issue_id': 2644501133, 'author': 'ephraimbuddy', 'body': ""> > Also there is the deprecated `execution_date` difference, maybe the TaskInstanceHistory is missing the `logical_date`/`execution_date` ?\r\n> \r\n> Additionally, I noticed that the following columns are missing in `TaskInstanceHistory` when compared with `TaskInstance`:\r\n> \r\n> * `sla_miss`\r\n> * `rendered_map_index`\r\n> * `rendered_fields`\r\n> * `trigger`\r\n> * `triggerer_job`\r\n> * `note`\r\n\r\nThose are the differences. We can't be able to have those in TI history."", 'created_at': datetime.datetime(2024, 11, 15, 10, 32, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2479346734, 'issue_id': 2644501133, 'author': 'pierrejeambrun', 'body': ""> Those are the differences. We can't be able to have those in TI history.\r\n\r\nAs there are some differences I think we need to actually fix the spec with the actual response returned. Otherwise client might expect one of those fields `trigger, etc..` while those are missing."", 'created_at': datetime.datetime(2024, 11, 15, 16, 21, 52, tzinfo=datetime.timezone.utc)}]","ephraimbuddy on (2024-11-12 15:15:42 UTC): There's no difference between TI and TI History except for loading related objects. It makes me wonder if we need this PR

pierrejeambrun on (2024-11-12 15:52:19 UTC): In that case exposing a TaskInstance might be sufficient and less confusing for users of the API. Otherwise they might be intrigued by `TaskInstanceHistory`. Maybe in this PR we can just add a comment in the code, in the `TaskInstanceHistory` Schema to specify that there are no differences beside loading objects, and that in terms of `response` TaskInstance is fine ? (All that will be deleted soon anyway).

Also there is the deprecated `execution_date` difference, maybe the TaskInstanceHistory is missing the `logical_date`/`execution_date` ?

kandharvishnu (Issue Creator) on (2024-11-12 15:59:51 UTC): Additionally, I noticed that the following columns are missing in `TaskInstanceHistory` when compared with `TaskInstance`:

- `sla_miss`
- `rendered_map_index`
- `rendered_fields`
- `trigger`
- `triggerer_job`
- `note`

ephraimbuddy on (2024-11-15 10:30:56 UTC): the logical_date/execution_date is a proxy in TaskInstance so we couldn't have it in TI history.

ephraimbuddy on (2024-11-15 10:32:29 UTC): Those are the differences. We can't be able to have those in TI history.

pierrejeambrun on (2024-11-15 16:21:52 UTC): As there are some differences I think we need to actually fix the spec with the actual response returned. Otherwise client might expect one of those fields `trigger, etc..` while those are missing.

"
2644396358,pull_request,closed,,Bump UV to 0.5.0,"This PR bumps UV to 0.5.0, which is latest version

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-08 15:37:20+00:00,[],2024-11-08 18:09:36+00:00,2024-11-08 18:09:31+00:00,https://github.com/apache/airflow/pull/43829,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2644378304,pull_request,closed,,Fix `HttpToS3Operator` throws exception if s3_bucket parameter is not passed,"Fixes #43379 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kunaljubce,2024-11-08 15:33:23+00:00,[],2024-11-08 16:18:48+00:00,2024-11-08 16:18:48+00:00,https://github.com/apache/airflow/pull/43828,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2644304395,pull_request,closed,,Bump packaging version to 24.2,"
https://github.com/apache/airflow/actions/runs/11743077370/job/32715173137#step:9:76
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-08 15:05:04+00:00,[],2024-11-08 16:19:53+00:00,2024-11-08 16:19:53+00:00,https://github.com/apache/airflow/pull/43827,[],"[{'comment_id': 2465038289, 'issue_id': 2644304395, 'author': 'gopidesupavan', 'body': 'We should be able to use dependabot for these things, change is already in-progress here https://github.com/dependabot/dependabot-core/pull/10899. :)', 'created_at': datetime.datetime(2024, 11, 8, 15, 26, 36, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-08 15:26:36 UTC): We should be able to use dependabot for these things, change is already in-progress here https://github.com/dependabot/dependabot-core/pull/10899. :)

"
2644280075,pull_request,closed,,AIP-82 Save references between assets and triggers,"Resolves #42510.

This PR adds a new attributes `watchers` to the `Asset` class and saves references between assets and triggers in the DB. For example:

```
trigger = SqsSensorTrigger(sqs_queue=""my_queue"")
asset = Asset(""example_asset_watchers"", watchers=[trigger])

with DAG(
    dag_id=""example_dataset_watcher"",
    schedule=[asset],
    catchup=False,
):
    task = EmptyOperator(task_id=""task"",)

    chain(task)
```

This PR creates the trigger in the DB if it does not exist and save the reference between `asset` and `trigger`.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-08 14:54:33+00:00,[],2024-11-25 17:27:37+00:00,2024-11-25 16:13:32+00:00,https://github.com/apache/airflow/pull/43826,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:task-sdk', None)]","[{'comment_id': 2465621190, 'issue_id': 2644280075, 'author': 'vincbeck', 'body': '@Lee-W @uranusjr When working on it I realized that assets are added in the DB from DAG definition but never removed (or at least I did not see the code). Meaning, as a DAG author if I define an asset in my DAG and then later on remove it, the asset is never removed from the DB. Am I wrong? If not, is it intended?', 'created_at': datetime.datetime(2024, 11, 8, 19, 39, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466046072, 'issue_id': 2644280075, 'author': 'Lee-W', 'body': '> @Lee-W @uranusjr When working on it I realized that assets are added in the DB from DAG definition but never removed (or at least I did not see the code). Meaning, as a DAG author if I define an asset in my DAG and then later on remove it, the asset is never removed from the DB. Am I wrong? If not, is it intended?\r\n\r\nYep, this is by design as of now. To keep the asset history.', 'created_at': datetime.datetime(2024, 11, 9, 4, 45, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470846458, 'issue_id': 2644280075, 'author': 'vincbeck', 'body': '> > @Lee-W @uranusjr When working on it I realized that assets are added in the DB from DAG definition but never removed (or at least I did not see the code). Meaning, as a DAG author if I define an asset in my DAG and then later on remove it, the asset is never removed from the DB. Am I wrong? If not, is it intended?\r\n> \r\n> Yep, this is by design as of now. To keep the asset history.\r\n\r\nAlright, thank you. I handled it then. I removed the references from asset and triggers if the asset is no longer used', 'created_at': datetime.datetime(2024, 11, 12, 15, 30, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474441954, 'issue_id': 2644280075, 'author': 'vincbeck', 'body': '@Lee-W Any chance you can review it? You have some experience around assets that could be interesting to have :)', 'created_at': datetime.datetime(2024, 11, 13, 18, 37, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475109657, 'issue_id': 2644280075, 'author': 'Lee-W', 'body': '> @Lee-W Any chance you can review it? You have some experience around assets that could be interesting to have :)\r\n\r\nSure thing :) Will take a look later today', 'created_at': datetime.datetime(2024, 11, 14, 0, 37, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2497645890, 'issue_id': 2644280075, 'author': 'gopidesupavan', 'body': 'Is there a plan to add tests separate ?', 'created_at': datetime.datetime(2024, 11, 25, 10, 44, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498369542, 'issue_id': 2644280075, 'author': 'vincbeck', 'body': ""> Is there a plan to add tests separate ?\r\n\r\nDefinitely! It is covered in #42515. However, I did not add unit test for my changes in `collection.py` but I think I should. Though, I'd like to do it in a separate PR. This PR is blocking other in flight PRs I have on that project so unless someone has concerns/feedbacks, I'd like to merge it :)"", 'created_at': datetime.datetime(2024, 11, 25, 15, 42, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498389691, 'issue_id': 2644280075, 'author': 'gopidesupavan', 'body': ""> > Is there a plan to add tests separate ?\r\n> \r\n> Definitely! It is covered in #42515. However, I did not add unit test for my changes in `collection.py` but I think I should. Though, I'd like to do it in a separate PR. This PR is blocking other in flight PRs I have on that project so unless someone has concerns/feedbacks, I'd like to merge it :)\r\n\r\nah okay make sense i didnt see that task."", 'created_at': datetime.datetime(2024, 11, 25, 15, 50, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498418321, 'issue_id': 2644280075, 'author': 'vincbeck', 'body': ""> LGTM. I have played around this table updates, and I believe that every DAG collection call verifies the asset relationships and removes any unused ones. Additionally, asset relationships are only valid during the trigger's lifespan.\r\n> \r\n> This is my understand :) ?\r\n\r\nThis is correct. Just one clarification here. The trigger lifespan here is as long as the trigger is referenced as watcher of one asset. These triggers will basically live way longer than the current triggers today, those which are associated to a task. But as soon as you remove these references, these triggers will be removed"", 'created_at': datetime.datetime(2024, 11, 25, 16, 0, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2498622048, 'issue_id': 2644280075, 'author': 'gopidesupavan', 'body': ""> > LGTM. I have played around this table updates, and I believe that every DAG collection call verifies the asset relationships and removes any unused ones. Additionally, asset relationships are only valid during the trigger's lifespan.\r\n> > This is my understand :) ?\r\n> \r\n> This is correct. Just one clarification here. The trigger lifespan here is as long as the trigger is referenced as watcher of one asset. These triggers will basically live way longer than the current triggers today, those which are associated to a task. But as soon as you remove these references, these triggers will be removed\r\n\r\ncool, thank you :)"", 'created_at': datetime.datetime(2024, 11, 25, 17, 27, 35, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-11-08 19:39:21 UTC): @Lee-W @uranusjr When working on it I realized that assets are added in the DB from DAG definition but never removed (or at least I did not see the code). Meaning, as a DAG author if I define an asset in my DAG and then later on remove it, the asset is never removed from the DB. Am I wrong? If not, is it intended?

Lee-W on (2024-11-09 04:45:13 UTC): Yep, this is by design as of now. To keep the asset history.

vincbeck (Issue Creator) on (2024-11-12 15:30:44 UTC): Alright, thank you. I handled it then. I removed the references from asset and triggers if the asset is no longer used

vincbeck (Issue Creator) on (2024-11-13 18:37:47 UTC): @Lee-W Any chance you can review it? You have some experience around assets that could be interesting to have :)

Lee-W on (2024-11-14 00:37:14 UTC): Sure thing :) Will take a look later today

gopidesupavan on (2024-11-25 10:44:33 UTC): Is there a plan to add tests separate ?

vincbeck (Issue Creator) on (2024-11-25 15:42:41 UTC): Definitely! It is covered in #42515. However, I did not add unit test for my changes in `collection.py` but I think I should. Though, I'd like to do it in a separate PR. This PR is blocking other in flight PRs I have on that project so unless someone has concerns/feedbacks, I'd like to merge it :)

gopidesupavan on (2024-11-25 15:50:35 UTC): ah okay make sense i didnt see that task.

vincbeck (Issue Creator) on (2024-11-25 16:00:46 UTC): This is correct. Just one clarification here. The trigger lifespan here is as long as the trigger is referenced as watcher of one asset. These triggers will basically live way longer than the current triggers today, those which are associated to a task. But as soon as you remove these references, these triggers will be removed

gopidesupavan on (2024-11-25 17:27:35 UTC): cool, thank you :)

"
2644119686,pull_request,closed,,AIP 84: Migrate GET one ASSET legacy API to fast API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

**NOTE TO REVIEWERS**
Only last 2 commits are relevant

Depends on https://github.com/apache/airflow/pull/43783
related: https://github.com/apache/airflow/issues/42370

Migrating the connexion API for GET one ASSETS to fastAPI.

Testing performed:
> Same setup as https://github.com/apache/airflow/pull/43783

API responses:

Legacy:
<img width=""1004"" alt=""image"" src=""https://github.com/user-attachments/assets/dde5c022-d607-4dab-a9a4-b31222375995"">

FastAPI:
<img width=""1004"" alt=""image"" src=""https://github.com/user-attachments/assets/23a65cb1-031d-4f02-a018-c35e81b87ce4"">


Swagger Spec:
![image](https://github.com/user-attachments/assets/28f248c4-ad1f-4113-b3e6-c997114df6d3)

![image](https://github.com/user-attachments/assets/51a757c1-1d06-45da-8bcb-37a2b4444bc5)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-08 13:54:11+00:00,['amoghrajesh'],2024-11-14 04:05:40+00:00,2024-11-14 04:05:39+00:00,https://github.com/apache/airflow/pull/43825,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2472551693, 'issue_id': 2644119686, 'author': 'amoghrajesh', 'body': '@pierrejeambrun the PR has been rebased now. Only has the relevant changes', 'created_at': datetime.datetime(2024, 11, 13, 6, 20, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475368380, 'issue_id': 2644119686, 'author': 'amoghrajesh', 'body': 'Thanks for the review @pierrejeambrun! Handled the review comment for tests. Merging it', 'created_at': datetime.datetime(2024, 11, 14, 4, 4, 25, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-13 06:20:56 UTC): @pierrejeambrun the PR has been rebased now. Only has the relevant changes

amoghrajesh (Issue Creator) on (2024-11-14 04:04:25 UTC): Thanks for the review @pierrejeambrun! Handled the review comment for tests. Merging it

"
2644099610,pull_request,closed,,Fix duplicate `TaskInstanceState` entity in FastApi Schema,"It was the cause of https://github.com/apache/airflow/pull/43823#discussion_r1834409827 (long generated name for the component that included the entire path)

```
airflow__api_fastapi__core_api__datamodels__ui__dashboard__TaskInstanceState
TaskInstanceState
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-08 13:46:01+00:00,[],2024-11-08 14:16:05+00:00,2024-11-08 14:16:03+00:00,https://github.com/apache/airflow/pull/43824,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2644056483,pull_request,closed,,Rename Fast API serializers/schemas to `datamodels`,"Pierre, Ash & I discussed about making the naming consistent for Pydantic Models. We agreed on `datamodels` since it is what OpenAPI terms it too apart from schemas: https://swagger.io/docs/specification/v3_0/data-models/data-models/.

We didn't choose `models` because we have DB models named as such.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-08 13:27:05+00:00,[],2024-11-08 13:46:14+00:00,2024-11-08 13:45:33+00:00,https://github.com/apache/airflow/pull/43823,[],[],
2643874166,pull_request,closed,,Refactor SerializedDagModel and DagCode for dag versioning,"Now that we have dag versioning, the SerializedDagModel and DagCode objects should no longer be deleted. Deletion should start with the DagModel, which will cascade to the DagVersion, then to the DagCode and SerializedDagModel.

Also, these models are no longer updated. Instead, a new object is added; hence, the last_updated is changed to created_at.",ephraimbuddy,2024-11-08 12:07:55+00:00,[],2024-11-16 05:28:18+00:00,2024-11-16 05:28:17+00:00,https://github.com/apache/airflow/pull/43821,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]",[],
2643745188,pull_request,closed,,Disable aip 44 for less than airflow 3 versions,"Currently in the CI it sets to default to true. https://github.com/apache/airflow/blob/main/dev/breeze/src/airflow_breeze/params/shell_params.py#L491

So for the other versions also its coming as true.

ex: i ran this `breeze shell --use-airflow-version 2.8.4 --mount-sources providers-and-tests` and i could see its setting as true.

<img width=""718"" alt=""image"" src=""https://github.com/user-attachments/assets/279ddd67-a5c1-43d2-9f07-1c13d3717505"">

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-08 11:24:08+00:00,[],2024-11-23 19:56:09+00:00,2024-11-11 19:14:22+00:00,https://github.com/apache/airflow/pull/43818,[],"[{'comment_id': 2465389553, 'issue_id': 2643745188, 'author': 'potiuk', 'body': 'Exactly the errors I expected.. I guess after we have #43556  (finally) merged and rebase this one, it should fix itself :)', 'created_at': datetime.datetime(2024, 11, 8, 17, 31, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466160339, 'issue_id': 2643745188, 'author': 'gopidesupavan', 'body': '> Exactly the errors I expected.. I guess after we have #43556 (finally) merged and rebase this one, it should fix itself :)\r\n\r\nYes agree :)', 'created_at': datetime.datetime(2024, 11, 9, 10, 18, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-08 17:31:07 UTC): Exactly the errors I expected.. I guess after we have #43556  (finally) merged and rebase this one, it should fix itself :)

gopidesupavan (Issue Creator) on (2024-11-09 10:18:00 UTC): Yes agree :)

"
2643734830,pull_request,closed,,Ensure lifespans of mounted FastAPI sub-apps are called,"FastAPI does not run Starlette lifespan events in mounted sub-applications by default (see [docs](https://fastapi.tiangolo.com/advanced/events/#sub-applications)), so we use the suggestion in [this issue](https://github.com/fastapi/fastapi/issues/811#issuecomment-1870030103) to run all mounted sub-application lifespans using an async context manager stack.

To ensure that lifespan events are run in the TestApp we use a context manager for the test_app as outlined [here](https://www.starlette.io/lifespan/#running-lifespan-in-tests). To allow assertions about the lifespans we add a simple boolean variable to application state to indicate the lifespan has been run.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ianbuss,2024-11-08 11:22:26+00:00,[],2024-11-08 11:51:09+00:00,2024-11-08 11:51:09+00:00,https://github.com/apache/airflow/pull/43817,[],[],
2643177898,pull_request,closed,,Improve ExecutionCallableRunner,"This allows us to pass ""self"" to the wrapped function by using a closure class to free up that argument. I decided to keep the class-like name for compatibility. We use this in the standard provider, so let's break as little as possible.",uranusjr,2024-11-08 07:49:12+00:00,[],2024-11-08 08:38:22+00:00,2024-11-08 08:38:21+00:00,https://github.com/apache/airflow/pull/43812,[],[],
2642949629,pull_request,closed,,"[BACKPORT (Modified)] Prevent using trigger_rule=""always"" in a dynamic mapped task (#43368)","(cherry picked from commit c753ca295d72d4e3dd74b9131d3ca4c47899cd96)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Backports: #43368

Due to breaking changes I couldn't backport as-is, so I had to modify it for compatibility.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2024-11-08 05:49:21+00:00,[],2024-12-10 06:41:27+00:00,2024-11-08 07:12:17+00:00,https://github.com/apache/airflow/pull/43810,"[('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2642564327,pull_request,closed,,Bump minimum version of open-telemetry,"The min version of open-telemetry we used was pretty old and that old open-telemetry had different package structure that caused an issue with cache invalidation (see #43770). Bumping it might help resolvers in uv and PyPI to avoid downgrading the versions as well as avoid caching issues in similar scenarios.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-08 01:01:37+00:00,[],2024-11-08 08:33:58+00:00,2024-11-08 08:33:56+00:00,https://github.com/apache/airflow/pull/43809,[],[],
2642500114,pull_request,closed,,Remove hatch as devel-devscript dependency,"We do not recommend hatch any more as development tool and none of our scripts expect hatch to be installed, also our pyproject.toml should not need hatch environment definition.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-08 00:14:36+00:00,[],2024-11-08 09:22:02+00:00,2024-11-08 09:22:01+00:00,https://github.com/apache/airflow/pull/43808,"[('area:dev-tools', '')]",[],
2642385955,pull_request,closed,,Fix PostgresHook bug when getting AWS Redshift Serverless credentials,"#43669 used the wrong keys for retrieving user and password from the boto3 redshift-serverless client response, leading to `KeyError` exceptions. This change uses the correct camel-cased `dbUser` and `dbPassword` keys; the boto3 redshift client response returns the Pascal-cased `DbUser` and `DbPassword` and these were mistakenly copied into the serverless code block (and the associated test code).

Unfortunately moto does not yet support redshift-serverless, which might have caught this bug in the first PR.

related: #43669 
",topherinternational,2024-11-07 22:49:30+00:00,[],2024-11-08 12:33:22+00:00,2024-11-08 07:23:21+00:00,https://github.com/apache/airflow/pull/43807,"[('area:providers', ''), ('provider:postgres', '')]","[{'comment_id': 2464650812, 'issue_id': 2642385955, 'author': 'topherinternational', 'body': '> Nice catch!\r\n\r\nThanks, the ""catch"" was when I shadowed this code into my org\'s Airflow instance and got the key error, so I found it the hard way 😅.', 'created_at': datetime.datetime(2024, 11, 8, 12, 33, 20, tzinfo=datetime.timezone.utc)}]","topherinternational (Issue Creator) on (2024-11-08 12:33:20 UTC): Thanks, the ""catch"" was when I shadowed this code into my org's Airflow instance and got the key error, so I found it the hard way 😅.

"
2642014049,pull_request,closed,,Make sure a default sort is persisted through tableUrlState,"In https://github.com/apache/airflow/pull/43793 the osrt passed in the defaultState wasn't actually being persisted.

We missed an if statement of when to decide to use the url params or the defaultState. Also, I added a test to catch that bug.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-07 19:47:49+00:00,[],2024-11-07 21:12:33+00:00,2024-11-07 21:12:31+00:00,https://github.com/apache/airflow/pull/43803,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2463081062, 'issue_id': 2642014049, 'author': 'bbovenzi', 'body': 'cc: @tirkarthi', 'created_at': datetime.datetime(2024, 11, 7, 19, 47, 56, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2024-11-07 19:47:56 UTC): cc: @tirkarthi

"
2641981986,pull_request,closed,,Move all scroll logic to page level,"Problem: We were not consistent with how scrolling worked. Which led to zIndex and position issues. Scrolling could happen on the webpage but also inside of individual components.

Solution:
Move scroll logic to the page level. In this case on the DagsList and Dag components

![code](https://github.com/user-attachments/assets/c9a42168-af13-4176-8343-28c27a7b1248)
![card](https://github.com/user-attachments/assets/cd13c728-3218-4920-b71f-7e678f4fa7bb)
![table](https://github.com/user-attachments/assets/07904e24-2293-4af3-b77f-0486fba32f07)


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-07 19:30:37+00:00,[],2024-11-08 00:18:18+00:00,2024-11-08 00:18:17+00:00,https://github.com/apache/airflow/pull/43802,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2463051982, 'issue_id': 2641981986, 'author': 'bbovenzi', 'body': 'cc: @tirkarthi', 'created_at': datetime.datetime(2024, 11, 7, 19, 30, 49, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2024-11-07 19:30:49 UTC): cc: @tirkarthi

"
2641841276,pull_request,closed,,Added test-case for callable values in path and query parameters of MSGraphAsyncOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR allow callable values to be passed into the path and query parameters so expensive evaluations (like Variable.get) don't get evaluated during DAG processing time.  I'm aware you can get variables through jinja expressions, but in case of jinja None get's evaluated as an empty string which causes issues when calling the MSGraph end point as key/value parameters with value None aren't taken into account while empty string is causing issues further on.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-07 18:30:53+00:00,[],2024-11-28 00:40:15+00:00,2024-11-28 00:40:08+00:00,https://github.com/apache/airflow/pull/43799,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2466838832, 'issue_id': 2641841276, 'author': 'raphaelauv', 'body': 'all templated fields can already be a callable since airflow 2.10.0', 'created_at': datetime.datetime(2024, 11, 10, 18, 32, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466844847, 'issue_id': 2641841276, 'author': 'dabla', 'body': '> all templated fields can already be a callable since airflow 2.10.0\r\n\r\nOw damn well that makes it easy then we may close this one.', 'created_at': datetime.datetime(2024, 11, 10, 18, 52, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466845606, 'issue_id': 2641841276, 'author': 'dabla', 'body': 'Maybe will reopen it and keep the tests but without additional code', 'created_at': datetime.datetime(2024, 11, 10, 18, 55, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466873562, 'issue_id': 2641841276, 'author': 'dabla', 'body': '> all templated fields can already be a callable since airflow 2.10.0\r\n\r\n~~Indeed templated fields are callable, but here I also support callable values of a dict key/value pair which is passed to a templated field, which is not supported by default in templated fields.  So this PR still makes sense.~~', 'created_at': datetime.datetime(2024, 11, 10, 19, 45, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469885609, 'issue_id': 2641841276, 'author': 'dabla', 'body': ""I've removed the code regarding callable evaluation within dict values for templated fields and I've adapted the tests so it uses the already existing behaviour of the callable templated fields in Airflow."", 'created_at': datetime.datetime(2024, 11, 12, 8, 28, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470525934, 'issue_id': 2641841276, 'author': 'raphaelauv', 'body': ""I invite you to open a new PR , I don't understand what new feature you propose"", 'created_at': datetime.datetime(2024, 11, 12, 13, 25, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470531387, 'issue_id': 2641841276, 'author': 'dabla', 'body': ""> I invite you to open a new PR , I don't understand what new feature you propose\r\n\r\nI removed the feature, I just updated the tests using the callable as of 2.10.  My proposition was to also allow callables within dict parameters, but I stepped away from it.  I now just use the existing Airflow feature but updated the tests accordingly"", 'created_at': datetime.datetime(2024, 11, 12, 13, 28, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472633922, 'issue_id': 2641841276, 'author': 'dabla', 'body': '@raphaelauv just consider this PR as an improvement of the integration tests for the MSGraph operator and sensor in which I now also test the usage of lambdas supported since Airflow 2.10.0', 'created_at': datetime.datetime(2024, 11, 13, 6, 59, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505052906, 'issue_id': 2641841276, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 28, 0, 40, 13, tzinfo=datetime.timezone.utc)}]","raphaelauv on (2024-11-10 18:32:38 UTC): all templated fields can already be a callable since airflow 2.10.0

dabla (Issue Creator) on (2024-11-10 18:52:32 UTC): Ow damn well that makes it easy then we may close this one.

dabla (Issue Creator) on (2024-11-10 18:55:06 UTC): Maybe will reopen it and keep the tests but without additional code

dabla (Issue Creator) on (2024-11-10 19:45:59 UTC): ~~Indeed templated fields are callable, but here I also support callable values of a dict key/value pair which is passed to a templated field, which is not supported by default in templated fields.  So this PR still makes sense.~~

dabla (Issue Creator) on (2024-11-12 08:28:17 UTC): I've removed the code regarding callable evaluation within dict values for templated fields and I've adapted the tests so it uses the already existing behaviour of the callable templated fields in Airflow.

raphaelauv on (2024-11-12 13:25:46 UTC): I invite you to open a new PR , I don't understand what new feature you propose

dabla (Issue Creator) on (2024-11-12 13:28:21 UTC): I removed the feature, I just updated the tests using the callable as of 2.10.  My proposition was to also allow callables within dict parameters, but I stepped away from it.  I now just use the existing Airflow feature but updated the tests accordingly

dabla (Issue Creator) on (2024-11-13 06:59:21 UTC): @raphaelauv just consider this PR as an improvement of the integration tests for the MSGraph operator and sensor in which I now also test the usage of lambdas supported since Airflow 2.10.0

potiuk on (2024-11-28 00:40:13 UTC): Nice!

"
2641747734,pull_request,closed,,AIP-84 Convert async route to sync routes,"As discussed in https://github.com/apache/airflow/pull/43718#discussion_r1831803076, routes with blocking I/O code should be sync to not block main event loop. (db access, disk read, network call, etc...)

More information in FastAPI documentation https://fastapi.tiangolo.com/async/#path-operation-functions.

This PR converts all of the endpoints, all that can me converted to `async def` when we implement full async support.

(I recall Maybe one or two endpoints that are purely in memory and could stay async but I didn't bother to make an exception for them)",pierrejeambrun,2024-11-07 17:40:59+00:00,['pierrejeambrun'],2024-11-08 12:59:59+00:00,2024-11-08 11:39:20+00:00,https://github.com/apache/airflow/pull/43797,[],"[{'comment_id': 2462929296, 'issue_id': 2641747734, 'author': 'bbovenzi', 'body': 'I see three endpoints still using `async`. Do we want to change those too?\r\n\r\n<img width=""271"" alt=""Screenshot 2024-11-07 at 1 18 14\u202fPM"" src=""https://github.com/user-attachments/assets/980c1e3e-610d-4f55-bae9-88cfe6b34b24"">', 'created_at': datetime.datetime(2024, 11, 7, 18, 18, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463133820, 'issue_id': 2641747734, 'author': 'pierrejeambrun', 'body': 'Good catch,, I forgot the private API. \r\n\r\nUpdated thanks Brent.', 'created_at': datetime.datetime(2024, 11, 7, 20, 18, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463876083, 'issue_id': 2641747734, 'author': 'omkar-foss', 'body': ""Hey @pierrejeambrun, I've one concern on this - if we use sync path funcs, the FastAPI requests will run in a threadpool (one request per thread), consuming more memory per request and will limit throughput on our new APIs, as there's a default limit of 40 threads on the threadpool, please see: https://github.com/encode/starlette/issues/1724 (context: AnyIO is now used for async IO by Starlette, which in turn is used by FastAPI to handle http requests).\r\n\r\nSo, just a suggestion - instead of changing all the path funcs from async to sync, it'll be great if wrap the blocking (sync) function calls inside the path funcs to make them async, using `asyncio.to_thread` or [asyncify](https://asyncer.tiangolo.com/tutorial/asyncify/) or similar."", 'created_at': datetime.datetime(2024, 11, 8, 6, 25, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463986851, 'issue_id': 2641747734, 'author': 'dolfinus', 'body': ""Hm, I don't get why this code:\r\n```python\r\n@route.get(...)\r\ndef handler(...):\r\n  something = session.get(...)\r\n  other = session.select(...)\r\n\r\nawait asyncio.to_thread(handler)\r\n```\r\n\r\ndoes limit thoughput, but this doesn't:\r\n```python\r\n@route.get(...)\r\nasync def handler(...):\r\n  something = await asyncio.to_thread(session.get, ...)\r\n  other = await asyncio.to_thread(session.select, ...)\r\n```\r\n\r\nCould you please elaborate?"", 'created_at': datetime.datetime(2024, 11, 8, 7, 55, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464363415, 'issue_id': 2641747734, 'author': 'pierrejeambrun', 'body': 'I agree with @dolfinus, running in a separate thread manually or leveraging FastAPI to do so is more or less the same. (just less work and more code maintainability to let FastAPI handle that).\r\n\r\nLong term we will rewrite that with full async support, in the meantime FastAPI is just `sync` for us.', 'created_at': datetime.datetime(2024, 11, 8, 10, 34, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464367518, 'issue_id': 2641747734, 'author': 'omkar-foss', 'body': 'Hey @dolfinus, yes, the throughput in this case would be very similar for both snippets, because when calling `asyncio.to_thread()` (executor unspecified), the default thread pool executor will be used and be subject to same 40 thread limit. But unlike sync functions where entire request is processed in a thread, in async we\'ll have control over what should be processed in a separate thread.\r\n\r\nExample: As our new APIs have a mix of CPU-bound (e.g. common params resolution, data checks, Pydantic validations, etc.) and IO-bound (e.g. DB queries, network calls) activities, I guess we could tune it something like this:\r\n```python\r\n@route.get(...)\r\nasync def handler(...):\r\n  # CPU bound\r\n  if some_check:\r\n      raise HTTPException(status.HTTP_404_NOT_FOUND, ""Not Found"")\r\n  \r\n  # IO bound, sent to it\'s own thread\r\n  something = await asyncio.to_thread(session.get, ...)\r\n  \r\n  # CPU bound again\r\n  return SomePydanticModel(something)\r\n```\r\n\r\nWe could alternatively use `run_in_threadpool` instead of `asyncio.to_thread` which is provided by FastAPI, [example here](https://github.com/fastapi/fastapi/issues/1066#issuecomment-612940187). Either way we go, it\'ll need thorough testing to understand what\'s working for us in terms of performance! :)', 'created_at': datetime.datetime(2024, 11, 8, 10, 36, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464373231, 'issue_id': 2641747734, 'author': 'omkar-foss', 'body': '>Long term we will rewrite that with full async support, in the meantime FastAPI is just sync for us.\r\n\r\nThat would be lovely, thank you! :)', 'created_at': datetime.datetime(2024, 11, 8, 10, 39, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464501814, 'issue_id': 2641747734, 'author': 'pierrejeambrun', 'body': ""I think that would be a lot of work to maintain + code becomes hard to read + 1 mistake (someone forget to manually put into the threadpool a blocking IO call) and then the main event loop is blocked...\r\n\r\nI think we can start like that, and if it's not enough we can go deeper into the fine tuning of what is executed in the main even loop and what is run in a separate thread. I believe CPU bound operations run in a separate thread won't bottleneck. (And if they do, most likely the main even loop would struggle too, so we would have another problem here)"", 'created_at': datetime.datetime(2024, 11, 8, 11, 38, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464697718, 'issue_id': 2641747734, 'author': 'omkar-foss', 'body': 'Yes sure, sounds good! Thanks @pierrejeambrun 👍🏽', 'created_at': datetime.datetime(2024, 11, 8, 12, 59, 57, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2024-11-07 18:18:50 UTC): I see three endpoints still using `async`. Do we want to change those too?

<img width=""271"" alt=""Screenshot 2024-11-07 at 1 18 14 PM"" src=""https://github.com/user-attachments/assets/980c1e3e-610d-4f55-bae9-88cfe6b34b24"">

pierrejeambrun (Issue Creator) on (2024-11-07 20:18:44 UTC): Good catch,, I forgot the private API. 

Updated thanks Brent.

omkar-foss on (2024-11-08 06:25:26 UTC): Hey @pierrejeambrun, I've one concern on this - if we use sync path funcs, the FastAPI requests will run in a threadpool (one request per thread), consuming more memory per request and will limit throughput on our new APIs, as there's a default limit of 40 threads on the threadpool, please see: https://github.com/encode/starlette/issues/1724 (context: AnyIO is now used for async IO by Starlette, which in turn is used by FastAPI to handle http requests).

So, just a suggestion - instead of changing all the path funcs from async to sync, it'll be great if wrap the blocking (sync) function calls inside the path funcs to make them async, using `asyncio.to_thread` or [asyncify](https://asyncer.tiangolo.com/tutorial/asyncify/) or similar.

dolfinus on (2024-11-08 07:55:09 UTC): Hm, I don't get why this code:
```python
@route.get(...)
def handler(...):
  something = session.get(...)
  other = session.select(...)

await asyncio.to_thread(handler)
```

does limit thoughput, but this doesn't:
```python
@route.get(...)
async def handler(...):
  something = await asyncio.to_thread(session.get, ...)
  other = await asyncio.to_thread(session.select, ...)
```

Could you please elaborate?

pierrejeambrun (Issue Creator) on (2024-11-08 10:34:46 UTC): I agree with @dolfinus, running in a separate thread manually or leveraging FastAPI to do so is more or less the same. (just less work and more code maintainability to let FastAPI handle that).

Long term we will rewrite that with full async support, in the meantime FastAPI is just `sync` for us.

omkar-foss on (2024-11-08 10:36:43 UTC): Hey @dolfinus, yes, the throughput in this case would be very similar for both snippets, because when calling `asyncio.to_thread()` (executor unspecified), the default thread pool executor will be used and be subject to same 40 thread limit. But unlike sync functions where entire request is processed in a thread, in async we'll have control over what should be processed in a separate thread.

Example: As our new APIs have a mix of CPU-bound (e.g. common params resolution, data checks, Pydantic validations, etc.) and IO-bound (e.g. DB queries, network calls) activities, I guess we could tune it something like this:
```python
@route.get(...)
async def handler(...):
  # CPU bound
  if some_check:
      raise HTTPException(status.HTTP_404_NOT_FOUND, ""Not Found"")
  
  # IO bound, sent to it's own thread
  something = await asyncio.to_thread(session.get, ...)
  
  # CPU bound again
  return SomePydanticModel(something)
```

We could alternatively use `run_in_threadpool` instead of `asyncio.to_thread` which is provided by FastAPI, [example here](https://github.com/fastapi/fastapi/issues/1066#issuecomment-612940187). Either way we go, it'll need thorough testing to understand what's working for us in terms of performance! :)

omkar-foss on (2024-11-08 10:39:56 UTC): That would be lovely, thank you! :)

pierrejeambrun (Issue Creator) on (2024-11-08 11:38:38 UTC): I think that would be a lot of work to maintain + code becomes hard to read + 1 mistake (someone forget to manually put into the threadpool a blocking IO call) and then the main event loop is blocked...

I think we can start like that, and if it's not enough we can go deeper into the fine tuning of what is executed in the main even loop and what is run in a separate thread. I believe CPU bound operations run in a separate thread won't bottleneck. (And if they do, most likely the main even loop would struggle too, so we would have another problem here)

omkar-foss on (2024-11-08 12:59:57 UTC): Yes sure, sounds good! Thanks @pierrejeambrun 👍🏽

"
2641732668,pull_request,closed,,Generate openapi.json for the Execution API sub-app,"`include_in_schema=False` this flag meant none of the path operations were included in `/execution/openapi.json`. This was initially done to ensure this paths aren't included in the top-level client but since it is a separate App, it doesn't include the path operations on `/openapi.json` (used by UI and generated OpenAPI client) but only for App on `/execution` .

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-07 17:33:59+00:00,[],2024-11-11 11:58:21+00:00,2024-11-07 17:41:20+00:00,https://github.com/apache/airflow/pull/43796,[],"[{'comment_id': 2468002340, 'issue_id': 2641732668, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 11, 11, 58, 19, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-11 11:58:19 UTC): Nice!

"
2641642329,pull_request,closed,,Add clear button to search bar,"Add a clear button to our SearchBar component.

<img width=""778"" alt=""Screenshot 2024-11-07 at 11 55 29 AM"" src=""https://github.com/user-attachments/assets/945221a9-f021-4fb6-a24a-bd1bd8afa553"">

This required a bit of change to how the search state with debouncing worked so I made defaultValue and onChange explicit props vs buried inside of InputProps.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-07 16:58:37+00:00,[],2024-11-07 19:19:50+00:00,2024-11-07 19:19:48+00:00,https://github.com/apache/airflow/pull/43795,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2641602596,pull_request,closed,,Add global events page to browse along with support to display only events for the dag.,"This adds support to display all events under browse page. This also adds support to display events only related to the dag under events tab in dag details which is basically filter by dag_id in the API when dag_id is present in the URL. The events per dag skips dag_id column which is redundant.

Add support to filter by when, event_log_id which needs to be replaced in the backend before querying. This was done in the legacy API connexion code and the same support is added here https://github.com/apache/airflow/blob/e50206563001337befad7a8fe70e9c3df1a98fcc/airflow/api_connexion/endpoints/event_log_endpoint.py#L78

Notes for self and review : 

1. eslint fails with below error that `<Time />` cannot be constructed for `when` column but I have seen this pattern used elsewhere and also previously when dags list page only had timestamp for next/last dagrun as `<Time />`

> /home/karthikeyan/stuff/python/airflow/airflow/ui/src/pages/Events/Events.tsx
> 56:13  error  Do not define components during render. React will see a new component type on every render and destroy the entire subtree’s DOM nodes and state (https://reactjs.org/docs/reconciliation.html#elements-of-different-types). Instead, move this component definition out of the parent component “Events” and pass data as props. If you want to allow component creation in props, set allowAsProps option to true  react/no-unstable-nested-component

2. Legacy UI does sorting by `when` in descending manner by default to display latest events first. I have passed it to `useTableURLState` as default yet somehow this is not working.
3. When there are no events the page displays `No Eventss found` where Events has a double s which needs to be fixed.
4. extra column is usually a json and might need a followup PR in new UI to pretty display JSON like legacy UI.
5. The events table under the dag details tab on scroll pushes the column of the table up and needs to be fixed. This is not observed in the code page.

Related

#43704 
#43705 

Screenshots 

![image](https://github.com/user-attachments/assets/858621f1-58c5-4d71-997a-48b6950c5329)

![image](https://github.com/user-attachments/assets/4c2d1c63-eaf7-4ad8-83be-123a381d19cb)
",tirkarthi,2024-11-07 16:45:48+00:00,[],2024-11-11 15:03:26+00:00,2024-11-11 15:03:26+00:00,https://github.com/apache/airflow/pull/43793,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2465438221, 'issue_id': 2641602596, 'author': 'tirkarthi', 'body': ""Thanks @bbovenzi , I rebased the PR with latest main branch changes with fixes to scrolling and default state. Currently, clicking on events goes to `webapp/events` and does sorting by when in descending mode which is the default value. But there could be a situation where user doesn't want any sort and tries to click on `when` which causes the sorting to be empty but since sorting is empty the default sort supplied to `useTableURLState` still gets applied. User can sort by dag_id and then clicking on when will sort in asc order but once the user loads the page by default or reaches a state where no sorting is done it becomes which leads to confusion. This is slightly tricky for me to solve since default state of `sort=-when` is to be used when there is no sorting on page load but there could be legitimate use case where user wants no sorting at all including `sort=-when` . \r\n\r\nI guess maybe the link to events page in browse menu could be changed to `events?sort=-when` by default but I don't see any example in createBrowserRouter and it's not expected to match with query parameter as expected as per the comment https://github.com/remix-run/react-router/issues/9613#issuecomment-1320812151\r\n\r\nhttps://reactrouter.com/en/main/routers/create-browser-router"", 'created_at': datetime.datetime(2024, 11, 8, 17, 56, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465447483, 'issue_id': 2641602596, 'author': 'tirkarthi', 'body': ""> For extra you can try to use the renderSubComponent field on DataTable. But I'm not sure yet if that will be a great UX\r\n\r\nI will skip rendering extra column in this PR since this might have more work on design and discussion. I will create an issue to track this. Thanks."", 'created_at': datetime.datetime(2024, 11, 8, 18, 0, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465703654, 'issue_id': 2641602596, 'author': 'bbovenzi', 'body': ""> Thanks @bbovenzi , I rebased the PR with latest main branch changes with fixes to scrolling and default state. Currently, clicking on events goes to `webapp/events` and does sorting by when in descending mode which is the default value. But there could be a situation where user doesn't want any sort and tries to click on `when` which causes the sorting to be empty but since sorting is empty the default sort supplied to `useTableURLState` still gets applied. User can sort by dag_id and then clicking on when will sort in asc order but once the user loads the page by default or reaches a state where no sorting is done it becomes which leads to confusion. This is slightly tricky for me to solve since default state of `sort=-when` is to be used when there is no sorting on page load but there could be legitimate use case where user wants no sorting at all including `sort=-when` .\r\n> \r\n> I guess maybe the link to events page in browse menu could be changed to `events?sort=-when` by default but I don't see any example in createBrowserRouter and it's not expected to match with query parameter as expected as per the comment [remix-run/react-router#9613 (comment)](https://github.com/remix-run/react-router/issues/9613#issuecomment-1320812151)\r\n> \r\n> https://reactrouter.com/en/main/routers/create-browser-router\r\n\r\nOh ok so that's still a bug. If its manually set to be empty then it shouldn't fall back on the default. Let me fix that."", 'created_at': datetime.datetime(2024, 11, 8, 20, 32, 50, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2024-11-08 17:56:35 UTC): Thanks @bbovenzi , I rebased the PR with latest main branch changes with fixes to scrolling and default state. Currently, clicking on events goes to `webapp/events` and does sorting by when in descending mode which is the default value. But there could be a situation where user doesn't want any sort and tries to click on `when` which causes the sorting to be empty but since sorting is empty the default sort supplied to `useTableURLState` still gets applied. User can sort by dag_id and then clicking on when will sort in asc order but once the user loads the page by default or reaches a state where no sorting is done it becomes which leads to confusion. This is slightly tricky for me to solve since default state of `sort=-when` is to be used when there is no sorting on page load but there could be legitimate use case where user wants no sorting at all including `sort=-when` . 

I guess maybe the link to events page in browse menu could be changed to `events?sort=-when` by default but I don't see any example in createBrowserRouter and it's not expected to match with query parameter as expected as per the comment https://github.com/remix-run/react-router/issues/9613#issuecomment-1320812151

https://reactrouter.com/en/main/routers/create-browser-router

tirkarthi (Issue Creator) on (2024-11-08 18:00:44 UTC): I will skip rendering extra column in this PR since this might have more work on design and discussion. I will create an issue to track this. Thanks.

bbovenzi on (2024-11-08 20:32:50 UTC): Oh ok so that's still a bug. If its manually set to be empty then it shouldn't fall back on the default. Let me fix that.

"
2641277424,pull_request,closed,,AIP-84 Get Task Instance and Mapped Task Instance dependencies,"related to: https://github.com/apache/airflow/issues/42370

closes: https://github.com/apache/airflow/issues/43749
closes: https://github.com/apache/airflow/issues/43750",pierrejeambrun,2024-11-07 14:54:54+00:00,['pierrejeambrun'],2024-11-07 16:55:14+00:00,2024-11-07 16:55:12+00:00,https://github.com/apache/airflow/pull/43788,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2641179678,pull_request,closed,,Extract OTEL span set attrs logic in one place in the scheduler,It's very noisy.  Need to get some noise away from the operative code.,dstandish,2024-11-07 14:24:58+00:00,[],2024-11-11 11:40:22+00:00,2024-11-07 15:08:33+00:00,https://github.com/apache/airflow/pull/43787,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2467968068, 'issue_id': 2641179678, 'author': 'potiuk', 'body': 'This is indeed way better!', 'created_at': datetime.datetime(2024, 11, 11, 11, 40, 20, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-11 11:40:20 UTC): This is indeed way better!

"
2640955200,pull_request,closed,,Suppress JException when get_autocommit and set_autocommit methods aren't supported on JDBC driver,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Today we experienced that when the get_autocommit or the set_autocommit methods aren't supported on the SAS Jdbc driver,
we get an jpype.JException instead of an jaydebeapi.Error, so I added it to the suppressed exceptions.  Unfortunately, I wasn't able to add a specific test case for that exception, as I was unable to mock the JException without the need of a JVM running, which we don't want.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-07 13:01:39+00:00,[],2024-11-28 00:38:28+00:00,2024-11-28 00:38:28+00:00,https://github.com/apache/airflow/pull/43786,"[('area:providers', ''), ('provider:jdbc', '')]",[],
2640859967,pull_request,closed,,Provide option to `force_delete` for `GCSToBigQueryOperator`,"When loading data into a BigQuery table, although there are options to create or truncate the destination table using `CREATE/WRITE_DISPOSITION`, it might also be desirable to recreate the table as part of the task but this is not currently possible and requires a separate task using `BigQueryDeleteTableOperator`.

Adding a `force_delete` parameter that simply calls the BigQuery hook's `delete_table` function would enable this.",nathadfield,2024-11-07 12:18:34+00:00,[],2024-11-11 12:49:52+00:00,2024-11-11 12:49:52+00:00,https://github.com/apache/airflow/pull/43785,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2464188657, 'issue_id': 2640859967, 'author': 'nathadfield', 'body': ""> I'm not strongly against, but why not using the existing the operator for that? (I'm questioning the atomicity of transfer operators in general)\r\n\r\nIt's a fair question.\r\n\r\nThe thought process came about because of a scenario I have encountered revolving around the use of BigQuery dataset expiration policies that will automatically drop tables after a specified amount of time, e.g. 7 days, which we do for temporary/staging areas.\r\n\r\nNow, suppose I use the `GCSToBQOperator` with `CREATE_IF_NEEDED` to load some data followed by another task to perform a query against it, initially this will result in a table being created that will expire exactly 7 days after it was created.\r\n\r\nOn that seventh day, if everything all runs at the same time, then the table will not have expired yet so the GCSToBQ task will succeed but not recreate the table.  However, in the few seconds between this task ending and the downstream task starting it will be deleted resulting in a task failure due to the table not existing.\r\n\r\nThe current solution to this is to add a prior task using `BigQueryDeleteTableOperator` which is perfectly viable but just results in lots of extra tasks.  Ideally there would be a another `CREATE_DISPOSITION` option in BigQuery - `ALWAYS_RECREATE`? - which would achieve the same outcome."", 'created_at': datetime.datetime(2024, 11, 8, 9, 9, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2464236370, 'issue_id': 2640859967, 'author': 'shahar1', 'body': ""> > I'm not strongly against, but why not using the existing the operator for that? (I'm questioning the atomicity of transfer operators in general)\r\n> \r\n> It's a fair question.\r\n> \r\n> The thought process came about because of a scenario I have encountered revolving around the use of BigQuery dataset expiration policies that will automatically drop tables after a specified amount of time, e.g. 7 days, which we do for temporary/staging areas.\r\n> \r\n> Now, suppose I use the `GCSToBQOperator` with `CREATE_IF_NEEDED` to load some data followed by another task to perform a query against it, initially this will result in a table being created that will expire exactly 7 days after it was created.\r\n> \r\n> On that seventh day, if everything all runs at the same time, then the table will not have expired yet so the GCSToBQ task will succeed but not recreate the table. However, in the few seconds between this task ending and the downstream task starting it will be deleted resulting in a task failure due to the table not existing.\r\n> \r\n> The current solution to this is to add a prior task using `BigQueryDeleteTableOperator` which is perfectly viable but just results in lots of extra tasks. Ideally there would be a another `CREATE_DISPOSITION` option in BigQuery - `ALWAYS_RECREATE`? - which would achieve the same outcome.\r\n\r\nSounds fine by me, I'd be happy for additional feedback before merging."", 'created_at': datetime.datetime(2024, 11, 8, 9, 34, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2468104554, 'issue_id': 2640859967, 'author': 'potiuk', 'body': 'LGTM', 'created_at': datetime.datetime(2024, 11, 11, 12, 49, 42, tzinfo=datetime.timezone.utc)}]","nathadfield (Issue Creator) on (2024-11-08 09:09:17 UTC): It's a fair question.

The thought process came about because of a scenario I have encountered revolving around the use of BigQuery dataset expiration policies that will automatically drop tables after a specified amount of time, e.g. 7 days, which we do for temporary/staging areas.

Now, suppose I use the `GCSToBQOperator` with `CREATE_IF_NEEDED` to load some data followed by another task to perform a query against it, initially this will result in a table being created that will expire exactly 7 days after it was created.

On that seventh day, if everything all runs at the same time, then the table will not have expired yet so the GCSToBQ task will succeed but not recreate the table.  However, in the few seconds between this task ending and the downstream task starting it will be deleted resulting in a task failure due to the table not existing.

The current solution to this is to add a prior task using `BigQueryDeleteTableOperator` which is perfectly viable but just results in lots of extra tasks.  Ideally there would be a another `CREATE_DISPOSITION` option in BigQuery - `ALWAYS_RECREATE`? - which would achieve the same outcome.

shahar1 on (2024-11-08 09:34:18 UTC): Sounds fine by me, I'd be happy for additional feedback before merging.

potiuk on (2024-11-11 12:49:42 UTC): LGTM

"
2640846110,pull_request,closed,,Migrate YDB Operator to new DBAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
For historical reasons, the YDB operator had a copied DBAPI from the ydb-platform/ydb-sqlalchemy repository. It was impossible to use it without copying - the repository has a dependency on SQLAlchemy > 2.0. (problem was described here https://github.com/apache/airflow/blob/995cd8fba8de4ab3d041c7e141a0b92d786a8277/providers/src/airflow/providers/ydb/hooks/_vendor/readme.md)

At the moment we split the DBAPI and SQLAlchemy Dialect, so now there are no conflicts between them. 

In this pull request, we delete the copied files, adding a new dependency on the ydb-dbapi package, and also adapt the current YDB Operator to the new dbapi. 

YDBScanQueryOperator was more of an experiment, the new YDBExecuteQueryOperator on top of the new dbapi covers all scenarios - no need to stop it (as far as I know, none of our users have started using it)

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vgvoleg,2024-11-07 12:11:48+00:00,[],2024-11-12 16:45:14+00:00,2024-11-12 10:47:29+00:00,https://github.com/apache/airflow/pull/43784,"[('area:providers', ''), ('kind:documentation', ''), ('provider:ydb', '')]","[{'comment_id': 2467980807, 'issue_id': 2640846110, 'author': 'potiuk', 'body': 'Nice set of changes BTW :)', 'created_at': datetime.datetime(2024, 11, 11, 11, 47, 2, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-11 11:47:02 UTC): Nice set of changes BTW :)

"
2640711640,pull_request,closed,,AIP-84 Migrating GET ASSETS Legacy API to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: https://github.com/apache/airflow/issues/42370
Migrating the connexion API for GET ASSETS to fastAPI.

Testing performed:
1. Created 2 pairs of DAGS each linking to different assets
![image](https://github.com/user-attachments/assets/be467908-159a-4f7c-b4dd-584565d0244b)

2. API responses using legacy and fastAPI endpoints (one example with all params used)

Legacy API:
![image](https://github.com/user-attachments/assets/2a362751-cffd-4db3-a8ed-d2148aa1947f)

Fast API:
![image](https://github.com/user-attachments/assets/e33e5f04-8277-4b4d-869b-e92a8e3eabb0)


Swagger Spec:
![image](https://github.com/user-attachments/assets/94924260-b881-417a-8b3d-68cf975fd934)

![image](https://github.com/user-attachments/assets/ec42eec4-861f-4a8c-acce-21002dc27e9e)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-07 11:21:03+00:00,"['pierrejeambrun', 'amoghrajesh']",2024-11-12 16:04:13+00:00,2024-11-12 16:04:10+00:00,https://github.com/apache/airflow/pull/43783,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2463857797, 'issue_id': 2640711640, 'author': 'amoghrajesh', 'body': ""Okay seems like the dag_ids filter doesn't work yet. FIxing it"", 'created_at': datetime.datetime(2024, 11, 8, 6, 8, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465079626, 'issue_id': 2640711640, 'author': 'amoghrajesh', 'body': 'With the latest commits, most of the things should be taken care of.\r\n@pierrejeambrun and @ephraimbuddy addressed your comments', 'created_at': datetime.datetime(2024, 11, 8, 15, 44, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465490643, 'issue_id': 2640711640, 'author': 'pierrejeambrun', 'body': ""Thanks, don't hesitate to resolve conversation that you have adressed. I'm out of office until tuesday. (Bank holiday in france)"", 'created_at': datetime.datetime(2024, 11, 8, 18, 26, 5, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-08 06:08:01 UTC): Okay seems like the dag_ids filter doesn't work yet. FIxing it

amoghrajesh (Issue Creator) on (2024-11-08 15:44:54 UTC): With the latest commits, most of the things should be taken care of.
@pierrejeambrun and @ephraimbuddy addressed your comments

pierrejeambrun (Assginee) on (2024-11-08 18:26:05 UTC): Thanks, don't hesitate to resolve conversation that you have adressed. I'm out of office until tuesday. (Bank holiday in france)

"
2640635087,pull_request,closed,,fix(providers/common): fallback to DatasetDetails if ImportError encountered when importing AssetDetails,"## Why
`airflow.auth.managers.models.resource_details` exists after 2.8, trying to import `airflow.auth.managers.models.resource_details.AssetDetails` raises an `ImportError` instead of a `ModuleNotFoundError`

## What
Do not import if `ModuleNotFound` (2.7.x) is encountered and import DatasetDetails when `ImportError` is encountered (2.8 ⬆︎)

Related to https://github.com/apache/airflow/pull/43781

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-07 10:49:13+00:00,[],2024-11-07 11:26:12+00:00,2024-11-07 11:26:12+00:00,https://github.com/apache/airflow/pull/43781,"[('area:providers', ''), ('provider:common-compat', '')]",[],
2640567207,pull_request,closed,,Correcting the wildcard character for _SearchParam,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The fastAPI endpoints using Search Param such as DAG filtering using `dag_id_pattern` or `dag_display_name_pattern` don't return the correct result because of a wrong wildcard entry in the ORM filtering. 

Example:
![image](https://github.com/user-attachments/assets/08d1e0fe-d832-4ad3-b8ee-b5af71f96baa)

After the fix:
![image](https://github.com/user-attachments/assets/94820f48-0a31-468a-92f5-6ddb76e907a6)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-07 10:29:39+00:00,[],2024-11-07 11:00:11+00:00,2024-11-07 11:00:09+00:00,https://github.com/apache/airflow/pull/43780,[],"[{'comment_id': 2461872846, 'issue_id': 2640567207, 'author': 'pierrejeambrun', 'body': 'Thanks', 'created_at': datetime.datetime(2024, 11, 7, 10, 31, 37, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-07 10:31:37 UTC): Thanks

"
2640524139,pull_request,open,,Update min version of Celery library to 5.5.0,"Closes: https://github.com/apache/airflow/issues/41359
Closes: https://github.com/apache/airflow/issues/26542


I'm not sure if it fixes the problem described but it prevents other related bugs associated with the older versions

Celery 5.5.0 hasn't been released yet.
https://pypi.org/project/celery/#history
waiting for it",eladkal,2024-11-07 10:11:38+00:00,[],2025-01-23 17:37:59+00:00,,https://github.com/apache/airflow/pull/43777,"[('area:providers', ''), ('provider:celery', '')]","[{'comment_id': 2465918400, 'issue_id': 2640524139, 'author': 'potiuk', 'body': 'nice', 'created_at': datetime.datetime(2024, 11, 9, 0, 1, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2561502172, 'issue_id': 2640524139, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 25, 0, 15, 5, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-09 00:01:38 UTC): nice

github-actions[bot] on (2024-12-25 00:15:05 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2640298417,pull_request,closed,,AIP 84: Migrating GET ASSETS Legacy API to fastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2024-11-07 08:44:20+00:00,[],2024-11-07 10:33:55+00:00,2024-11-07 10:33:54+00:00,https://github.com/apache/airflow/pull/43775,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2461641127, 'issue_id': 2640298417, 'author': 'amoghrajesh', 'body': 'Pending Unit tests and fixing filtering by uri_pattern and dag_ids', 'created_at': datetime.datetime(2024, 11, 7, 8, 44, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461877756, 'issue_id': 2640298417, 'author': 'amoghrajesh', 'body': 'Closing in favour of another PR that I will upload soon', 'created_at': datetime.datetime(2024, 11, 7, 10, 33, 55, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2024-11-07 08:44:42 UTC): Pending Unit tests and fixing filtering by uri_pattern and dag_ids

amoghrajesh (Issue Creator) on (2024-11-07 10:33:55 UTC): Closing in favour of another PR that I will upload soon

"
2640182592,pull_request,closed,,"Add missing attribute ""name"" and ""group"" for Asset and ""group"" for AssetAlias in serialization, api and methods","## Why
asset attribute name and group are not respected in many aspect after introuduced

## What
* serialization
    * serialize attributes ""name"", ""uri"" and ""group"" for Asset
    * serialize attributes ""group"" for AssetAlias
    * change `dependency_id` to use asset name instead of uri
* assets/manager
    * filter asset by ""name"", ""URI"", and ""group"" when registering asset event
* api
    * schema
        * add ""name"", ""group"" to asset schema
        * add ""group"" to asset alias schema
    * endpoints (also the one in fastapi)
        * fix how the asset event is fetched in the create asset event endpoint
* task_sdk/asset
    * change `iter_assets` to return `((name, uri), obj)` instead of `(uri, obj)`
    * use asset ""name"" to `evaluate` instead of ""uri""
    * extend Asset as_expression methods to include ""name"", ""group"" attribute
    * extend AssetAlias as_expression to include ""group"" attribute
* lineage/hook
    * extend asset related methods to include name and group

Close: https://github.com/apache/airflow/issues/43958
---
Extend the following test case to include more asset attributes (i.e., name, group)

* [x] tests/api_fastapi/core_api/routes/ui/test_assets.py
* [x] tests/dags/test_only_empty_tasks.py
* [x] tests/dags/test_assets.py
* [x] tests/api_connexion/endpoints/test_dag_run_endpoint.py
* [x] tests/api_connexion/schemas/test_dag_schema.py
* [x] tests/api_connexion/schemas/test_asset_schema.py
* [x] tests/timetables/test_assets_timetable.py
* [x] tests/decorators/test_python.py
* [x] tests/serialization/test_serialized_objects.py
* [x] tests/serialization/test_dag_serialization.py
* [x] tests/serialization/test_serde.py
* ~~[ ] tests/io/test_wrapper.py~~ it looks like it makes more sense to keep it as it
* [x] tests/io/test_path.py
* ~d[ ] tests/utils/test_context.py~~ defer to https://github.com/apache/airflow/pull/43959
* [x] tests/utils/test_json.py
* [x] tests/models/test_dag.py
* ~~[ ] tests/models/test_taskinstance.py~~ defer to https://github.com/apache/airflow/pull/43959
* [x] tests/models/test_serialized_dag.py
* [x] tests/www/views/test_views_asset.py
* [x] tests/www/views/test_views_grid.py
* [x] tests/lineage/test_hook.py
* [x] tests/jobs/test_scheduler_job.py
* [x] tests/assets/test_asset.py
* [x] tests/assets/test_manager.py
* [x] tests/listeners/test_asset_listener.py

Rest API stuff will be handled at https://github.com/apache/airflow/issues/44412

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-07 07:51:22+00:00,['Lee-W'],2024-12-02 10:34:44+00:00,2024-12-02 10:34:42+00:00,https://github.com/apache/airflow/pull/43774,"[('area:webserver', 'Webserver related Issues'), ('area:serialization', ''), ('AIP-74', 'Dataset -> Asset'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2467340517, 'issue_id': 2640182592, 'author': 'Lee-W', 'body': '## TODO\r\nExtend the following test case to include more asset attributes\r\n\r\n* [x] tests/api_fastapi/core_api/routes/ui/test_assets.py\r\n* [x] tests/dags/test_only_empty_tasks.py\r\n* [x] tests/dags/test_assets.py\r\n* [x] tests/api_connexion/endpoints/test_dag_run_endpoint.py\r\n* [x] tests/api_connexion/schemas/test_dag_schema.py\r\n* [x] tests/api_connexion/schemas/test_asset_schema.py\r\n* [x] tests/timetables/test_assets_timetable.py\r\n* [x] tests/decorators/test_python.py\r\n* [x] tests/serialization/test_serialized_objects.py\r\n* [x] tests/serialization/test_dag_serialization.py\r\n* [x] tests/serialization/test_serde.py\r\n* ~~[ ] tests/io/test_wrapper.py~~ looks like it makes more sense to keep it as it it\r\n* [x] tests/io/test_path.py\r\n* ~d[ ] tests/utils/test_context.py~~ defer to https://github.com/apache/airflow/pull/43959\r\n* [x] tests/utils/test_json.py\r\n* [x] tests/models/test_dag.py\r\n* ~~[ ] tests/models/test_taskinstance.py~~ defer to https://github.com/apache/airflow/pull/43959\r\n* [x] tests/models/test_serialized_dag.py\r\n* [x] tests/www/views/test_views_asset.py\r\n* [x] tests/www/views/test_views_grid.py\r\n* [x] tests/lineage/test_hook.py\r\n* [x] tests/jobs/test_scheduler_job.py\r\n* [x] tests/assets/test_asset.py\r\n* [x] tests/assets/test_manager.py\r\n* [x] tests/listeners/test_asset_listener.py', 'created_at': datetime.datetime(2024, 11, 11, 6, 27, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475637845, 'issue_id': 2640182592, 'author': 'uranusjr', 'body': 'Makes sense to me. Will take another look when this is ready for review.', 'created_at': datetime.datetime(2024, 11, 14, 7, 47, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505569230, 'issue_id': 2640182592, 'author': 'amoghrajesh', 'body': 'Closing & Reopening for `legacy-api` tests', 'created_at': datetime.datetime(2024, 11, 28, 8, 51, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505733603, 'issue_id': 2640182592, 'author': 'vatsrahul1001', 'body': '@Lee-W Should I create an issue to do the same migration in fastAPI endpoints as well?', 'created_at': datetime.datetime(2024, 11, 28, 10, 10, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505758850, 'issue_id': 2640182592, 'author': 'Lee-W', 'body': '> @Lee-W Should I create an issue to do the same migration in fastAPI endpoints as well?\r\n\r\nI think I already fixed the part in Fast API. Or are there additional steps needed?', 'created_at': datetime.datetime(2024, 11, 28, 10, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505892262, 'issue_id': 2640182592, 'author': 'amoghrajesh', 'body': 'Looks like the CodeQL part goes through now', 'created_at': datetime.datetime(2024, 11, 28, 11, 26, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2505926096, 'issue_id': 2640182592, 'author': 'Lee-W', 'body': '> Looks like the CodeQL part goes through now\r\n\r\nYep! Thanks so much for helping out!', 'created_at': datetime.datetime(2024, 11, 28, 11, 45, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2506983421, 'issue_id': 2640182592, 'author': 'Lee-W', 'body': '> I think we need to update fastapi `datamodels` to be able to serialize extra `group` and `name` in responses.\r\n\r\nI just rebased, and TP seems to have fixed it already. Add one missing group column to the asset alias.\r\n\r\nother parts of asset API improvement be tracked in https://github.com/apache/airflow/issues/44412', 'created_at': datetime.datetime(2024, 11, 29, 2, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2511160394, 'issue_id': 2640182592, 'author': 'Lee-W', 'body': '> This makes sense. I wonder if we can manage the DagDependency values better… but maybe it’s not in scope for this PR.\r\n\r\nprobably need to discuss with brent maybe 🤔', 'created_at': datetime.datetime(2024, 12, 2, 10, 34, 36, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2024-11-11 06:27:19 UTC): ## TODO
Extend the following test case to include more asset attributes

* [x] tests/api_fastapi/core_api/routes/ui/test_assets.py
* [x] tests/dags/test_only_empty_tasks.py
* [x] tests/dags/test_assets.py
* [x] tests/api_connexion/endpoints/test_dag_run_endpoint.py
* [x] tests/api_connexion/schemas/test_dag_schema.py
* [x] tests/api_connexion/schemas/test_asset_schema.py
* [x] tests/timetables/test_assets_timetable.py
* [x] tests/decorators/test_python.py
* [x] tests/serialization/test_serialized_objects.py
* [x] tests/serialization/test_dag_serialization.py
* [x] tests/serialization/test_serde.py
* ~~[ ] tests/io/test_wrapper.py~~ looks like it makes more sense to keep it as it it
* [x] tests/io/test_path.py
* ~d[ ] tests/utils/test_context.py~~ defer to https://github.com/apache/airflow/pull/43959
* [x] tests/utils/test_json.py
* [x] tests/models/test_dag.py
* ~~[ ] tests/models/test_taskinstance.py~~ defer to https://github.com/apache/airflow/pull/43959
* [x] tests/models/test_serialized_dag.py
* [x] tests/www/views/test_views_asset.py
* [x] tests/www/views/test_views_grid.py
* [x] tests/lineage/test_hook.py
* [x] tests/jobs/test_scheduler_job.py
* [x] tests/assets/test_asset.py
* [x] tests/assets/test_manager.py
* [x] tests/listeners/test_asset_listener.py

uranusjr on (2024-11-14 07:47:12 UTC): Makes sense to me. Will take another look when this is ready for review.

amoghrajesh on (2024-11-28 08:51:31 UTC): Closing & Reopening for `legacy-api` tests

vatsrahul1001 on (2024-11-28 10:10:29 UTC): @Lee-W Should I create an issue to do the same migration in fastAPI endpoints as well?

Lee-W (Issue Creator) on (2024-11-28 10:20:00 UTC): I think I already fixed the part in Fast API. Or are there additional steps needed?

amoghrajesh on (2024-11-28 11:26:30 UTC): Looks like the CodeQL part goes through now

Lee-W (Issue Creator) on (2024-11-28 11:45:02 UTC): Yep! Thanks so much for helping out!

Lee-W (Issue Creator) on (2024-11-29 02:32:00 UTC): I just rebased, and TP seems to have fixed it already. Add one missing group column to the asset alias.

other parts of asset API improvement be tracked in https://github.com/apache/airflow/issues/44412

Lee-W (Issue Creator) on (2024-12-02 10:34:36 UTC): probably need to discuss with brent maybe 🤔

"
2640092162,pull_request,closed,,Move Asset user facing components to task_sdk,"## Why
As part of [AIP-72](https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-72+Task+Execution+Interface+aka+Task+SDK)

Closes: https://github.com/apache/airflow/issues/43619

## What
* Move ""Asset"", ""AssetAll"", ""AssetAny"", ""Dataset"", ""Model"", ""@asset"" from Airflow Core to task_sdk
* Import Asset from task_sdk for common.compat provider
* Fix ImportError handling in common.compat provider
    * Add a temporary workaround for this error for the following providers (which should be removed after common.compat provider change in this PR has been released)
         * providers/openlineage
         * providers/google
         * providers/amazon 


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-07 07:09:45+00:00,[],2024-12-03 14:15:58+00:00,2024-11-20 09:09:41+00:00,https://github.com/apache/airflow/pull/43773,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:lineage', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('provider:common-compat', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2639684395,pull_request,closed,,Fix pickyness of google.auth 2.36.0 for mocks,"Google-auth 2.36.0 is more picky about credentials being mocked. It expects the `universe_domain` attribute to be real string not mock because it passes it as argument of `replace` string method.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-07 02:43:23+00:00,[],2024-11-07 02:49:12+00:00,2024-11-07 02:49:11+00:00,https://github.com/apache/airflow/pull/43771,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2639640786,pull_request,closed,,Bumping epoch of cache for our dependencies,"The dependencies cached for Airlfow might sometimes cause problems that new resolution might cause conflicting dependencies - because when resolution of changed dependencies changes set of dependencies, that might leave soem of those ""orphaned"" dependencies in a version that conflicts with others.

Example of this is https://github.com/astral-sh/uv/issues/8871 where opentelemetry download caused broken installation because of a stale opentelemetry-common.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-07 02:02:00+00:00,[],2024-11-07 02:40:55+00:00,2024-11-07 02:40:53+00:00,https://github.com/apache/airflow/pull/43770,"[('area:dev-tools', '')]",[],
2639589852,pull_request,closed,,Add option --version-suffix-for-local,"Adds an option to build providers with a local suffix. This could be used for local patches to libraries or to test updates to a provider in a local installation before the official release.

The flag ""--version-suffix-for-local"" also effectively sets ""--skip-tag-check"" since this will release a subversion against a tag that already exists.

I'm sure more work is needed here; I look forward to reviews.",perry2of5,2024-11-07 01:08:34+00:00,[],2024-11-18 16:10:44+00:00,2024-11-18 02:45:45+00:00,https://github.com/apache/airflow/pull/43769,"[('area:dev-tools', '')]","[{'comment_id': 2469489823, 'issue_id': 2639589852, 'author': 'perry2of5', 'body': 'I like this suggestion. I hadn’t thought of people verifying the release, but I see the value. Thanks for pointing this out. I will implement this suggestion. Probably Wednesday or Thursday PST.', 'created_at': datetime.datetime(2024, 11, 12, 2, 55, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483489023, 'issue_id': 2639589852, 'author': 'perry2of5', 'body': 'Thanks for the help, @potiuk', 'created_at': datetime.datetime(2024, 11, 18, 16, 10, 43, tzinfo=datetime.timezone.utc)}]","perry2of5 (Issue Creator) on (2024-11-12 02:55:37 UTC): I like this suggestion. I hadn’t thought of people verifying the release, but I see the value. Thanks for pointing this out. I will implement this suggestion. Probably Wednesday or Thursday PST.

perry2of5 (Issue Creator) on (2024-11-18 16:10:43 UTC): Thanks for the help, @potiuk

"
2639519064,pull_request,closed,,Workaround strange resolution bug in `uv` with opentelemetry downgrades,"Apparently `uv 0.4.30` has some strange resolution bug that results in inconsistent dependencies in opentelemetry that are detected by `pip check` when we are running eager upgrade. This is described in detail in https://github.com/astral-sh/uv/issues/8871 . Until the issue is diagnosed and Solved, we workaround it by providing a hint to `uv` to use higher version of opentelemetry-proto than it wants to downgrade to - for no apparent reason.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-06 23:57:35+00:00,[],2024-11-07 02:10:24+00:00,2024-11-07 02:10:24+00:00,https://github.com/apache/airflow/pull/43768,"[('area:dev-tools', '')]","[{'comment_id': 2461069233, 'issue_id': 2639519064, 'author': 'potiuk', 'body': '> Tested this locally and it does allow `breeze ci-image build` to complete successfully. 👍\r\n\r\nStill - it fails when trying to generate constraints using `pypi` packages.... because it cannot build `apache-beam \r\n\r\n```\r\n    × Failed to download and build `apache-beam==2.0.0`\r\n```\r\n\r\nWhich is even stranger!. I will have to workaround it a bit more - and add a beam limitation as well it seems. I think that one will be a head-scratcher for the `uv team` and @notatallshaw :)', 'created_at': datetime.datetime(2024, 11, 7, 0, 21, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461071604, 'issue_id': 2639519064, 'author': 'potiuk', 'body': 'From: https://github.com/apache/airflow/actions/runs/11713890095/job/32627785553?pr=43768#step:12:545\r\n\r\n```\r\nRunning command: uv pip install --python /usr/local/bin/python3 \'.[all-core]\' apache-airflow-providers-airbyte apache-airflow-providers-alibaba \'apache-airflow-providers-amazon @ [...]\r\n  Running command: uv pip install --python /usr/local/bin/python3 \'.[all-core]\' apache-airflow-providers-airbyte apache-airflow-providers-alibaba \'apache-airflow-providers-amazon @ file:///dist/apache_airflow_providers_amazon-9.1.0.dev0-py3-none-any.whl\' apache-airflow-providers-apache-beam apache-airflow-providers-apache-cassandra apache-airflow-providers-apache-drill \r\n  apache-airflow-providers-apache-druid apache-airflow-providers-apache-flink apache-airflow-providers-apache-hdfs apache-airflow-providers-apache-hive apache-airflow-providers-apache-iceberg apache-airflow-providers-apache-impala apache-airflow-providers-apache-kafka apache-airflow-providers-apache-kylin apache-airflow-providers-apache-livy apache-airflow-providers-apache-pig \r\n  apache-airflow-providers-apache-pinot apache-airflow-providers-apache-spark apache-airflow-providers-apprise apache-airflow-providers-arangodb apache-airflow-providers-asana apache-airflow-providers-atlassian-jira apache-airflow-providers-celery apache-airflow-providers-cncf-kubernetes apache-airflow-providers-cohere apache-airflow-providers-common-compat apache-airflow-providers-common-io \r\n  apache-airflow-providers-common-sql apache-airflow-providers-databricks apache-airflow-providers-datadog apache-airflow-providers-dbt-cloud apache-airflow-providers-dingding apache-airflow-providers-discord apache-airflow-providers-docker apache-airflow-providers-elasticsearch apache-airflow-providers-exasol apache-airflow-providers-fab apache-airflow-providers-facebook \r\n  apache-airflow-providers-ftp apache-airflow-providers-github apache-airflow-providers-google apache-airflow-providers-grpc apache-airflow-providers-hashicorp apache-airflow-providers-http apache-airflow-providers-imap apache-airflow-providers-influxdb apache-airflow-providers-jdbc apache-airflow-providers-jenkins apache-airflow-providers-microsoft-azure apache-airflow-providers-microsoft-mssql \r\n  apache-airflow-providers-microsoft-psrp apache-airflow-providers-microsoft-winrm apache-airflow-providers-mongo apache-airflow-providers-mysql apache-airflow-providers-neo4j apache-airflow-providers-odbc apache-airflow-providers-openai apache-airflow-providers-openfaas apache-airflow-providers-openlineage apache-airflow-providers-opensearch apache-airflow-providers-opsgenie \r\n  apache-airflow-providers-oracle apache-airflow-providers-pagerduty apache-airflow-providers-papermill apache-airflow-providers-pgvector apache-airflow-providers-pinecone apache-airflow-providers-postgres apache-airflow-providers-presto apache-airflow-providers-qdrant apache-airflow-providers-redis apache-airflow-providers-salesforce apache-airflow-providers-samba apache-airflow-providers-segment \r\n  apache-airflow-providers-sendgrid apache-airflow-providers-sftp apache-airflow-providers-singularity apache-airflow-providers-slack apache-airflow-providers-smtp apache-airflow-providers-snowflake apache-airflow-providers-sqlite apache-airflow-providers-ssh \'apache-airflow-providers-standard @ file:///dist/apache_airflow_providers_standard-0.0.1.dev0-py3-none-any.whl\' \r\n  apache-airflow-providers-tableau apache-airflow-providers-telegram apache-airflow-providers-teradata apache-airflow-providers-trino apache-airflow-providers-vertica apache-airflow-providers-weaviate apache-airflow-providers-yandex apache-airflow-providers-ydb apache-airflow-providers-zendesk \'opentelemetry-proto>=1.27.0\' --resolution highest\r\n  Using Python 3.9.20 environment at /usr/local\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-common-compat`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-common-io`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-common-sql`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-ftp`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-http`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-imap`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-smtp`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-sqlite`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-standard`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-airbyte`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-alibaba`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-amazon`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-beam`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-cassandra`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-drill`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-druid`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-flink`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-hdfs`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-hive`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-iceberg`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-impala`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-kafka`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-kylin`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-livy`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-pig`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-pinot`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-spark`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apprise`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-arangodb`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-asana`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-atlassian-jira`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-celery`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-cloudant`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-cncf-kubernetes`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-cohere`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-databricks`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-datadog`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-dbt-cloud`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-dingding`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-discord`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-docker`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-elasticsearch`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-exasol`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-fab`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-facebook`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-github`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-google`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-grpc`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-hashicorp`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-influxdb`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-jdbc`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-jenkins`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-azure`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-mssql`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-psrp`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-winrm`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-mongo`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-mysql`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-neo4j`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-odbc`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-openai`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-openfaas`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-openlineage`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-opensearch`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-opsgenie`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-oracle`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-pagerduty`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-papermill`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-pgvector`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-pinecone`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-postgres`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-presto`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-qdrant`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-redis`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-salesforce`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-samba`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-segment`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-sendgrid`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-sftp`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-singularity`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-slack`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-snowflake`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-ssh`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-tableau`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-telegram`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-teradata`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-trino`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-vertica`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-weaviate`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-yandex`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-ydb`\r\n  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-zendesk`\r\n    × Failed to download and build `apache-beam==2.0.0`\r\n    ╰─▶ Build backend failed to determine requirements with `build_wheel()`\r\n        (exit status: 1)\r\n  \r\n        [stderr]\r\n        <string>:29: DeprecationWarning: pkg_resources is deprecated as an API.\r\n        See https://setuptools.pypa.io/en/latest/pkg_resources.html\r\n        Traceback (most recent call last):\r\n          File ""<string>"", line 14, in <module>\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",\r\n        line 333, in get_requires_for_build_wheel\r\n            return self._get_build_requires(config_settings, requirements=[])\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",\r\n        line 303, in _get_build_requires\r\n            self.run_setup()\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",\r\n        line 521, in run_setup\r\n            super().run_setup(setup_script=setup_script)\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",\r\n        line 319, in run_setup\r\n            exec(code, locals())\r\n          File ""<string>"", line 53, in <module>\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",\r\n        line 534, in get_distribution\r\n            dist = get_provider(dist)\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",\r\n        line 417, in get_provider\r\n            return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",\r\n        line 1070, in require\r\n            needed = self.resolve(parse_requirements(requirements))\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",\r\n        line 897, in resolve\r\n            dist = self._resolve_dist(\r\n          File\r\n        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",\r\n        line 938, in _resolve_dist\r\n            raise DistributionNotFound(req, requirers)\r\n        pkg_resources.DistributionNotFound: The \'pip\' distribution was not found\r\n        and is required by the application\r\n```', 'created_at': datetime.datetime(2024, 11, 7, 0, 23, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461073421, 'issue_id': 2639519064, 'author': 'potiuk', 'body': 'We have `apache-beam==2.60.0` - but uv  tries to download `2.0.0` ????', 'created_at': datetime.datetime(2024, 11, 7, 0, 25, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461074946, 'issue_id': 2639519064, 'author': 'ferruzzi', 'body': '> Still - it fails when trying to generate constraints using pypi packages.... because it cannot build `apache-beam\r\n\r\nWhat was the exact command that ran into that?     I ran `breeze ci-image build --python 3.9 --upgrade-to-newer-dependencies` to test it; that failed before the change and worked with this change.', 'created_at': datetime.datetime(2024, 11, 7, 0, 26, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461093301, 'issue_id': 2639519064, 'author': 'notatallshaw', 'body': ""> We have `apache-beam==2.60.0` - but uv tries to download `2.0.0` ????\r\n\r\nI'm surprised you don't see this more often: https://github.com/astral-sh/uv/issues/3078\r\n\r\nBtw, I have some big optimizations coming to pip and I see the same issue when pip is much more focused on backtracking causes.\r\n\r\nI strongly recommend Airflow puts a reasonable minimal bounds on it's providers. Or at least for apache-beam provider."", 'created_at': datetime.datetime(2024, 11, 7, 0, 46, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461125381, 'issue_id': 2639519064, 'author': 'potiuk', 'body': ""> I strongly recommend Airflow puts a reasonable minimal bounds on it's providers. Or at least for apache-beam provider.\r\n\r\nWe do `apache-beam>=2.53.0`"", 'created_at': datetime.datetime(2024, 11, 7, 1, 19, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461127796, 'issue_id': 2639519064, 'author': 'potiuk', 'body': ""> I strongly recommend Airflow puts a reasonable minimal bounds on it's providers. Or at least for apache-beam provider.\r\n\r\nAnd yes this is what we actively do for quite some time - including very recent https://github.com/apache/airflow/issues/42989 ... so ... I am just surprised it happened, but I am solving this isssue in another way (as discussed in https://github.com/astral-sh/uv/issues/8871 - by removing caching from the picture). So that one with beam == 2.0.0 might be an issue for another day :D."", 'created_at': datetime.datetime(2024, 11, 7, 1, 22, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461128919, 'issue_id': 2639519064, 'author': 'potiuk', 'body': 'Closing that one. The discussion with @notatallshaw and @charliermarsh on https://github.com/astral-sh/uv/issues/8871 - made me realise this is not an issue with `uv` and resolution but. ... cache invalidation issue.', 'created_at': datetime.datetime(2024, 11, 7, 1, 24, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461171791, 'issue_id': 2639519064, 'author': 'potiuk', 'body': 'Closing in favour of #43770', 'created_at': datetime.datetime(2024, 11, 7, 2, 10, 21, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-07 00:21:59 UTC): Still - it fails when trying to generate constraints using `pypi` packages.... because it cannot build `apache-beam 

```
    × Failed to download and build `apache-beam==2.0.0`
```

Which is even stranger!. I will have to workaround it a bit more - and add a beam limitation as well it seems. I think that one will be a head-scratcher for the `uv team` and @notatallshaw :)

potiuk (Issue Creator) on (2024-11-07 00:23:30 UTC): From: https://github.com/apache/airflow/actions/runs/11713890095/job/32627785553?pr=43768#step:12:545

```
Running command: uv pip install --python /usr/local/bin/python3 '.[all-core]' apache-airflow-providers-airbyte apache-airflow-providers-alibaba 'apache-airflow-providers-amazon @ [...]
  Running command: uv pip install --python /usr/local/bin/python3 '.[all-core]' apache-airflow-providers-airbyte apache-airflow-providers-alibaba 'apache-airflow-providers-amazon @ file:///dist/apache_airflow_providers_amazon-9.1.0.dev0-py3-none-any.whl' apache-airflow-providers-apache-beam apache-airflow-providers-apache-cassandra apache-airflow-providers-apache-drill 
  apache-airflow-providers-apache-druid apache-airflow-providers-apache-flink apache-airflow-providers-apache-hdfs apache-airflow-providers-apache-hive apache-airflow-providers-apache-iceberg apache-airflow-providers-apache-impala apache-airflow-providers-apache-kafka apache-airflow-providers-apache-kylin apache-airflow-providers-apache-livy apache-airflow-providers-apache-pig 
  apache-airflow-providers-apache-pinot apache-airflow-providers-apache-spark apache-airflow-providers-apprise apache-airflow-providers-arangodb apache-airflow-providers-asana apache-airflow-providers-atlassian-jira apache-airflow-providers-celery apache-airflow-providers-cncf-kubernetes apache-airflow-providers-cohere apache-airflow-providers-common-compat apache-airflow-providers-common-io 
  apache-airflow-providers-common-sql apache-airflow-providers-databricks apache-airflow-providers-datadog apache-airflow-providers-dbt-cloud apache-airflow-providers-dingding apache-airflow-providers-discord apache-airflow-providers-docker apache-airflow-providers-elasticsearch apache-airflow-providers-exasol apache-airflow-providers-fab apache-airflow-providers-facebook 
  apache-airflow-providers-ftp apache-airflow-providers-github apache-airflow-providers-google apache-airflow-providers-grpc apache-airflow-providers-hashicorp apache-airflow-providers-http apache-airflow-providers-imap apache-airflow-providers-influxdb apache-airflow-providers-jdbc apache-airflow-providers-jenkins apache-airflow-providers-microsoft-azure apache-airflow-providers-microsoft-mssql 
  apache-airflow-providers-microsoft-psrp apache-airflow-providers-microsoft-winrm apache-airflow-providers-mongo apache-airflow-providers-mysql apache-airflow-providers-neo4j apache-airflow-providers-odbc apache-airflow-providers-openai apache-airflow-providers-openfaas apache-airflow-providers-openlineage apache-airflow-providers-opensearch apache-airflow-providers-opsgenie 
  apache-airflow-providers-oracle apache-airflow-providers-pagerduty apache-airflow-providers-papermill apache-airflow-providers-pgvector apache-airflow-providers-pinecone apache-airflow-providers-postgres apache-airflow-providers-presto apache-airflow-providers-qdrant apache-airflow-providers-redis apache-airflow-providers-salesforce apache-airflow-providers-samba apache-airflow-providers-segment 
  apache-airflow-providers-sendgrid apache-airflow-providers-sftp apache-airflow-providers-singularity apache-airflow-providers-slack apache-airflow-providers-smtp apache-airflow-providers-snowflake apache-airflow-providers-sqlite apache-airflow-providers-ssh 'apache-airflow-providers-standard @ file:///dist/apache_airflow_providers_standard-0.0.1.dev0-py3-none-any.whl' 
  apache-airflow-providers-tableau apache-airflow-providers-telegram apache-airflow-providers-teradata apache-airflow-providers-trino apache-airflow-providers-vertica apache-airflow-providers-weaviate apache-airflow-providers-yandex apache-airflow-providers-ydb apache-airflow-providers-zendesk 'opentelemetry-proto>=1.27.0' --resolution highest
  Using Python 3.9.20 environment at /usr/local
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-common-compat`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-common-io`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-common-sql`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-ftp`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-http`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-imap`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-smtp`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-sqlite`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-standard`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-airbyte`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-alibaba`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-amazon`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-beam`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-cassandra`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-drill`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-druid`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-flink`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-hdfs`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-hive`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-iceberg`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-impala`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-kafka`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-kylin`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-livy`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-pig`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-pinot`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apache-spark`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-apprise`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-arangodb`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-asana`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-atlassian-jira`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-celery`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-cloudant`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-cncf-kubernetes`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-cohere`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-databricks`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-datadog`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-dbt-cloud`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-dingding`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-discord`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-docker`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-elasticsearch`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-exasol`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-fab`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-facebook`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-github`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-google`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-grpc`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-hashicorp`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-influxdb`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-jdbc`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-jenkins`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-azure`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-mssql`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-psrp`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-microsoft-winrm`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-mongo`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-mysql`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-neo4j`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-odbc`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-openai`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-openfaas`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-openlineage`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-opensearch`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-opsgenie`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-oracle`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-pagerduty`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-papermill`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-pgvector`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-pinecone`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-postgres`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-presto`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-qdrant`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-redis`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-salesforce`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-samba`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-segment`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-sendgrid`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-sftp`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-singularity`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-slack`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-snowflake`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-ssh`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-tableau`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-telegram`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-teradata`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-trino`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-vertica`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-weaviate`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-yandex`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-ydb`
  warning: Missing version constraint (e.g., a lower bound) for `apache-airflow-providers-zendesk`
    × Failed to download and build `apache-beam==2.0.0`
    ╰─▶ Build backend failed to determine requirements with `build_wheel()`
        (exit status: 1)
  
        [stderr]
        <string>:29: DeprecationWarning: pkg_resources is deprecated as an API.
        See https://setuptools.pypa.io/en/latest/pkg_resources.html
        Traceback (most recent call last):
          File ""<string>"", line 14, in <module>
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",
        line 333, in get_requires_for_build_wheel
            return self._get_build_requires(config_settings, requirements=[])
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",
        line 303, in _get_build_requires
            self.run_setup()
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",
        line 521, in run_setup
            super().run_setup(setup_script=setup_script)
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/setuptools/build_meta.py"",
        line 319, in run_setup
            exec(code, locals())
          File ""<string>"", line 53, in <module>
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",
        line 534, in get_distribution
            dist = get_provider(dist)
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",
        line 417, in get_provider
            return working_set.find(moduleOrReq) or require(str(moduleOrReq))[0]
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",
        line 1070, in require
            needed = self.resolve(parse_requirements(requirements))
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",
        line 897, in resolve
            dist = self._resolve_dist(
          File
        ""/tmp/.tmpSGooeS/builds-v0/.tmpWagsma/lib/python3.9/site-packages/pkg_resources/__init__.py"",
        line 938, in _resolve_dist
            raise DistributionNotFound(req, requirers)
        pkg_resources.DistributionNotFound: The 'pip' distribution was not found
        and is required by the application
```

potiuk (Issue Creator) on (2024-11-07 00:25:05 UTC): We have `apache-beam==2.60.0` - but uv  tries to download `2.0.0` ????

ferruzzi on (2024-11-07 00:26:35 UTC): What was the exact command that ran into that?     I ran `breeze ci-image build --python 3.9 --upgrade-to-newer-dependencies` to test it; that failed before the change and worked with this change.

notatallshaw on (2024-11-07 00:46:16 UTC): I'm surprised you don't see this more often: https://github.com/astral-sh/uv/issues/3078

Btw, I have some big optimizations coming to pip and I see the same issue when pip is much more focused on backtracking causes.

I strongly recommend Airflow puts a reasonable minimal bounds on it's providers. Or at least for apache-beam provider.

potiuk (Issue Creator) on (2024-11-07 01:19:54 UTC): We do `apache-beam>=2.53.0`

potiuk (Issue Creator) on (2024-11-07 01:22:48 UTC): And yes this is what we actively do for quite some time - including very recent https://github.com/apache/airflow/issues/42989 ... so ... I am just surprised it happened, but I am solving this isssue in another way (as discussed in https://github.com/astral-sh/uv/issues/8871 - by removing caching from the picture). So that one with beam == 2.0.0 might be an issue for another day :D.

potiuk (Issue Creator) on (2024-11-07 01:24:05 UTC): Closing that one. The discussion with @notatallshaw and @charliermarsh on https://github.com/astral-sh/uv/issues/8871 - made me realise this is not an issue with `uv` and resolution but. ... cache invalidation issue.

potiuk (Issue Creator) on (2024-11-07 02:10:21 UTC): Closing in favour of #43770

"
2639451064,pull_request,closed,,"AIP-72: Add ""Get Connection"" endpoint for Execution API","AIP doc: https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-72+Task+Execution+Interface+aka+Task+SDK
Part of https://github.com/orgs/apache/projects/405/views/1

This commit introduces a new endpoint, `/execution/connection/{connection_id}`, in the Execution API to retrieve connection details. 

### Changes:

This PR adds:
- `get_connection` endpoint to fetch connection details by `connection_id` from all secrets backend. For the deployments that don’t want to get conns from all secres backend — they could not set Secrets backend on API Server.. that way it falls back to DB.
- Placeholder function `get_task_token()` for token-based access control.
- Placeholder `check_connection_access` function to validate task permissions for each connection request.

### Access control
- Access to connections is determined by the `allowed_connections` attribute in the task token (currently mocked).
- Endpoint returns a 403 Forbidden status if the task does not have permission for the requested connection.
- Placeholder `get_task_token()` function simulates task authentication; future updates will include JWT-based authentication.

### Future Work
- Replace the placeholder `get_task_token()` with actual JWT-based authentication to dynamically determine task permissions. This would be done more holistically.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-06 23:13:05+00:00,[],2024-11-07 17:11:40+00:00,2024-11-07 17:11:38+00:00,https://github.com/apache/airflow/pull/43767,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2639363459,pull_request,closed,,AIP-84 Migrate test a connection to FastAPI API,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42594
It includes unifying parameter naming conventions for `test_connections.py`

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-11-06 22:18:00+00:00,[],2024-11-12 17:00:16+00:00,2024-11-12 17:00:16+00:00,https://github.com/apache/airflow/pull/43766,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2470935549, 'issue_id': 2639363459, 'author': 'bugraoz93', 'body': 'Rebased and solved the conflicts.', 'created_at': datetime.datetime(2024, 11, 12, 16, 6, 5, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-11-12 16:06:05 UTC): Rebased and solved the conflicts.

"
2639113792,pull_request,closed,,Bump happy-dom from 15.10.1 to 15.10.2 in /airflow/ui,"Bumps [happy-dom](https://github.com/capricorn86/happy-dom) from 15.10.1 to 15.10.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/capricorn86/happy-dom/releases"">happy-dom's releases</a>.</em></p>
<blockquote>
<h2>v15.10.2</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Fixes a security vulnerability that allowed for server side code to be executed by a <code>&lt;script&gt;</code> tag - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1585"">#1585</a>
<ul>
<li>There was a case that was missed with the first patch</li>
</ul>
</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/d23834c232f1cf5519c9418b073f1dcec6b2f0fd""><code>d23834c</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1585"">#1585</a> Fixes a security vulnerability that allowed for server side code...</li>
<li>See full diff in <a href=""https://github.com/capricorn86/happy-dom/compare/v15.10.1...v15.10.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=happy-dom&package-manager=npm_and_yarn&previous-version=15.10.1&new-version=15.10.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-11-06 20:11:30+00:00,[],2024-11-06 21:17:58+00:00,2024-11-06 21:17:49+00:00,https://github.com/apache/airflow/pull/43765,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2638889620,pull_request,closed,,"Update the ""legacy command"" help text for backfill","In 1.x there was an `airflow backfill` command.  In 2.x it became `airflow dags backfill`.

In 3.x it's back to `airflow backfill`.

Need to update the ""yo, your command been moved"" text.
",dstandish,2024-11-06 18:28:21+00:00,[],2024-11-12 23:20:17+00:00,2024-11-12 23:20:15+00:00,https://github.com/apache/airflow/pull/43764,"[('area:CLI', '')]",[],
2638833864,pull_request,closed,,Remove AIRFLOW_V_2_8_PLUS for provider's compatibility tests,"The AIRFLOW_V_2_8_PLUS is not needed as min airflow version already is 2.8.0+.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-06 17:57:54+00:00,[],2024-11-07 09:41:01+00:00,2024-11-07 09:40:59+00:00,https://github.com/apache/airflow/pull/43763,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:common-sql', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2460435091, 'issue_id': 2638833864, 'author': 'potiuk', 'body': 'Extracted from #43556', 'created_at': datetime.datetime(2024, 11, 6, 17, 58, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461205488, 'issue_id': 2638833864, 'author': 'potiuk', 'body': 'Failing tests should be fixed after https://github.com/apache/airflow/pull/43771 is merged.', 'created_at': datetime.datetime(2024, 11, 7, 2, 48, 55, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-06 17:58:46 UTC): Extracted from #43556

potiuk (Issue Creator) on (2024-11-07 02:48:55 UTC): Failing tests should be fixed after https://github.com/apache/airflow/pull/43771 is merged.

"
2638731109,pull_request,closed,,Update 'namespace' priority for 'find_pod' function,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have updated the `namespace` priority for the `find_pod` function.  Because we faced the bug, in case when the user specified `namespace` in the task and inside the metadata for  `pod_request_obj` user has a different namespace. Then `namespace` will be overwritten by the value which is specified in the task.  This priority looks incorrect, because in the `find_pod` function we need to find a Pod which has already started. And information about this Pod inside the `pod_request_obj` variable. It means that firstly we need to check value in `pod_request_obj.metadata.namespace` and, then, value inside `self.namespace`.      

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2024-11-06 17:16:11+00:00,[],2024-11-14 08:30:47+00:00,2024-11-14 08:30:47+00:00,https://github.com/apache/airflow/pull/43762,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2638714262,pull_request,closed,,Remove connections file in Execution API,"Sry! bad merge, it is the copy/paste of task_instance file and fixed some typos

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-06 17:08:06+00:00,[],2024-11-06 17:18:56+00:00,2024-11-06 17:18:55+00:00,https://github.com/apache/airflow/pull/43761,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2638550298,pull_request,closed,,AIP-84 List Task Instances,"related to https://github.com/apache/airflow/issues/42370

On top of https://github.com/apache/airflow/pull/43642, only last commit is relevant.

Closes: https://github.com/apache/airflow/issues/43748",pierrejeambrun,2024-11-06 16:06:55+00:00,['pierrejeambrun'],2024-11-07 15:28:59+00:00,2024-11-07 15:28:57+00:00,https://github.com/apache/airflow/pull/43760,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2638498368,pull_request,closed,,Bump happy-dom from 15.0.0 to 15.10.1 in /airflow/ui,"Bumps [happy-dom](https://github.com/capricorn86/happy-dom) from 15.0.0 to 15.10.1.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/capricorn86/happy-dom/releases"">happy-dom's releases</a>.</em></p>
<blockquote>
<h2>v15.10.1</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Fixes a security vulnerability that allowed for server side code to be executed by a <code>&lt;script&gt;</code> tag - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1585"">#1585</a></li>
</ul>
<h2>v15.10.0</h2>
<h3>:art: Features</h3>
<ul>
<li>Adds setting disableSameOriginPolicy, to make it possible to bypass the same-origin policy - By <strong><a href=""https://github.com/betterqualityassuranceuser""><code>@​betterqualityassuranceuser</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1553"">#1553</a></li>
</ul>
<h2>v15.9.0</h2>
<h3>:art: Features</h3>
<ul>
<li>Adds support for &quot;aspect-ratio&quot; to <code>CSSStyleDeclaration</code> - By <strong><a href=""https://github.com/yinm""><code>@​yinm</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1147"">#1147</a></li>
</ul>
<h2>v15.8.5</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Fixes bug where <code>Node.getRootNode()</code> returned null when it was  within a <code>ShadowRoot</code> that previously been disconnected from the <code>Document</code> - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1581"">#1581</a></li>
</ul>
<h2>v15.8.4</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Fixes bug where child nodes of <code>HTMLSelectElement</code> and <code>HTMLFormElement</code> had the wrong reference to the parent - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1578"">#1578</a></li>
</ul>
<h2>v15.8.3</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Toggle &quot;open&quot; attribute on <code>HTMLDetailsElement</code> when dispatching a click event on a summary element which is a child of the details element - By <strong><a href=""https://github.com/mikedidomizio""><code>@​mikedidomizio</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1534"">#1534</a></li>
</ul>
<h2>v15.8.2</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Use <code>globalThis</code> instead of <code>global</code> to make Happy DOM work in other runtimes such as Cloudflare workers - By <strong><a href=""https://github.com/mattallty""><code>@​mattallty</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1546"">#1546</a></li>
</ul>
<h2>v15.8.1</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Always return <code>Promise&lt;Blob&gt;</code> from <code>ClipboardItem.getType()</code> - By <strong><a href=""https://github.com/ezzatron""><code>@​ezzatron</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1538"">#1538</a></li>
</ul>
<h2>v15.8.0</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Adds support for using non-ASCII characters in custom elements when parsing HTML - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a></li>
<li>Fixes an issue where <code>getHTML()</code> and <code>getInnerHTML()</code> would return the slotted content of a shadow root before the template, but the template should be the first child - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a></li>
<li>Fixes a bug where SVG elements would not be found by <code>getElementsByTagName()</code> - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a></li>
<li>Improves performance when creating elements (e.g. during parsing of HTML) - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1550"">#1550</a>
<ul>
<li>Binding all methods to the target scope in Proxies caused a performance hit, so this is now done when calling a method the first time</li>
</ul>
</li>
</ul>
<h3>:art: Features</h3>
<ul>
<li>Adds support for all remaining SVG elements: <code>SVGAnimateElement</code>, <code>SVGAnimateMotionElement</code>, <code>SVGAnimateTransformElement</code>, <code>SVGCircleElement</code>, <code>SVGClipPathElement</code>, <code>SVGDefsElement</code>, <code>SVGDescElement</code>, <code>SVGEllipseElement</code>, <code>SVGFEBlendElement</code>, <code>SVGFEColorMatrixElement</code>, <code>SVGFEComponentTransferElement</code>, <code>SVGFECompositeElement</code>, <code>SVGFEConvolveMatrixElement</code>, <code>SVGFEDiffuseLightingElement</code>, <code>SVGFEDisplacementMapElement</code>, <code>SVGFEDistantLightElement</code>, <code>SVGFEDropShadowElement</code>, <code>SVGFEFloodElement</code>, <code>SVGFEFuncAElement</code>, <code>SVGFEFuncBElement</code>, <code>SVGFEFuncGElement</code>, <code>SVGFEFuncRElement</code>, <code>SVGFEGaussianBlurElement</code>, <code>SVGFEImageElement</code>, <code>SVGFEMergeElement</code>, <code>SVGFEMergeNodeElement</code>, <code>SVGFEMorphologyElement</code>, <code>SVGFEOffsetElement</code>, <code>SVGFEPointLightElement</code>, <code>SVGFESpecularLightingElement</code>, <code>SVGFESpotLightElement</code>, <code>SVGFETileElement</code>, <code>SVGFETurbulenceElement</code>, <code>SVGFilterElement</code>, <code>SVGForeignObjectElement</code>, <code>SVGGElement</code>, <code>SVGImageElement</code>, <code>SVGLineElement</code>, <code>SVGLinearGradientElement</code>, <code>SVGMarkerElement</code>, <code>SVGMaskElement</code>, <code>SVGMetadataElement</code>, <code>SVGMPathElement</code>, <code>SVGPathElement</code>, <code>SVGPatternElement</code>, <code>SVGPolygonElement</code>, <code>SVGPolylineElement</code>, <code>SVGRadialGradientElement</code>, <code>SVGRectElement</code>, <code>SVGScriptElement</code>, <code>SVGSetElement</code>, <code>SVGStopElement</code>, <code>SVGStyleElement</code>, <code>SVGSwitchElement</code>, <code>SVGSymbolElement</code>, <code>SVGTextElement</code>, <code>SVGTextPathElement</code>, <code>SVGTitleElement</code>, <code>SVGTSpanElement</code>, <code>SVGUseElement</code> and <code>SVGViewElement</code> - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a></li>
<li>Adds support for <code>DOMMatrix</code>, <code>DOMMatrixReadOnly</code>, <code>DOMPoint</code> and <code>DOMPointReadOnly</code> - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a></li>
<li>Adds support for <code>SVGAngle</code>, <code>SVGAnimatedAngle</code>, <code>SVGAnimatedBoolean</code>, <code>SVGAnimatedEnumeration</code>, <code>SVGAnimatedInteger</code>, <code>SVGAnimatedLength</code>, <code>SVGAnimatedLengthList</code>, <code>SVGAnimatedNumber</code>, <code>SVGAnimatedNumberList</code>, <code>SVGAnimatedPreserveAspectRatio</code>, <code>SVGAnimatedRect</code>, <code>SVGAnimatedString</code>, <code>SVGAnimatedTransformList</code>, <code>SVGLength</code>, <code>SVGLengthList</code>, <code>SVGMatrix</code>, <code>SVGNumber</code>, <code>SVGNumberList</code>, <code>SVGPoint</code>, <code>SVGPointList</code>, <code>SVGPreserveAspectRatio</code>, <code>SVGRect</code>, <code>SVGStringList</code>, <code>SVGTransform</code>, <code>SVGTransformList</code> and <code>SVGUnitTypes</code> - By <strong><a href=""https://github.com/capricorn86""><code>@​capricorn86</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a></li>
</ul>
<h2>v15.7.4</h2>
<h3>:construction_worker_man: Patch fixes</h3>
<ul>
<li>Fixes incorrect handling of non-node items inserted using <code>replaceWith()</code>, <code>before()</code> and <code>after()</code> - By <strong><a href=""https://github.com/BenjaminAster""><code>@​BenjaminAster</code></a></strong> in task <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1533"">#1533</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/5ee0b1676d4ce20cc2a70d1c9c8d6f1e3f57efac""><code>5ee0b16</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1585"">#1585</a> Fixes security vulnerability that allowed for server side code t...</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/a20dba9440b5e93b6f0364c220212f0ce4264b27""><code>a20dba9</code></a> chore: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1542"">#1542</a> Adds SECURITY.md file (<a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1584"">#1584</a>)</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/1625d4080339190682bc76bbe79ea26132accfda""><code>1625d40</code></a> feat: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1553"">#1553</a> Adds setting disableSameOriginPolicy, to make it possible to by...</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/a78cd8f28d8b83cff087aab826b2ed97920b2813""><code>a78cd8f</code></a> feat: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1147"">#1147</a> Adds support for aspect-ratio to CSSStyleDeclaration (<a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1537"">#1537</a>)</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/e6f8b13b5775c5a669d852c834527dab66fb5662""><code>e6f8b13</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1581"">#1581</a> Fixes bug where Node.getRootNode() returned null when it was  wi...</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/38ab960d0e1e3f230996cc163d78819290c91558""><code>38ab960</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1578"">#1578</a> Fixes bug where child nodes of HTMLSelectElement and HTMLFormEle...</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/8f74989abe973bb1459fd7195c24d63724236ccf""><code>8f74989</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1534"">#1534</a> Toggle open attribute on HTMLDetailsElement when dispatching a c...</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/7f57469f2e6f54279e31c95a53ee3f497ebdeff6""><code>7f57469</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1546"">#1546</a> Use <code>globalThis</code> instead of <code>global</code> to make Happy DOM work in o...</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/759b4fb60e0ad0d0bc6743a79ae25076313f36fa""><code>759b4fb</code></a> fix: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1538"">#1538</a> Always return Promise&lt;Blob&gt; from ClipboardItem.getType() (<a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1539"">#1539</a>)</li>
<li><a href=""https://github.com/capricorn86/happy-dom/commit/33a72ca38277d2aab5341b4b66b0ca6380285c0b""><code>33a72ca</code></a> feat: <a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1079"">#1079</a> Adds support for all SVG elements (<a href=""https://redirect.github.com/capricorn86/happy-dom/issues/1572"">#1572</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/capricorn86/happy-dom/compare/v15.0.0...v15.10.1"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=happy-dom&package-manager=npm_and_yarn&previous-version=15.0.0&new-version=15.10.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2024-11-06 15:50:02+00:00,[],2024-11-06 16:16:54+00:00,2024-11-06 16:16:45+00:00,https://github.com/apache/airflow/pull/43759,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2638186165,pull_request,closed,,Moved common SQL handler methods of common-sql-provider into dedicated module,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#41327](https://github.com/apache/airflow/pull/41327)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR is linked to the original [PR Introduce notion of dialects in DbApiHook](https://github.com/apache/airflow/pull/41327), but only contains a small refactoring in which the sql handlers of the common-sql -provider are moved from the sql module to a dedicated handler module, as this will be needed later on to avoid circular import issues. This is to make the review easier as asked by @potiuk.  This PR only impacts the common-sql provider, also a dedicated unit test has been added for the handlers.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-06 14:02:20+00:00,[],2024-11-19 21:56:56+00:00,2024-11-19 18:48:20+00:00,https://github.com/apache/airflow/pull/43747,"[('area:providers', ''), ('provider:common-sql', '')]","[{'comment_id': 2461500003, 'issue_id': 2638186165, 'author': 'dabla', 'body': 'Some things are failing but dunno why', 'created_at': datetime.datetime(2024, 11, 7, 7, 24, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461770395, 'issue_id': 2638186165, 'author': 'potiuk', 'body': 'It seems like installing node to build packages is very unstable recently (connection reset by peer etc.) - we will get it cached soon WIP is here: https://github.com/apache/airflow/pull/43329 cc: @bugraoz93 that should improve stability.', 'created_at': datetime.datetime(2024, 11, 7, 9, 46, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461771507, 'issue_id': 2638186165, 'author': 'potiuk', 'body': 'For now rebasing, commit--amend or close/reopening the PR should retry it.', 'created_at': datetime.datetime(2024, 11, 7, 9, 46, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461785505, 'issue_id': 2638186165, 'author': 'dabla', 'body': ""> It seems like installing node to build packages is very unstable recently (connection reset by peer etc.) - we will get it cached soon WIP is here: #43329 cc: @bugraoz93 that should improve stability.\r\n\r\nIsn't there a way to be able to re-run a failing step in the ci cd checks of github?"", 'created_at': datetime.datetime(2024, 11, 7, 9, 52, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461787884, 'issue_id': 2638186165, 'author': 'dabla', 'body': ""> For now rebasing, commit--amend or close/reopening the PR should retry it.\r\n\r\nYeah just did it again, I was a bit worried cause my other PR didn't suffer from those random errors so I though maybe something was wrong in this one."", 'created_at': datetime.datetime(2024, 11, 7, 9, 53, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2462793309, 'issue_id': 2638186165, 'author': 'bugraoz93', 'body': ""> > For now rebasing, commit--amend or close/reopening the PR should retry it.\n> \n> Yeah just did it again, I was a bit worried cause my other PR didn't suffer from those random errors so I though maybe something was wrong in this one.\n\nThis is purely too many trials on node servers trying to download the dependencies and appear in random CI runs"", 'created_at': datetime.datetime(2024, 11, 7, 17, 11, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486487099, 'issue_id': 2638186165, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2024, 11, 19, 18, 48, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486834562, 'issue_id': 2638186165, 'author': 'dabla', 'body': '> Nice!\r\n\r\nThx @potiuk', 'created_at': datetime.datetime(2024, 11, 19, 21, 56, 54, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2024-11-07 07:24:40 UTC): Some things are failing but dunno why

potiuk on (2024-11-07 09:46:14 UTC): It seems like installing node to build packages is very unstable recently (connection reset by peer etc.) - we will get it cached soon WIP is here: https://github.com/apache/airflow/pull/43329 cc: @bugraoz93 that should improve stability.

potiuk on (2024-11-07 09:46:46 UTC): For now rebasing, commit--amend or close/reopening the PR should retry it.

dabla (Issue Creator) on (2024-11-07 09:52:58 UTC): Isn't there a way to be able to re-run a failing step in the ci cd checks of github?

dabla (Issue Creator) on (2024-11-07 09:53:43 UTC): Yeah just did it again, I was a bit worried cause my other PR didn't suffer from those random errors so I though maybe something was wrong in this one.

bugraoz93 on (2024-11-07 17:11:01 UTC): This is purely too many trials on node servers trying to download the dependencies and appear in random CI runs

potiuk on (2024-11-19 18:48:25 UTC): Nice!

dabla (Issue Creator) on (2024-11-19 21:56:54 UTC): Thx @potiuk

"
2638025703,pull_request,closed,,remove constraint from OpenLineage client version,PR testing if the 1.24.2 version fixes compatibility issue,mobuchowski,2024-11-06 12:58:51+00:00,[],2024-11-06 17:56:48+00:00,2024-11-06 17:56:48+00:00,https://github.com/apache/airflow/pull/43742,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:openlineage', 'AIP-53'), ('canary', 'When set on PR running from apache repo - behave as canary run')]",[],
2638012827,pull_request,closed,,"Remove schedule downstream tasks after execution (aka ""mini scheduler"")","This has been questionable how much benefit it actually had, but with the move towards task DB isolation in Airflow 3 we won't be able to keep this anymore (as we didn't when AIP-44 DB isolation was enabled), so lets remove it now.
",ashb,2024-11-06 12:52:48+00:00,[],2024-11-06 18:13:45+00:00,2024-11-06 15:29:50+00:00,https://github.com/apache/airflow/pull/43741,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:providers', ''), ('area:serialization', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]","[{'comment_id': 2459695956, 'issue_id': 2638012827, 'author': 'tirkarthi', 'body': 'Docs portion can also be removed.\r\n\r\nhttps://github.com/apache/airflow/blob/b89f43ebe1ae020c9808c90b84d0737ab8ac7f5b/docs/apache-airflow/administration-and-deployment/scheduler.rst?plain=1#L386-L389', 'created_at': datetime.datetime(2024, 11, 6, 13, 1, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459702902, 'issue_id': 2638012827, 'author': 'ashb', 'body': '> Docs portion can also be removed.\n> \n> https://github.com/apache/airflow/blob/b89f43ebe1ae020c9808c90b84d0737ab8ac7f5b/docs/apache-airflow/administration-and-deployment/scheduler.rst?plain=1#L386-L389\n\nThanks - I was grepping based on config option, guess I missed some', 'created_at': datetime.datetime(2024, 11, 6, 13, 4, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460322832, 'issue_id': 2638012827, 'author': 'raphaelauv', 'body': 'In multiple context of high number of concurrent task ( more than 1000 and around 50 new task by sec ) we had problems and by disabling the mini scheduler things are running way more smoothly,\r\n\r\nmaybe we could deprecate the option in 2.10.4 and set it to false in 2.11.0 , wdyt ?', 'created_at': datetime.datetime(2024, 11, 6, 17, 3, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460358427, 'issue_id': 2638012827, 'author': 'kaxil', 'body': '> In multiple context of high number of concurrent task ( more than 1000 and around 50 new task by sec ) we had problems and by disabling the mini scheduler things are running way more smoothly,\r\n> \r\n> maybe we could deprecate the option in 2.10.4 and set it to false in 2.11.0 , wdyt ?\r\n\r\nYeah good point, fancy a PR to 2-10-test?', 'created_at': datetime.datetime(2024, 11, 6, 17, 19, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460463204, 'issue_id': 2638012827, 'author': 'jscheffl', 'body': '> > In multiple context of high number of concurrent task ( more than 1000 and around 50 new task by sec ) we had problems and by disabling the mini scheduler things are running way more smoothly,\r\n> > maybe we could deprecate the option in 2.10.4 and set it to false in 2.11.0 , wdyt ?\r\n> \r\n> Yeah good point, fancy a PR to 2-10-test?\r\n\r\nI think deprecating the option as warning would be good. I also see it needs a re-work as with AIP-72 the function can not be ""distributed on worker"" as in the past.\r\n\r\nNevertheless when scheduling MANY tasks this was really a performance boost comparing Airflow v1 to Airflow v2 when this was added. Waiting for scheduler loop to schedule the next is really slowing down DAGs... so maybe we need a (future) similar mechanism to schedule next tasks immediately after one has finished to have the same low-latency like in the past... on the backend of course... (like a notification queue where it makes most-sense to schedule next because one task just finished...)', 'created_at': datetime.datetime(2024, 11, 6, 18, 13, 44, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2024-11-06 13:01:38 UTC): Docs portion can also be removed.

https://github.com/apache/airflow/blob/b89f43ebe1ae020c9808c90b84d0737ab8ac7f5b/docs/apache-airflow/administration-and-deployment/scheduler.rst?plain=1#L386-L389

ashb (Issue Creator) on (2024-11-06 13:04:50 UTC): Thanks - I was grepping based on config option, guess I missed some

raphaelauv on (2024-11-06 17:03:21 UTC): In multiple context of high number of concurrent task ( more than 1000 and around 50 new task by sec ) we had problems and by disabling the mini scheduler things are running way more smoothly,

maybe we could deprecate the option in 2.10.4 and set it to false in 2.11.0 , wdyt ?

kaxil on (2024-11-06 17:19:40 UTC): Yeah good point, fancy a PR to 2-10-test?

jscheffl on (2024-11-06 18:13:44 UTC): I think deprecating the option as warning would be good. I also see it needs a re-work as with AIP-72 the function can not be ""distributed on worker"" as in the past.

Nevertheless when scheduling MANY tasks this was really a performance boost comparing Airflow v1 to Airflow v2 when this was added. Waiting for scheduler loop to schedule the next is really slowing down DAGs... so maybe we need a (future) similar mechanism to schedule next tasks immediately after one has finished to have the same low-latency like in the past... on the backend of course... (like a notification queue where it makes most-sense to schedule next because one task just finished...)

"
2637996992,pull_request,closed,,openlineage: accept whole config when instantiating OpenLineageClient,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Before 1.24.0 `OpenLineageClient.from_dict` accepted only transport configuration. This PR aims to allow passing whole config read from yaml file.

<!-- Please keep an empty line above the dashes. -->
---
",JDarDagran,2024-11-06 12:45:17+00:00,[],2024-11-06 14:45:23+00:00,2024-11-06 14:45:23+00:00,https://github.com/apache/airflow/pull/43740,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2459819218, 'issue_id': 2637996992, 'author': 'potiuk', 'body': 'Does it mean that previous versions of openlineage provider will fail with 1.24? Is there any mechanism that the users of past openlineage provider will be warned or guided to upgrade to the new provider when their provider will start to fail after upgrading the`openlineage-python` library to 1.24.2 ?', 'created_at': datetime.datetime(2024, 11, 6, 13, 55, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459832751, 'issue_id': 2637996992, 'author': 'JDarDagran', 'body': ""To be clear: 1.24.0 introduced backwards-incompatible changes that were fixed in 1.24.2 (`from_dict` in 1.24.0 assumed you can pass dict with full config, not only transport. I don't think it's relevant what was exactly the problem but just saying). Therefore if OL providers attempts to upgrade `openlineage-python` to the latest version they should be fine (@mobuchowski  is running canary build [here](https://github.com/apache/airflow/pull/43742) to confirm that).\r\n\r\nIn 1.24.2 we add possibility to pass config as argument (not only transport as it was in case of `from_dict` method that we deprecate in this version)."", 'created_at': datetime.datetime(2024, 11, 6, 14, 0, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459843088, 'issue_id': 2637996992, 'author': 'potiuk', 'body': '> In 1.24.2 we add possibility to pass config as argument (not only transport as it was in case of from_dict method that we deprecate in this version).\r\n\r\nUnderstood! perfect then! Should you also yank 1.24.0 and 1.24.1 ?', 'created_at': datetime.datetime(2024, 11, 6, 14, 4, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459944392, 'issue_id': 2637996992, 'author': 'mobuchowski', 'body': ""We'll look into it... It's not a normal procedure for us"", 'created_at': datetime.datetime(2024, 11, 6, 14, 45, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-06 13:55:11 UTC): Does it mean that previous versions of openlineage provider will fail with 1.24? Is there any mechanism that the users of past openlineage provider will be warned or guided to upgrade to the new provider when their provider will start to fail after upgrading the`openlineage-python` library to 1.24.2 ?

JDarDagran (Issue Creator) on (2024-11-06 14:00:38 UTC): To be clear: 1.24.0 introduced backwards-incompatible changes that were fixed in 1.24.2 (`from_dict` in 1.24.0 assumed you can pass dict with full config, not only transport. I don't think it's relevant what was exactly the problem but just saying). Therefore if OL providers attempts to upgrade `openlineage-python` to the latest version they should be fine (@mobuchowski  is running canary build [here](https://github.com/apache/airflow/pull/43742) to confirm that).

In 1.24.2 we add possibility to pass config as argument (not only transport as it was in case of `from_dict` method that we deprecate in this version).

potiuk on (2024-11-06 14:04:33 UTC): Understood! perfect then! Should you also yank 1.24.0 and 1.24.1 ?

mobuchowski on (2024-11-06 14:45:16 UTC): We'll look into it... It's not a normal procedure for us

"
2637916458,pull_request,closed,,Note in pytest_plugin to not global import Airflow,What it says on the tin… otherwise tests break.,uranusjr,2024-11-06 12:08:47+00:00,[],2024-11-07 02:51:04+00:00,2024-11-07 02:51:03+00:00,https://github.com/apache/airflow/pull/43738,[],[],
2637902303,pull_request,closed,,[Edge] Edge worker supports capacity handling instead of concurrency,"# Description

Edge worker supported at the current state only concurrency. Every job reduced the available concurrency by one. If worker had  concurrency of 8 then 8 jobs can run parallel. Concurrency is now switched to capacity. 

The idea behind is that not all jobs on a worker which runs parallel are consuming the same amount of resources. Now it is possible to set need_capacity value for a job which need more resources. By default the need_capacity is 1 for each job. If worker has capacity of 2 and executes one job with 2 then no new job is executed by the worker. But if a job with need_capacity of 1 is executed a second job with need_capacity of 1 can be executed in parallel. 

For detailed information check the edge_executor.rst changes in this PR.

# Details about changes 

* Concurrency is renamed to capacity
* Job can use the executor_config to define the need_capacitiy
* edge_job table includes new column need_capacity
* Free_capacity of a worker is exported as metric
* As alembic provider migration will be supported inAirflow 3 and Edge package is not fully released yet, a workaround is implemented to drop old table and create new edge_job table.",AutomationDev85,2024-11-06 12:01:41+00:00,[],2024-11-27 16:12:14+00:00,2024-11-27 16:12:13+00:00,https://github.com/apache/airflow/pull/43737,"[('area:providers', ''), ('kind:documentation', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2459781450, 'issue_id': 2637902303, 'author': 'potiuk', 'body': 'Should not that capacity be a task parameter rather than executor config parameter on DAG level. We have similar concept with `pool_slots` and there they are ""per task"" - and part of the BaseOperator. It seems to be way more flexible to specify it this way (additionally then this could be renamed as ""task_slots""  - to be similar to ""pool_slots"") or maybe even we should combine the two. This way it will also be potentially usable by other executors.', 'created_at': datetime.datetime(2024, 11, 6, 13, 39, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461447690, 'issue_id': 2637902303, 'author': 'AutomationDev85', 'body': '> Should not that capacity be a task parameter rather than executor config parameter on DAG level. We have similar concept with `pool_slots` and there they are ""per task"" - and part of the BaseOperator. It seems to be way more flexible to specify it this way (additionally then this could be renamed as ""task_slots"" - to be similar to ""pool_slots"") or maybe even we should combine the two. This way it will also be potentially usable by other executors.\r\n\r\nI was thinking in the same way, but during coding I saw that the need_capacity parameter is no easy to get into the executor. We have to tough core code like TaskInstanceKey class to get the info into the Executor. I just used the idea of the KubernetesExecutor to add additional data into the executor and that is the reason why I started using the executor_config parameter. My main idea is to tough only Edge package t and then make a later PR which can add this changes into the core because the Edge package is the only which will support this feature for the moment and it is not released yet.\r\nSo what is your opinion about that? \r\nShall we change this also in this PR or in a separate PR? \r\nDuring writing this lines I have also the feeling to use still the term concurrency instead of capacity. Then it is easier to adapt this to already existing Executor code in the future.', 'created_at': datetime.datetime(2024, 11, 7, 6, 46, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463373135, 'issue_id': 2637902303, 'author': 'jscheffl', 'body': '> > Should not that capacity be a task parameter rather than executor config parameter on DAG level. We have similar concept with `pool_slots` and there they are ""per task"" - and part of the BaseOperator. It seems to be way more flexible to specify it this way (additionally then this could be renamed as ""task_slots"" - to be similar to ""pool_slots"") or maybe even we should combine the two. This way it will also be potentially usable by other executors.\r\n> \r\n> I was thinking in the same way, but during coding I saw that the need_capacity parameter is no easy to get into the executor. We have to tough core code like TaskInstanceKey class to get the info into the Executor. I just used the idea of the KubernetesExecutor to add additional data into the executor and that is the reason why I started using the executor_config parameter. My main idea is to tough only Edge package t and then make a later PR which can add this changes into the core because the Edge package is the only which will support this feature for the moment and it is not released yet. So what is your opinion about that? Shall we change this also in this PR or in a separate PR? During writing this lines I have also the feeling to use still the term concurrency instead of capacity. Then it is easier to adapt this to already existing Executor code in the future.\r\n\r\n@potiuk I had also a longer talk to @AutomationDev85 today about this. Reading the docs from https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/kubernetes_executor.html#pod-override this field is used (and is only used there today) to carry a dict with a potential included of `pod_override` element that can define extra details of the POD to run for the task execution. That can be used to add volume mounts, request resources or add sidecars... whatsoever.\r\n\r\nWith this interface generically more parameters can be carried. An additional field in the dict would not harm. I am thinking that maybe instead of ""needs capacity"" we should name it `pool_slots` according to the task instance parameter. With this PR here, you would need to define this as extra field on the task instance... but with a small additional PR we could bring the `pool_slots` from the task instance per default in there for future leverage... but then this intrinsic is a bit confusing though.\r\n\r\nAs @AutomationDev85 said we could also bring the `pool_slots` field directly from the task instance into the executor, but today the interface in the scheduler in airflow/executors/base_executor.py:execute_async() only carries TaskInstanceKey, Command, queue and the executor_config - adding the full TaskInstance or the pool_slots here would be a breaking change in the interface or the executor would need to query the DB additionally to get the pool_slots (which the scheduler obviously already has because it allocated the pool slots before scheduling... the calling method `_process_tasks()` has the taskinstance object).\r\n\r\n@potiuk Do you think we need/should to make a breaking change in the scheduler/executor interface or add an intrinsic?\r\n@ashb as being the Scheduler expert, would you have an opinion on this?', 'created_at': datetime.datetime(2024, 11, 7, 22, 43, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469190946, 'issue_id': 2637902303, 'author': 'potiuk', 'body': '> As @AutomationDev85 said we could also bring the pool_slots field directly from the task instance into the executor, but today the interface in the scheduler in airflow/executors/base_executor.py:execute_async() only carries TaskInstanceKey, Command, queue and the executor_config - adding the full TaskInstance or the pool_slots here would be a breaking change in the interface or the executor would need to query the DB additionally to get the pool_slots (which the scheduler obviously already has because it allocated the pool slots before scheduling... the calling method _process_tasks() has the taskinstance object).\r\n\r\nAnd comment on that - again, I am not really trying to block/veto it, but I don\'t think the breaking or not breaking here matters when we go to Airlfow 3. We will already have breaking changes for Executors i believe, and we will have to handle them. For me it is much more important to try to deliberate and discuss and come up with good future executor interface than to merge a PR for edge executor only. This can wait. There is absolutely no hurry with it (unless i am mistaken) - we can even keep on rebasing it until we come to conclusion on what\'s best/)\r\n\r\nI think it is more important to think forward and whether we want to address an improvement need of one executor (which is not even production ready yet) or whether we want to think of future common ""executor"" scenarios. I think if we will not consider the future now, we might be building technical debt before even we release Airflow 3.\r\n\r\nFor example when I think about YuniKorn executor in the future (cc: @amoghrajesh ) I think we would like some way of passing metadata to uvicorn executor from tasks - to allow various ways of scheduling those. I think we need to discuss how ""executor specific"" vs.""airflow abstract"" the meta-data should be. I.e. do we have some properties of the task that can be mapped from ""airflow abstract"" terms to specific executor matadata - this can help in the future to freely move tasks betweeen executors without specifically rewriting their metadata.\r\n\r\nAnd I do not think we will be able to do it for all parameters, but there are certain properties that could be ""abstract"":\r\n\r\n* task weight\r\n* task group task belongs to\r\n* task labels\r\n\r\nAll those seems to be ""abstract"" enough to be shared between different executors - unlike kubernetes executor config that is really a pod-template override, those could cover vast majority of cases where we want to attach some common properties with tasks that might have similar meaning even if they are run by different executors.\r\n\r\nMaybe we want this, maybe not - maybe it\'s a wrong abstraction. But at least it\'s worth to discuss it rather than merge the PR without discussing it.', 'created_at': datetime.datetime(2024, 11, 11, 22, 25, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469252532, 'issue_id': 2637902303, 'author': 'jscheffl', 'body': '> Maybe we want this, maybe not - maybe it\'s a wrong abstraction. But at least it\'s worth to discuss it rather than merge the PR without discussing it.\r\n\r\nFair. And it is a bit a pity that the ""TaskInstance"" object is not passed into the Executor interface, the calling method has all the fields available. So if the TaskInstance would be included in `execute_async` signature all would be there.\r\n\r\nFor sure, don\'t mis-understand. We don\'t want to build an EdgeWorker ""balcony"" here. Would be great if other executors would have this as well. Was looking once about if this could be made for Celery as well but could not find an entry point w/o patching deep in celery :-D\r\n\r\nIf you dislike the parameter - I assume this can be changed... main point is how more task context can be made available. For example ""some"" fields like priority, pool slots, labels, max_tries, pool, queue could be genericaly be added into the dict of `executor_config`...', 'created_at': datetime.datetime(2024, 11, 11, 23, 1, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469290901, 'issue_id': 2637902303, 'author': 'o-nikolas', 'body': '> I want to hear other\'s opinion on that @ashb @o-nikolas ? and mark it as request changes for now until we agree if this is fine or not to keep it as ""executor-specific"" config.\r\n\r\n\r\nHere are my thoughts:\r\n\r\n## 1) _Can_ we use executor_config in this way?\r\n\r\nThe `executor_config` field is there to pass any key/value configuration to the executor for a specific task. The k8s executor uses it as already discussed, the ECS executor treats it as AWS parameters which are passed along to the boto3 call to ecs `run_task` (so the user can configure more memory for a particular task, or send it to a different ECS cluster, or simply add tags, etc). So it is free to be used in any way an executor sees fit and it\'s a nice mechanism to customize execution for a task.\r\n\r\n## 2) _Should_ we use `executor_config` in this way for capacity management\r\nI think this idea of capacity management is interesting and agree we have to make a call on whether or not we should adopt this as a firstclass feature or not within the Airflow executor interface. I agree with @potiuk that there is no harm in updating the executor interface to support it. We have a major release coming up and that\'s what they\'re for, so if we want to update the `exec_async` method now to include more parameters (or even pass along the entire TI as @jscheffl suggested) that\'s perfectly doable.\r\nBut whether we **should** is another story. Here I think it\'s less obvious. Many executors don\'t even have a notion of long lived ""workers"" (they are completely ephemeral and map 1:1 with a single task for any containerized executor like k8s and AWS ECS). But they don\'t have to make use of it, or you could imagine it as a way to map to a larger container image configuration for executors like this (i.e. a two slot task would get a larger container with more memory or what have you, pre-defined by the user). \r\n\r\nOne last thing that I do feel strongly about (and I think this also agrees with what @potiuk is saying) is that Airflow already has slots and executors also _already_ have a notion of their own slots (kind of like their internal capacity), which they use to manage how many tasks they can run concurrently/in parallel. I think we should build on this existing mechanism (i.e. a larger task should consume >1 executor slots for the executor that receives it) and then within the executor, knowing that a task is consuming a particular number of slots, the executor can handle that task especially/differently (or do nothing at all if the executor doesn\'t care about task size). This pushes this to be a Task Instance property which I think makes the most sense, because it is the task that is taking up more capacity and the executor just needs to account for that and react appropriately.', 'created_at': datetime.datetime(2024, 11, 11, 23, 37, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469925701, 'issue_id': 2637902303, 'author': 'potiuk', 'body': 'Should we turn it into a devlist discussion? It seems that is a decision that shoudd be made about **now** - i.e. what we really want to do with executor and ""task properties"".\r\n\r\nI think we have two options:\r\n\r\n1) we make any metadata we want to attach to task ""executor specific"" - like kubernetes executor so far\r\n2) we try to make some common (well defined) ""properties"" of the task, exposed to executors so that they can adapt on how they are running tasks. Task ""weight"" seem to be a good candidate for that that we can also use elsewhere (i.e. pool slots).\r\n\r\nAnd indeed, we are at the right time to introduce breaking chnges (or variations) in the executor interface to acommodate to 2) if we choose to go this direction.', 'created_at': datetime.datetime(2024, 11, 12, 8, 47, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474613396, 'issue_id': 2637902303, 'author': 'jscheffl', 'body': '> Should we turn it into a devlist discussion? It seems that is a decision that shoudd be made about **now** - i.e. what we really want to do with executor and ""task properties"".\r\n> \r\nYeah, would support a devlist discussion... @AutomationDev85 will you take this?\r\n\r\n@potiuk would it be only a discussion, does this then need a formal vote or lazy consensus? I believe we did not vote on breaking changes in the past... discussion would be mainly to attract opinions and feedback on PR?\r\n\r\nI\'d propose to go into the option (2) and (while on my way back from work) I had a good idea such that the change would be softly breaking:\r\n\r\nBesides the today\'s (interface limited) `execute_async()` we add a new `<name-tbd>()` method (e.g. `execute()` because the existing method is not really async and name is a bit mis-leading). The existing `execute_async()` will get a deprecation warning and call the new method. So old and new interface could be supported.\r\nWe could add this to 2.10.4, latest to 2.11. As it is non-breaking I\'d say the earlier the better. Docs would need to be updated as well, highlighting the deprecation.\r\n\r\nThen we could have starting from 2.10.4 slowly start migrating existing executors to the new interface, also support the old signature still not to break Airflow compatibility.... and drop the old method in 3.0. (We still do not force and could keep the old signature, does not harm).\r\n\r\nOne option as (2) could be to have a specific well-defined interface.... but actually much easier, we could directly pass the `TaskInstance` object as the caller has this. Then all details like priority, pool slots, executor_config are directly accessible. And we can implement the pool_slot awareness in `LocalExecutor` as first-class citizen as well. And if TaskInstance is extended in future, no interface changes needed.', 'created_at': datetime.datetime(2024, 11, 13, 19, 48, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2490606968, 'issue_id': 2637902303, 'author': 'AutomationDev85', 'body': '@jscheffl Sorry I had to rework again because if oversaw that the function _process_tasks in BaseExecutor deletes the key out of the queued_tasks. See  [_del self.queued_tasks[key]](https://github.com/apache/airflow/blob/main/airflow/executors/base_executor.py#L407). So I added an overload on the _process_tasks  function to store the queued_tasks in an own variable. What is your opinion about this solution? Not happy about this but looking forward to remove this with Airflow 3.', 'created_at': datetime.datetime(2024, 11, 21, 9, 50, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504082633, 'issue_id': 2637902303, 'author': 'potiuk', 'body': ""LGTM - we can discuss if we can generalize it separately, but I agree at this stage it's ok to merge as is."", 'created_at': datetime.datetime(2024, 11, 27, 14, 54, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2504087380, 'issue_id': 2637902303, 'author': 'jscheffl', 'body': ""> LGTM - we can discuss if we can generalize it separately, but I agree at this stage it's ok to merge as is.\r\n\r\nThanks. Happy to generalize. Probably post AIP-72 on Airflow 3 this makes sense. But ring me and I'll promise to contribute this."", 'created_at': datetime.datetime(2024, 11, 27, 14, 56, 43, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-06 13:39:31 UTC): Should not that capacity be a task parameter rather than executor config parameter on DAG level. We have similar concept with `pool_slots` and there they are ""per task"" - and part of the BaseOperator. It seems to be way more flexible to specify it this way (additionally then this could be renamed as ""task_slots""  - to be similar to ""pool_slots"") or maybe even we should combine the two. This way it will also be potentially usable by other executors.

AutomationDev85 (Issue Creator) on (2024-11-07 06:46:08 UTC): I was thinking in the same way, but during coding I saw that the need_capacity parameter is no easy to get into the executor. We have to tough core code like TaskInstanceKey class to get the info into the Executor. I just used the idea of the KubernetesExecutor to add additional data into the executor and that is the reason why I started using the executor_config parameter. My main idea is to tough only Edge package t and then make a later PR which can add this changes into the core because the Edge package is the only which will support this feature for the moment and it is not released yet.
So what is your opinion about that? 
Shall we change this also in this PR or in a separate PR? 
During writing this lines I have also the feeling to use still the term concurrency instead of capacity. Then it is easier to adapt this to already existing Executor code in the future.

jscheffl on (2024-11-07 22:43:38 UTC): @potiuk I had also a longer talk to @AutomationDev85 today about this. Reading the docs from https://airflow.apache.org/docs/apache-airflow-providers-cncf-kubernetes/stable/kubernetes_executor.html#pod-override this field is used (and is only used there today) to carry a dict with a potential included of `pod_override` element that can define extra details of the POD to run for the task execution. That can be used to add volume mounts, request resources or add sidecars... whatsoever.

With this interface generically more parameters can be carried. An additional field in the dict would not harm. I am thinking that maybe instead of ""needs capacity"" we should name it `pool_slots` according to the task instance parameter. With this PR here, you would need to define this as extra field on the task instance... but with a small additional PR we could bring the `pool_slots` from the task instance per default in there for future leverage... but then this intrinsic is a bit confusing though.

As @AutomationDev85 said we could also bring the `pool_slots` field directly from the task instance into the executor, but today the interface in the scheduler in airflow/executors/base_executor.py:execute_async() only carries TaskInstanceKey, Command, queue and the executor_config - adding the full TaskInstance or the pool_slots here would be a breaking change in the interface or the executor would need to query the DB additionally to get the pool_slots (which the scheduler obviously already has because it allocated the pool slots before scheduling... the calling method `_process_tasks()` has the taskinstance object).

@potiuk Do you think we need/should to make a breaking change in the scheduler/executor interface or add an intrinsic?
@ashb as being the Scheduler expert, would you have an opinion on this?

potiuk on (2024-11-11 22:25:35 UTC): And comment on that - again, I am not really trying to block/veto it, but I don't think the breaking or not breaking here matters when we go to Airlfow 3. We will already have breaking changes for Executors i believe, and we will have to handle them. For me it is much more important to try to deliberate and discuss and come up with good future executor interface than to merge a PR for edge executor only. This can wait. There is absolutely no hurry with it (unless i am mistaken) - we can even keep on rebasing it until we come to conclusion on what's best/)

I think it is more important to think forward and whether we want to address an improvement need of one executor (which is not even production ready yet) or whether we want to think of future common ""executor"" scenarios. I think if we will not consider the future now, we might be building technical debt before even we release Airflow 3.

For example when I think about YuniKorn executor in the future (cc: @amoghrajesh ) I think we would like some way of passing metadata to uvicorn executor from tasks - to allow various ways of scheduling those. I think we need to discuss how ""executor specific"" vs.""airflow abstract"" the meta-data should be. I.e. do we have some properties of the task that can be mapped from ""airflow abstract"" terms to specific executor matadata - this can help in the future to freely move tasks betweeen executors without specifically rewriting their metadata.

And I do not think we will be able to do it for all parameters, but there are certain properties that could be ""abstract"":

* task weight
* task group task belongs to
* task labels

All those seems to be ""abstract"" enough to be shared between different executors - unlike kubernetes executor config that is really a pod-template override, those could cover vast majority of cases where we want to attach some common properties with tasks that might have similar meaning even if they are run by different executors.

Maybe we want this, maybe not - maybe it's a wrong abstraction. But at least it's worth to discuss it rather than merge the PR without discussing it.

jscheffl on (2024-11-11 23:01:42 UTC): Fair. And it is a bit a pity that the ""TaskInstance"" object is not passed into the Executor interface, the calling method has all the fields available. So if the TaskInstance would be included in `execute_async` signature all would be there.

For sure, don't mis-understand. We don't want to build an EdgeWorker ""balcony"" here. Would be great if other executors would have this as well. Was looking once about if this could be made for Celery as well but could not find an entry point w/o patching deep in celery :-D

If you dislike the parameter - I assume this can be changed... main point is how more task context can be made available. For example ""some"" fields like priority, pool slots, labels, max_tries, pool, queue could be genericaly be added into the dict of `executor_config`...

o-nikolas on (2024-11-11 23:37:13 UTC): Here are my thoughts:

## 1) _Can_ we use executor_config in this way?

The `executor_config` field is there to pass any key/value configuration to the executor for a specific task. The k8s executor uses it as already discussed, the ECS executor treats it as AWS parameters which are passed along to the boto3 call to ecs `run_task` (so the user can configure more memory for a particular task, or send it to a different ECS cluster, or simply add tags, etc). So it is free to be used in any way an executor sees fit and it's a nice mechanism to customize execution for a task.

## 2) _Should_ we use `executor_config` in this way for capacity management
I think this idea of capacity management is interesting and agree we have to make a call on whether or not we should adopt this as a firstclass feature or not within the Airflow executor interface. I agree with @potiuk that there is no harm in updating the executor interface to support it. We have a major release coming up and that's what they're for, so if we want to update the `exec_async` method now to include more parameters (or even pass along the entire TI as @jscheffl suggested) that's perfectly doable.
But whether we **should** is another story. Here I think it's less obvious. Many executors don't even have a notion of long lived ""workers"" (they are completely ephemeral and map 1:1 with a single task for any containerized executor like k8s and AWS ECS). But they don't have to make use of it, or you could imagine it as a way to map to a larger container image configuration for executors like this (i.e. a two slot task would get a larger container with more memory or what have you, pre-defined by the user). 

One last thing that I do feel strongly about (and I think this also agrees with what @potiuk is saying) is that Airflow already has slots and executors also _already_ have a notion of their own slots (kind of like their internal capacity), which they use to manage how many tasks they can run concurrently/in parallel. I think we should build on this existing mechanism (i.e. a larger task should consume >1 executor slots for the executor that receives it) and then within the executor, knowing that a task is consuming a particular number of slots, the executor can handle that task especially/differently (or do nothing at all if the executor doesn't care about task size). This pushes this to be a Task Instance property which I think makes the most sense, because it is the task that is taking up more capacity and the executor just needs to account for that and react appropriately.

potiuk on (2024-11-12 08:47:49 UTC): Should we turn it into a devlist discussion? It seems that is a decision that shoudd be made about **now** - i.e. what we really want to do with executor and ""task properties"".

I think we have two options:

1) we make any metadata we want to attach to task ""executor specific"" - like kubernetes executor so far
2) we try to make some common (well defined) ""properties"" of the task, exposed to executors so that they can adapt on how they are running tasks. Task ""weight"" seem to be a good candidate for that that we can also use elsewhere (i.e. pool slots).

And indeed, we are at the right time to introduce breaking chnges (or variations) in the executor interface to acommodate to 2) if we choose to go this direction.

jscheffl on (2024-11-13 19:48:27 UTC): Yeah, would support a devlist discussion... @AutomationDev85 will you take this?

@potiuk would it be only a discussion, does this then need a formal vote or lazy consensus? I believe we did not vote on breaking changes in the past... discussion would be mainly to attract opinions and feedback on PR?

I'd propose to go into the option (2) and (while on my way back from work) I had a good idea such that the change would be softly breaking:

Besides the today's (interface limited) `execute_async()` we add a new `<name-tbd>()` method (e.g. `execute()` because the existing method is not really async and name is a bit mis-leading). The existing `execute_async()` will get a deprecation warning and call the new method. So old and new interface could be supported.
We could add this to 2.10.4, latest to 2.11. As it is non-breaking I'd say the earlier the better. Docs would need to be updated as well, highlighting the deprecation.

Then we could have starting from 2.10.4 slowly start migrating existing executors to the new interface, also support the old signature still not to break Airflow compatibility.... and drop the old method in 3.0. (We still do not force and could keep the old signature, does not harm).

One option as (2) could be to have a specific well-defined interface.... but actually much easier, we could directly pass the `TaskInstance` object as the caller has this. Then all details like priority, pool slots, executor_config are directly accessible. And we can implement the pool_slot awareness in `LocalExecutor` as first-class citizen as well. And if TaskInstance is extended in future, no interface changes needed.

AutomationDev85 (Issue Creator) on (2024-11-21 09:50:50 UTC): @jscheffl Sorry I had to rework again because if oversaw that the function _process_tasks in BaseExecutor deletes the key out of the queued_tasks. See  [_del self.queued_tasks[key]](https://github.com/apache/airflow/blob/main/airflow/executors/base_executor.py#L407). So I added an overload on the _process_tasks  function to store the queued_tasks in an own variable. What is your opinion about this solution? Not happy about this but looking forward to remove this with Airflow 3.

potiuk on (2024-11-27 14:54:44 UTC): LGTM - we can discuss if we can generalize it separately, but I agree at this stage it's ok to merge as is.

jscheffl on (2024-11-27 14:56:43 UTC): Thanks. Happy to generalize. Probably post AIP-72 on Airflow 3 this makes sense. But ring me and I'll promise to contribute this.

"
2637873380,pull_request,closed,,Add data-testid attributes to key UI components for unit test and automation tests,"**Summary**
This PR addresses [Issue #43381](https://github.com/apache/airflow/issues/43381) by adding `data-testid `attributes to key UI components to improve stability and reliability for automated testing and external tools.

**Why This Change?**
Currently, UI lacks reliable identifiers for DOM elements, making automation difficult and unstable. Using sibling and child selectors is not a dependable approach. Adding `data-testid `attributes provides a robust solution, allowing automation frameworks and external tools to interact with UI elements consistently.

**Testing**
Verified that the added `data-testid `attributes do not interfere with the UI's functionality.
Conducted tests to ensure elements are correctly identified and manipulated by automation scripts.
Related Issue
Fixes [Issue #43381](https://github.com/apache/airflow/issues/43381).




---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2024-11-06 11:49:42+00:00,[],2024-11-06 13:41:49+00:00,2024-11-06 13:41:47+00:00,https://github.com/apache/airflow/pull/43736,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2637837842,pull_request,closed,,AIP-65: Add back DAG versioning support,"This reverts commit b757bd8df824d4eba952f6e140bcb373bc3f1003.

",ephraimbuddy,2024-11-06 11:33:48+00:00,[],2025-01-16 20:20:21+00:00,2024-11-07 11:01:47+00:00,https://github.com/apache/airflow/pull/43735,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:fab', ''), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs'), ('area:db-migrations', 'PRs with DB migration'), ('AIP-65: DAG history in UI', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-sdk', None)]","[{'comment_id': 2459786521, 'issue_id': 2637837842, 'author': 'potiuk', 'body': 'Yeah.. Looks like fairly `reliably flaky` (if we can use such oxymoron :D ).', 'created_at': datetime.datetime(2024, 11, 6, 13, 41, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2461449864, 'issue_id': 2637837842, 'author': 'ephraimbuddy', 'body': ""> Should be good, though i'd be more happy if this one is rebased (and tests are green) after #43771 that should fix google.auth pickiness about mocks used.\r\n\r\nYeah, rebased, and it was green except for a Kubernetes test and task sdk test that stopped midway. Have rebased again. Let's see how it goes"", 'created_at': datetime.datetime(2024, 11, 7, 6, 48, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-06 13:41:35 UTC): Yeah.. Looks like fairly `reliably flaky` (if we can use such oxymoron :D ).

ephraimbuddy (Issue Creator) on (2024-11-07 06:48:00 UTC): Yeah, rebased, and it was green except for a Kubernetes test and task sdk test that stopped midway. Have rebased again. Let's see how it goes

"
2637623939,pull_request,closed,,[Edge] EdgeWorker beautify queues output on overview page,"# Description

This PR does only do a small beautify of the EdgeWorker overview page. The queues are now presented as list and not the string in the queues filed of the table.

",AutomationDev85,2024-11-06 10:15:10+00:00,[],2024-11-06 10:43:07+00:00,2024-11-06 10:43:06+00:00,https://github.com/apache/airflow/pull/43734,"[('area:providers', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2637567007,pull_request,closed,,Temporarily limit openlineage to <1.24.0,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-06 09:52:11+00:00,[],2024-11-06 09:53:43+00:00,2024-11-06 09:53:41+00:00,https://github.com/apache/airflow/pull/43732,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2637542964,pull_request,closed,,Remove unnecessary DB clear in test,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ephraimbuddy,2024-11-06 09:43:25+00:00,[],2024-11-06 12:12:03+00:00,2024-11-06 12:12:03+00:00,https://github.com/apache/airflow/pull/43731,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2459510906, 'issue_id': 2637542964, 'author': 'kaxil', 'body': 'If we merge this, could you add a PR description of why it was the cause of the side effect?', 'created_at': datetime.datetime(2024, 11, 6, 11, 35, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459513001, 'issue_id': 2637542964, 'author': 'ephraimbuddy', 'body': ""> If we merge this, could you add a PR description of why it was the cause of the side effect?\r\n\r\nThis is now for test. Just trying to use it to figure out what's wrong. Shouldn't be merged"", 'created_at': datetime.datetime(2024, 11, 6, 11, 36, 17, tzinfo=datetime.timezone.utc)}]","kaxil on (2024-11-06 11:35:13 UTC): If we merge this, could you add a PR description of why it was the cause of the side effect?

ephraimbuddy (Issue Creator) on (2024-11-06 11:36:17 UTC): This is now for test. Just trying to use it to figure out what's wrong. Shouldn't be merged

"
2637505443,pull_request,closed,,Attempt to revert dag versioning changes,"Revert ""Delete the Serialized Dag and DagCode before DagVersion migration #43700
Revert ""AIP-65: Add DAG versioning support #42913

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-06 09:29:36+00:00,[],2025-01-11 19:41:47+00:00,2024-11-06 11:26:00+00:00,https://github.com/apache/airflow/pull/43730,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('upgrade to newer dependencies', 'If set, upgrade to newer dependencies is forced'), ('provider:fab', ''), ('canary', 'When set on PR running from apache repo - behave as canary run'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs'), ('area:db-migrations', 'PRs with DB migration'), ('area:task-sdk', None)]","[{'comment_id': 2459115732, 'issue_id': 2637505443, 'author': 'potiuk', 'body': ""Attempting to revert the changes that are likely causing flaky tests on `main' cc: @ephraimbuddy -> let's see if that will help,  and if it will, we should revert, and make a closer investigation - with redoing those two reverted changes."", 'created_at': datetime.datetime(2024, 11, 6, 9, 30, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459340571, 'issue_id': 2637505443, 'author': 'potiuk', 'body': 'Closing in favour of #43731 [43731](https://github.com/apache/airflow/pull/43731) that seem to fix the cause of the problem.', 'created_at': datetime.datetime(2024, 11, 6, 10, 34, 36, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-06 09:30:50 UTC): Attempting to revert the changes that are likely causing flaky tests on `main' cc: @ephraimbuddy -> let's see if that will help,  and if it will, we should revert, and make a closer investigation - with redoing those two reverted changes.

potiuk (Issue Creator) on (2024-11-06 10:34:36 UTC): Closing in favour of #43731 [43731](https://github.com/apache/airflow/pull/43731) that seem to fix the cause of the problem.

"
2637467407,pull_request,closed,,Remove note about MySQL 5,adapting https://github.com/apache/airflow/pull/43701/ to v2-10-test branch,eladkal,2024-11-06 09:10:56+00:00,[],2024-11-06 12:55:19+00:00,2024-11-06 12:55:16+00:00,https://github.com/apache/airflow/pull/43729,[],[],
2637408617,pull_request,closed,,Added contributors documentation regarding configuration of source root directories in PyCharm,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Added contributors documentation regarding configuration of source root directories in PyCharm for providers and task_sdk.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-06 08:42:54+00:00,[],2024-11-06 09:19:20+00:00,2024-11-06 09:19:13+00:00,https://github.com/apache/airflow/pull/43727,"[('area:dev-tools', '')]","[{'comment_id': 2459092823, 'issue_id': 2637408617, 'author': 'potiuk', 'body': 'Nice :)', 'created_at': datetime.datetime(2024, 11, 6, 9, 19, 19, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-06 09:19:19 UTC): Nice :)

"
2637355490,pull_request,closed,,Added notion of dialects into ProvidersManager,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#41327](https://github.com/apache/airflow/pull/41327)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR is linked to the original [PR Introduce notion of dialects in DbApiHook](https://github.com/apache/airflow/pull/41327), but only contains the first smaller part which implements the notion of dialects into the provider packages and made the ProvidersManager aware if it without actually implementing the different dialects yet, that will be done in a separate PR once this one has been approved and merged. This is to make the review easier as asked by @potiuk.  This PR only impacts the airflow codebase, not the providers, that will be for the next PR.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2024-11-06 08:17:43+00:00,[],2024-11-12 06:53:48+00:00,2024-11-11 21:40:44+00:00,https://github.com/apache/airflow/pull/43726,"[('area:CLI', ''), ('area:dev-tools', '')]","[{'comment_id': 2469082047, 'issue_id': 2637355490, 'author': 'potiuk', 'body': 'Wooohooo!', 'created_at': datetime.datetime(2024, 11, 11, 21, 40, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469737890, 'issue_id': 2637355490, 'author': 'dabla', 'body': '> Wooohooo!\r\n\r\nThx @potiuk jarek', 'created_at': datetime.datetime(2024, 11, 12, 6, 53, 47, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-11 21:40:51 UTC): Wooohooo!

dabla (Issue Creator) on (2024-11-12 06:53:47 UTC): Thx @potiuk jarek

"
2636751038,pull_request,closed,,Check if awslogs_stream_prefix already ends with container_name,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

fixes PR: #43138 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pyrr,2024-11-06 00:05:48+00:00,[],2024-11-06 17:23:24+00:00,2024-11-06 17:23:12+00:00,https://github.com/apache/airflow/pull/43724,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2458445780, 'issue_id': 2636751038, 'author': 'pyrr', 'body': 'Please add @ferruzzi and @vincbeck for review', 'created_at': datetime.datetime(2024, 11, 6, 0, 9, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460365612, 'issue_id': 2636751038, 'author': 'ferruzzi', 'body': 'Thanks!', 'created_at': datetime.datetime(2024, 11, 6, 17, 23, 23, tzinfo=datetime.timezone.utc)}]","pyrr (Issue Creator) on (2024-11-06 00:09:06 UTC): Please add @ferruzzi and @vincbeck for review

ferruzzi on (2024-11-06 17:23:23 UTC): Thanks!

"
2636579470,pull_request,closed,,"AIP-72: Add ""TI heartbeat"" endpoint for Execution API","closes https://github.com/apache/airflow/issues/43586

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-05 22:14:38+00:00,[],2024-11-06 17:10:44+00:00,2024-11-06 17:04:17+00:00,https://github.com/apache/airflow/pull/43722,[],[],
2636467870,pull_request,closed,,Update helm chart docs for private registry params,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/43720
",omkar-foss,2024-11-05 21:03:18+00:00,['omkar-foss'],2025-02-05 15:52:01+00:00,2024-11-06 17:46:47+00:00,https://github.com/apache/airflow/pull/43721,"[('area:helm-chart', 'Airflow Helm Chart'), ('kind:documentation', '')]","[{'comment_id': 2459704926, 'issue_id': 2636467870, 'author': 'omkar-foss', 'body': 'PR rebased and synced with `main` just now ✅', 'created_at': datetime.datetime(2024, 11, 6, 13, 5, 46, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-06 13:05:46 UTC): PR rebased and synced with `main` just now ✅

"
2636378308,pull_request,closed,,Include unit test to Legacy UI/API Selective Check in Breeze,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #42774


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2024-11-05 20:16:04+00:00,[],2024-11-11 14:16:36+00:00,2024-11-11 14:16:36+00:00,https://github.com/apache/airflow/pull/43719,"[('area:dev-tools', '')]","[{'comment_id': 2465514948, 'issue_id': 2636378308, 'author': 'bugraoz93', 'body': '@potiuk could you please review this when you have time? It failed at first two days due to other problems affecting the PRs. It is now all green :)', 'created_at': datetime.datetime(2024, 11, 8, 18, 41, 33, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2024-11-08 18:41:33 UTC): @potiuk could you please review this when you have time? It failed at first two days due to other problems affecting the PRs. It is now all green :)

"
2636296384,pull_request,closed,,Migrate public endpoint Get Task to FastAPI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/42874
related: https://github.com/apache/airflow/issues/42370

This migrates the Get Task API from `api_connexion` to `api_fastapi`.",omkar-foss,2024-11-05 19:30:38+00:00,['omkar-foss'],2024-11-14 18:33:17+00:00,2024-11-13 08:52:47+00:00,https://github.com/apache/airflow/pull/43718,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2464819740, 'issue_id': 2636296384, 'author': 'omkar-foss', 'body': '@pierrejeambrun PR rebased and synced with `main` and all comments resolved, please check it out. Thank you!', 'created_at': datetime.datetime(2024, 11, 8, 13, 51, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2465200380, 'issue_id': 2636296384, 'author': 'omkar-foss', 'body': '> Overall looking good. Need rebasing and conflicts resolution. Thanks\r\n\r\nDone! Rebased and conflicts resolved ✅', 'created_at': datetime.datetime(2024, 11, 8, 16, 21, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2472736918, 'issue_id': 2636296384, 'author': 'omkar-foss', 'body': '> Needs rebasing again. Ready to merge\r\n\r\n@pierrejeambrun rebasing done, thank you ✅', 'created_at': datetime.datetime(2024, 11, 13, 7, 58, 50, tzinfo=datetime.timezone.utc)}]","omkar-foss (Issue Creator) on (2024-11-08 13:51:53 UTC): @pierrejeambrun PR rebased and synced with `main` and all comments resolved, please check it out. Thank you!

omkar-foss (Issue Creator) on (2024-11-08 16:21:26 UTC): Done! Rebased and conflicts resolved ✅

omkar-foss (Issue Creator) on (2024-11-13 07:58:50 UTC): @pierrejeambrun rebasing done, thank you ✅

"
2636149876,pull_request,closed,,Add documentation to standard provider operators,"Python/Bash operator documentation update has missed from the previous PR's. 

This updates python/bash documentation to standard provider and have also moved inside operators folder.

related: #43641 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-05 18:11:12+00:00,[],2024-11-23 19:56:05+00:00,2024-11-11 12:28:34+00:00,https://github.com/apache/airflow/pull/43716,"[('area:providers', ''), ('kind:documentation', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:standard', '')]","[{'comment_id': 2457861853, 'issue_id': 2636149876, 'author': 'gopidesupavan', 'body': ""cc: @romsharon98 I've relocated the existing documentation you updated with the datetime changes into the operators folder. Hope that's okay. :)"", 'created_at': datetime.datetime(2024, 11, 5, 18, 14, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463910476, 'issue_id': 2636149876, 'author': 'romsharon98', 'body': 'We we decided to combine datetime operators and sensors under operators documentation?', 'created_at': datetime.datetime(2024, 11, 8, 6, 57, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2463959750, 'issue_id': 2636149876, 'author': 'gopidesupavan', 'body': '> We we decided to combine datetime operators and sensors under operators documentation?\r\n\r\nSorry I’m not aware that, Do you think it’s worth combining everything into a single operator file? My main concern is that the file could become excessively large with all the content, and large file can be hard to read if any comes and see in my opinion.\r\n\r\nBut i am happy to merge, please suggest :) \r\n\r\nI see one good thing sphinax is very smart :) its keeping all in one place when it generated even the content in different files under operator section, sample screenshot for the docs build.\r\n\r\n<img width=""1091"" alt=""image"" src=""https://github.com/user-attachments/assets/6319b189-ad4d-4551-b459-52185d6edada"">', 'created_at': datetime.datetime(2024, 11, 8, 7, 35, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466188234, 'issue_id': 2636149876, 'author': 'romsharon98', 'body': '> > We we decided to combine datetime operators and sensors under operators documentation?\r\n> \r\n> Sorry I’m not aware that, Do you think it’s worth combining everything into a single operator file? My main concern is that the file could become excessively large with all the content, and large file can be hard to read if any comes and see in my opinion.\r\n> \r\n> But i am happy to merge, please suggest :)\r\n> \r\n> I see one good thing sphinax is very smart :) its keeping all in one place when it generated even the content in different files under operator section, sample screenshot for the docs build.\r\n> \r\n> <img alt=""image"" width=""1091"" src=""https://private-user-images.githubusercontent.com/31437079/384268236-6319b189-ad4d-4551-b459-52185d6edada.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExNTM4MjMsIm5iZiI6MTczMTE1MzUyMywicGF0aCI6Ii8zMTQzNzA3OS8zODQyNjgyMzYtNjMxOWIxODktYWQ0ZC00NTUxLWI0NTktNTIxODVkNmVkYWRhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDExNTg0M1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ4MjdjMDkwYmEzODQ1MjdkMzRkMTFhZDFhMzg2OGUwMWFkMzkzNzk2OGM2MzAzMzlhYWMyM2IxMTIyMjRkODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Hdo0sNpjUzOweramHkYYFtsJVJIWpV_H75PJskdn-Z4"">\r\n\r\nWhat I ment is why we combined the sensors and the operators under the operators page? (and not keep a page for the sensors)', 'created_at': datetime.datetime(2024, 11, 9, 12, 0, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466193295, 'issue_id': 2636149876, 'author': 'gopidesupavan', 'body': '> > > We we decided to combine datetime operators and sensors under operators documentation?\r\n> > \r\n> > \r\n> > Sorry I’m not aware that, Do you think it’s worth combining everything into a single operator file? My main concern is that the file could become excessively large with all the content, and large file can be hard to read if any comes and see in my opinion.\r\n> > But i am happy to merge, please suggest :)\r\n> > I see one good thing sphinax is very smart :) its keeping all in one place when it generated even the content in different files under operator section, sample screenshot for the docs build.\r\n> > <img alt=""image"" width=""1091"" src=""https://private-user-images.githubusercontent.com/31437079/384268236-6319b189-ad4d-4551-b459-52185d6edada.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExNTM4MjMsIm5iZiI6MTczMTE1MzUyMywicGF0aCI6Ii8zMTQzNzA3OS8zODQyNjgyMzYtNjMxOWIxODktYWQ0ZC00NTUxLWI0NTktNTIxODVkNmVkYWRhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDExNTg0M1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ4MjdjMDkwYmEzODQ1MjdkMzRkMTFhZDFhMzg2OGUwMWFkMzkzNzk2OGM2MzAzMzlhYWMyM2IxMTIyMjRkODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Hdo0sNpjUzOweramHkYYFtsJVJIWpV_H75PJskdn-Z4"">\r\n> \r\n> What I ment is why we combined the sensors and the operators under the operators page? (and not keep a page for the sensors)\r\n\r\nOh okay sorry i miss understood the comment :). Yeah can do separate sections for sensors and operators? is it okay please confirm.', 'created_at': datetime.datetime(2024, 11, 9, 12, 16, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466200324, 'issue_id': 2636149876, 'author': 'romsharon98', 'body': '> > > > We we decided to combine datetime operators and sensors under operators documentation?\r\n> > > \r\n> > > \r\n> > > Sorry I’m not aware that, Do you think it’s worth combining everything into a single operator file? My main concern is that the file could become excessively large with all the content, and large file can be hard to read if any comes and see in my opinion.\r\n> > > But i am happy to merge, please suggest :)\r\n> > > I see one good thing sphinax is very smart :) its keeping all in one place when it generated even the content in different files under operator section, sample screenshot for the docs build.\r\n> > > <img alt=""image"" width=""1091"" src=""https://private-user-images.githubusercontent.com/31437079/384268236-6319b189-ad4d-4551-b459-52185d6edada.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExNTM4MjMsIm5iZiI6MTczMTE1MzUyMywicGF0aCI6Ii8zMTQzNzA3OS8zODQyNjgyMzYtNjMxOWIxODktYWQ0ZC00NTUxLWI0NTktNTIxODVkNmVkYWRhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDExNTg0M1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ4MjdjMDkwYmEzODQ1MjdkMzRkMTFhZDFhMzg2OGUwMWFkMzkzNzk2OGM2MzAzMzlhYWMyM2IxMTIyMjRkODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Hdo0sNpjUzOweramHkYYFtsJVJIWpV_H75PJskdn-Z4"">\r\n> > \r\n> > \r\n> > What I ment is why we combined the sensors and the operators under the operators page? (and not keep a page for the sensors)\r\n> \r\n> Oh okay sorry i miss understood the comment :). Yeah can do separate sections for sensors and operators? is it okay please confirm.\r\n\r\nYes I think it\'s better to separate them like before and add the additional documentation to the correct sections 😄', 'created_at': datetime.datetime(2024, 11, 9, 12, 42, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466628635, 'issue_id': 2636149876, 'author': 'gopidesupavan', 'body': '> > > > > We we decided to combine datetime operators and sensors under operators documentation?\r\n> > > > \r\n> > > > \r\n> > > > Sorry I’m not aware that, Do you think it’s worth combining everything into a single operator file? My main concern is that the file could become excessively large with all the content, and large file can be hard to read if any comes and see in my opinion.\r\n> > > > But i am happy to merge, please suggest :)\r\n> > > > I see one good thing sphinax is very smart :) its keeping all in one place when it generated even the content in different files under operator section, sample screenshot for the docs build.\r\n> > > > <img alt=""image"" width=""1091"" src=""https://private-user-images.githubusercontent.com/31437079/384268236-6319b189-ad4d-4551-b459-52185d6edada.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExNTM4MjMsIm5iZiI6MTczMTE1MzUyMywicGF0aCI6Ii8zMTQzNzA3OS8zODQyNjgyMzYtNjMxOWIxODktYWQ0ZC00NTUxLWI0NTktNTIxODVkNmVkYWRhLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDExNTg0M1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQ4MjdjMDkwYmEzODQ1MjdkMzRkMTFhZDFhMzg2OGUwMWFkMzkzNzk2OGM2MzAzMzlhYWMyM2IxMTIyMjRkODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Hdo0sNpjUzOweramHkYYFtsJVJIWpV_H75PJskdn-Z4"">\r\n> > > \r\n> > > \r\n> > > What I ment is why we combined the sensors and the operators under the operators page? (and not keep a page for the sensors)\r\n> > \r\n> > \r\n> > Oh okay sorry i miss understood the comment :). Yeah can do separate sections for sensors and operators? is it okay please confirm.\r\n> \r\n> Yes I think it\'s better to separate them like before and add the additional documentation to the correct sections 😄\r\n\r\nYeah agree, hope this is fine now.\r\n\r\n<img width=""1614"" alt=""image"" src=""https://github.com/user-attachments/assets/68e114a6-1211-4204-94da-6d2cf487ce27"">', 'created_at': datetime.datetime(2024, 11, 10, 7, 55, 25, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-05 18:14:03 UTC): cc: @romsharon98 I've relocated the existing documentation you updated with the datetime changes into the operators folder. Hope that's okay. :)

romsharon98 on (2024-11-08 06:57:33 UTC): We we decided to combine datetime operators and sensors under operators documentation?

gopidesupavan (Issue Creator) on (2024-11-08 07:35:56 UTC): Sorry I’m not aware that, Do you think it’s worth combining everything into a single operator file? My main concern is that the file could become excessively large with all the content, and large file can be hard to read if any comes and see in my opinion.

But i am happy to merge, please suggest :) 

I see one good thing sphinax is very smart :) its keeping all in one place when it generated even the content in different files under operator section, sample screenshot for the docs build.

<img width=""1091"" alt=""image"" src=""https://github.com/user-attachments/assets/6319b189-ad4d-4551-b459-52185d6edada"">

romsharon98 on (2024-11-09 12:00:01 UTC): What I ment is why we combined the sensors and the operators under the operators page? (and not keep a page for the sensors)

gopidesupavan (Issue Creator) on (2024-11-09 12:16:35 UTC): Oh okay sorry i miss understood the comment :). Yeah can do separate sections for sensors and operators? is it okay please confirm.

romsharon98 on (2024-11-09 12:42:46 UTC): Yes I think it's better to separate them like before and add the additional documentation to the correct sections 😄

gopidesupavan (Issue Creator) on (2024-11-10 07:55:25 UTC): Yeah agree, hope this is fine now.

<img width=""1614"" alt=""image"" src=""https://github.com/user-attachments/assets/68e114a6-1211-4204-94da-6d2cf487ce27"">

"
2636146812,pull_request,closed,,[BACKPORT] Handle FileNotFound Error returned by missing uv or pipx (#43714),"Subprocess.run raises FileNotFound when uv or pipx are not installed at all. This PR will handle it.

(cherry picked from commit ed3accb30086b9ed5eddcd12b17a5f7c8d52d53b)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-05 18:09:21+00:00,[],2024-11-05 18:17:18+00:00,2024-11-05 18:17:15+00:00,https://github.com/apache/airflow/pull/43715,"[('area:dev-tools', '')]","[{'comment_id': 2457854436, 'issue_id': 2636146812, 'author': 'potiuk', 'body': 'Backporting #43714', 'created_at': datetime.datetime(2024, 11, 5, 18, 9, 55, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-05 18:09:55 UTC): Backporting #43714

"
2636134072,pull_request,closed,,Handle FileNotFound Error returned by missing uv or pipx,"Subprocess.run raises FileNotFound when uv or pipx are not installed at all. This PR will handle it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-05 18:01:55+00:00,[],2024-11-05 18:15:41+00:00,2024-11-05 18:06:58+00:00,https://github.com/apache/airflow/pull/43714,"[('area:dev-tools', '')]",[],
2636063651,pull_request,closed,,Add GZipMiddleware to compress response content.,"Closes #43640 

The change adds GZipMiddleware to compress response content. Minimum response size for compression is greater than 1kB and compress level is 5 with values ranging from 1 to 9 with 1 (fastest, lowest compression) and 9 (slowest, most compression)

Docs : https://fastapi.tiangolo.com/advanced/middleware/#gzipmiddleware

Dag list page with 75 dags

|compress level  | original size (kB)  | compressed size (kB)   |
|---|---|---|
| 1 | 48.40  | 6.28  |
|  5 | 48.40  | 5.68  |
|  9 | 48.40  | 5.51  |",tirkarthi,2024-11-05 17:29:25+00:00,[],2024-11-06 13:10:35+00:00,2024-11-06 13:10:35+00:00,https://github.com/apache/airflow/pull/43707,[],[],
2635893423,pull_request,closed,,AIP-84 Use status constants,Some of the recently merged PRs do not use constants and small refactoring leftovers,pierrejeambrun,2024-11-05 16:12:01+00:00,['pierrejeambrun'],2024-11-05 23:19:33+00:00,2024-11-05 23:19:24+00:00,https://github.com/apache/airflow/pull/43702,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2635883724,pull_request,closed,,Remove note about MySQL 5,We no longer support MySQL 5 as backend so we can remove the specific note about it with HA scheduler,eladkal,2024-11-05 16:07:24+00:00,[],2024-11-06 09:06:27+00:00,2024-11-05 22:52:47+00:00,https://github.com/apache/airflow/pull/43701,[],[],
2635873498,pull_request,closed,,Delete the Serialized Dag and DagCode before DagVersion migration,"This is necessary for a smooth migration from the old DB to the new one that added versioning; otherwise, the non-nullable columns raise an integrity error.

Instead of populating those not nullable columns, this seems to be a better option since the Serialized Dag and DagCode would be regenerated after the migration.",ephraimbuddy,2024-11-05 16:02:38+00:00,[],2024-11-14 19:03:08+00:00,2024-11-05 17:54:44+00:00,https://github.com/apache/airflow/pull/43700,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-65: DAG history in UI', '')]",[],
2635859157,pull_request,closed,,Update Breeze UI_Files to match pnpm lock file,"For the CI, we just copied over the www files over to the UI_FILES, but as caught [here](https://github.com/apache/airflow/pull/43633#issuecomment-2455138419), pnpm's lock file is yaml and wasn't being caught.


Now, we will just have all files inside of `airflow/ui` count. Then, changes to the html file,`.prettierrc`, or anything else also don't force the CI to run everything.

Also, added the pnpm lock yaml file to the javascript production files check.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2024-11-05 15:56:47+00:00,[],2024-11-05 23:23:33+00:00,2024-11-05 23:23:24+00:00,https://github.com/apache/airflow/pull/43699,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2635735702,pull_request,closed,,Chart: Default airflow version to 2.10.3,,utkarsharma2,2024-11-05 15:10:40+00:00,[],2025-02-05 15:52:01+00:00,2024-11-06 09:36:26+00:00,https://github.com/apache/airflow/pull/43698,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2635717988,pull_request,closed,,Airflow 2.10.3 has been released,,utkarsharma2,2024-11-05 15:03:23+00:00,[],2024-11-06 14:02:11+00:00,2024-11-06 14:02:09+00:00,https://github.com/apache/airflow/pull/43697,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2635661371,pull_request,closed,,Disable XCom list ordering by execution_date (#43680),"* Disable XCom list ordering by execution_date

* Update airflow/www/views.py

Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>

---------

Co-authored-by: Kaxil Naik <kaxilnaik@gmail.com>
(cherry picked from commit c96b618b60ed049658470a9696479c0df36957af)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2024-11-05 14:43:09+00:00,[],2024-12-04 08:58:41+00:00,2024-11-05 15:28:16+00:00,https://github.com/apache/airflow/pull/43696,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2635618872,pull_request,closed,,[BACKPORT] Detect situation where Breeze is installed with both pipx and uv (#43…,"…694)

When breeze is installed with both - pipx and uv, we do not know which version is available first on the path and self-upgrading breeze might not upgrade the one that is first. Therefore we detect that situation and fail self upgrade with appropriate instructions what to do (recommending leaving uv as faster)

(cherry picked from commit ccd65867387117cd4503715195a877a1ac2892a2)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-05 14:28:28+00:00,[],2024-11-05 14:45:52+00:00,2024-11-05 14:45:50+00:00,https://github.com/apache/airflow/pull/43695,"[('area:dev-tools', '')]","[{'comment_id': 2457327954, 'issue_id': 2635618872, 'author': 'potiuk', 'body': 'Backport #43694', 'created_at': datetime.datetime(2024, 11, 5, 14, 29, 22, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-05 14:29:22 UTC): Backport #43694

"
2635512815,pull_request,closed,,Detect situation where Breeze is installed with both pipx and uv,"When breeze is installed with both - pipx and uv, we do not know which version is available first on the path and self-upgrading breeze might not upgrade the one that is first. Therefore we detect that situation and fail self upgrade with appropriate instructions what to do (recommending leaving uv as faster)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-05 13:45:33+00:00,[],2024-11-05 14:46:06+00:00,2024-11-05 14:26:18+00:00,https://github.com/apache/airflow/pull/43694,"[('area:dev-tools', '')]","[{'comment_id': 2457320091, 'issue_id': 2635512815, 'author': 'potiuk', 'body': ""cc: @amoghrajesh  -> seems that we had to handle the situation where both are installed - following your yesterday's question :)"", 'created_at': datetime.datetime(2024, 11, 5, 14, 26, 14, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-05 14:26:14 UTC): cc: @amoghrajesh  -> seems that we had to handle the situation where both are installed - following your yesterday's question :)

"
2635465927,pull_request,closed,,remove the to-write asset active dag warnings that already exists in the db instead of those that does not exist,"## Why
In https://github.com/apache/airflow/pull/43254, we introduce a new dag warning type ASSET_CONFLICT. When the scheduler notices assets with the same names but different URIs, it collects the dag_warnings to write, removes the dag_warnings **not** in the warnings to write, and then writes these warnings to db, which fails the unique constraint. It should remove the rows in the dag_warings to write instead of those that are not.

## What
Remove the rows that exist in the dag_warnings to write.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2024-11-05 13:26:41+00:00,['Lee-W'],2024-11-11 06:40:18+00:00,2024-11-11 06:40:04+00:00,https://github.com/apache/airflow/pull/43693,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2467356720, 'issue_id': 2635465927, 'author': 'uranusjr', 'body': 'Hmm wait… is the logic in `existing_warned_dag_ids` also backwards? Or at least it’s named wrong.', 'created_at': datetime.datetime(2024, 11, 11, 6, 40, 16, tzinfo=datetime.timezone.utc)}]","uranusjr on (2024-11-11 06:40:16 UTC): Hmm wait… is the logic in `existing_warned_dag_ids` also backwards? Or at least it’s named wrong.

"
2635336609,pull_request,closed,,Bump `uv` to `0.4.30`,"https://pypi.org/project/uv/0.4.30/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-05 12:35:24+00:00,[],2024-11-05 14:08:27+00:00,2024-11-05 14:08:26+00:00,https://github.com/apache/airflow/pull/43692,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]",[],
2635335981,pull_request,closed,,Prepare docs for Nov 1st wave of providers,I will add more providers later,eladkal,2024-11-05 12:35:06+00:00,[],2024-11-14 08:04:23+00:00,2024-11-14 08:04:20+00:00,https://github.com/apache/airflow/pull/43691,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('kind:documentation', ''), ('provider:standard', '')]","[{'comment_id': 2457872475, 'issue_id': 2635335981, 'author': 'gopidesupavan', 'body': 'Does this require compat provider along with the current providers?', 'created_at': datetime.datetime(2024, 11, 5, 18, 20, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457917079, 'issue_id': 2635335981, 'author': 'eladkal', 'body': ""> Does this require compat provider along with the current providers?\r\n\r\nNo worries. I'm going to do a full wave"", 'created_at': datetime.datetime(2024, 11, 5, 18, 46, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475665782, 'issue_id': 2635335981, 'author': 'eladkal', 'body': 'suppressed by https://github.com/apache/airflow/pull/44011', 'created_at': datetime.datetime(2024, 11, 14, 8, 4, 20, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-05 18:20:20 UTC): Does this require compat provider along with the current providers?

eladkal (Issue Creator) on (2024-11-05 18:46:13 UTC): No worries. I'm going to do a full wave

eladkal (Issue Creator) on (2024-11-14 08:04:20 UTC): suppressed by https://github.com/apache/airflow/pull/44011

"
2635315795,pull_request,closed,,remove all deprecations cncf.kubernetes,"since we now change the provider version to be 10.0.0 we can now remove all the deprecation warnings.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2024-11-05 12:25:20+00:00,[],2024-11-09 20:43:40+00:00,2024-11-09 20:43:40+00:00,https://github.com/apache/airflow/pull/43689,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2460329889, 'issue_id': 2635315795, 'author': 'eladkal', 'body': 'static checks are failing', 'created_at': datetime.datetime(2024, 11, 6, 17, 6, 37, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-06 17:06:37 UTC): static checks are failing

"
2635236965,pull_request,closed,,GlueJobOperator: add option to wait for cleanup before returning job status,"This changes to solve a bug around the case of concurrency=1. In that scenario Glue returns final state before actually cleaning up the resources. This leads to a problem we can have more than 1 concurrent job in Glue.
To avoid this and according to AWS recommendation adding the option to wait (5-10) seconds before returning the job status 

Not sure how to test this one (if we need testing for this at all?).
It just adds sleep before returning the final status
",eladkal,2024-11-05 11:48:15+00:00,[],2024-11-05 16:08:02+00:00,2024-11-05 16:07:58+00:00,https://github.com/apache/airflow/pull/43688,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2635168250,pull_request,closed,,[BACKPORT] Fix reproducibility of prepared provider packages (fix flit frontend)…,"… (#43683)

After some checks it turned out that reproducibility of produced packages depends not only on the build backend configured for the project but also on the build front-end used - because frontend is the one to modify meta-data in prepared packages - including the build tool used, it's version and metadata version supported by the front-end.

That's why in order to maintain reproducibility for anyone who builds the packages, we have to pin not only the build backend in pyproject.toml (flit-core) but also build fronted used (flit).

Since package preparation is done with breeze, we can do it by pinning flit (and just in case also flit-core) so that anyone who builds specific version of the package will use exactly the same flit as the person who built the original packages.

This way we will avoid reproducibility problems experienced with 1.5.0 release of FAB.

(cherry picked from commit 18ea01cef2b92fe820ceaa33be7b44f9f576aad4)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-05 11:18:58+00:00,[],2024-11-05 14:26:51+00:00,2024-11-05 14:26:49+00:00,https://github.com/apache/airflow/pull/43687,"[('area:dev-tools', '')]","[{'comment_id': 2456905664, 'issue_id': 2635168250, 'author': 'potiuk', 'body': 'Backport #43683', 'created_at': datetime.datetime(2024, 11, 5, 11, 19, 15, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2024-11-05 11:19:15 UTC): Backport #43683

"
2635095076,pull_request,closed,,Update AirflowRunFacet.json to allow array of strings for tags fixes,"closes: #43638
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sumedhakoranga,2024-11-05 10:46:53+00:00,[],2024-11-05 13:54:27+00:00,2024-11-05 13:54:27+00:00,https://github.com/apache/airflow/pull/43686,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]","[{'comment_id': 2456839857, 'issue_id': 2635095076, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2024, 11, 5, 10, 46, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457018912, 'issue_id': 2635095076, 'author': 'mobuchowski', 'body': 'This breaks backwards compatibility, as described in https://github.com/apache/airflow/issues/43638#issuecomment-2457006902', 'created_at': datetime.datetime(2024, 11, 5, 12, 16, 29, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2024-11-05 10:46:58 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

mobuchowski on (2024-11-05 12:16:29 UTC): This breaks backwards compatibility, as described in https://github.com/apache/airflow/issues/43638#issuecomment-2457006902

"
2634963556,pull_request,closed,,Fix reproducibility of prepared provider packages (fix flit frontend),"After some checks it turned out that reproducibility of produced packages depends not only on the build backend configured for the project but also on the build front-end used - because frontend is the one to modify meta-data in prepared packages - including the build tool used, it's version and metadata version supported by the front-end.

That's why in order to maintain reproducibility for anyone who builds the packages, we have to pin not only the build backend in pyproject.toml (flit-core) but also build fronted used (flit).

Since package preparation is done with breeze, we can do it by pinning flit (and just in case also flit-core) so that anyone who builds specific version of the package will use exactly the same flit as the person who built the original packages.

This way we will avoid reproducibility problems experienced with 1.5.0 release of FAB.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2024-11-05 09:51:26+00:00,[],2024-11-05 16:50:30+00:00,2024-11-05 11:01:30+00:00,https://github.com/apache/airflow/pull/43683,"[('area:dev-tools', '')]","[{'comment_id': 2457686687, 'issue_id': 2634963556, 'author': 'gopidesupavan', 'body': 'Woohooo nice :)', 'created_at': datetime.datetime(2024, 11, 5, 16, 49, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457689788, 'issue_id': 2634963556, 'author': 'potiuk', 'body': 'Yeah. Build reproducibiliy is cool :) and surprisingly difficult.', 'created_at': datetime.datetime(2024, 11, 5, 16, 50, 29, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2024-11-05 16:49:03 UTC): Woohooo nice :)

potiuk (Issue Creator) on (2024-11-05 16:50:29 UTC): Yeah. Build reproducibiliy is cool :) and surprisingly difficult.

"
2634944123,pull_request,closed,,Expand and improve the kerberos api authentication documentation,"The following improvemenrs were added to the API Kerberos authentication documentation section:
- unify `@REALM` and `@KERBEROS-REALM`: the fact that they read different was confusing and prompted the question whether they were two different names for the same realm value or not
- provide a `curl` example
- mention that the stable API is authorized _and_ access-controled, so the authenticated user should have the required permissions to request the API
- fix a typo

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",brouberol,2024-11-05 09:43:40+00:00,[],2024-11-12 13:55:58+00:00,2024-11-12 13:55:58+00:00,https://github.com/apache/airflow/pull/43682,"[('area:providers', ''), ('kind:documentation', ''), ('provider:fab', '')]","[{'comment_id': 2466653601, 'issue_id': 2634944123, 'author': 'brouberol', 'body': ""@vincbeck I don't have merge permissions. Would you be able to merge? Thanks!"", 'created_at': datetime.datetime(2024, 11, 10, 9, 15, 14, tzinfo=datetime.timezone.utc)}]","brouberol (Issue Creator) on (2024-11-10 09:15:14 UTC): @vincbeck I don't have merge permissions. Would you be able to merge? Thanks!

"
2634941468,pull_request,closed,,Log message source details are grouped,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Log message source details are grouped: they are not relevant for most users and can distract them from finding the root cause of their errors.

![image](https://github.com/user-attachments/assets/04d5f3d1-746a-4e76-981b-f3e454c045cb)


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2024-11-05 09:42:47+00:00,[],2024-11-15 19:43:47+00:00,2024-11-15 19:43:47+00:00,https://github.com/apache/airflow/pull/43681,"[('area:logging', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]","[{'comment_id': 2457365464, 'issue_id': 2634941468, 'author': 'majorosdonat', 'body': 'Moved back to draft until pytests are fixed', 'created_at': datetime.datetime(2024, 11, 5, 14, 44, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2457959132, 'issue_id': 2634941468, 'author': 'bbovenzi', 'body': 'Makes sense to me!', 'created_at': datetime.datetime(2024, 11, 5, 19, 10, 22, tzinfo=datetime.timezone.utc)}]","majorosdonat (Issue Creator) on (2024-11-05 14:44:32 UTC): Moved back to draft until pytests are fixed

bbovenzi on (2024-11-05 19:10:22 UTC): Makes sense to me!

"
2634826596,pull_request,closed,,Disable XCom list ordering by execution_date,"I tried to fix it and make it work, some other resources (TaskInstance) are able to sort on `execution_date` but for some reason (I suspect db side / model differences) it is not working for `XCom`.

Before:
![Screenshot 2024-11-05 at 09 52 25](https://github.com/user-attachments/assets/0439343e-4f36-4ff2-9a7f-81d0818bb155)

Now:
![Screenshot 2024-11-05 at 09 51 04](https://github.com/user-attachments/assets/e1f87be2-ec5e-4a2d-a1b9-3429b6dd035a)
",pierrejeambrun,2024-11-05 08:54:01+00:00,['pierrejeambrun'],2024-11-05 14:40:30+00:00,2024-11-05 14:40:28+00:00,https://github.com/apache/airflow/pull/43680,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2634765155,pull_request,closed,,Replace `principle` by `principal` in kerberos-related code,"Kerberos has the notion of a [principal](https://web.mit.edu/kerberos/krb5-1.5/krb5-1.5.4/doc/krb5-user/What-is-a-Kerberos-Principal_003f.html). ""principle"" seemed to be a typo.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",brouberol,2024-11-05 08:28:21+00:00,[],2024-11-19 12:45:45+00:00,2024-11-19 12:45:45+00:00,https://github.com/apache/airflow/pull/43679,"[('area:core', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes')]","[{'comment_id': 2456974285, 'issue_id': 2634765155, 'author': 'eladkal', 'body': ""> I think the hassle is not worth the typo fix\r\n\r\n~We can just have a function with the correct name and deprecate the old one\r\ngiven that we are going to remove all deprecations before 2.11 I think it's good chance to do it~\r\n\r\nAh sorry this involves also Airflow core\r\n\r\nStill I think we can do it with Airflow 3 and backport to 2.10.. this is pretty minor and easy to do."", 'created_at': datetime.datetime(2024, 11, 5, 11, 55, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458272499, 'issue_id': 2634765155, 'author': 'potiuk', 'body': '> Still I think we can do it with Airflow 3 and backport to 2.10.. this is pretty minor and easy to do.\r\n\r\nIf @brouberol wishes to do the back-compatiblity code for both issues, we can do it, yes.', 'created_at': datetime.datetime(2024, 11, 5, 22, 32, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458946460, 'issue_id': 2634765155, 'author': 'eladkal', 'body': 'OK lets take it by steps:\r\n1. changes to `airflow/security/kerberos.py` should be in a separated PR. Add new function `get_kerberos_principal` with the logic and deprecate `get_kerberos_principle` once this PR is merged to main branch, we can start similar PR for v2.10-test branch.\r\n2. once (1) is completed we can handle the provider changes\r\n\r\nI can handle (1) if you prefer', 'created_at': datetime.datetime(2024, 11, 6, 8, 5, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460078421, 'issue_id': 2634765155, 'author': 'brouberol', 'body': ""I can give it a go, but I'll be a bit tied up in the coming days. Feel free to proceed with 1) if you want. If not, I'll try to address your comment when I have the time. Thanks again!"", 'created_at': datetime.datetime(2024, 11, 6, 15, 31, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2460343939, 'issue_id': 2634765155, 'author': 'eladkal', 'body': 'Cool but actually we need (2) ready before (1)\r\n\r\nAll you need to do here is to remove the changes to `airflow/security/kerberos.py` and `tests/security/test_kerberos.py`.\r\n\r\nKeep the changes you have in providers but change the imports to:\r\n\r\n```\r\n#todo: remove try/exception when min airflow version is 3.0\r\ntry:\r\n    from airflow.security.kerberos import get_kerberos_principal\r\nexcept ModuleNotFoundError:\r\n    from airflow.security.kerberos import get_kerberos_principle\r\n```\r\n\r\nOnce you do that provider is compatible with both name and I can do the change to airflow core.', 'created_at': datetime.datetime(2024, 11, 6, 17, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483443671, 'issue_id': 2634765155, 'author': 'brouberol', 'body': ""I've reworked this patch to only rename the affected function, and have opened https://github.com/apache/airflow/pull/44150 that attempts to import the fixed function and falls back to the typoed one, as suggested in https://github.com/apache/airflow/pull/43679#issuecomment-2460343939"", 'created_at': datetime.datetime(2024, 11, 18, 15, 52, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2483471977, 'issue_id': 2634765155, 'author': 'eladkal', 'body': 'Lets add `43679.misc.rst` in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).\r\nJust need to say in the file that we renamed the function due to misspelling. This will be used to generate the release notes.', 'created_at': datetime.datetime(2024, 11, 18, 16, 3, 54, tzinfo=datetime.timezone.utc)}]","eladkal on (2024-11-05 11:55:26 UTC): ~We can just have a function with the correct name and deprecate the old one
given that we are going to remove all deprecations before 2.11 I think it's good chance to do it~

Ah sorry this involves also Airflow core

Still I think we can do it with Airflow 3 and backport to 2.10.. this is pretty minor and easy to do.

potiuk on (2024-11-05 22:32:39 UTC): If @brouberol wishes to do the back-compatiblity code for both issues, we can do it, yes.

eladkal on (2024-11-06 08:05:36 UTC): OK lets take it by steps:
1. changes to `airflow/security/kerberos.py` should be in a separated PR. Add new function `get_kerberos_principal` with the logic and deprecate `get_kerberos_principle` once this PR is merged to main branch, we can start similar PR for v2.10-test branch.
2. once (1) is completed we can handle the provider changes

I can handle (1) if you prefer

brouberol (Issue Creator) on (2024-11-06 15:31:02 UTC): I can give it a go, but I'll be a bit tied up in the coming days. Feel free to proceed with 1) if you want. If not, I'll try to address your comment when I have the time. Thanks again!

eladkal on (2024-11-06 17:13:00 UTC): Cool but actually we need (2) ready before (1)

All you need to do here is to remove the changes to `airflow/security/kerberos.py` and `tests/security/test_kerberos.py`.

Keep the changes you have in providers but change the imports to:

```
#todo: remove try/exception when min airflow version is 3.0
try:
    from airflow.security.kerberos import get_kerberos_principal
except ModuleNotFoundError:
    from airflow.security.kerberos import get_kerberos_principle
```

Once you do that provider is compatible with both name and I can do the change to airflow core.

brouberol (Issue Creator) on (2024-11-18 15:52:52 UTC): I've reworked this patch to only rename the affected function, and have opened https://github.com/apache/airflow/pull/44150 that attempts to import the fixed function and falls back to the typoed one, as suggested in https://github.com/apache/airflow/pull/43679#issuecomment-2460343939

eladkal on (2024-11-18 16:03:54 UTC): Lets add `43679.misc.rst` in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
Just need to say in the file that we renamed the function due to misspelling. This will be used to generate the release notes.

"
2634754259,pull_request,closed,,Remove execution_date and logical_date from arguments in api_connexion,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR removes the `execution_date` and `logical_date` arguments from `api_connexion` that are used to retrieve DAG runs, aligning with the broader changes introduced in Airflow 2.2 and preparing for Airflow 3.0. The functions now use `run_id` as the sole identifier for DAG runs, simplifying the process and eliminating deprecated behaviour.

### **Motivation**:
In Airflow, `execution_date` has historically been used to distinguish different DAG run instances. However, the introduction of `run_id` and the DAG run concept in Airflow 2.2 shifts away from using `execution_date` as an identifier. Continuing to rely on `execution_date` introduces limitations, such as the inability to handle multiple DAG runs at the same logical time, especially in cases like `TriggerDagRunOperator` when dynamic runs are generated.

By removing `execution_date` in favor of `run_id`, this PR eliminates these limitations. This also removes the unique constraint on `execution_date` at the database level, paving the way for a cleaner and more flexible scheduling system in Airflow 3.0.



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sunank200,2024-11-05 08:22:35+00:00,[],2024-11-15 12:15:54+00:00,2024-11-15 12:15:54+00:00,https://github.com/apache/airflow/pull/43678,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-83', 'Remove Execution Date Unique Constraint from DAG Run'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2456819410, 'issue_id': 2634754259, 'author': 'potiuk', 'body': 'Are we going to remove it first and then move the API ? I was under the impression we wanted to make it new ""while"" moving it to the new fast_api framework? But maybe there is a good reason to do it first here?', 'created_at': datetime.datetime(2024, 11, 5, 10, 37, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2458984559, 'issue_id': 2634754259, 'author': 'Lee-W', 'body': '> Are we going to remove it first and then move the API ? I was under the impression we wanted to make it new ""while"" moving it to the new fast_api framework? But maybe there is a good reason to do it first here?\r\n\r\nAs long as there\'s no conflict, I think it\'s ok to do it first 🤔 so that whoever\'s working on moving the API', 'created_at': datetime.datetime(2024, 11, 6, 8, 26, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2459013065, 'issue_id': 2634754259, 'author': 'Lee-W', 'body': 'For these pull requests, we will probably need the `legacy ui` and `legacy api` labels to run the CI. Please let me know if you need help adding the labels to the following pull requests. 🙂', 'created_at': datetime.datetime(2024, 11, 6, 8, 41, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2478687873, 'issue_id': 2634754259, 'author': 'sunank200', 'body': 'This can be closed rename of `execution_date` is done as part of `logical_date` here: [43902](https://github.com/apache/airflow/pull/43902)\r\n\r\nRemoval of execution_date is being done in [42404](https://github.com/apache/airflow/pull/42404)', 'created_at': datetime.datetime(2024, 11, 15, 12, 15, 54, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-05 10:37:18 UTC): Are we going to remove it first and then move the API ? I was under the impression we wanted to make it new ""while"" moving it to the new fast_api framework? But maybe there is a good reason to do it first here?

Lee-W on (2024-11-06 08:26:45 UTC): As long as there's no conflict, I think it's ok to do it first 🤔 so that whoever's working on moving the API

Lee-W on (2024-11-06 08:41:16 UTC): For these pull requests, we will probably need the `legacy ui` and `legacy api` labels to run the CI. Please let me know if you need help adding the labels to the following pull requests. 🙂

sunank200 (Issue Creator) on (2024-11-15 12:15:54 UTC): This can be closed rename of `execution_date` is done as part of `logical_date` here: [43902](https://github.com/apache/airflow/pull/43902)

Removal of execution_date is being done in [42404](https://github.com/apache/airflow/pull/42404)

"
2634712339,pull_request,closed,,Update providers metadata 2024-11-05,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",eladkal,2024-11-05 07:59:39+00:00,[],2024-11-05 11:53:42+00:00,2024-11-05 11:53:39+00:00,https://github.com/apache/airflow/pull/43677,[],[],
2634626728,pull_request,closed,,AIP-84 Get Task Instance Try Details,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related to: https://github.com/apache/airflow/issues/42370

<!-- Please keep an empty line above the dashes. -->
---
",kandharvishnu,2024-11-05 07:17:45+00:00,[],2024-11-19 13:23:45+00:00,2024-11-19 13:18:13+00:00,https://github.com/apache/airflow/pull/43675,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2479433434, 'issue_id': 2634626728, 'author': 'pierrejeambrun', 'body': 'Need rebasing as well.', 'created_at': datetime.datetime(2024, 11, 15, 16, 57, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2482418951, 'issue_id': 2634626728, 'author': 'pierrejeambrun', 'body': 'Needs rebasing. We can merge after the small adjustments are done.', 'created_at': datetime.datetime(2024, 11, 18, 9, 35, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485705791, 'issue_id': 2634626728, 'author': 'rawwar', 'body': 'Nice! On to the next one @kandharvishnu', 'created_at': datetime.datetime(2024, 11, 19, 13, 23, 44, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2024-11-15 16:57:40 UTC): Need rebasing as well.

pierrejeambrun on (2024-11-18 09:35:41 UTC): Needs rebasing. We can merge after the small adjustments are done.

rawwar on (2024-11-19 13:23:44 UTC): Nice! On to the next one @kandharvishnu

"
2634498892,pull_request,closed,,Fix main add config section to standard provider docs index,"Part of this https://github.com/apache/airflow/pull/43612 config section has been added. I guess the failure might be missing config section on index.

CI failure: https://github.com/apache/airflow/actions/runs/11676095038/job/32515724863#step:7:2078

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2024-11-05 05:56:59+00:00,[],2024-11-05 07:12:30+00:00,2024-11-05 06:29:29+00:00,https://github.com/apache/airflow/pull/43674,"[('area:providers', ''), ('kind:documentation', ''), ('provider:standard', '')]","[{'comment_id': 2456303347, 'issue_id': 2634498892, 'author': 'gopidesupavan', 'body': 'I just realised some doc update missing for moved operators in standard provider. Added to checklist here https://github.com/apache/airflow/issues/43641 to update those.', 'created_at': datetime.datetime(2024, 11, 5, 6, 0, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2456308550, 'issue_id': 2634498892, 'author': 'gopidesupavan', 'body': 'It looks like the code at https://github.com/apache/airflow/blob/main/docs/exts/operators_and_hooks_ref.py#L430  is fetching the configuration section from the provider. In this particular case, a recent update added a configuration section to the standard provider, but it seems there’s no reference to it in the index file, which I suspect is causing the failure. :)', 'created_at': datetime.datetime(2024, 11, 5, 6, 5, 12, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2024-11-05 06:00:54 UTC): I just realised some doc update missing for moved operators in standard provider. Added to checklist here https://github.com/apache/airflow/issues/43641 to update those.

gopidesupavan (Issue Creator) on (2024-11-05 06:05:12 UTC): It looks like the code at https://github.com/apache/airflow/blob/main/docs/exts/operators_and_hooks_ref.py#L430  is fetching the configuration section from the provider. In this particular case, a recent update added a configuration section to the standard provider, but it seems there’s no reference to it in the index file, which I suspect is causing the failure. :)

"
2634168594,pull_request,closed,,Fix System test type in breeze,"Adjust the behaviour of the `System` test type in Breeze testing tests. Remove the path appending to the beginning of the breeze command (because as we've discussed before with the reorganization of our test directories this creates a non-top level loading of a pytest plugin which pytest disallows). This allow us to still specify the System test type because that option controls other beahviours we need (like disabling db init).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2024-11-05 00:46:40+00:00,[],2024-11-05 07:32:05+00:00,2024-11-05 07:32:05+00:00,https://github.com/apache/airflow/pull/43670,"[('area:dev-tools', '')]","[{'comment_id': 2456430970, 'issue_id': 2634168594, 'author': 'potiuk', 'body': 'The ""standard"" python issue with docs is caused by unrelated issue, we will fix it separately.\r\n\r\nYeah - it looks like a good band-aid for now. I will fix it during https://github.com/apache/airflow/issues/42632 (I already have a draft). I will also add a separate test to test sytem tests in CI as part of it, so that it will not happen in the future', 'created_at': datetime.datetime(2024, 11, 5, 7, 32, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2024-11-05 07:32:01 UTC): The ""standard"" python issue with docs is caused by unrelated issue, we will fix it separately.

Yeah - it looks like a good band-aid for now. I will fix it during https://github.com/apache/airflow/issues/42632 (I already have a draft). I will also add a separate test to test sytem tests in CI as part of it, so that it will not happen in the future

"
2634126867,pull_request,closed,,Add AWS Redshift Serverless support to PostgresHook,"This change add AWS Redshift Serverless support to the `PostgresHook`.

`PostgresHook` now supports the following keys in the `extras` of the connection parameters (or the query parameters if the connection is specified by a URI):
- `redshift-serverless`: set this to `True` to authenticate and connect to an AWS Redshift Serverless authentication
- `workgroup-name`: the name of the workgroup associated with the database, to be passed to the redshift-serverless client's `get_credentials` method when authenticating (if the workgroup-name is not provided, the hook falls back to the first label of the hostname in the same fashion as the redshift option for `PostgresHook`)
",topherinternational,2024-11-05 00:01:24+00:00,[],2024-11-06 07:22:24+00:00,2024-11-06 07:22:24+00:00,https://github.com/apache/airflow/pull/43669,"[('area:providers', ''), ('provider:postgres', '')]","[{'comment_id': 2458391290, 'issue_id': 2634126867, 'author': 'topherinternational', 'body': 'To most of the reviewers - your being requested was an accident, a rebase-push went bad and brought in a bunch of other changes so a bunch of people got tagged.', 'created_at': datetime.datetime(2024, 11, 5, 23, 18, 48, tzinfo=datetime.timezone.utc)}]","topherinternational (Issue Creator) on (2024-11-05 23:18:48 UTC): To most of the reviewers - your being requested was an accident, a rebase-push went bad and brought in a bunch of other changes so a bunch of people got tagged.

"
2634036086,pull_request,closed,,Bump `ruff` to `0.7.2`,"updates:
- [github.com/astral-sh/ruff-pre-commit: v0.7.1 → v0.7.2](https://github.com/astral-sh/ruff-pre-commit/compare/v0.7.1...v0.7.2)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-04 22:59:16+00:00,[],2024-11-04 23:24:08+00:00,2024-11-04 23:24:07+00:00,https://github.com/apache/airflow/pull/43668,"[('area:dev-tools', '')]",[],
2633985279,pull_request,closed,,AIP-72: Remove DAG pickling,"This was a less used part of Airflow and does not make sense to keep it since we are removing DB access as part of AIP-72, I am removing it here. This was missed in Airflow 2.0!

### TODO

- [x] Handle it for Celery & Kubernetes Executors

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-04 22:29:56+00:00,[],2024-11-05 09:06:06+00:00,2024-11-05 09:06:04+00:00,https://github.com/apache/airflow/pull/43667,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('area:db-migrations', 'PRs with DB migration'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]","[{'comment_id': 2455862109, 'issue_id': 2633985279, 'author': 'kaxil', 'body': '@jedcunningham Done now :) - https://github.com/apache/airflow/pull/43667/commits/c6505d7d5260a4b3e304a995d2bdb54662408379', 'created_at': datetime.datetime(2024, 11, 4, 22, 51, 23, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2024-11-04 22:51:23 UTC): @jedcunningham Done now :) - https://github.com/apache/airflow/pull/43667/commits/c6505d7d5260a4b3e304a995d2bdb54662408379

"
2633926131,pull_request,closed,,AIP-82 Create references between triggers and assets,"Resolves #42509.

This migration creates a table to store relations between triggers and assets. The goal is a trigger can update an asset whenever an external change is detected.

For more details on AIP-82, please [read the AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-82+External+event+driven+scheduling+in+Airflow).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2024-11-04 21:53:07+00:00,[],2024-11-07 17:32:01+00:00,2024-11-07 17:31:58+00:00,https://github.com/apache/airflow/pull/43666,"[('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration')]","[{'comment_id': 2455909705, 'issue_id': 2633926131, 'author': 'vincbeck', 'body': '> Hey, it\'s not really clear exactly what we\'re doing with this relationship and therefore it\'s kindof hard to review -- we don\'t know how it will be used, so it\'s not clear if this is the right structure as opposed to say a many to many relationship.\r\n> \r\n> Why do we need a key between the trigger and the asset in order for the trigger to do something with the asset or in response to an asset update? E.g. couldn\'t it just take an asset id as kwargs to the trigger obj?\r\n\r\nThe goal here is to create a table to store references between assets and triggers. The relation here is many to many (hence the table). Or maybe I did something wrong and the relation is not many to many? Nonetheless, the relation SHOULD be many to many :)\r\n\r\nWhy do we want to associate assets and triggers? The ultimate goal is to add `watchers` to assets. These watchers are triggers and whenever the trigger is triggered ... it updates the asset. See example below:\r\n\r\n```\r\ntrigger = SqsSensorTrigger(sqs_queue=""<my_queue>"")\r\nasset = Asset(""<my_queue>"", watchers=[trigger])\r\n```\r\n\r\nWhenever the trigger `trigger` is triggered, the asset `asset` will be sent an event \r\n\r\n> E.g. couldn\'t it just take an asset id as kwargs to the trigger obj?\r\n\r\nI am not sure I understand this one :)', 'created_at': datetime.datetime(2024, 11, 4, 23, 30, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455932312, 'issue_id': 2633926131, 'author': 'dstandish', 'body': ""> > E.g. couldn't it just take an asset id as kwargs to the trigger obj?\r\n> \r\n> I am not sure I understand this one :)\r\n\r\nI was saying like we create a trigger like `MyTrigger(asset_id: str, other_stuff: Any)`\r\n\r\nBut I see now from your explanation and example that you are looking to change triggers so they are not specific to a TI, but rather that they may be long lived, not associated with a TI, and can be instead associated to assets.  And one asset can be associated to many triggers.  And one trigger can be associated with many assets.\r\n\r\nThis is a big one 😅"", 'created_at': datetime.datetime(2024, 11, 4, 23, 46, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2455939430, 'issue_id': 2633926131, 'author': 'vincbeck', 'body': ""> > > E.g. couldn't it just take an asset id as kwargs to the trigger obj?\r\n> > \r\n> > \r\n> > I am not sure I understand this one :)\r\n> \r\n> I was saying like we create a trigger like `MyTrigger(asset_id: str, other_stuff: Any)`\r\n> \r\n> But I see now from your explanation and example that you are looking to change triggers so they are not specific to a TI, but rather that they may be long lived, not associated with a TI, and can be instead associated to assets. And one asset can be associated to many triggers. And one trigger can be associated with many assets.\r\n> \r\n> This is a big one 😅\r\n\r\nHaha, yeah :) This is AIP-82 :) First cornerstone :D But I am happy you understood exactly what I am trying to do"", 'created_at': datetime.datetime(2024, 11, 4, 23, 52, 40, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2024-11-04 23:30:14 UTC): The goal here is to create a table to store references between assets and triggers. The relation here is many to many (hence the table). Or maybe I did something wrong and the relation is not many to many? Nonetheless, the relation SHOULD be many to many :)

Why do we want to associate assets and triggers? The ultimate goal is to add `watchers` to assets. These watchers are triggers and whenever the trigger is triggered ... it updates the asset. See example below:

```
trigger = SqsSensorTrigger(sqs_queue=""<my_queue>"")
asset = Asset(""<my_queue>"", watchers=[trigger])
```

Whenever the trigger `trigger` is triggered, the asset `asset` will be sent an event 


I am not sure I understand this one :)

dstandish on (2024-11-04 23:46:06 UTC): I was saying like we create a trigger like `MyTrigger(asset_id: str, other_stuff: Any)`

But I see now from your explanation and example that you are looking to change triggers so they are not specific to a TI, but rather that they may be long lived, not associated with a TI, and can be instead associated to assets.  And one asset can be associated to many triggers.  And one trigger can be associated with many assets.

This is a big one 😅

vincbeck (Issue Creator) on (2024-11-04 23:52:40 UTC): Haha, yeah :) This is AIP-82 :) First cornerstone :D But I am happy you understood exactly what I am trying to do

"
2633916811,pull_request,closed,,Replace subtask references,"Follow-up of https://github.com/apache/airflow/pull/43599, specifically https://github.com/apache/airflow/pull/43599/files#r1826351853 from @dstandish.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-04 21:46:44+00:00,[],2024-12-26 00:15:14+00:00,2024-12-26 00:15:14+00:00,https://github.com/apache/airflow/pull/43665,"[('stale', 'Stale PRs per the .github/workflows/stale.yml policy file'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', '')]","[{'comment_id': 2555996887, 'issue_id': 2633916811, 'author': 'github-actions[bot]', 'body': 'This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.', 'created_at': datetime.datetime(2024, 12, 20, 0, 15, 28, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2024-12-20 00:15:28 UTC): This pull request has been automatically marked as stale because it has not had recent activity. It will be closed in 5 days if no further activity occurs. Thank you for your contributions.

"
2633891819,pull_request,closed,,Pass Task Instance ids in API response,"https://github.com/apache/airflow/pull/43243 added Task Instance ""id"" as primary key. This PR passes the same API to API responses.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2024-11-04 21:32:14+00:00,[],2024-11-04 22:54:34+00:00,2024-11-04 22:54:33+00:00,https://github.com/apache/airflow/pull/43664,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
